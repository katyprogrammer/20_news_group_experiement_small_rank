Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 200),b=(200,)
decomposing tensor W of shape (1, 200, 200)...
decomposing tensor B of shape (1, 200)...
Starting training...
Epoch 1 of 2000 took 0.050s
  training loss:		2.949375
  validation loss:		2.845780
  validation accuracy:		12.39 %
Epoch 2 of 2000 took 0.043s
  training loss:		2.774025
  validation loss:		2.624289
  validation accuracy:		12.83 %
Epoch 3 of 2000 took 0.039s
  training loss:		2.586264
  validation loss:		2.425959
  validation accuracy:		12.83 %
Epoch 4 of 2000 took 0.038s
  training loss:		2.440457
  validation loss:		2.298387
  validation accuracy:		28.04 %
Epoch 5 of 2000 took 0.038s
  training loss:		2.350142
  validation loss:		2.253103
  validation accuracy:		29.46 %
Epoch 6 of 2000 took 0.037s
  training loss:		2.306605
  validation loss:		2.239704
  validation accuracy:		33.15 %
Epoch 7 of 2000 took 0.037s
  training loss:		2.283760
  validation loss:		2.227263
  validation accuracy:		24.46 %
Epoch 8 of 2000 took 0.037s
  training loss:		2.270171
  validation loss:		2.205317
  validation accuracy:		31.20 %
Epoch 9 of 2000 took 0.044s
  training loss:		2.259781
  validation loss:		2.199155
  validation accuracy:		53.37 %
Epoch 10 of 2000 took 0.056s
  training loss:		2.249512
  validation loss:		2.193115
  validation accuracy:		30.65 %
Epoch 11 of 2000 took 0.046s
  training loss:		2.239628
  validation loss:		2.176640
  validation accuracy:		34.35 %
Epoch 12 of 2000 took 0.041s
  training loss:		2.230777
  validation loss:		2.171980
  validation accuracy:		46.63 %
Epoch 13 of 2000 took 0.037s
  training loss:		2.219471
  validation loss:		2.154923
  validation accuracy:		32.61 %
Epoch 14 of 2000 took 0.035s
  training loss:		2.209874
  validation loss:		2.143261
  validation accuracy:		43.48 %
Epoch 15 of 2000 took 0.035s
  training loss:		2.197636
  validation loss:		2.134571
  validation accuracy:		50.00 %
Epoch 16 of 2000 took 0.035s
  training loss:		2.185490
  validation loss:		2.118281
  validation accuracy:		46.96 %
Epoch 17 of 2000 took 0.035s
  training loss:		2.171858
  validation loss:		2.099553
  validation accuracy:		44.13 %
Epoch 18 of 2000 took 0.035s
  training loss:		2.158113
  validation loss:		2.090565
  validation accuracy:		47.93 %
Epoch 19 of 2000 took 0.035s
  training loss:		2.140196
  validation loss:		2.062557
  validation accuracy:		51.30 %
Epoch 20 of 2000 took 0.035s
  training loss:		2.122723
  validation loss:		2.045497
  validation accuracy:		50.54 %
Epoch 21 of 2000 took 0.038s
  training loss:		2.100631
  validation loss:		2.024994
  validation accuracy:		47.17 %
Epoch 22 of 2000 took 0.035s
  training loss:		2.081690
  validation loss:		2.003213
  validation accuracy:		59.46 %
Epoch 23 of 2000 took 0.035s
  training loss:		2.057939
  validation loss:		1.968623
  validation accuracy:		51.20 %
Epoch 24 of 2000 took 0.035s
  training loss:		2.031241
  validation loss:		1.945697
  validation accuracy:		56.30 %
Epoch 25 of 2000 took 0.035s
  training loss:		2.003123
  validation loss:		1.917098
  validation accuracy:		58.37 %
Epoch 26 of 2000 took 0.035s
  training loss:		1.975240
  validation loss:		1.885421
  validation accuracy:		58.37 %
Epoch 27 of 2000 took 0.035s
  training loss:		1.943914
  validation loss:		1.855452
  validation accuracy:		65.76 %
Epoch 28 of 2000 took 0.035s
  training loss:		1.913010
  validation loss:		1.808381
  validation accuracy:		63.15 %
Epoch 29 of 2000 took 0.035s
  training loss:		1.877521
  validation loss:		1.784347
  validation accuracy:		65.00 %
Epoch 30 of 2000 took 0.035s
  training loss:		1.843728
  validation loss:		1.743028
  validation accuracy:		64.89 %
Epoch 31 of 2000 took 0.035s
  training loss:		1.804468
  validation loss:		1.691055
  validation accuracy:		71.20 %
Epoch 32 of 2000 took 0.035s
  training loss:		1.770631
  validation loss:		1.663909
  validation accuracy:		72.72 %
Epoch 33 of 2000 took 0.035s
  training loss:		1.733953
  validation loss:		1.617147
  validation accuracy:		73.70 %
Epoch 34 of 2000 took 0.035s
  training loss:		1.688379
  validation loss:		1.577440
  validation accuracy:		73.48 %
Epoch 35 of 2000 took 0.035s
  training loss:		1.648316
  validation loss:		1.529743
  validation accuracy:		78.48 %
Epoch 36 of 2000 took 0.036s
  training loss:		1.603660
  validation loss:		1.489517
  validation accuracy:		75.54 %
Epoch 37 of 2000 took 0.035s
  training loss:		1.558496
  validation loss:		1.432669
  validation accuracy:		79.13 %
Epoch 38 of 2000 took 0.036s
  training loss:		1.509366
  validation loss:		1.387098
  validation accuracy:		78.59 %
Epoch 39 of 2000 took 0.036s
  training loss:		1.458570
  validation loss:		1.335658
  validation accuracy:		77.61 %
Epoch 40 of 2000 took 0.035s
  training loss:		1.411838
  validation loss:		1.284389
  validation accuracy:		80.76 %
Epoch 41 of 2000 took 0.035s
  training loss:		1.360464
  validation loss:		1.234942
  validation accuracy:		81.30 %
Epoch 42 of 2000 took 0.035s
  training loss:		1.311246
  validation loss:		1.185940
  validation accuracy:		81.74 %
Epoch 43 of 2000 took 0.035s
  training loss:		1.257864
  validation loss:		1.130034
  validation accuracy:		83.37 %
Epoch 44 of 2000 took 0.035s
  training loss:		1.216595
  validation loss:		1.097050
  validation accuracy:		82.07 %
Epoch 45 of 2000 took 0.035s
  training loss:		1.166366
  validation loss:		1.043116
  validation accuracy:		81.85 %
Epoch 46 of 2000 took 0.035s
  training loss:		1.123625
  validation loss:		1.001428
  validation accuracy:		81.74 %
Epoch 47 of 2000 took 0.036s
  training loss:		1.077741
  validation loss:		0.962553
  validation accuracy:		83.15 %
Epoch 48 of 2000 took 0.035s
  training loss:		1.042162
  validation loss:		0.920640
  validation accuracy:		82.61 %
Epoch 49 of 2000 took 0.035s
  training loss:		0.995975
  validation loss:		0.886669
  validation accuracy:		84.78 %
Epoch 50 of 2000 took 0.035s
  training loss:		0.954233
  validation loss:		0.849604
  validation accuracy:		82.83 %
Epoch 51 of 2000 took 0.035s
  training loss:		0.921002
  validation loss:		0.818098
  validation accuracy:		83.04 %
Epoch 52 of 2000 took 0.035s
  training loss:		0.885788
  validation loss:		0.793257
  validation accuracy:		84.78 %
Epoch 53 of 2000 took 0.035s
  training loss:		0.856466
  validation loss:		0.758922
  validation accuracy:		84.78 %
Epoch 54 of 2000 took 0.035s
  training loss:		0.822745
  validation loss:		0.728381
  validation accuracy:		85.22 %
Epoch 55 of 2000 took 0.035s
  training loss:		0.797197
  validation loss:		0.705056
  validation accuracy:		85.87 %
Epoch 56 of 2000 took 0.035s
  training loss:		0.766892
  validation loss:		0.674283
  validation accuracy:		85.54 %
Epoch 57 of 2000 took 0.035s
  training loss:		0.734742
  validation loss:		0.648097
  validation accuracy:		86.85 %
Epoch 58 of 2000 took 0.035s
  training loss:		0.717991
  validation loss:		0.632431
  validation accuracy:		85.76 %
Epoch 59 of 2000 took 0.035s
  training loss:		0.687821
  validation loss:		0.615071
  validation accuracy:		87.61 %
Epoch 60 of 2000 took 0.035s
  training loss:		0.670687
  validation loss:		0.588044
  validation accuracy:		86.74 %
Epoch 61 of 2000 took 0.035s
  training loss:		0.643904
  validation loss:		0.575684
  validation accuracy:		86.20 %
Epoch 62 of 2000 took 0.038s
  training loss:		0.625640
  validation loss:		0.561449
  validation accuracy:		88.37 %
Epoch 63 of 2000 took 0.036s
  training loss:		0.612925
  validation loss:		0.536850
  validation accuracy:		87.39 %
Epoch 64 of 2000 took 0.035s
  training loss:		0.587905
  validation loss:		0.523083
  validation accuracy:		88.04 %
Epoch 65 of 2000 took 0.035s
  training loss:		0.569658
  validation loss:		0.509439
  validation accuracy:		88.26 %
Epoch 66 of 2000 took 0.035s
  training loss:		0.557170
  validation loss:		0.494678
  validation accuracy:		87.61 %
Epoch 67 of 2000 took 0.035s
  training loss:		0.543380
  validation loss:		0.479609
  validation accuracy:		89.13 %
Epoch 68 of 2000 took 0.035s
  training loss:		0.526301
  validation loss:		0.478991
  validation accuracy:		88.26 %
Epoch 69 of 2000 took 0.035s
  training loss:		0.513853
  validation loss:		0.457674
  validation accuracy:		88.70 %
Epoch 70 of 2000 took 0.035s
  training loss:		0.499285
  validation loss:		0.449491
  validation accuracy:		89.13 %
Epoch 71 of 2000 took 0.035s
  training loss:		0.487904
  validation loss:		0.430690
  validation accuracy:		89.89 %
Epoch 72 of 2000 took 0.035s
  training loss:		0.475049
  validation loss:		0.431490
  validation accuracy:		89.13 %
Epoch 73 of 2000 took 0.035s
  training loss:		0.470375
  validation loss:		0.418759
  validation accuracy:		90.33 %
Epoch 74 of 2000 took 0.035s
  training loss:		0.456252
  validation loss:		0.402439
  validation accuracy:		90.65 %
Epoch 75 of 2000 took 0.035s
  training loss:		0.446649
  validation loss:		0.403884
  validation accuracy:		90.33 %
Epoch 76 of 2000 took 0.035s
  training loss:		0.440011
  validation loss:		0.398937
  validation accuracy:		89.78 %
Epoch 77 of 2000 took 0.035s
  training loss:		0.432967
  validation loss:		0.392141
  validation accuracy:		90.22 %
Epoch 78 of 2000 took 0.035s
  training loss:		0.421264
  validation loss:		0.387773
  validation accuracy:		90.54 %
Epoch 79 of 2000 took 0.035s
  training loss:		0.410710
  validation loss:		0.372815
  validation accuracy:		90.87 %
Epoch 80 of 2000 took 0.035s
  training loss:		0.404152
  validation loss:		0.360948
  validation accuracy:		91.74 %
Epoch 81 of 2000 took 0.035s
  training loss:		0.395240
  validation loss:		0.357901
  validation accuracy:		91.41 %
Epoch 82 of 2000 took 0.035s
  training loss:		0.391067
  validation loss:		0.356090
  validation accuracy:		91.20 %
Epoch 83 of 2000 took 0.035s
  training loss:		0.385758
  validation loss:		0.348103
  validation accuracy:		91.63 %
Epoch 84 of 2000 took 0.035s
  training loss:		0.375518
  validation loss:		0.341886
  validation accuracy:		91.85 %
Epoch 85 of 2000 took 0.035s
  training loss:		0.367245
  validation loss:		0.346917
  validation accuracy:		91.20 %
Epoch 86 of 2000 took 0.035s
  training loss:		0.358362
  validation loss:		0.331014
  validation accuracy:		91.96 %
Epoch 87 of 2000 took 0.035s
  training loss:		0.361928
  validation loss:		0.327008
  validation accuracy:		92.39 %
Epoch 88 of 2000 took 0.035s
  training loss:		0.353866
  validation loss:		0.323265
  validation accuracy:		92.39 %
Epoch 89 of 2000 took 0.035s
  training loss:		0.349722
  validation loss:		0.322725
  validation accuracy:		91.85 %
Epoch 90 of 2000 took 0.035s
  training loss:		0.345837
  validation loss:		0.312726
  validation accuracy:		92.28 %
Epoch 91 of 2000 took 0.035s
  training loss:		0.336699
  validation loss:		0.317345
  validation accuracy:		92.39 %
Epoch 92 of 2000 took 0.035s
  training loss:		0.333041
  validation loss:		0.323083
  validation accuracy:		91.85 %
Epoch 93 of 2000 took 0.035s
  training loss:		0.330816
  validation loss:		0.335692
  validation accuracy:		90.87 %
Epoch 94 of 2000 took 0.035s
  training loss:		0.327386
  validation loss:		0.309646
  validation accuracy:		92.07 %
Epoch 95 of 2000 took 0.035s
  training loss:		0.320221
  validation loss:		0.304837
  validation accuracy:		92.39 %
Epoch 96 of 2000 took 0.035s
  training loss:		0.315806
  validation loss:		0.303063
  validation accuracy:		92.28 %
Epoch 97 of 2000 took 0.035s
  training loss:		0.311659
  validation loss:		0.296040
  validation accuracy:		92.83 %
Epoch 98 of 2000 took 0.035s
  training loss:		0.307590
  validation loss:		0.296955
  validation accuracy:		92.50 %
Epoch 99 of 2000 took 0.035s
  training loss:		0.303181
  validation loss:		0.285809
  validation accuracy:		92.50 %
Epoch 100 of 2000 took 0.035s
  training loss:		0.300738
  validation loss:		0.291080
  validation accuracy:		92.83 %
Epoch 101 of 2000 took 0.035s
  training loss:		0.296518
  validation loss:		0.288436
  validation accuracy:		92.83 %
Epoch 102 of 2000 took 0.035s
  training loss:		0.297317
  validation loss:		0.280951
  validation accuracy:		92.50 %
Epoch 103 of 2000 took 0.035s
  training loss:		0.290254
  validation loss:		0.283068
  validation accuracy:		92.17 %
Epoch 104 of 2000 took 0.036s
  training loss:		0.287757
  validation loss:		0.277138
  validation accuracy:		92.93 %
Epoch 105 of 2000 took 0.035s
  training loss:		0.286659
  validation loss:		0.281844
  validation accuracy:		92.39 %
Epoch 106 of 2000 took 0.035s
  training loss:		0.282706
  validation loss:		0.268230
  validation accuracy:		92.72 %
Epoch 107 of 2000 took 0.035s
  training loss:		0.277382
  validation loss:		0.275466
  validation accuracy:		92.72 %
Epoch 108 of 2000 took 0.035s
  training loss:		0.276263
  validation loss:		0.274285
  validation accuracy:		92.83 %
Epoch 109 of 2000 took 0.035s
  training loss:		0.274822
  validation loss:		0.266237
  validation accuracy:		92.83 %
Epoch 110 of 2000 took 0.035s
  training loss:		0.269115
  validation loss:		0.278723
  validation accuracy:		92.61 %
Epoch 111 of 2000 took 0.035s
  training loss:		0.272298
  validation loss:		0.268382
  validation accuracy:		93.04 %
Epoch 112 of 2000 took 0.035s
  training loss:		0.265870
  validation loss:		0.256221
  validation accuracy:		93.48 %
Epoch 113 of 2000 took 0.035s
  training loss:		0.261393
  validation loss:		0.257693
  validation accuracy:		93.15 %
Epoch 114 of 2000 took 0.035s
  training loss:		0.253979
  validation loss:		0.261503
  validation accuracy:		92.83 %
Epoch 115 of 2000 took 0.035s
  training loss:		0.256183
  validation loss:		0.268399
  validation accuracy:		93.04 %
Epoch 116 of 2000 took 0.035s
  training loss:		0.257602
  validation loss:		0.255277
  validation accuracy:		92.93 %
Epoch 117 of 2000 took 0.035s
  training loss:		0.251337
  validation loss:		0.260348
  validation accuracy:		92.61 %
Epoch 118 of 2000 took 0.035s
  training loss:		0.250730
  validation loss:		0.247625
  validation accuracy:		93.37 %
Epoch 119 of 2000 took 0.035s
  training loss:		0.248931
  validation loss:		0.247904
  validation accuracy:		93.04 %
Epoch 120 of 2000 took 0.035s
  training loss:		0.246118
  validation loss:		0.247747
  validation accuracy:		93.48 %
Epoch 121 of 2000 took 0.036s
  training loss:		0.244878
  validation loss:		0.253964
  validation accuracy:		93.37 %
Epoch 122 of 2000 took 0.035s
  training loss:		0.241713
  validation loss:		0.254403
  validation accuracy:		93.26 %
Epoch 123 of 2000 took 0.035s
  training loss:		0.238915
  validation loss:		0.251383
  validation accuracy:		92.72 %
Epoch 124 of 2000 took 0.036s
  training loss:		0.236238
  validation loss:		0.248243
  validation accuracy:		92.93 %
Epoch 125 of 2000 took 0.035s
  training loss:		0.234691
  validation loss:		0.251820
  validation accuracy:		93.37 %
Epoch 126 of 2000 took 0.035s
  training loss:		0.233143
  validation loss:		0.237718
  validation accuracy:		93.37 %
Epoch 127 of 2000 took 0.035s
  training loss:		0.233333
  validation loss:		0.244320
  validation accuracy:		93.48 %
Epoch 128 of 2000 took 0.035s
  training loss:		0.228976
  validation loss:		0.248775
  validation accuracy:		93.37 %
Epoch 129 of 2000 took 0.035s
  training loss:		0.234685
  validation loss:		0.246104
  validation accuracy:		93.15 %
Epoch 130 of 2000 took 0.035s
  training loss:		0.227464
  validation loss:		0.234121
  validation accuracy:		93.80 %
Epoch 131 of 2000 took 0.035s
  training loss:		0.225115
  validation loss:		0.241609
  validation accuracy:		93.59 %
Epoch 132 of 2000 took 0.035s
  training loss:		0.223810
  validation loss:		0.230484
  validation accuracy:		93.70 %
Epoch 133 of 2000 took 0.035s
  training loss:		0.221660
  validation loss:		0.241793
  validation accuracy:		93.48 %
Epoch 134 of 2000 took 0.035s
  training loss:		0.222068
  validation loss:		0.236020
  validation accuracy:		93.37 %
Epoch 135 of 2000 took 0.035s
  training loss:		0.220511
  validation loss:		0.231409
  validation accuracy:		94.24 %
Epoch 136 of 2000 took 0.035s
  training loss:		0.218690
  validation loss:		0.227973
  validation accuracy:		93.91 %
Epoch 137 of 2000 took 0.035s
  training loss:		0.218477
  validation loss:		0.229432
  validation accuracy:		93.70 %
Epoch 138 of 2000 took 0.035s
  training loss:		0.217380
  validation loss:		0.232062
  validation accuracy:		93.70 %
Epoch 139 of 2000 took 0.035s
  training loss:		0.215415
  validation loss:		0.224598
  validation accuracy:		93.91 %
Epoch 140 of 2000 took 0.035s
  training loss:		0.210923
  validation loss:		0.228774
  validation accuracy:		93.37 %
Epoch 141 of 2000 took 0.035s
  training loss:		0.212287
  validation loss:		0.223801
  validation accuracy:		94.02 %
Epoch 142 of 2000 took 0.035s
  training loss:		0.207465
  validation loss:		0.227325
  validation accuracy:		93.80 %
Epoch 143 of 2000 took 0.035s
  training loss:		0.206144
  validation loss:		0.225099
  validation accuracy:		93.91 %
Epoch 144 of 2000 took 0.035s
  training loss:		0.206482
  validation loss:		0.224601
  validation accuracy:		94.13 %
Epoch 145 of 2000 took 0.035s
  training loss:		0.204917
  validation loss:		0.234407
  validation accuracy:		93.48 %
Epoch 146 of 2000 took 0.035s
  training loss:		0.204217
  validation loss:		0.221428
  validation accuracy:		93.80 %
Epoch 147 of 2000 took 0.035s
  training loss:		0.204087
  validation loss:		0.219811
  validation accuracy:		93.91 %
Epoch 148 of 2000 took 0.035s
  training loss:		0.200301
  validation loss:		0.222835
  validation accuracy:		93.26 %
Epoch 149 of 2000 took 0.035s
  training loss:		0.203045
  validation loss:		0.220075
  validation accuracy:		94.24 %
Epoch 150 of 2000 took 0.035s
  training loss:		0.201238
  validation loss:		0.225377
  validation accuracy:		94.13 %
Epoch 151 of 2000 took 0.035s
  training loss:		0.200889
  validation loss:		0.219959
  validation accuracy:		94.13 %
Epoch 152 of 2000 took 0.035s
  training loss:		0.200603
  validation loss:		0.223284
  validation accuracy:		93.48 %
Epoch 153 of 2000 took 0.035s
  training loss:		0.195635
  validation loss:		0.218936
  validation accuracy:		94.13 %
Epoch 154 of 2000 took 0.035s
  training loss:		0.193219
  validation loss:		0.224385
  validation accuracy:		94.02 %
Epoch 155 of 2000 took 0.035s
  training loss:		0.196274
  validation loss:		0.222463
  validation accuracy:		94.24 %
Epoch 156 of 2000 took 0.035s
  training loss:		0.191595
  validation loss:		0.226098
  validation accuracy:		93.59 %
Epoch 157 of 2000 took 0.035s
  training loss:		0.193987
  validation loss:		0.221404
  validation accuracy:		94.13 %
Epoch 158 of 2000 took 0.035s
  training loss:		0.193176
  validation loss:		0.213786
  validation accuracy:		94.02 %
Epoch 159 of 2000 took 0.035s
  training loss:		0.187667
  validation loss:		0.221992
  validation accuracy:		93.80 %
Epoch 160 of 2000 took 0.035s
  training loss:		0.188986
  validation loss:		0.213087
  validation accuracy:		94.35 %
Epoch 161 of 2000 took 0.035s
  training loss:		0.188626
  validation loss:		0.222980
  validation accuracy:		93.37 %
Epoch 162 of 2000 took 0.035s
  training loss:		0.188542
  validation loss:		0.208554
  validation accuracy:		94.35 %
Epoch 163 of 2000 took 0.036s
  training loss:		0.190816
  validation loss:		0.212878
  validation accuracy:		93.91 %
Epoch 164 of 2000 took 0.035s
  training loss:		0.185677
  validation loss:		0.232072
  validation accuracy:		93.80 %
Epoch 165 of 2000 took 0.035s
  training loss:		0.188362
  validation loss:		0.217771
  validation accuracy:		93.91 %
Epoch 166 of 2000 took 0.035s
  training loss:		0.183646
  validation loss:		0.214753
  validation accuracy:		93.70 %
Epoch 167 of 2000 took 0.035s
  training loss:		0.184481
  validation loss:		0.217449
  validation accuracy:		94.13 %
Epoch 168 of 2000 took 0.035s
  training loss:		0.184930
  validation loss:		0.227884
  validation accuracy:		93.59 %
Epoch 169 of 2000 took 0.035s
  training loss:		0.181632
  validation loss:		0.218364
  validation accuracy:		93.80 %
Epoch 170 of 2000 took 0.035s
  training loss:		0.180308
  validation loss:		0.216339
  validation accuracy:		93.48 %
Epoch 171 of 2000 took 0.035s
  training loss:		0.180344
  validation loss:		0.214450
  validation accuracy:		93.59 %
Epoch 172 of 2000 took 0.035s
  training loss:		0.175924
  validation loss:		0.216128
  validation accuracy:		93.91 %
Epoch 173 of 2000 took 0.035s
  training loss:		0.177930
  validation loss:		0.208667
  validation accuracy:		93.80 %
Epoch 174 of 2000 took 0.035s
  training loss:		0.180357
  validation loss:		0.217306
  validation accuracy:		93.70 %
Epoch 175 of 2000 took 0.035s
  training loss:		0.176415
  validation loss:		0.223258
  validation accuracy:		94.02 %
Epoch 176 of 2000 took 0.035s
  training loss:		0.175286
  validation loss:		0.219039
  validation accuracy:		93.80 %
Epoch 177 of 2000 took 0.035s
  training loss:		0.174055
  validation loss:		0.203187
  validation accuracy:		94.89 %
Epoch 178 of 2000 took 0.035s
  training loss:		0.171962
  validation loss:		0.211269
  validation accuracy:		94.35 %
Epoch 179 of 2000 took 0.035s
  training loss:		0.172566
  validation loss:		0.209352
  validation accuracy:		94.35 %
Epoch 180 of 2000 took 0.035s
  training loss:		0.172638
  validation loss:		0.215311
  validation accuracy:		94.02 %
Epoch 181 of 2000 took 0.036s
  training loss:		0.171431
  validation loss:		0.206041
  validation accuracy:		94.24 %
Epoch 182 of 2000 took 0.035s
  training loss:		0.172889
  validation loss:		0.203673
  validation accuracy:		94.57 %
Epoch 183 of 2000 took 0.035s
  training loss:		0.171516
  validation loss:		0.202616
  validation accuracy:		94.24 %
Epoch 184 of 2000 took 0.035s
  training loss:		0.170195
  validation loss:		0.199990
  validation accuracy:		94.57 %
Epoch 185 of 2000 took 0.035s
  training loss:		0.165572
  validation loss:		0.216484
  validation accuracy:		94.24 %
Epoch 186 of 2000 took 0.035s
  training loss:		0.166865
  validation loss:		0.204689
  validation accuracy:		94.24 %
Epoch 187 of 2000 took 0.035s
  training loss:		0.167497
  validation loss:		0.206071
  validation accuracy:		93.91 %
Epoch 188 of 2000 took 0.035s
  training loss:		0.168729
  validation loss:		0.204419
  validation accuracy:		94.13 %
Epoch 189 of 2000 took 0.035s
  training loss:		0.163877
  validation loss:		0.207214
  validation accuracy:		94.46 %
Epoch 190 of 2000 took 0.035s
  training loss:		0.167689
  validation loss:		0.203149
  validation accuracy:		94.24 %
Epoch 191 of 2000 took 0.035s
  training loss:		0.163013
  validation loss:		0.206648
  validation accuracy:		94.24 %
Epoch 192 of 2000 took 0.035s
  training loss:		0.161443
  validation loss:		0.203427
  validation accuracy:		94.67 %
Epoch 193 of 2000 took 0.035s
  training loss:		0.162942
  validation loss:		0.196305
  validation accuracy:		94.89 %
Epoch 194 of 2000 took 0.035s
  training loss:		0.164915
  validation loss:		0.205858
  validation accuracy:		94.24 %
Epoch 195 of 2000 took 0.035s
  training loss:		0.164108
  validation loss:		0.203081
  validation accuracy:		94.24 %
Epoch 196 of 2000 took 0.035s
  training loss:		0.156285
  validation loss:		0.200873
  validation accuracy:		94.24 %
Epoch 197 of 2000 took 0.035s
  training loss:		0.160302
  validation loss:		0.208693
  validation accuracy:		94.46 %
Epoch 198 of 2000 took 0.035s
  training loss:		0.158494
  validation loss:		0.205444
  validation accuracy:		93.91 %
Epoch 199 of 2000 took 0.035s
  training loss:		0.158203
  validation loss:		0.200919
  validation accuracy:		94.57 %
Epoch 200 of 2000 took 0.035s
  training loss:		0.157927
  validation loss:		0.209666
  validation accuracy:		94.02 %
Epoch 201 of 2000 took 0.035s
  training loss:		0.157489
  validation loss:		0.206675
  validation accuracy:		94.46 %
Epoch 202 of 2000 took 0.035s
  training loss:		0.157755
  validation loss:		0.208653
  validation accuracy:		94.13 %
Epoch 203 of 2000 took 0.035s
  training loss:		0.157201
  validation loss:		0.210300
  validation accuracy:		93.37 %
Epoch 204 of 2000 took 0.035s
  training loss:		0.157054
  validation loss:		0.198402
  validation accuracy:		94.67 %
Epoch 205 of 2000 took 0.035s
  training loss:		0.159233
  validation loss:		0.211912
  validation accuracy:		93.80 %
Epoch 206 of 2000 took 0.037s
  training loss:		0.158420
  validation loss:		0.198628
  validation accuracy:		94.24 %
Epoch 207 of 2000 took 0.036s
  training loss:		0.154532
  validation loss:		0.201504
  validation accuracy:		93.80 %
Epoch 208 of 2000 took 0.035s
  training loss:		0.154613
  validation loss:		0.201155
  validation accuracy:		94.46 %
Epoch 209 of 2000 took 0.035s
  training loss:		0.154800
  validation loss:		0.195579
  validation accuracy:		94.67 %
Epoch 210 of 2000 took 0.035s
  training loss:		0.155874
  validation loss:		0.198641
  validation accuracy:		94.78 %
Epoch 211 of 2000 took 0.035s
  training loss:		0.152257
  validation loss:		0.209581
  validation accuracy:		93.80 %
Epoch 212 of 2000 took 0.035s
  training loss:		0.152653
  validation loss:		0.216125
  validation accuracy:		93.37 %
Epoch 213 of 2000 took 0.035s
  training loss:		0.153934
  validation loss:		0.209893
  validation accuracy:		93.48 %
Epoch 214 of 2000 took 0.035s
  training loss:		0.150173
  validation loss:		0.201493
  validation accuracy:		94.35 %
Epoch 215 of 2000 took 0.035s
  training loss:		0.150956
  validation loss:		0.197458
  validation accuracy:		94.67 %
Epoch 216 of 2000 took 0.035s
  training loss:		0.150929
  validation loss:		0.195384
  validation accuracy:		94.78 %
Epoch 217 of 2000 took 0.035s
  training loss:		0.151011
  validation loss:		0.213051
  validation accuracy:		94.46 %
Epoch 218 of 2000 took 0.035s
  training loss:		0.151069
  validation loss:		0.196459
  validation accuracy:		94.46 %
Epoch 219 of 2000 took 0.035s
  training loss:		0.147543
  validation loss:		0.205153
  validation accuracy:		94.57 %
Epoch 220 of 2000 took 0.035s
  training loss:		0.149501
  validation loss:		0.199626
  validation accuracy:		94.57 %
Epoch 221 of 2000 took 0.035s
  training loss:		0.145802
  validation loss:		0.199439
  validation accuracy:		94.78 %
Epoch 222 of 2000 took 0.035s
  training loss:		0.150090
  validation loss:		0.212189
  validation accuracy:		93.59 %
Epoch 223 of 2000 took 0.035s
  training loss:		0.148449
  validation loss:		0.196060
  validation accuracy:		94.46 %
Epoch 224 of 2000 took 0.035s
  training loss:		0.145406
  validation loss:		0.202929
  validation accuracy:		94.02 %
Epoch 225 of 2000 took 0.035s
  training loss:		0.147642
  validation loss:		0.194937
  validation accuracy:		95.00 %
Epoch 226 of 2000 took 0.035s
  training loss:		0.144317
  validation loss:		0.200248
  validation accuracy:		94.35 %
Epoch 227 of 2000 took 0.035s
  training loss:		0.140182
  validation loss:		0.197744
  validation accuracy:		94.24 %
Epoch 228 of 2000 took 0.035s
  training loss:		0.143313
  validation loss:		0.203563
  validation accuracy:		94.02 %
Epoch 229 of 2000 took 0.035s
  training loss:		0.144278
  validation loss:		0.196001
  validation accuracy:		94.46 %
Epoch 230 of 2000 took 0.035s
  training loss:		0.145273
  validation loss:		0.207144
  validation accuracy:		93.59 %
Epoch 231 of 2000 took 0.035s
  training loss:		0.142456
  validation loss:		0.204745
  validation accuracy:		94.24 %
Epoch 232 of 2000 took 0.035s
  training loss:		0.140031
  validation loss:		0.201297
  validation accuracy:		94.46 %
Epoch 233 of 2000 took 0.035s
  training loss:		0.138700
  validation loss:		0.191440
  validation accuracy:		95.11 %
Epoch 234 of 2000 took 0.035s
  training loss:		0.143812
  validation loss:		0.199845
  validation accuracy:		94.35 %
Epoch 235 of 2000 took 0.036s
  training loss:		0.143294
  validation loss:		0.189646
  validation accuracy:		94.78 %
Epoch 236 of 2000 took 0.035s
  training loss:		0.140649
  validation loss:		0.199931
  validation accuracy:		94.67 %
Epoch 237 of 2000 took 0.036s
  training loss:		0.135929
  validation loss:		0.205574
  validation accuracy:		93.80 %
Epoch 238 of 2000 took 0.035s
  training loss:		0.140406
  validation loss:		0.208674
  validation accuracy:		93.70 %
Epoch 239 of 2000 took 0.035s
  training loss:		0.140007
  validation loss:		0.200953
  validation accuracy:		94.02 %
Epoch 240 of 2000 took 0.035s
  training loss:		0.138193
  validation loss:		0.196461
  validation accuracy:		94.67 %
Epoch 241 of 2000 took 0.035s
  training loss:		0.140543
  validation loss:		0.193313
  validation accuracy:		94.89 %
Epoch 242 of 2000 took 0.035s
  training loss:		0.137888
  validation loss:		0.211722
  validation accuracy:		93.91 %
Epoch 243 of 2000 took 0.035s
  training loss:		0.140519
  validation loss:		0.207896
  validation accuracy:		93.70 %
Epoch 244 of 2000 took 0.035s
  training loss:		0.138742
  validation loss:		0.202079
  validation accuracy:		94.57 %
Epoch 245 of 2000 took 0.035s
  training loss:		0.134320
  validation loss:		0.198890
  validation accuracy:		94.24 %
Epoch 246 of 2000 took 0.035s
  training loss:		0.136132
  validation loss:		0.198618
  validation accuracy:		94.24 %
Epoch 247 of 2000 took 0.035s
  training loss:		0.138111
  validation loss:		0.206230
  validation accuracy:		93.59 %
Epoch 248 of 2000 took 0.035s
  training loss:		0.133607
  validation loss:		0.199104
  validation accuracy:		94.35 %
Epoch 249 of 2000 took 0.035s
  training loss:		0.135616
  validation loss:		0.209515
  validation accuracy:		93.48 %
Epoch 250 of 2000 took 0.035s
  training loss:		0.136305
  validation loss:		0.197634
  validation accuracy:		94.02 %
Epoch 251 of 2000 took 0.036s
  training loss:		0.131448
  validation loss:		0.201494
  validation accuracy:		94.46 %
Epoch 252 of 2000 took 0.035s
  training loss:		0.131869
  validation loss:		0.189112
  validation accuracy:		94.78 %
Epoch 253 of 2000 took 0.035s
  training loss:		0.135323
  validation loss:		0.200245
  validation accuracy:		94.46 %
Epoch 254 of 2000 took 0.035s
  training loss:		0.130261
  validation loss:		0.208025
  validation accuracy:		93.59 %
Epoch 255 of 2000 took 0.035s
  training loss:		0.130567
  validation loss:		0.200743
  validation accuracy:		94.57 %
Epoch 256 of 2000 took 0.035s
  training loss:		0.134319
  validation loss:		0.194390
  validation accuracy:		94.46 %
Epoch 257 of 2000 took 0.035s
  training loss:		0.131266
  validation loss:		0.208122
  validation accuracy:		94.02 %
Epoch 258 of 2000 took 0.035s
  training loss:		0.132211
  validation loss:		0.195118
  validation accuracy:		94.57 %
Epoch 259 of 2000 took 0.035s
  training loss:		0.131636
  validation loss:		0.193468
  validation accuracy:		94.78 %
Epoch 260 of 2000 took 0.035s
  training loss:		0.126665
  validation loss:		0.196619
  validation accuracy:		94.57 %
Epoch 261 of 2000 took 0.035s
  training loss:		0.133522
  validation loss:		0.196097
  validation accuracy:		95.11 %
Epoch 262 of 2000 took 0.035s
  training loss:		0.131195
  validation loss:		0.197934
  validation accuracy:		94.46 %
Epoch 263 of 2000 took 0.035s
  training loss:		0.129182
  validation loss:		0.187430
  validation accuracy:		94.78 %
Epoch 264 of 2000 took 0.035s
  training loss:		0.128124
  validation loss:		0.203623
  validation accuracy:		94.35 %
Epoch 265 of 2000 took 0.035s
  training loss:		0.129448
  validation loss:		0.194248
  validation accuracy:		94.57 %
Epoch 266 of 2000 took 0.035s
  training loss:		0.132585
  validation loss:		0.207575
  validation accuracy:		94.13 %
Epoch 267 of 2000 took 0.035s
  training loss:		0.129200
  validation loss:		0.202160
  validation accuracy:		94.13 %
Epoch 268 of 2000 took 0.035s
  training loss:		0.127276
  validation loss:		0.196823
  validation accuracy:		94.67 %
Epoch 269 of 2000 took 0.035s
  training loss:		0.127284
  validation loss:		0.205507
  validation accuracy:		94.57 %
Epoch 270 of 2000 took 0.035s
  training loss:		0.127115
  validation loss:		0.198289
  validation accuracy:		94.35 %
Epoch 271 of 2000 took 0.035s
  training loss:		0.125785
  validation loss:		0.199629
  validation accuracy:		94.13 %
Epoch 272 of 2000 took 0.035s
  training loss:		0.126126
  validation loss:		0.206463
  validation accuracy:		94.46 %
Epoch 273 of 2000 took 0.035s
  training loss:		0.126910
  validation loss:		0.202541
  validation accuracy:		94.13 %
Epoch 274 of 2000 took 0.035s
  training loss:		0.128608
  validation loss:		0.198611
  validation accuracy:		94.46 %
Epoch 275 of 2000 took 0.035s
  training loss:		0.123651
  validation loss:		0.196484
  validation accuracy:		94.46 %
Epoch 276 of 2000 took 0.035s
  training loss:		0.123817
  validation loss:		0.193065
  validation accuracy:		94.67 %
Epoch 277 of 2000 took 0.035s
  training loss:		0.126010
  validation loss:		0.197987
  validation accuracy:		94.67 %
Epoch 278 of 2000 took 0.035s
  training loss:		0.121174
  validation loss:		0.200164
  validation accuracy:		94.46 %
Epoch 279 of 2000 took 0.035s
  training loss:		0.123875
  validation loss:		0.199912
  validation accuracy:		94.67 %
Epoch 280 of 2000 took 0.035s
  training loss:		0.123042
  validation loss:		0.198161
  validation accuracy:		94.57 %
Epoch 281 of 2000 took 0.035s
  training loss:		0.121100
  validation loss:		0.201254
  validation accuracy:		94.13 %
Epoch 282 of 2000 took 0.035s
  training loss:		0.125715
  validation loss:		0.204068
  validation accuracy:		94.02 %
Epoch 283 of 2000 took 0.035s
  training loss:		0.119141
  validation loss:		0.195485
  validation accuracy:		94.57 %
Epoch 284 of 2000 took 0.035s
  training loss:		0.120023
  validation loss:		0.196671
  validation accuracy:		94.78 %
Epoch 285 of 2000 took 0.035s
  training loss:		0.119648
  validation loss:		0.208076
  validation accuracy:		94.13 %
Epoch 286 of 2000 took 0.035s
  training loss:		0.118313
  validation loss:		0.198254
  validation accuracy:		94.57 %
Epoch 287 of 2000 took 0.035s
  training loss:		0.119517
  validation loss:		0.193614
  validation accuracy:		94.57 %
Epoch 288 of 2000 took 0.035s
  training loss:		0.118980
  validation loss:		0.200684
  validation accuracy:		94.24 %
Epoch 289 of 2000 took 0.035s
  training loss:		0.122287
  validation loss:		0.200684
  validation accuracy:		94.24 %
Epoch 290 of 2000 took 0.035s
  training loss:		0.117520
  validation loss:		0.197615
  validation accuracy:		94.89 %
Epoch 291 of 2000 took 0.035s
  training loss:		0.119092
  validation loss:		0.203854
  validation accuracy:		94.13 %
Epoch 292 of 2000 took 0.035s
  training loss:		0.119225
  validation loss:		0.198307
  validation accuracy:		94.57 %
Epoch 293 of 2000 took 0.035s
  training loss:		0.119516
  validation loss:		0.199769
  validation accuracy:		94.78 %
Epoch 294 of 2000 took 0.036s
  training loss:		0.117984
  validation loss:		0.197836
  validation accuracy:		94.57 %
Epoch 295 of 2000 took 0.035s
  training loss:		0.116125
  validation loss:		0.206457
  validation accuracy:		94.24 %
Epoch 296 of 2000 took 0.035s
  training loss:		0.120718
  validation loss:		0.198241
  validation accuracy:		94.67 %
Epoch 297 of 2000 took 0.035s
  training loss:		0.115440
  validation loss:		0.197948
  validation accuracy:		94.46 %
Epoch 298 of 2000 took 0.035s
  training loss:		0.117515
  validation loss:		0.191920
  validation accuracy:		94.78 %
Epoch 299 of 2000 took 0.035s
  training loss:		0.115376
  validation loss:		0.196424
  validation accuracy:		94.89 %
Epoch 300 of 2000 took 0.035s
  training loss:		0.116028
  validation loss:		0.194272
  validation accuracy:		94.67 %
Epoch 301 of 2000 took 0.035s
  training loss:		0.118411
  validation loss:		0.199019
  validation accuracy:		94.78 %
Epoch 302 of 2000 took 0.035s
  training loss:		0.117348
  validation loss:		0.201476
  validation accuracy:		94.24 %
Epoch 303 of 2000 took 0.035s
  training loss:		0.114381
  validation loss:		0.203570
  validation accuracy:		94.67 %
Epoch 304 of 2000 took 0.035s
  training loss:		0.114107
  validation loss:		0.200623
  validation accuracy:		94.35 %
Epoch 305 of 2000 took 0.035s
  training loss:		0.117079
  validation loss:		0.201689
  validation accuracy:		94.57 %
Epoch 306 of 2000 took 0.035s
  training loss:		0.116197
  validation loss:		0.206615
  validation accuracy:		94.02 %
Epoch 307 of 2000 took 0.035s
  training loss:		0.115580
  validation loss:		0.200798
  validation accuracy:		94.57 %
Epoch 308 of 2000 took 0.035s
  training loss:		0.113874
  validation loss:		0.188346
  validation accuracy:		94.67 %
Epoch 309 of 2000 took 0.035s
  training loss:		0.110676
  validation loss:		0.200818
  validation accuracy:		94.89 %
Epoch 310 of 2000 took 0.035s
  training loss:		0.111262
  validation loss:		0.202723
  validation accuracy:		94.24 %
Epoch 311 of 2000 took 0.035s
  training loss:		0.110450
  validation loss:		0.202955
  validation accuracy:		94.35 %
Epoch 312 of 2000 took 0.035s
  training loss:		0.113485
  validation loss:		0.207114
  validation accuracy:		94.02 %
Epoch 313 of 2000 took 0.035s
  training loss:		0.112151
  validation loss:		0.203210
  validation accuracy:		94.35 %
Epoch 314 of 2000 took 0.035s
  training loss:		0.111894
  validation loss:		0.198498
  validation accuracy:		94.46 %
Epoch 315 of 2000 took 0.035s
  training loss:		0.108339
  validation loss:		0.208334
  validation accuracy:		94.02 %
Epoch 316 of 2000 took 0.035s
  training loss:		0.110763
  validation loss:		0.204819
  validation accuracy:		94.35 %
Epoch 317 of 2000 took 0.035s
  training loss:		0.109860
  validation loss:		0.202009
  validation accuracy:		94.35 %
Epoch 318 of 2000 took 0.035s
  training loss:		0.110442
  validation loss:		0.209560
  validation accuracy:		94.13 %
Epoch 319 of 2000 took 0.035s
  training loss:		0.108152
  validation loss:		0.201774
  validation accuracy:		94.57 %
Epoch 320 of 2000 took 0.035s
  training loss:		0.112429
  validation loss:		0.197574
  validation accuracy:		94.57 %
Epoch 321 of 2000 took 0.035s
  training loss:		0.108261
  validation loss:		0.197864
  validation accuracy:		94.67 %
Epoch 322 of 2000 took 0.035s
  training loss:		0.107289
  validation loss:		0.201510
  validation accuracy:		94.46 %
Epoch 323 of 2000 took 0.035s
  training loss:		0.111498
  validation loss:		0.213489
  validation accuracy:		93.70 %
Epoch 324 of 2000 took 0.035s
  training loss:		0.106353
  validation loss:		0.205953
  validation accuracy:		94.35 %
Epoch 325 of 2000 took 0.035s
  training loss:		0.109110
  validation loss:		0.207496
  validation accuracy:		94.24 %
Epoch 326 of 2000 took 0.035s
  training loss:		0.108678
  validation loss:		0.203349
  validation accuracy:		94.02 %
Epoch 327 of 2000 took 0.035s
  training loss:		0.107418
  validation loss:		0.200439
  validation accuracy:		94.57 %
Epoch 328 of 2000 took 0.035s
  training loss:		0.104435
  validation loss:		0.211053
  validation accuracy:		94.13 %
Epoch 329 of 2000 took 0.035s
  training loss:		0.106077
  validation loss:		0.205262
  validation accuracy:		94.13 %
Epoch 330 of 2000 took 0.035s
  training loss:		0.108378
  validation loss:		0.194441
  validation accuracy:		94.89 %
Epoch 331 of 2000 took 0.035s
  training loss:		0.107060
  validation loss:		0.207744
  validation accuracy:		94.13 %
Epoch 332 of 2000 took 0.036s
  training loss:		0.105366
  validation loss:		0.202108
  validation accuracy:		94.67 %
Epoch 333 of 2000 took 0.035s
  training loss:		0.107079
  validation loss:		0.214944
  validation accuracy:		93.80 %
Epoch 334 of 2000 took 0.035s
  training loss:		0.108010
  validation loss:		0.209376
  validation accuracy:		93.59 %
Epoch 335 of 2000 took 0.035s
  training loss:		0.105854
  validation loss:		0.199866
  validation accuracy:		94.89 %
Epoch 336 of 2000 took 0.035s
  training loss:		0.106536
  validation loss:		0.211994
  validation accuracy:		93.48 %
Epoch 337 of 2000 took 0.035s
  training loss:		0.105419
  validation loss:		0.207009
  validation accuracy:		94.02 %
Epoch 338 of 2000 took 0.035s
  training loss:		0.107842
  validation loss:		0.201694
  validation accuracy:		94.57 %
Epoch 339 of 2000 took 0.035s
  training loss:		0.106112
  validation loss:		0.206004
  validation accuracy:		94.46 %
Epoch 340 of 2000 took 0.035s
  training loss:		0.103810
  validation loss:		0.207601
  validation accuracy:		93.91 %
Epoch 341 of 2000 took 0.035s
  training loss:		0.102303
  validation loss:		0.204663
  validation accuracy:		94.35 %
Epoch 342 of 2000 took 0.035s
  training loss:		0.105092
  validation loss:		0.209626
  validation accuracy:		93.80 %
Epoch 343 of 2000 took 0.035s
  training loss:		0.104284
  validation loss:		0.202663
  validation accuracy:		94.46 %
Epoch 344 of 2000 took 0.035s
  training loss:		0.102252
  validation loss:		0.229785
  validation accuracy:		93.15 %
Epoch 345 of 2000 took 0.035s
  training loss:		0.106548
  validation loss:		0.210126
  validation accuracy:		94.02 %
Epoch 346 of 2000 took 0.035s
  training loss:		0.098246
  validation loss:		0.210811
  validation accuracy:		94.46 %
Epoch 347 of 2000 took 0.035s
  training loss:		0.103559
  validation loss:		0.211274
  validation accuracy:		94.02 %
Epoch 348 of 2000 took 0.035s
  training loss:		0.102253
  validation loss:		0.206401
  validation accuracy:		94.46 %
Epoch 349 of 2000 took 0.035s
  training loss:		0.104240
  validation loss:		0.197135
  validation accuracy:		94.67 %
Epoch 350 of 2000 took 0.036s
  training loss:		0.101072
  validation loss:		0.203416
  validation accuracy:		94.46 %
Epoch 351 of 2000 took 0.035s
  training loss:		0.102351
  validation loss:		0.210891
  validation accuracy:		94.35 %
Epoch 352 of 2000 took 0.035s
  training loss:		0.097525
  validation loss:		0.210042
  validation accuracy:		93.80 %
Epoch 353 of 2000 took 0.035s
  training loss:		0.103022
  validation loss:		0.203430
  validation accuracy:		94.13 %
Epoch 354 of 2000 took 0.035s
  training loss:		0.099989
  validation loss:		0.204750
  validation accuracy:		94.02 %
Epoch 355 of 2000 took 0.035s
  training loss:		0.101695
  validation loss:		0.218176
  validation accuracy:		93.70 %
Epoch 356 of 2000 took 0.035s
  training loss:		0.100805
  validation loss:		0.214056
  validation accuracy:		93.59 %
Epoch 357 of 2000 took 0.035s
  training loss:		0.101064
  validation loss:		0.209914
  validation accuracy:		93.80 %
Epoch 358 of 2000 took 0.035s
  training loss:		0.097903
  validation loss:		0.210636
  validation accuracy:		94.24 %
Epoch 359 of 2000 took 0.035s
  training loss:		0.098936
  validation loss:		0.205470
  validation accuracy:		94.35 %
Epoch 360 of 2000 took 0.035s
  training loss:		0.098468
  validation loss:		0.199153
  validation accuracy:		94.67 %
Epoch 361 of 2000 took 0.035s
  training loss:		0.099711
  validation loss:		0.208788
  validation accuracy:		93.80 %
Epoch 362 of 2000 took 0.035s
  training loss:		0.098414
  validation loss:		0.204459
  validation accuracy:		94.24 %
Epoch 363 of 2000 took 0.035s
  training loss:		0.097949
  validation loss:		0.205954
  validation accuracy:		94.13 %
Epoch 364 of 2000 took 0.035s
  training loss:		0.097686
  validation loss:		0.211540
  validation accuracy:		93.91 %
Epoch 365 of 2000 took 0.035s
  training loss:		0.095805
  validation loss:		0.214402
  validation accuracy:		93.70 %
Epoch 366 of 2000 took 0.035s
  training loss:		0.093798
  validation loss:		0.206434
  validation accuracy:		94.02 %
Epoch 367 of 2000 took 0.035s
  training loss:		0.097357
  validation loss:		0.203593
  validation accuracy:		94.57 %
Epoch 368 of 2000 took 0.035s
  training loss:		0.095039
  validation loss:		0.203143
  validation accuracy:		94.57 %
Epoch 369 of 2000 took 0.036s
  training loss:		0.096767
  validation loss:		0.214385
  validation accuracy:		93.91 %
Epoch 370 of 2000 took 0.035s
  training loss:		0.095412
  validation loss:		0.200704
  validation accuracy:		94.46 %
Epoch 371 of 2000 took 0.035s
  training loss:		0.097460
  validation loss:		0.208707
  validation accuracy:		94.67 %
Epoch 372 of 2000 took 0.035s
  training loss:		0.095793
  validation loss:		0.210331
  validation accuracy:		94.13 %
Epoch 373 of 2000 took 0.035s
  training loss:		0.094966
  validation loss:		0.209419
  validation accuracy:		94.13 %
Epoch 374 of 2000 took 0.035s
  training loss:		0.093974
  validation loss:		0.206942
  validation accuracy:		94.57 %
Epoch 375 of 2000 took 0.035s
  training loss:		0.095798
  validation loss:		0.207279
  validation accuracy:		94.78 %
Epoch 376 of 2000 took 0.035s
  training loss:		0.094159
  validation loss:		0.210246
  validation accuracy:		94.57 %
Epoch 377 of 2000 took 0.035s
  training loss:		0.090324
  validation loss:		0.203700
  validation accuracy:		94.67 %
Epoch 378 of 2000 took 0.035s
  training loss:		0.092940
  validation loss:		0.207346
  validation accuracy:		94.13 %
Epoch 379 of 2000 took 0.035s
  training loss:		0.094644
  validation loss:		0.209558
  validation accuracy:		94.57 %
Epoch 380 of 2000 took 0.035s
  training loss:		0.096397
  validation loss:		0.203373
  validation accuracy:		94.57 %
Epoch 381 of 2000 took 0.035s
  training loss:		0.095056
  validation loss:		0.209492
  validation accuracy:		94.02 %
Epoch 382 of 2000 took 0.035s
  training loss:		0.091969
  validation loss:		0.220130
  validation accuracy:		93.59 %
Epoch 383 of 2000 took 0.036s
  training loss:		0.092718
  validation loss:		0.206267
  validation accuracy:		94.67 %
Epoch 384 of 2000 took 0.035s
  training loss:		0.093722
  validation loss:		0.211330
  validation accuracy:		94.13 %
Epoch 385 of 2000 took 0.035s
  training loss:		0.092612
  validation loss:		0.215042
  validation accuracy:		94.24 %
Epoch 386 of 2000 took 0.035s
  training loss:		0.088716
  validation loss:		0.225609
  validation accuracy:		93.70 %
Epoch 387 of 2000 took 0.035s
  training loss:		0.093052
  validation loss:		0.211078
  validation accuracy:		94.24 %
Epoch 388 of 2000 took 0.035s
  training loss:		0.089442
  validation loss:		0.206637
  validation accuracy:		94.57 %
Epoch 389 of 2000 took 0.035s
  training loss:		0.092817
  validation loss:		0.207850
  validation accuracy:		94.35 %
Epoch 390 of 2000 took 0.035s
  training loss:		0.089099
  validation loss:		0.213387
  validation accuracy:		94.46 %
Epoch 391 of 2000 took 0.035s
  training loss:		0.091351
  validation loss:		0.214169
  validation accuracy:		94.89 %
Epoch 392 of 2000 took 0.035s
  training loss:		0.091655
  validation loss:		0.206863
  validation accuracy:		94.57 %
Epoch 393 of 2000 took 0.035s
  training loss:		0.091973
  validation loss:		0.206813
  validation accuracy:		94.46 %
Epoch 394 of 2000 took 0.035s
  training loss:		0.090981
  validation loss:		0.210715
  validation accuracy:		94.35 %
Epoch 395 of 2000 took 0.035s
  training loss:		0.090970
  validation loss:		0.207581
  validation accuracy:		94.46 %
Epoch 396 of 2000 took 0.035s
  training loss:		0.087836
  validation loss:		0.215608
  validation accuracy:		94.46 %
Epoch 397 of 2000 took 0.035s
  training loss:		0.090121
  validation loss:		0.223315
  validation accuracy:		93.80 %
Epoch 398 of 2000 took 0.035s
  training loss:		0.089010
  validation loss:		0.205463
  validation accuracy:		94.78 %
Epoch 399 of 2000 took 0.035s
  training loss:		0.088934
  validation loss:		0.213237
  validation accuracy:		94.35 %
Epoch 400 of 2000 took 0.035s
  training loss:		0.086128
  validation loss:		0.214066
  validation accuracy:		94.13 %
Epoch 401 of 2000 took 0.035s
  training loss:		0.089046
  validation loss:		0.208890
  validation accuracy:		94.46 %
Epoch 402 of 2000 took 0.035s
  training loss:		0.089769
  validation loss:		0.207508
  validation accuracy:		94.57 %
Epoch 403 of 2000 took 0.035s
  training loss:		0.089186
  validation loss:		0.214463
  validation accuracy:		94.35 %
Epoch 404 of 2000 took 0.036s
  training loss:		0.089413
  validation loss:		0.209764
  validation accuracy:		94.46 %
Epoch 405 of 2000 took 0.035s
  training loss:		0.087435
  validation loss:		0.219972
  validation accuracy:		94.13 %
Epoch 406 of 2000 took 0.035s
  training loss:		0.087450
  validation loss:		0.223180
  validation accuracy:		93.48 %
Epoch 407 of 2000 took 0.036s
  training loss:		0.086706
  validation loss:		0.217814
  validation accuracy:		93.80 %
Epoch 408 of 2000 took 0.035s
  training loss:		0.087839
  validation loss:		0.211394
  validation accuracy:		94.24 %
Epoch 409 of 2000 took 0.035s
  training loss:		0.090295
  validation loss:		0.223846
  validation accuracy:		94.02 %
Epoch 410 of 2000 took 0.035s
  training loss:		0.087103
  validation loss:		0.218387
  validation accuracy:		93.91 %
Epoch 411 of 2000 took 0.035s
  training loss:		0.087199
  validation loss:		0.213186
  validation accuracy:		94.35 %
Epoch 412 of 2000 took 0.035s
  training loss:		0.084952
  validation loss:		0.224453
  validation accuracy:		94.02 %
Epoch 413 of 2000 took 0.035s
  training loss:		0.083021
  validation loss:		0.216520
  validation accuracy:		94.57 %
Epoch 414 of 2000 took 0.036s
  training loss:		0.086122
  validation loss:		0.225159
  validation accuracy:		93.80 %
Epoch 415 of 2000 took 0.035s
  training loss:		0.087438
  validation loss:		0.211594
  validation accuracy:		94.57 %
Epoch 416 of 2000 took 0.035s
  training loss:		0.085383
  validation loss:		0.220051
  validation accuracy:		94.13 %
Epoch 417 of 2000 took 0.035s
  training loss:		0.084411
  validation loss:		0.223803
  validation accuracy:		94.02 %
Epoch 418 of 2000 took 0.035s
  training loss:		0.085524
  validation loss:		0.212114
  validation accuracy:		94.24 %
Epoch 419 of 2000 took 0.035s
  training loss:		0.086237
  validation loss:		0.210131
  validation accuracy:		94.35 %
Epoch 420 of 2000 took 0.035s
  training loss:		0.082520
  validation loss:		0.215710
  validation accuracy:		94.24 %
Epoch 421 of 2000 took 0.035s
  training loss:		0.085268
  validation loss:		0.211329
  validation accuracy:		94.02 %
Epoch 422 of 2000 took 0.035s
  training loss:		0.082853
  validation loss:		0.216103
  validation accuracy:		94.24 %
Epoch 423 of 2000 took 0.035s
  training loss:		0.082232
  validation loss:		0.215921
  validation accuracy:		93.91 %
Epoch 424 of 2000 took 0.035s
  training loss:		0.084253
  validation loss:		0.229457
  validation accuracy:		93.70 %
Epoch 425 of 2000 took 0.035s
  training loss:		0.083716
  validation loss:		0.214040
  validation accuracy:		94.57 %
Epoch 426 of 2000 took 0.035s
  training loss:		0.081450
  validation loss:		0.211608
  validation accuracy:		94.78 %
Epoch 427 of 2000 took 0.035s
  training loss:		0.082419
  validation loss:		0.224279
  validation accuracy:		93.91 %
Epoch 428 of 2000 took 0.035s
  training loss:		0.085276
  validation loss:		0.215850
  validation accuracy:		94.46 %
Epoch 429 of 2000 took 0.035s
  training loss:		0.083456
  validation loss:		0.218700
  validation accuracy:		94.13 %
Epoch 430 of 2000 took 0.035s
  training loss:		0.083766
  validation loss:		0.228774
  validation accuracy:		94.02 %
Epoch 431 of 2000 took 0.035s
  training loss:		0.082254
  validation loss:		0.219680
  validation accuracy:		94.24 %
Epoch 432 of 2000 took 0.036s
  training loss:		0.080840
  validation loss:		0.217488
  validation accuracy:		94.24 %
Epoch 433 of 2000 took 0.035s
  training loss:		0.081775
  validation loss:		0.222391
  validation accuracy:		93.91 %
Epoch 434 of 2000 took 0.035s
  training loss:		0.082333
  validation loss:		0.215002
  validation accuracy:		94.13 %
Epoch 435 of 2000 took 0.035s
  training loss:		0.081488
  validation loss:		0.225233
  validation accuracy:		94.13 %
Epoch 436 of 2000 took 0.035s
  training loss:		0.078361
  validation loss:		0.207836
  validation accuracy:		94.78 %
Epoch 437 of 2000 took 0.035s
  training loss:		0.082202
  validation loss:		0.217123
  validation accuracy:		93.80 %
Epoch 438 of 2000 took 0.037s
  training loss:		0.080931
  validation loss:		0.230428
  validation accuracy:		93.59 %
Epoch 439 of 2000 took 0.035s
  training loss:		0.081241
  validation loss:		0.215447
  validation accuracy:		94.46 %
Epoch 440 of 2000 took 0.035s
  training loss:		0.080884
  validation loss:		0.220902
  validation accuracy:		94.35 %
Epoch 441 of 2000 took 0.035s
  training loss:		0.080255
  validation loss:		0.220573
  validation accuracy:		94.24 %
Epoch 442 of 2000 took 0.035s
  training loss:		0.080208
  validation loss:		0.226687
  validation accuracy:		94.24 %
Epoch 443 of 2000 took 0.035s
  training loss:		0.081785
  validation loss:		0.243191
  validation accuracy:		92.93 %
Epoch 444 of 2000 took 0.035s
  training loss:		0.076850
  validation loss:		0.219429
  validation accuracy:		93.80 %
Epoch 445 of 2000 took 0.035s
  training loss:		0.080080
  validation loss:		0.231870
  validation accuracy:		93.48 %
Epoch 446 of 2000 took 0.035s
  training loss:		0.079519
  validation loss:		0.215028
  validation accuracy:		94.89 %
Epoch 447 of 2000 took 0.035s
  training loss:		0.077882
  validation loss:		0.224759
  validation accuracy:		94.46 %
Epoch 448 of 2000 took 0.035s
  training loss:		0.080087
  validation loss:		0.217134
  validation accuracy:		94.46 %
Epoch 449 of 2000 took 0.035s
  training loss:		0.080440
  validation loss:		0.224283
  validation accuracy:		94.13 %
Epoch 450 of 2000 took 0.035s
  training loss:		0.075970
  validation loss:		0.220335
  validation accuracy:		94.24 %
Epoch 451 of 2000 took 0.035s
  training loss:		0.078578
  validation loss:		0.225433
  validation accuracy:		94.24 %
Epoch 452 of 2000 took 0.035s
  training loss:		0.077265
  validation loss:		0.220701
  validation accuracy:		94.24 %
Epoch 453 of 2000 took 0.035s
  training loss:		0.077372
  validation loss:		0.225570
  validation accuracy:		94.13 %
Epoch 454 of 2000 took 0.035s
  training loss:		0.077101
  validation loss:		0.222080
  validation accuracy:		94.24 %
Epoch 455 of 2000 took 0.036s
  training loss:		0.076735
  validation loss:		0.225746
  validation accuracy:		94.13 %
Epoch 456 of 2000 took 0.035s
  training loss:		0.072580
  validation loss:		0.224214
  validation accuracy:		94.35 %
Epoch 457 of 2000 took 0.035s
  training loss:		0.077135
  validation loss:		0.225997
  validation accuracy:		94.24 %
Epoch 458 of 2000 took 0.035s
  training loss:		0.075767
  validation loss:		0.230824
  validation accuracy:		93.70 %
Epoch 459 of 2000 took 0.035s
  training loss:		0.077220
  validation loss:		0.221512
  validation accuracy:		94.35 %
Epoch 460 of 2000 took 0.035s
  training loss:		0.077979
  validation loss:		0.221734
  validation accuracy:		94.13 %
Epoch 461 of 2000 took 0.035s
  training loss:		0.076221
  validation loss:		0.231172
  validation accuracy:		93.70 %
Epoch 462 of 2000 took 0.035s
  training loss:		0.076332
  validation loss:		0.234173
  validation accuracy:		93.70 %
Epoch 463 of 2000 took 0.035s
  training loss:		0.076349
  validation loss:		0.230499
  validation accuracy:		94.24 %
Epoch 464 of 2000 took 0.035s
  training loss:		0.074213
  validation loss:		0.222443
  validation accuracy:		93.91 %
Epoch 465 of 2000 took 0.035s
  training loss:		0.075848
  validation loss:		0.226697
  validation accuracy:		93.91 %
Epoch 466 of 2000 took 0.035s
  training loss:		0.074236
  validation loss:		0.218985
  validation accuracy:		94.46 %
Epoch 467 of 2000 took 0.035s
  training loss:		0.075054
  validation loss:		0.222270
  validation accuracy:		94.35 %
Epoch 468 of 2000 took 0.035s
  training loss:		0.073082
  validation loss:		0.230912
  validation accuracy:		93.91 %
Epoch 469 of 2000 took 0.035s
  training loss:		0.075276
  validation loss:		0.232656
  validation accuracy:		94.02 %
Epoch 470 of 2000 took 0.035s
  training loss:		0.075533
  validation loss:		0.224139
  validation accuracy:		94.35 %
Epoch 471 of 2000 took 0.036s
  training loss:		0.073930
  validation loss:		0.242446
  validation accuracy:		93.59 %
Epoch 472 of 2000 took 0.035s
  training loss:		0.074487
  validation loss:		0.248170
  validation accuracy:		93.15 %
Epoch 473 of 2000 took 0.035s
  training loss:		0.075291
  validation loss:		0.231213
  validation accuracy:		93.91 %
Epoch 474 of 2000 took 0.035s
  training loss:		0.074342
  validation loss:		0.229267
  validation accuracy:		93.91 %
Epoch 475 of 2000 took 0.035s
  training loss:		0.075322
  validation loss:		0.219778
  validation accuracy:		94.13 %
Epoch 476 of 2000 took 0.036s
  training loss:		0.074395
  validation loss:		0.224552
  validation accuracy:		94.24 %
Epoch 477 of 2000 took 0.035s
  training loss:		0.073344
  validation loss:		0.230709
  validation accuracy:		94.46 %
Epoch 478 of 2000 took 0.035s
  training loss:		0.074090
  validation loss:		0.238483
  validation accuracy:		93.80 %
Epoch 479 of 2000 took 0.035s
  training loss:		0.072908
  validation loss:		0.233049
  validation accuracy:		93.80 %
Epoch 480 of 2000 took 0.035s
  training loss:		0.069679
  validation loss:		0.238870
  validation accuracy:		93.70 %
Epoch 481 of 2000 took 0.035s
  training loss:		0.070606
  validation loss:		0.222076
  validation accuracy:		94.35 %
Epoch 482 of 2000 took 0.035s
  training loss:		0.070244
  validation loss:		0.231377
  validation accuracy:		94.02 %
Epoch 483 of 2000 took 0.035s
  training loss:		0.071770
  validation loss:		0.235506
  validation accuracy:		93.91 %
Epoch 484 of 2000 took 0.035s
  training loss:		0.071315
  validation loss:		0.232283
  validation accuracy:		94.24 %
Epoch 485 of 2000 took 0.035s
  training loss:		0.072516
  validation loss:		0.233556
  validation accuracy:		93.91 %
Epoch 486 of 2000 took 0.035s
  training loss:		0.072225
  validation loss:		0.236596
  validation accuracy:		93.59 %
Epoch 487 of 2000 took 0.035s
  training loss:		0.072687
  validation loss:		0.242915
  validation accuracy:		93.48 %
Epoch 488 of 2000 took 0.035s
  training loss:		0.072794
  validation loss:		0.231927
  validation accuracy:		94.02 %
Epoch 489 of 2000 took 0.035s
  training loss:		0.070581
  validation loss:		0.237930
  validation accuracy:		94.02 %
Epoch 490 of 2000 took 0.035s
  training loss:		0.070103
  validation loss:		0.229522
  validation accuracy:		94.13 %
Epoch 491 of 2000 took 0.035s
  training loss:		0.070709
  validation loss:		0.232720
  validation accuracy:		94.35 %
Epoch 492 of 2000 took 0.035s
  training loss:		0.071494
  validation loss:		0.237371
  validation accuracy:		94.13 %
Epoch 493 of 2000 took 0.035s
  training loss:		0.070823
  validation loss:		0.232870
  validation accuracy:		94.35 %
Epoch 494 of 2000 took 0.035s
  training loss:		0.070299
  validation loss:		0.247158
  validation accuracy:		94.02 %
Epoch 495 of 2000 took 0.035s
  training loss:		0.071926
  validation loss:		0.243036
  validation accuracy:		93.59 %
Epoch 496 of 2000 took 0.035s
  training loss:		0.069508
  validation loss:		0.230564
  validation accuracy:		94.13 %
Epoch 497 of 2000 took 0.035s
  training loss:		0.070224
  validation loss:		0.229842
  validation accuracy:		94.24 %
Epoch 498 of 2000 took 0.035s
  training loss:		0.065037
  validation loss:		0.230382
  validation accuracy:		94.24 %
Epoch 499 of 2000 took 0.035s
  training loss:		0.068785
  validation loss:		0.234425
  validation accuracy:		94.13 %
Epoch 500 of 2000 took 0.035s
  training loss:		0.069711
  validation loss:		0.236339
  validation accuracy:		94.24 %
Epoch 501 of 2000 took 0.035s
  training loss:		0.068501
  validation loss:		0.234266
  validation accuracy:		94.35 %
Epoch 502 of 2000 took 0.035s
  training loss:		0.066143
  validation loss:		0.225741
  validation accuracy:		94.35 %
Epoch 503 of 2000 took 0.035s
  training loss:		0.068120
  validation loss:		0.235189
  validation accuracy:		94.24 %
Epoch 504 of 2000 took 0.035s
  training loss:		0.067244
  validation loss:		0.241091
  validation accuracy:		93.48 %
Epoch 505 of 2000 took 0.035s
  training loss:		0.067327
  validation loss:		0.237092
  validation accuracy:		93.59 %
Epoch 506 of 2000 took 0.035s
  training loss:		0.069562
  validation loss:		0.235192
  validation accuracy:		94.13 %
Epoch 507 of 2000 took 0.035s
  training loss:		0.068745
  validation loss:		0.242266
  validation accuracy:		93.91 %
Epoch 508 of 2000 took 0.035s
  training loss:		0.066624
  validation loss:		0.245330
  validation accuracy:		93.80 %
Epoch 509 of 2000 took 0.035s
  training loss:		0.066940
  validation loss:		0.250139
  validation accuracy:		93.80 %
Epoch 510 of 2000 took 0.035s
  training loss:		0.068852
  validation loss:		0.236189
  validation accuracy:		93.70 %
Epoch 511 of 2000 took 0.035s
  training loss:		0.068621
  validation loss:		0.248599
  validation accuracy:		93.80 %
Epoch 512 of 2000 took 0.035s
  training loss:		0.069180
  validation loss:		0.235877
  validation accuracy:		94.24 %
Epoch 513 of 2000 took 0.035s
  training loss:		0.067910
  validation loss:		0.237443
  validation accuracy:		94.13 %
Epoch 514 of 2000 took 0.035s
  training loss:		0.066994
  validation loss:		0.242093
  validation accuracy:		93.80 %
Epoch 515 of 2000 took 0.035s
  training loss:		0.067642
  validation loss:		0.230607
  validation accuracy:		94.57 %
Epoch 516 of 2000 took 0.035s
  training loss:		0.065809
  validation loss:		0.247817
  validation accuracy:		93.80 %
Epoch 517 of 2000 took 0.035s
  training loss:		0.066155
  validation loss:		0.236704
  validation accuracy:		94.24 %
Epoch 518 of 2000 took 0.035s
  training loss:		0.064622
  validation loss:		0.234302
  validation accuracy:		94.24 %
Epoch 519 of 2000 took 0.035s
  training loss:		0.065910
  validation loss:		0.230352
  validation accuracy:		94.35 %
Epoch 520 of 2000 took 0.036s
  training loss:		0.067230
  validation loss:		0.244892
  validation accuracy:		94.24 %
Epoch 521 of 2000 took 0.035s
  training loss:		0.067672
  validation loss:		0.253589
  validation accuracy:		93.48 %
Epoch 522 of 2000 took 0.035s
  training loss:		0.067833
  validation loss:		0.232662
  validation accuracy:		94.24 %
Epoch 523 of 2000 took 0.035s
  training loss:		0.065401
  validation loss:		0.243715
  validation accuracy:		93.70 %
Epoch 524 of 2000 took 0.035s
  training loss:		0.065075
  validation loss:		0.253513
  validation accuracy:		93.70 %
Epoch 525 of 2000 took 0.035s
  training loss:		0.065627
  validation loss:		0.246981
  validation accuracy:		93.70 %
Epoch 526 of 2000 took 0.035s
  training loss:		0.065613
  validation loss:		0.234511
  validation accuracy:		94.24 %
Epoch 527 of 2000 took 0.036s
  training loss:		0.063835
  validation loss:		0.242330
  validation accuracy:		93.80 %
Epoch 528 of 2000 took 0.035s
  training loss:		0.064632
  validation loss:		0.246603
  validation accuracy:		93.59 %
Epoch 529 of 2000 took 0.035s
  training loss:		0.065418
  validation loss:		0.231410
  validation accuracy:		94.24 %
Epoch 530 of 2000 took 0.035s
  training loss:		0.065318
  validation loss:		0.238013
  validation accuracy:		94.02 %
Epoch 531 of 2000 took 0.035s
  training loss:		0.064684
  validation loss:		0.250330
  validation accuracy:		94.13 %
Epoch 532 of 2000 took 0.035s
  training loss:		0.063282
  validation loss:		0.258446
  validation accuracy:		93.70 %
Epoch 533 of 2000 took 0.035s
  training loss:		0.065137
  validation loss:		0.242333
  validation accuracy:		93.91 %
Epoch 534 of 2000 took 0.035s
  training loss:		0.064369
  validation loss:		0.241312
  validation accuracy:		94.24 %
Epoch 535 of 2000 took 0.035s
  training loss:		0.064747
  validation loss:		0.252003
  validation accuracy:		93.91 %
Epoch 536 of 2000 took 0.035s
  training loss:		0.063064
  validation loss:		0.237101
  validation accuracy:		94.35 %
Epoch 537 of 2000 took 0.035s
  training loss:		0.065895
  validation loss:		0.253330
  validation accuracy:		93.70 %
Epoch 538 of 2000 took 0.035s
  training loss:		0.064070
  validation loss:		0.230459
  validation accuracy:		94.35 %
Epoch 539 of 2000 took 0.035s
  training loss:		0.062159
  validation loss:		0.237147
  validation accuracy:		94.24 %
Epoch 540 of 2000 took 0.035s
  training loss:		0.061363
  validation loss:		0.238948
  validation accuracy:		94.02 %
Epoch 541 of 2000 took 0.035s
  training loss:		0.063251
  validation loss:		0.249516
  validation accuracy:		93.70 %
Epoch 542 of 2000 took 0.035s
  training loss:		0.061831
  validation loss:		0.241364
  validation accuracy:		93.80 %
Epoch 543 of 2000 took 0.035s
  training loss:		0.059806
  validation loss:		0.257560
  validation accuracy:		93.70 %
Epoch 544 of 2000 took 0.035s
  training loss:		0.063329
  validation loss:		0.252605
  validation accuracy:		93.70 %
Epoch 545 of 2000 took 0.036s
  training loss:		0.063058
  validation loss:		0.249037
  validation accuracy:		93.80 %
Epoch 546 of 2000 took 0.035s
  training loss:		0.060608
  validation loss:		0.263220
  validation accuracy:		93.70 %
Epoch 547 of 2000 took 0.035s
  training loss:		0.061197
  validation loss:		0.249680
  validation accuracy:		93.91 %
Epoch 548 of 2000 took 0.035s
  training loss:		0.060145
  validation loss:		0.249033
  validation accuracy:		94.24 %
Epoch 549 of 2000 took 0.035s
  training loss:		0.061970
  validation loss:		0.251976
  validation accuracy:		93.91 %
Epoch 550 of 2000 took 0.035s
  training loss:		0.060555
  validation loss:		0.245198
  validation accuracy:		94.35 %
Epoch 551 of 2000 took 0.035s
  training loss:		0.060576
  validation loss:		0.249543
  validation accuracy:		94.24 %
Epoch 552 of 2000 took 0.035s
  training loss:		0.061685
  validation loss:		0.248898
  validation accuracy:		93.59 %
Epoch 553 of 2000 took 0.035s
  training loss:		0.061725
  validation loss:		0.260419
  validation accuracy:		93.91 %
Epoch 554 of 2000 took 0.035s
  training loss:		0.059494
  validation loss:		0.245333
  validation accuracy:		93.80 %
Epoch 555 of 2000 took 0.035s
  training loss:		0.061425
  validation loss:		0.246499
  validation accuracy:		94.46 %
Epoch 556 of 2000 took 0.035s
  training loss:		0.059576
  validation loss:		0.239950
  validation accuracy:		94.35 %
Epoch 557 of 2000 took 0.035s
  training loss:		0.060306
  validation loss:		0.242895
  validation accuracy:		94.02 %
Epoch 558 of 2000 took 0.035s
  training loss:		0.061490
  validation loss:		0.246180
  validation accuracy:		94.13 %
Epoch 559 of 2000 took 0.035s
  training loss:		0.061143
  validation loss:		0.247045
  validation accuracy:		93.91 %
Epoch 560 of 2000 took 0.035s
  training loss:		0.058154
  validation loss:		0.246033
  validation accuracy:		94.35 %
Epoch 561 of 2000 took 0.035s
  training loss:		0.059463
  validation loss:		0.244394
  validation accuracy:		94.02 %
Epoch 562 of 2000 took 0.035s
  training loss:		0.060319
  validation loss:		0.258228
  validation accuracy:		93.91 %
Epoch 563 of 2000 took 0.035s
  training loss:		0.059408
  validation loss:		0.248950
  validation accuracy:		93.80 %
Epoch 564 of 2000 took 0.035s
  training loss:		0.060054
  validation loss:		0.253616
  validation accuracy:		93.91 %
Epoch 565 of 2000 took 0.035s
  training loss:		0.057353
  validation loss:		0.249005
  validation accuracy:		93.80 %
Epoch 566 of 2000 took 0.035s
  training loss:		0.061177
  validation loss:		0.248194
  validation accuracy:		94.46 %
Epoch 567 of 2000 took 0.035s
  training loss:		0.058929
  validation loss:		0.255365
  validation accuracy:		94.13 %
Epoch 568 of 2000 took 0.035s
  training loss:		0.059920
  validation loss:		0.251582
  validation accuracy:		94.13 %
Epoch 569 of 2000 took 0.035s
  training loss:		0.058894
  validation loss:		0.253553
  validation accuracy:		94.02 %
Epoch 570 of 2000 took 0.036s
  training loss:		0.058601
  validation loss:		0.259776
  validation accuracy:		93.91 %
Epoch 571 of 2000 took 0.035s
  training loss:		0.057370
  validation loss:		0.248452
  validation accuracy:		94.02 %
Epoch 572 of 2000 took 0.035s
  training loss:		0.058514
  validation loss:		0.252760
  validation accuracy:		93.80 %
Epoch 573 of 2000 took 0.036s
  training loss:		0.057323
  validation loss:		0.270391
  validation accuracy:		93.59 %
Epoch 574 of 2000 took 0.035s
  training loss:		0.059575
  validation loss:		0.255818
  validation accuracy:		93.91 %
Epoch 575 of 2000 took 0.035s
  training loss:		0.058039
  validation loss:		0.277909
  validation accuracy:		93.48 %
Epoch 576 of 2000 took 0.036s
  training loss:		0.061209
  validation loss:		0.265128
  validation accuracy:		93.70 %
Epoch 577 of 2000 took 0.035s
  training loss:		0.059457
  validation loss:		0.247183
  validation accuracy:		94.24 %
Epoch 578 of 2000 took 0.035s
  training loss:		0.060550
  validation loss:		0.262148
  validation accuracy:		93.80 %
Epoch 579 of 2000 took 0.035s
  training loss:		0.056999
  validation loss:		0.265360
  validation accuracy:		93.80 %
Epoch 580 of 2000 took 0.035s
  training loss:		0.058040
  validation loss:		0.253977
  validation accuracy:		94.13 %
Epoch 581 of 2000 took 0.035s
  training loss:		0.057286
  validation loss:		0.265315
  validation accuracy:		93.80 %
Epoch 582 of 2000 took 0.035s
  training loss:		0.058779
  validation loss:		0.256590
  validation accuracy:		94.13 %
Epoch 583 of 2000 took 0.035s
  training loss:		0.055478
  validation loss:		0.253881
  validation accuracy:		93.59 %
Epoch 584 of 2000 took 0.035s
  training loss:		0.058273
  validation loss:		0.263861
  validation accuracy:		93.80 %
Epoch 585 of 2000 took 0.035s
  training loss:		0.057095
  validation loss:		0.249638
  validation accuracy:		94.13 %
Epoch 586 of 2000 took 0.035s
  training loss:		0.056201
  validation loss:		0.246404
  validation accuracy:		94.35 %
Epoch 587 of 2000 took 0.035s
  training loss:		0.056672
  validation loss:		0.257896
  validation accuracy:		93.70 %
Epoch 588 of 2000 took 0.035s
  training loss:		0.055249
  validation loss:		0.258269
  validation accuracy:		93.70 %
Epoch 589 of 2000 took 0.035s
  training loss:		0.056621
  validation loss:		0.256044
  validation accuracy:		93.91 %
Epoch 590 of 2000 took 0.035s
  training loss:		0.055043
  validation loss:		0.255023
  validation accuracy:		94.02 %
Epoch 591 of 2000 took 0.035s
  training loss:		0.056564
  validation loss:		0.264989
  validation accuracy:		93.91 %
Epoch 592 of 2000 took 0.035s
  training loss:		0.056510
  validation loss:		0.264531
  validation accuracy:		93.91 %
Epoch 593 of 2000 took 0.035s
  training loss:		0.057785
  validation loss:		0.276111
  validation accuracy:		93.04 %
Epoch 594 of 2000 took 0.035s
  training loss:		0.056779
  validation loss:		0.254999
  validation accuracy:		94.13 %
Epoch 595 of 2000 took 0.035s
  training loss:		0.053427
  validation loss:		0.260506
  validation accuracy:		93.80 %
Epoch 596 of 2000 took 0.035s
  training loss:		0.054875
  validation loss:		0.253208
  validation accuracy:		94.35 %
Epoch 597 of 2000 took 0.035s
  training loss:		0.056014
  validation loss:		0.254258
  validation accuracy:		94.24 %
Epoch 598 of 2000 took 0.035s
  training loss:		0.055300
  validation loss:		0.263558
  validation accuracy:		94.02 %
Epoch 599 of 2000 took 0.035s
  training loss:		0.054672
  validation loss:		0.257983
  validation accuracy:		93.91 %
Epoch 600 of 2000 took 0.035s
  training loss:		0.055490
  validation loss:		0.256867
  validation accuracy:		94.02 %
Epoch 601 of 2000 took 0.035s
  training loss:		0.053286
  validation loss:		0.266267
  validation accuracy:		93.91 %
Epoch 602 of 2000 took 0.035s
  training loss:		0.051839
  validation loss:		0.267949
  validation accuracy:		93.70 %
Epoch 603 of 2000 took 0.035s
  training loss:		0.054608
  validation loss:		0.264723
  validation accuracy:		93.91 %
Epoch 604 of 2000 took 0.035s
  training loss:		0.054922
  validation loss:		0.249603
  validation accuracy:		94.02 %
Epoch 605 of 2000 took 0.035s
  training loss:		0.055839
  validation loss:		0.267967
  validation accuracy:		93.48 %
Epoch 606 of 2000 took 0.035s
  training loss:		0.055652
  validation loss:		0.263467
  validation accuracy:		93.70 %
Epoch 607 of 2000 took 0.035s
  training loss:		0.054612
  validation loss:		0.260537
  validation accuracy:		94.02 %
Epoch 608 of 2000 took 0.035s
  training loss:		0.053725
  validation loss:		0.263233
  validation accuracy:		93.91 %
Epoch 609 of 2000 took 0.035s
  training loss:		0.053781
  validation loss:		0.266129
  validation accuracy:		93.80 %
Epoch 610 of 2000 took 0.035s
  training loss:		0.053015
  validation loss:		0.265023
  validation accuracy:		93.80 %
Epoch 611 of 2000 took 0.035s
  training loss:		0.054013
  validation loss:		0.263223
  validation accuracy:		93.91 %
Epoch 612 of 2000 took 0.035s
  training loss:		0.052915
  validation loss:		0.265420
  validation accuracy:		94.02 %
Epoch 613 of 2000 took 0.035s
  training loss:		0.054807
  validation loss:		0.260927
  validation accuracy:		93.80 %
Epoch 614 of 2000 took 0.035s
  training loss:		0.052502
  validation loss:		0.265338
  validation accuracy:		93.48 %
Epoch 615 of 2000 took 0.035s
  training loss:		0.054502
  validation loss:		0.262010
  validation accuracy:		93.80 %
Epoch 616 of 2000 took 0.035s
  training loss:		0.052612
  validation loss:		0.257193
  validation accuracy:		93.80 %
Epoch 617 of 2000 took 0.035s
  training loss:		0.053859
  validation loss:		0.272972
  validation accuracy:		93.91 %
Epoch 618 of 2000 took 0.035s
  training loss:		0.051523
  validation loss:		0.258400
  validation accuracy:		94.13 %
Epoch 619 of 2000 took 0.035s
  training loss:		0.051193
  validation loss:		0.253356
  validation accuracy:		94.02 %
Epoch 620 of 2000 took 0.035s
  training loss:		0.051133
  validation loss:		0.257190
  validation accuracy:		94.13 %
Epoch 621 of 2000 took 0.035s
  training loss:		0.053346
  validation loss:		0.265203
  validation accuracy:		93.91 %
Epoch 622 of 2000 took 0.035s
  training loss:		0.052037
  validation loss:		0.277160
  validation accuracy:		93.80 %
Epoch 623 of 2000 took 0.035s
  training loss:		0.049198
  validation loss:		0.256708
  validation accuracy:		94.35 %
Epoch 624 of 2000 took 0.035s
  training loss:		0.051241
  validation loss:		0.271214
  validation accuracy:		93.91 %
Epoch 625 of 2000 took 0.035s
  training loss:		0.051648
  validation loss:		0.257707
  validation accuracy:		94.13 %
Epoch 626 of 2000 took 0.035s
  training loss:		0.052840
  validation loss:		0.267875
  validation accuracy:		93.91 %
Epoch 627 of 2000 took 0.035s
  training loss:		0.051518
  validation loss:		0.264960
  validation accuracy:		93.70 %
Epoch 628 of 2000 took 0.035s
  training loss:		0.050246
  validation loss:		0.258014
  validation accuracy:		94.13 %
Epoch 629 of 2000 took 0.035s
  training loss:		0.051089
  validation loss:		0.265927
  validation accuracy:		94.13 %
Epoch 630 of 2000 took 0.035s
  training loss:		0.051425
  validation loss:		0.260779
  validation accuracy:		94.02 %
Epoch 631 of 2000 took 0.035s
  training loss:		0.051834
  validation loss:		0.266471
  validation accuracy:		93.91 %
Epoch 632 of 2000 took 0.035s
  training loss:		0.049319
  validation loss:		0.259014
  validation accuracy:		94.13 %
Epoch 633 of 2000 took 0.036s
  training loss:		0.050553
  validation loss:		0.262523
  validation accuracy:		94.13 %
Epoch 634 of 2000 took 0.035s
  training loss:		0.048744
  validation loss:		0.276486
  validation accuracy:		93.70 %
Epoch 635 of 2000 took 0.035s
  training loss:		0.050364
  validation loss:		0.266671
  validation accuracy:		93.91 %
Epoch 636 of 2000 took 0.035s
  training loss:		0.050354
  validation loss:		0.276798
  validation accuracy:		93.48 %
Epoch 637 of 2000 took 0.035s
  training loss:		0.049147
  validation loss:		0.285689
  validation accuracy:		93.59 %
Epoch 638 of 2000 took 0.035s
  training loss:		0.052073
  validation loss:		0.274097
  validation accuracy:		93.70 %
Epoch 639 of 2000 took 0.035s
  training loss:		0.050834
  validation loss:		0.281099
  validation accuracy:		93.70 %
Epoch 640 of 2000 took 0.035s
  training loss:		0.049443
  validation loss:		0.271296
  validation accuracy:		93.70 %
Epoch 641 of 2000 took 0.035s
  training loss:		0.049185
  validation loss:		0.265472
  validation accuracy:		93.91 %
Epoch 642 of 2000 took 0.035s
  training loss:		0.048721
  validation loss:		0.275879
  validation accuracy:		93.59 %
Epoch 643 of 2000 took 0.035s
  training loss:		0.049686
  validation loss:		0.274859
  validation accuracy:		94.13 %
Epoch 644 of 2000 took 0.035s
  training loss:		0.049389
  validation loss:		0.262796
  validation accuracy:		94.24 %
Epoch 645 of 2000 took 0.035s
  training loss:		0.051173
  validation loss:		0.269925
  validation accuracy:		93.80 %
Epoch 646 of 2000 took 0.035s
  training loss:		0.050293
  validation loss:		0.269625
  validation accuracy:		94.24 %
Epoch 647 of 2000 took 0.035s
  training loss:		0.049018
  validation loss:		0.258962
  validation accuracy:		94.46 %
Epoch 648 of 2000 took 0.035s
  training loss:		0.050850
  validation loss:		0.275462
  validation accuracy:		93.91 %
Epoch 649 of 2000 took 0.035s
  training loss:		0.048458
  validation loss:		0.277712
  validation accuracy:		93.26 %
Epoch 650 of 2000 took 0.035s
  training loss:		0.048572
  validation loss:		0.267244
  validation accuracy:		94.02 %
Epoch 651 of 2000 took 0.035s
  training loss:		0.049312
  validation loss:		0.272038
  validation accuracy:		94.24 %
Epoch 652 of 2000 took 0.035s
  training loss:		0.048060
  validation loss:		0.281275
  validation accuracy:		93.70 %
Epoch 653 of 2000 took 0.035s
  training loss:		0.047605
  validation loss:		0.284661
  validation accuracy:		93.70 %
Epoch 654 of 2000 took 0.035s
  training loss:		0.049596
  validation loss:		0.267756
  validation accuracy:		93.91 %
Epoch 655 of 2000 took 0.035s
  training loss:		0.047998
  validation loss:		0.287644
  validation accuracy:		93.37 %
Epoch 656 of 2000 took 0.035s
  training loss:		0.047578
  validation loss:		0.274062
  validation accuracy:		93.80 %
Epoch 657 of 2000 took 0.035s
  training loss:		0.048097
  validation loss:		0.278945
  validation accuracy:		93.80 %
Epoch 658 of 2000 took 0.036s
  training loss:		0.049150
  validation loss:		0.275007
  validation accuracy:		93.80 %
Epoch 659 of 2000 took 0.035s
  training loss:		0.046613
  validation loss:		0.281606
  validation accuracy:		93.91 %
Epoch 660 of 2000 took 0.035s
  training loss:		0.047898
  validation loss:		0.269271
  validation accuracy:		93.80 %
Epoch 661 of 2000 took 0.035s
  training loss:		0.048172
  validation loss:		0.272254
  validation accuracy:		93.70 %
Epoch 662 of 2000 took 0.035s
  training loss:		0.047220
  validation loss:		0.276742
  validation accuracy:		93.59 %
Epoch 663 of 2000 took 0.035s
  training loss:		0.047704
  validation loss:		0.279171
  validation accuracy:		93.91 %
Epoch 664 of 2000 took 0.035s
  training loss:		0.048926
  validation loss:		0.274500
  validation accuracy:		93.70 %
Epoch 665 of 2000 took 0.035s
  training loss:		0.047100
  validation loss:		0.268504
  validation accuracy:		94.02 %
Epoch 666 of 2000 took 0.035s
  training loss:		0.045045
  validation loss:		0.268384
  validation accuracy:		94.02 %
Epoch 667 of 2000 took 0.035s
  training loss:		0.046589
  validation loss:		0.278998
  validation accuracy:		93.91 %
Epoch 668 of 2000 took 0.035s
  training loss:		0.047414
  validation loss:		0.288385
  validation accuracy:		93.70 %
Epoch 669 of 2000 took 0.035s
  training loss:		0.047384
  validation loss:		0.274929
  validation accuracy:		93.91 %
Epoch 670 of 2000 took 0.035s
  training loss:		0.046382
  validation loss:		0.280727
  validation accuracy:		93.48 %
Epoch 671 of 2000 took 0.035s
  training loss:		0.047260
  validation loss:		0.287337
  validation accuracy:		93.59 %
Epoch 672 of 2000 took 0.035s
  training loss:		0.044992
  validation loss:		0.274276
  validation accuracy:		93.70 %
Epoch 673 of 2000 took 0.035s
  training loss:		0.046542
  validation loss:		0.281816
  validation accuracy:		93.80 %
Epoch 674 of 2000 took 0.035s
  training loss:		0.043901
  validation loss:		0.279620
  validation accuracy:		94.02 %
Epoch 675 of 2000 took 0.035s
  training loss:		0.045448
  validation loss:		0.274883
  validation accuracy:		94.02 %
Epoch 676 of 2000 took 0.035s
  training loss:		0.045005
  validation loss:		0.297657
  validation accuracy:		93.70 %
Epoch 677 of 2000 took 0.035s
  training loss:		0.047053
  validation loss:		0.283659
  validation accuracy:		93.80 %
Epoch 678 of 2000 took 0.035s
  training loss:		0.045437
  validation loss:		0.282436
  validation accuracy:		93.48 %
Epoch 679 of 2000 took 0.035s
  training loss:		0.045792
  validation loss:		0.283267
  validation accuracy:		94.02 %
Epoch 680 of 2000 took 0.035s
  training loss:		0.043631
  validation loss:		0.296667
  validation accuracy:		93.37 %
Epoch 681 of 2000 took 0.035s
  training loss:		0.045194
  validation loss:		0.290831
  validation accuracy:		93.70 %
Epoch 682 of 2000 took 0.035s
  training loss:		0.045308
  validation loss:		0.274156
  validation accuracy:		94.24 %
Epoch 683 of 2000 took 0.035s
  training loss:		0.044801
  validation loss:		0.283726
  validation accuracy:		93.70 %
Epoch 684 of 2000 took 0.035s
  training loss:		0.046258
  validation loss:		0.287680
  validation accuracy:		93.91 %
Epoch 685 of 2000 took 0.035s
  training loss:		0.044645
  validation loss:		0.283442
  validation accuracy:		93.70 %
Epoch 686 of 2000 took 0.036s
  training loss:		0.044813
  validation loss:		0.294095
  validation accuracy:		93.59 %
Epoch 687 of 2000 took 0.035s
  training loss:		0.042856
  validation loss:		0.295623
  validation accuracy:		93.80 %
Epoch 688 of 2000 took 0.035s
  training loss:		0.045732
  validation loss:		0.288723
  validation accuracy:		94.02 %
Epoch 689 of 2000 took 0.036s
  training loss:		0.044265
  validation loss:		0.290665
  validation accuracy:		93.37 %
Epoch 690 of 2000 took 0.035s
  training loss:		0.043862
  validation loss:		0.290572
  validation accuracy:		93.70 %
Epoch 691 of 2000 took 0.035s
  training loss:		0.044362
  validation loss:		0.280501
  validation accuracy:		93.91 %
Epoch 692 of 2000 took 0.035s
  training loss:		0.042547
  validation loss:		0.284949
  validation accuracy:		93.91 %
Epoch 693 of 2000 took 0.035s
  training loss:		0.043112
  validation loss:		0.280467
  validation accuracy:		93.70 %
Epoch 694 of 2000 took 0.035s
  training loss:		0.044719
  validation loss:		0.283252
  validation accuracy:		93.26 %
Epoch 695 of 2000 took 0.035s
  training loss:		0.043266
  validation loss:		0.277144
  validation accuracy:		94.13 %
Epoch 696 of 2000 took 0.035s
  training loss:		0.043177
  validation loss:		0.284097
  validation accuracy:		93.91 %
Epoch 697 of 2000 took 0.035s
  training loss:		0.044809
  validation loss:		0.281916
  validation accuracy:		93.48 %
Epoch 698 of 2000 took 0.035s
  training loss:		0.043706
  validation loss:		0.287350
  validation accuracy:		93.70 %
Epoch 699 of 2000 took 0.035s
  training loss:		0.044182
  validation loss:		0.291415
  validation accuracy:		93.48 %
Epoch 700 of 2000 took 0.035s
  training loss:		0.044116
  validation loss:		0.276585
  validation accuracy:		93.80 %
Epoch 701 of 2000 took 0.035s
  training loss:		0.042973
  validation loss:		0.289576
  validation accuracy:		94.02 %
Epoch 702 of 2000 took 0.035s
  training loss:		0.042796
  validation loss:		0.286812
  validation accuracy:		93.48 %
Epoch 703 of 2000 took 0.035s
  training loss:		0.042351
  validation loss:		0.286696
  validation accuracy:		93.80 %
Epoch 704 of 2000 took 0.035s
  training loss:		0.043503
  validation loss:		0.285508
  validation accuracy:		93.80 %
Epoch 705 of 2000 took 0.035s
  training loss:		0.041734
  validation loss:		0.295330
  validation accuracy:		94.02 %
Epoch 706 of 2000 took 0.035s
  training loss:		0.043157
  validation loss:		0.292502
  validation accuracy:		93.59 %
Epoch 707 of 2000 took 0.035s
  training loss:		0.043966
  validation loss:		0.285502
  validation accuracy:		93.37 %
Epoch 708 of 2000 took 0.035s
  training loss:		0.042670
  validation loss:		0.293266
  validation accuracy:		93.91 %
Epoch 709 of 2000 took 0.035s
  training loss:		0.042452
  validation loss:		0.280428
  validation accuracy:		94.02 %
Epoch 710 of 2000 took 0.035s
  training loss:		0.042757
  validation loss:		0.285689
  validation accuracy:		93.91 %
Epoch 711 of 2000 took 0.035s
  training loss:		0.042306
  validation loss:		0.294267
  validation accuracy:		94.02 %
Epoch 712 of 2000 took 0.035s
  training loss:		0.042249
  validation loss:		0.287539
  validation accuracy:		93.70 %
Epoch 713 of 2000 took 0.035s
  training loss:		0.042973
  validation loss:		0.307206
  validation accuracy:		93.48 %
Epoch 714 of 2000 took 0.036s
  training loss:		0.041221
  validation loss:		0.289979
  validation accuracy:		93.59 %
Epoch 715 of 2000 took 0.035s
  training loss:		0.041561
  validation loss:		0.299230
  validation accuracy:		93.48 %
Epoch 716 of 2000 took 0.035s
  training loss:		0.041094
  validation loss:		0.288835
  validation accuracy:		94.02 %
Epoch 717 of 2000 took 0.035s
  training loss:		0.042765
  validation loss:		0.277986
  validation accuracy:		94.02 %
Epoch 718 of 2000 took 0.035s
  training loss:		0.041692
  validation loss:		0.294342
  validation accuracy:		93.70 %
Epoch 719 of 2000 took 0.035s
  training loss:		0.041168
  validation loss:		0.300447
  validation accuracy:		93.59 %
Epoch 720 of 2000 took 0.035s
  training loss:		0.039369
  validation loss:		0.295671
  validation accuracy:		93.15 %
Epoch 721 of 2000 took 0.035s
  training loss:		0.042574
  validation loss:		0.292671
  validation accuracy:		93.48 %
Epoch 722 of 2000 took 0.035s
  training loss:		0.041700
  validation loss:		0.296884
  validation accuracy:		93.80 %
Epoch 723 of 2000 took 0.035s
  training loss:		0.040629
  validation loss:		0.288875
  validation accuracy:		94.02 %
Epoch 724 of 2000 took 0.035s
  training loss:		0.042191
  validation loss:		0.305454
  validation accuracy:		93.59 %
Epoch 725 of 2000 took 0.036s
  training loss:		0.040571
  validation loss:		0.305367
  validation accuracy:		93.59 %
Epoch 726 of 2000 took 0.035s
  training loss:		0.039286
  validation loss:		0.292023
  validation accuracy:		93.37 %
Epoch 727 of 2000 took 0.035s
  training loss:		0.041361
  validation loss:		0.304331
  validation accuracy:		93.59 %
Epoch 728 of 2000 took 0.035s
  training loss:		0.040571
  validation loss:		0.294962
  validation accuracy:		93.70 %
Epoch 729 of 2000 took 0.035s
  training loss:		0.038963
  validation loss:		0.294053
  validation accuracy:		94.02 %
Epoch 730 of 2000 took 0.035s
  training loss:		0.041520
  validation loss:		0.297467
  validation accuracy:		93.48 %
Epoch 731 of 2000 took 0.035s
  training loss:		0.040230
  validation loss:		0.287365
  validation accuracy:		93.80 %
Epoch 732 of 2000 took 0.035s
  training loss:		0.039953
  validation loss:		0.303493
  validation accuracy:		93.26 %
Epoch 733 of 2000 took 0.035s
  training loss:		0.040956
  validation loss:		0.297912
  validation accuracy:		93.80 %
Epoch 734 of 2000 took 0.035s
  training loss:		0.039999
  validation loss:		0.299928
  validation accuracy:		93.59 %
Epoch 735 of 2000 took 0.035s
  training loss:		0.039620
  validation loss:		0.307466
  validation accuracy:		93.59 %
Epoch 736 of 2000 took 0.035s
  training loss:		0.040032
  validation loss:		0.296058
  validation accuracy:		94.02 %
Epoch 737 of 2000 took 0.035s
  training loss:		0.040446
  validation loss:		0.299497
  validation accuracy:		93.91 %
Epoch 738 of 2000 took 0.035s
  training loss:		0.038501
  validation loss:		0.293874
  validation accuracy:		93.70 %
Epoch 739 of 2000 took 0.035s
  training loss:		0.039812
  validation loss:		0.296515
  validation accuracy:		93.59 %
Epoch 740 of 2000 took 0.035s
  training loss:		0.040451
  validation loss:		0.310670
  validation accuracy:		93.37 %
Epoch 741 of 2000 took 0.035s
  training loss:		0.040883
  validation loss:		0.307463
  validation accuracy:		93.26 %
Epoch 742 of 2000 took 0.035s
  training loss:		0.039607
  validation loss:		0.307505
  validation accuracy:		93.48 %
Epoch 743 of 2000 took 0.035s
  training loss:		0.038482
  validation loss:		0.293664
  validation accuracy:		94.02 %
Epoch 744 of 2000 took 0.035s
  training loss:		0.039438
  validation loss:		0.300403
  validation accuracy:		94.02 %
Epoch 745 of 2000 took 0.035s
  training loss:		0.039631
  validation loss:		0.302414
  validation accuracy:		93.80 %
Epoch 746 of 2000 took 0.035s
  training loss:		0.036469
  validation loss:		0.290551
  validation accuracy:		94.02 %
Epoch 747 of 2000 took 0.035s
  training loss:		0.038704
  validation loss:		0.300606
  validation accuracy:		93.59 %
Epoch 748 of 2000 took 0.035s
  training loss:		0.040117
  validation loss:		0.293753
  validation accuracy:		93.59 %
Epoch 749 of 2000 took 0.035s
  training loss:		0.040107
  validation loss:		0.307936
  validation accuracy:		93.48 %
Epoch 750 of 2000 took 0.035s
  training loss:		0.040317
  validation loss:		0.301810
  validation accuracy:		93.59 %
Epoch 751 of 2000 took 0.035s
  training loss:		0.038100
  validation loss:		0.305917
  validation accuracy:		93.48 %
Epoch 752 of 2000 took 0.035s
  training loss:		0.039203
  validation loss:		0.299095
  validation accuracy:		93.59 %
Epoch 753 of 2000 took 0.035s
  training loss:		0.037318
  validation loss:		0.293741
  validation accuracy:		94.02 %
Epoch 754 of 2000 took 0.035s
  training loss:		0.038483
  validation loss:		0.310487
  validation accuracy:		93.26 %
Epoch 755 of 2000 took 0.035s
  training loss:		0.038789
  validation loss:		0.302020
  validation accuracy:		93.59 %
Epoch 756 of 2000 took 0.035s
  training loss:		0.037618
  validation loss:		0.298245
  validation accuracy:		93.80 %
Epoch 757 of 2000 took 0.035s
  training loss:		0.037780
  validation loss:		0.299913
  validation accuracy:		93.70 %
Epoch 758 of 2000 took 0.035s
  training loss:		0.038316
  validation loss:		0.318486
  validation accuracy:		93.37 %
Epoch 759 of 2000 took 0.035s
  training loss:		0.037864
  validation loss:		0.302963
  validation accuracy:		93.70 %
Epoch 760 of 2000 took 0.035s
  training loss:		0.036206
  validation loss:		0.297463
  validation accuracy:		93.80 %
Epoch 761 of 2000 took 0.035s
  training loss:		0.035835
  validation loss:		0.316078
  validation accuracy:		93.37 %
Epoch 762 of 2000 took 0.035s
  training loss:		0.038696
  validation loss:		0.302858
  validation accuracy:		93.70 %
Epoch 763 of 2000 took 0.035s
  training loss:		0.037699
  validation loss:		0.309277
  validation accuracy:		93.70 %
Epoch 764 of 2000 took 0.035s
  training loss:		0.036955
  validation loss:		0.318844
  validation accuracy:		93.48 %
Epoch 765 of 2000 took 0.035s
  training loss:		0.037862
  validation loss:		0.302275
  validation accuracy:		93.48 %
Epoch 766 of 2000 took 0.035s
  training loss:		0.036704
  validation loss:		0.305693
  validation accuracy:		93.48 %
Epoch 767 of 2000 took 0.035s
  training loss:		0.037534
  validation loss:		0.306904
  validation accuracy:		93.59 %
Epoch 768 of 2000 took 0.035s
  training loss:		0.037387
  validation loss:		0.298859
  validation accuracy:		93.70 %
Epoch 769 of 2000 took 0.035s
  training loss:		0.037706
  validation loss:		0.308610
  validation accuracy:		93.48 %
Epoch 770 of 2000 took 0.035s
  training loss:		0.039271
  validation loss:		0.302813
  validation accuracy:		93.59 %
Epoch 771 of 2000 took 0.035s
  training loss:		0.036079
  validation loss:		0.312803
  validation accuracy:		93.48 %
Epoch 772 of 2000 took 0.035s
  training loss:		0.036584
  validation loss:		0.306239
  validation accuracy:		93.59 %
Epoch 773 of 2000 took 0.035s
  training loss:		0.036735
  validation loss:		0.301389
  validation accuracy:		93.59 %
Epoch 774 of 2000 took 0.035s
  training loss:		0.037200
  validation loss:		0.298071
  validation accuracy:		94.02 %
Epoch 775 of 2000 took 0.035s
  training loss:		0.036538
  validation loss:		0.320897
  validation accuracy:		93.59 %
Epoch 776 of 2000 took 0.035s
  training loss:		0.037459
  validation loss:		0.322424
  validation accuracy:		93.37 %
Epoch 777 of 2000 took 0.035s
  training loss:		0.037057
  validation loss:		0.313357
  validation accuracy:		93.70 %
Epoch 778 of 2000 took 0.035s
  training loss:		0.036955
  validation loss:		0.310499
  validation accuracy:		93.48 %
Epoch 779 of 2000 took 0.035s
  training loss:		0.036275
  validation loss:		0.301573
  validation accuracy:		94.13 %
Epoch 780 of 2000 took 0.035s
  training loss:		0.036361
  validation loss:		0.307269
  validation accuracy:		93.70 %
Epoch 781 of 2000 took 0.035s
  training loss:		0.035216
  validation loss:		0.316773
  validation accuracy:		93.59 %
Epoch 782 of 2000 took 0.035s
  training loss:		0.034364
  validation loss:		0.310158
  validation accuracy:		93.48 %
Epoch 783 of 2000 took 0.035s
  training loss:		0.033767
  validation loss:		0.319611
  validation accuracy:		93.48 %
Epoch 784 of 2000 took 0.035s
  training loss:		0.035977
  validation loss:		0.326477
  validation accuracy:		93.37 %
Epoch 785 of 2000 took 0.035s
  training loss:		0.035682
  validation loss:		0.321831
  validation accuracy:		93.59 %
Epoch 786 of 2000 took 0.035s
  training loss:		0.035321
  validation loss:		0.325856
  validation accuracy:		93.48 %
Epoch 787 of 2000 took 0.035s
  training loss:		0.035212
  validation loss:		0.303767
  validation accuracy:		93.70 %
Epoch 788 of 2000 took 0.035s
  training loss:		0.036126
  validation loss:		0.321455
  validation accuracy:		93.26 %
Epoch 789 of 2000 took 0.035s
  training loss:		0.034520
  validation loss:		0.313181
  validation accuracy:		93.59 %
Epoch 790 of 2000 took 0.035s
  training loss:		0.035489
  validation loss:		0.326505
  validation accuracy:		93.04 %
Epoch 791 of 2000 took 0.035s
  training loss:		0.035235
  validation loss:		0.316121
  validation accuracy:		93.59 %
Epoch 792 of 2000 took 0.035s
  training loss:		0.033156
  validation loss:		0.306558
  validation accuracy:		93.91 %
Epoch 793 of 2000 took 0.035s
  training loss:		0.035302
  validation loss:		0.320671
  validation accuracy:		93.48 %
Epoch 794 of 2000 took 0.035s
  training loss:		0.034693
  validation loss:		0.327890
  validation accuracy:		93.37 %
Epoch 795 of 2000 took 0.035s
  training loss:		0.035577
  validation loss:		0.321054
  validation accuracy:		93.48 %
Epoch 796 of 2000 took 0.035s
  training loss:		0.035444
  validation loss:		0.317677
  validation accuracy:		93.59 %
Epoch 797 of 2000 took 0.035s
  training loss:		0.034089
  validation loss:		0.319464
  validation accuracy:		93.48 %
Epoch 798 of 2000 took 0.035s
  training loss:		0.034173
  validation loss:		0.337711
  validation accuracy:		93.04 %
Epoch 799 of 2000 took 0.036s
  training loss:		0.036020
  validation loss:		0.318993
  validation accuracy:		93.48 %
Epoch 800 of 2000 took 0.035s
  training loss:		0.032993
  validation loss:		0.318600
  validation accuracy:		93.37 %
Epoch 801 of 2000 took 0.035s
  training loss:		0.034713
  validation loss:		0.311474
  validation accuracy:		93.80 %
Epoch 802 of 2000 took 0.036s
  training loss:		0.034182
  validation loss:		0.314151
  validation accuracy:		93.80 %
Epoch 803 of 2000 took 0.035s
  training loss:		0.034659
  validation loss:		0.312160
  validation accuracy:		93.70 %
Epoch 804 of 2000 took 0.035s
  training loss:		0.033378
  validation loss:		0.307785
  validation accuracy:		93.70 %
Epoch 805 of 2000 took 0.035s
  training loss:		0.033641
  validation loss:		0.315982
  validation accuracy:		93.59 %
Epoch 806 of 2000 took 0.035s
  training loss:		0.033860
  validation loss:		0.318738
  validation accuracy:		93.48 %
Epoch 807 of 2000 took 0.035s
  training loss:		0.032727
  validation loss:		0.323039
  validation accuracy:		93.37 %
Epoch 808 of 2000 took 0.037s
  training loss:		0.035619
  validation loss:		0.320080
  validation accuracy:		93.37 %
Epoch 809 of 2000 took 0.036s
  training loss:		0.033496
  validation loss:		0.328825
  validation accuracy:		93.48 %
Epoch 810 of 2000 took 0.036s
  training loss:		0.036162
  validation loss:		0.314911
  validation accuracy:		94.02 %
Epoch 811 of 2000 took 0.035s
  training loss:		0.033034
  validation loss:		0.308126
  validation accuracy:		93.70 %
Epoch 812 of 2000 took 0.035s
  training loss:		0.033854
  validation loss:		0.312738
  validation accuracy:		93.59 %
Epoch 813 of 2000 took 0.035s
  training loss:		0.033206
  validation loss:		0.314656
  validation accuracy:		93.59 %
Epoch 814 of 2000 took 0.035s
  training loss:		0.032172
  validation loss:		0.319658
  validation accuracy:		93.70 %
Epoch 815 of 2000 took 0.035s
  training loss:		0.032404
  validation loss:		0.321942
  validation accuracy:		93.59 %
Epoch 816 of 2000 took 0.035s
  training loss:		0.032000
  validation loss:		0.334570
  validation accuracy:		93.48 %
Epoch 817 of 2000 took 0.035s
  training loss:		0.032893
  validation loss:		0.319088
  validation accuracy:		93.59 %
Epoch 818 of 2000 took 0.036s
  training loss:		0.030417
  validation loss:		0.327644
  validation accuracy:		93.37 %
Epoch 819 of 2000 took 0.035s
  training loss:		0.034026
  validation loss:		0.325591
  validation accuracy:		93.37 %
Epoch 820 of 2000 took 0.035s
  training loss:		0.032493
  validation loss:		0.327721
  validation accuracy:		93.59 %
Epoch 821 of 2000 took 0.035s
  training loss:		0.032843
  validation loss:		0.323577
  validation accuracy:		93.80 %
Epoch 822 of 2000 took 0.035s
  training loss:		0.033034
  validation loss:		0.320679
  validation accuracy:		93.59 %
Epoch 823 of 2000 took 0.035s
  training loss:		0.031925
  validation loss:		0.322326
  validation accuracy:		93.48 %
Epoch 824 of 2000 took 0.035s
  training loss:		0.031867
  validation loss:		0.313378
  validation accuracy:		93.80 %
Epoch 825 of 2000 took 0.036s
  training loss:		0.033720
  validation loss:		0.310665
  validation accuracy:		93.59 %
Epoch 826 of 2000 took 0.035s
  training loss:		0.032065
  validation loss:		0.329042
  validation accuracy:		93.37 %
Epoch 827 of 2000 took 0.035s
  training loss:		0.033326
  validation loss:		0.319590
  validation accuracy:		93.59 %
Epoch 828 of 2000 took 0.035s
  training loss:		0.031430
  validation loss:		0.329700
  validation accuracy:		93.48 %
Epoch 829 of 2000 took 0.035s
  training loss:		0.032130
  validation loss:		0.321028
  validation accuracy:		93.59 %
Epoch 830 of 2000 took 0.035s
  training loss:		0.031806
  validation loss:		0.325258
  validation accuracy:		93.59 %
Epoch 831 of 2000 took 0.035s
  training loss:		0.031907
  validation loss:		0.337198
  validation accuracy:		93.48 %
Epoch 832 of 2000 took 0.035s
  training loss:		0.031477
  validation loss:		0.338281
  validation accuracy:		93.37 %
Epoch 833 of 2000 took 0.035s
  training loss:		0.031957
  validation loss:		0.316631
  validation accuracy:		93.70 %
Epoch 834 of 2000 took 0.035s
  training loss:		0.032257
  validation loss:		0.321269
  validation accuracy:		93.26 %
Epoch 835 of 2000 took 0.035s
  training loss:		0.032946
  validation loss:		0.336420
  validation accuracy:		93.48 %
Epoch 836 of 2000 took 0.035s
  training loss:		0.031486
  validation loss:		0.318160
  validation accuracy:		94.02 %
Epoch 837 of 2000 took 0.035s
  training loss:		0.030807
  validation loss:		0.328499
  validation accuracy:		93.26 %
Epoch 838 of 2000 took 0.035s
  training loss:		0.033209
  validation loss:		0.338449
  validation accuracy:		93.26 %
Epoch 839 of 2000 took 0.035s
  training loss:		0.030665
  validation loss:		0.321768
  validation accuracy:		93.48 %
Epoch 840 of 2000 took 0.035s
  training loss:		0.029981
  validation loss:		0.323247
  validation accuracy:		93.37 %
Epoch 841 of 2000 took 0.035s
  training loss:		0.030715
  validation loss:		0.327431
  validation accuracy:		93.59 %
Epoch 842 of 2000 took 0.035s
  training loss:		0.029892
  validation loss:		0.338649
  validation accuracy:		93.59 %
Epoch 843 of 2000 took 0.035s
  training loss:		0.031767
  validation loss:		0.322425
  validation accuracy:		93.70 %
Epoch 844 of 2000 took 0.035s
  training loss:		0.031313
  validation loss:		0.329968
  validation accuracy:		93.26 %
Epoch 845 of 2000 took 0.035s
  training loss:		0.031462
  validation loss:		0.339572
  validation accuracy:		93.48 %
Epoch 846 of 2000 took 0.035s
  training loss:		0.031021
  validation loss:		0.339525
  validation accuracy:		93.15 %
Epoch 847 of 2000 took 0.035s
  training loss:		0.030557
  validation loss:		0.329904
  validation accuracy:		93.48 %
Epoch 848 of 2000 took 0.035s
  training loss:		0.029141
  validation loss:		0.332675
  validation accuracy:		93.26 %
Epoch 849 of 2000 took 0.035s
  training loss:		0.030882
  validation loss:		0.333163
  validation accuracy:		93.26 %
Epoch 850 of 2000 took 0.035s
  training loss:		0.030440
  validation loss:		0.320610
  validation accuracy:		93.91 %
Epoch 851 of 2000 took 0.035s
  training loss:		0.029747
  validation loss:		0.334242
  validation accuracy:		93.59 %
Epoch 852 of 2000 took 0.035s
  training loss:		0.030864
  validation loss:		0.334788
  validation accuracy:		93.37 %
Epoch 853 of 2000 took 0.035s
  training loss:		0.029820
  validation loss:		0.333921
  validation accuracy:		93.26 %
Epoch 854 of 2000 took 0.035s
  training loss:		0.030528
  validation loss:		0.326723
  validation accuracy:		93.59 %
Epoch 855 of 2000 took 0.035s
  training loss:		0.028486
  validation loss:		0.333723
  validation accuracy:		93.80 %
Epoch 856 of 2000 took 0.035s
  training loss:		0.030511
  validation loss:		0.343490
  validation accuracy:		93.26 %
Epoch 857 of 2000 took 0.035s
  training loss:		0.031386
  validation loss:		0.331460
  validation accuracy:		93.37 %
Epoch 858 of 2000 took 0.035s
  training loss:		0.030312
  validation loss:		0.328062
  validation accuracy:		93.59 %
Epoch 859 of 2000 took 0.036s
  training loss:		0.030462
  validation loss:		0.342429
  validation accuracy:		93.37 %
Epoch 860 of 2000 took 0.035s
  training loss:		0.028965
  validation loss:		0.345683
  validation accuracy:		93.37 %
Epoch 861 of 2000 took 0.035s
  training loss:		0.029709
  validation loss:		0.332300
  validation accuracy:		93.48 %
Epoch 862 of 2000 took 0.035s
  training loss:		0.030123
  validation loss:		0.334739
  validation accuracy:		93.48 %
Epoch 863 of 2000 took 0.035s
  training loss:		0.028633
  validation loss:		0.336011
  validation accuracy:		93.37 %
Epoch 864 of 2000 took 0.035s
  training loss:		0.028906
  validation loss:		0.346153
  validation accuracy:		93.26 %
Epoch 865 of 2000 took 0.035s
  training loss:		0.028194
  validation loss:		0.338801
  validation accuracy:		93.48 %
Epoch 866 of 2000 took 0.035s
  training loss:		0.027509
  validation loss:		0.341503
  validation accuracy:		93.48 %
Epoch 867 of 2000 took 0.036s
  training loss:		0.029102
  validation loss:		0.338738
  validation accuracy:		93.15 %
Epoch 868 of 2000 took 0.035s
  training loss:		0.028821
  validation loss:		0.324485
  validation accuracy:		94.02 %
Epoch 869 of 2000 took 0.035s
  training loss:		0.029055
  validation loss:		0.336489
  validation accuracy:		93.48 %
Epoch 870 of 2000 took 0.035s
  training loss:		0.028422
  validation loss:		0.334187
  validation accuracy:		93.48 %
Epoch 871 of 2000 took 0.035s
  training loss:		0.028388
  validation loss:		0.326859
  validation accuracy:		93.48 %
Epoch 872 of 2000 took 0.035s
  training loss:		0.028782
  validation loss:		0.339109
  validation accuracy:		93.48 %
Epoch 873 of 2000 took 0.035s
  training loss:		0.029239
  validation loss:		0.335259
  validation accuracy:		93.26 %
Epoch 874 of 2000 took 0.035s
  training loss:		0.030232
  validation loss:		0.340879
  validation accuracy:		93.15 %
Epoch 875 of 2000 took 0.035s
  training loss:		0.028735
  validation loss:		0.339280
  validation accuracy:		93.37 %
Epoch 876 of 2000 took 0.035s
  training loss:		0.028540
  validation loss:		0.347502
  validation accuracy:		93.26 %
Epoch 877 of 2000 took 0.035s
  training loss:		0.027508
  validation loss:		0.346966
  validation accuracy:		93.26 %
Epoch 878 of 2000 took 0.035s
  training loss:		0.029121
  validation loss:		0.344750
  validation accuracy:		93.37 %
Epoch 879 of 2000 took 0.035s
  training loss:		0.028776
  validation loss:		0.334990
  validation accuracy:		93.26 %
Epoch 880 of 2000 took 0.035s
  training loss:		0.027279
  validation loss:		0.333184
  validation accuracy:		93.59 %
Epoch 881 of 2000 took 0.035s
  training loss:		0.028821
  validation loss:		0.346045
  validation accuracy:		93.26 %
Epoch 882 of 2000 took 0.035s
  training loss:		0.028455
  validation loss:		0.342442
  validation accuracy:		93.37 %
Epoch 883 of 2000 took 0.035s
  training loss:		0.028528
  validation loss:		0.338551
  validation accuracy:		93.59 %
Epoch 884 of 2000 took 0.036s
  training loss:		0.028128
  validation loss:		0.338043
  validation accuracy:		93.48 %
Epoch 885 of 2000 took 0.035s
  training loss:		0.027778
  validation loss:		0.341849
  validation accuracy:		93.37 %
Epoch 886 of 2000 took 0.035s
  training loss:		0.028757
  validation loss:		0.332400
  validation accuracy:		93.48 %
Epoch 887 of 2000 took 0.035s
  training loss:		0.028165
  validation loss:		0.342476
  validation accuracy:		93.48 %
Epoch 888 of 2000 took 0.035s
  training loss:		0.028057
  validation loss:		0.345647
  validation accuracy:		93.26 %
Epoch 889 of 2000 took 0.036s
  training loss:		0.028355
  validation loss:		0.348628
  validation accuracy:		93.26 %
Epoch 890 of 2000 took 0.035s
  training loss:		0.028426
  validation loss:		0.338770
  validation accuracy:		93.70 %
Epoch 891 of 2000 took 0.035s
  training loss:		0.027877
  validation loss:		0.345856
  validation accuracy:		93.26 %
Epoch 892 of 2000 took 0.035s
  training loss:		0.027362
  validation loss:		0.339729
  validation accuracy:		93.80 %
Epoch 893 of 2000 took 0.035s
  training loss:		0.028689
  validation loss:		0.348931
  validation accuracy:		93.37 %
Epoch 894 of 2000 took 0.035s
  training loss:		0.027631
  validation loss:		0.337049
  validation accuracy:		93.59 %
Epoch 895 of 2000 took 0.036s
  training loss:		0.026745
  validation loss:		0.345784
  validation accuracy:		93.37 %
Epoch 896 of 2000 took 0.035s
  training loss:		0.026463
  validation loss:		0.341694
  validation accuracy:		93.59 %
Epoch 897 of 2000 took 0.035s
  training loss:		0.026937
  validation loss:		0.365336
  validation accuracy:		93.48 %
Epoch 898 of 2000 took 0.035s
  training loss:		0.027742
  validation loss:		0.343315
  validation accuracy:		93.37 %
Epoch 899 of 2000 took 0.035s
  training loss:		0.027268
  validation loss:		0.362608
  validation accuracy:		93.15 %
Epoch 900 of 2000 took 0.035s
  training loss:		0.027387
  validation loss:		0.354754
  validation accuracy:		93.48 %
Epoch 901 of 2000 took 0.035s
  training loss:		0.028099
  validation loss:		0.335080
  validation accuracy:		93.70 %
Epoch 902 of 2000 took 0.035s
  training loss:		0.027105
  validation loss:		0.345802
  validation accuracy:		93.59 %
Epoch 903 of 2000 took 0.035s
  training loss:		0.025762
  validation loss:		0.345464
  validation accuracy:		93.48 %
Epoch 904 of 2000 took 0.035s
  training loss:		0.026314
  validation loss:		0.358124
  validation accuracy:		93.37 %
Epoch 905 of 2000 took 0.035s
  training loss:		0.026480
  validation loss:		0.339898
  validation accuracy:		93.70 %
Epoch 906 of 2000 took 0.035s
  training loss:		0.027654
  validation loss:		0.351281
  validation accuracy:		93.26 %
Epoch 907 of 2000 took 0.035s
  training loss:		0.027327
  validation loss:		0.355055
  validation accuracy:		93.37 %
Epoch 908 of 2000 took 0.035s
  training loss:		0.026625
  validation loss:		0.345139
  validation accuracy:		93.70 %
Epoch 909 of 2000 took 0.035s
  training loss:		0.025919
  validation loss:		0.349337
  validation accuracy:		93.48 %
Epoch 910 of 2000 took 0.035s
  training loss:		0.026575
  validation loss:		0.355191
  validation accuracy:		93.37 %
Epoch 911 of 2000 took 0.035s
  training loss:		0.026844
  validation loss:		0.361031
  validation accuracy:		93.59 %
Epoch 912 of 2000 took 0.035s
  training loss:		0.027444
  validation loss:		0.351257
  validation accuracy:		93.48 %
Epoch 913 of 2000 took 0.035s
  training loss:		0.025953
  validation loss:		0.354806
  validation accuracy:		93.48 %
Epoch 914 of 2000 took 0.035s
  training loss:		0.025628
  validation loss:		0.356486
  validation accuracy:		93.37 %
Epoch 915 of 2000 took 0.036s
  training loss:		0.025505
  validation loss:		0.357503
  validation accuracy:		93.37 %
Epoch 916 of 2000 took 0.035s
  training loss:		0.024638
  validation loss:		0.365372
  validation accuracy:		93.26 %
Epoch 917 of 2000 took 0.035s
  training loss:		0.025382
  validation loss:		0.334583
  validation accuracy:		93.70 %
Epoch 918 of 2000 took 0.035s
  training loss:		0.026052
  validation loss:		0.370458
  validation accuracy:		93.26 %
Epoch 919 of 2000 took 0.035s
  training loss:		0.028383
  validation loss:		0.349925
  validation accuracy:		93.26 %
Epoch 920 of 2000 took 0.035s
  training loss:		0.026658
  validation loss:		0.358129
  validation accuracy:		93.48 %
Epoch 921 of 2000 took 0.035s
  training loss:		0.026299
  validation loss:		0.348599
  validation accuracy:		93.37 %
Epoch 922 of 2000 took 0.035s
  training loss:		0.025397
  validation loss:		0.369149
  validation accuracy:		93.26 %
Epoch 923 of 2000 took 0.035s
  training loss:		0.024462
  validation loss:		0.348833
  validation accuracy:		93.37 %
Epoch 924 of 2000 took 0.035s
  training loss:		0.024882
  validation loss:		0.347743
  validation accuracy:		93.26 %
Epoch 925 of 2000 took 0.035s
  training loss:		0.025338
  validation loss:		0.354242
  validation accuracy:		93.26 %
Epoch 926 of 2000 took 0.035s
  training loss:		0.025507
  validation loss:		0.367606
  validation accuracy:		93.15 %
Epoch 927 of 2000 took 0.035s
  training loss:		0.025069
  validation loss:		0.354748
  validation accuracy:		93.15 %
Epoch 928 of 2000 took 0.035s
  training loss:		0.027332
  validation loss:		0.349340
  validation accuracy:		93.70 %
Epoch 929 of 2000 took 0.035s
  training loss:		0.026022
  validation loss:		0.348667
  validation accuracy:		93.37 %
Epoch 930 of 2000 took 0.035s
  training loss:		0.024492
  validation loss:		0.355452
  validation accuracy:		93.59 %
Epoch 931 of 2000 took 0.035s
  training loss:		0.025286
  validation loss:		0.354271
  validation accuracy:		93.48 %
Epoch 932 of 2000 took 0.035s
  training loss:		0.024610
  validation loss:		0.353284
  validation accuracy:		93.59 %
Epoch 933 of 2000 took 0.035s
  training loss:		0.024623
  validation loss:		0.352041
  validation accuracy:		93.48 %
Epoch 934 of 2000 took 0.035s
  training loss:		0.024080
  validation loss:		0.350545
  validation accuracy:		93.37 %
Epoch 935 of 2000 took 0.036s
  training loss:		0.024895
  validation loss:		0.356852
  validation accuracy:		93.37 %
Epoch 936 of 2000 took 0.035s
  training loss:		0.026106
  validation loss:		0.366801
  validation accuracy:		93.15 %
Epoch 937 of 2000 took 0.035s
  training loss:		0.024865
  validation loss:		0.349705
  validation accuracy:		93.48 %
Epoch 938 of 2000 took 0.035s
  training loss:		0.025166
  validation loss:		0.359252
  validation accuracy:		93.37 %
Epoch 939 of 2000 took 0.035s
  training loss:		0.024019
  validation loss:		0.353102
  validation accuracy:		93.37 %
Epoch 940 of 2000 took 0.035s
  training loss:		0.024587
  validation loss:		0.361322
  validation accuracy:		93.15 %
Epoch 941 of 2000 took 0.035s
  training loss:		0.024787
  validation loss:		0.362586
  validation accuracy:		93.26 %
Epoch 942 of 2000 took 0.035s
  training loss:		0.025358
  validation loss:		0.352900
  validation accuracy:		93.48 %
Epoch 943 of 2000 took 0.035s
  training loss:		0.024756
  validation loss:		0.352562
  validation accuracy:		93.37 %
Epoch 944 of 2000 took 0.035s
  training loss:		0.024196
  validation loss:		0.360667
  validation accuracy:		93.26 %
Epoch 945 of 2000 took 0.035s
  training loss:		0.024208
  validation loss:		0.356962
  validation accuracy:		93.37 %
Epoch 946 of 2000 took 0.035s
  training loss:		0.023702
  validation loss:		0.369677
  validation accuracy:		92.93 %
Epoch 947 of 2000 took 0.035s
  training loss:		0.024820
  validation loss:		0.363482
  validation accuracy:		93.37 %
Epoch 948 of 2000 took 0.035s
  training loss:		0.024106
  validation loss:		0.374979
  validation accuracy:		93.37 %
Epoch 949 of 2000 took 0.035s
  training loss:		0.024842
  validation loss:		0.370777
  validation accuracy:		93.26 %
Epoch 950 of 2000 took 0.035s
  training loss:		0.024501
  validation loss:		0.361127
  validation accuracy:		93.37 %
Epoch 951 of 2000 took 0.035s
  training loss:		0.024151
  validation loss:		0.379589
  validation accuracy:		93.15 %
Epoch 952 of 2000 took 0.035s
  training loss:		0.024031
  validation loss:		0.357707
  validation accuracy:		93.59 %
Epoch 953 of 2000 took 0.035s
  training loss:		0.024134
  validation loss:		0.357259
  validation accuracy:		93.70 %
Epoch 954 of 2000 took 0.035s
  training loss:		0.025343
  validation loss:		0.361356
  validation accuracy:		93.59 %
Epoch 955 of 2000 took 0.035s
  training loss:		0.025372
  validation loss:		0.357790
  validation accuracy:		93.37 %
Epoch 956 of 2000 took 0.035s
  training loss:		0.024599
  validation loss:		0.370775
  validation accuracy:		93.70 %
Epoch 957 of 2000 took 0.035s
  training loss:		0.024008
  validation loss:		0.365812
  validation accuracy:		93.15 %
Epoch 958 of 2000 took 0.036s
  training loss:		0.025783
  validation loss:		0.372453
  validation accuracy:		93.15 %
Epoch 959 of 2000 took 0.035s
  training loss:		0.023460
  validation loss:		0.355018
  validation accuracy:		93.59 %
Epoch 960 of 2000 took 0.035s
  training loss:		0.024125
  validation loss:		0.359666
  validation accuracy:		93.37 %
Epoch 961 of 2000 took 0.035s
  training loss:		0.023451
  validation loss:		0.365077
  validation accuracy:		93.37 %
Epoch 962 of 2000 took 0.035s
  training loss:		0.023138
  validation loss:		0.384818
  validation accuracy:		92.72 %
Epoch 963 of 2000 took 0.035s
  training loss:		0.023011
  validation loss:		0.375983
  validation accuracy:		93.15 %
Epoch 964 of 2000 took 0.035s
  training loss:		0.023198
  validation loss:		0.362830
  validation accuracy:		93.48 %
Epoch 965 of 2000 took 0.035s
  training loss:		0.023409
  validation loss:		0.361901
  validation accuracy:		93.59 %
Epoch 966 of 2000 took 0.035s
  training loss:		0.023225
  validation loss:		0.356283
  validation accuracy:		93.15 %
Epoch 967 of 2000 took 0.035s
  training loss:		0.023806
  validation loss:		0.368384
  validation accuracy:		93.15 %
Epoch 968 of 2000 took 0.035s
  training loss:		0.022923
  validation loss:		0.363829
  validation accuracy:		93.48 %
Epoch 969 of 2000 took 0.035s
  training loss:		0.022477
  validation loss:		0.367317
  validation accuracy:		93.37 %
Epoch 970 of 2000 took 0.035s
  training loss:		0.023707
  validation loss:		0.361986
  validation accuracy:		93.70 %
Epoch 971 of 2000 took 0.035s
  training loss:		0.024000
  validation loss:		0.374722
  validation accuracy:		93.26 %
Epoch 972 of 2000 took 0.036s
  training loss:		0.023338
  validation loss:		0.379940
  validation accuracy:		93.37 %
Epoch 973 of 2000 took 0.035s
  training loss:		0.022837
  validation loss:		0.364044
  validation accuracy:		93.37 %
Epoch 974 of 2000 took 0.035s
  training loss:		0.024324
  validation loss:		0.379003
  validation accuracy:		93.26 %
Epoch 975 of 2000 took 0.035s
  training loss:		0.022546
  validation loss:		0.369688
  validation accuracy:		93.37 %
Epoch 976 of 2000 took 0.035s
  training loss:		0.022633
  validation loss:		0.376886
  validation accuracy:		92.83 %
Epoch 977 of 2000 took 0.035s
  training loss:		0.022433
  validation loss:		0.373690
  validation accuracy:		93.37 %
Epoch 978 of 2000 took 0.035s
  training loss:		0.022918
  validation loss:		0.377624
  validation accuracy:		93.04 %
Epoch 979 of 2000 took 0.035s
  training loss:		0.022784
  validation loss:		0.364674
  validation accuracy:		93.59 %
Epoch 980 of 2000 took 0.036s
  training loss:		0.022544
  validation loss:		0.370094
  validation accuracy:		93.37 %
Epoch 981 of 2000 took 0.035s
  training loss:		0.022994
  validation loss:		0.376862
  validation accuracy:		93.15 %
Epoch 982 of 2000 took 0.035s
  training loss:		0.022241
  validation loss:		0.379645
  validation accuracy:		93.15 %
Epoch 983 of 2000 took 0.035s
  training loss:		0.022221
  validation loss:		0.359884
  validation accuracy:		93.70 %
Epoch 984 of 2000 took 0.035s
  training loss:		0.023398
  validation loss:		0.374090
  validation accuracy:		93.48 %
Epoch 985 of 2000 took 0.035s
  training loss:		0.022607
  validation loss:		0.367327
  validation accuracy:		93.26 %
Epoch 986 of 2000 took 0.035s
  training loss:		0.021138
  validation loss:		0.393729
  validation accuracy:		92.83 %
Epoch 987 of 2000 took 0.035s
  training loss:		0.022048
  validation loss:		0.383584
  validation accuracy:		93.04 %
Epoch 988 of 2000 took 0.035s
  training loss:		0.021776
  validation loss:		0.376649
  validation accuracy:		93.48 %
Epoch 989 of 2000 took 0.035s
  training loss:		0.021994
  validation loss:		0.375436
  validation accuracy:		93.37 %
Epoch 990 of 2000 took 0.035s
  training loss:		0.022871
  validation loss:		0.380560
  validation accuracy:		93.26 %
Epoch 991 of 2000 took 0.035s
  training loss:		0.022884
  validation loss:		0.385600
  validation accuracy:		93.04 %
Epoch 992 of 2000 took 0.035s
  training loss:		0.022268
  validation loss:		0.389356
  validation accuracy:		92.83 %
Epoch 993 of 2000 took 0.035s
  training loss:		0.022234
  validation loss:		0.365993
  validation accuracy:		93.59 %
Epoch 994 of 2000 took 0.035s
  training loss:		0.022346
  validation loss:		0.380097
  validation accuracy:		93.37 %
Epoch 995 of 2000 took 0.035s
  training loss:		0.021415
  validation loss:		0.385358
  validation accuracy:		93.15 %
Epoch 996 of 2000 took 0.035s
  training loss:		0.021856
  validation loss:		0.363650
  validation accuracy:		93.59 %
Epoch 997 of 2000 took 0.035s
  training loss:		0.022696
  validation loss:		0.383819
  validation accuracy:		92.72 %
Epoch 998 of 2000 took 0.035s
  training loss:		0.021014
  validation loss:		0.376458
  validation accuracy:		93.26 %
Epoch 999 of 2000 took 0.035s
  training loss:		0.022307
  validation loss:		0.379272
  validation accuracy:		93.26 %
Epoch 1000 of 2000 took 0.035s
  training loss:		0.020256
  validation loss:		0.372914
  validation accuracy:		93.37 %
Epoch 1001 of 2000 took 0.035s
  training loss:		0.022048
  validation loss:		0.373342
  validation accuracy:		93.26 %
Epoch 1002 of 2000 took 0.035s
  training loss:		0.021989
  validation loss:		0.369771
  validation accuracy:		93.59 %
Epoch 1003 of 2000 took 0.035s
  training loss:		0.021284
  validation loss:		0.378483
  validation accuracy:		93.37 %
Epoch 1004 of 2000 took 0.035s
  training loss:		0.021615
  validation loss:		0.387732
  validation accuracy:		93.15 %
Epoch 1005 of 2000 took 0.035s
  training loss:		0.021775
  validation loss:		0.379305
  validation accuracy:		93.26 %
Epoch 1006 of 2000 took 0.035s
  training loss:		0.020971
  validation loss:		0.373884
  validation accuracy:		93.26 %
Epoch 1007 of 2000 took 0.035s
  training loss:		0.020734
  validation loss:		0.383956
  validation accuracy:		93.15 %
Epoch 1008 of 2000 took 0.035s
  training loss:		0.021569
  validation loss:		0.373485
  validation accuracy:		93.48 %
Epoch 1009 of 2000 took 0.035s
  training loss:		0.021300
  validation loss:		0.373023
  validation accuracy:		93.48 %
Epoch 1010 of 2000 took 0.035s
  training loss:		0.021139
  validation loss:		0.380671
  validation accuracy:		93.37 %
Epoch 1011 of 2000 took 0.035s
  training loss:		0.021043
  validation loss:		0.386351
  validation accuracy:		93.26 %
Epoch 1012 of 2000 took 0.035s
  training loss:		0.021799
  validation loss:		0.389619
  validation accuracy:		93.37 %
Epoch 1013 of 2000 took 0.035s
  training loss:		0.020381
  validation loss:		0.389081
  validation accuracy:		93.26 %
Epoch 1014 of 2000 took 0.035s
  training loss:		0.020987
  validation loss:		0.384718
  validation accuracy:		93.37 %
Epoch 1015 of 2000 took 0.035s
  training loss:		0.020234
  validation loss:		0.395836
  validation accuracy:		93.15 %
Epoch 1016 of 2000 took 0.035s
  training loss:		0.020613
  validation loss:		0.363518
  validation accuracy:		93.70 %
Epoch 1017 of 2000 took 0.035s
  training loss:		0.021441
  validation loss:		0.378180
  validation accuracy:		93.37 %
Epoch 1018 of 2000 took 0.035s
  training loss:		0.021261
  validation loss:		0.378362
  validation accuracy:		93.37 %
Epoch 1019 of 2000 took 0.035s
  training loss:		0.020506
  validation loss:		0.382703
  validation accuracy:		93.15 %
Epoch 1020 of 2000 took 0.035s
  training loss:		0.020191
  validation loss:		0.382758
  validation accuracy:		93.48 %
Epoch 1021 of 2000 took 0.035s
  training loss:		0.020317
  validation loss:		0.391692
  validation accuracy:		93.04 %
Epoch 1022 of 2000 took 0.035s
  training loss:		0.020813
  validation loss:		0.376806
  validation accuracy:		93.37 %
Epoch 1023 of 2000 took 0.035s
  training loss:		0.020452
  validation loss:		0.388469
  validation accuracy:		93.15 %
Epoch 1024 of 2000 took 0.035s
  training loss:		0.019989
  validation loss:		0.386451
  validation accuracy:		93.37 %
Epoch 1025 of 2000 took 0.035s
  training loss:		0.019671
  validation loss:		0.375442
  validation accuracy:		93.59 %
Epoch 1026 of 2000 took 0.035s
  training loss:		0.019147
  validation loss:		0.390065
  validation accuracy:		93.26 %
Epoch 1027 of 2000 took 0.035s
  training loss:		0.020036
  validation loss:		0.378956
  validation accuracy:		93.26 %
Epoch 1028 of 2000 took 0.036s
  training loss:		0.019320
  validation loss:		0.380198
  validation accuracy:		93.48 %
Epoch 1029 of 2000 took 0.035s
  training loss:		0.020037
  validation loss:		0.372661
  validation accuracy:		93.59 %
Epoch 1030 of 2000 took 0.035s
  training loss:		0.020671
  validation loss:		0.384939
  validation accuracy:		93.15 %
Epoch 1031 of 2000 took 0.035s
  training loss:		0.019873
  validation loss:		0.394244
  validation accuracy:		93.26 %
Epoch 1032 of 2000 took 0.035s
  training loss:		0.020160
  validation loss:		0.384389
  validation accuracy:		93.48 %
Epoch 1033 of 2000 took 0.035s
  training loss:		0.019953
  validation loss:		0.389049
  validation accuracy:		93.04 %
Epoch 1034 of 2000 took 0.035s
  training loss:		0.019575
  validation loss:		0.375981
  validation accuracy:		93.59 %
Epoch 1035 of 2000 took 0.035s
  training loss:		0.019619
  validation loss:		0.386069
  validation accuracy:		93.26 %
Epoch 1036 of 2000 took 0.036s
  training loss:		0.020525
  validation loss:		0.391606
  validation accuracy:		93.26 %
Epoch 1037 of 2000 took 0.035s
  training loss:		0.020171
  validation loss:		0.389795
  validation accuracy:		93.26 %
Epoch 1038 of 2000 took 0.036s
  training loss:		0.019032
  validation loss:		0.394016
  validation accuracy:		93.04 %
Epoch 1039 of 2000 took 0.035s
  training loss:		0.019653
  validation loss:		0.388496
  validation accuracy:		93.26 %
Epoch 1040 of 2000 took 0.035s
  training loss:		0.019715
  validation loss:		0.389528
  validation accuracy:		93.37 %
Epoch 1041 of 2000 took 0.035s
  training loss:		0.020090
  validation loss:		0.397067
  validation accuracy:		93.04 %
Epoch 1042 of 2000 took 0.035s
  training loss:		0.018948
  validation loss:		0.388944
  validation accuracy:		93.37 %
Epoch 1043 of 2000 took 0.036s
  training loss:		0.019170
  validation loss:		0.401286
  validation accuracy:		93.04 %
Epoch 1044 of 2000 took 0.035s
  training loss:		0.019855
  validation loss:		0.389955
  validation accuracy:		93.15 %
Epoch 1045 of 2000 took 0.035s
  training loss:		0.019930
  validation loss:		0.381714
  validation accuracy:		93.48 %
Epoch 1046 of 2000 took 0.035s
  training loss:		0.019271
  validation loss:		0.403459
  validation accuracy:		93.26 %
Epoch 1047 of 2000 took 0.035s
  training loss:		0.019168
  validation loss:		0.380179
  validation accuracy:		93.48 %
Epoch 1048 of 2000 took 0.035s
  training loss:		0.018890
  validation loss:		0.385827
  validation accuracy:		93.26 %
Epoch 1049 of 2000 took 0.035s
  training loss:		0.018671
  validation loss:		0.401050
  validation accuracy:		93.26 %
Epoch 1050 of 2000 took 0.035s
  training loss:		0.019302
  validation loss:		0.391437
  validation accuracy:		93.26 %
Epoch 1051 of 2000 took 0.035s
  training loss:		0.019186
  validation loss:		0.387471
  validation accuracy:		93.26 %
Epoch 1052 of 2000 took 0.035s
  training loss:		0.017885
  validation loss:		0.409571
  validation accuracy:		92.93 %
Epoch 1053 of 2000 took 0.035s
  training loss:		0.018750
  validation loss:		0.403136
  validation accuracy:		93.26 %
Epoch 1054 of 2000 took 0.036s
  training loss:		0.019269
  validation loss:		0.387085
  validation accuracy:		93.15 %
Epoch 1055 of 2000 took 0.035s
  training loss:		0.018876
  validation loss:		0.390473
  validation accuracy:		93.37 %
Epoch 1056 of 2000 took 0.035s
  training loss:		0.018567
  validation loss:		0.396837
  validation accuracy:		93.15 %
Epoch 1057 of 2000 took 0.035s
  training loss:		0.018459
  validation loss:		0.412896
  validation accuracy:		93.26 %
Epoch 1058 of 2000 took 0.035s
  training loss:		0.019041
  validation loss:		0.390872
  validation accuracy:		93.48 %
Epoch 1059 of 2000 took 0.035s
  training loss:		0.018200
  validation loss:		0.394369
  validation accuracy:		93.26 %
Epoch 1060 of 2000 took 0.035s
  training loss:		0.018491
  validation loss:		0.402046
  validation accuracy:		93.37 %
Epoch 1061 of 2000 took 0.035s
  training loss:		0.018539
  validation loss:		0.393308
  validation accuracy:		93.37 %
Epoch 1062 of 2000 took 0.035s
  training loss:		0.017970
  validation loss:		0.397941
  validation accuracy:		93.26 %
Epoch 1063 of 2000 took 0.035s
  training loss:		0.018718
  validation loss:		0.398925
  validation accuracy:		93.15 %
Epoch 1064 of 2000 took 0.035s
  training loss:		0.018307
  validation loss:		0.387612
  validation accuracy:		93.37 %
Epoch 1065 of 2000 took 0.036s
  training loss:		0.018890
  validation loss:		0.395578
  validation accuracy:		93.26 %
Epoch 1066 of 2000 took 0.035s
  training loss:		0.017624
  validation loss:		0.389068
  validation accuracy:		93.59 %
Epoch 1067 of 2000 took 0.035s
  training loss:		0.017432
  validation loss:		0.399952
  validation accuracy:		93.15 %
Epoch 1068 of 2000 took 0.035s
  training loss:		0.017618
  validation loss:		0.402319
  validation accuracy:		93.15 %
Epoch 1069 of 2000 took 0.035s
  training loss:		0.018158
  validation loss:		0.397409
  validation accuracy:		93.15 %
Epoch 1070 of 2000 took 0.035s
  training loss:		0.018080
  validation loss:		0.405796
  validation accuracy:		93.37 %
Epoch 1071 of 2000 took 0.035s
  training loss:		0.018399
  validation loss:		0.398103
  validation accuracy:		93.15 %
Epoch 1072 of 2000 took 0.035s
  training loss:		0.018394
  validation loss:		0.391861
  validation accuracy:		93.26 %
Epoch 1073 of 2000 took 0.035s
  training loss:		0.018023
  validation loss:		0.401399
  validation accuracy:		93.15 %
Epoch 1074 of 2000 took 0.035s
  training loss:		0.018572
  validation loss:		0.407952
  validation accuracy:		93.26 %
Epoch 1075 of 2000 took 0.035s
  training loss:		0.017703
  validation loss:		0.395645
  validation accuracy:		93.26 %
Epoch 1076 of 2000 took 0.035s
  training loss:		0.018281
  validation loss:		0.415444
  validation accuracy:		93.26 %
Epoch 1077 of 2000 took 0.035s
  training loss:		0.017668
  validation loss:		0.398485
  validation accuracy:		93.48 %
Epoch 1078 of 2000 took 0.035s
  training loss:		0.017694
  validation loss:		0.395356
  validation accuracy:		93.26 %
Epoch 1079 of 2000 took 0.035s
  training loss:		0.018436
  validation loss:		0.400195
  validation accuracy:		93.26 %
Epoch 1080 of 2000 took 0.035s
  training loss:		0.017651
  validation loss:		0.408585
  validation accuracy:		93.04 %
Epoch 1081 of 2000 took 0.035s
  training loss:		0.017328
  validation loss:		0.394803
  validation accuracy:		93.26 %
Epoch 1082 of 2000 took 0.036s
  training loss:		0.019016
  validation loss:		0.405550
  validation accuracy:		93.26 %
Epoch 1083 of 2000 took 0.035s
  training loss:		0.017749
  validation loss:		0.404555
  validation accuracy:		93.15 %
Epoch 1084 of 2000 took 0.035s
  training loss:		0.018006
  validation loss:		0.395451
  validation accuracy:		93.37 %
Epoch 1085 of 2000 took 0.036s
  training loss:		0.018050
  validation loss:		0.408380
  validation accuracy:		93.15 %
Epoch 1086 of 2000 took 0.035s
  training loss:		0.016931
  validation loss:		0.399291
  validation accuracy:		93.37 %
Epoch 1087 of 2000 took 0.035s
  training loss:		0.017396
  validation loss:		0.399556
  validation accuracy:		93.26 %
Epoch 1088 of 2000 took 0.035s
  training loss:		0.017100
  validation loss:		0.408391
  validation accuracy:		93.26 %
Epoch 1089 of 2000 took 0.035s
  training loss:		0.017171
  validation loss:		0.409925
  validation accuracy:		93.15 %
Epoch 1090 of 2000 took 0.035s
  training loss:		0.017501
  validation loss:		0.401687
  validation accuracy:		93.04 %
Epoch 1091 of 2000 took 0.035s
  training loss:		0.017269
  validation loss:		0.404668
  validation accuracy:		93.26 %
Epoch 1092 of 2000 took 0.035s
  training loss:		0.017488
  validation loss:		0.405035
  validation accuracy:		93.37 %
Epoch 1093 of 2000 took 0.035s
  training loss:		0.017197
  validation loss:		0.413268
  validation accuracy:		93.26 %
Epoch 1094 of 2000 took 0.035s
  training loss:		0.016863
  validation loss:		0.414088
  validation accuracy:		92.93 %
Epoch 1095 of 2000 took 0.036s
  training loss:		0.017231
  validation loss:		0.402438
  validation accuracy:		93.26 %
Epoch 1096 of 2000 took 0.035s
  training loss:		0.017350
  validation loss:		0.403112
  validation accuracy:		93.26 %
Epoch 1097 of 2000 took 0.035s
  training loss:		0.016607
  validation loss:		0.400700
  validation accuracy:		93.59 %
Epoch 1098 of 2000 took 0.035s
  training loss:		0.017463
  validation loss:		0.394315
  validation accuracy:		93.37 %
Epoch 1099 of 2000 took 0.035s
  training loss:		0.017187
  validation loss:		0.406990
  validation accuracy:		93.15 %
Epoch 1100 of 2000 took 0.035s
  training loss:		0.017279
  validation loss:		0.404279
  validation accuracy:		93.26 %
Epoch 1101 of 2000 took 0.036s
  training loss:		0.017063
  validation loss:		0.405882
  validation accuracy:		93.26 %
Epoch 1102 of 2000 took 0.035s
  training loss:		0.016907
  validation loss:		0.408912
  validation accuracy:		93.15 %
Epoch 1103 of 2000 took 0.035s
  training loss:		0.016486
  validation loss:		0.397365
  validation accuracy:		93.37 %
Epoch 1104 of 2000 took 0.035s
  training loss:		0.017187
  validation loss:		0.398334
  validation accuracy:		93.48 %
Epoch 1105 of 2000 took 0.035s
  training loss:		0.016739
  validation loss:		0.404999
  validation accuracy:		93.26 %
Epoch 1106 of 2000 took 0.035s
  training loss:		0.017002
  validation loss:		0.410531
  validation accuracy:		93.15 %
Epoch 1107 of 2000 took 0.035s
  training loss:		0.015644
  validation loss:		0.405444
  validation accuracy:		93.26 %
Epoch 1108 of 2000 took 0.035s
  training loss:		0.016909
  validation loss:		0.406467
  validation accuracy:		93.15 %
Epoch 1109 of 2000 took 0.035s
  training loss:		0.016546
  validation loss:		0.405630
  validation accuracy:		93.37 %
Epoch 1110 of 2000 took 0.035s
  training loss:		0.016421
  validation loss:		0.403121
  validation accuracy:		93.26 %
Epoch 1111 of 2000 took 0.036s
  training loss:		0.016405
  validation loss:		0.410152
  validation accuracy:		93.15 %
Epoch 1112 of 2000 took 0.035s
  training loss:		0.016385
  validation loss:		0.405844
  validation accuracy:		93.37 %
Epoch 1113 of 2000 took 0.035s
  training loss:		0.016352
  validation loss:		0.405526
  validation accuracy:		93.26 %
Epoch 1114 of 2000 took 0.035s
  training loss:		0.016111
  validation loss:		0.415780
  validation accuracy:		93.15 %
Epoch 1115 of 2000 took 0.035s
  training loss:		0.015706
  validation loss:		0.401766
  validation accuracy:		93.59 %
Epoch 1116 of 2000 took 0.035s
  training loss:		0.016611
  validation loss:		0.405535
  validation accuracy:		93.48 %
Epoch 1117 of 2000 took 0.035s
  training loss:		0.016269
  validation loss:		0.409958
  validation accuracy:		93.15 %
Epoch 1118 of 2000 took 0.035s
  training loss:		0.016453
  validation loss:		0.409521
  validation accuracy:		93.26 %
Epoch 1119 of 2000 took 0.035s
  training loss:		0.016291
  validation loss:		0.423465
  validation accuracy:		93.15 %
Epoch 1120 of 2000 took 0.035s
  training loss:		0.016124
  validation loss:		0.412656
  validation accuracy:		93.48 %
Epoch 1121 of 2000 took 0.036s
  training loss:		0.016175
  validation loss:		0.406543
  validation accuracy:		93.26 %
Epoch 1122 of 2000 took 0.035s
  training loss:		0.015898
  validation loss:		0.412693
  validation accuracy:		93.04 %
Epoch 1123 of 2000 took 0.035s
  training loss:		0.016897
  validation loss:		0.416958
  validation accuracy:		93.15 %
Epoch 1124 of 2000 took 0.035s
  training loss:		0.016507
  validation loss:		0.405131
  validation accuracy:		93.37 %
Epoch 1125 of 2000 took 0.035s
  training loss:		0.016019
  validation loss:		0.416636
  validation accuracy:		93.15 %
Epoch 1126 of 2000 took 0.035s
  training loss:		0.016225
  validation loss:		0.424510
  validation accuracy:		93.15 %
Epoch 1127 of 2000 took 0.035s
  training loss:		0.015944
  validation loss:		0.399436
  validation accuracy:		93.70 %
Epoch 1128 of 2000 took 0.035s
  training loss:		0.016879
  validation loss:		0.410248
  validation accuracy:		93.37 %
Epoch 1129 of 2000 took 0.035s
  training loss:		0.015866
  validation loss:		0.418151
  validation accuracy:		93.04 %
Epoch 1130 of 2000 took 0.035s
  training loss:		0.015817
  validation loss:		0.418454
  validation accuracy:		93.15 %
Epoch 1131 of 2000 took 0.035s
  training loss:		0.015482
  validation loss:		0.405359
  validation accuracy:		93.48 %
Epoch 1132 of 2000 took 0.035s
  training loss:		0.016111
  validation loss:		0.430117
  validation accuracy:		93.04 %
Epoch 1133 of 2000 took 0.035s
  training loss:		0.016178
  validation loss:		0.418080
  validation accuracy:		93.15 %
Epoch 1134 of 2000 took 0.035s
  training loss:		0.015992
  validation loss:		0.435784
  validation accuracy:		93.04 %
Epoch 1135 of 2000 took 0.035s
  training loss:		0.015849
  validation loss:		0.415549
  validation accuracy:		93.15 %
Epoch 1136 of 2000 took 0.035s
  training loss:		0.015330
  validation loss:		0.418338
  validation accuracy:		93.26 %
Epoch 1137 of 2000 took 0.035s
  training loss:		0.015491
  validation loss:		0.422708
  validation accuracy:		93.26 %
Epoch 1138 of 2000 took 0.035s
  training loss:		0.015150
  validation loss:		0.427733
  validation accuracy:		93.15 %
Epoch 1139 of 2000 took 0.035s
  training loss:		0.015091
  validation loss:		0.421646
  validation accuracy:		93.15 %
Epoch 1140 of 2000 took 0.035s
  training loss:		0.015740
  validation loss:		0.412129
  validation accuracy:		93.26 %
Epoch 1141 of 2000 took 0.036s
  training loss:		0.015573
  validation loss:		0.419330
  validation accuracy:		93.15 %
Epoch 1142 of 2000 took 0.035s
  training loss:		0.016146
  validation loss:		0.413821
  validation accuracy:		93.26 %
Epoch 1143 of 2000 took 0.035s
  training loss:		0.015454
  validation loss:		0.420645
  validation accuracy:		92.93 %
Epoch 1144 of 2000 took 0.035s
  training loss:		0.015636
  validation loss:		0.428245
  validation accuracy:		93.26 %
Epoch 1145 of 2000 took 0.035s
  training loss:		0.015198
  validation loss:		0.420534
  validation accuracy:		93.26 %
Epoch 1146 of 2000 took 0.035s
  training loss:		0.015105
  validation loss:		0.412624
  validation accuracy:		93.37 %
Epoch 1147 of 2000 took 0.035s
  training loss:		0.015065
  validation loss:		0.418530
  validation accuracy:		93.37 %
Epoch 1148 of 2000 took 0.035s
  training loss:		0.015294
  validation loss:		0.414331
  validation accuracy:		93.37 %
Epoch 1149 of 2000 took 0.036s
  training loss:		0.014889
  validation loss:		0.431068
  validation accuracy:		92.93 %
Epoch 1150 of 2000 took 0.035s
  training loss:		0.015706
  validation loss:		0.427761
  validation accuracy:		93.26 %
Epoch 1151 of 2000 took 0.035s
  training loss:		0.015047
  validation loss:		0.410038
  validation accuracy:		93.70 %
Epoch 1152 of 2000 took 0.035s
  training loss:		0.014726
  validation loss:		0.423580
  validation accuracy:		93.26 %
Epoch 1153 of 2000 took 0.035s
  training loss:		0.015046
  validation loss:		0.428778
  validation accuracy:		93.15 %
Epoch 1154 of 2000 took 0.035s
  training loss:		0.015070
  validation loss:		0.431523
  validation accuracy:		92.93 %
Epoch 1155 of 2000 took 0.035s
  training loss:		0.015007
  validation loss:		0.415340
  validation accuracy:		93.15 %
Epoch 1156 of 2000 took 0.035s
  training loss:		0.014790
  validation loss:		0.421679
  validation accuracy:		93.26 %
Epoch 1157 of 2000 took 0.035s
  training loss:		0.015644
  validation loss:		0.417177
  validation accuracy:		93.37 %
Epoch 1158 of 2000 took 0.035s
  training loss:		0.014457
  validation loss:		0.418279
  validation accuracy:		93.37 %
Epoch 1159 of 2000 took 0.035s
  training loss:		0.015211
  validation loss:		0.439496
  validation accuracy:		92.83 %
Epoch 1160 of 2000 took 0.035s
  training loss:		0.015041
  validation loss:		0.421126
  validation accuracy:		93.26 %
Epoch 1161 of 2000 took 0.035s
  training loss:		0.015034
  validation loss:		0.425239
  validation accuracy:		93.26 %
Epoch 1162 of 2000 took 0.035s
  training loss:		0.015280
  validation loss:		0.423617
  validation accuracy:		93.26 %
Epoch 1163 of 2000 took 0.035s
  training loss:		0.014319
  validation loss:		0.419288
  validation accuracy:		93.26 %
Epoch 1164 of 2000 took 0.035s
  training loss:		0.014721
  validation loss:		0.435820
  validation accuracy:		93.04 %
Epoch 1165 of 2000 took 0.035s
  training loss:		0.014480
  validation loss:		0.428513
  validation accuracy:		93.15 %
Epoch 1166 of 2000 took 0.036s
  training loss:		0.014573
  validation loss:		0.413042
  validation accuracy:		93.48 %
Epoch 1167 of 2000 took 0.035s
  training loss:		0.014281
  validation loss:		0.425907
  validation accuracy:		93.26 %
Epoch 1168 of 2000 took 0.035s
  training loss:		0.014384
  validation loss:		0.438179
  validation accuracy:		92.72 %
Epoch 1169 of 2000 took 0.035s
  training loss:		0.015087
  validation loss:		0.424937
  validation accuracy:		93.37 %
Epoch 1170 of 2000 took 0.035s
  training loss:		0.014392
  validation loss:		0.419133
  validation accuracy:		93.15 %
Epoch 1171 of 2000 took 0.036s
  training loss:		0.015194
  validation loss:		0.433795
  validation accuracy:		92.93 %
Epoch 1172 of 2000 took 0.035s
  training loss:		0.014354
  validation loss:		0.426345
  validation accuracy:		93.15 %
Epoch 1173 of 2000 took 0.035s
  training loss:		0.014792
  validation loss:		0.440106
  validation accuracy:		92.83 %
Epoch 1174 of 2000 took 0.035s
  training loss:		0.014366
  validation loss:		0.433631
  validation accuracy:		93.04 %
Epoch 1175 of 2000 took 0.035s
  training loss:		0.013923
  validation loss:		0.415897
  validation accuracy:		93.59 %
Epoch 1176 of 2000 took 0.035s
  training loss:		0.014891
  validation loss:		0.430962
  validation accuracy:		93.26 %
Epoch 1177 of 2000 took 0.035s
  training loss:		0.014645
  validation loss:		0.428920
  validation accuracy:		93.26 %
Epoch 1178 of 2000 took 0.035s
  training loss:		0.014534
  validation loss:		0.431222
  validation accuracy:		93.04 %
Epoch 1179 of 2000 took 0.035s
  training loss:		0.014002
  validation loss:		0.419819
  validation accuracy:		93.59 %
Epoch 1180 of 2000 took 0.035s
  training loss:		0.014424
  validation loss:		0.429916
  validation accuracy:		93.26 %
Epoch 1181 of 2000 took 0.035s
  training loss:		0.014503
  validation loss:		0.432835
  validation accuracy:		93.26 %
Epoch 1182 of 2000 took 0.035s
  training loss:		0.014298
  validation loss:		0.424377
  validation accuracy:		93.15 %
Epoch 1183 of 2000 took 0.035s
  training loss:		0.014120
  validation loss:		0.425022
  validation accuracy:		93.48 %
Epoch 1184 of 2000 took 0.035s
  training loss:		0.014224
  validation loss:		0.430771
  validation accuracy:		93.15 %
Epoch 1185 of 2000 took 0.035s
  training loss:		0.013941
  validation loss:		0.446223
  validation accuracy:		92.83 %
Epoch 1186 of 2000 took 0.035s
  training loss:		0.013867
  validation loss:		0.429409
  validation accuracy:		93.37 %
Epoch 1187 of 2000 took 0.035s
  training loss:		0.013401
  validation loss:		0.428195
  validation accuracy:		93.26 %
Epoch 1188 of 2000 took 0.035s
  training loss:		0.013766
  validation loss:		0.421988
  validation accuracy:		93.15 %
Epoch 1189 of 2000 took 0.035s
  training loss:		0.013725
  validation loss:		0.433962
  validation accuracy:		93.15 %
Epoch 1190 of 2000 took 0.035s
  training loss:		0.013802
  validation loss:		0.427929
  validation accuracy:		93.26 %
Epoch 1191 of 2000 took 0.035s
  training loss:		0.014517
  validation loss:		0.438247
  validation accuracy:		93.15 %
Epoch 1192 of 2000 took 0.035s
  training loss:		0.013740
  validation loss:		0.425144
  validation accuracy:		93.59 %
Epoch 1193 of 2000 took 0.035s
  training loss:		0.013771
  validation loss:		0.441416
  validation accuracy:		93.04 %
Epoch 1194 of 2000 took 0.035s
  training loss:		0.013574
  validation loss:		0.435008
  validation accuracy:		93.15 %
Epoch 1195 of 2000 took 0.036s
  training loss:		0.013048
  validation loss:		0.429833
  validation accuracy:		93.26 %
Epoch 1196 of 2000 took 0.035s
  training loss:		0.013404
  validation loss:		0.439197
  validation accuracy:		93.04 %
Epoch 1197 of 2000 took 0.035s
  training loss:		0.013827
  validation loss:		0.432079
  validation accuracy:		93.04 %
Epoch 1198 of 2000 took 0.036s
  training loss:		0.013856
  validation loss:		0.446705
  validation accuracy:		92.93 %
Epoch 1199 of 2000 took 0.035s
  training loss:		0.014060
  validation loss:		0.430640
  validation accuracy:		93.48 %
Epoch 1200 of 2000 took 0.036s
  training loss:		0.013648
  validation loss:		0.427020
  validation accuracy:		93.37 %
Epoch 1201 of 2000 took 0.035s
  training loss:		0.013392
  validation loss:		0.437302
  validation accuracy:		93.26 %
Epoch 1202 of 2000 took 0.035s
  training loss:		0.013476
  validation loss:		0.434103
  validation accuracy:		93.26 %
Epoch 1203 of 2000 took 0.035s
  training loss:		0.013671
  validation loss:		0.436493
  validation accuracy:		93.26 %
Epoch 1204 of 2000 took 0.035s
  training loss:		0.013479
  validation loss:		0.434553
  validation accuracy:		93.37 %
Epoch 1205 of 2000 took 0.035s
  training loss:		0.013239
  validation loss:		0.429855
  validation accuracy:		93.48 %
Epoch 1206 of 2000 took 0.035s
  training loss:		0.014175
  validation loss:		0.433312
  validation accuracy:		93.15 %
Epoch 1207 of 2000 took 0.035s
  training loss:		0.013230
  validation loss:		0.430618
  validation accuracy:		93.15 %
Epoch 1208 of 2000 took 0.035s
  training loss:		0.013834
  validation loss:		0.431781
  validation accuracy:		93.48 %
Epoch 1209 of 2000 took 0.035s
  training loss:		0.012497
  validation loss:		0.450458
  validation accuracy:		92.72 %
Epoch 1210 of 2000 took 0.035s
  training loss:		0.013292
  validation loss:		0.434482
  validation accuracy:		93.15 %
Epoch 1211 of 2000 took 0.035s
  training loss:		0.013900
  validation loss:		0.435375
  validation accuracy:		93.26 %
Epoch 1212 of 2000 took 0.035s
  training loss:		0.013223
  validation loss:		0.442634
  validation accuracy:		93.26 %
Epoch 1213 of 2000 took 0.035s
  training loss:		0.013520
  validation loss:		0.449526
  validation accuracy:		92.93 %
Epoch 1214 of 2000 took 0.035s
  training loss:		0.013407
  validation loss:		0.446930
  validation accuracy:		92.83 %
Epoch 1215 of 2000 took 0.035s
  training loss:		0.013380
  validation loss:		0.429496
  validation accuracy:		93.26 %
Epoch 1216 of 2000 took 0.035s
  training loss:		0.013485
  validation loss:		0.436219
  validation accuracy:		93.26 %
Epoch 1217 of 2000 took 0.036s
  training loss:		0.012842
  validation loss:		0.440333
  validation accuracy:		93.15 %
Epoch 1218 of 2000 took 0.035s
  training loss:		0.013276
  validation loss:		0.440028
  validation accuracy:		93.26 %
Epoch 1219 of 2000 took 0.035s
  training loss:		0.012725
  validation loss:		0.451658
  validation accuracy:		92.93 %
Epoch 1220 of 2000 took 0.035s
  training loss:		0.013573
  validation loss:		0.442924
  validation accuracy:		93.15 %
Epoch 1221 of 2000 took 0.035s
  training loss:		0.012803
  validation loss:		0.453162
  validation accuracy:		92.83 %
Epoch 1222 of 2000 took 0.035s
  training loss:		0.013218
  validation loss:		0.445107
  validation accuracy:		92.93 %
Epoch 1223 of 2000 took 0.035s
  training loss:		0.012955
  validation loss:		0.442907
  validation accuracy:		93.26 %
Epoch 1224 of 2000 took 0.036s
  training loss:		0.013210
  validation loss:		0.446598
  validation accuracy:		92.93 %
Epoch 1225 of 2000 took 0.035s
  training loss:		0.013121
  validation loss:		0.434817
  validation accuracy:		93.26 %
Epoch 1226 of 2000 took 0.035s
  training loss:		0.012817
  validation loss:		0.443966
  validation accuracy:		93.04 %
Epoch 1227 of 2000 took 0.035s
  training loss:		0.013036
  validation loss:		0.442814
  validation accuracy:		93.15 %
Epoch 1228 of 2000 took 0.035s
  training loss:		0.013162
  validation loss:		0.440252
  validation accuracy:		93.15 %
Epoch 1229 of 2000 took 0.035s
  training loss:		0.012904
  validation loss:		0.440603
  validation accuracy:		93.48 %
Epoch 1230 of 2000 took 0.035s
  training loss:		0.012958
  validation loss:		0.443912
  validation accuracy:		93.04 %
Epoch 1231 of 2000 took 0.035s
  training loss:		0.012645
  validation loss:		0.442492
  validation accuracy:		93.04 %
Epoch 1232 of 2000 took 0.035s
  training loss:		0.012392
  validation loss:		0.437727
  validation accuracy:		93.15 %
Epoch 1233 of 2000 took 0.035s
  training loss:		0.012904
  validation loss:		0.449290
  validation accuracy:		93.26 %
Epoch 1234 of 2000 took 0.036s
  training loss:		0.012556
  validation loss:		0.446101
  validation accuracy:		93.04 %
Epoch 1235 of 2000 took 0.035s
  training loss:		0.012935
  validation loss:		0.452173
  validation accuracy:		93.26 %
Epoch 1236 of 2000 took 0.035s
  training loss:		0.012449
  validation loss:		0.436727
  validation accuracy:		93.48 %
Epoch 1237 of 2000 took 0.035s
  training loss:		0.012459
  validation loss:		0.441905
  validation accuracy:		93.15 %
Epoch 1238 of 2000 took 0.035s
  training loss:		0.012184
  validation loss:		0.434893
  validation accuracy:		93.48 %
Epoch 1239 of 2000 took 0.035s
  training loss:		0.012556
  validation loss:		0.451178
  validation accuracy:		93.15 %
Epoch 1240 of 2000 took 0.035s
  training loss:		0.012479
  validation loss:		0.438349
  validation accuracy:		93.48 %
Epoch 1241 of 2000 took 0.036s
  training loss:		0.012482
  validation loss:		0.445437
  validation accuracy:		93.48 %
Epoch 1242 of 2000 took 0.035s
  training loss:		0.012142
  validation loss:		0.443978
  validation accuracy:		93.48 %
Epoch 1243 of 2000 took 0.035s
  training loss:		0.012353
  validation loss:		0.444472
  validation accuracy:		93.48 %
Epoch 1244 of 2000 took 0.035s
  training loss:		0.011972
  validation loss:		0.458181
  validation accuracy:		92.72 %
Epoch 1245 of 2000 took 0.035s
  training loss:		0.012253
  validation loss:		0.435663
  validation accuracy:		93.37 %
Epoch 1246 of 2000 took 0.035s
  training loss:		0.012568
  validation loss:		0.443223
  validation accuracy:		93.15 %
Epoch 1247 of 2000 took 0.035s
  training loss:		0.012674
  validation loss:		0.445502
  validation accuracy:		93.26 %
Epoch 1248 of 2000 took 0.035s
  training loss:		0.012262
  validation loss:		0.448285
  validation accuracy:		93.26 %
Epoch 1249 of 2000 took 0.035s
  training loss:		0.011967
  validation loss:		0.444073
  validation accuracy:		93.26 %
Epoch 1250 of 2000 took 0.035s
  training loss:		0.012047
  validation loss:		0.454483
  validation accuracy:		93.04 %
Epoch 1251 of 2000 took 0.036s
  training loss:		0.012315
  validation loss:		0.447159
  validation accuracy:		93.37 %
Epoch 1252 of 2000 took 0.035s
  training loss:		0.012432
  validation loss:		0.447840
  validation accuracy:		92.93 %
Epoch 1253 of 2000 took 0.035s
  training loss:		0.012487
  validation loss:		0.453452
  validation accuracy:		93.15 %
Epoch 1254 of 2000 took 0.036s
  training loss:		0.012453
  validation loss:		0.448293
  validation accuracy:		93.48 %
Epoch 1255 of 2000 took 0.035s
  training loss:		0.012099
  validation loss:		0.463463
  validation accuracy:		92.83 %
Epoch 1256 of 2000 took 0.035s
  training loss:		0.012342
  validation loss:		0.450574
  validation accuracy:		93.04 %
Epoch 1257 of 2000 took 0.035s
  training loss:		0.012273
  validation loss:		0.441429
  validation accuracy:		93.48 %
Epoch 1258 of 2000 took 0.035s
  training loss:		0.011834
  validation loss:		0.447924
  validation accuracy:		93.26 %
Epoch 1259 of 2000 took 0.035s
  training loss:		0.012258
  validation loss:		0.445197
  validation accuracy:		93.26 %
Epoch 1260 of 2000 took 0.035s
  training loss:		0.011574
  validation loss:		0.457552
  validation accuracy:		93.04 %
Epoch 1261 of 2000 took 0.035s
  training loss:		0.011797
  validation loss:		0.452645
  validation accuracy:		93.15 %
Epoch 1262 of 2000 took 0.036s
  training loss:		0.012018
  validation loss:		0.454101
  validation accuracy:		93.04 %
Epoch 1263 of 2000 took 0.035s
  training loss:		0.011793
  validation loss:		0.449519
  validation accuracy:		93.15 %
Epoch 1264 of 2000 took 0.035s
  training loss:		0.011730
  validation loss:		0.451942
  validation accuracy:		93.26 %
Epoch 1265 of 2000 took 0.035s
  training loss:		0.011406
  validation loss:		0.451041
  validation accuracy:		93.15 %
Epoch 1266 of 2000 took 0.035s
  training loss:		0.011704
  validation loss:		0.459322
  validation accuracy:		92.93 %
Epoch 1267 of 2000 took 0.036s
  training loss:		0.011748
  validation loss:		0.462202
  validation accuracy:		92.83 %
Epoch 1268 of 2000 took 0.035s
  training loss:		0.011799
  validation loss:		0.454850
  validation accuracy:		93.04 %
Epoch 1269 of 2000 took 0.036s
  training loss:		0.011853
  validation loss:		0.451978
  validation accuracy:		93.48 %
Epoch 1270 of 2000 took 0.035s
  training loss:		0.011519
  validation loss:		0.460461
  validation accuracy:		93.04 %
Epoch 1271 of 2000 took 0.035s
  training loss:		0.011550
  validation loss:		0.463018
  validation accuracy:		92.83 %
Epoch 1272 of 2000 took 0.035s
  training loss:		0.011553
  validation loss:		0.463042
  validation accuracy:		92.93 %
Epoch 1273 of 2000 took 0.035s
  training loss:		0.011872
  validation loss:		0.450541
  validation accuracy:		93.15 %
Epoch 1274 of 2000 took 0.035s
  training loss:		0.011739
  validation loss:		0.452004
  validation accuracy:		93.59 %
Epoch 1275 of 2000 took 0.035s
  training loss:		0.011659
  validation loss:		0.458115
  validation accuracy:		93.15 %
Epoch 1276 of 2000 took 0.035s
  training loss:		0.011533
  validation loss:		0.450415
  validation accuracy:		93.48 %
Epoch 1277 of 2000 took 0.035s
  training loss:		0.011843
  validation loss:		0.453783
  validation accuracy:		93.26 %
Epoch 1278 of 2000 took 0.035s
  training loss:		0.011621
  validation loss:		0.449401
  validation accuracy:		93.15 %
Epoch 1279 of 2000 took 0.035s
  training loss:		0.011519
  validation loss:		0.456587
  validation accuracy:		93.15 %
Epoch 1280 of 2000 took 0.035s
  training loss:		0.011338
  validation loss:		0.444070
  validation accuracy:		93.37 %
Epoch 1281 of 2000 took 0.035s
  training loss:		0.011276
  validation loss:		0.454749
  validation accuracy:		93.15 %
Epoch 1282 of 2000 took 0.035s
  training loss:		0.011133
  validation loss:		0.457483
  validation accuracy:		93.15 %
Epoch 1283 of 2000 took 0.035s
  training loss:		0.011391
  validation loss:		0.449715
  validation accuracy:		93.37 %
Epoch 1284 of 2000 took 0.035s
  training loss:		0.011229
  validation loss:		0.448534
  validation accuracy:		93.37 %
Epoch 1285 of 2000 took 0.035s
  training loss:		0.011386
  validation loss:		0.449076
  validation accuracy:		93.37 %
Epoch 1286 of 2000 took 0.035s
  training loss:		0.011093
  validation loss:		0.457933
  validation accuracy:		93.37 %
Epoch 1287 of 2000 took 0.035s
  training loss:		0.011385
  validation loss:		0.464223
  validation accuracy:		93.04 %
Epoch 1288 of 2000 took 0.035s
  training loss:		0.011698
  validation loss:		0.454838
  validation accuracy:		93.04 %
Epoch 1289 of 2000 took 0.035s
  training loss:		0.011494
  validation loss:		0.456995
  validation accuracy:		93.04 %
Epoch 1290 of 2000 took 0.035s
  training loss:		0.011339
  validation loss:		0.454107
  validation accuracy:		93.59 %
Epoch 1291 of 2000 took 0.035s
  training loss:		0.011185
  validation loss:		0.468948
  validation accuracy:		92.72 %
Epoch 1292 of 2000 took 0.035s
  training loss:		0.011096
  validation loss:		0.453905
  validation accuracy:		93.26 %
Epoch 1293 of 2000 took 0.035s
  training loss:		0.011123
  validation loss:		0.452310
  validation accuracy:		93.04 %
Epoch 1294 of 2000 took 0.035s
  training loss:		0.011038
  validation loss:		0.451115
  validation accuracy:		93.48 %
Epoch 1295 of 2000 took 0.035s
  training loss:		0.011222
  validation loss:		0.455271
  validation accuracy:		93.37 %
Epoch 1296 of 2000 took 0.035s
  training loss:		0.010851
  validation loss:		0.457016
  validation accuracy:		93.37 %
Epoch 1297 of 2000 took 0.035s
  training loss:		0.010855
  validation loss:		0.452755
  validation accuracy:		93.37 %
Epoch 1298 of 2000 took 0.035s
  training loss:		0.011169
  validation loss:		0.461774
  validation accuracy:		93.04 %
Epoch 1299 of 2000 took 0.035s
  training loss:		0.011278
  validation loss:		0.461126
  validation accuracy:		93.15 %
Epoch 1300 of 2000 took 0.035s
  training loss:		0.010623
  validation loss:		0.457933
  validation accuracy:		93.48 %
Epoch 1301 of 2000 took 0.035s
  training loss:		0.010814
  validation loss:		0.463586
  validation accuracy:		93.15 %
Epoch 1302 of 2000 took 0.035s
  training loss:		0.010587
  validation loss:		0.465093
  validation accuracy:		93.26 %
Epoch 1303 of 2000 took 0.035s
  training loss:		0.010818
  validation loss:		0.468709
  validation accuracy:		92.93 %
Epoch 1304 of 2000 took 0.035s
  training loss:		0.010936
  validation loss:		0.469027
  validation accuracy:		92.83 %
Epoch 1305 of 2000 took 0.035s
  training loss:		0.010697
  validation loss:		0.459975
  validation accuracy:		93.15 %
Epoch 1306 of 2000 took 0.035s
  training loss:		0.010789
  validation loss:		0.462609
  validation accuracy:		93.04 %
Epoch 1307 of 2000 took 0.035s
  training loss:		0.010406
  validation loss:		0.479279
  validation accuracy:		92.72 %
Epoch 1308 of 2000 took 0.035s
  training loss:		0.010816
  validation loss:		0.481381
  validation accuracy:		92.50 %
Epoch 1309 of 2000 took 0.035s
  training loss:		0.011071
  validation loss:		0.476014
  validation accuracy:		92.72 %
Epoch 1310 of 2000 took 0.035s
  training loss:		0.010489
  validation loss:		0.459595
  validation accuracy:		93.59 %
Epoch 1311 of 2000 took 0.036s
  training loss:		0.010900
  validation loss:		0.460134
  validation accuracy:		93.37 %
Epoch 1312 of 2000 took 0.035s
  training loss:		0.011035
  validation loss:		0.472451
  validation accuracy:		92.93 %
Epoch 1313 of 2000 took 0.035s
  training loss:		0.010605
  validation loss:		0.459135
  validation accuracy:		93.37 %
Epoch 1314 of 2000 took 0.035s
  training loss:		0.010789
  validation loss:		0.471433
  validation accuracy:		92.72 %
Epoch 1315 of 2000 took 0.035s
  training loss:		0.010825
  validation loss:		0.465212
  validation accuracy:		93.26 %
Epoch 1316 of 2000 took 0.035s
  training loss:		0.010424
  validation loss:		0.473868
  validation accuracy:		92.93 %
Epoch 1317 of 2000 took 0.035s
  training loss:		0.010732
  validation loss:		0.471019
  validation accuracy:		93.04 %
Epoch 1318 of 2000 took 0.035s
  training loss:		0.010333
  validation loss:		0.468198
  validation accuracy:		93.04 %
Epoch 1319 of 2000 took 0.035s
  training loss:		0.010736
  validation loss:		0.448550
  validation accuracy:		93.37 %
Epoch 1320 of 2000 took 0.035s
  training loss:		0.010972
  validation loss:		0.459342
  validation accuracy:		93.37 %
Epoch 1321 of 2000 took 0.035s
  training loss:		0.010759
  validation loss:		0.464850
  validation accuracy:		93.15 %
Epoch 1322 of 2000 took 0.035s
  training loss:		0.010523
  validation loss:		0.478213
  validation accuracy:		92.72 %
Epoch 1323 of 2000 took 0.035s
  training loss:		0.010656
  validation loss:		0.463169
  validation accuracy:		93.26 %
Epoch 1324 of 2000 took 0.035s
  training loss:		0.010380
  validation loss:		0.467429
  validation accuracy:		93.37 %
Epoch 1325 of 2000 took 0.035s
  training loss:		0.010523
  validation loss:		0.465094
  validation accuracy:		93.37 %
Epoch 1326 of 2000 took 0.035s
  training loss:		0.010411
  validation loss:		0.462780
  validation accuracy:		93.26 %
Epoch 1327 of 2000 took 0.035s
  training loss:		0.010281
  validation loss:		0.456998
  validation accuracy:		93.15 %
Epoch 1328 of 2000 took 0.035s
  training loss:		0.010790
  validation loss:		0.468545
  validation accuracy:		93.04 %
Epoch 1329 of 2000 took 0.035s
  training loss:		0.010591
  validation loss:		0.466068
  validation accuracy:		93.48 %
Epoch 1330 of 2000 took 0.035s
  training loss:		0.010327
  validation loss:		0.470858
  validation accuracy:		93.04 %
Epoch 1331 of 2000 took 0.035s
  training loss:		0.010141
  validation loss:		0.468186
  validation accuracy:		93.04 %
Epoch 1332 of 2000 took 0.035s
  training loss:		0.010559
  validation loss:		0.468702
  validation accuracy:		93.15 %
Epoch 1333 of 2000 took 0.035s
  training loss:		0.010022
  validation loss:		0.464382
  validation accuracy:		93.26 %
Epoch 1334 of 2000 took 0.035s
  training loss:		0.010459
  validation loss:		0.474713
  validation accuracy:		93.15 %
Epoch 1335 of 2000 took 0.035s
  training loss:		0.010352
  validation loss:		0.473876
  validation accuracy:		92.72 %
Epoch 1336 of 2000 took 0.035s
  training loss:		0.010143
  validation loss:		0.475826
  validation accuracy:		93.15 %
Epoch 1337 of 2000 took 0.035s
  training loss:		0.009861
  validation loss:		0.471582
  validation accuracy:		93.04 %
Epoch 1338 of 2000 took 0.035s
  training loss:		0.010260
  validation loss:		0.472293
  validation accuracy:		93.48 %
Epoch 1339 of 2000 took 0.035s
  training loss:		0.010303
  validation loss:		0.476405
  validation accuracy:		92.83 %
Epoch 1340 of 2000 took 0.035s
  training loss:		0.010122
  validation loss:		0.477735
  validation accuracy:		92.93 %
Epoch 1341 of 2000 took 0.035s
  training loss:		0.010312
  validation loss:		0.469897
  validation accuracy:		93.26 %
Epoch 1342 of 2000 took 0.035s
  training loss:		0.009857
  validation loss:		0.472536
  validation accuracy:		93.04 %
Epoch 1343 of 2000 took 0.035s
  training loss:		0.010126
  validation loss:		0.480006
  validation accuracy:		93.15 %
Epoch 1344 of 2000 took 0.035s
  training loss:		0.010141
  validation loss:		0.466851
  validation accuracy:		93.15 %
Epoch 1345 of 2000 took 0.035s
  training loss:		0.009876
  validation loss:		0.469318
  validation accuracy:		93.37 %
Epoch 1346 of 2000 took 0.035s
  training loss:		0.009795
  validation loss:		0.468294
  validation accuracy:		93.48 %
Epoch 1347 of 2000 took 0.035s
  training loss:		0.010174
  validation loss:		0.473074
  validation accuracy:		93.15 %
Epoch 1348 of 2000 took 0.035s
  training loss:		0.010098
  validation loss:		0.466589
  validation accuracy:		93.37 %
Epoch 1349 of 2000 took 0.035s
  training loss:		0.009877
  validation loss:		0.472624
  validation accuracy:		93.04 %
Epoch 1350 of 2000 took 0.035s
  training loss:		0.010082
  validation loss:		0.486739
  validation accuracy:		92.93 %
Epoch 1351 of 2000 took 0.035s
  training loss:		0.009476
  validation loss:		0.476068
  validation accuracy:		93.04 %
Epoch 1352 of 2000 took 0.035s
  training loss:		0.009765
  validation loss:		0.479567
  validation accuracy:		92.72 %
Epoch 1353 of 2000 took 0.035s
  training loss:		0.009990
  validation loss:		0.481008
  validation accuracy:		92.72 %
Epoch 1354 of 2000 took 0.035s
  training loss:		0.009626
  validation loss:		0.482040
  validation accuracy:		93.04 %
Epoch 1355 of 2000 took 0.035s
  training loss:		0.009559
  validation loss:		0.467549
  validation accuracy:		93.48 %
Epoch 1356 of 2000 took 0.035s
  training loss:		0.009452
  validation loss:		0.470034
  validation accuracy:		93.26 %
Epoch 1357 of 2000 took 0.035s
  training loss:		0.009814
  validation loss:		0.468226
  validation accuracy:		93.04 %
Epoch 1358 of 2000 took 0.035s
  training loss:		0.010054
  validation loss:		0.471150
  validation accuracy:		93.48 %
Epoch 1359 of 2000 took 0.035s
  training loss:		0.009839
  validation loss:		0.479833
  validation accuracy:		93.26 %
Epoch 1360 of 2000 took 0.035s
  training loss:		0.009667
  validation loss:		0.477923
  validation accuracy:		93.15 %
Epoch 1361 of 2000 took 0.035s
  training loss:		0.009589
  validation loss:		0.472691
  validation accuracy:		93.26 %
Epoch 1362 of 2000 took 0.035s
  training loss:		0.009600
  validation loss:		0.475823
  validation accuracy:		93.15 %
Epoch 1363 of 2000 took 0.035s
  training loss:		0.009835
  validation loss:		0.482082
  validation accuracy:		93.15 %
Epoch 1364 of 2000 took 0.035s
  training loss:		0.009801
  validation loss:		0.474812
  validation accuracy:		93.15 %
Epoch 1365 of 2000 took 0.035s
  training loss:		0.009983
  validation loss:		0.472637
  validation accuracy:		93.26 %
Epoch 1366 of 2000 took 0.035s
  training loss:		0.009262
  validation loss:		0.477853
  validation accuracy:		93.04 %
Epoch 1367 of 2000 took 0.036s
  training loss:		0.009446
  validation loss:		0.483330
  validation accuracy:		93.04 %
Epoch 1368 of 2000 took 0.035s
  training loss:		0.009587
  validation loss:		0.484947
  validation accuracy:		92.83 %
Epoch 1369 of 2000 took 0.035s
  training loss:		0.009765
  validation loss:		0.474974
  validation accuracy:		93.26 %
Epoch 1370 of 2000 took 0.035s
  training loss:		0.009695
  validation loss:		0.483295
  validation accuracy:		92.72 %
Epoch 1371 of 2000 took 0.035s
  training loss:		0.009777
  validation loss:		0.482734
  validation accuracy:		92.72 %
Epoch 1372 of 2000 took 0.035s
  training loss:		0.009695
  validation loss:		0.479205
  validation accuracy:		93.26 %
Epoch 1373 of 2000 took 0.035s
  training loss:		0.009247
  validation loss:		0.479284
  validation accuracy:		93.26 %
Epoch 1374 of 2000 took 0.035s
  training loss:		0.009148
  validation loss:		0.484383
  validation accuracy:		92.93 %
Epoch 1375 of 2000 took 0.036s
  training loss:		0.009365
  validation loss:		0.481990
  validation accuracy:		93.15 %
Epoch 1376 of 2000 took 0.035s
  training loss:		0.009368
  validation loss:		0.477727
  validation accuracy:		93.37 %
Epoch 1377 of 2000 took 0.035s
  training loss:		0.009215
  validation loss:		0.471742
  validation accuracy:		93.26 %
Epoch 1378 of 2000 took 0.035s
  training loss:		0.009211
  validation loss:		0.483026
  validation accuracy:		93.37 %
Epoch 1379 of 2000 took 0.035s
  training loss:		0.009623
  validation loss:		0.479896
  validation accuracy:		92.93 %
Epoch 1380 of 2000 took 0.035s
  training loss:		0.009568
  validation loss:		0.480538
  validation accuracy:		92.61 %
Epoch 1381 of 2000 took 0.035s
  training loss:		0.009634
  validation loss:		0.482348
  validation accuracy:		93.04 %
Epoch 1382 of 2000 took 0.035s
  training loss:		0.009207
  validation loss:		0.476438
  validation accuracy:		93.37 %
Epoch 1383 of 2000 took 0.035s
  training loss:		0.009592
  validation loss:		0.489024
  validation accuracy:		92.83 %
Epoch 1384 of 2000 took 0.035s
  training loss:		0.009471
  validation loss:		0.475045
  validation accuracy:		93.26 %
Epoch 1385 of 2000 took 0.035s
  training loss:		0.009621
  validation loss:		0.477514
  validation accuracy:		93.15 %
Epoch 1386 of 2000 took 0.035s
  training loss:		0.008962
  validation loss:		0.485850
  validation accuracy:		93.26 %
Epoch 1387 of 2000 took 0.035s
  training loss:		0.009084
  validation loss:		0.480167
  validation accuracy:		93.04 %
Epoch 1388 of 2000 took 0.035s
  training loss:		0.009381
  validation loss:		0.467229
  validation accuracy:		93.15 %
Epoch 1389 of 2000 took 0.035s
  training loss:		0.009319
  validation loss:		0.486740
  validation accuracy:		92.93 %
Epoch 1390 of 2000 took 0.035s
  training loss:		0.009081
  validation loss:		0.486718
  validation accuracy:		93.04 %
Epoch 1391 of 2000 took 0.035s
  training loss:		0.009238
  validation loss:		0.488825
  validation accuracy:		93.15 %
Epoch 1392 of 2000 took 0.036s
  training loss:		0.009139
  validation loss:		0.489357
  validation accuracy:		93.04 %
Epoch 1393 of 2000 took 0.035s
  training loss:		0.009007
  validation loss:		0.477052
  validation accuracy:		93.26 %
Epoch 1394 of 2000 took 0.035s
  training loss:		0.009303
  validation loss:		0.482281
  validation accuracy:		92.93 %
Epoch 1395 of 2000 took 0.035s
  training loss:		0.009450
  validation loss:		0.487557
  validation accuracy:		93.26 %
Epoch 1396 of 2000 took 0.035s
  training loss:		0.009347
  validation loss:		0.480770
  validation accuracy:		93.37 %
Epoch 1397 of 2000 took 0.035s
  training loss:		0.008979
  validation loss:		0.482958
  validation accuracy:		93.26 %
Epoch 1398 of 2000 took 0.035s
  training loss:		0.009038
  validation loss:		0.483342
  validation accuracy:		92.93 %
Epoch 1399 of 2000 took 0.035s
  training loss:		0.009106
  validation loss:		0.481380
  validation accuracy:		92.93 %
Epoch 1400 of 2000 took 0.035s
  training loss:		0.008887
  validation loss:		0.478058
  validation accuracy:		93.37 %
Epoch 1401 of 2000 took 0.037s
  training loss:		0.009315
  validation loss:		0.483222
  validation accuracy:		93.37 %
Epoch 1402 of 2000 took 0.036s
  training loss:		0.008973
  validation loss:		0.482942
  validation accuracy:		93.26 %
Epoch 1403 of 2000 took 0.035s
  training loss:		0.009146
  validation loss:		0.482683
  validation accuracy:		93.37 %
Epoch 1404 of 2000 took 0.035s
  training loss:		0.008911
  validation loss:		0.489108
  validation accuracy:		93.04 %
Epoch 1405 of 2000 took 0.035s
  training loss:		0.008778
  validation loss:		0.484182
  validation accuracy:		93.26 %
Epoch 1406 of 2000 took 0.035s
  training loss:		0.008877
  validation loss:		0.487595
  validation accuracy:		93.15 %
Epoch 1407 of 2000 took 0.035s
  training loss:		0.009012
  validation loss:		0.484217
  validation accuracy:		93.04 %
Epoch 1408 of 2000 took 0.035s
  training loss:		0.008972
  validation loss:		0.487191
  validation accuracy:		93.26 %
Epoch 1409 of 2000 took 0.036s
  training loss:		0.008725
  validation loss:		0.488942
  validation accuracy:		93.37 %
Epoch 1410 of 2000 took 0.036s
  training loss:		0.009039
  validation loss:		0.480058
  validation accuracy:		93.26 %
Epoch 1411 of 2000 took 0.035s
  training loss:		0.009007
  validation loss:		0.490158
  validation accuracy:		93.26 %
Epoch 1412 of 2000 took 0.035s
  training loss:		0.008794
  validation loss:		0.490790
  validation accuracy:		92.93 %
Epoch 1413 of 2000 took 0.035s
  training loss:		0.009226
  validation loss:		0.484318
  validation accuracy:		93.15 %
Epoch 1414 of 2000 took 0.035s
  training loss:		0.008960
  validation loss:		0.491587
  validation accuracy:		93.04 %
Epoch 1415 of 2000 took 0.035s
  training loss:		0.008639
  validation loss:		0.495155
  validation accuracy:		93.04 %
Epoch 1416 of 2000 took 0.035s
  training loss:		0.008452
  validation loss:		0.500319
  validation accuracy:		92.72 %
Epoch 1417 of 2000 took 0.035s
  training loss:		0.008887
  validation loss:		0.499563
  validation accuracy:		92.83 %
Epoch 1418 of 2000 took 0.035s
  training loss:		0.008680
  validation loss:		0.488443
  validation accuracy:		93.37 %
Epoch 1419 of 2000 took 0.035s
  training loss:		0.008784
  validation loss:		0.492923
  validation accuracy:		92.83 %
Epoch 1420 of 2000 took 0.035s
  training loss:		0.008735
  validation loss:		0.484741
  validation accuracy:		93.37 %
Epoch 1421 of 2000 took 0.035s
  training loss:		0.008632
  validation loss:		0.491726
  validation accuracy:		93.04 %
Epoch 1422 of 2000 took 0.035s
  training loss:		0.008639
  validation loss:		0.500004
  validation accuracy:		93.04 %
Epoch 1423 of 2000 took 0.035s
  training loss:		0.008819
  validation loss:		0.496296
  validation accuracy:		93.26 %
Epoch 1424 of 2000 took 0.036s
  training loss:		0.008699
  validation loss:		0.499289
  validation accuracy:		92.83 %
Epoch 1425 of 2000 took 0.035s
  training loss:		0.008873
  validation loss:		0.497152
  validation accuracy:		93.04 %
Epoch 1426 of 2000 took 0.035s
  training loss:		0.008845
  validation loss:		0.484737
  validation accuracy:		93.15 %
Epoch 1427 of 2000 took 0.035s
  training loss:		0.008439
  validation loss:		0.497092
  validation accuracy:		92.83 %
Epoch 1428 of 2000 took 0.035s
  training loss:		0.008324
  validation loss:		0.496828
  validation accuracy:		92.93 %
Epoch 1429 of 2000 took 0.035s
  training loss:		0.008725
  validation loss:		0.503063
  validation accuracy:		92.83 %
Epoch 1430 of 2000 took 0.035s
  training loss:		0.008469
  validation loss:		0.483043
  validation accuracy:		92.93 %
Epoch 1431 of 2000 took 0.035s
  training loss:		0.008550
  validation loss:		0.497810
  validation accuracy:		92.93 %
Epoch 1432 of 2000 took 0.035s
  training loss:		0.008708
  validation loss:		0.495863
  validation accuracy:		93.26 %
Epoch 1433 of 2000 took 0.035s
  training loss:		0.008251
  validation loss:		0.493661
  validation accuracy:		92.93 %
Epoch 1434 of 2000 took 0.035s
  training loss:		0.008482
  validation loss:		0.486414
  validation accuracy:		93.48 %
Epoch 1435 of 2000 took 0.035s
  training loss:		0.008754
  validation loss:		0.500547
  validation accuracy:		92.50 %
Epoch 1436 of 2000 took 0.035s
  training loss:		0.008364
  validation loss:		0.500903
  validation accuracy:		92.83 %
Epoch 1437 of 2000 took 0.035s
  training loss:		0.008423
  validation loss:		0.503815
  validation accuracy:		92.72 %
Epoch 1438 of 2000 took 0.035s
  training loss:		0.008399
  validation loss:		0.493174
  validation accuracy:		93.04 %
Epoch 1439 of 2000 took 0.035s
  training loss:		0.008349
  validation loss:		0.501825
  validation accuracy:		92.72 %
Epoch 1440 of 2000 took 0.035s
  training loss:		0.008442
  validation loss:		0.494367
  validation accuracy:		92.93 %
Epoch 1441 of 2000 took 0.035s
  training loss:		0.008057
  validation loss:		0.499716
  validation accuracy:		92.72 %
Epoch 1442 of 2000 took 0.035s
  training loss:		0.008387
  validation loss:		0.500474
  validation accuracy:		93.15 %
Epoch 1443 of 2000 took 0.035s
  training loss:		0.008386
  validation loss:		0.489695
  validation accuracy:		93.15 %
Epoch 1444 of 2000 took 0.035s
  training loss:		0.008368
  validation loss:		0.506852
  validation accuracy:		92.72 %
Epoch 1445 of 2000 took 0.035s
  training loss:		0.008740
  validation loss:		0.494709
  validation accuracy:		92.93 %
Epoch 1446 of 2000 took 0.035s
  training loss:		0.008029
  validation loss:		0.508368
  validation accuracy:		92.83 %
Epoch 1447 of 2000 took 0.035s
  training loss:		0.008652
  validation loss:		0.498949
  validation accuracy:		93.04 %
Epoch 1448 of 2000 took 0.035s
  training loss:		0.008153
  validation loss:		0.486412
  validation accuracy:		93.04 %
Epoch 1449 of 2000 took 0.035s
  training loss:		0.008526
  validation loss:		0.494774
  validation accuracy:		93.15 %
Epoch 1450 of 2000 took 0.035s
  training loss:		0.008284
  validation loss:		0.504155
  validation accuracy:		92.83 %
Epoch 1451 of 2000 took 0.035s
  training loss:		0.008136
  validation loss:		0.494583
  validation accuracy:		92.93 %
Epoch 1452 of 2000 took 0.035s
  training loss:		0.008321
  validation loss:		0.507690
  validation accuracy:		92.61 %
Epoch 1453 of 2000 took 0.035s
  training loss:		0.008175
  validation loss:		0.494666
  validation accuracy:		93.15 %
Epoch 1454 of 2000 took 0.035s
  training loss:		0.008321
  validation loss:		0.493078
  validation accuracy:		93.15 %
Epoch 1455 of 2000 took 0.035s
  training loss:		0.008013
  validation loss:		0.503843
  validation accuracy:		92.39 %
Epoch 1456 of 2000 took 0.035s
  training loss:		0.008195
  validation loss:		0.500754
  validation accuracy:		93.04 %
Epoch 1457 of 2000 took 0.035s
  training loss:		0.007894
  validation loss:		0.502917
  validation accuracy:		93.04 %
Epoch 1458 of 2000 took 0.035s
  training loss:		0.008035
  validation loss:		0.491020
  validation accuracy:		93.04 %
Epoch 1459 of 2000 took 0.035s
  training loss:		0.008197
  validation loss:		0.494195
  validation accuracy:		93.26 %
Epoch 1460 of 2000 took 0.035s
  training loss:		0.007894
  validation loss:		0.508809
  validation accuracy:		92.61 %
Epoch 1461 of 2000 took 0.035s
  training loss:		0.008163
  validation loss:		0.500919
  validation accuracy:		92.93 %
Epoch 1462 of 2000 took 0.035s
  training loss:		0.007813
  validation loss:		0.508949
  validation accuracy:		92.83 %
Epoch 1463 of 2000 took 0.035s
  training loss:		0.007841
  validation loss:		0.498540
  validation accuracy:		93.15 %
Epoch 1464 of 2000 took 0.035s
  training loss:		0.008161
  validation loss:		0.509038
  validation accuracy:		93.04 %
Epoch 1465 of 2000 took 0.035s
  training loss:		0.008216
  validation loss:		0.510110
  validation accuracy:		92.72 %
Epoch 1466 of 2000 took 0.035s
  training loss:		0.007807
  validation loss:		0.500788
  validation accuracy:		92.93 %
Epoch 1467 of 2000 took 0.035s
  training loss:		0.008171
  validation loss:		0.493930
  validation accuracy:		93.26 %
Epoch 1468 of 2000 took 0.035s
  training loss:		0.007792
  validation loss:		0.497979
  validation accuracy:		92.83 %
Epoch 1469 of 2000 took 0.035s
  training loss:		0.008019
  validation loss:		0.506181
  validation accuracy:		93.26 %
Epoch 1470 of 2000 took 0.035s
  training loss:		0.008029
  validation loss:		0.512804
  validation accuracy:		92.72 %
Epoch 1471 of 2000 took 0.035s
  training loss:		0.007975
  validation loss:		0.510028
  validation accuracy:		92.72 %
Epoch 1472 of 2000 took 0.035s
  training loss:		0.007765
  validation loss:		0.507289
  validation accuracy:		93.04 %
Epoch 1473 of 2000 took 0.035s
  training loss:		0.007936
  validation loss:		0.506168
  validation accuracy:		92.83 %
Epoch 1474 of 2000 took 0.035s
  training loss:		0.007555
  validation loss:		0.495564
  validation accuracy:		93.37 %
Epoch 1475 of 2000 took 0.035s
  training loss:		0.007927
  validation loss:		0.499879
  validation accuracy:		93.15 %
Epoch 1476 of 2000 took 0.035s
  training loss:		0.008029
  validation loss:		0.500625
  validation accuracy:		93.15 %
Epoch 1477 of 2000 took 0.035s
  training loss:		0.007781
  validation loss:		0.509458
  validation accuracy:		92.93 %
Epoch 1478 of 2000 took 0.035s
  training loss:		0.007778
  validation loss:		0.497964
  validation accuracy:		93.15 %
Epoch 1479 of 2000 took 0.035s
  training loss:		0.007921
  validation loss:		0.505474
  validation accuracy:		92.83 %
Epoch 1480 of 2000 took 0.036s
  training loss:		0.007885
  validation loss:		0.508387
  validation accuracy:		93.04 %
Epoch 1481 of 2000 took 0.035s
  training loss:		0.007620
  validation loss:		0.510356
  validation accuracy:		92.50 %
Epoch 1482 of 2000 took 0.035s
  training loss:		0.007811
  validation loss:		0.512246
  validation accuracy:		92.93 %
Epoch 1483 of 2000 took 0.035s
  training loss:		0.007870
  validation loss:		0.506624
  validation accuracy:		93.04 %
Epoch 1484 of 2000 took 0.035s
  training loss:		0.007570
  validation loss:		0.511753
  validation accuracy:		92.61 %
Epoch 1485 of 2000 took 0.035s
  training loss:		0.007568
  validation loss:		0.507911
  validation accuracy:		92.93 %
Epoch 1486 of 2000 took 0.035s
  training loss:		0.007583
  validation loss:		0.506733
  validation accuracy:		93.04 %
Epoch 1487 of 2000 took 0.035s
  training loss:		0.007542
  validation loss:		0.503250
  validation accuracy:		93.04 %
Epoch 1488 of 2000 took 0.035s
  training loss:		0.007485
  validation loss:		0.513127
  validation accuracy:		92.83 %
Epoch 1489 of 2000 took 0.035s
  training loss:		0.007767
  validation loss:		0.511311
  validation accuracy:		92.61 %
Epoch 1490 of 2000 took 0.035s
  training loss:		0.007441
  validation loss:		0.504872
  validation accuracy:		92.93 %
Epoch 1491 of 2000 took 0.035s
  training loss:		0.007384
  validation loss:		0.502888
  validation accuracy:		93.04 %
Epoch 1492 of 2000 took 0.035s
  training loss:		0.007394
  validation loss:		0.505571
  validation accuracy:		93.15 %
Epoch 1493 of 2000 took 0.036s
  training loss:		0.007544
  validation loss:		0.510517
  validation accuracy:		92.83 %
Epoch 1494 of 2000 took 0.035s
  training loss:		0.007566
  validation loss:		0.508209
  validation accuracy:		93.04 %
Epoch 1495 of 2000 took 0.035s
  training loss:		0.007539
  validation loss:		0.511879
  validation accuracy:		92.93 %
Epoch 1496 of 2000 took 0.035s
  training loss:		0.007493
  validation loss:		0.506340
  validation accuracy:		93.15 %
Epoch 1497 of 2000 took 0.035s
  training loss:		0.007743
  validation loss:		0.508803
  validation accuracy:		93.04 %
Epoch 1498 of 2000 took 0.035s
  training loss:		0.007719
  validation loss:		0.505794
  validation accuracy:		93.04 %
Epoch 1499 of 2000 took 0.035s
  training loss:		0.007579
  validation loss:		0.508586
  validation accuracy:		93.04 %
Epoch 1500 of 2000 took 0.035s
  training loss:		0.007441
  validation loss:		0.506118
  validation accuracy:		93.04 %
Epoch 1501 of 2000 took 0.035s
  training loss:		0.007413
  validation loss:		0.509007
  validation accuracy:		92.83 %
Epoch 1502 of 2000 took 0.035s
  training loss:		0.007604
  validation loss:		0.502373
  validation accuracy:		93.04 %
Epoch 1503 of 2000 took 0.035s
  training loss:		0.007664
  validation loss:		0.512926
  validation accuracy:		92.93 %
Epoch 1504 of 2000 took 0.035s
  training loss:		0.007545
  validation loss:		0.503543
  validation accuracy:		93.04 %
Epoch 1505 of 2000 took 0.036s
  training loss:		0.007570
  validation loss:		0.504283
  validation accuracy:		92.93 %
Epoch 1506 of 2000 took 0.035s
  training loss:		0.007419
  validation loss:		0.504169
  validation accuracy:		93.04 %
Epoch 1507 of 2000 took 0.035s
  training loss:		0.007574
  validation loss:		0.511183
  validation accuracy:		93.04 %
Epoch 1508 of 2000 took 0.035s
  training loss:		0.007271
  validation loss:		0.510768
  validation accuracy:		93.15 %
Epoch 1509 of 2000 took 0.035s
  training loss:		0.007268
  validation loss:		0.508179
  validation accuracy:		92.93 %
Epoch 1510 of 2000 took 0.035s
  training loss:		0.007265
  validation loss:		0.508293
  validation accuracy:		93.04 %
Epoch 1511 of 2000 took 0.035s
  training loss:		0.007536
  validation loss:		0.518337
  validation accuracy:		92.39 %
Epoch 1512 of 2000 took 0.035s
  training loss:		0.007691
  validation loss:		0.512066
  validation accuracy:		93.04 %
Epoch 1513 of 2000 took 0.035s
  training loss:		0.007375
  validation loss:		0.519295
  validation accuracy:		92.83 %
Epoch 1514 of 2000 took 0.035s
  training loss:		0.007394
  validation loss:		0.513655
  validation accuracy:		92.93 %
Epoch 1515 of 2000 took 0.035s
  training loss:		0.007358
  validation loss:		0.513189
  validation accuracy:		93.04 %
Epoch 1516 of 2000 took 0.036s
  training loss:		0.007134
  validation loss:		0.498238
  validation accuracy:		93.48 %
Epoch 1517 of 2000 took 0.036s
  training loss:		0.007354
  validation loss:		0.521711
  validation accuracy:		92.83 %
Epoch 1518 of 2000 took 0.035s
  training loss:		0.007236
  validation loss:		0.516417
  validation accuracy:		92.93 %
Epoch 1519 of 2000 took 0.035s
  training loss:		0.007123
  validation loss:		0.529059
  validation accuracy:		92.50 %
Epoch 1520 of 2000 took 0.035s
  training loss:		0.007521
  validation loss:		0.510390
  validation accuracy:		93.04 %
Epoch 1521 of 2000 took 0.035s
  training loss:		0.007442
  validation loss:		0.509792
  validation accuracy:		93.04 %
Epoch 1522 of 2000 took 0.035s
  training loss:		0.007225
  validation loss:		0.525058
  validation accuracy:		92.83 %
Epoch 1523 of 2000 took 0.035s
  training loss:		0.007108
  validation loss:		0.511235
  validation accuracy:		92.83 %
Epoch 1524 of 2000 took 0.035s
  training loss:		0.007332
  validation loss:		0.519980
  validation accuracy:		92.61 %
Epoch 1525 of 2000 took 0.035s
  training loss:		0.007207
  validation loss:		0.511659
  validation accuracy:		92.61 %
Epoch 1526 of 2000 took 0.035s
  training loss:		0.007027
  validation loss:		0.508018
  validation accuracy:		92.93 %
Epoch 1527 of 2000 took 0.035s
  training loss:		0.007361
  validation loss:		0.511158
  validation accuracy:		92.93 %
Epoch 1528 of 2000 took 0.035s
  training loss:		0.007435
  validation loss:		0.514118
  validation accuracy:		93.04 %
Epoch 1529 of 2000 took 0.035s
  training loss:		0.007241
  validation loss:		0.507002
  validation accuracy:		92.93 %
Epoch 1530 of 2000 took 0.035s
  training loss:		0.007318
  validation loss:		0.517519
  validation accuracy:		92.83 %
Epoch 1531 of 2000 took 0.035s
  training loss:		0.007133
  validation loss:		0.526745
  validation accuracy:		92.72 %
Epoch 1532 of 2000 took 0.035s
  training loss:		0.007280
  validation loss:		0.519475
  validation accuracy:		92.83 %
Epoch 1533 of 2000 took 0.035s
  training loss:		0.007200
  validation loss:		0.516970
  validation accuracy:		93.04 %
Epoch 1534 of 2000 took 0.035s
  training loss:		0.006901
  validation loss:		0.517891
  validation accuracy:		93.04 %
Epoch 1535 of 2000 took 0.035s
  training loss:		0.007225
  validation loss:		0.516809
  validation accuracy:		92.93 %
Epoch 1536 of 2000 took 0.035s
  training loss:		0.006926
  validation loss:		0.517400
  validation accuracy:		92.61 %
Epoch 1537 of 2000 took 0.036s
  training loss:		0.006827
  validation loss:		0.513715
  validation accuracy:		93.04 %
Epoch 1538 of 2000 took 0.035s
  training loss:		0.007345
  validation loss:		0.510938
  validation accuracy:		93.04 %
Epoch 1539 of 2000 took 0.035s
  training loss:		0.006861
  validation loss:		0.514998
  validation accuracy:		92.83 %
Epoch 1540 of 2000 took 0.035s
  training loss:		0.007314
  validation loss:		0.522132
  validation accuracy:		92.72 %
Epoch 1541 of 2000 took 0.035s
  training loss:		0.006972
  validation loss:		0.524650
  validation accuracy:		92.50 %
Epoch 1542 of 2000 took 0.035s
  training loss:		0.007234
  validation loss:		0.517171
  validation accuracy:		93.15 %
Epoch 1543 of 2000 took 0.035s
  training loss:		0.007004
  validation loss:		0.523580
  validation accuracy:		92.72 %
Epoch 1544 of 2000 took 0.035s
  training loss:		0.006941
  validation loss:		0.517336
  validation accuracy:		93.04 %
Epoch 1545 of 2000 took 0.035s
  training loss:		0.006847
  validation loss:		0.513475
  validation accuracy:		93.15 %
Epoch 1546 of 2000 took 0.035s
  training loss:		0.007205
  validation loss:		0.506654
  validation accuracy:		93.15 %
Epoch 1547 of 2000 took 0.035s
  training loss:		0.006832
  validation loss:		0.522160
  validation accuracy:		92.72 %
Epoch 1548 of 2000 took 0.035s
  training loss:		0.006826
  validation loss:		0.521302
  validation accuracy:		92.61 %
Epoch 1549 of 2000 took 0.035s
  training loss:		0.006965
  validation loss:		0.515403
  validation accuracy:		93.04 %
Epoch 1550 of 2000 took 0.035s
  training loss:		0.006831
  validation loss:		0.516557
  validation accuracy:		93.04 %
Epoch 1551 of 2000 took 0.035s
  training loss:		0.006948
  validation loss:		0.519540
  validation accuracy:		93.04 %
Epoch 1552 of 2000 took 0.035s
  training loss:		0.006753
  validation loss:		0.513375
  validation accuracy:		93.37 %
Epoch 1553 of 2000 took 0.035s
  training loss:		0.006891
  validation loss:		0.523701
  validation accuracy:		92.93 %
Epoch 1554 of 2000 took 0.035s
  training loss:		0.006873
  validation loss:		0.510905
  validation accuracy:		93.15 %
Epoch 1555 of 2000 took 0.035s
  training loss:		0.006939
  validation loss:		0.518448
  validation accuracy:		92.93 %
Epoch 1556 of 2000 took 0.035s
  training loss:		0.006601
  validation loss:		0.516558
  validation accuracy:		93.04 %
Epoch 1557 of 2000 took 0.035s
  training loss:		0.006952
  validation loss:		0.518731
  validation accuracy:		93.15 %
Epoch 1558 of 2000 took 0.035s
  training loss:		0.006662
  validation loss:		0.512915
  validation accuracy:		92.93 %
Epoch 1559 of 2000 took 0.035s
  training loss:		0.006588
  validation loss:		0.522623
  validation accuracy:		92.83 %
Epoch 1560 of 2000 took 0.035s
  training loss:		0.006611
  validation loss:		0.514899
  validation accuracy:		93.04 %
Epoch 1561 of 2000 took 0.035s
  training loss:		0.006725
  validation loss:		0.520468
  validation accuracy:		93.15 %
Epoch 1562 of 2000 took 0.035s
  training loss:		0.006693
  validation loss:		0.519051
  validation accuracy:		93.04 %
Epoch 1563 of 2000 took 0.036s
  training loss:		0.006892
  validation loss:		0.523168
  validation accuracy:		92.93 %
Epoch 1564 of 2000 took 0.035s
  training loss:		0.006788
  validation loss:		0.521062
  validation accuracy:		92.72 %
Epoch 1565 of 2000 took 0.035s
  training loss:		0.006635
  validation loss:		0.521820
  validation accuracy:		93.04 %
Epoch 1566 of 2000 took 0.035s
  training loss:		0.006893
  validation loss:		0.520343
  validation accuracy:		93.04 %
Epoch 1567 of 2000 took 0.035s
  training loss:		0.006634
  validation loss:		0.519753
  validation accuracy:		92.93 %
Epoch 1568 of 2000 took 0.035s
  training loss:		0.006742
  validation loss:		0.530333
  validation accuracy:		92.72 %
Epoch 1569 of 2000 took 0.035s
  training loss:		0.006921
  validation loss:		0.524603
  validation accuracy:		92.93 %
Epoch 1570 of 2000 took 0.035s
  training loss:		0.006617
  validation loss:		0.527691
  validation accuracy:		92.72 %
Epoch 1571 of 2000 took 0.035s
  training loss:		0.006763
  validation loss:		0.526832
  validation accuracy:		93.04 %
Epoch 1572 of 2000 took 0.036s
  training loss:		0.006839
  validation loss:		0.524172
  validation accuracy:		93.04 %
Epoch 1573 of 2000 took 0.035s
  training loss:		0.006586
  validation loss:		0.519563
  validation accuracy:		92.83 %
Epoch 1574 of 2000 took 0.035s
  training loss:		0.006551
  validation loss:		0.528405
  validation accuracy:		92.61 %
Epoch 1575 of 2000 took 0.035s
  training loss:		0.006589
  validation loss:		0.523098
  validation accuracy:		92.83 %
Epoch 1576 of 2000 took 0.035s
  training loss:		0.006455
  validation loss:		0.523828
  validation accuracy:		92.93 %
Epoch 1577 of 2000 took 0.035s
  training loss:		0.006585
  validation loss:		0.529918
  validation accuracy:		93.04 %
Epoch 1578 of 2000 took 0.035s
  training loss:		0.006432
  validation loss:		0.523991
  validation accuracy:		92.83 %
Epoch 1579 of 2000 took 0.035s
  training loss:		0.006585
  validation loss:		0.527185
  validation accuracy:		92.61 %
Epoch 1580 of 2000 took 0.035s
  training loss:		0.006302
  validation loss:		0.525832
  validation accuracy:		92.93 %
Epoch 1581 of 2000 took 0.035s
  training loss:		0.006540
  validation loss:		0.532914
  validation accuracy:		92.61 %
Epoch 1582 of 2000 took 0.035s
  training loss:		0.006538
  validation loss:		0.522654
  validation accuracy:		93.15 %
Epoch 1583 of 2000 took 0.035s
  training loss:		0.006513
  validation loss:		0.528071
  validation accuracy:		92.93 %
Epoch 1584 of 2000 took 0.035s
  training loss:		0.006426
  validation loss:		0.527196
  validation accuracy:		92.93 %
Epoch 1585 of 2000 took 0.035s
  training loss:		0.006432
  validation loss:		0.529414
  validation accuracy:		93.04 %
Epoch 1586 of 2000 took 0.035s
  training loss:		0.006567
  validation loss:		0.519288
  validation accuracy:		93.26 %
Epoch 1587 of 2000 took 0.035s
  training loss:		0.006676
  validation loss:		0.529438
  validation accuracy:		93.04 %
Epoch 1588 of 2000 took 0.035s
  training loss:		0.006395
  validation loss:		0.524473
  validation accuracy:		92.93 %
Epoch 1589 of 2000 took 0.035s
  training loss:		0.006260
  validation loss:		0.523706
  validation accuracy:		92.93 %
Epoch 1590 of 2000 took 0.035s
  training loss:		0.006461
  validation loss:		0.520336
  validation accuracy:		93.15 %
Epoch 1591 of 2000 took 0.035s
  training loss:		0.006746
  validation loss:		0.523760
  validation accuracy:		92.93 %
Epoch 1592 of 2000 took 0.035s
  training loss:		0.006404
  validation loss:		0.520610
  validation accuracy:		93.15 %
Epoch 1593 of 2000 took 0.036s
  training loss:		0.006318
  validation loss:		0.538984
  validation accuracy:		92.50 %
Epoch 1594 of 2000 took 0.035s
  training loss:		0.006549
  validation loss:		0.531193
  validation accuracy:		92.93 %
Epoch 1595 of 2000 took 0.035s
  training loss:		0.006505
  validation loss:		0.522820
  validation accuracy:		93.04 %
Epoch 1596 of 2000 took 0.035s
  training loss:		0.006307
  validation loss:		0.520794
  validation accuracy:		93.15 %
Epoch 1597 of 2000 took 0.035s
  training loss:		0.006223
  validation loss:		0.532403
  validation accuracy:		93.15 %
Epoch 1598 of 2000 took 0.035s
  training loss:		0.006434
  validation loss:		0.530196
  validation accuracy:		93.04 %
Epoch 1599 of 2000 took 0.035s
  training loss:		0.006075
  validation loss:		0.532997
  validation accuracy:		93.15 %
Epoch 1600 of 2000 took 0.035s
  training loss:		0.006254
  validation loss:		0.531453
  validation accuracy:		92.93 %
Epoch 1601 of 2000 took 0.036s
  training loss:		0.006355
  validation loss:		0.538413
  validation accuracy:		92.50 %
Epoch 1602 of 2000 took 0.035s
  training loss:		0.006142
  validation loss:		0.524102
  validation accuracy:		92.93 %
Epoch 1603 of 2000 took 0.035s
  training loss:		0.006550
  validation loss:		0.529678
  validation accuracy:		92.83 %
Epoch 1604 of 2000 took 0.035s
  training loss:		0.006300
  validation loss:		0.529809
  validation accuracy:		93.04 %
Epoch 1605 of 2000 took 0.036s
  training loss:		0.006327
  validation loss:		0.528538
  validation accuracy:		93.04 %
Epoch 1606 of 2000 took 0.036s
  training loss:		0.006088
  validation loss:		0.526555
  validation accuracy:		93.04 %
Epoch 1607 of 2000 took 0.037s
  training loss:		0.006330
  validation loss:		0.538906
  validation accuracy:		93.04 %
Epoch 1608 of 2000 took 0.037s
  training loss:		0.006337
  validation loss:		0.525140
  validation accuracy:		93.04 %
Epoch 1609 of 2000 took 0.037s
  training loss:		0.006169
  validation loss:		0.531561
  validation accuracy:		93.04 %
Epoch 1610 of 2000 took 0.036s
  training loss:		0.006250
  validation loss:		0.537024
  validation accuracy:		93.04 %
Epoch 1611 of 2000 took 0.037s
  training loss:		0.006226
  validation loss:		0.531308
  validation accuracy:		93.04 %
Epoch 1612 of 2000 took 0.037s
  training loss:		0.006366
  validation loss:		0.533944
  validation accuracy:		93.15 %
Epoch 1613 of 2000 took 0.037s
  training loss:		0.006142
  validation loss:		0.534661
  validation accuracy:		93.04 %
Epoch 1614 of 2000 took 0.037s
  training loss:		0.005891
  validation loss:		0.524719
  validation accuracy:		93.04 %
Epoch 1615 of 2000 took 0.037s
  training loss:		0.006292
  validation loss:		0.525574
  validation accuracy:		92.93 %
Epoch 1616 of 2000 took 0.036s
  training loss:		0.006149
  validation loss:		0.529881
  validation accuracy:		92.93 %
Epoch 1617 of 2000 took 0.037s
  training loss:		0.006140
  validation loss:		0.528087
  validation accuracy:		93.04 %
Epoch 1618 of 2000 took 0.037s
  training loss:		0.006221
  validation loss:		0.541166
  validation accuracy:		92.83 %
Epoch 1619 of 2000 took 0.037s
  training loss:		0.006166
  validation loss:		0.530338
  validation accuracy:		92.83 %
Epoch 1620 of 2000 took 0.037s
  training loss:		0.006056
  validation loss:		0.540794
  validation accuracy:		92.93 %
Epoch 1621 of 2000 took 0.036s
  training loss:		0.006073
  validation loss:		0.541863
  validation accuracy:		92.93 %
Epoch 1622 of 2000 took 0.036s
  training loss:		0.006084
  validation loss:		0.535481
  validation accuracy:		92.72 %
Epoch 1623 of 2000 took 0.036s
  training loss:		0.006243
  validation loss:		0.532572
  validation accuracy:		93.04 %
Epoch 1624 of 2000 took 0.036s
  training loss:		0.006027
  validation loss:		0.528262
  validation accuracy:		92.93 %
Epoch 1625 of 2000 took 0.036s
  training loss:		0.006201
  validation loss:		0.530945
  validation accuracy:		93.04 %
Epoch 1626 of 2000 took 0.036s
  training loss:		0.006030
  validation loss:		0.532516
  validation accuracy:		93.26 %
Epoch 1627 of 2000 took 0.036s
  training loss:		0.005934
  validation loss:		0.525585
  validation accuracy:		93.15 %
Epoch 1628 of 2000 took 0.036s
  training loss:		0.006148
  validation loss:		0.544962
  validation accuracy:		92.72 %
Epoch 1629 of 2000 took 0.036s
  training loss:		0.006127
  validation loss:		0.532027
  validation accuracy:		93.15 %
Epoch 1630 of 2000 took 0.036s
  training loss:		0.005880
  validation loss:		0.532893
  validation accuracy:		93.04 %
Epoch 1631 of 2000 took 0.036s
  training loss:		0.005946
  validation loss:		0.538981
  validation accuracy:		93.15 %
Epoch 1632 of 2000 took 0.036s
  training loss:		0.006006
  validation loss:		0.532742
  validation accuracy:		93.15 %
Epoch 1633 of 2000 took 0.036s
  training loss:		0.005859
  validation loss:		0.530993
  validation accuracy:		93.04 %
Epoch 1634 of 2000 took 0.036s
  training loss:		0.005958
  validation loss:		0.534268
  validation accuracy:		92.83 %
Epoch 1635 of 2000 took 0.036s
  training loss:		0.006068
  validation loss:		0.527499
  validation accuracy:		92.93 %
Epoch 1636 of 2000 took 0.036s
  training loss:		0.006136
  validation loss:		0.533466
  validation accuracy:		93.15 %
Epoch 1637 of 2000 took 0.036s
  training loss:		0.006030
  validation loss:		0.533316
  validation accuracy:		93.04 %
Epoch 1638 of 2000 took 0.036s
  training loss:		0.006286
  validation loss:		0.534569
  validation accuracy:		92.83 %
Epoch 1639 of 2000 took 0.036s
  training loss:		0.005976
  validation loss:		0.540678
  validation accuracy:		92.72 %
Epoch 1640 of 2000 took 0.036s
  training loss:		0.006010
  validation loss:		0.538356
  validation accuracy:		93.15 %
Epoch 1641 of 2000 took 0.036s
  training loss:		0.005931
  validation loss:		0.536539
  validation accuracy:		93.04 %
Epoch 1642 of 2000 took 0.036s
  training loss:		0.005939
  validation loss:		0.540094
  validation accuracy:		93.04 %
Epoch 1643 of 2000 took 0.036s
  training loss:		0.006038
  validation loss:		0.541816
  validation accuracy:		93.04 %
Epoch 1644 of 2000 took 0.036s
  training loss:		0.005915
  validation loss:		0.532074
  validation accuracy:		92.93 %
Epoch 1645 of 2000 took 0.036s
  training loss:		0.005872
  validation loss:		0.547346
  validation accuracy:		92.93 %
Epoch 1646 of 2000 took 0.036s
  training loss:		0.005915
  validation loss:		0.542566
  validation accuracy:		92.72 %
Epoch 1647 of 2000 took 0.036s
  training loss:		0.006006
  validation loss:		0.542919
  validation accuracy:		92.93 %
Epoch 1648 of 2000 took 0.036s
  training loss:		0.005793
  validation loss:		0.536793
  validation accuracy:		93.04 %
Epoch 1649 of 2000 took 0.036s
  training loss:		0.005910
  validation loss:		0.537050
  validation accuracy:		93.15 %
Epoch 1650 of 2000 took 0.035s
  training loss:		0.005936
  validation loss:		0.538378
  validation accuracy:		93.15 %
Epoch 1651 of 2000 took 0.035s
  training loss:		0.005870
  validation loss:		0.538837
  validation accuracy:		93.04 %
Epoch 1652 of 2000 took 0.035s
  training loss:		0.005865
  validation loss:		0.543321
  validation accuracy:		92.72 %
Epoch 1653 of 2000 took 0.035s
  training loss:		0.005761
  validation loss:		0.540455
  validation accuracy:		92.93 %
Epoch 1654 of 2000 took 0.035s
  training loss:		0.005995
  validation loss:		0.539952
  validation accuracy:		92.93 %
Epoch 1655 of 2000 took 0.035s
  training loss:		0.006050
  validation loss:		0.537191
  validation accuracy:		92.93 %
Epoch 1656 of 2000 took 0.035s
  training loss:		0.005608
  validation loss:		0.534694
  validation accuracy:		92.93 %
Epoch 1657 of 2000 took 0.035s
  training loss:		0.005863
  validation loss:		0.542630
  validation accuracy:		93.04 %
Epoch 1658 of 2000 took 0.035s
  training loss:		0.005631
  validation loss:		0.548163
  validation accuracy:		93.15 %
Epoch 1659 of 2000 took 0.035s
  training loss:		0.005942
  validation loss:		0.540245
  validation accuracy:		93.04 %
Epoch 1660 of 2000 took 0.035s
  training loss:		0.005775
  validation loss:		0.537881
  validation accuracy:		93.26 %
Epoch 1661 of 2000 took 0.035s
  training loss:		0.006019
  validation loss:		0.544109
  validation accuracy:		93.15 %
Epoch 1662 of 2000 took 0.035s
  training loss:		0.005745
  validation loss:		0.544542
  validation accuracy:		93.15 %
Epoch 1663 of 2000 took 0.035s
  training loss:		0.005650
  validation loss:		0.546100
  validation accuracy:		92.83 %
Epoch 1664 of 2000 took 0.035s
  training loss:		0.006057
  validation loss:		0.543383
  validation accuracy:		92.93 %
Epoch 1665 of 2000 took 0.036s
  training loss:		0.005805
  validation loss:		0.552043
  validation accuracy:		93.04 %
Epoch 1666 of 2000 took 0.035s
  training loss:		0.005694
  validation loss:		0.533747
  validation accuracy:		93.04 %
Epoch 1667 of 2000 took 0.035s
  training loss:		0.005886
  validation loss:		0.553279
  validation accuracy:		92.61 %
Epoch 1668 of 2000 took 0.035s
  training loss:		0.005668
  validation loss:		0.548787
  validation accuracy:		92.93 %
Epoch 1669 of 2000 took 0.035s
  training loss:		0.005689
  validation loss:		0.544610
  validation accuracy:		92.83 %
Epoch 1670 of 2000 took 0.035s
  training loss:		0.005674
  validation loss:		0.536155
  validation accuracy:		93.04 %
Epoch 1671 of 2000 took 0.035s
  training loss:		0.005518
  validation loss:		0.543782
  validation accuracy:		92.93 %
Epoch 1672 of 2000 took 0.035s
  training loss:		0.005664
  validation loss:		0.551201
  validation accuracy:		92.83 %
Epoch 1673 of 2000 took 0.036s
  training loss:		0.005648
  validation loss:		0.544286
  validation accuracy:		93.04 %
Epoch 1674 of 2000 took 0.035s
  training loss:		0.005776
  validation loss:		0.542000
  validation accuracy:		92.93 %
Epoch 1675 of 2000 took 0.035s
  training loss:		0.005606
  validation loss:		0.547182
  validation accuracy:		92.93 %
Epoch 1676 of 2000 took 0.035s
  training loss:		0.005687
  validation loss:		0.550688
  validation accuracy:		92.93 %
Epoch 1677 of 2000 took 0.035s
  training loss:		0.005524
  validation loss:		0.548118
  validation accuracy:		93.04 %
Epoch 1678 of 2000 took 0.035s
  training loss:		0.005516
  validation loss:		0.543403
  validation accuracy:		93.04 %
Epoch 1679 of 2000 took 0.035s
  training loss:		0.005458
  validation loss:		0.544513
  validation accuracy:		92.93 %
Epoch 1680 of 2000 took 0.035s
  training loss:		0.005483
  validation loss:		0.549890
  validation accuracy:		92.50 %
Epoch 1681 of 2000 took 0.035s
  training loss:		0.005300
  validation loss:		0.535356
  validation accuracy:		93.04 %
Epoch 1682 of 2000 took 0.035s
  training loss:		0.005545
  validation loss:		0.547330
  validation accuracy:		92.83 %
Epoch 1683 of 2000 took 0.035s
  training loss:		0.005572
  validation loss:		0.549856
  validation accuracy:		92.72 %
Epoch 1684 of 2000 took 0.036s
  training loss:		0.005689
  validation loss:		0.542718
  validation accuracy:		93.15 %
Epoch 1685 of 2000 took 0.035s
  training loss:		0.005631
  validation loss:		0.546054
  validation accuracy:		93.04 %
Epoch 1686 of 2000 took 0.035s
  training loss:		0.005518
  validation loss:		0.550372
  validation accuracy:		93.04 %
Epoch 1687 of 2000 took 0.035s
  training loss:		0.005549
  validation loss:		0.544471
  validation accuracy:		93.04 %
Epoch 1688 of 2000 took 0.035s
  training loss:		0.005521
  validation loss:		0.552215
  validation accuracy:		93.04 %
Epoch 1689 of 2000 took 0.035s
  training loss:		0.005564
  validation loss:		0.551543
  validation accuracy:		93.04 %
Epoch 1690 of 2000 took 0.035s
  training loss:		0.005398
  validation loss:		0.542028
  validation accuracy:		93.04 %
Epoch 1691 of 2000 took 0.035s
  training loss:		0.005493
  validation loss:		0.558404
  validation accuracy:		92.72 %
Epoch 1692 of 2000 took 0.035s
  training loss:		0.005415
  validation loss:		0.543387
  validation accuracy:		92.93 %
Epoch 1693 of 2000 took 0.035s
  training loss:		0.005400
  validation loss:		0.540295
  validation accuracy:		92.93 %
Epoch 1694 of 2000 took 0.035s
  training loss:		0.005499
  validation loss:		0.554116
  validation accuracy:		92.93 %
Epoch 1695 of 2000 took 0.035s
  training loss:		0.005470
  validation loss:		0.553850
  validation accuracy:		93.15 %
Epoch 1696 of 2000 took 0.035s
  training loss:		0.005634
  validation loss:		0.549660
  validation accuracy:		92.93 %
Epoch 1697 of 2000 took 0.035s
  training loss:		0.005474
  validation loss:		0.552379
  validation accuracy:		93.04 %
Epoch 1698 of 2000 took 0.035s
  training loss:		0.005316
  validation loss:		0.540965
  validation accuracy:		93.15 %
Epoch 1699 of 2000 took 0.035s
  training loss:		0.005516
  validation loss:		0.544505
  validation accuracy:		93.04 %
Epoch 1700 of 2000 took 0.035s
  training loss:		0.005475
  validation loss:		0.550946
  validation accuracy:		92.93 %
Epoch 1701 of 2000 took 0.035s
  training loss:		0.005471
  validation loss:		0.546713
  validation accuracy:		93.04 %
Epoch 1702 of 2000 took 0.035s
  training loss:		0.005376
  validation loss:		0.555930
  validation accuracy:		93.04 %
Epoch 1703 of 2000 took 0.035s
  training loss:		0.005584
  validation loss:		0.555847
  validation accuracy:		93.15 %
Epoch 1704 of 2000 took 0.035s
  training loss:		0.005396
  validation loss:		0.553283
  validation accuracy:		93.04 %
Epoch 1705 of 2000 took 0.036s
  training loss:		0.005116
  validation loss:		0.548087
  validation accuracy:		92.93 %
Epoch 1706 of 2000 took 0.035s
  training loss:		0.005295
  validation loss:		0.551668
  validation accuracy:		93.15 %
Epoch 1707 of 2000 took 0.035s
  training loss:		0.005370
  validation loss:		0.556872
  validation accuracy:		92.72 %
Epoch 1708 of 2000 took 0.035s
  training loss:		0.005247
  validation loss:		0.540615
  validation accuracy:		93.15 %
Epoch 1709 of 2000 took 0.035s
  training loss:		0.005340
  validation loss:		0.553038
  validation accuracy:		93.15 %
Epoch 1710 of 2000 took 0.035s
  training loss:		0.005511
  validation loss:		0.556970
  validation accuracy:		92.83 %
Epoch 1711 of 2000 took 0.035s
  training loss:		0.005325
  validation loss:		0.549133
  validation accuracy:		92.83 %
Epoch 1712 of 2000 took 0.035s
  training loss:		0.005276
  validation loss:		0.551206
  validation accuracy:		93.15 %
Epoch 1713 of 2000 took 0.036s
  training loss:		0.005494
  validation loss:		0.555414
  validation accuracy:		93.04 %
Epoch 1714 of 2000 took 0.035s
  training loss:		0.005338
  validation loss:		0.553967
  validation accuracy:		93.04 %
Epoch 1715 of 2000 took 0.035s
  training loss:		0.005346
  validation loss:		0.547278
  validation accuracy:		93.04 %
Epoch 1716 of 2000 took 0.035s
  training loss:		0.005407
  validation loss:		0.558819
  validation accuracy:		93.04 %
Epoch 1717 of 2000 took 0.035s
  training loss:		0.005375
  validation loss:		0.564042
  validation accuracy:		92.83 %
Epoch 1718 of 2000 took 0.036s
  training loss:		0.005197
  validation loss:		0.546256
  validation accuracy:		92.83 %
Epoch 1719 of 2000 took 0.035s
  training loss:		0.005262
  validation loss:		0.553653
  validation accuracy:		93.04 %
Epoch 1720 of 2000 took 0.035s
  training loss:		0.005275
  validation loss:		0.558018
  validation accuracy:		93.04 %
Epoch 1721 of 2000 took 0.035s
  training loss:		0.005269
  validation loss:		0.543684
  validation accuracy:		93.15 %
Epoch 1722 of 2000 took 0.035s
  training loss:		0.005343
  validation loss:		0.557678
  validation accuracy:		93.04 %
Epoch 1723 of 2000 took 0.035s
  training loss:		0.005145
  validation loss:		0.562187
  validation accuracy:		92.93 %
Epoch 1724 of 2000 took 0.035s
  training loss:		0.005224
  validation loss:		0.551270
  validation accuracy:		93.04 %
Epoch 1725 of 2000 took 0.035s
  training loss:		0.005109
  validation loss:		0.554424
  validation accuracy:		93.04 %
Epoch 1726 of 2000 took 0.035s
  training loss:		0.005194
  validation loss:		0.548480
  validation accuracy:		93.04 %
Epoch 1727 of 2000 took 0.035s
  training loss:		0.005197
  validation loss:		0.554552
  validation accuracy:		93.15 %
Epoch 1728 of 2000 took 0.035s
  training loss:		0.005356
  validation loss:		0.555881
  validation accuracy:		92.93 %
Epoch 1729 of 2000 took 0.035s
  training loss:		0.004986
  validation loss:		0.551161
  validation accuracy:		93.04 %
Epoch 1730 of 2000 took 0.036s
  training loss:		0.005211
  validation loss:		0.552415
  validation accuracy:		93.15 %
Epoch 1731 of 2000 took 0.035s
  training loss:		0.005229
  validation loss:		0.547745
  validation accuracy:		93.15 %
Epoch 1732 of 2000 took 0.036s
  training loss:		0.005158
  validation loss:		0.562845
  validation accuracy:		92.93 %
Epoch 1733 of 2000 took 0.035s
  training loss:		0.005260
  validation loss:		0.557712
  validation accuracy:		92.83 %
Epoch 1734 of 2000 took 0.035s
  training loss:		0.005341
  validation loss:		0.550394
  validation accuracy:		92.93 %
Epoch 1735 of 2000 took 0.035s
  training loss:		0.005189
  validation loss:		0.558329
  validation accuracy:		92.93 %
Epoch 1736 of 2000 took 0.036s
  training loss:		0.005059
  validation loss:		0.556073
  validation accuracy:		93.15 %
Epoch 1737 of 2000 took 0.035s
  training loss:		0.005205
  validation loss:		0.550234
  validation accuracy:		93.04 %
Epoch 1738 of 2000 took 0.035s
  training loss:		0.005169
  validation loss:		0.558074
  validation accuracy:		92.83 %
Epoch 1739 of 2000 took 0.035s
  training loss:		0.005279
  validation loss:		0.560184
  validation accuracy:		92.72 %
Epoch 1740 of 2000 took 0.035s
  training loss:		0.005239
  validation loss:		0.558591
  validation accuracy:		93.04 %
Epoch 1741 of 2000 took 0.036s
  training loss:		0.005045
  validation loss:		0.557008
  validation accuracy:		92.93 %
Epoch 1742 of 2000 took 0.035s
  training loss:		0.004882
  validation loss:		0.550772
  validation accuracy:		93.26 %
Epoch 1743 of 2000 took 0.035s
  training loss:		0.005259
  validation loss:		0.557640
  validation accuracy:		93.15 %
Epoch 1744 of 2000 took 0.035s
  training loss:		0.005153
  validation loss:		0.553494
  validation accuracy:		93.04 %
Epoch 1745 of 2000 took 0.035s
  training loss:		0.005004
  validation loss:		0.554103
  validation accuracy:		93.04 %
Epoch 1746 of 2000 took 0.036s
  training loss:		0.005143
  validation loss:		0.553885
  validation accuracy:		92.83 %
Epoch 1747 of 2000 took 0.035s
  training loss:		0.005049
  validation loss:		0.554181
  validation accuracy:		93.15 %
Epoch 1748 of 2000 took 0.035s
  training loss:		0.004853
  validation loss:		0.554077
  validation accuracy:		93.04 %
Epoch 1749 of 2000 took 0.035s
  training loss:		0.005108
  validation loss:		0.555497
  validation accuracy:		93.04 %
Epoch 1750 of 2000 took 0.035s
  training loss:		0.005057
  validation loss:		0.559002
  validation accuracy:		93.15 %
Epoch 1751 of 2000 took 0.035s
  training loss:		0.005113
  validation loss:		0.553909
  validation accuracy:		93.04 %
Epoch 1752 of 2000 took 0.035s
  training loss:		0.004967
  validation loss:		0.559616
  validation accuracy:		92.93 %
Epoch 1753 of 2000 took 0.035s
  training loss:		0.005046
  validation loss:		0.551438
  validation accuracy:		93.26 %
Epoch 1754 of 2000 took 0.035s
  training loss:		0.004903
  validation loss:		0.558936
  validation accuracy:		92.93 %
Epoch 1755 of 2000 took 0.035s
  training loss:		0.004946
  validation loss:		0.559566
  validation accuracy:		93.15 %
Epoch 1756 of 2000 took 0.035s
  training loss:		0.005137
  validation loss:		0.562015
  validation accuracy:		92.93 %
Epoch 1757 of 2000 took 0.035s
  training loss:		0.005078
  validation loss:		0.556532
  validation accuracy:		93.15 %
Epoch 1758 of 2000 took 0.035s
  training loss:		0.004753
  validation loss:		0.562360
  validation accuracy:		93.15 %
Epoch 1759 of 2000 took 0.035s
  training loss:		0.004847
  validation loss:		0.555381
  validation accuracy:		92.83 %
Epoch 1760 of 2000 took 0.035s
  training loss:		0.004816
  validation loss:		0.555192
  validation accuracy:		93.15 %
Epoch 1761 of 2000 took 0.035s
  training loss:		0.005093
  validation loss:		0.554145
  validation accuracy:		93.04 %
Epoch 1762 of 2000 took 0.036s
  training loss:		0.004697
  validation loss:		0.556915
  validation accuracy:		93.04 %
Epoch 1763 of 2000 took 0.035s
  training loss:		0.004838
  validation loss:		0.560224
  validation accuracy:		93.04 %
Epoch 1764 of 2000 took 0.035s
  training loss:		0.005205
  validation loss:		0.557707
  validation accuracy:		92.83 %
Epoch 1765 of 2000 took 0.035s
  training loss:		0.004806
  validation loss:		0.563495
  validation accuracy:		93.04 %
Epoch 1766 of 2000 took 0.035s
  training loss:		0.004961
  validation loss:		0.565108
  validation accuracy:		92.93 %
Epoch 1767 of 2000 took 0.035s
  training loss:		0.004908
  validation loss:		0.562753
  validation accuracy:		92.83 %
Epoch 1768 of 2000 took 0.035s
  training loss:		0.005013
  validation loss:		0.556921
  validation accuracy:		93.15 %
Epoch 1769 of 2000 took 0.035s
  training loss:		0.004848
  validation loss:		0.556657
  validation accuracy:		93.04 %
Epoch 1770 of 2000 took 0.035s
  training loss:		0.004721
  validation loss:		0.569372
  validation accuracy:		93.04 %
Epoch 1771 of 2000 took 0.035s
  training loss:		0.005003
  validation loss:		0.562517
  validation accuracy:		93.04 %
Epoch 1772 of 2000 took 0.035s
  training loss:		0.004968
  validation loss:		0.558647
  validation accuracy:		92.83 %
Epoch 1773 of 2000 took 0.035s
  training loss:		0.004913
  validation loss:		0.565645
  validation accuracy:		92.61 %
Epoch 1774 of 2000 took 0.035s
  training loss:		0.005082
  validation loss:		0.563847
  validation accuracy:		92.93 %
Epoch 1775 of 2000 took 0.035s
  training loss:		0.004902
  validation loss:		0.563755
  validation accuracy:		92.83 %
Epoch 1776 of 2000 took 0.036s
  training loss:		0.004969
  validation loss:		0.567676
  validation accuracy:		92.83 %
Epoch 1777 of 2000 took 0.035s
  training loss:		0.004779
  validation loss:		0.560238
  validation accuracy:		93.15 %
Epoch 1778 of 2000 took 0.035s
  training loss:		0.004944
  validation loss:		0.557516
  validation accuracy:		93.15 %
Epoch 1779 of 2000 took 0.035s
  training loss:		0.004815
  validation loss:		0.563940
  validation accuracy:		93.04 %
Epoch 1780 of 2000 took 0.035s
  training loss:		0.004978
  validation loss:		0.559340
  validation accuracy:		93.26 %
Epoch 1781 of 2000 took 0.036s
  training loss:		0.004770
  validation loss:		0.561255
  validation accuracy:		92.83 %
Epoch 1782 of 2000 took 0.035s
  training loss:		0.004782
  validation loss:		0.565602
  validation accuracy:		92.93 %
Epoch 1783 of 2000 took 0.035s
  training loss:		0.004885
  validation loss:		0.562542
  validation accuracy:		93.15 %
Epoch 1784 of 2000 took 0.035s
  training loss:		0.004740
  validation loss:		0.562693
  validation accuracy:		93.04 %
Epoch 1785 of 2000 took 0.035s
  training loss:		0.004721
  validation loss:		0.561442
  validation accuracy:		93.04 %
Epoch 1786 of 2000 took 0.035s
  training loss:		0.004737
  validation loss:		0.565603
  validation accuracy:		92.93 %
Epoch 1787 of 2000 took 0.035s
  training loss:		0.004641
  validation loss:		0.562976
  validation accuracy:		93.04 %
Epoch 1788 of 2000 took 0.035s
  training loss:		0.004951
  validation loss:		0.570294
  validation accuracy:		92.72 %
Epoch 1789 of 2000 took 0.035s
  training loss:		0.004823
  validation loss:		0.568620
  validation accuracy:		93.04 %
Epoch 1790 of 2000 took 0.035s
  training loss:		0.004750
  validation loss:		0.570358
  validation accuracy:		93.15 %
Epoch 1791 of 2000 took 0.035s
  training loss:		0.004731
  validation loss:		0.559839
  validation accuracy:		93.15 %
Epoch 1792 of 2000 took 0.035s
  training loss:		0.004728
  validation loss:		0.570301
  validation accuracy:		92.72 %
Epoch 1793 of 2000 took 0.035s
  training loss:		0.004804
  validation loss:		0.563629
  validation accuracy:		93.04 %
Epoch 1794 of 2000 took 0.035s
  training loss:		0.004621
  validation loss:		0.564450
  validation accuracy:		93.15 %
Epoch 1795 of 2000 took 0.035s
  training loss:		0.004659
  validation loss:		0.575386
  validation accuracy:		92.83 %
Epoch 1796 of 2000 took 0.035s
  training loss:		0.004666
  validation loss:		0.555742
  validation accuracy:		93.04 %
Epoch 1797 of 2000 took 0.035s
  training loss:		0.004880
  validation loss:		0.559494
  validation accuracy:		93.15 %
Epoch 1798 of 2000 took 0.035s
  training loss:		0.004910
  validation loss:		0.572144
  validation accuracy:		92.83 %
Epoch 1799 of 2000 took 0.035s
  training loss:		0.004710
  validation loss:		0.566458
  validation accuracy:		93.04 %
Epoch 1800 of 2000 took 0.035s
  training loss:		0.004796
  validation loss:		0.566437
  validation accuracy:		92.83 %
Epoch 1801 of 2000 took 0.035s
  training loss:		0.004831
  validation loss:		0.566303
  validation accuracy:		93.04 %
Epoch 1802 of 2000 took 0.035s
  training loss:		0.004526
  validation loss:		0.563504
  validation accuracy:		93.15 %
Epoch 1803 of 2000 took 0.035s
  training loss:		0.004627
  validation loss:		0.567440
  validation accuracy:		93.04 %
Epoch 1804 of 2000 took 0.035s
  training loss:		0.004626
  validation loss:		0.561666
  validation accuracy:		92.93 %
Epoch 1805 of 2000 took 0.035s
  training loss:		0.004659
  validation loss:		0.572195
  validation accuracy:		92.93 %
Epoch 1806 of 2000 took 0.035s
  training loss:		0.004672
  validation loss:		0.578551
  validation accuracy:		92.93 %
Epoch 1807 of 2000 took 0.035s
  training loss:		0.004595
  validation loss:		0.571070
  validation accuracy:		93.04 %
Epoch 1808 of 2000 took 0.035s
  training loss:		0.004553
  validation loss:		0.564645
  validation accuracy:		93.04 %
Epoch 1809 of 2000 took 0.035s
  training loss:		0.004589
  validation loss:		0.564644
  validation accuracy:		93.26 %
Epoch 1810 of 2000 took 0.035s
  training loss:		0.004759
  validation loss:		0.575973
  validation accuracy:		93.04 %
Epoch 1811 of 2000 took 0.035s
  training loss:		0.004719
  validation loss:		0.575401
  validation accuracy:		93.04 %
Epoch 1812 of 2000 took 0.035s
  training loss:		0.004692
  validation loss:		0.566641
  validation accuracy:		93.04 %
Epoch 1813 of 2000 took 0.035s
  training loss:		0.004478
  validation loss:		0.569343
  validation accuracy:		93.04 %
Epoch 1814 of 2000 took 0.035s
  training loss:		0.004638
  validation loss:		0.576295
  validation accuracy:		93.15 %
Epoch 1815 of 2000 took 0.035s
  training loss:		0.004437
  validation loss:		0.575468
  validation accuracy:		92.93 %
Epoch 1816 of 2000 took 0.035s
  training loss:		0.004579
  validation loss:		0.567237
  validation accuracy:		92.93 %
Epoch 1817 of 2000 took 0.035s
  training loss:		0.004487
  validation loss:		0.573254
  validation accuracy:		93.15 %
Epoch 1818 of 2000 took 0.035s
  training loss:		0.004606
  validation loss:		0.566304
  validation accuracy:		93.04 %
Epoch 1819 of 2000 took 0.035s
  training loss:		0.004436
  validation loss:		0.568760
  validation accuracy:		93.15 %
Epoch 1820 of 2000 took 0.035s
  training loss:		0.004506
  validation loss:		0.565814
  validation accuracy:		93.04 %
Epoch 1821 of 2000 took 0.035s
  training loss:		0.004519
  validation loss:		0.572084
  validation accuracy:		92.93 %
Epoch 1822 of 2000 took 0.035s
  training loss:		0.004637
  validation loss:		0.569306
  validation accuracy:		93.15 %
Epoch 1823 of 2000 took 0.035s
  training loss:		0.004491
  validation loss:		0.562056
  validation accuracy:		93.15 %
Epoch 1824 of 2000 took 0.035s
  training loss:		0.004414
  validation loss:		0.580016
  validation accuracy:		92.93 %
Epoch 1825 of 2000 took 0.035s
  training loss:		0.004548
  validation loss:		0.568738
  validation accuracy:		93.15 %
Epoch 1826 of 2000 took 0.036s
  training loss:		0.004513
  validation loss:		0.568957
  validation accuracy:		93.04 %
Epoch 1827 of 2000 took 0.035s
  training loss:		0.004551
  validation loss:		0.574061
  validation accuracy:		93.04 %
Epoch 1828 of 2000 took 0.035s
  training loss:		0.004563
  validation loss:		0.574534
  validation accuracy:		93.15 %
Epoch 1829 of 2000 took 0.035s
  training loss:		0.004552
  validation loss:		0.571527
  validation accuracy:		93.04 %
Epoch 1830 of 2000 took 0.035s
  training loss:		0.004533
  validation loss:		0.571199
  validation accuracy:		92.72 %
Epoch 1831 of 2000 took 0.036s
  training loss:		0.004562
  validation loss:		0.566753
  validation accuracy:		93.26 %
Epoch 1832 of 2000 took 0.035s
  training loss:		0.004628
  validation loss:		0.569522
  validation accuracy:		93.15 %
Epoch 1833 of 2000 took 0.035s
  training loss:		0.004628
  validation loss:		0.578943
  validation accuracy:		92.93 %
Epoch 1834 of 2000 took 0.035s
  training loss:		0.004533
  validation loss:		0.574477
  validation accuracy:		93.15 %
Epoch 1835 of 2000 took 0.035s
  training loss:		0.004561
  validation loss:		0.574261
  validation accuracy:		92.93 %
Epoch 1836 of 2000 took 0.035s
  training loss:		0.004374
  validation loss:		0.570194
  validation accuracy:		92.93 %
Epoch 1837 of 2000 took 0.035s
  training loss:		0.004600
  validation loss:		0.574350
  validation accuracy:		93.15 %
Epoch 1838 of 2000 took 0.035s
  training loss:		0.004472
  validation loss:		0.571281
  validation accuracy:		93.04 %
Epoch 1839 of 2000 took 0.035s
  training loss:		0.004474
  validation loss:		0.569721
  validation accuracy:		92.93 %
Epoch 1840 of 2000 took 0.035s
  training loss:		0.004501
  validation loss:		0.572998
  validation accuracy:		93.15 %
Epoch 1841 of 2000 took 0.035s
  training loss:		0.004502
  validation loss:		0.567898
  validation accuracy:		93.04 %
Epoch 1842 of 2000 took 0.035s
  training loss:		0.004317
  validation loss:		0.579119
  validation accuracy:		92.83 %
Epoch 1843 of 2000 took 0.036s
  training loss:		0.004483
  validation loss:		0.570187
  validation accuracy:		93.15 %
Epoch 1844 of 2000 took 0.035s
  training loss:		0.004337
  validation loss:		0.567094
  validation accuracy:		93.26 %
Epoch 1845 of 2000 took 0.035s
  training loss:		0.004486
  validation loss:		0.572968
  validation accuracy:		93.15 %
Epoch 1846 of 2000 took 0.035s
  training loss:		0.004347
  validation loss:		0.572331
  validation accuracy:		93.04 %
Epoch 1847 of 2000 took 0.035s
  training loss:		0.004396
  validation loss:		0.581094
  validation accuracy:		93.04 %
Epoch 1848 of 2000 took 0.035s
  training loss:		0.004567
  validation loss:		0.579009
  validation accuracy:		92.72 %
Epoch 1849 of 2000 took 0.035s
  training loss:		0.004476
  validation loss:		0.571799
  validation accuracy:		93.15 %
Epoch 1850 of 2000 took 0.035s
  training loss:		0.004427
  validation loss:		0.580507
  validation accuracy:		93.04 %
Epoch 1851 of 2000 took 0.035s
  training loss:		0.004375
  validation loss:		0.576982
  validation accuracy:		93.04 %
Epoch 1852 of 2000 took 0.035s
  training loss:		0.004572
  validation loss:		0.576218
  validation accuracy:		93.15 %
Epoch 1853 of 2000 took 0.035s
  training loss:		0.004434
  validation loss:		0.573671
  validation accuracy:		93.04 %
Epoch 1854 of 2000 took 0.036s
  training loss:		0.004383
  validation loss:		0.577462
  validation accuracy:		92.83 %
Epoch 1855 of 2000 took 0.035s
  training loss:		0.004490
  validation loss:		0.574975
  validation accuracy:		93.15 %
Epoch 1856 of 2000 took 0.035s
  training loss:		0.004349
  validation loss:		0.585109
  validation accuracy:		92.93 %
Epoch 1857 of 2000 took 0.035s
  training loss:		0.004468
  validation loss:		0.573977
  validation accuracy:		93.26 %
Epoch 1858 of 2000 took 0.035s
  training loss:		0.004304
  validation loss:		0.575933
  validation accuracy:		93.15 %
Epoch 1859 of 2000 took 0.035s
  training loss:		0.004325
  validation loss:		0.580535
  validation accuracy:		93.04 %
Epoch 1860 of 2000 took 0.035s
  training loss:		0.004208
  validation loss:		0.577994
  validation accuracy:		92.93 %
Epoch 1861 of 2000 took 0.035s
  training loss:		0.004324
  validation loss:		0.580258
  validation accuracy:		93.04 %
Epoch 1862 of 2000 took 0.035s
  training loss:		0.004341
  validation loss:		0.574800
  validation accuracy:		93.15 %
Epoch 1863 of 2000 took 0.035s
  training loss:		0.004310
  validation loss:		0.582437
  validation accuracy:		92.72 %
Epoch 1864 of 2000 took 0.035s
  training loss:		0.004433
  validation loss:		0.573951
  validation accuracy:		93.15 %
Epoch 1865 of 2000 took 0.035s
  training loss:		0.004361
  validation loss:		0.579134
  validation accuracy:		92.83 %
Epoch 1866 of 2000 took 0.035s
  training loss:		0.004415
  validation loss:		0.578831
  validation accuracy:		93.04 %
Epoch 1867 of 2000 took 0.035s
  training loss:		0.004321
  validation loss:		0.580842
  validation accuracy:		93.15 %
Epoch 1868 of 2000 took 0.035s
  training loss:		0.004163
  validation loss:		0.583451
  validation accuracy:		92.93 %
Epoch 1869 of 2000 took 0.035s
  training loss:		0.004370
  validation loss:		0.576966
  validation accuracy:		93.04 %
Epoch 1870 of 2000 took 0.035s
  training loss:		0.004362
  validation loss:		0.576092
  validation accuracy:		93.15 %
Epoch 1871 of 2000 took 0.035s
  training loss:		0.004313
  validation loss:		0.575193
  validation accuracy:		92.93 %
Epoch 1872 of 2000 took 0.035s
  training loss:		0.004311
  validation loss:		0.575058
  validation accuracy:		92.93 %
Epoch 1873 of 2000 took 0.035s
  training loss:		0.004229
  validation loss:		0.580677
  validation accuracy:		93.15 %
Epoch 1874 of 2000 took 0.035s
  training loss:		0.004233
  validation loss:		0.580481
  validation accuracy:		92.93 %
Epoch 1875 of 2000 took 0.036s
  training loss:		0.004326
  validation loss:		0.569747
  validation accuracy:		93.26 %
Epoch 1876 of 2000 took 0.035s
  training loss:		0.004371
  validation loss:		0.571604
  validation accuracy:		93.15 %
Epoch 1877 of 2000 took 0.035s
  training loss:		0.004402
  validation loss:		0.580250
  validation accuracy:		92.83 %
Epoch 1878 of 2000 took 0.035s
  training loss:		0.004313
  validation loss:		0.580320
  validation accuracy:		93.15 %
Epoch 1879 of 2000 took 0.035s
  training loss:		0.004166
  validation loss:		0.582263
  validation accuracy:		93.15 %
Epoch 1880 of 2000 took 0.035s
  training loss:		0.004221
  validation loss:		0.575974
  validation accuracy:		93.04 %
Epoch 1881 of 2000 took 0.035s
  training loss:		0.004239
  validation loss:		0.585255
  validation accuracy:		93.04 %
Epoch 1882 of 2000 took 0.036s
  training loss:		0.004207
  validation loss:		0.576198
  validation accuracy:		93.26 %
Epoch 1883 of 2000 took 0.035s
  training loss:		0.004209
  validation loss:		0.580256
  validation accuracy:		93.15 %
Epoch 1884 of 2000 took 0.035s
  training loss:		0.004115
  validation loss:		0.572339
  validation accuracy:		93.15 %
Epoch 1885 of 2000 took 0.035s
  training loss:		0.004344
  validation loss:		0.589210
  validation accuracy:		93.15 %
Epoch 1886 of 2000 took 0.035s
  training loss:		0.004320
  validation loss:		0.586236
  validation accuracy:		93.04 %
Epoch 1887 of 2000 took 0.035s
  training loss:		0.004137
  validation loss:		0.585971
  validation accuracy:		93.04 %
Epoch 1888 of 2000 took 0.035s
  training loss:		0.004245
  validation loss:		0.578509
  validation accuracy:		93.04 %
Epoch 1889 of 2000 took 0.036s
  training loss:		0.004287
  validation loss:		0.578202
  validation accuracy:		92.93 %
Epoch 1890 of 2000 took 0.035s
  training loss:		0.004268
  validation loss:		0.582119
  validation accuracy:		93.15 %
Epoch 1891 of 2000 took 0.035s
  training loss:		0.004136
  validation loss:		0.585339
  validation accuracy:		92.93 %
Epoch 1892 of 2000 took 0.036s
  training loss:		0.004116
  validation loss:		0.582421
  validation accuracy:		93.04 %
Epoch 1893 of 2000 took 0.035s
  training loss:		0.003929
  validation loss:		0.578027
  validation accuracy:		93.15 %
Epoch 1894 of 2000 took 0.035s
  training loss:		0.004244
  validation loss:		0.585343
  validation accuracy:		93.04 %
Epoch 1895 of 2000 took 0.035s
  training loss:		0.004230
  validation loss:		0.582941
  validation accuracy:		93.04 %
Epoch 1896 of 2000 took 0.035s
  training loss:		0.004223
  validation loss:		0.583102
  validation accuracy:		92.93 %
Epoch 1897 of 2000 took 0.035s
  training loss:		0.004070
  validation loss:		0.585789
  validation accuracy:		93.15 %
Epoch 1898 of 2000 took 0.035s
  training loss:		0.004094
  validation loss:		0.588892
  validation accuracy:		93.15 %
Epoch 1899 of 2000 took 0.035s
  training loss:		0.003994
  validation loss:		0.580201
  validation accuracy:		93.04 %
Epoch 1900 of 2000 took 0.035s
  training loss:		0.004322
  validation loss:		0.584959
  validation accuracy:		93.26 %
Epoch 1901 of 2000 took 0.035s
  training loss:		0.004168
  validation loss:		0.583376
  validation accuracy:		92.93 %
Epoch 1902 of 2000 took 0.035s
  training loss:		0.004157
  validation loss:		0.584987
  validation accuracy:		93.26 %
Epoch 1903 of 2000 took 0.035s
  training loss:		0.004187
  validation loss:		0.584854
  validation accuracy:		93.15 %
Epoch 1904 of 2000 took 0.035s
  training loss:		0.004186
  validation loss:		0.585719
  validation accuracy:		93.04 %
Epoch 1905 of 2000 took 0.035s
  training loss:		0.004003
  validation loss:		0.583888
  validation accuracy:		92.61 %
Epoch 1906 of 2000 took 0.035s
  training loss:		0.004185
  validation loss:		0.585539
  validation accuracy:		93.04 %
Epoch 1907 of 2000 took 0.035s
  training loss:		0.004029
  validation loss:		0.583796
  validation accuracy:		93.04 %
Epoch 1908 of 2000 took 0.035s
  training loss:		0.004062
  validation loss:		0.584856
  validation accuracy:		93.04 %
Epoch 1909 of 2000 took 0.035s
  training loss:		0.004239
  validation loss:		0.584460
  validation accuracy:		93.04 %
Epoch 1910 of 2000 took 0.035s
  training loss:		0.004234
  validation loss:		0.585405
  validation accuracy:		93.04 %
Epoch 1911 of 2000 took 0.035s
  training loss:		0.004075
  validation loss:		0.580210
  validation accuracy:		92.93 %
Epoch 1912 of 2000 took 0.035s
  training loss:		0.004166
  validation loss:		0.587735
  validation accuracy:		93.04 %
Epoch 1913 of 2000 took 0.035s
  training loss:		0.004033
  validation loss:		0.585171
  validation accuracy:		93.15 %
Epoch 1914 of 2000 took 0.035s
  training loss:		0.003908
  validation loss:		0.583665
  validation accuracy:		92.83 %
Epoch 1915 of 2000 took 0.035s
  training loss:		0.004070
  validation loss:		0.586577
  validation accuracy:		93.15 %
Epoch 1916 of 2000 took 0.035s
  training loss:		0.003973
  validation loss:		0.585264
  validation accuracy:		93.04 %
Epoch 1917 of 2000 took 0.035s
  training loss:		0.003978
  validation loss:		0.587126
  validation accuracy:		93.04 %
Epoch 1918 of 2000 took 0.035s
  training loss:		0.004055
  validation loss:		0.582464
  validation accuracy:		93.15 %
Epoch 1919 of 2000 took 0.035s
  training loss:		0.003999
  validation loss:		0.588619
  validation accuracy:		92.83 %
Epoch 1920 of 2000 took 0.035s
  training loss:		0.004108
  validation loss:		0.588877
  validation accuracy:		93.15 %
Epoch 1921 of 2000 took 0.035s
  training loss:		0.004032
  validation loss:		0.592910
  validation accuracy:		92.93 %
Epoch 1922 of 2000 took 0.036s
  training loss:		0.003980
  validation loss:		0.586754
  validation accuracy:		93.04 %
Epoch 1923 of 2000 took 0.035s
  training loss:		0.004028
  validation loss:		0.596210
  validation accuracy:		92.93 %
Epoch 1924 of 2000 took 0.035s
  training loss:		0.003877
  validation loss:		0.582038
  validation accuracy:		92.93 %
Epoch 1925 of 2000 took 0.035s
  training loss:		0.004015
  validation loss:		0.591386
  validation accuracy:		93.04 %
Epoch 1926 of 2000 took 0.035s
  training loss:		0.003935
  validation loss:		0.587603
  validation accuracy:		93.15 %
Epoch 1927 of 2000 took 0.035s
  training loss:		0.003975
  validation loss:		0.588684
  validation accuracy:		92.93 %
Epoch 1928 of 2000 took 0.035s
  training loss:		0.004012
  validation loss:		0.585325
  validation accuracy:		93.15 %
Epoch 1929 of 2000 took 0.035s
  training loss:		0.003840
  validation loss:		0.591687
  validation accuracy:		93.15 %
Epoch 1930 of 2000 took 0.035s
  training loss:		0.003967
  validation loss:		0.587748
  validation accuracy:		93.15 %
Epoch 1931 of 2000 took 0.035s
  training loss:		0.003943
  validation loss:		0.585578
  validation accuracy:		93.15 %
Epoch 1932 of 2000 took 0.035s
  training loss:		0.003964
  validation loss:		0.591568
  validation accuracy:		93.04 %
Epoch 1933 of 2000 took 0.035s
  training loss:		0.004017
  validation loss:		0.591662
  validation accuracy:		93.04 %
Epoch 1934 of 2000 took 0.035s
  training loss:		0.003898
  validation loss:		0.586902
  validation accuracy:		92.93 %
Epoch 1935 of 2000 took 0.035s
  training loss:		0.003923
  validation loss:		0.592641
  validation accuracy:		93.15 %
Epoch 1936 of 2000 took 0.035s
  training loss:		0.003906
  validation loss:		0.588844
  validation accuracy:		93.15 %
Epoch 1937 of 2000 took 0.035s
  training loss:		0.003812
  validation loss:		0.587048
  validation accuracy:		93.15 %
Epoch 1938 of 2000 took 0.035s
  training loss:		0.003867
  validation loss:		0.594051
  validation accuracy:		93.15 %
Epoch 1939 of 2000 took 0.036s
  training loss:		0.003962
  validation loss:		0.591652
  validation accuracy:		92.93 %
Epoch 1940 of 2000 took 0.035s
  training loss:		0.003930
  validation loss:		0.584573
  validation accuracy:		93.26 %
Epoch 1941 of 2000 took 0.035s
  training loss:		0.003845
  validation loss:		0.587633
  validation accuracy:		93.15 %
Epoch 1942 of 2000 took 0.035s
  training loss:		0.004051
  validation loss:		0.593380
  validation accuracy:		92.93 %
Epoch 1943 of 2000 took 0.035s
  training loss:		0.003975
  validation loss:		0.593383
  validation accuracy:		93.04 %
Epoch 1944 of 2000 took 0.036s
  training loss:		0.003832
  validation loss:		0.587194
  validation accuracy:		93.04 %
Epoch 1945 of 2000 took 0.035s
  training loss:		0.003688
  validation loss:		0.595211
  validation accuracy:		93.04 %
Epoch 1946 of 2000 took 0.035s
  training loss:		0.003801
  validation loss:		0.590510
  validation accuracy:		93.15 %
Epoch 1947 of 2000 took 0.035s
  training loss:		0.003985
  validation loss:		0.588463
  validation accuracy:		93.04 %
Epoch 1948 of 2000 took 0.035s
  training loss:		0.003879
  validation loss:		0.592341
  validation accuracy:		93.04 %
Epoch 1949 of 2000 took 0.035s
  training loss:		0.003839
  validation loss:		0.591404
  validation accuracy:		93.04 %
Epoch 1950 of 2000 took 0.035s
  training loss:		0.003846
  validation loss:		0.591704
  validation accuracy:		93.15 %
Epoch 1951 of 2000 took 0.035s
  training loss:		0.003775
  validation loss:		0.590081
  validation accuracy:		93.04 %
Epoch 1952 of 2000 took 0.035s
  training loss:		0.003899
  validation loss:		0.588384
  validation accuracy:		93.04 %
Epoch 1953 of 2000 took 0.035s
  training loss:		0.003670
  validation loss:		0.595393
  validation accuracy:		93.04 %
Epoch 1954 of 2000 took 0.035s
  training loss:		0.003771
  validation loss:		0.587387
  validation accuracy:		93.26 %
Epoch 1955 of 2000 took 0.035s
  training loss:		0.003788
  validation loss:		0.599240
  validation accuracy:		93.04 %
Epoch 1956 of 2000 took 0.036s
  training loss:		0.003918
  validation loss:		0.595451
  validation accuracy:		92.93 %
Epoch 1957 of 2000 took 0.035s
  training loss:		0.003909
  validation loss:		0.588497
  validation accuracy:		93.15 %
Epoch 1958 of 2000 took 0.035s
  training loss:		0.003855
  validation loss:		0.595530
  validation accuracy:		93.04 %
Epoch 1959 of 2000 took 0.035s
  training loss:		0.003826
  validation loss:		0.599201
  validation accuracy:		93.04 %
Epoch 1960 of 2000 took 0.035s
  training loss:		0.003867
  validation loss:		0.593375
  validation accuracy:		93.15 %
Epoch 1961 of 2000 took 0.035s
  training loss:		0.003772
  validation loss:		0.600166
  validation accuracy:		92.83 %
Epoch 1962 of 2000 took 0.035s
  training loss:		0.003838
  validation loss:		0.590041
  validation accuracy:		93.15 %
Epoch 1963 of 2000 took 0.035s
  training loss:		0.003815
  validation loss:		0.595463
  validation accuracy:		92.83 %
Epoch 1964 of 2000 took 0.035s
  training loss:		0.003843
  validation loss:		0.595432
  validation accuracy:		93.04 %
Epoch 1965 of 2000 took 0.035s
  training loss:		0.003839
  validation loss:		0.592227
  validation accuracy:		93.04 %
Epoch 1966 of 2000 took 0.035s
  training loss:		0.003859
  validation loss:		0.592887
  validation accuracy:		93.26 %
Epoch 1967 of 2000 took 0.036s
  training loss:		0.003856
  validation loss:		0.590398
  validation accuracy:		92.93 %
Epoch 1968 of 2000 took 0.035s
  training loss:		0.003855
  validation loss:		0.601448
  validation accuracy:		92.83 %
Epoch 1969 of 2000 took 0.035s
  training loss:		0.003880
  validation loss:		0.593496
  validation accuracy:		92.93 %
Epoch 1970 of 2000 took 0.035s
  training loss:		0.003725
  validation loss:		0.594294
  validation accuracy:		93.15 %
Epoch 1971 of 2000 took 0.035s
  training loss:		0.003737
  validation loss:		0.594602
  validation accuracy:		93.26 %
Epoch 1972 of 2000 took 0.035s
  training loss:		0.003812
  validation loss:		0.590036
  validation accuracy:		93.15 %
Epoch 1973 of 2000 took 0.035s
  training loss:		0.003805
  validation loss:		0.592541
  validation accuracy:		93.15 %
Epoch 1974 of 2000 took 0.035s
  training loss:		0.003787
  validation loss:		0.592065
  validation accuracy:		93.15 %
Epoch 1975 of 2000 took 0.035s
  training loss:		0.003729
  validation loss:		0.594861
  validation accuracy:		93.15 %
Epoch 1976 of 2000 took 0.035s
  training loss:		0.003753
  validation loss:		0.600408
  validation accuracy:		93.26 %
Epoch 1977 of 2000 took 0.035s
  training loss:		0.003752
  validation loss:		0.593058
  validation accuracy:		93.04 %
Epoch 1978 of 2000 took 0.035s
  training loss:		0.003856
  validation loss:		0.593164
  validation accuracy:		92.93 %
Epoch 1979 of 2000 took 0.035s
  training loss:		0.003730
  validation loss:		0.593127
  validation accuracy:		93.15 %
Epoch 1980 of 2000 took 0.035s
  training loss:		0.003703
  validation loss:		0.590859
  validation accuracy:		93.04 %
Epoch 1981 of 2000 took 0.035s
  training loss:		0.003758
  validation loss:		0.595660
  validation accuracy:		93.26 %
Epoch 1982 of 2000 took 0.035s
  training loss:		0.003752
  validation loss:		0.600778
  validation accuracy:		92.61 %
Epoch 1983 of 2000 took 0.035s
  training loss:		0.003849
  validation loss:		0.593610
  validation accuracy:		93.15 %
Epoch 1984 of 2000 took 0.035s
  training loss:		0.003746
  validation loss:		0.594700
  validation accuracy:		93.04 %
Epoch 1985 of 2000 took 0.035s
  training loss:		0.003764
  validation loss:		0.601425
  validation accuracy:		93.04 %
Epoch 1986 of 2000 took 0.035s
  training loss:		0.003682
  validation loss:		0.598195
  validation accuracy:		92.93 %
Epoch 1987 of 2000 took 0.035s
  training loss:		0.003746
  validation loss:		0.600007
  validation accuracy:		92.83 %
Epoch 1988 of 2000 took 0.036s
  training loss:		0.003609
  validation loss:		0.595683
  validation accuracy:		93.26 %
Epoch 1989 of 2000 took 0.035s
  training loss:		0.003680
  validation loss:		0.593275
  validation accuracy:		93.15 %
Epoch 1990 of 2000 took 0.035s
  training loss:		0.003588
  validation loss:		0.599130
  validation accuracy:		93.04 %
Epoch 1991 of 2000 took 0.035s
  training loss:		0.003858
  validation loss:		0.602017
  validation accuracy:		93.04 %
Epoch 1992 of 2000 took 0.035s
  training loss:		0.003634
  validation loss:		0.598221
  validation accuracy:		93.26 %
Epoch 1993 of 2000 took 0.035s
  training loss:		0.003612
  validation loss:		0.596588
  validation accuracy:		93.04 %
Epoch 1994 of 2000 took 0.035s
  training loss:		0.003590
  validation loss:		0.597908
  validation accuracy:		93.15 %
Epoch 1995 of 2000 took 0.035s
  training loss:		0.003673
  validation loss:		0.599623
  validation accuracy:		93.04 %
Epoch 1996 of 2000 took 0.035s
  training loss:		0.003771
  validation loss:		0.603046
  validation accuracy:		93.15 %
Epoch 1997 of 2000 took 0.035s
  training loss:		0.003662
  validation loss:		0.602641
  validation accuracy:		93.04 %
Epoch 1998 of 2000 took 0.035s
  training loss:		0.003629
  validation loss:		0.595996
  validation accuracy:		93.15 %
Epoch 1999 of 2000 took 0.035s
  training loss:		0.003635
  validation loss:		0.601103
  validation accuracy:		92.72 %
Epoch 2000 of 2000 took 0.035s
  training loss:		0.003811
  validation loss:		0.595436
  validation accuracy:		93.04 %
Final results:
  test loss:			1.329341
  test accuracy:		84.07 %
