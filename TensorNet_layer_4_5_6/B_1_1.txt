Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
decomposing tensor W of shape (3, 50, 50)...
decomposing tensor B of shape (3, 50)...
Starting training...
Epoch 1 of 2000 took 0.100s
  training loss:		2.994417
  validation loss:		2.983129
  validation accuracy:		13.04 %
Epoch 2 of 2000 took 0.096s
  training loss:		2.974302
  validation loss:		2.956930
  validation accuracy:		13.04 %
Epoch 3 of 2000 took 0.095s
  training loss:		2.947741
  validation loss:		2.927689
  validation accuracy:		13.04 %
Epoch 4 of 2000 took 0.095s
  training loss:		2.919510
  validation loss:		2.897466
  validation accuracy:		13.04 %
Epoch 5 of 2000 took 0.095s
  training loss:		2.891134
  validation loss:		2.867013
  validation accuracy:		13.04 %
Epoch 6 of 2000 took 0.095s
  training loss:		2.862140
  validation loss:		2.836006
  validation accuracy:		13.04 %
Epoch 7 of 2000 took 0.096s
  training loss:		2.834143
  validation loss:		2.804903
  validation accuracy:		13.04 %
Epoch 8 of 2000 took 0.096s
  training loss:		2.804346
  validation loss:		2.772919
  validation accuracy:		13.04 %
Epoch 9 of 2000 took 0.095s
  training loss:		2.774783
  validation loss:		2.739787
  validation accuracy:		13.04 %
Epoch 10 of 2000 took 0.095s
  training loss:		2.744430
  validation loss:		2.705602
  validation accuracy:		13.04 %
Epoch 11 of 2000 took 0.096s
  training loss:		2.713317
  validation loss:		2.670230
  validation accuracy:		13.04 %
Epoch 12 of 2000 took 0.096s
  training loss:		2.681468
  validation loss:		2.634131
  validation accuracy:		13.04 %
Epoch 13 of 2000 took 0.096s
  training loss:		2.649833
  validation loss:		2.597824
  validation accuracy:		13.04 %
Epoch 14 of 2000 took 0.095s
  training loss:		2.617996
  validation loss:		2.561238
  validation accuracy:		13.04 %
Epoch 15 of 2000 took 0.095s
  training loss:		2.585712
  validation loss:		2.525542
  validation accuracy:		13.04 %
Epoch 16 of 2000 took 0.095s
  training loss:		2.555402
  validation loss:		2.490153
  validation accuracy:		13.04 %
Epoch 17 of 2000 took 0.095s
  training loss:		2.525556
  validation loss:		2.457244
  validation accuracy:		13.04 %
Epoch 18 of 2000 took 0.096s
  training loss:		2.499268
  validation loss:		2.426436
  validation accuracy:		13.04 %
Epoch 19 of 2000 took 0.096s
  training loss:		2.473100
  validation loss:		2.398323
  validation accuracy:		13.04 %
Epoch 20 of 2000 took 0.095s
  training loss:		2.450251
  validation loss:		2.373492
  validation accuracy:		13.04 %
Epoch 21 of 2000 took 0.095s
  training loss:		2.429895
  validation loss:		2.351993
  validation accuracy:		13.04 %
Epoch 22 of 2000 took 0.095s
  training loss:		2.411560
  validation loss:		2.334162
  validation accuracy:		13.04 %
Epoch 23 of 2000 took 0.096s
  training loss:		2.394494
  validation loss:		2.318585
  validation accuracy:		13.04 %
Epoch 24 of 2000 took 0.096s
  training loss:		2.381542
  validation loss:		2.307190
  validation accuracy:		13.04 %
Epoch 25 of 2000 took 0.095s
  training loss:		2.370135
  validation loss:		2.297491
  validation accuracy:		13.04 %
Epoch 26 of 2000 took 0.095s
  training loss:		2.360877
  validation loss:		2.290478
  validation accuracy:		13.04 %
Epoch 27 of 2000 took 0.096s
  training loss:		2.352093
  validation loss:		2.285307
  validation accuracy:		13.04 %
Epoch 28 of 2000 took 0.097s
  training loss:		2.344970
  validation loss:		2.280339
  validation accuracy:		13.04 %
Epoch 29 of 2000 took 0.096s
  training loss:		2.339768
  validation loss:		2.277190
  validation accuracy:		13.04 %
Epoch 30 of 2000 took 0.096s
  training loss:		2.335552
  validation loss:		2.273874
  validation accuracy:		12.93 %
Epoch 31 of 2000 took 0.096s
  training loss:		2.329926
  validation loss:		2.270824
  validation accuracy:		13.04 %
Epoch 32 of 2000 took 0.096s
  training loss:		2.325581
  validation loss:		2.269273
  validation accuracy:		14.78 %
Epoch 33 of 2000 took 0.096s
  training loss:		2.323344
  validation loss:		2.266068
  validation accuracy:		13.04 %
Epoch 34 of 2000 took 0.096s
  training loss:		2.320877
  validation loss:		2.263577
  validation accuracy:		13.04 %
Epoch 35 of 2000 took 0.096s
  training loss:		2.319063
  validation loss:		2.264282
  validation accuracy:		12.93 %
Epoch 36 of 2000 took 0.096s
  training loss:		2.316723
  validation loss:		2.263024
  validation accuracy:		13.04 %
Epoch 37 of 2000 took 0.096s
  training loss:		2.313672
  validation loss:		2.262077
  validation accuracy:		12.72 %
Epoch 38 of 2000 took 0.097s
  training loss:		2.312846
  validation loss:		2.259359
  validation accuracy:		12.93 %
Epoch 39 of 2000 took 0.100s
  training loss:		2.311631
  validation loss:		2.256490
  validation accuracy:		12.93 %
Epoch 40 of 2000 took 0.097s
  training loss:		2.310282
  validation loss:		2.255658
  validation accuracy:		13.04 %
Epoch 41 of 2000 took 0.097s
  training loss:		2.309056
  validation loss:		2.254729
  validation accuracy:		13.26 %
Epoch 42 of 2000 took 0.096s
  training loss:		2.307871
  validation loss:		2.255892
  validation accuracy:		20.22 %
Epoch 43 of 2000 took 0.097s
  training loss:		2.307416
  validation loss:		2.254120
  validation accuracy:		13.04 %
Epoch 44 of 2000 took 0.096s
  training loss:		2.307394
  validation loss:		2.254777
  validation accuracy:		13.04 %
Epoch 45 of 2000 took 0.096s
  training loss:		2.306113
  validation loss:		2.254886
  validation accuracy:		15.76 %
Epoch 46 of 2000 took 0.096s
  training loss:		2.304842
  validation loss:		2.254080
  validation accuracy:		13.04 %
Epoch 47 of 2000 took 0.096s
  training loss:		2.303842
  validation loss:		2.251973
  validation accuracy:		13.04 %
Epoch 48 of 2000 took 0.096s
  training loss:		2.303555
  validation loss:		2.250747
  validation accuracy:		13.04 %
Epoch 49 of 2000 took 0.097s
  training loss:		2.303665
  validation loss:		2.250533
  validation accuracy:		13.04 %
Epoch 50 of 2000 took 0.096s
  training loss:		2.302662
  validation loss:		2.249974
  validation accuracy:		12.93 %
Epoch 51 of 2000 took 0.096s
  training loss:		2.302229
  validation loss:		2.249756
  validation accuracy:		12.93 %
Epoch 52 of 2000 took 0.097s
  training loss:		2.301912
  validation loss:		2.249454
  validation accuracy:		12.93 %
Epoch 53 of 2000 took 0.096s
  training loss:		2.302369
  validation loss:		2.249299
  validation accuracy:		13.04 %
Epoch 54 of 2000 took 0.096s
  training loss:		2.302087
  validation loss:		2.249864
  validation accuracy:		13.04 %
Epoch 55 of 2000 took 0.096s
  training loss:		2.300808
  validation loss:		2.249440
  validation accuracy:		12.83 %
Epoch 56 of 2000 took 0.096s
  training loss:		2.300262
  validation loss:		2.248230
  validation accuracy:		14.78 %
Epoch 57 of 2000 took 0.096s
  training loss:		2.301425
  validation loss:		2.249803
  validation accuracy:		13.04 %
Epoch 58 of 2000 took 0.096s
  training loss:		2.299789
  validation loss:		2.251523
  validation accuracy:		12.93 %
Epoch 59 of 2000 took 0.097s
  training loss:		2.301171
  validation loss:		2.249051
  validation accuracy:		12.83 %
Epoch 60 of 2000 took 0.097s
  training loss:		2.300094
  validation loss:		2.248250
  validation accuracy:		12.83 %
Epoch 61 of 2000 took 0.096s
  training loss:		2.299542
  validation loss:		2.248759
  validation accuracy:		13.15 %
Epoch 62 of 2000 took 0.097s
  training loss:		2.299547
  validation loss:		2.248413
  validation accuracy:		12.72 %
Epoch 63 of 2000 took 0.096s
  training loss:		2.299422
  validation loss:		2.248542
  validation accuracy:		12.93 %
Epoch 64 of 2000 took 0.096s
  training loss:		2.298861
  validation loss:		2.249040
  validation accuracy:		17.72 %
Epoch 65 of 2000 took 0.097s
  training loss:		2.300003
  validation loss:		2.249968
  validation accuracy:		13.70 %
Epoch 66 of 2000 took 0.097s
  training loss:		2.298327
  validation loss:		2.248467
  validation accuracy:		13.59 %
Epoch 67 of 2000 took 0.096s
  training loss:		2.298955
  validation loss:		2.246858
  validation accuracy:		13.04 %
Epoch 68 of 2000 took 0.097s
  training loss:		2.298265
  validation loss:		2.246031
  validation accuracy:		18.26 %
Epoch 69 of 2000 took 0.097s
  training loss:		2.297185
  validation loss:		2.246881
  validation accuracy:		13.04 %
Epoch 70 of 2000 took 0.096s
  training loss:		2.298673
  validation loss:		2.246867
  validation accuracy:		13.04 %
Epoch 71 of 2000 took 0.097s
  training loss:		2.297895
  validation loss:		2.246486
  validation accuracy:		13.04 %
Epoch 72 of 2000 took 0.096s
  training loss:		2.297927
  validation loss:		2.247595
  validation accuracy:		12.93 %
Epoch 73 of 2000 took 0.096s
  training loss:		2.298321
  validation loss:		2.248151
  validation accuracy:		13.37 %
Epoch 74 of 2000 took 0.097s
  training loss:		2.298460
  validation loss:		2.247406
  validation accuracy:		13.04 %
Epoch 75 of 2000 took 0.097s
  training loss:		2.298469
  validation loss:		2.248000
  validation accuracy:		11.96 %
Epoch 76 of 2000 took 0.096s
  training loss:		2.297915
  validation loss:		2.248813
  validation accuracy:		13.04 %
Epoch 77 of 2000 took 0.096s
  training loss:		2.297483
  validation loss:		2.247287
  validation accuracy:		12.93 %
Epoch 78 of 2000 took 0.096s
  training loss:		2.297400
  validation loss:		2.247306
  validation accuracy:		13.48 %
Epoch 79 of 2000 took 0.097s
  training loss:		2.296779
  validation loss:		2.245404
  validation accuracy:		13.91 %
Epoch 80 of 2000 took 0.096s
  training loss:		2.297276
  validation loss:		2.246049
  validation accuracy:		13.37 %
Epoch 81 of 2000 took 0.097s
  training loss:		2.295926
  validation loss:		2.246171
  validation accuracy:		13.04 %
Epoch 82 of 2000 took 0.096s
  training loss:		2.296891
  validation loss:		2.246155
  validation accuracy:		13.04 %
Epoch 83 of 2000 took 0.097s
  training loss:		2.296827
  validation loss:		2.243946
  validation accuracy:		13.04 %
Epoch 84 of 2000 took 0.097s
  training loss:		2.297680
  validation loss:		2.244814
  validation accuracy:		12.83 %
Epoch 85 of 2000 took 0.097s
  training loss:		2.297500
  validation loss:		2.249637
  validation accuracy:		12.93 %
Epoch 86 of 2000 took 0.097s
  training loss:		2.297180
  validation loss:		2.246521
  validation accuracy:		13.04 %
Epoch 87 of 2000 took 0.096s
  training loss:		2.296563
  validation loss:		2.246658
  validation accuracy:		13.04 %
Epoch 88 of 2000 took 0.096s
  training loss:		2.296844
  validation loss:		2.244937
  validation accuracy:		12.93 %
Epoch 89 of 2000 took 0.096s
  training loss:		2.296009
  validation loss:		2.244804
  validation accuracy:		12.93 %
Epoch 90 of 2000 took 0.097s
  training loss:		2.297595
  validation loss:		2.245996
  validation accuracy:		20.65 %
Epoch 91 of 2000 took 0.097s
  training loss:		2.297072
  validation loss:		2.245555
  validation accuracy:		13.04 %
Epoch 92 of 2000 took 0.096s
  training loss:		2.297278
  validation loss:		2.246901
  validation accuracy:		13.04 %
Epoch 93 of 2000 took 0.097s
  training loss:		2.296917
  validation loss:		2.247826
  validation accuracy:		13.04 %
Epoch 94 of 2000 took 0.096s
  training loss:		2.296336
  validation loss:		2.249106
  validation accuracy:		12.93 %
Epoch 95 of 2000 took 0.096s
  training loss:		2.296521
  validation loss:		2.243671
  validation accuracy:		12.93 %
Epoch 96 of 2000 took 0.096s
  training loss:		2.296208
  validation loss:		2.245516
  validation accuracy:		12.93 %
Epoch 97 of 2000 took 0.096s
  training loss:		2.294509
  validation loss:		2.243423
  validation accuracy:		12.93 %
Epoch 98 of 2000 took 0.096s
  training loss:		2.295909
  validation loss:		2.241912
  validation accuracy:		12.93 %
Epoch 99 of 2000 took 0.096s
  training loss:		2.296066
  validation loss:		2.241924
  validation accuracy:		13.04 %
Epoch 100 of 2000 took 0.096s
  training loss:		2.296559
  validation loss:		2.244926
  validation accuracy:		13.04 %
Epoch 101 of 2000 took 0.096s
  training loss:		2.296857
  validation loss:		2.246655
  validation accuracy:		13.04 %
Epoch 102 of 2000 took 0.097s
  training loss:		2.295794
  validation loss:		2.244012
  validation accuracy:		12.93 %
Epoch 103 of 2000 took 0.096s
  training loss:		2.296616
  validation loss:		2.244686
  validation accuracy:		16.41 %
Epoch 104 of 2000 took 0.096s
  training loss:		2.296240
  validation loss:		2.247118
  validation accuracy:		12.93 %
Epoch 105 of 2000 took 0.097s
  training loss:		2.295578
  validation loss:		2.245047
  validation accuracy:		12.83 %
Epoch 106 of 2000 took 0.097s
  training loss:		2.296105
  validation loss:		2.244700
  validation accuracy:		13.04 %
Epoch 107 of 2000 took 0.097s
  training loss:		2.295576
  validation loss:		2.245069
  validation accuracy:		12.93 %
Epoch 108 of 2000 took 0.100s
  training loss:		2.295624
  validation loss:		2.243012
  validation accuracy:		13.04 %
Epoch 109 of 2000 took 0.097s
  training loss:		2.295811
  validation loss:		2.245822
  validation accuracy:		13.15 %
Epoch 110 of 2000 took 0.097s
  training loss:		2.295551
  validation loss:		2.244928
  validation accuracy:		12.93 %
Epoch 111 of 2000 took 0.097s
  training loss:		2.296351
  validation loss:		2.243807
  validation accuracy:		13.80 %
Epoch 112 of 2000 took 0.097s
  training loss:		2.296448
  validation loss:		2.248518
  validation accuracy:		13.04 %
Epoch 113 of 2000 took 0.096s
  training loss:		2.294951
  validation loss:		2.247327
  validation accuracy:		13.04 %
Epoch 114 of 2000 took 0.097s
  training loss:		2.296059
  validation loss:		2.241246
  validation accuracy:		13.26 %
Epoch 115 of 2000 took 0.097s
  training loss:		2.295596
  validation loss:		2.243255
  validation accuracy:		13.26 %
Epoch 116 of 2000 took 0.096s
  training loss:		2.294957
  validation loss:		2.244770
  validation accuracy:		12.93 %
Epoch 117 of 2000 took 0.096s
  training loss:		2.296005
  validation loss:		2.244789
  validation accuracy:		12.93 %
Epoch 118 of 2000 took 0.096s
  training loss:		2.295600
  validation loss:		2.244775
  validation accuracy:		11.85 %
Epoch 119 of 2000 took 0.096s
  training loss:		2.295039
  validation loss:		2.244174
  validation accuracy:		12.83 %
Epoch 120 of 2000 took 0.096s
  training loss:		2.295879
  validation loss:		2.244996
  validation accuracy:		13.48 %
Epoch 121 of 2000 took 0.096s
  training loss:		2.296341
  validation loss:		2.245119
  validation accuracy:		10.33 %
Epoch 122 of 2000 took 0.097s
  training loss:		2.294976
  validation loss:		2.246914
  validation accuracy:		13.15 %
Epoch 123 of 2000 took 0.097s
  training loss:		2.295826
  validation loss:		2.244897
  validation accuracy:		12.93 %
Epoch 124 of 2000 took 0.096s
  training loss:		2.295289
  validation loss:		2.242386
  validation accuracy:		13.04 %
Epoch 125 of 2000 took 0.096s
  training loss:		2.295484
  validation loss:		2.243403
  validation accuracy:		13.04 %
Epoch 126 of 2000 took 0.096s
  training loss:		2.295876
  validation loss:		2.244547
  validation accuracy:		12.93 %
Epoch 127 of 2000 took 0.096s
  training loss:		2.295584
  validation loss:		2.244559
  validation accuracy:		14.57 %
Epoch 128 of 2000 took 0.096s
  training loss:		2.296174
  validation loss:		2.246044
  validation accuracy:		13.04 %
Epoch 129 of 2000 took 0.096s
  training loss:		2.294479
  validation loss:		2.244931
  validation accuracy:		12.93 %
Epoch 130 of 2000 took 0.096s
  training loss:		2.295361
  validation loss:		2.244578
  validation accuracy:		13.15 %
Epoch 131 of 2000 took 0.097s
  training loss:		2.295397
  validation loss:		2.244225
  validation accuracy:		12.83 %
Epoch 132 of 2000 took 0.097s
  training loss:		2.295459
  validation loss:		2.244022
  validation accuracy:		12.83 %
Epoch 133 of 2000 took 0.097s
  training loss:		2.295405
  validation loss:		2.244753
  validation accuracy:		13.04 %
Epoch 134 of 2000 took 0.097s
  training loss:		2.294776
  validation loss:		2.243266
  validation accuracy:		13.04 %
Epoch 135 of 2000 took 0.096s
  training loss:		2.294664
  validation loss:		2.243831
  validation accuracy:		12.83 %
Epoch 136 of 2000 took 0.097s
  training loss:		2.294717
  validation loss:		2.243519
  validation accuracy:		13.59 %
Epoch 137 of 2000 took 0.097s
  training loss:		2.295334
  validation loss:		2.244574
  validation accuracy:		12.93 %
Epoch 138 of 2000 took 0.096s
  training loss:		2.294613
  validation loss:		2.243551
  validation accuracy:		15.43 %
Epoch 139 of 2000 took 0.096s
  training loss:		2.295324
  validation loss:		2.244473
  validation accuracy:		13.04 %
Epoch 140 of 2000 took 0.096s
  training loss:		2.295065
  validation loss:		2.243016
  validation accuracy:		13.04 %
Epoch 141 of 2000 took 0.096s
  training loss:		2.294150
  validation loss:		2.243884
  validation accuracy:		15.00 %
Epoch 142 of 2000 took 0.096s
  training loss:		2.294860
  validation loss:		2.242122
  validation accuracy:		16.74 %
Epoch 143 of 2000 took 0.097s
  training loss:		2.294713
  validation loss:		2.240527
  validation accuracy:		12.83 %
Epoch 144 of 2000 took 0.096s
  training loss:		2.294718
  validation loss:		2.245358
  validation accuracy:		13.04 %
Epoch 145 of 2000 took 0.096s
  training loss:		2.295610
  validation loss:		2.246077
  validation accuracy:		13.04 %
Epoch 146 of 2000 took 0.096s
  training loss:		2.295199
  validation loss:		2.246930
  validation accuracy:		13.04 %
Epoch 147 of 2000 took 0.096s
  training loss:		2.295555
  validation loss:		2.246733
  validation accuracy:		21.09 %
Epoch 148 of 2000 took 0.097s
  training loss:		2.294851
  validation loss:		2.244377
  validation accuracy:		13.15 %
Epoch 149 of 2000 took 0.096s
  training loss:		2.294252
  validation loss:		2.242757
  validation accuracy:		12.93 %
Epoch 150 of 2000 took 0.096s
  training loss:		2.296216
  validation loss:		2.246471
  validation accuracy:		13.26 %
Epoch 151 of 2000 took 0.097s
  training loss:		2.295022
  validation loss:		2.245315
  validation accuracy:		12.83 %
Epoch 152 of 2000 took 0.097s
  training loss:		2.293754
  validation loss:		2.242236
  validation accuracy:		18.48 %
Epoch 153 of 2000 took 0.097s
  training loss:		2.293937
  validation loss:		2.239717
  validation accuracy:		21.74 %
Epoch 154 of 2000 took 0.097s
  training loss:		2.294563
  validation loss:		2.242477
  validation accuracy:		13.04 %
Epoch 155 of 2000 took 0.096s
  training loss:		2.294711
  validation loss:		2.243447
  validation accuracy:		13.04 %
Epoch 156 of 2000 took 0.096s
  training loss:		2.294806
  validation loss:		2.242880
  validation accuracy:		13.70 %
Epoch 157 of 2000 took 0.096s
  training loss:		2.294306
  validation loss:		2.244135
  validation accuracy:		15.54 %
Epoch 158 of 2000 took 0.097s
  training loss:		2.294702
  validation loss:		2.245362
  validation accuracy:		15.54 %
Epoch 159 of 2000 took 0.096s
  training loss:		2.294265
  validation loss:		2.240925
  validation accuracy:		12.83 %
Epoch 160 of 2000 took 0.096s
  training loss:		2.295632
  validation loss:		2.245568
  validation accuracy:		13.59 %
Epoch 161 of 2000 took 0.096s
  training loss:		2.293674
  validation loss:		2.243643
  validation accuracy:		12.93 %
Epoch 162 of 2000 took 0.096s
  training loss:		2.294663
  validation loss:		2.239869
  validation accuracy:		11.63 %
Epoch 163 of 2000 took 0.097s
  training loss:		2.295464
  validation loss:		2.245562
  validation accuracy:		13.70 %
Epoch 164 of 2000 took 0.097s
  training loss:		2.294323
  validation loss:		2.246938
  validation accuracy:		12.61 %
Epoch 165 of 2000 took 0.097s
  training loss:		2.294828
  validation loss:		2.242675
  validation accuracy:		12.83 %
Epoch 166 of 2000 took 0.096s
  training loss:		2.295334
  validation loss:		2.244570
  validation accuracy:		22.17 %
Epoch 167 of 2000 took 0.096s
  training loss:		2.294689
  validation loss:		2.244089
  validation accuracy:		12.93 %
Epoch 168 of 2000 took 0.097s
  training loss:		2.295284
  validation loss:		2.246085
  validation accuracy:		13.48 %
Epoch 169 of 2000 took 0.096s
  training loss:		2.295071
  validation loss:		2.244206
  validation accuracy:		22.07 %
Epoch 170 of 2000 took 0.096s
  training loss:		2.294876
  validation loss:		2.244200
  validation accuracy:		12.93 %
Epoch 171 of 2000 took 0.096s
  training loss:		2.294710
  validation loss:		2.245765
  validation accuracy:		14.24 %
Epoch 172 of 2000 took 0.096s
  training loss:		2.294768
  validation loss:		2.244841
  validation accuracy:		13.26 %
Epoch 173 of 2000 took 0.097s
  training loss:		2.294407
  validation loss:		2.241523
  validation accuracy:		13.80 %
Epoch 174 of 2000 took 0.097s
  training loss:		2.294373
  validation loss:		2.243317
  validation accuracy:		13.04 %
Epoch 175 of 2000 took 0.096s
  training loss:		2.293779
  validation loss:		2.243531
  validation accuracy:		13.37 %
Epoch 176 of 2000 took 0.096s
  training loss:		2.294736
  validation loss:		2.241206
  validation accuracy:		14.46 %
Epoch 177 of 2000 took 0.096s
  training loss:		2.294997
  validation loss:		2.242684
  validation accuracy:		12.83 %
Epoch 178 of 2000 took 0.096s
  training loss:		2.293914
  validation loss:		2.242559
  validation accuracy:		14.57 %
Epoch 179 of 2000 took 0.096s
  training loss:		2.294108
  validation loss:		2.239806
  validation accuracy:		13.48 %
Epoch 180 of 2000 took 0.096s
  training loss:		2.294146
  validation loss:		2.243541
  validation accuracy:		13.26 %
Epoch 181 of 2000 took 0.096s
  training loss:		2.293595
  validation loss:		2.241528
  validation accuracy:		12.61 %
Epoch 182 of 2000 took 0.096s
  training loss:		2.294028
  validation loss:		2.241925
  validation accuracy:		14.35 %
Epoch 183 of 2000 took 0.096s
  training loss:		2.295077
  validation loss:		2.245975
  validation accuracy:		12.83 %
Epoch 184 of 2000 took 0.096s
  training loss:		2.294415
  validation loss:		2.242084
  validation accuracy:		13.91 %
Epoch 185 of 2000 took 0.096s
  training loss:		2.294868
  validation loss:		2.242748
  validation accuracy:		18.48 %
Epoch 186 of 2000 took 0.096s
  training loss:		2.293809
  validation loss:		2.244032
  validation accuracy:		12.93 %
Epoch 187 of 2000 took 0.097s
  training loss:		2.294526
  validation loss:		2.244299
  validation accuracy:		12.93 %
Epoch 188 of 2000 took 0.096s
  training loss:		2.295397
  validation loss:		2.244799
  validation accuracy:		13.59 %
Epoch 189 of 2000 took 0.097s
  training loss:		2.294385
  validation loss:		2.245070
  validation accuracy:		13.04 %
Epoch 190 of 2000 took 0.097s
  training loss:		2.294961
  validation loss:		2.244621
  validation accuracy:		16.74 %
Epoch 191 of 2000 took 0.096s
  training loss:		2.294709
  validation loss:		2.244152
  validation accuracy:		14.24 %
Epoch 192 of 2000 took 0.096s
  training loss:		2.295415
  validation loss:		2.246882
  validation accuracy:		13.04 %
Epoch 193 of 2000 took 0.097s
  training loss:		2.294406
  validation loss:		2.241516
  validation accuracy:		13.04 %
Epoch 194 of 2000 took 0.096s
  training loss:		2.294330
  validation loss:		2.242506
  validation accuracy:		13.59 %
Epoch 195 of 2000 took 0.097s
  training loss:		2.294832
  validation loss:		2.245503
  validation accuracy:		15.76 %
Epoch 196 of 2000 took 0.096s
  training loss:		2.293707
  validation loss:		2.242051
  validation accuracy:		12.93 %
Epoch 197 of 2000 took 0.096s
  training loss:		2.295012
  validation loss:		2.245406
  validation accuracy:		22.28 %
Epoch 198 of 2000 took 0.096s
  training loss:		2.294406
  validation loss:		2.245457
  validation accuracy:		15.00 %
Epoch 199 of 2000 took 0.097s
  training loss:		2.294475
  validation loss:		2.243932
  validation accuracy:		13.04 %
Epoch 200 of 2000 took 0.096s
  training loss:		2.293505
  validation loss:		2.239217
  validation accuracy:		13.04 %
Epoch 201 of 2000 took 0.096s
  training loss:		2.293474
  validation loss:		2.238040
  validation accuracy:		14.89 %
Epoch 202 of 2000 took 0.096s
  training loss:		2.294308
  validation loss:		2.241808
  validation accuracy:		14.24 %
Epoch 203 of 2000 took 0.096s
  training loss:		2.294110
  validation loss:		2.244323
  validation accuracy:		19.02 %
Epoch 204 of 2000 took 0.099s
  training loss:		2.295070
  validation loss:		2.244658
  validation accuracy:		13.04 %
Epoch 205 of 2000 took 0.098s
  training loss:		2.294613
  validation loss:		2.243367
  validation accuracy:		13.04 %
Epoch 206 of 2000 took 0.096s
  training loss:		2.294357
  validation loss:		2.245968
  validation accuracy:		12.83 %
Epoch 207 of 2000 took 0.096s
  training loss:		2.294574
  validation loss:		2.245826
  validation accuracy:		18.37 %
Epoch 208 of 2000 took 0.096s
  training loss:		2.293914
  validation loss:		2.243964
  validation accuracy:		19.24 %
Epoch 209 of 2000 took 0.096s
  training loss:		2.294173
  validation loss:		2.242707
  validation accuracy:		13.26 %
Epoch 210 of 2000 took 0.096s
  training loss:		2.293402
  validation loss:		2.240686
  validation accuracy:		21.41 %
Epoch 211 of 2000 took 0.096s
  training loss:		2.294132
  validation loss:		2.243504
  validation accuracy:		15.98 %
Epoch 212 of 2000 took 0.096s
  training loss:		2.294240
  validation loss:		2.244235
  validation accuracy:		12.83 %
Epoch 213 of 2000 took 0.096s
  training loss:		2.295045
  validation loss:		2.242550
  validation accuracy:		13.04 %
Epoch 214 of 2000 took 0.096s
  training loss:		2.293591
  validation loss:		2.241842
  validation accuracy:		13.04 %
Epoch 215 of 2000 took 0.096s
  training loss:		2.294048
  validation loss:		2.243523
  validation accuracy:		12.93 %
Epoch 216 of 2000 took 0.096s
  training loss:		2.293562
  validation loss:		2.242002
  validation accuracy:		14.57 %
Epoch 217 of 2000 took 0.096s
  training loss:		2.294061
  validation loss:		2.242259
  validation accuracy:		13.48 %
Epoch 218 of 2000 took 0.097s
  training loss:		2.294699
  validation loss:		2.243612
  validation accuracy:		14.13 %
Epoch 219 of 2000 took 0.097s
  training loss:		2.293195
  validation loss:		2.243216
  validation accuracy:		13.37 %
Epoch 220 of 2000 took 0.097s
  training loss:		2.293157
  validation loss:		2.239568
  validation accuracy:		12.72 %
Epoch 221 of 2000 took 0.096s
  training loss:		2.294229
  validation loss:		2.240166
  validation accuracy:		12.83 %
Epoch 222 of 2000 took 0.096s
  training loss:		2.292883
  validation loss:		2.241282
  validation accuracy:		13.04 %
Epoch 223 of 2000 took 0.096s
  training loss:		2.294677
  validation loss:		2.243337
  validation accuracy:		14.13 %
Epoch 224 of 2000 took 0.096s
  training loss:		2.293144
  validation loss:		2.242238
  validation accuracy:		20.87 %
Epoch 225 of 2000 took 0.096s
  training loss:		2.293418
  validation loss:		2.243061
  validation accuracy:		13.70 %
Epoch 226 of 2000 took 0.097s
  training loss:		2.293157
  validation loss:		2.242904
  validation accuracy:		12.83 %
Epoch 227 of 2000 took 0.096s
  training loss:		2.294242
  validation loss:		2.243899
  validation accuracy:		13.37 %
Epoch 228 of 2000 took 0.096s
  training loss:		2.294041
  validation loss:		2.242275
  validation accuracy:		19.57 %
Epoch 229 of 2000 took 0.096s
  training loss:		2.294712
  validation loss:		2.246330
  validation accuracy:		17.39 %
Epoch 230 of 2000 took 0.097s
  training loss:		2.293980
  validation loss:		2.248304
  validation accuracy:		13.15 %
Epoch 231 of 2000 took 0.097s
  training loss:		2.292837
  validation loss:		2.241468
  validation accuracy:		14.02 %
Epoch 232 of 2000 took 0.096s
  training loss:		2.292199
  validation loss:		2.239020
  validation accuracy:		20.43 %
Epoch 233 of 2000 took 0.096s
  training loss:		2.293585
  validation loss:		2.240319
  validation accuracy:		9.67 %
Epoch 234 of 2000 took 0.097s
  training loss:		2.293529
  validation loss:		2.240638
  validation accuracy:		16.20 %
Epoch 235 of 2000 took 0.097s
  training loss:		2.293644
  validation loss:		2.244196
  validation accuracy:		13.04 %
Epoch 236 of 2000 took 0.096s
  training loss:		2.293165
  validation loss:		2.241871
  validation accuracy:		20.65 %
Epoch 237 of 2000 took 0.097s
  training loss:		2.293562
  validation loss:		2.239871
  validation accuracy:		13.37 %
Epoch 238 of 2000 took 0.096s
  training loss:		2.293950
  validation loss:		2.243999
  validation accuracy:		12.93 %
Epoch 239 of 2000 took 0.096s
  training loss:		2.293092
  validation loss:		2.244407
  validation accuracy:		15.00 %
Epoch 240 of 2000 took 0.096s
  training loss:		2.293841
  validation loss:		2.242448
  validation accuracy:		21.41 %
Epoch 241 of 2000 took 0.096s
  training loss:		2.293617
  validation loss:		2.243254
  validation accuracy:		13.26 %
Epoch 242 of 2000 took 0.096s
  training loss:		2.294534
  validation loss:		2.245164
  validation accuracy:		17.39 %
Epoch 243 of 2000 took 0.096s
  training loss:		2.292768
  validation loss:		2.239944
  validation accuracy:		13.80 %
Epoch 244 of 2000 took 0.096s
  training loss:		2.292953
  validation loss:		2.239821
  validation accuracy:		14.67 %
Epoch 245 of 2000 took 0.096s
  training loss:		2.293092
  validation loss:		2.241375
  validation accuracy:		12.93 %
Epoch 246 of 2000 took 0.097s
  training loss:		2.293116
  validation loss:		2.242830
  validation accuracy:		14.35 %
Epoch 247 of 2000 took 0.097s
  training loss:		2.292996
  validation loss:		2.241043
  validation accuracy:		13.04 %
Epoch 248 of 2000 took 0.096s
  training loss:		2.293300
  validation loss:		2.241210
  validation accuracy:		13.26 %
Epoch 249 of 2000 took 0.096s
  training loss:		2.292715
  validation loss:		2.242569
  validation accuracy:		12.93 %
Epoch 250 of 2000 took 0.096s
  training loss:		2.293756
  validation loss:		2.243053
  validation accuracy:		13.04 %
Epoch 251 of 2000 took 0.097s
  training loss:		2.292832
  validation loss:		2.243022
  validation accuracy:		17.93 %
Epoch 252 of 2000 took 0.096s
  training loss:		2.292773
  validation loss:		2.240735
  validation accuracy:		13.15 %
Epoch 253 of 2000 took 0.096s
  training loss:		2.293328
  validation loss:		2.241223
  validation accuracy:		15.00 %
Epoch 254 of 2000 took 0.096s
  training loss:		2.293930
  validation loss:		2.242558
  validation accuracy:		22.72 %
Epoch 255 of 2000 took 0.096s
  training loss:		2.293172
  validation loss:		2.245585
  validation accuracy:		13.48 %
Epoch 256 of 2000 took 0.096s
  training loss:		2.293489
  validation loss:		2.246151
  validation accuracy:		15.76 %
Epoch 257 of 2000 took 0.096s
  training loss:		2.292410
  validation loss:		2.238754
  validation accuracy:		17.17 %
Epoch 258 of 2000 took 0.096s
  training loss:		2.293549
  validation loss:		2.237133
  validation accuracy:		12.93 %
Epoch 259 of 2000 took 0.096s
  training loss:		2.292484
  validation loss:		2.243090
  validation accuracy:		13.26 %
Epoch 260 of 2000 took 0.096s
  training loss:		2.293576
  validation loss:		2.242721
  validation accuracy:		14.24 %
Epoch 261 of 2000 took 0.097s
  training loss:		2.294019
  validation loss:		2.242603
  validation accuracy:		13.04 %
Epoch 262 of 2000 took 0.097s
  training loss:		2.293161
  validation loss:		2.244429
  validation accuracy:		15.00 %
Epoch 263 of 2000 took 0.096s
  training loss:		2.292341
  validation loss:		2.241680
  validation accuracy:		15.33 %
Epoch 264 of 2000 took 0.096s
  training loss:		2.293152
  validation loss:		2.241285
  validation accuracy:		22.61 %
Epoch 265 of 2000 took 0.096s
  training loss:		2.294049
  validation loss:		2.243912
  validation accuracy:		20.00 %
Epoch 266 of 2000 took 0.096s
  training loss:		2.292823
  validation loss:		2.242553
  validation accuracy:		14.13 %
Epoch 267 of 2000 took 0.097s
  training loss:		2.293126
  validation loss:		2.240302
  validation accuracy:		13.15 %
Epoch 268 of 2000 took 0.097s
  training loss:		2.292407
  validation loss:		2.241337
  validation accuracy:		22.61 %
Epoch 269 of 2000 took 0.096s
  training loss:		2.293233
  validation loss:		2.242997
  validation accuracy:		19.24 %
Epoch 270 of 2000 took 0.097s
  training loss:		2.293775
  validation loss:		2.244260
  validation accuracy:		14.35 %
Epoch 271 of 2000 took 0.096s
  training loss:		2.292562
  validation loss:		2.239281
  validation accuracy:		20.22 %
Epoch 272 of 2000 took 0.097s
  training loss:		2.293179
  validation loss:		2.241535
  validation accuracy:		17.39 %
Epoch 273 of 2000 took 0.096s
  training loss:		2.291934
  validation loss:		2.240262
  validation accuracy:		22.72 %
Epoch 274 of 2000 took 0.096s
  training loss:		2.292741
  validation loss:		2.243401
  validation accuracy:		25.33 %
Epoch 275 of 2000 took 0.096s
  training loss:		2.293049
  validation loss:		2.241085
  validation accuracy:		13.59 %
Epoch 276 of 2000 took 0.097s
  training loss:		2.293692
  validation loss:		2.244903
  validation accuracy:		24.35 %
Epoch 277 of 2000 took 0.097s
  training loss:		2.292777
  validation loss:		2.245571
  validation accuracy:		21.30 %
Epoch 278 of 2000 took 0.097s
  training loss:		2.292608
  validation loss:		2.243861
  validation accuracy:		17.50 %
Epoch 279 of 2000 took 0.096s
  training loss:		2.291821
  validation loss:		2.238287
  validation accuracy:		14.35 %
Epoch 280 of 2000 took 0.096s
  training loss:		2.291785
  validation loss:		2.240253
  validation accuracy:		18.37 %
Epoch 281 of 2000 took 0.096s
  training loss:		2.291839
  validation loss:		2.240898
  validation accuracy:		12.93 %
Epoch 282 of 2000 took 0.096s
  training loss:		2.292052
  validation loss:		2.238925
  validation accuracy:		23.26 %
Epoch 283 of 2000 took 0.096s
  training loss:		2.292541
  validation loss:		2.241010
  validation accuracy:		14.13 %
Epoch 284 of 2000 took 0.096s
  training loss:		2.292208
  validation loss:		2.240572
  validation accuracy:		19.13 %
Epoch 285 of 2000 took 0.096s
  training loss:		2.290712
  validation loss:		2.237470
  validation accuracy:		14.35 %
Epoch 286 of 2000 took 0.097s
  training loss:		2.292647
  validation loss:		2.237910
  validation accuracy:		16.52 %
Epoch 287 of 2000 took 0.097s
  training loss:		2.292508
  validation loss:		2.244974
  validation accuracy:		22.50 %
Epoch 288 of 2000 took 0.097s
  training loss:		2.292720
  validation loss:		2.245403
  validation accuracy:		14.46 %
Epoch 289 of 2000 took 0.096s
  training loss:		2.291157
  validation loss:		2.240607
  validation accuracy:		22.17 %
Epoch 290 of 2000 took 0.096s
  training loss:		2.292611
  validation loss:		2.238027
  validation accuracy:		14.24 %
Epoch 291 of 2000 took 0.097s
  training loss:		2.291583
  validation loss:		2.240948
  validation accuracy:		22.61 %
Epoch 292 of 2000 took 0.097s
  training loss:		2.291509
  validation loss:		2.239625
  validation accuracy:		25.33 %
Epoch 293 of 2000 took 0.097s
  training loss:		2.291505
  validation loss:		2.238557
  validation accuracy:		23.48 %
Epoch 294 of 2000 took 0.096s
  training loss:		2.292044
  validation loss:		2.242023
  validation accuracy:		13.80 %
Epoch 295 of 2000 took 0.097s
  training loss:		2.291666
  validation loss:		2.239926
  validation accuracy:		17.07 %
Epoch 296 of 2000 took 0.096s
  training loss:		2.291752
  validation loss:		2.240257
  validation accuracy:		18.80 %
Epoch 297 of 2000 took 0.096s
  training loss:		2.290947
  validation loss:		2.240453
  validation accuracy:		12.50 %
Epoch 298 of 2000 took 0.097s
  training loss:		2.291065
  validation loss:		2.239492
  validation accuracy:		15.54 %
Epoch 299 of 2000 took 0.096s
  training loss:		2.291722
  validation loss:		2.237786
  validation accuracy:		15.87 %
Epoch 300 of 2000 took 0.096s
  training loss:		2.290351
  validation loss:		2.237604
  validation accuracy:		21.30 %
Epoch 301 of 2000 took 0.096s
  training loss:		2.291862
  validation loss:		2.240604
  validation accuracy:		19.02 %
Epoch 302 of 2000 took 0.096s
  training loss:		2.289863
  validation loss:		2.237179
  validation accuracy:		13.48 %
Epoch 303 of 2000 took 0.096s
  training loss:		2.290901
  validation loss:		2.236993
  validation accuracy:		18.70 %
Epoch 304 of 2000 took 0.096s
  training loss:		2.290950
  validation loss:		2.239769
  validation accuracy:		20.00 %
Epoch 305 of 2000 took 0.096s
  training loss:		2.290663
  validation loss:		2.240298
  validation accuracy:		23.48 %
Epoch 306 of 2000 took 0.096s
  training loss:		2.291816
  validation loss:		2.239968
  validation accuracy:		15.33 %
Epoch 307 of 2000 took 0.096s
  training loss:		2.290869
  validation loss:		2.241020
  validation accuracy:		21.63 %
Epoch 308 of 2000 took 0.097s
  training loss:		2.291232
  validation loss:		2.238397
  validation accuracy:		18.70 %
Epoch 309 of 2000 took 0.097s
  training loss:		2.290556
  validation loss:		2.238023
  validation accuracy:		23.15 %
Epoch 310 of 2000 took 0.096s
  training loss:		2.290057
  validation loss:		2.240728
  validation accuracy:		24.13 %
Epoch 311 of 2000 took 0.100s
  training loss:		2.289511
  validation loss:		2.240669
  validation accuracy:		23.15 %
Epoch 312 of 2000 took 0.096s
  training loss:		2.290800
  validation loss:		2.237699
  validation accuracy:		24.78 %
Epoch 313 of 2000 took 0.097s
  training loss:		2.290820
  validation loss:		2.237901
  validation accuracy:		20.33 %
Epoch 314 of 2000 took 0.097s
  training loss:		2.290003
  validation loss:		2.239636
  validation accuracy:		15.43 %
Epoch 315 of 2000 took 0.096s
  training loss:		2.289870
  validation loss:		2.238598
  validation accuracy:		23.26 %
Epoch 316 of 2000 took 0.097s
  training loss:		2.290071
  validation loss:		2.239099
  validation accuracy:		17.17 %
Epoch 317 of 2000 took 0.097s
  training loss:		2.289879
  validation loss:		2.240570
  validation accuracy:		18.59 %
Epoch 318 of 2000 took 0.097s
  training loss:		2.288883
  validation loss:		2.237123
  validation accuracy:		19.67 %
Epoch 319 of 2000 took 0.097s
  training loss:		2.289244
  validation loss:		2.234811
  validation accuracy:		14.89 %
Epoch 320 of 2000 took 0.096s
  training loss:		2.288389
  validation loss:		2.233529
  validation accuracy:		19.78 %
Epoch 321 of 2000 took 0.096s
  training loss:		2.288935
  validation loss:		2.237640
  validation accuracy:		16.30 %
Epoch 322 of 2000 took 0.097s
  training loss:		2.289108
  validation loss:		2.238976
  validation accuracy:		20.22 %
Epoch 323 of 2000 took 0.096s
  training loss:		2.288310
  validation loss:		2.236302
  validation accuracy:		23.48 %
Epoch 324 of 2000 took 0.097s
  training loss:		2.289959
  validation loss:		2.237162
  validation accuracy:		21.52 %
Epoch 325 of 2000 took 0.096s
  training loss:		2.287547
  validation loss:		2.236293
  validation accuracy:		22.39 %
Epoch 326 of 2000 took 0.096s
  training loss:		2.287869
  validation loss:		2.237582
  validation accuracy:		15.11 %
Epoch 327 of 2000 took 0.096s
  training loss:		2.287742
  validation loss:		2.232332
  validation accuracy:		19.89 %
Epoch 328 of 2000 took 0.097s
  training loss:		2.287875
  validation loss:		2.231896
  validation accuracy:		23.91 %
Epoch 329 of 2000 took 0.097s
  training loss:		2.287472
  validation loss:		2.237871
  validation accuracy:		15.54 %
Epoch 330 of 2000 took 0.097s
  training loss:		2.287835
  validation loss:		2.235828
  validation accuracy:		15.76 %
Epoch 331 of 2000 took 0.096s
  training loss:		2.287231
  validation loss:		2.233791
  validation accuracy:		22.50 %
Epoch 332 of 2000 took 0.096s
  training loss:		2.285076
  validation loss:		2.232972
  validation accuracy:		19.67 %
Epoch 333 of 2000 took 0.096s
  training loss:		2.286444
  validation loss:		2.231959
  validation accuracy:		27.39 %
Epoch 334 of 2000 took 0.097s
  training loss:		2.287097
  validation loss:		2.232178
  validation accuracy:		13.80 %
Epoch 335 of 2000 took 0.096s
  training loss:		2.286801
  validation loss:		2.233949
  validation accuracy:		21.30 %
Epoch 336 of 2000 took 0.096s
  training loss:		2.287442
  validation loss:		2.237880
  validation accuracy:		17.93 %
Epoch 337 of 2000 took 0.096s
  training loss:		2.287083
  validation loss:		2.233404
  validation accuracy:		20.43 %
Epoch 338 of 2000 took 0.096s
  training loss:		2.286762
  validation loss:		2.238783
  validation accuracy:		27.07 %
Epoch 339 of 2000 took 0.097s
  training loss:		2.286539
  validation loss:		2.231158
  validation accuracy:		22.28 %
Epoch 340 of 2000 took 0.097s
  training loss:		2.285246
  validation loss:		2.233554
  validation accuracy:		21.30 %
Epoch 341 of 2000 took 0.096s
  training loss:		2.286144
  validation loss:		2.231544
  validation accuracy:		25.22 %
Epoch 342 of 2000 took 0.096s
  training loss:		2.285597
  validation loss:		2.230843
  validation accuracy:		23.70 %
Epoch 343 of 2000 took 0.096s
  training loss:		2.284872
  validation loss:		2.232513
  validation accuracy:		22.83 %
Epoch 344 of 2000 took 0.096s
  training loss:		2.283973
  validation loss:		2.234417
  validation accuracy:		15.22 %
Epoch 345 of 2000 took 0.096s
  training loss:		2.283718
  validation loss:		2.229335
  validation accuracy:		20.87 %
Epoch 346 of 2000 took 0.096s
  training loss:		2.284475
  validation loss:		2.230518
  validation accuracy:		24.67 %
Epoch 347 of 2000 took 0.097s
  training loss:		2.285032
  validation loss:		2.228408
  validation accuracy:		25.87 %
Epoch 348 of 2000 took 0.096s
  training loss:		2.284053
  validation loss:		2.235676
  validation accuracy:		20.87 %
Epoch 349 of 2000 took 0.096s
  training loss:		2.283298
  validation loss:		2.227888
  validation accuracy:		19.24 %
Epoch 350 of 2000 took 0.096s
  training loss:		2.282538
  validation loss:		2.228192
  validation accuracy:		22.83 %
Epoch 351 of 2000 took 0.096s
  training loss:		2.282310
  validation loss:		2.227698
  validation accuracy:		21.85 %
Epoch 352 of 2000 took 0.096s
  training loss:		2.281763
  validation loss:		2.229688
  validation accuracy:		20.33 %
Epoch 353 of 2000 took 0.096s
  training loss:		2.281896
  validation loss:		2.223992
  validation accuracy:		24.57 %
Epoch 354 of 2000 took 0.096s
  training loss:		2.280972
  validation loss:		2.229741
  validation accuracy:		18.48 %
Epoch 355 of 2000 took 0.097s
  training loss:		2.279201
  validation loss:		2.227601
  validation accuracy:		18.15 %
Epoch 356 of 2000 took 0.096s
  training loss:		2.279129
  validation loss:		2.224351
  validation accuracy:		23.80 %
Epoch 357 of 2000 took 0.096s
  training loss:		2.279426
  validation loss:		2.221005
  validation accuracy:		17.61 %
Epoch 358 of 2000 took 0.096s
  training loss:		2.280341
  validation loss:		2.223061
  validation accuracy:		24.13 %
Epoch 359 of 2000 took 0.096s
  training loss:		2.277607
  validation loss:		2.229229
  validation accuracy:		28.26 %
Epoch 360 of 2000 took 0.097s
  training loss:		2.277955
  validation loss:		2.228333
  validation accuracy:		16.96 %
Epoch 361 of 2000 took 0.097s
  training loss:		2.277552
  validation loss:		2.221933
  validation accuracy:		17.50 %
Epoch 362 of 2000 took 0.096s
  training loss:		2.276767
  validation loss:		2.221784
  validation accuracy:		23.80 %
Epoch 363 of 2000 took 0.096s
  training loss:		2.276202
  validation loss:		2.225562
  validation accuracy:		21.52 %
Epoch 364 of 2000 took 0.096s
  training loss:		2.274555
  validation loss:		2.222283
  validation accuracy:		22.93 %
Epoch 365 of 2000 took 0.096s
  training loss:		2.273747
  validation loss:		2.217749
  validation accuracy:		24.67 %
Epoch 366 of 2000 took 0.096s
  training loss:		2.273313
  validation loss:		2.218722
  validation accuracy:		21.74 %
Epoch 367 of 2000 took 0.096s
  training loss:		2.272331
  validation loss:		2.215734
  validation accuracy:		22.61 %
Epoch 368 of 2000 took 0.096s
  training loss:		2.270096
  validation loss:		2.216192
  validation accuracy:		23.70 %
Epoch 369 of 2000 took 0.096s
  training loss:		2.269633
  validation loss:		2.212504
  validation accuracy:		21.52 %
Epoch 370 of 2000 took 0.096s
  training loss:		2.268780
  validation loss:		2.209421
  validation accuracy:		24.02 %
Epoch 371 of 2000 took 0.097s
  training loss:		2.268360
  validation loss:		2.213468
  validation accuracy:		21.41 %
Epoch 372 of 2000 took 0.096s
  training loss:		2.267175
  validation loss:		2.214557
  validation accuracy:		24.46 %
Epoch 373 of 2000 took 0.096s
  training loss:		2.264233
  validation loss:		2.208066
  validation accuracy:		26.30 %
Epoch 374 of 2000 took 0.096s
  training loss:		2.262710
  validation loss:		2.206217
  validation accuracy:		22.72 %
Epoch 375 of 2000 took 0.096s
  training loss:		2.260760
  validation loss:		2.203264
  validation accuracy:		22.72 %
Epoch 376 of 2000 took 0.096s
  training loss:		2.258706
  validation loss:		2.200773
  validation accuracy:		25.54 %
Epoch 377 of 2000 took 0.096s
  training loss:		2.256870
  validation loss:		2.198127
  validation accuracy:		29.57 %
Epoch 378 of 2000 took 0.096s
  training loss:		2.254323
  validation loss:		2.191939
  validation accuracy:		23.37 %
Epoch 379 of 2000 took 0.096s
  training loss:		2.252582
  validation loss:		2.196547
  validation accuracy:		23.70 %
Epoch 380 of 2000 took 0.097s
  training loss:		2.249317
  validation loss:		2.193035
  validation accuracy:		26.09 %
Epoch 381 of 2000 took 0.096s
  training loss:		2.246138
  validation loss:		2.184957
  validation accuracy:		24.89 %
Epoch 382 of 2000 took 0.096s
  training loss:		2.244004
  validation loss:		2.182523
  validation accuracy:		27.93 %
Epoch 383 of 2000 took 0.096s
  training loss:		2.239094
  validation loss:		2.177279
  validation accuracy:		23.48 %
Epoch 384 of 2000 took 0.096s
  training loss:		2.235849
  validation loss:		2.171458
  validation accuracy:		26.52 %
Epoch 385 of 2000 took 0.096s
  training loss:		2.229842
  validation loss:		2.163952
  validation accuracy:		25.00 %
Epoch 386 of 2000 took 0.097s
  training loss:		2.224774
  validation loss:		2.159910
  validation accuracy:		30.43 %
Epoch 387 of 2000 took 0.096s
  training loss:		2.218356
  validation loss:		2.154600
  validation accuracy:		25.22 %
Epoch 388 of 2000 took 0.096s
  training loss:		2.213336
  validation loss:		2.146563
  validation accuracy:		27.83 %
Epoch 389 of 2000 took 0.096s
  training loss:		2.204339
  validation loss:		2.137766
  validation accuracy:		28.26 %
Epoch 390 of 2000 took 0.096s
  training loss:		2.193782
  validation loss:		2.123933
  validation accuracy:		27.72 %
Epoch 391 of 2000 took 0.096s
  training loss:		2.185887
  validation loss:		2.112419
  validation accuracy:		27.61 %
Epoch 392 of 2000 took 0.101s
  training loss:		2.173682
  validation loss:		2.100343
  validation accuracy:		30.22 %
Epoch 393 of 2000 took 0.106s
  training loss:		2.160488
  validation loss:		2.081490
  validation accuracy:		29.57 %
Epoch 394 of 2000 took 0.112s
  training loss:		2.147468
  validation loss:		2.063724
  validation accuracy:		31.63 %
Epoch 395 of 2000 took 0.135s
  training loss:		2.129546
  validation loss:		2.046602
  validation accuracy:		32.83 %
Epoch 396 of 2000 took 0.099s
  training loss:		2.108644
  validation loss:		2.019595
  validation accuracy:		31.30 %
Epoch 397 of 2000 took 0.097s
  training loss:		2.090996
  validation loss:		1.994942
  validation accuracy:		31.85 %
Epoch 398 of 2000 took 0.100s
  training loss:		2.064289
  validation loss:		1.968710
  validation accuracy:		31.30 %
Epoch 399 of 2000 took 0.103s
  training loss:		2.040087
  validation loss:		1.936959
  validation accuracy:		34.13 %
Epoch 400 of 2000 took 0.103s
  training loss:		2.012970
  validation loss:		1.907085
  validation accuracy:		35.87 %
Epoch 401 of 2000 took 0.100s
  training loss:		1.986267
  validation loss:		1.876215
  validation accuracy:		35.00 %
Epoch 402 of 2000 took 0.100s
  training loss:		1.955394
  validation loss:		1.843078
  validation accuracy:		35.11 %
Epoch 403 of 2000 took 0.100s
  training loss:		1.926737
  validation loss:		1.813261
  validation accuracy:		35.76 %
Epoch 404 of 2000 took 0.100s
  training loss:		1.902313
  validation loss:		1.784685
  validation accuracy:		36.96 %
Epoch 405 of 2000 took 0.100s
  training loss:		1.870921
  validation loss:		1.756673
  validation accuracy:		37.17 %
Epoch 406 of 2000 took 0.100s
  training loss:		1.849346
  validation loss:		1.731490
  validation accuracy:		37.50 %
Epoch 407 of 2000 took 0.100s
  training loss:		1.817848
  validation loss:		1.706254
  validation accuracy:		37.17 %
Epoch 408 of 2000 took 0.100s
  training loss:		1.794887
  validation loss:		1.688905
  validation accuracy:		36.74 %
Epoch 409 of 2000 took 0.100s
  training loss:		1.782544
  validation loss:		1.661687
  validation accuracy:		39.02 %
Epoch 410 of 2000 took 0.101s
  training loss:		1.758199
  validation loss:		1.641253
  validation accuracy:		39.67 %
Epoch 411 of 2000 took 0.101s
  training loss:		1.745075
  validation loss:		1.622984
  validation accuracy:		39.35 %
Epoch 412 of 2000 took 0.100s
  training loss:		1.726556
  validation loss:		1.606727
  validation accuracy:		38.80 %
Epoch 413 of 2000 took 0.100s
  training loss:		1.701203
  validation loss:		1.590725
  validation accuracy:		39.67 %
Epoch 414 of 2000 took 0.101s
  training loss:		1.687174
  validation loss:		1.574249
  validation accuracy:		41.30 %
Epoch 415 of 2000 took 0.100s
  training loss:		1.673485
  validation loss:		1.558976
  validation accuracy:		40.76 %
Epoch 416 of 2000 took 0.101s
  training loss:		1.660000
  validation loss:		1.543342
  validation accuracy:		41.63 %
Epoch 417 of 2000 took 0.101s
  training loss:		1.638573
  validation loss:		1.532384
  validation accuracy:		40.00 %
Epoch 418 of 2000 took 0.106s
  training loss:		1.629345
  validation loss:		1.515757
  validation accuracy:		41.41 %
Epoch 419 of 2000 took 0.105s
  training loss:		1.609246
  validation loss:		1.508837
  validation accuracy:		42.17 %
Epoch 420 of 2000 took 0.102s
  training loss:		1.593017
  validation loss:		1.491876
  validation accuracy:		41.96 %
Epoch 421 of 2000 took 0.101s
  training loss:		1.590969
  validation loss:		1.479706
  validation accuracy:		42.39 %
Epoch 422 of 2000 took 0.100s
  training loss:		1.568139
  validation loss:		1.467005
  validation accuracy:		42.07 %
Epoch 423 of 2000 took 0.100s
  training loss:		1.557731
  validation loss:		1.454500
  validation accuracy:		43.48 %
Epoch 424 of 2000 took 0.101s
  training loss:		1.552074
  validation loss:		1.446813
  validation accuracy:		44.35 %
Epoch 425 of 2000 took 0.103s
  training loss:		1.534729
  validation loss:		1.435626
  validation accuracy:		44.02 %
Epoch 426 of 2000 took 0.101s
  training loss:		1.529734
  validation loss:		1.430184
  validation accuracy:		44.35 %
Epoch 427 of 2000 took 0.100s
  training loss:		1.510940
  validation loss:		1.417885
  validation accuracy:		45.65 %
Epoch 428 of 2000 took 0.100s
  training loss:		1.507363
  validation loss:		1.415930
  validation accuracy:		45.98 %
Epoch 429 of 2000 took 0.100s
  training loss:		1.500255
  validation loss:		1.399014
  validation accuracy:		45.54 %
Epoch 430 of 2000 took 0.101s
  training loss:		1.486962
  validation loss:		1.392280
  validation accuracy:		45.43 %
Epoch 431 of 2000 took 0.101s
  training loss:		1.478410
  validation loss:		1.384631
  validation accuracy:		46.20 %
Epoch 432 of 2000 took 0.100s
  training loss:		1.466935
  validation loss:		1.377375
  validation accuracy:		47.07 %
Epoch 433 of 2000 took 0.102s
  training loss:		1.454335
  validation loss:		1.373566
  validation accuracy:		46.74 %
Epoch 434 of 2000 took 0.123s
  training loss:		1.457685
  validation loss:		1.367235
  validation accuracy:		47.39 %
Epoch 435 of 2000 took 0.136s
  training loss:		1.447776
  validation loss:		1.372870
  validation accuracy:		47.17 %
Epoch 436 of 2000 took 0.100s
  training loss:		1.447481
  validation loss:		1.360589
  validation accuracy:		46.74 %
Epoch 437 of 2000 took 0.101s
  training loss:		1.435547
  validation loss:		1.354959
  validation accuracy:		47.93 %
Epoch 438 of 2000 took 0.102s
  training loss:		1.432190
  validation loss:		1.349529
  validation accuracy:		47.28 %
Epoch 439 of 2000 took 0.110s
  training loss:		1.433606
  validation loss:		1.357680
  validation accuracy:		48.48 %
Epoch 440 of 2000 took 0.130s
  training loss:		1.431897
  validation loss:		1.405814
  validation accuracy:		46.52 %
Epoch 441 of 2000 took 0.098s
  training loss:		1.422985
  validation loss:		1.372170
  validation accuracy:		46.85 %
Epoch 442 of 2000 took 0.102s
  training loss:		1.423339
  validation loss:		1.381693
  validation accuracy:		47.72 %
Epoch 443 of 2000 took 0.097s
  training loss:		1.410556
  validation loss:		1.332114
  validation accuracy:		48.80 %
Epoch 444 of 2000 took 0.100s
  training loss:		1.419079
  validation loss:		1.388417
  validation accuracy:		45.87 %
Epoch 445 of 2000 took 0.101s
  training loss:		1.416680
  validation loss:		1.329548
  validation accuracy:		49.24 %
Epoch 446 of 2000 took 0.100s
  training loss:		1.423866
  validation loss:		1.349459
  validation accuracy:		48.80 %
Epoch 447 of 2000 took 0.100s
  training loss:		1.470480
  validation loss:		1.333153
  validation accuracy:		48.59 %
Epoch 448 of 2000 took 0.100s
  training loss:		1.398482
  validation loss:		1.323293
  validation accuracy:		49.46 %
Epoch 449 of 2000 took 0.100s
  training loss:		1.390147
  validation loss:		1.326138
  validation accuracy:		49.57 %
Epoch 450 of 2000 took 0.098s
  training loss:		1.386957
  validation loss:		1.325655
  validation accuracy:		48.80 %
Epoch 451 of 2000 took 0.097s
  training loss:		1.395798
  validation loss:		1.316735
  validation accuracy:		50.98 %
Epoch 452 of 2000 took 0.096s
  training loss:		1.389337
  validation loss:		1.345194
  validation accuracy:		48.37 %
Epoch 453 of 2000 took 0.097s
  training loss:		1.416628
  validation loss:		1.354091
  validation accuracy:		49.67 %
Epoch 454 of 2000 took 0.096s
  training loss:		1.383320
  validation loss:		1.354024
  validation accuracy:		48.48 %
Epoch 455 of 2000 took 0.096s
  training loss:		1.373691
  validation loss:		1.351518
  validation accuracy:		48.15 %
Epoch 456 of 2000 took 0.096s
  training loss:		1.380983
  validation loss:		1.334054
  validation accuracy:		50.54 %
Epoch 457 of 2000 took 0.096s
  training loss:		1.378683
  validation loss:		1.308483
  validation accuracy:		51.74 %
Epoch 458 of 2000 took 0.096s
  training loss:		1.629917
  validation loss:		1.721240
  validation accuracy:		37.83 %
Epoch 459 of 2000 took 0.097s
  training loss:		1.480705
  validation loss:		1.352097
  validation accuracy:		50.11 %
Epoch 460 of 2000 took 0.097s
  training loss:		1.365833
  validation loss:		1.362758
  validation accuracy:		50.65 %
Epoch 461 of 2000 took 0.097s
  training loss:		1.375699
  validation loss:		1.328154
  validation accuracy:		50.54 %
Epoch 462 of 2000 took 0.096s
  training loss:		1.376918
  validation loss:		1.308378
  validation accuracy:		52.07 %
Epoch 463 of 2000 took 0.096s
  training loss:		1.427342
  validation loss:		1.508646
  validation accuracy:		41.96 %
Epoch 464 of 2000 took 0.096s
  training loss:		1.438846
  validation loss:		1.315126
  validation accuracy:		52.17 %
Epoch 465 of 2000 took 0.097s
  training loss:		1.380199
  validation loss:		1.310935
  validation accuracy:		51.52 %
Epoch 466 of 2000 took 0.096s
  training loss:		1.431932
  validation loss:		1.425961
  validation accuracy:		45.76 %
Epoch 467 of 2000 took 0.096s
  training loss:		1.387487
  validation loss:		1.306192
  validation accuracy:		52.28 %
Epoch 468 of 2000 took 0.096s
  training loss:		1.359099
  validation loss:		1.336281
  validation accuracy:		49.35 %
Epoch 469 of 2000 took 0.096s
  training loss:		1.385273
  validation loss:		1.308602
  validation accuracy:		52.28 %
Epoch 470 of 2000 took 0.097s
  training loss:		1.376906
  validation loss:		1.320461
  validation accuracy:		51.96 %
Epoch 471 of 2000 took 0.097s
  training loss:		1.364963
  validation loss:		1.310399
  validation accuracy:		52.72 %
Epoch 472 of 2000 took 0.096s
  training loss:		1.407537
  validation loss:		1.387272
  validation accuracy:		47.07 %
Epoch 473 of 2000 took 0.097s
  training loss:		1.380186
  validation loss:		1.369992
  validation accuracy:		50.00 %
Epoch 474 of 2000 took 0.096s
  training loss:		1.419544
  validation loss:		1.327495
  validation accuracy:		50.98 %
Epoch 475 of 2000 took 0.097s
  training loss:		1.366779
  validation loss:		1.380205
  validation accuracy:		47.72 %
Epoch 476 of 2000 took 0.097s
  training loss:		1.368198
  validation loss:		1.304967
  validation accuracy:		53.15 %
Epoch 477 of 2000 took 0.097s
  training loss:		1.350543
  validation loss:		1.301088
  validation accuracy:		52.39 %
Epoch 478 of 2000 took 0.097s
  training loss:		1.339052
  validation loss:		1.300837
  validation accuracy:		51.63 %
Epoch 479 of 2000 took 0.097s
  training loss:		1.383173
  validation loss:		1.357386
  validation accuracy:		48.26 %
Epoch 480 of 2000 took 0.097s
  training loss:		1.430015
  validation loss:		1.323655
  validation accuracy:		52.83 %
Epoch 481 of 2000 took 0.097s
  training loss:		1.341943
  validation loss:		1.317162
  validation accuracy:		52.17 %
Epoch 482 of 2000 took 0.096s
  training loss:		1.336198
  validation loss:		1.306195
  validation accuracy:		53.37 %
Epoch 483 of 2000 took 0.096s
  training loss:		1.352488
  validation loss:		1.332663
  validation accuracy:		51.30 %
Epoch 484 of 2000 took 0.096s
  training loss:		1.355435
  validation loss:		1.303686
  validation accuracy:		51.41 %
Epoch 485 of 2000 took 0.096s
  training loss:		1.328023
  validation loss:		1.293925
  validation accuracy:		52.39 %
Epoch 486 of 2000 took 0.096s
  training loss:		1.344327
  validation loss:		1.311918
  validation accuracy:		51.30 %
Epoch 487 of 2000 took 0.096s
  training loss:		1.406203
  validation loss:		1.394058
  validation accuracy:		48.91 %
Epoch 488 of 2000 took 0.096s
  training loss:		1.379682
  validation loss:		1.303123
  validation accuracy:		51.74 %
Epoch 489 of 2000 took 0.096s
  training loss:		1.339446
  validation loss:		1.296240
  validation accuracy:		53.04 %
Epoch 490 of 2000 took 0.096s
  training loss:		1.338230
  validation loss:		1.300807
  validation accuracy:		52.17 %
Epoch 491 of 2000 took 0.097s
  training loss:		1.481950
  validation loss:		1.513710
  validation accuracy:		44.13 %
Epoch 492 of 2000 took 0.096s
  training loss:		1.430377
  validation loss:		1.326679
  validation accuracy:		51.52 %
Epoch 493 of 2000 took 0.096s
  training loss:		1.354773
  validation loss:		1.318315
  validation accuracy:		50.87 %
Epoch 494 of 2000 took 0.097s
  training loss:		1.352393
  validation loss:		1.312039
  validation accuracy:		53.26 %
Epoch 495 of 2000 took 0.096s
  training loss:		1.333924
  validation loss:		1.311055
  validation accuracy:		50.98 %
Epoch 496 of 2000 took 0.097s
  training loss:		1.347733
  validation loss:		1.298401
  validation accuracy:		53.04 %
Epoch 497 of 2000 took 0.096s
  training loss:		1.350644
  validation loss:		1.300558
  validation accuracy:		52.72 %
Epoch 498 of 2000 took 0.096s
  training loss:		1.330870
  validation loss:		1.340628
  validation accuracy:		50.33 %
Epoch 499 of 2000 took 0.097s
  training loss:		1.348056
  validation loss:		1.335539
  validation accuracy:		50.87 %
Epoch 500 of 2000 took 0.096s
  training loss:		1.335214
  validation loss:		1.295208
  validation accuracy:		52.61 %
Epoch 501 of 2000 took 0.097s
  training loss:		1.392007
  validation loss:		1.431510
  validation accuracy:		45.43 %
Epoch 502 of 2000 took 0.097s
  training loss:		1.442581
  validation loss:		1.298642
  validation accuracy:		53.04 %
Epoch 503 of 2000 took 0.096s
  training loss:		1.340550
  validation loss:		1.305141
  validation accuracy:		52.28 %
Epoch 504 of 2000 took 0.097s
  training loss:		1.327014
  validation loss:		1.303501
  validation accuracy:		51.30 %
Epoch 505 of 2000 took 0.096s
  training loss:		1.369911
  validation loss:		1.321111
  validation accuracy:		53.04 %
Epoch 506 of 2000 took 0.097s
  training loss:		1.336137
  validation loss:		1.294101
  validation accuracy:		52.83 %
Epoch 507 of 2000 took 0.097s
  training loss:		1.344187
  validation loss:		1.291639
  validation accuracy:		52.72 %
Epoch 508 of 2000 took 0.096s
  training loss:		1.333962
  validation loss:		1.305316
  validation accuracy:		53.37 %
Epoch 509 of 2000 took 0.096s
  training loss:		1.345499
  validation loss:		1.296194
  validation accuracy:		53.91 %
Epoch 510 of 2000 took 0.096s
  training loss:		1.330281
  validation loss:		1.298244
  validation accuracy:		52.07 %
Epoch 511 of 2000 took 0.096s
  training loss:		1.324590
  validation loss:		1.299526
  validation accuracy:		54.13 %
Epoch 512 of 2000 took 0.097s
  training loss:		1.336819
  validation loss:		1.299249
  validation accuracy:		51.52 %
Epoch 513 of 2000 took 0.097s
  training loss:		1.357410
  validation loss:		1.455832
  validation accuracy:		44.24 %
Epoch 514 of 2000 took 0.096s
  training loss:		1.354155
  validation loss:		1.296281
  validation accuracy:		52.83 %
Epoch 515 of 2000 took 0.097s
  training loss:		1.358468
  validation loss:		1.295233
  validation accuracy:		54.02 %
Epoch 516 of 2000 took 0.097s
  training loss:		1.320881
  validation loss:		1.359566
  validation accuracy:		48.91 %
Epoch 517 of 2000 took 0.097s
  training loss:		1.440407
  validation loss:		1.295613
  validation accuracy:		53.26 %
Epoch 518 of 2000 took 0.097s
  training loss:		1.332215
  validation loss:		1.302279
  validation accuracy:		52.07 %
Epoch 519 of 2000 took 0.097s
  training loss:		1.346065
  validation loss:		1.349519
  validation accuracy:		50.33 %
Epoch 520 of 2000 took 0.097s
  training loss:		1.385585
  validation loss:		1.387883
  validation accuracy:		49.89 %
Epoch 521 of 2000 took 0.097s
  training loss:		1.345928
  validation loss:		1.301673
  validation accuracy:		51.85 %
Epoch 522 of 2000 took 0.097s
  training loss:		1.333780
  validation loss:		1.297154
  validation accuracy:		52.93 %
Epoch 523 of 2000 took 0.097s
  training loss:		1.328928
  validation loss:		1.291672
  validation accuracy:		53.04 %
Epoch 524 of 2000 took 0.096s
  training loss:		1.336364
  validation loss:		1.315584
  validation accuracy:		53.26 %
Epoch 525 of 2000 took 0.097s
  training loss:		1.337288
  validation loss:		1.290338
  validation accuracy:		52.61 %
Epoch 526 of 2000 took 0.096s
  training loss:		1.345613
  validation loss:		1.300799
  validation accuracy:		51.74 %
Epoch 527 of 2000 took 0.097s
  training loss:		1.333122
  validation loss:		1.298668
  validation accuracy:		54.24 %
Epoch 528 of 2000 took 0.096s
  training loss:		1.341624
  validation loss:		1.298964
  validation accuracy:		53.04 %
Epoch 529 of 2000 took 0.096s
  training loss:		1.331924
  validation loss:		1.294107
  validation accuracy:		52.83 %
Epoch 530 of 2000 took 0.096s
  training loss:		1.327596
  validation loss:		1.296295
  validation accuracy:		51.96 %
Epoch 531 of 2000 took 0.097s
  training loss:		1.336513
  validation loss:		1.296092
  validation accuracy:		54.46 %
Epoch 532 of 2000 took 0.097s
  training loss:		1.337770
  validation loss:		1.399915
  validation accuracy:		47.28 %
Epoch 533 of 2000 took 0.097s
  training loss:		1.405330
  validation loss:		1.319510
  validation accuracy:		53.80 %
Epoch 534 of 2000 took 0.096s
  training loss:		1.341205
  validation loss:		1.302926
  validation accuracy:		53.15 %
Epoch 535 of 2000 took 0.097s
  training loss:		1.333277
  validation loss:		1.295624
  validation accuracy:		52.28 %
Epoch 536 of 2000 took 0.096s
  training loss:		1.340505
  validation loss:		1.380132
  validation accuracy:		50.65 %
Epoch 537 of 2000 took 0.097s
  training loss:		1.332178
  validation loss:		1.302487
  validation accuracy:		52.28 %
Epoch 538 of 2000 took 0.097s
  training loss:		1.318858
  validation loss:		1.318725
  validation accuracy:		50.65 %
Epoch 539 of 2000 took 0.097s
  training loss:		1.332752
  validation loss:		1.293936
  validation accuracy:		51.96 %
Epoch 540 of 2000 took 0.096s
  training loss:		1.317439
  validation loss:		1.295014
  validation accuracy:		53.80 %
Epoch 541 of 2000 took 0.096s
  training loss:		1.332197
  validation loss:		1.300907
  validation accuracy:		54.24 %
Epoch 542 of 2000 took 0.097s
  training loss:		1.356089
  validation loss:		1.335948
  validation accuracy:		49.89 %
Epoch 543 of 2000 took 0.097s
  training loss:		1.333055
  validation loss:		1.294351
  validation accuracy:		52.93 %
Epoch 544 of 2000 took 0.097s
  training loss:		1.352340
  validation loss:		1.292349
  validation accuracy:		53.04 %
Epoch 545 of 2000 took 0.097s
  training loss:		1.336743
  validation loss:		1.339017
  validation accuracy:		52.39 %
Epoch 546 of 2000 took 0.097s
  training loss:		1.346080
  validation loss:		1.297284
  validation accuracy:		53.59 %
Epoch 547 of 2000 took 0.096s
  training loss:		1.329689
  validation loss:		1.293850
  validation accuracy:		51.85 %
Epoch 548 of 2000 took 0.097s
  training loss:		1.323529
  validation loss:		1.320706
  validation accuracy:		50.54 %
Epoch 549 of 2000 took 0.097s
  training loss:		1.386507
  validation loss:		1.296864
  validation accuracy:		53.70 %
Epoch 550 of 2000 took 0.097s
  training loss:		1.339694
  validation loss:		1.294210
  validation accuracy:		52.50 %
Epoch 551 of 2000 took 0.097s
  training loss:		1.328315
  validation loss:		1.293116
  validation accuracy:		52.61 %
Epoch 552 of 2000 took 0.102s
  training loss:		1.351298
  validation loss:		1.299337
  validation accuracy:		52.07 %
Epoch 553 of 2000 took 0.097s
  training loss:		1.343213
  validation loss:		1.295075
  validation accuracy:		52.93 %
Epoch 554 of 2000 took 0.097s
  training loss:		1.333558
  validation loss:		1.299453
  validation accuracy:		52.61 %
Epoch 555 of 2000 took 0.096s
  training loss:		1.325807
  validation loss:		1.288626
  validation accuracy:		52.17 %
Epoch 556 of 2000 took 0.096s
  training loss:		1.315912
  validation loss:		1.294745
  validation accuracy:		52.72 %
Epoch 557 of 2000 took 0.096s
  training loss:		1.343884
  validation loss:		1.345038
  validation accuracy:		49.89 %
Epoch 558 of 2000 took 0.097s
  training loss:		1.339632
  validation loss:		1.298727
  validation accuracy:		52.28 %
Epoch 559 of 2000 took 0.096s
  training loss:		1.321137
  validation loss:		1.295557
  validation accuracy:		51.96 %
Epoch 560 of 2000 took 0.096s
  training loss:		1.331576
  validation loss:		1.349522
  validation accuracy:		48.59 %
Epoch 561 of 2000 took 0.096s
  training loss:		1.347700
  validation loss:		1.314730
  validation accuracy:		53.15 %
Epoch 562 of 2000 took 0.097s
  training loss:		1.328811
  validation loss:		1.291770
  validation accuracy:		52.61 %
Epoch 563 of 2000 took 0.097s
  training loss:		1.315511
  validation loss:		1.316577
  validation accuracy:		53.59 %
Epoch 564 of 2000 took 0.097s
  training loss:		1.343674
  validation loss:		1.295132
  validation accuracy:		52.28 %
Epoch 565 of 2000 took 0.096s
  training loss:		1.333659
  validation loss:		1.301549
  validation accuracy:		52.72 %
Epoch 566 of 2000 took 0.096s
  training loss:		1.328454
  validation loss:		1.294051
  validation accuracy:		52.50 %
Epoch 567 of 2000 took 0.096s
  training loss:		1.323247
  validation loss:		1.295524
  validation accuracy:		52.07 %
Epoch 568 of 2000 took 0.096s
  training loss:		1.320625
  validation loss:		1.296061
  validation accuracy:		52.07 %
Epoch 569 of 2000 took 0.097s
  training loss:		1.320165
  validation loss:		1.294605
  validation accuracy:		53.15 %
Epoch 570 of 2000 took 0.096s
  training loss:		1.319376
  validation loss:		1.313735
  validation accuracy:		50.87 %
Epoch 571 of 2000 took 0.096s
  training loss:		1.339755
  validation loss:		1.303341
  validation accuracy:		52.93 %
Epoch 572 of 2000 took 0.096s
  training loss:		1.333803
  validation loss:		1.295934
  validation accuracy:		52.50 %
Epoch 573 of 2000 took 0.096s
  training loss:		1.325452
  validation loss:		1.306603
  validation accuracy:		52.93 %
Epoch 574 of 2000 took 0.097s
  training loss:		1.327763
  validation loss:		1.313986
  validation accuracy:		50.87 %
Epoch 575 of 2000 took 0.096s
  training loss:		1.319856
  validation loss:		1.319481
  validation accuracy:		50.76 %
Epoch 576 of 2000 took 0.096s
  training loss:		1.320418
  validation loss:		1.292376
  validation accuracy:		52.83 %
Epoch 577 of 2000 took 0.096s
  training loss:		1.329834
  validation loss:		1.299910
  validation accuracy:		51.85 %
Epoch 578 of 2000 took 0.096s
  training loss:		1.329706
  validation loss:		1.290961
  validation accuracy:		52.61 %
Epoch 579 of 2000 took 0.096s
  training loss:		1.336453
  validation loss:		1.380994
  validation accuracy:		50.54 %
Epoch 580 of 2000 took 0.096s
  training loss:		1.426057
  validation loss:		1.297257
  validation accuracy:		53.48 %
Epoch 581 of 2000 took 0.096s
  training loss:		1.353545
  validation loss:		1.297539
  validation accuracy:		53.59 %
Epoch 582 of 2000 took 0.096s
  training loss:		1.319004
  validation loss:		1.308565
  validation accuracy:		53.80 %
Epoch 583 of 2000 took 0.096s
  training loss:		1.345799
  validation loss:		1.305025
  validation accuracy:		53.59 %
Epoch 584 of 2000 took 0.096s
  training loss:		1.319057
  validation loss:		1.313506
  validation accuracy:		50.87 %
Epoch 585 of 2000 took 0.096s
  training loss:		1.325353
  validation loss:		1.294235
  validation accuracy:		53.15 %
Epoch 586 of 2000 took 0.096s
  training loss:		1.319521
  validation loss:		1.293429
  validation accuracy:		52.17 %
Epoch 587 of 2000 took 0.096s
  training loss:		1.332896
  validation loss:		1.317575
  validation accuracy:		50.65 %
Epoch 588 of 2000 took 0.096s
  training loss:		1.377351
  validation loss:		1.298050
  validation accuracy:		53.15 %
Epoch 589 of 2000 took 0.096s
  training loss:		1.321902
  validation loss:		1.297556
  validation accuracy:		52.61 %
Epoch 590 of 2000 took 0.096s
  training loss:		1.324490
  validation loss:		1.291531
  validation accuracy:		52.28 %
Epoch 591 of 2000 took 0.096s
  training loss:		1.331487
  validation loss:		1.297860
  validation accuracy:		51.85 %
Epoch 592 of 2000 took 0.096s
  training loss:		1.315218
  validation loss:		1.302954
  validation accuracy:		51.85 %
Epoch 593 of 2000 took 0.096s
  training loss:		1.328199
  validation loss:		1.304188
  validation accuracy:		53.26 %
Epoch 594 of 2000 took 0.096s
  training loss:		1.335767
  validation loss:		1.294945
  validation accuracy:		53.15 %
Epoch 595 of 2000 took 0.097s
  training loss:		1.319875
  validation loss:		1.342721
  validation accuracy:		49.24 %
Epoch 596 of 2000 took 0.096s
  training loss:		1.331905
  validation loss:		1.300229
  validation accuracy:		52.28 %
Epoch 597 of 2000 took 0.096s
  training loss:		1.325103
  validation loss:		1.297727
  validation accuracy:		52.28 %
Epoch 598 of 2000 took 0.097s
  training loss:		1.334041
  validation loss:		1.295040
  validation accuracy:		51.85 %
Epoch 599 of 2000 took 0.096s
  training loss:		1.349197
  validation loss:		1.296224
  validation accuracy:		52.39 %
Epoch 600 of 2000 took 0.097s
  training loss:		1.305756
  validation loss:		1.296409
  validation accuracy:		53.15 %
Epoch 601 of 2000 took 0.097s
  training loss:		1.328330
  validation loss:		1.294513
  validation accuracy:		53.91 %
Epoch 602 of 2000 took 0.096s
  training loss:		1.324822
  validation loss:		1.300867
  validation accuracy:		53.26 %
Epoch 603 of 2000 took 0.097s
  training loss:		1.321932
  validation loss:		1.290152
  validation accuracy:		53.48 %
Epoch 604 of 2000 took 0.097s
  training loss:		1.317517
  validation loss:		1.294597
  validation accuracy:		53.37 %
Epoch 605 of 2000 took 0.096s
  training loss:		1.315160
  validation loss:		1.290639
  validation accuracy:		52.28 %
Epoch 606 of 2000 took 0.096s
  training loss:		1.318698
  validation loss:		1.337908
  validation accuracy:		49.78 %
Epoch 607 of 2000 took 0.096s
  training loss:		1.330836
  validation loss:		1.302944
  validation accuracy:		52.61 %
Epoch 608 of 2000 took 0.096s
  training loss:		1.320640
  validation loss:		1.303147
  validation accuracy:		51.09 %
Epoch 609 of 2000 took 0.096s
  training loss:		1.328256
  validation loss:		1.293388
  validation accuracy:		53.37 %
Epoch 610 of 2000 took 0.096s
  training loss:		1.332318
  validation loss:		1.339635
  validation accuracy:		49.57 %
Epoch 611 of 2000 took 0.096s
  training loss:		1.351252
  validation loss:		1.298178
  validation accuracy:		53.48 %
Epoch 612 of 2000 took 0.096s
  training loss:		1.333829
  validation loss:		1.326499
  validation accuracy:		53.15 %
Epoch 613 of 2000 took 0.096s
  training loss:		1.326459
  validation loss:		1.328914
  validation accuracy:		49.57 %
Epoch 614 of 2000 took 0.096s
  training loss:		1.337122
  validation loss:		1.292799
  validation accuracy:		51.30 %
Epoch 615 of 2000 took 0.097s
  training loss:		1.335260
  validation loss:		1.323874
  validation accuracy:		53.48 %
Epoch 616 of 2000 took 0.097s
  training loss:		1.356238
  validation loss:		1.298811
  validation accuracy:		52.50 %
Epoch 617 of 2000 took 0.096s
  training loss:		1.321482
  validation loss:		1.294964
  validation accuracy:		52.61 %
Epoch 618 of 2000 took 0.096s
  training loss:		1.329812
  validation loss:		1.300801
  validation accuracy:		52.28 %
Epoch 619 of 2000 took 0.096s
  training loss:		1.318936
  validation loss:		1.294860
  validation accuracy:		51.96 %
Epoch 620 of 2000 took 0.096s
  training loss:		1.321454
  validation loss:		1.315845
  validation accuracy:		53.04 %
Epoch 621 of 2000 took 0.096s
  training loss:		1.327950
  validation loss:		1.288958
  validation accuracy:		53.91 %
Epoch 622 of 2000 took 0.096s
  training loss:		1.329484
  validation loss:		1.313105
  validation accuracy:		52.83 %
Epoch 623 of 2000 took 0.096s
  training loss:		1.322330
  validation loss:		1.299561
  validation accuracy:		52.07 %
Epoch 624 of 2000 took 0.096s
  training loss:		1.336406
  validation loss:		1.305020
  validation accuracy:		51.41 %
Epoch 625 of 2000 took 0.097s
  training loss:		1.312267
  validation loss:		1.292733
  validation accuracy:		52.07 %
Epoch 626 of 2000 took 0.096s
  training loss:		1.328892
  validation loss:		1.297067
  validation accuracy:		51.74 %
Epoch 627 of 2000 took 0.096s
  training loss:		1.313724
  validation loss:		1.296812
  validation accuracy:		51.96 %
Epoch 628 of 2000 took 0.096s
  training loss:		1.330852
  validation loss:		1.293175
  validation accuracy:		52.83 %
Epoch 629 of 2000 took 0.097s
  training loss:		1.313176
  validation loss:		1.294008
  validation accuracy:		52.07 %
Epoch 630 of 2000 took 0.096s
  training loss:		1.316884
  validation loss:		1.320967
  validation accuracy:		51.09 %
Epoch 631 of 2000 took 0.096s
  training loss:		1.322524
  validation loss:		1.301232
  validation accuracy:		52.61 %
Epoch 632 of 2000 took 0.097s
  training loss:		1.317495
  validation loss:		1.298205
  validation accuracy:		52.61 %
Epoch 633 of 2000 took 0.096s
  training loss:		1.336489
  validation loss:		1.296938
  validation accuracy:		52.17 %
Epoch 634 of 2000 took 0.096s
  training loss:		1.321951
  validation loss:		1.294434
  validation accuracy:		52.28 %
Epoch 635 of 2000 took 0.096s
  training loss:		1.315582
  validation loss:		1.303754
  validation accuracy:		52.72 %
Epoch 636 of 2000 took 0.096s
  training loss:		1.315773
  validation loss:		1.289453
  validation accuracy:		52.17 %
Epoch 637 of 2000 took 0.096s
  training loss:		1.323529
  validation loss:		1.294510
  validation accuracy:		51.96 %
Epoch 638 of 2000 took 0.096s
  training loss:		1.319693
  validation loss:		1.296135
  validation accuracy:		52.17 %
Epoch 639 of 2000 took 0.096s
  training loss:		1.317336
  validation loss:		1.294800
  validation accuracy:		52.93 %
Epoch 640 of 2000 took 0.096s
  training loss:		1.319700
  validation loss:		1.299874
  validation accuracy:		52.61 %
Epoch 641 of 2000 took 0.097s
  training loss:		1.355961
  validation loss:		1.297734
  validation accuracy:		51.74 %
Epoch 642 of 2000 took 0.096s
  training loss:		1.321659
  validation loss:		1.293392
  validation accuracy:		51.41 %
Epoch 643 of 2000 took 0.096s
  training loss:		1.311052
  validation loss:		1.316925
  validation accuracy:		50.87 %
Epoch 644 of 2000 took 0.096s
  training loss:		1.317665
  validation loss:		1.301155
  validation accuracy:		51.74 %
Epoch 645 of 2000 took 0.096s
  training loss:		1.317135
  validation loss:		1.295664
  validation accuracy:		52.50 %
Epoch 646 of 2000 took 0.096s
  training loss:		1.325483
  validation loss:		1.307787
  validation accuracy:		52.28 %
Epoch 647 of 2000 took 0.097s
  training loss:		1.312662
  validation loss:		1.293261
  validation accuracy:		53.04 %
Epoch 648 of 2000 took 0.096s
  training loss:		1.319534
  validation loss:		1.305916
  validation accuracy:		50.87 %
Epoch 649 of 2000 took 0.096s
  training loss:		1.316966
  validation loss:		1.295815
  validation accuracy:		51.30 %
Epoch 650 of 2000 took 0.096s
  training loss:		1.310366
  validation loss:		1.322926
  validation accuracy:		51.30 %
Epoch 651 of 2000 took 0.096s
  training loss:		1.324393
  validation loss:		1.292972
  validation accuracy:		52.17 %
Epoch 652 of 2000 took 0.096s
  training loss:		1.325198
  validation loss:		1.300669
  validation accuracy:		51.63 %
Epoch 653 of 2000 took 0.096s
  training loss:		1.317070
  validation loss:		1.296737
  validation accuracy:		52.50 %
Epoch 654 of 2000 took 0.096s
  training loss:		1.323731
  validation loss:		1.296596
  validation accuracy:		51.30 %
Epoch 655 of 2000 took 0.096s
  training loss:		1.319896
  validation loss:		1.290000
  validation accuracy:		52.93 %
Epoch 656 of 2000 took 0.096s
  training loss:		1.318823
  validation loss:		1.291736
  validation accuracy:		52.83 %
Epoch 657 of 2000 took 0.100s
  training loss:		1.311256
  validation loss:		1.288606
  validation accuracy:		52.28 %
Epoch 658 of 2000 took 0.099s
  training loss:		1.330448
  validation loss:		1.299275
  validation accuracy:		51.85 %
Epoch 659 of 2000 took 0.099s
  training loss:		1.327195
  validation loss:		1.348175
  validation accuracy:		50.65 %
Epoch 660 of 2000 took 0.099s
  training loss:		1.328338
  validation loss:		1.306127
  validation accuracy:		52.93 %
Epoch 661 of 2000 took 0.099s
  training loss:		1.323258
  validation loss:		1.296157
  validation accuracy:		52.28 %
Epoch 662 of 2000 took 0.099s
  training loss:		1.332162
  validation loss:		1.302732
  validation accuracy:		51.52 %
Epoch 663 of 2000 took 0.100s
  training loss:		1.321866
  validation loss:		1.300078
  validation accuracy:		52.39 %
Epoch 664 of 2000 took 0.099s
  training loss:		1.318008
  validation loss:		1.296937
  validation accuracy:		52.28 %
Epoch 665 of 2000 took 0.099s
  training loss:		1.323966
  validation loss:		1.294492
  validation accuracy:		51.52 %
Epoch 666 of 2000 took 0.100s
  training loss:		1.319093
  validation loss:		1.301320
  validation accuracy:		52.50 %
Epoch 667 of 2000 took 0.100s
  training loss:		1.328979
  validation loss:		1.383585
  validation accuracy:		49.13 %
Epoch 668 of 2000 took 0.100s
  training loss:		1.345308
  validation loss:		1.291336
  validation accuracy:		51.85 %
Epoch 669 of 2000 took 0.099s
  training loss:		1.344028
  validation loss:		1.293590
  validation accuracy:		52.50 %
Epoch 670 of 2000 took 0.099s
  training loss:		1.324810
  validation loss:		1.293722
  validation accuracy:		52.39 %
Epoch 671 of 2000 took 0.099s
  training loss:		1.331364
  validation loss:		1.311049
  validation accuracy:		52.72 %
Epoch 672 of 2000 took 0.100s
  training loss:		1.325359
  validation loss:		1.321814
  validation accuracy:		51.52 %
Epoch 673 of 2000 took 0.099s
  training loss:		1.340087
  validation loss:		1.312798
  validation accuracy:		49.67 %
Epoch 674 of 2000 took 0.100s
  training loss:		1.313820
  validation loss:		1.332675
  validation accuracy:		49.13 %
Epoch 675 of 2000 took 0.099s
  training loss:		1.332759
  validation loss:		1.316260
  validation accuracy:		52.61 %
Epoch 676 of 2000 took 0.099s
  training loss:		1.348303
  validation loss:		1.303773
  validation accuracy:		51.20 %
Epoch 677 of 2000 took 0.097s
  training loss:		1.312710
  validation loss:		1.312838
  validation accuracy:		51.63 %
Epoch 678 of 2000 took 0.096s
  training loss:		1.316980
  validation loss:		1.297234
  validation accuracy:		52.72 %
Epoch 679 of 2000 took 0.096s
  training loss:		1.332875
  validation loss:		1.363226
  validation accuracy:		49.67 %
Epoch 680 of 2000 took 0.096s
  training loss:		1.333085
  validation loss:		1.294050
  validation accuracy:		50.87 %
Epoch 681 of 2000 took 0.096s
  training loss:		1.327341
  validation loss:		1.307889
  validation accuracy:		52.61 %
Epoch 682 of 2000 took 0.097s
  training loss:		1.344930
  validation loss:		1.303079
  validation accuracy:		51.52 %
Epoch 683 of 2000 took 0.096s
  training loss:		1.328289
  validation loss:		1.339583
  validation accuracy:		50.33 %
Epoch 684 of 2000 took 0.096s
  training loss:		1.340712
  validation loss:		1.304532
  validation accuracy:		53.26 %
Epoch 685 of 2000 took 0.098s
  training loss:		1.329802
  validation loss:		1.316234
  validation accuracy:		53.04 %
Epoch 686 of 2000 took 0.100s
  training loss:		1.325144
  validation loss:		1.292802
  validation accuracy:		52.83 %
Epoch 687 of 2000 took 0.099s
  training loss:		1.327499
  validation loss:		1.302170
  validation accuracy:		53.15 %
Epoch 688 of 2000 took 0.099s
  training loss:		1.322385
  validation loss:		1.302691
  validation accuracy:		52.72 %
Epoch 689 of 2000 took 0.099s
  training loss:		1.320656
  validation loss:		1.291376
  validation accuracy:		53.59 %
Epoch 690 of 2000 took 0.099s
  training loss:		1.321564
  validation loss:		1.303270
  validation accuracy:		51.41 %
Epoch 691 of 2000 took 0.099s
  training loss:		1.310257
  validation loss:		1.349884
  validation accuracy:		48.04 %
Epoch 692 of 2000 took 0.102s
  training loss:		1.328563
  validation loss:		1.296662
  validation accuracy:		53.70 %
Epoch 693 of 2000 took 0.101s
  training loss:		1.324470
  validation loss:		1.304822
  validation accuracy:		53.37 %
Epoch 694 of 2000 took 0.100s
  training loss:		1.338712
  validation loss:		1.292488
  validation accuracy:		50.33 %
Epoch 695 of 2000 took 0.099s
  training loss:		1.325325
  validation loss:		1.290640
  validation accuracy:		50.98 %
Epoch 696 of 2000 took 0.099s
  training loss:		1.316611
  validation loss:		1.289477
  validation accuracy:		53.37 %
Epoch 697 of 2000 took 0.100s
  training loss:		1.314030
  validation loss:		1.289469
  validation accuracy:		51.20 %
Epoch 698 of 2000 took 0.100s
  training loss:		1.323507
  validation loss:		1.296841
  validation accuracy:		51.09 %
Epoch 699 of 2000 took 0.099s
  training loss:		1.313799
  validation loss:		1.291702
  validation accuracy:		53.15 %
Epoch 700 of 2000 took 0.100s
  training loss:		1.322203
  validation loss:		1.303180
  validation accuracy:		51.09 %
Epoch 701 of 2000 took 0.099s
  training loss:		1.324009
  validation loss:		1.289275
  validation accuracy:		52.72 %
Epoch 702 of 2000 took 0.100s
  training loss:		1.321365
  validation loss:		1.299414
  validation accuracy:		51.20 %
Epoch 703 of 2000 took 0.099s
  training loss:		1.331694
  validation loss:		1.309912
  validation accuracy:		52.17 %
Epoch 704 of 2000 took 0.099s
  training loss:		1.312412
  validation loss:		1.289491
  validation accuracy:		52.72 %
Epoch 705 of 2000 took 0.099s
  training loss:		1.321905
  validation loss:		1.310136
  validation accuracy:		50.00 %
Epoch 706 of 2000 took 0.099s
  training loss:		1.322636
  validation loss:		1.296841
  validation accuracy:		50.76 %
Epoch 707 of 2000 took 0.100s
  training loss:		1.317266
  validation loss:		1.290621
  validation accuracy:		52.93 %
Epoch 708 of 2000 took 0.100s
  training loss:		1.331029
  validation loss:		1.297836
  validation accuracy:		51.20 %
Epoch 709 of 2000 took 0.099s
  training loss:		1.333680
  validation loss:		1.296946
  validation accuracy:		54.35 %
Epoch 710 of 2000 took 0.099s
  training loss:		1.309001
  validation loss:		1.293151
  validation accuracy:		51.96 %
Epoch 711 of 2000 took 0.099s
  training loss:		1.321583
  validation loss:		1.293478
  validation accuracy:		52.93 %
Epoch 712 of 2000 took 0.099s
  training loss:		1.323906
  validation loss:		1.289876
  validation accuracy:		53.37 %
Epoch 713 of 2000 took 0.099s
  training loss:		1.321204
  validation loss:		1.294011
  validation accuracy:		52.50 %
Epoch 714 of 2000 took 0.099s
  training loss:		1.318254
  validation loss:		1.302167
  validation accuracy:		50.98 %
Epoch 715 of 2000 took 0.099s
  training loss:		1.316788
  validation loss:		1.292071
  validation accuracy:		53.80 %
Epoch 716 of 2000 took 0.099s
  training loss:		1.332176
  validation loss:		1.296865
  validation accuracy:		51.30 %
Epoch 717 of 2000 took 0.100s
  training loss:		1.336884
  validation loss:		1.316773
  validation accuracy:		51.30 %
Epoch 718 of 2000 took 0.099s
  training loss:		1.322595
  validation loss:		1.296511
  validation accuracy:		53.04 %
Epoch 719 of 2000 took 0.099s
  training loss:		1.346429
  validation loss:		1.295685
  validation accuracy:		53.15 %
Epoch 720 of 2000 took 0.099s
  training loss:		1.319241
  validation loss:		1.298127
  validation accuracy:		52.28 %
Epoch 721 of 2000 took 0.099s
  training loss:		1.324164
  validation loss:		1.293083
  validation accuracy:		53.59 %
Epoch 722 of 2000 took 0.100s
  training loss:		1.312717
  validation loss:		1.295758
  validation accuracy:		51.74 %
Epoch 723 of 2000 took 0.100s
  training loss:		1.320659
  validation loss:		1.291237
  validation accuracy:		54.46 %
Epoch 724 of 2000 took 0.100s
  training loss:		1.318474
  validation loss:		1.292342
  validation accuracy:		52.28 %
Epoch 725 of 2000 took 0.098s
  training loss:		1.331097
  validation loss:		1.292935
  validation accuracy:		51.85 %
Epoch 726 of 2000 took 0.097s
  training loss:		1.331620
  validation loss:		1.295824
  validation accuracy:		52.93 %
Epoch 727 of 2000 took 0.096s
  training loss:		1.324660
  validation loss:		1.295383
  validation accuracy:		53.37 %
Epoch 728 of 2000 took 0.097s
  training loss:		1.339876
  validation loss:		1.295541
  validation accuracy:		53.80 %
Epoch 729 of 2000 took 0.096s
  training loss:		1.325856
  validation loss:		1.302450
  validation accuracy:		52.61 %
Epoch 730 of 2000 took 0.097s
  training loss:		1.306227
  validation loss:		1.290684
  validation accuracy:		53.48 %
Epoch 731 of 2000 took 0.097s
  training loss:		1.324731
  validation loss:		1.290744
  validation accuracy:		53.91 %
Epoch 732 of 2000 took 0.096s
  training loss:		1.317834
  validation loss:		1.296279
  validation accuracy:		52.50 %
Epoch 733 of 2000 took 0.096s
  training loss:		1.308654
  validation loss:		1.302941
  validation accuracy:		52.39 %
Epoch 734 of 2000 took 0.096s
  training loss:		1.347883
  validation loss:		1.308220
  validation accuracy:		52.28 %
Epoch 735 of 2000 took 0.096s
  training loss:		1.324320
  validation loss:		1.296249
  validation accuracy:		53.04 %
Epoch 736 of 2000 took 0.096s
  training loss:		1.323115
  validation loss:		1.293148
  validation accuracy:		53.26 %
Epoch 737 of 2000 took 0.096s
  training loss:		1.309059
  validation loss:		1.347985
  validation accuracy:		49.13 %
Epoch 738 of 2000 took 0.097s
  training loss:		1.317260
  validation loss:		1.291553
  validation accuracy:		53.70 %
Epoch 739 of 2000 took 0.096s
  training loss:		1.316989
  validation loss:		1.296130
  validation accuracy:		53.48 %
Epoch 740 of 2000 took 0.096s
  training loss:		1.329628
  validation loss:		1.313123
  validation accuracy:		50.87 %
Epoch 741 of 2000 took 0.096s
  training loss:		1.328854
  validation loss:		1.307586
  validation accuracy:		53.04 %
Epoch 742 of 2000 took 0.096s
  training loss:		1.321266
  validation loss:		1.296365
  validation accuracy:		53.26 %
Epoch 743 of 2000 took 0.096s
  training loss:		1.324895
  validation loss:		1.297106
  validation accuracy:		52.72 %
Epoch 744 of 2000 took 0.096s
  training loss:		1.323804
  validation loss:		1.291703
  validation accuracy:		53.15 %
Epoch 745 of 2000 took 0.096s
  training loss:		1.317670
  validation loss:		1.289857
  validation accuracy:		54.78 %
Epoch 746 of 2000 took 0.096s
  training loss:		1.305353
  validation loss:		1.298448
  validation accuracy:		52.61 %
Epoch 747 of 2000 took 0.097s
  training loss:		1.333425
  validation loss:		1.387766
  validation accuracy:		48.80 %
Epoch 748 of 2000 took 0.096s
  training loss:		1.341267
  validation loss:		1.295126
  validation accuracy:		54.46 %
Epoch 749 of 2000 took 0.097s
  training loss:		1.330050
  validation loss:		1.308578
  validation accuracy:		51.52 %
Epoch 750 of 2000 took 0.096s
  training loss:		1.334016
  validation loss:		1.301043
  validation accuracy:		53.91 %
Epoch 751 of 2000 took 0.096s
  training loss:		1.308959
  validation loss:		1.303629
  validation accuracy:		52.61 %
Epoch 752 of 2000 took 0.096s
  training loss:		1.321614
  validation loss:		1.291637
  validation accuracy:		52.17 %
Epoch 753 of 2000 took 0.096s
  training loss:		1.314101
  validation loss:		1.312925
  validation accuracy:		52.07 %
Epoch 754 of 2000 took 0.096s
  training loss:		1.320015
  validation loss:		1.290940
  validation accuracy:		54.13 %
Epoch 755 of 2000 took 0.097s
  training loss:		1.309256
  validation loss:		1.293105
  validation accuracy:		53.91 %
Epoch 756 of 2000 took 0.096s
  training loss:		1.320066
  validation loss:		1.291720
  validation accuracy:		54.02 %
Epoch 757 of 2000 took 0.097s
  training loss:		1.322815
  validation loss:		1.294676
  validation accuracy:		52.17 %
Epoch 758 of 2000 took 0.096s
  training loss:		1.315668
  validation loss:		1.295536
  validation accuracy:		53.80 %
Epoch 759 of 2000 took 0.097s
  training loss:		1.319709
  validation loss:		1.291241
  validation accuracy:		54.57 %
Epoch 760 of 2000 took 0.096s
  training loss:		1.323833
  validation loss:		1.291637
  validation accuracy:		54.24 %
Epoch 761 of 2000 took 0.096s
  training loss:		1.320349
  validation loss:		1.294139
  validation accuracy:		53.26 %
Epoch 762 of 2000 took 0.096s
  training loss:		1.333010
  validation loss:		1.313151
  validation accuracy:		51.96 %
Epoch 763 of 2000 took 0.096s
  training loss:		1.323360
  validation loss:		1.288766
  validation accuracy:		54.35 %
Epoch 764 of 2000 took 0.097s
  training loss:		1.322469
  validation loss:		1.294790
  validation accuracy:		52.61 %
Epoch 765 of 2000 took 0.096s
  training loss:		1.321831
  validation loss:		1.295881
  validation accuracy:		52.83 %
Epoch 766 of 2000 took 0.096s
  training loss:		1.324537
  validation loss:		1.292856
  validation accuracy:		54.24 %
Epoch 767 of 2000 took 0.097s
  training loss:		1.308225
  validation loss:		1.296161
  validation accuracy:		52.83 %
Epoch 768 of 2000 took 0.097s
  training loss:		1.345741
  validation loss:		1.329388
  validation accuracy:		49.13 %
Epoch 769 of 2000 took 0.096s
  training loss:		1.324585
  validation loss:		1.297112
  validation accuracy:		53.59 %
Epoch 770 of 2000 took 0.096s
  training loss:		1.314398
  validation loss:		1.297918
  validation accuracy:		53.26 %
Epoch 771 of 2000 took 0.096s
  training loss:		1.316609
  validation loss:		1.308575
  validation accuracy:		52.50 %
Epoch 772 of 2000 took 0.096s
  training loss:		1.322539
  validation loss:		1.309483
  validation accuracy:		51.74 %
Epoch 773 of 2000 took 0.096s
  training loss:		1.321122
  validation loss:		1.294725
  validation accuracy:		53.80 %
Epoch 774 of 2000 took 0.096s
  training loss:		1.322234
  validation loss:		1.292650
  validation accuracy:		53.59 %
Epoch 775 of 2000 took 0.096s
  training loss:		1.319716
  validation loss:		1.302483
  validation accuracy:		52.28 %
Epoch 776 of 2000 took 0.096s
  training loss:		1.311616
  validation loss:		1.298882
  validation accuracy:		52.17 %
Epoch 777 of 2000 took 0.096s
  training loss:		1.313267
  validation loss:		1.293299
  validation accuracy:		53.37 %
Epoch 778 of 2000 took 0.096s
  training loss:		1.316371
  validation loss:		1.293198
  validation accuracy:		52.28 %
Epoch 779 of 2000 took 0.096s
  training loss:		1.320598
  validation loss:		1.294039
  validation accuracy:		53.91 %
Epoch 780 of 2000 took 0.096s
  training loss:		1.313958
  validation loss:		1.289304
  validation accuracy:		54.46 %
Epoch 781 of 2000 took 0.096s
  training loss:		1.310144
  validation loss:		1.296551
  validation accuracy:		53.48 %
Epoch 782 of 2000 took 0.096s
  training loss:		1.313480
  validation loss:		1.292065
  validation accuracy:		55.00 %
Epoch 783 of 2000 took 0.096s
  training loss:		1.324117
  validation loss:		1.295041
  validation accuracy:		53.04 %
Epoch 784 of 2000 took 0.096s
  training loss:		1.311985
  validation loss:		1.292604
  validation accuracy:		54.57 %
Epoch 785 of 2000 took 0.096s
  training loss:		1.311270
  validation loss:		1.294086
  validation accuracy:		53.91 %
Epoch 786 of 2000 took 0.097s
  training loss:		1.310957
  validation loss:		1.295857
  validation accuracy:		54.24 %
Epoch 787 of 2000 took 0.096s
  training loss:		1.317909
  validation loss:		1.290533
  validation accuracy:		53.59 %
Epoch 788 of 2000 took 0.096s
  training loss:		1.316129
  validation loss:		1.292878
  validation accuracy:		53.15 %
Epoch 789 of 2000 took 0.097s
  training loss:		1.326529
  validation loss:		1.295848
  validation accuracy:		52.93 %
Epoch 790 of 2000 took 0.097s
  training loss:		1.302265
  validation loss:		1.290848
  validation accuracy:		54.57 %
Epoch 791 of 2000 took 0.096s
  training loss:		1.307777
  validation loss:		1.303625
  validation accuracy:		52.93 %
Epoch 792 of 2000 took 0.096s
  training loss:		1.310981
  validation loss:		1.291931
  validation accuracy:		53.37 %
Epoch 793 of 2000 took 0.096s
  training loss:		1.349650
  validation loss:		1.300750
  validation accuracy:		52.61 %
Epoch 794 of 2000 took 0.096s
  training loss:		1.315429
  validation loss:		1.296826
  validation accuracy:		54.13 %
Epoch 795 of 2000 took 0.096s
  training loss:		1.316026
  validation loss:		1.315190
  validation accuracy:		51.96 %
Epoch 796 of 2000 took 0.096s
  training loss:		1.325081
  validation loss:		1.312525
  validation accuracy:		52.17 %
Epoch 797 of 2000 took 0.096s
  training loss:		1.315551
  validation loss:		1.294372
  validation accuracy:		53.37 %
Epoch 798 of 2000 took 0.096s
  training loss:		1.321304
  validation loss:		1.317700
  validation accuracy:		52.07 %
Epoch 799 of 2000 took 0.096s
  training loss:		1.326384
  validation loss:		1.292961
  validation accuracy:		53.70 %
Epoch 800 of 2000 took 0.097s
  training loss:		1.321139
  validation loss:		1.292665
  validation accuracy:		54.35 %
Epoch 801 of 2000 took 0.096s
  training loss:		1.331919
  validation loss:		1.310224
  validation accuracy:		52.28 %
Epoch 802 of 2000 took 0.096s
  training loss:		1.322729
  validation loss:		1.294993
  validation accuracy:		53.15 %
Epoch 803 of 2000 took 0.097s
  training loss:		1.317147
  validation loss:		1.316712
  validation accuracy:		52.28 %
Epoch 804 of 2000 took 0.096s
  training loss:		1.324323
  validation loss:		1.297433
  validation accuracy:		53.59 %
Epoch 805 of 2000 took 0.097s
  training loss:		1.314632
  validation loss:		1.289705
  validation accuracy:		54.46 %
Epoch 806 of 2000 took 0.096s
  training loss:		1.313882
  validation loss:		1.299151
  validation accuracy:		53.15 %
Epoch 807 of 2000 took 0.096s
  training loss:		1.315327
  validation loss:		1.300542
  validation accuracy:		52.93 %
Epoch 808 of 2000 took 0.096s
  training loss:		1.318757
  validation loss:		1.295236
  validation accuracy:		52.61 %
Epoch 809 of 2000 took 0.097s
  training loss:		1.314797
  validation loss:		1.291449
  validation accuracy:		53.91 %
Epoch 810 of 2000 took 0.096s
  training loss:		1.306946
  validation loss:		1.292488
  validation accuracy:		53.15 %
Epoch 811 of 2000 took 0.096s
  training loss:		1.313818
  validation loss:		1.307471
  validation accuracy:		52.83 %
Epoch 812 of 2000 took 0.096s
  training loss:		1.313960
  validation loss:		1.310306
  validation accuracy:		52.39 %
Epoch 813 of 2000 took 0.096s
  training loss:		1.311333
  validation loss:		1.292176
  validation accuracy:		54.02 %
Epoch 814 of 2000 took 0.097s
  training loss:		1.316051
  validation loss:		1.294103
  validation accuracy:		53.15 %
Epoch 815 of 2000 took 0.096s
  training loss:		1.312142
  validation loss:		1.304617
  validation accuracy:		52.61 %
Epoch 816 of 2000 took 0.096s
  training loss:		1.312305
  validation loss:		1.291476
  validation accuracy:		52.39 %
Epoch 817 of 2000 took 0.097s
  training loss:		1.318747
  validation loss:		1.289110
  validation accuracy:		53.59 %
Epoch 818 of 2000 took 0.096s
  training loss:		1.302137
  validation loss:		1.294836
  validation accuracy:		53.59 %
Epoch 819 of 2000 took 0.096s
  training loss:		1.322324
  validation loss:		1.337222
  validation accuracy:		51.20 %
Epoch 820 of 2000 took 0.096s
  training loss:		1.323503
  validation loss:		1.294735
  validation accuracy:		53.80 %
Epoch 821 of 2000 took 0.097s
  training loss:		1.325868
  validation loss:		1.313170
  validation accuracy:		52.50 %
Epoch 822 of 2000 took 0.097s
  training loss:		1.322697
  validation loss:		1.307348
  validation accuracy:		52.39 %
Epoch 823 of 2000 took 0.099s
  training loss:		1.313994
  validation loss:		1.293592
  validation accuracy:		53.59 %
Epoch 824 of 2000 took 0.099s
  training loss:		1.310849
  validation loss:		1.295988
  validation accuracy:		53.59 %
Epoch 825 of 2000 took 0.100s
  training loss:		1.318484
  validation loss:		1.306750
  validation accuracy:		52.72 %
Epoch 826 of 2000 took 0.099s
  training loss:		1.319286
  validation loss:		1.297741
  validation accuracy:		54.02 %
Epoch 827 of 2000 took 0.099s
  training loss:		1.318328
  validation loss:		1.293932
  validation accuracy:		53.15 %
Epoch 828 of 2000 took 0.099s
  training loss:		1.314895
  validation loss:		1.313000
  validation accuracy:		52.93 %
Epoch 829 of 2000 took 0.099s
  training loss:		1.322886
  validation loss:		1.295035
  validation accuracy:		52.83 %
Epoch 830 of 2000 took 0.100s
  training loss:		1.315211
  validation loss:		1.291857
  validation accuracy:		53.26 %
Epoch 831 of 2000 took 0.100s
  training loss:		1.322707
  validation loss:		1.293421
  validation accuracy:		53.91 %
Epoch 832 of 2000 took 0.099s
  training loss:		1.319160
  validation loss:		1.292495
  validation accuracy:		53.04 %
Epoch 833 of 2000 took 0.099s
  training loss:		1.318545
  validation loss:		1.294077
  validation accuracy:		53.37 %
Epoch 834 of 2000 took 0.100s
  training loss:		1.333189
  validation loss:		1.314414
  validation accuracy:		51.96 %
Epoch 835 of 2000 took 0.099s
  training loss:		1.320213
  validation loss:		1.291579
  validation accuracy:		53.59 %
Epoch 836 of 2000 took 0.096s
  training loss:		1.319076
  validation loss:		1.292312
  validation accuracy:		54.02 %
Epoch 837 of 2000 took 0.096s
  training loss:		1.318092
  validation loss:		1.292928
  validation accuracy:		52.93 %
Epoch 838 of 2000 took 0.096s
  training loss:		1.318673
  validation loss:		1.294965
  validation accuracy:		52.93 %
Epoch 839 of 2000 took 0.096s
  training loss:		1.313313
  validation loss:		1.302179
  validation accuracy:		53.04 %
Epoch 840 of 2000 took 0.096s
  training loss:		1.320297
  validation loss:		1.294281
  validation accuracy:		53.48 %
Epoch 841 of 2000 took 0.096s
  training loss:		1.320869
  validation loss:		1.294980
  validation accuracy:		53.59 %
Epoch 842 of 2000 took 0.097s
  training loss:		1.312408
  validation loss:		1.293610
  validation accuracy:		53.37 %
Epoch 843 of 2000 took 0.096s
  training loss:		1.341772
  validation loss:		1.292589
  validation accuracy:		53.48 %
Epoch 844 of 2000 took 0.096s
  training loss:		1.326132
  validation loss:		1.293573
  validation accuracy:		53.59 %
Epoch 845 of 2000 took 0.096s
  training loss:		1.314748
  validation loss:		1.309966
  validation accuracy:		52.93 %
Epoch 846 of 2000 took 0.097s
  training loss:		1.319353
  validation loss:		1.293770
  validation accuracy:		53.91 %
Epoch 847 of 2000 took 0.099s
  training loss:		1.310678
  validation loss:		1.294239
  validation accuracy:		53.59 %
Epoch 848 of 2000 took 0.097s
  training loss:		1.313663
  validation loss:		1.294662
  validation accuracy:		53.04 %
Epoch 849 of 2000 took 0.096s
  training loss:		1.310119
  validation loss:		1.298284
  validation accuracy:		53.48 %
Epoch 850 of 2000 took 0.096s
  training loss:		1.324299
  validation loss:		1.292882
  validation accuracy:		53.26 %
Epoch 851 of 2000 took 0.096s
  training loss:		1.316470
  validation loss:		1.297266
  validation accuracy:		53.37 %
Epoch 852 of 2000 took 0.096s
  training loss:		1.320797
  validation loss:		1.319071
  validation accuracy:		51.30 %
Epoch 853 of 2000 took 0.096s
  training loss:		1.331139
  validation loss:		1.307404
  validation accuracy:		53.04 %
Epoch 854 of 2000 took 0.096s
  training loss:		1.319986
  validation loss:		1.344730
  validation accuracy:		48.80 %
Epoch 855 of 2000 took 0.096s
  training loss:		1.335298
  validation loss:		1.293014
  validation accuracy:		53.04 %
Epoch 856 of 2000 took 0.096s
  training loss:		1.321334
  validation loss:		1.299603
  validation accuracy:		52.39 %
Epoch 857 of 2000 took 0.096s
  training loss:		1.311315
  validation loss:		1.297399
  validation accuracy:		53.04 %
Epoch 858 of 2000 took 0.096s
  training loss:		1.317613
  validation loss:		1.301360
  validation accuracy:		52.93 %
Epoch 859 of 2000 took 0.096s
  training loss:		1.318819
  validation loss:		1.301163
  validation accuracy:		52.61 %
Epoch 860 of 2000 took 0.096s
  training loss:		1.314975
  validation loss:		1.294632
  validation accuracy:		53.26 %
Epoch 861 of 2000 took 0.096s
  training loss:		1.320924
  validation loss:		1.367417
  validation accuracy:		50.43 %
Epoch 862 of 2000 took 0.096s
  training loss:		1.327606
  validation loss:		1.295601
  validation accuracy:		53.48 %
Epoch 863 of 2000 took 0.096s
  training loss:		1.319434
  validation loss:		1.317709
  validation accuracy:		53.04 %
Epoch 864 of 2000 took 0.096s
  training loss:		1.322197
  validation loss:		1.291966
  validation accuracy:		53.15 %
Epoch 865 of 2000 took 0.096s
  training loss:		1.314653
  validation loss:		1.301851
  validation accuracy:		51.85 %
Epoch 866 of 2000 took 0.096s
  training loss:		1.329940
  validation loss:		1.304420
  validation accuracy:		52.72 %
Epoch 867 of 2000 took 0.096s
  training loss:		1.324808
  validation loss:		1.293591
  validation accuracy:		52.83 %
Epoch 868 of 2000 took 0.096s
  training loss:		1.321253
  validation loss:		1.299943
  validation accuracy:		53.04 %
Epoch 869 of 2000 took 0.096s
  training loss:		1.309662
  validation loss:		1.297200
  validation accuracy:		52.50 %
Epoch 870 of 2000 took 0.096s
  training loss:		1.319002
  validation loss:		1.291513
  validation accuracy:		52.72 %
Epoch 871 of 2000 took 0.096s
  training loss:		1.317961
  validation loss:		1.287410
  validation accuracy:		53.59 %
Epoch 872 of 2000 took 0.096s
  training loss:		1.314667
  validation loss:		1.287519
  validation accuracy:		53.80 %
Epoch 873 of 2000 took 0.096s
  training loss:		1.307710
  validation loss:		1.293559
  validation accuracy:		52.39 %
Epoch 874 of 2000 took 0.096s
  training loss:		1.307139
  validation loss:		1.295178
  validation accuracy:		52.61 %
Epoch 875 of 2000 took 0.096s
  training loss:		1.315236
  validation loss:		1.299570
  validation accuracy:		51.96 %
Epoch 876 of 2000 took 0.096s
  training loss:		1.323136
  validation loss:		1.291337
  validation accuracy:		53.48 %
Epoch 877 of 2000 took 0.096s
  training loss:		1.311944
  validation loss:		1.293014
  validation accuracy:		53.59 %
Epoch 878 of 2000 took 0.096s
  training loss:		1.316438
  validation loss:		1.313510
  validation accuracy:		51.41 %
Epoch 879 of 2000 took 0.097s
  training loss:		1.326238
  validation loss:		1.311772
  validation accuracy:		51.30 %
Epoch 880 of 2000 took 0.097s
  training loss:		1.315275
  validation loss:		1.292046
  validation accuracy:		53.48 %
Epoch 881 of 2000 took 0.096s
  training loss:		1.312117
  validation loss:		1.286349
  validation accuracy:		54.78 %
Epoch 882 of 2000 took 0.096s
  training loss:		1.314335
  validation loss:		1.291951
  validation accuracy:		53.59 %
Epoch 883 of 2000 took 0.097s
  training loss:		1.321410
  validation loss:		1.314357
  validation accuracy:		52.61 %
Epoch 884 of 2000 took 0.096s
  training loss:		1.317046
  validation loss:		1.293884
  validation accuracy:		53.15 %
Epoch 885 of 2000 took 0.096s
  training loss:		1.321313
  validation loss:		1.302398
  validation accuracy:		53.04 %
Epoch 886 of 2000 took 0.096s
  training loss:		1.309768
  validation loss:		1.288881
  validation accuracy:		53.91 %
Epoch 887 of 2000 took 0.097s
  training loss:		1.315791
  validation loss:		1.293570
  validation accuracy:		52.17 %
Epoch 888 of 2000 took 0.097s
  training loss:		1.325099
  validation loss:		1.295103
  validation accuracy:		53.48 %
Epoch 889 of 2000 took 0.096s
  training loss:		1.315752
  validation loss:		1.291905
  validation accuracy:		52.93 %
Epoch 890 of 2000 took 0.096s
  training loss:		1.324154
  validation loss:		1.291850
  validation accuracy:		52.50 %
Epoch 891 of 2000 took 0.097s
  training loss:		1.317048
  validation loss:		1.302138
  validation accuracy:		52.72 %
Epoch 892 of 2000 took 0.097s
  training loss:		1.317070
  validation loss:		1.291365
  validation accuracy:		53.26 %
Epoch 893 of 2000 took 0.096s
  training loss:		1.335749
  validation loss:		1.292281
  validation accuracy:		52.28 %
Epoch 894 of 2000 took 0.096s
  training loss:		1.315696
  validation loss:		1.290399
  validation accuracy:		52.72 %
Epoch 895 of 2000 took 0.096s
  training loss:		1.322216
  validation loss:		1.304572
  validation accuracy:		53.04 %
Epoch 896 of 2000 took 0.096s
  training loss:		1.325681
  validation loss:		1.292092
  validation accuracy:		53.91 %
Epoch 897 of 2000 took 0.096s
  training loss:		1.305831
  validation loss:		1.291023
  validation accuracy:		52.72 %
Epoch 898 of 2000 took 0.096s
  training loss:		1.314946
  validation loss:		1.296395
  validation accuracy:		53.37 %
Epoch 899 of 2000 took 0.096s
  training loss:		1.319547
  validation loss:		1.304422
  validation accuracy:		52.17 %
Epoch 900 of 2000 took 0.096s
  training loss:		1.314401
  validation loss:		1.289043
  validation accuracy:		54.13 %
Epoch 901 of 2000 took 0.096s
  training loss:		1.311621
  validation loss:		1.302189
  validation accuracy:		52.07 %
Epoch 902 of 2000 took 0.096s
  training loss:		1.315127
  validation loss:		1.294107
  validation accuracy:		52.93 %
Epoch 903 of 2000 took 0.096s
  training loss:		1.305286
  validation loss:		1.321242
  validation accuracy:		51.85 %
Epoch 904 of 2000 took 0.097s
  training loss:		1.314169
  validation loss:		1.291310
  validation accuracy:		53.26 %
Epoch 905 of 2000 took 0.096s
  training loss:		1.315226
  validation loss:		1.293635
  validation accuracy:		53.26 %
Epoch 906 of 2000 took 0.097s
  training loss:		1.312156
  validation loss:		1.291524
  validation accuracy:		52.28 %
Epoch 907 of 2000 took 0.096s
  training loss:		1.319296
  validation loss:		1.296902
  validation accuracy:		52.72 %
Epoch 908 of 2000 took 0.096s
  training loss:		1.315628
  validation loss:		1.296446
  validation accuracy:		52.39 %
Epoch 909 of 2000 took 0.096s
  training loss:		1.313337
  validation loss:		1.313697
  validation accuracy:		53.37 %
Epoch 910 of 2000 took 0.097s
  training loss:		1.315018
  validation loss:		1.294186
  validation accuracy:		52.61 %
Epoch 911 of 2000 took 0.096s
  training loss:		1.309515
  validation loss:		1.293702
  validation accuracy:		52.72 %
Epoch 912 of 2000 took 0.096s
  training loss:		1.314888
  validation loss:		1.314146
  validation accuracy:		53.04 %
Epoch 913 of 2000 took 0.096s
  training loss:		1.318985
  validation loss:		1.294759
  validation accuracy:		52.83 %
Epoch 914 of 2000 took 0.096s
  training loss:		1.315644
  validation loss:		1.290720
  validation accuracy:		53.80 %
Epoch 915 of 2000 took 0.096s
  training loss:		1.319237
  validation loss:		1.291055
  validation accuracy:		52.72 %
Epoch 916 of 2000 took 0.096s
  training loss:		1.305218
  validation loss:		1.300582
  validation accuracy:		52.72 %
Epoch 917 of 2000 took 0.096s
  training loss:		1.321124
  validation loss:		1.292841
  validation accuracy:		52.83 %
Epoch 918 of 2000 took 0.096s
  training loss:		1.310599
  validation loss:		1.295504
  validation accuracy:		52.28 %
Epoch 919 of 2000 took 0.096s
  training loss:		1.323228
  validation loss:		1.294443
  validation accuracy:		52.50 %
Epoch 920 of 2000 took 0.096s
  training loss:		1.311328
  validation loss:		1.290272
  validation accuracy:		52.61 %
Epoch 921 of 2000 took 0.096s
  training loss:		1.319986
  validation loss:		1.309187
  validation accuracy:		51.63 %
Epoch 922 of 2000 took 0.096s
  training loss:		1.337352
  validation loss:		1.340860
  validation accuracy:		51.20 %
Epoch 923 of 2000 took 0.096s
  training loss:		1.322290
  validation loss:		1.295316
  validation accuracy:		53.15 %
Epoch 924 of 2000 took 0.097s
  training loss:		1.314491
  validation loss:		1.308762
  validation accuracy:		52.17 %
Epoch 925 of 2000 took 0.096s
  training loss:		1.321762
  validation loss:		1.303216
  validation accuracy:		52.83 %
Epoch 926 of 2000 took 0.096s
  training loss:		1.312123
  validation loss:		1.312070
  validation accuracy:		53.37 %
Epoch 927 of 2000 took 0.096s
  training loss:		1.317049
  validation loss:		1.296574
  validation accuracy:		52.07 %
Epoch 928 of 2000 took 0.096s
  training loss:		1.312192
  validation loss:		1.291388
  validation accuracy:		52.28 %
Epoch 929 of 2000 took 0.097s
  training loss:		1.312046
  validation loss:		1.296860
  validation accuracy:		53.37 %
Epoch 930 of 2000 took 0.096s
  training loss:		1.303864
  validation loss:		1.290975
  validation accuracy:		52.61 %
Epoch 931 of 2000 took 0.096s
  training loss:		1.321072
  validation loss:		1.298236
  validation accuracy:		53.15 %
Epoch 932 of 2000 took 0.096s
  training loss:		1.316806
  validation loss:		1.313049
  validation accuracy:		53.15 %
Epoch 933 of 2000 took 0.096s
  training loss:		1.321607
  validation loss:		1.317220
  validation accuracy:		53.37 %
Epoch 934 of 2000 took 0.096s
  training loss:		1.317260
  validation loss:		1.295872
  validation accuracy:		52.17 %
Epoch 935 of 2000 took 0.096s
  training loss:		1.339624
  validation loss:		1.296593
  validation accuracy:		52.83 %
Epoch 936 of 2000 took 0.096s
  training loss:		1.324059
  validation loss:		1.294942
  validation accuracy:		52.50 %
Epoch 937 of 2000 took 0.096s
  training loss:		1.301531
  validation loss:		1.297294
  validation accuracy:		54.02 %
Epoch 938 of 2000 took 0.096s
  training loss:		1.332932
  validation loss:		1.288935
  validation accuracy:		53.80 %
Epoch 939 of 2000 took 0.096s
  training loss:		1.306157
  validation loss:		1.310130
  validation accuracy:		52.50 %
Epoch 940 of 2000 took 0.096s
  training loss:		1.311912
  validation loss:		1.291269
  validation accuracy:		52.83 %
Epoch 941 of 2000 took 0.096s
  training loss:		1.312535
  validation loss:		1.292581
  validation accuracy:		52.72 %
Epoch 942 of 2000 took 0.097s
  training loss:		1.312781
  validation loss:		1.292881
  validation accuracy:		53.04 %
Epoch 943 of 2000 took 0.096s
  training loss:		1.313296
  validation loss:		1.307312
  validation accuracy:		53.48 %
Epoch 944 of 2000 took 0.096s
  training loss:		1.328572
  validation loss:		1.294869
  validation accuracy:		52.39 %
Epoch 945 of 2000 took 0.097s
  training loss:		1.310393
  validation loss:		1.335346
  validation accuracy:		51.41 %
Epoch 946 of 2000 took 0.096s
  training loss:		1.306341
  validation loss:		1.287672
  validation accuracy:		54.13 %
Epoch 947 of 2000 took 0.097s
  training loss:		1.316265
  validation loss:		1.290803
  validation accuracy:		52.72 %
Epoch 948 of 2000 took 0.096s
  training loss:		1.320993
  validation loss:		1.291744
  validation accuracy:		53.04 %
Epoch 949 of 2000 took 0.096s
  training loss:		1.320105
  validation loss:		1.291560
  validation accuracy:		52.83 %
Epoch 950 of 2000 took 0.096s
  training loss:		1.320865
  validation loss:		1.307128
  validation accuracy:		53.15 %
Epoch 951 of 2000 took 0.096s
  training loss:		1.313588
  validation loss:		1.302806
  validation accuracy:		51.41 %
Epoch 952 of 2000 took 0.096s
  training loss:		1.314833
  validation loss:		1.301025
  validation accuracy:		53.37 %
Epoch 953 of 2000 took 0.096s
  training loss:		1.316866
  validation loss:		1.292038
  validation accuracy:		53.48 %
Epoch 954 of 2000 took 0.096s
  training loss:		1.311896
  validation loss:		1.299747
  validation accuracy:		53.70 %
Epoch 955 of 2000 took 0.096s
  training loss:		1.314291
  validation loss:		1.294695
  validation accuracy:		52.61 %
Epoch 956 of 2000 took 0.096s
  training loss:		1.304611
  validation loss:		1.305265
  validation accuracy:		53.59 %
Epoch 957 of 2000 took 0.096s
  training loss:		1.316390
  validation loss:		1.291118
  validation accuracy:		53.59 %
Epoch 958 of 2000 took 0.096s
  training loss:		1.315705
  validation loss:		1.291140
  validation accuracy:		52.39 %
Epoch 959 of 2000 took 0.096s
  training loss:		1.314725
  validation loss:		1.295941
  validation accuracy:		51.96 %
Epoch 960 of 2000 took 0.096s
  training loss:		1.324819
  validation loss:		1.291488
  validation accuracy:		53.26 %
Epoch 961 of 2000 took 0.096s
  training loss:		1.310648
  validation loss:		1.308711
  validation accuracy:		52.61 %
Epoch 962 of 2000 took 0.096s
  training loss:		1.308414
  validation loss:		1.288302
  validation accuracy:		52.93 %
Epoch 963 of 2000 took 0.096s
  training loss:		1.310570
  validation loss:		1.291857
  validation accuracy:		52.61 %
Epoch 964 of 2000 took 0.096s
  training loss:		1.306633
  validation loss:		1.292295
  validation accuracy:		53.15 %
Epoch 965 of 2000 took 0.096s
  training loss:		1.319493
  validation loss:		1.291805
  validation accuracy:		52.72 %
Epoch 966 of 2000 took 0.096s
  training loss:		1.311872
  validation loss:		1.292999
  validation accuracy:		52.17 %
Epoch 967 of 2000 took 0.096s
  training loss:		1.309492
  validation loss:		1.295221
  validation accuracy:		51.96 %
Epoch 968 of 2000 took 0.096s
  training loss:		1.315941
  validation loss:		1.312809
  validation accuracy:		53.59 %
Epoch 969 of 2000 took 0.096s
  training loss:		1.321845
  validation loss:		1.290819
  validation accuracy:		53.70 %
Epoch 970 of 2000 took 0.097s
  training loss:		1.313605
  validation loss:		1.289681
  validation accuracy:		52.17 %
Epoch 971 of 2000 took 0.097s
  training loss:		1.313246
  validation loss:		1.295705
  validation accuracy:		53.37 %
Epoch 972 of 2000 took 0.096s
  training loss:		1.307369
  validation loss:		1.288776
  validation accuracy:		53.80 %
Epoch 973 of 2000 took 0.097s
  training loss:		1.306950
  validation loss:		1.288942
  validation accuracy:		52.28 %
Epoch 974 of 2000 took 0.097s
  training loss:		1.310940
  validation loss:		1.297422
  validation accuracy:		53.48 %
Epoch 975 of 2000 took 0.096s
  training loss:		1.315058
  validation loss:		1.293236
  validation accuracy:		52.39 %
Epoch 976 of 2000 took 0.097s
  training loss:		1.319776
  validation loss:		1.293253
  validation accuracy:		53.48 %
Epoch 977 of 2000 took 0.096s
  training loss:		1.314998
  validation loss:		1.292084
  validation accuracy:		54.46 %
Epoch 978 of 2000 took 0.096s
  training loss:		1.308647
  validation loss:		1.289821
  validation accuracy:		51.74 %
Epoch 979 of 2000 took 0.096s
  training loss:		1.311436
  validation loss:		1.295043
  validation accuracy:		52.83 %
Epoch 980 of 2000 took 0.096s
  training loss:		1.316412
  validation loss:		1.295254
  validation accuracy:		52.50 %
Epoch 981 of 2000 took 0.096s
  training loss:		1.309571
  validation loss:		1.292461
  validation accuracy:		53.80 %
Epoch 982 of 2000 took 0.096s
  training loss:		1.310752
  validation loss:		1.298237
  validation accuracy:		53.48 %
Epoch 983 of 2000 took 0.096s
  training loss:		1.311472
  validation loss:		1.323990
  validation accuracy:		52.72 %
Epoch 984 of 2000 took 0.096s
  training loss:		1.317678
  validation loss:		1.291867
  validation accuracy:		53.26 %
Epoch 985 of 2000 took 0.096s
  training loss:		1.309133
  validation loss:		1.287929
  validation accuracy:		53.37 %
Epoch 986 of 2000 took 0.097s
  training loss:		1.313969
  validation loss:		1.293552
  validation accuracy:		53.04 %
Epoch 987 of 2000 took 0.096s
  training loss:		1.312178
  validation loss:		1.301009
  validation accuracy:		52.93 %
Epoch 988 of 2000 took 0.096s
  training loss:		1.313457
  validation loss:		1.293001
  validation accuracy:		53.70 %
Epoch 989 of 2000 took 0.096s
  training loss:		1.317250
  validation loss:		1.299188
  validation accuracy:		53.04 %
Epoch 990 of 2000 took 0.096s
  training loss:		1.310225
  validation loss:		1.309189
  validation accuracy:		53.48 %
Epoch 991 of 2000 took 0.096s
  training loss:		1.318975
  validation loss:		1.301151
  validation accuracy:		54.24 %
Epoch 992 of 2000 took 0.096s
  training loss:		1.301734
  validation loss:		1.295116
  validation accuracy:		53.48 %
Epoch 993 of 2000 took 0.096s
  training loss:		1.309414
  validation loss:		1.313818
  validation accuracy:		53.48 %
Epoch 994 of 2000 took 0.096s
  training loss:		1.316215
  validation loss:		1.294022
  validation accuracy:		53.15 %
Epoch 995 of 2000 took 0.096s
  training loss:		1.312251
  validation loss:		1.302069
  validation accuracy:		53.48 %
Epoch 996 of 2000 took 0.096s
  training loss:		1.310682
  validation loss:		1.309407
  validation accuracy:		53.70 %
Epoch 997 of 2000 took 0.096s
  training loss:		1.320817
  validation loss:		1.299035
  validation accuracy:		53.15 %
Epoch 998 of 2000 took 0.096s
  training loss:		1.314059
  validation loss:		1.314770
  validation accuracy:		52.50 %
Epoch 999 of 2000 took 0.096s
  training loss:		1.317057
  validation loss:		1.297401
  validation accuracy:		51.74 %
Epoch 1000 of 2000 took 0.096s
  training loss:		1.307686
  validation loss:		1.292111
  validation accuracy:		53.26 %
Epoch 1001 of 2000 took 0.096s
  training loss:		1.313433
  validation loss:		1.293664
  validation accuracy:		53.15 %
Epoch 1002 of 2000 took 0.096s
  training loss:		1.313431
  validation loss:		1.297315
  validation accuracy:		52.72 %
Epoch 1003 of 2000 took 0.096s
  training loss:		1.307162
  validation loss:		1.297250
  validation accuracy:		52.28 %
Epoch 1004 of 2000 took 0.097s
  training loss:		1.314642
  validation loss:		1.291053
  validation accuracy:		53.91 %
Epoch 1005 of 2000 took 0.096s
  training loss:		1.311271
  validation loss:		1.292149
  validation accuracy:		53.04 %
Epoch 1006 of 2000 took 0.096s
  training loss:		1.318278
  validation loss:		1.291509
  validation accuracy:		53.80 %
Epoch 1007 of 2000 took 0.096s
  training loss:		1.309779
  validation loss:		1.306880
  validation accuracy:		52.83 %
Epoch 1008 of 2000 took 0.097s
  training loss:		1.315390
  validation loss:		1.292264
  validation accuracy:		52.39 %
Epoch 1009 of 2000 took 0.096s
  training loss:		1.308067
  validation loss:		1.288959
  validation accuracy:		53.15 %
Epoch 1010 of 2000 took 0.097s
  training loss:		1.306853
  validation loss:		1.290583
  validation accuracy:		53.04 %
Epoch 1011 of 2000 took 0.096s
  training loss:		1.314065
  validation loss:		1.330228
  validation accuracy:		52.28 %
Epoch 1012 of 2000 took 0.097s
  training loss:		1.310875
  validation loss:		1.297101
  validation accuracy:		52.72 %
Epoch 1013 of 2000 took 0.097s
  training loss:		1.307315
  validation loss:		1.289610
  validation accuracy:		52.93 %
Epoch 1014 of 2000 took 0.097s
  training loss:		1.302914
  validation loss:		1.293353
  validation accuracy:		53.70 %
Epoch 1015 of 2000 took 0.097s
  training loss:		1.309306
  validation loss:		1.301654
  validation accuracy:		53.48 %
Epoch 1016 of 2000 took 0.097s
  training loss:		1.314392
  validation loss:		1.291197
  validation accuracy:		54.35 %
Epoch 1017 of 2000 took 0.097s
  training loss:		1.311685
  validation loss:		1.308329
  validation accuracy:		52.17 %
Epoch 1018 of 2000 took 0.099s
  training loss:		1.314815
  validation loss:		1.305229
  validation accuracy:		53.48 %
Epoch 1019 of 2000 took 0.096s
  training loss:		1.312516
  validation loss:		1.290759
  validation accuracy:		53.15 %
Epoch 1020 of 2000 took 0.096s
  training loss:		1.320759
  validation loss:		1.298112
  validation accuracy:		51.41 %
Epoch 1021 of 2000 took 0.096s
  training loss:		1.302010
  validation loss:		1.314849
  validation accuracy:		52.61 %
Epoch 1022 of 2000 took 0.097s
  training loss:		1.324576
  validation loss:		1.296611
  validation accuracy:		53.48 %
Epoch 1023 of 2000 took 0.096s
  training loss:		1.312109
  validation loss:		1.288086
  validation accuracy:		53.04 %
Epoch 1024 of 2000 took 0.096s
  training loss:		1.312496
  validation loss:		1.291191
  validation accuracy:		52.93 %
Epoch 1025 of 2000 took 0.096s
  training loss:		1.306153
  validation loss:		1.291465
  validation accuracy:		52.83 %
Epoch 1026 of 2000 took 0.096s
  training loss:		1.319248
  validation loss:		1.300418
  validation accuracy:		53.04 %
Epoch 1027 of 2000 took 0.096s
  training loss:		1.311594
  validation loss:		1.310397
  validation accuracy:		53.80 %
Epoch 1028 of 2000 took 0.096s
  training loss:		1.314854
  validation loss:		1.325439
  validation accuracy:		52.28 %
Epoch 1029 of 2000 took 0.096s
  training loss:		1.311591
  validation loss:		1.292627
  validation accuracy:		53.48 %
Epoch 1030 of 2000 took 0.096s
  training loss:		1.313120
  validation loss:		1.298051
  validation accuracy:		53.15 %
Epoch 1031 of 2000 took 0.096s
  training loss:		1.313847
  validation loss:		1.294194
  validation accuracy:		53.26 %
Epoch 1032 of 2000 took 0.096s
  training loss:		1.335814
  validation loss:		1.292844
  validation accuracy:		53.80 %
Epoch 1033 of 2000 took 0.096s
  training loss:		1.323714
  validation loss:		1.300190
  validation accuracy:		53.04 %
Epoch 1034 of 2000 took 0.096s
  training loss:		1.315630
  validation loss:		1.295306
  validation accuracy:		52.72 %
Epoch 1035 of 2000 took 0.097s
  training loss:		1.318822
  validation loss:		1.308214
  validation accuracy:		52.72 %
Epoch 1036 of 2000 took 0.096s
  training loss:		1.311590
  validation loss:		1.292707
  validation accuracy:		52.83 %
Epoch 1037 of 2000 took 0.097s
  training loss:		1.318607
  validation loss:		1.288508
  validation accuracy:		53.91 %
Epoch 1038 of 2000 took 0.097s
  training loss:		1.315630
  validation loss:		1.292550
  validation accuracy:		53.59 %
Epoch 1039 of 2000 took 0.096s
  training loss:		1.305763
  validation loss:		1.300394
  validation accuracy:		53.26 %
Epoch 1040 of 2000 took 0.096s
  training loss:		1.319250
  validation loss:		1.332919
  validation accuracy:		51.41 %
Epoch 1041 of 2000 took 0.097s
  training loss:		1.318494
  validation loss:		1.291013
  validation accuracy:		53.48 %
Epoch 1042 of 2000 took 0.096s
  training loss:		1.311106
  validation loss:		1.288991
  validation accuracy:		53.70 %
Epoch 1043 of 2000 took 0.096s
  training loss:		1.308809
  validation loss:		1.292376
  validation accuracy:		53.70 %
Epoch 1044 of 2000 took 0.096s
  training loss:		1.312612
  validation loss:		1.288345
  validation accuracy:		54.02 %
Epoch 1045 of 2000 took 0.096s
  training loss:		1.317577
  validation loss:		1.302024
  validation accuracy:		51.96 %
Epoch 1046 of 2000 took 0.096s
  training loss:		1.306636
  validation loss:		1.309374
  validation accuracy:		53.37 %
Epoch 1047 of 2000 took 0.096s
  training loss:		1.312382
  validation loss:		1.293249
  validation accuracy:		54.13 %
Epoch 1048 of 2000 took 0.096s
  training loss:		1.309838
  validation loss:		1.291948
  validation accuracy:		54.24 %
Epoch 1049 of 2000 took 0.096s
  training loss:		1.317505
  validation loss:		1.290891
  validation accuracy:		53.80 %
Epoch 1050 of 2000 took 0.096s
  training loss:		1.310377
  validation loss:		1.289675
  validation accuracy:		54.13 %
Epoch 1051 of 2000 took 0.096s
  training loss:		1.306027
  validation loss:		1.290126
  validation accuracy:		53.15 %
Epoch 1052 of 2000 took 0.096s
  training loss:		1.315721
  validation loss:		1.291863
  validation accuracy:		54.57 %
Epoch 1053 of 2000 took 0.097s
  training loss:		1.314082
  validation loss:		1.290665
  validation accuracy:		54.24 %
Epoch 1054 of 2000 took 0.096s
  training loss:		1.308255
  validation loss:		1.287489
  validation accuracy:		53.91 %
Epoch 1055 of 2000 took 0.096s
  training loss:		1.318514
  validation loss:		1.309417
  validation accuracy:		53.80 %
Epoch 1056 of 2000 took 0.097s
  training loss:		1.303774
  validation loss:		1.296094
  validation accuracy:		53.15 %
Epoch 1057 of 2000 took 0.097s
  training loss:		1.332404
  validation loss:		1.296722
  validation accuracy:		53.91 %
Epoch 1058 of 2000 took 0.096s
  training loss:		1.310344
  validation loss:		1.292846
  validation accuracy:		54.13 %
Epoch 1059 of 2000 took 0.096s
  training loss:		1.311433
  validation loss:		1.293751
  validation accuracy:		53.37 %
Epoch 1060 of 2000 took 0.096s
  training loss:		1.324038
  validation loss:		1.306426
  validation accuracy:		54.46 %
Epoch 1061 of 2000 took 0.096s
  training loss:		1.334337
  validation loss:		1.307658
  validation accuracy:		52.83 %
Epoch 1062 of 2000 took 0.096s
  training loss:		1.317127
  validation loss:		1.290822
  validation accuracy:		54.24 %
Epoch 1063 of 2000 took 0.096s
  training loss:		1.316749
  validation loss:		1.289445
  validation accuracy:		53.48 %
Epoch 1064 of 2000 took 0.096s
  training loss:		1.312609
  validation loss:		1.320355
  validation accuracy:		52.39 %
Epoch 1065 of 2000 took 0.096s
  training loss:		1.320925
  validation loss:		1.290068
  validation accuracy:		54.02 %
Epoch 1066 of 2000 took 0.096s
  training loss:		1.306841
  validation loss:		1.288401
  validation accuracy:		54.35 %
Epoch 1067 of 2000 took 0.097s
  training loss:		1.306103
  validation loss:		1.304660
  validation accuracy:		53.70 %
Epoch 1068 of 2000 took 0.096s
  training loss:		1.308018
  validation loss:		1.293907
  validation accuracy:		52.61 %
Epoch 1069 of 2000 took 0.096s
  training loss:		1.314410
  validation loss:		1.292801
  validation accuracy:		53.26 %
Epoch 1070 of 2000 took 0.096s
  training loss:		1.323160
  validation loss:		1.304288
  validation accuracy:		53.37 %
Epoch 1071 of 2000 took 0.096s
  training loss:		1.308224
  validation loss:		1.293531
  validation accuracy:		53.91 %
Epoch 1072 of 2000 took 0.096s
  training loss:		1.312456
  validation loss:		1.292134
  validation accuracy:		54.02 %
Epoch 1073 of 2000 took 0.096s
  training loss:		1.312639
  validation loss:		1.318219
  validation accuracy:		53.04 %
Epoch 1074 of 2000 took 0.096s
  training loss:		1.304348
  validation loss:		1.291300
  validation accuracy:		53.80 %
Epoch 1075 of 2000 took 0.097s
  training loss:		1.313735
  validation loss:		1.290272
  validation accuracy:		54.02 %
Epoch 1076 of 2000 took 0.103s
  training loss:		1.309323
  validation loss:		1.300324
  validation accuracy:		53.48 %
Epoch 1077 of 2000 took 0.106s
  training loss:		1.320775
  validation loss:		1.297513
  validation accuracy:		52.39 %
Epoch 1078 of 2000 took 0.143s
  training loss:		1.319367
  validation loss:		1.290949
  validation accuracy:		54.24 %
Epoch 1079 of 2000 took 0.100s
  training loss:		1.316697
  validation loss:		1.315064
  validation accuracy:		53.04 %
Epoch 1080 of 2000 took 0.097s
  training loss:		1.304915
  validation loss:		1.291458
  validation accuracy:		53.15 %
Epoch 1081 of 2000 took 0.101s
  training loss:		1.328829
  validation loss:		1.297142
  validation accuracy:		52.83 %
Epoch 1082 of 2000 took 0.102s
  training loss:		1.314556
  validation loss:		1.298266
  validation accuracy:		54.24 %
Epoch 1083 of 2000 took 0.099s
  training loss:		1.306578
  validation loss:		1.296398
  validation accuracy:		53.59 %
Epoch 1084 of 2000 took 0.103s
  training loss:		1.310536
  validation loss:		1.286182
  validation accuracy:		54.78 %
Epoch 1085 of 2000 took 0.101s
  training loss:		1.312147
  validation loss:		1.286930
  validation accuracy:		54.02 %
Epoch 1086 of 2000 took 0.096s
  training loss:		1.311235
  validation loss:		1.289491
  validation accuracy:		53.91 %
Epoch 1087 of 2000 took 0.096s
  training loss:		1.310306
  validation loss:		1.301545
  validation accuracy:		54.24 %
Epoch 1088 of 2000 took 0.096s
  training loss:		1.309547
  validation loss:		1.290495
  validation accuracy:		54.13 %
Epoch 1089 of 2000 took 0.097s
  training loss:		1.315430
  validation loss:		1.291022
  validation accuracy:		53.37 %
Epoch 1090 of 2000 took 0.096s
  training loss:		1.305138
  validation loss:		1.287932
  validation accuracy:		53.91 %
Epoch 1091 of 2000 took 0.096s
  training loss:		1.304245
  validation loss:		1.291954
  validation accuracy:		54.02 %
Epoch 1092 of 2000 took 0.096s
  training loss:		1.304504
  validation loss:		1.289634
  validation accuracy:		54.02 %
Epoch 1093 of 2000 took 0.096s
  training loss:		1.318626
  validation loss:		1.294621
  validation accuracy:		53.37 %
Epoch 1094 of 2000 took 0.097s
  training loss:		1.309742
  validation loss:		1.289364
  validation accuracy:		54.13 %
Epoch 1095 of 2000 took 0.096s
  training loss:		1.320905
  validation loss:		1.302465
  validation accuracy:		52.61 %
Epoch 1096 of 2000 took 0.096s
  training loss:		1.326292
  validation loss:		1.293380
  validation accuracy:		54.57 %
Epoch 1097 of 2000 took 0.097s
  training loss:		1.308728
  validation loss:		1.292282
  validation accuracy:		55.22 %
Epoch 1098 of 2000 took 0.097s
  training loss:		1.302914
  validation loss:		1.291309
  validation accuracy:		53.37 %
Epoch 1099 of 2000 took 0.097s
  training loss:		1.315370
  validation loss:		1.288938
  validation accuracy:		53.70 %
Epoch 1100 of 2000 took 0.096s
  training loss:		1.309228
  validation loss:		1.296660
  validation accuracy:		53.04 %
Epoch 1101 of 2000 took 0.096s
  training loss:		1.308083
  validation loss:		1.290166
  validation accuracy:		54.02 %
Epoch 1102 of 2000 took 0.096s
  training loss:		1.308273
  validation loss:		1.287996
  validation accuracy:		54.35 %
Epoch 1103 of 2000 took 0.096s
  training loss:		1.315315
  validation loss:		1.308576
  validation accuracy:		52.83 %
Epoch 1104 of 2000 took 0.096s
  training loss:		1.318390
  validation loss:		1.294103
  validation accuracy:		54.57 %
Epoch 1105 of 2000 took 0.096s
  training loss:		1.317724
  validation loss:		1.290820
  validation accuracy:		55.76 %
Epoch 1106 of 2000 took 0.096s
  training loss:		1.313647
  validation loss:		1.295235
  validation accuracy:		53.37 %
Epoch 1107 of 2000 took 0.096s
  training loss:		1.310531
  validation loss:		1.289847
  validation accuracy:		53.37 %
Epoch 1108 of 2000 took 0.096s
  training loss:		1.306178
  validation loss:		1.292243
  validation accuracy:		53.48 %
Epoch 1109 of 2000 took 0.096s
  training loss:		1.315548
  validation loss:		1.292049
  validation accuracy:		54.35 %
Epoch 1110 of 2000 took 0.097s
  training loss:		1.320784
  validation loss:		1.293696
  validation accuracy:		53.91 %
Epoch 1111 of 2000 took 0.096s
  training loss:		1.309181
  validation loss:		1.303496
  validation accuracy:		53.37 %
Epoch 1112 of 2000 took 0.096s
  training loss:		1.309060
  validation loss:		1.290552
  validation accuracy:		53.59 %
Epoch 1113 of 2000 took 0.097s
  training loss:		1.313177
  validation loss:		1.284363
  validation accuracy:		55.43 %
Epoch 1114 of 2000 took 0.096s
  training loss:		1.314525
  validation loss:		1.292279
  validation accuracy:		52.93 %
Epoch 1115 of 2000 took 0.096s
  training loss:		1.305391
  validation loss:		1.290639
  validation accuracy:		54.67 %
Epoch 1116 of 2000 took 0.096s
  training loss:		1.315211
  validation loss:		1.294543
  validation accuracy:		53.37 %
Epoch 1117 of 2000 took 0.098s
  training loss:		1.306708
  validation loss:		1.289141
  validation accuracy:		54.78 %
Epoch 1118 of 2000 took 0.154s
  training loss:		1.307919
  validation loss:		1.295990
  validation accuracy:		53.91 %
Epoch 1119 of 2000 took 0.120s
  training loss:		1.314217
  validation loss:		1.299113
  validation accuracy:		54.46 %
Epoch 1120 of 2000 took 0.096s
  training loss:		1.312407
  validation loss:		1.290003
  validation accuracy:		53.80 %
Epoch 1121 of 2000 took 0.100s
  training loss:		1.294785
  validation loss:		1.289307
  validation accuracy:		54.67 %
Epoch 1122 of 2000 took 0.103s
  training loss:		1.318214
  validation loss:		1.306542
  validation accuracy:		53.48 %
Epoch 1123 of 2000 took 0.106s
  training loss:		1.320293
  validation loss:		1.289196
  validation accuracy:		54.57 %
Epoch 1124 of 2000 took 0.099s
  training loss:		1.314707
  validation loss:		1.308331
  validation accuracy:		51.96 %
Epoch 1125 of 2000 took 0.096s
  training loss:		1.310973
  validation loss:		1.298511
  validation accuracy:		53.91 %
Epoch 1126 of 2000 took 0.096s
  training loss:		1.306327
  validation loss:		1.295533
  validation accuracy:		54.35 %
Epoch 1127 of 2000 took 0.096s
  training loss:		1.311485
  validation loss:		1.286037
  validation accuracy:		54.24 %
Epoch 1128 of 2000 took 0.096s
  training loss:		1.311153
  validation loss:		1.312488
  validation accuracy:		53.26 %
Epoch 1129 of 2000 took 0.097s
  training loss:		1.316318
  validation loss:		1.307173
  validation accuracy:		53.91 %
Epoch 1130 of 2000 took 0.096s
  training loss:		1.315096
  validation loss:		1.301593
  validation accuracy:		52.72 %
Epoch 1131 of 2000 took 0.096s
  training loss:		1.324383
  validation loss:		1.292902
  validation accuracy:		53.15 %
Epoch 1132 of 2000 took 0.096s
  training loss:		1.299694
  validation loss:		1.286545
  validation accuracy:		55.87 %
Epoch 1133 of 2000 took 0.096s
  training loss:		1.307310
  validation loss:		1.286171
  validation accuracy:		55.87 %
Epoch 1134 of 2000 took 0.100s
  training loss:		1.314399
  validation loss:		1.289580
  validation accuracy:		54.24 %
Epoch 1135 of 2000 took 0.098s
  training loss:		1.317631
  validation loss:		1.307130
  validation accuracy:		54.02 %
Epoch 1136 of 2000 took 0.096s
  training loss:		1.315881
  validation loss:		1.291441
  validation accuracy:		53.80 %
Epoch 1137 of 2000 took 0.097s
  training loss:		1.305239
  validation loss:		1.287961
  validation accuracy:		54.57 %
Epoch 1138 of 2000 took 0.097s
  training loss:		1.314038
  validation loss:		1.291644
  validation accuracy:		54.46 %
Epoch 1139 of 2000 took 0.097s
  training loss:		1.305132
  validation loss:		1.297615
  validation accuracy:		53.91 %
Epoch 1140 of 2000 took 0.097s
  training loss:		1.308843
  validation loss:		1.301782
  validation accuracy:		53.91 %
Epoch 1141 of 2000 took 0.097s
  training loss:		1.314515
  validation loss:		1.294452
  validation accuracy:		54.46 %
Epoch 1142 of 2000 took 0.096s
  training loss:		1.315103
  validation loss:		1.300802
  validation accuracy:		54.02 %
Epoch 1143 of 2000 took 0.097s
  training loss:		1.310503
  validation loss:		1.296915
  validation accuracy:		53.91 %
Epoch 1144 of 2000 took 0.096s
  training loss:		1.310584
  validation loss:		1.296282
  validation accuracy:		54.13 %
Epoch 1145 of 2000 took 0.097s
  training loss:		1.312411
  validation loss:		1.291779
  validation accuracy:		54.02 %
Epoch 1146 of 2000 took 0.096s
  training loss:		1.323678
  validation loss:		1.308649
  validation accuracy:		53.04 %
Epoch 1147 of 2000 took 0.096s
  training loss:		1.304874
  validation loss:		1.290284
  validation accuracy:		55.87 %
Epoch 1148 of 2000 took 0.096s
  training loss:		1.317818
  validation loss:		1.291017
  validation accuracy:		54.46 %
Epoch 1149 of 2000 took 0.096s
  training loss:		1.312353
  validation loss:		1.286501
  validation accuracy:		54.89 %
Epoch 1150 of 2000 took 0.097s
  training loss:		1.316613
  validation loss:		1.287200
  validation accuracy:		55.11 %
Epoch 1151 of 2000 took 0.097s
  training loss:		1.315078
  validation loss:		1.299659
  validation accuracy:		52.61 %
Epoch 1152 of 2000 took 0.096s
  training loss:		1.319600
  validation loss:		1.291396
  validation accuracy:		55.43 %
Epoch 1153 of 2000 took 0.096s
  training loss:		1.313914
  validation loss:		1.288093
  validation accuracy:		54.57 %
Epoch 1154 of 2000 took 0.096s
  training loss:		1.310098
  validation loss:		1.290532
  validation accuracy:		54.46 %
Epoch 1155 of 2000 took 0.097s
  training loss:		1.309079
  validation loss:		1.292225
  validation accuracy:		53.80 %
Epoch 1156 of 2000 took 0.096s
  training loss:		1.315850
  validation loss:		1.290483
  validation accuracy:		54.13 %
Epoch 1157 of 2000 took 0.096s
  training loss:		1.311465
  validation loss:		1.288751
  validation accuracy:		55.22 %
Epoch 1158 of 2000 took 0.097s
  training loss:		1.304299
  validation loss:		1.288592
  validation accuracy:		54.35 %
Epoch 1159 of 2000 took 0.096s
  training loss:		1.307185
  validation loss:		1.291627
  validation accuracy:		55.00 %
Epoch 1160 of 2000 took 0.096s
  training loss:		1.314040
  validation loss:		1.292431
  validation accuracy:		55.43 %
Epoch 1161 of 2000 took 0.097s
  training loss:		1.305548
  validation loss:		1.293760
  validation accuracy:		54.78 %
Epoch 1162 of 2000 took 0.096s
  training loss:		1.315354
  validation loss:		1.287067
  validation accuracy:		54.57 %
Epoch 1163 of 2000 took 0.096s
  training loss:		1.308718
  validation loss:		1.287898
  validation accuracy:		55.43 %
Epoch 1164 of 2000 took 0.096s
  training loss:		1.311720
  validation loss:		1.294900
  validation accuracy:		54.02 %
Epoch 1165 of 2000 took 0.096s
  training loss:		1.303127
  validation loss:		1.292014
  validation accuracy:		53.80 %
Epoch 1166 of 2000 took 0.096s
  training loss:		1.309135
  validation loss:		1.286647
  validation accuracy:		55.22 %
Epoch 1167 of 2000 took 0.096s
  training loss:		1.306475
  validation loss:		1.287992
  validation accuracy:		54.35 %
Epoch 1168 of 2000 took 0.096s
  training loss:		1.317384
  validation loss:		1.294598
  validation accuracy:		54.57 %
Epoch 1169 of 2000 took 0.096s
  training loss:		1.317566
  validation loss:		1.292610
  validation accuracy:		54.35 %
Epoch 1170 of 2000 took 0.096s
  training loss:		1.312648
  validation loss:		1.285889
  validation accuracy:		55.11 %
Epoch 1171 of 2000 took 0.097s
  training loss:		1.317908
  validation loss:		1.286846
  validation accuracy:		54.57 %
Epoch 1172 of 2000 took 0.096s
  training loss:		1.310803
  validation loss:		1.288327
  validation accuracy:		54.57 %
Epoch 1173 of 2000 took 0.097s
  training loss:		1.304783
  validation loss:		1.292365
  validation accuracy:		54.78 %
Epoch 1174 of 2000 took 0.096s
  training loss:		1.311629
  validation loss:		1.290937
  validation accuracy:		54.57 %
Epoch 1175 of 2000 took 0.096s
  training loss:		1.332897
  validation loss:		1.292677
  validation accuracy:		54.57 %
Epoch 1176 of 2000 took 0.097s
  training loss:		1.300008
  validation loss:		1.291023
  validation accuracy:		54.78 %
Epoch 1177 of 2000 took 0.096s
  training loss:		1.316830
  validation loss:		1.286483
  validation accuracy:		55.00 %
Epoch 1178 of 2000 took 0.096s
  training loss:		1.313663
  validation loss:		1.288394
  validation accuracy:		55.87 %
Epoch 1179 of 2000 took 0.097s
  training loss:		1.318321
  validation loss:		1.287579
  validation accuracy:		55.11 %
Epoch 1180 of 2000 took 0.097s
  training loss:		1.320405
  validation loss:		1.291315
  validation accuracy:		54.78 %
Epoch 1181 of 2000 took 0.096s
  training loss:		1.307876
  validation loss:		1.295579
  validation accuracy:		53.80 %
Epoch 1182 of 2000 took 0.096s
  training loss:		1.299349
  validation loss:		1.296693
  validation accuracy:		53.48 %
Epoch 1183 of 2000 took 0.096s
  training loss:		1.301448
  validation loss:		1.288807
  validation accuracy:		55.22 %
Epoch 1184 of 2000 took 0.096s
  training loss:		1.321862
  validation loss:		1.308428
  validation accuracy:		54.13 %
Epoch 1185 of 2000 took 0.096s
  training loss:		1.304602
  validation loss:		1.290515
  validation accuracy:		53.80 %
Epoch 1186 of 2000 took 0.096s
  training loss:		1.313898
  validation loss:		1.296583
  validation accuracy:		53.70 %
Epoch 1187 of 2000 took 0.096s
  training loss:		1.309984
  validation loss:		1.291764
  validation accuracy:		54.13 %
Epoch 1188 of 2000 took 0.096s
  training loss:		1.313907
  validation loss:		1.288053
  validation accuracy:		55.54 %
Epoch 1189 of 2000 took 0.097s
  training loss:		1.311496
  validation loss:		1.301794
  validation accuracy:		53.37 %
Epoch 1190 of 2000 took 0.097s
  training loss:		1.316190
  validation loss:		1.299506
  validation accuracy:		53.37 %
Epoch 1191 of 2000 took 0.096s
  training loss:		1.315134
  validation loss:		1.290637
  validation accuracy:		56.20 %
Epoch 1192 of 2000 took 0.096s
  training loss:		1.307477
  validation loss:		1.292207
  validation accuracy:		53.59 %
Epoch 1193 of 2000 took 0.096s
  training loss:		1.311945
  validation loss:		1.288433
  validation accuracy:		55.87 %
Epoch 1194 of 2000 took 0.096s
  training loss:		1.314899
  validation loss:		1.295367
  validation accuracy:		54.24 %
Epoch 1195 of 2000 took 0.096s
  training loss:		1.314484
  validation loss:		1.308879
  validation accuracy:		53.80 %
Epoch 1196 of 2000 took 0.096s
  training loss:		1.313895
  validation loss:		1.292605
  validation accuracy:		54.02 %
Epoch 1197 of 2000 took 0.096s
  training loss:		1.319480
  validation loss:		1.288607
  validation accuracy:		54.57 %
Epoch 1198 of 2000 took 0.096s
  training loss:		1.309961
  validation loss:		1.290936
  validation accuracy:		54.02 %
Epoch 1199 of 2000 took 0.096s
  training loss:		1.298735
  validation loss:		1.288381
  validation accuracy:		55.33 %
Epoch 1200 of 2000 took 0.096s
  training loss:		1.312097
  validation loss:		1.319797
  validation accuracy:		53.59 %
Epoch 1201 of 2000 took 0.097s
  training loss:		1.306169
  validation loss:		1.291593
  validation accuracy:		54.13 %
Epoch 1202 of 2000 took 0.097s
  training loss:		1.294970
  validation loss:		1.298063
  validation accuracy:		53.91 %
Epoch 1203 of 2000 took 0.097s
  training loss:		1.302239
  validation loss:		1.287271
  validation accuracy:		55.11 %
Epoch 1204 of 2000 took 0.097s
  training loss:		1.308043
  validation loss:		1.314758
  validation accuracy:		52.50 %
Epoch 1205 of 2000 took 0.096s
  training loss:		1.310681
  validation loss:		1.293603
  validation accuracy:		53.48 %
Epoch 1206 of 2000 took 0.096s
  training loss:		1.318109
  validation loss:		1.306526
  validation accuracy:		53.91 %
Epoch 1207 of 2000 took 0.096s
  training loss:		1.310556
  validation loss:		1.293916
  validation accuracy:		54.02 %
Epoch 1208 of 2000 took 0.096s
  training loss:		1.310388
  validation loss:		1.300566
  validation accuracy:		53.59 %
Epoch 1209 of 2000 took 0.096s
  training loss:		1.312095
  validation loss:		1.297877
  validation accuracy:		53.91 %
Epoch 1210 of 2000 took 0.096s
  training loss:		1.306454
  validation loss:		1.327253
  validation accuracy:		52.50 %
Epoch 1211 of 2000 took 0.096s
  training loss:		1.319014
  validation loss:		1.288309
  validation accuracy:		55.65 %
Epoch 1212 of 2000 took 0.097s
  training loss:		1.304690
  validation loss:		1.292480
  validation accuracy:		54.67 %
Epoch 1213 of 2000 took 0.096s
  training loss:		1.313262
  validation loss:		1.292070
  validation accuracy:		54.13 %
Epoch 1214 of 2000 took 0.096s
  training loss:		1.303471
  validation loss:		1.289159
  validation accuracy:		55.33 %
Epoch 1215 of 2000 took 0.097s
  training loss:		1.302647
  validation loss:		1.302928
  validation accuracy:		53.70 %
Epoch 1216 of 2000 took 0.096s
  training loss:		1.302387
  validation loss:		1.286567
  validation accuracy:		54.89 %
Epoch 1217 of 2000 took 0.097s
  training loss:		1.305539
  validation loss:		1.298942
  validation accuracy:		54.24 %
Epoch 1218 of 2000 took 0.097s
  training loss:		1.306321
  validation loss:		1.314402
  validation accuracy:		52.93 %
Epoch 1219 of 2000 took 0.097s
  training loss:		1.314435
  validation loss:		1.294914
  validation accuracy:		53.26 %
Epoch 1220 of 2000 took 0.097s
  training loss:		1.301495
  validation loss:		1.306003
  validation accuracy:		53.70 %
Epoch 1221 of 2000 took 0.100s
  training loss:		1.325767
  validation loss:		1.288512
  validation accuracy:		55.33 %
Epoch 1222 of 2000 took 0.097s
  training loss:		1.303571
  validation loss:		1.288137
  validation accuracy:		55.54 %
Epoch 1223 of 2000 took 0.096s
  training loss:		1.313022
  validation loss:		1.289669
  validation accuracy:		54.24 %
Epoch 1224 of 2000 took 0.096s
  training loss:		1.309632
  validation loss:		1.293817
  validation accuracy:		54.46 %
Epoch 1225 of 2000 took 0.096s
  training loss:		1.302562
  validation loss:		1.290902
  validation accuracy:		54.67 %
Epoch 1226 of 2000 took 0.096s
  training loss:		1.306697
  validation loss:		1.293953
  validation accuracy:		53.91 %
Epoch 1227 of 2000 took 0.096s
  training loss:		1.311191
  validation loss:		1.293564
  validation accuracy:		53.91 %
Epoch 1228 of 2000 took 0.096s
  training loss:		1.301786
  validation loss:		1.297532
  validation accuracy:		54.35 %
Epoch 1229 of 2000 took 0.096s
  training loss:		1.315654
  validation loss:		1.297224
  validation accuracy:		54.02 %
Epoch 1230 of 2000 took 0.096s
  training loss:		1.318391
  validation loss:		1.302421
  validation accuracy:		53.37 %
Epoch 1231 of 2000 took 0.096s
  training loss:		1.302630
  validation loss:		1.291385
  validation accuracy:		53.70 %
Epoch 1232 of 2000 took 0.096s
  training loss:		1.318371
  validation loss:		1.307587
  validation accuracy:		54.24 %
Epoch 1233 of 2000 took 0.097s
  training loss:		1.321052
  validation loss:		1.304889
  validation accuracy:		53.59 %
Epoch 1234 of 2000 took 0.096s
  training loss:		1.327588
  validation loss:		1.290908
  validation accuracy:		55.43 %
Epoch 1235 of 2000 took 0.096s
  training loss:		1.312568
  validation loss:		1.330849
  validation accuracy:		50.98 %
Epoch 1236 of 2000 took 0.096s
  training loss:		1.322708
  validation loss:		1.291745
  validation accuracy:		54.78 %
Epoch 1237 of 2000 took 0.096s
  training loss:		1.306001
  validation loss:		1.313746
  validation accuracy:		54.02 %
Epoch 1238 of 2000 took 0.096s
  training loss:		1.319112
  validation loss:		1.286250
  validation accuracy:		55.00 %
Epoch 1239 of 2000 took 0.096s
  training loss:		1.302739
  validation loss:		1.287239
  validation accuracy:		54.89 %
Epoch 1240 of 2000 took 0.096s
  training loss:		1.316324
  validation loss:		1.293505
  validation accuracy:		53.91 %
Epoch 1241 of 2000 took 0.096s
  training loss:		1.309754
  validation loss:		1.291666
  validation accuracy:		54.46 %
Epoch 1242 of 2000 took 0.096s
  training loss:		1.320433
  validation loss:		1.288766
  validation accuracy:		54.89 %
Epoch 1243 of 2000 took 0.096s
  training loss:		1.311612
  validation loss:		1.285919
  validation accuracy:		55.54 %
Epoch 1244 of 2000 took 0.096s
  training loss:		1.311715
  validation loss:		1.300791
  validation accuracy:		53.80 %
Epoch 1245 of 2000 took 0.096s
  training loss:		1.312947
  validation loss:		1.289778
  validation accuracy:		55.00 %
Epoch 1246 of 2000 took 0.096s
  training loss:		1.314993
  validation loss:		1.287257
  validation accuracy:		55.11 %
Epoch 1247 of 2000 took 0.096s
  training loss:		1.311001
  validation loss:		1.287837
  validation accuracy:		55.87 %
Epoch 1248 of 2000 took 0.096s
  training loss:		1.316567
  validation loss:		1.290133
  validation accuracy:		53.91 %
Epoch 1249 of 2000 took 0.096s
  training loss:		1.309332
  validation loss:		1.294424
  validation accuracy:		53.15 %
Epoch 1250 of 2000 took 0.096s
  training loss:		1.307839
  validation loss:		1.292146
  validation accuracy:		53.80 %
Epoch 1251 of 2000 took 0.096s
  training loss:		1.308501
  validation loss:		1.284839
  validation accuracy:		54.89 %
Epoch 1252 of 2000 took 0.097s
  training loss:		1.319073
  validation loss:		1.301915
  validation accuracy:		53.15 %
Epoch 1253 of 2000 took 0.096s
  training loss:		1.313905
  validation loss:		1.300743
  validation accuracy:		54.24 %
Epoch 1254 of 2000 took 0.096s
  training loss:		1.315620
  validation loss:		1.292847
  validation accuracy:		55.33 %
Epoch 1255 of 2000 took 0.096s
  training loss:		1.308383
  validation loss:		1.288119
  validation accuracy:		54.67 %
Epoch 1256 of 2000 took 0.096s
  training loss:		1.310141
  validation loss:		1.287973
  validation accuracy:		55.22 %
Epoch 1257 of 2000 took 0.096s
  training loss:		1.318933
  validation loss:		1.292046
  validation accuracy:		54.35 %
Epoch 1258 of 2000 took 0.096s
  training loss:		1.311231
  validation loss:		1.286335
  validation accuracy:		55.22 %
Epoch 1259 of 2000 took 0.097s
  training loss:		1.304606
  validation loss:		1.309770
  validation accuracy:		53.91 %
Epoch 1260 of 2000 took 0.096s
  training loss:		1.309387
  validation loss:		1.291248
  validation accuracy:		55.54 %
Epoch 1261 of 2000 took 0.096s
  training loss:		1.295138
  validation loss:		1.287259
  validation accuracy:		55.11 %
Epoch 1262 of 2000 took 0.097s
  training loss:		1.315847
  validation loss:		1.308024
  validation accuracy:		52.39 %
Epoch 1263 of 2000 took 0.097s
  training loss:		1.307140
  validation loss:		1.286083
  validation accuracy:		54.78 %
Epoch 1264 of 2000 took 0.096s
  training loss:		1.321470
  validation loss:		1.290550
  validation accuracy:		54.67 %
Epoch 1265 of 2000 took 0.096s
  training loss:		1.307574
  validation loss:		1.299734
  validation accuracy:		54.13 %
Epoch 1266 of 2000 took 0.096s
  training loss:		1.324616
  validation loss:		1.294595
  validation accuracy:		54.78 %
Epoch 1267 of 2000 took 0.096s
  training loss:		1.302575
  validation loss:		1.293077
  validation accuracy:		54.46 %
Epoch 1268 of 2000 took 0.096s
  training loss:		1.310838
  validation loss:		1.298534
  validation accuracy:		52.93 %
Epoch 1269 of 2000 took 0.096s
  training loss:		1.306091
  validation loss:		1.293402
  validation accuracy:		54.46 %
Epoch 1270 of 2000 took 0.096s
  training loss:		1.299883
  validation loss:		1.285951
  validation accuracy:		54.67 %
Epoch 1271 of 2000 took 0.096s
  training loss:		1.314746
  validation loss:		1.295690
  validation accuracy:		54.02 %
Epoch 1272 of 2000 took 0.096s
  training loss:		1.314902
  validation loss:		1.288386
  validation accuracy:		55.54 %
Epoch 1273 of 2000 took 0.096s
  training loss:		1.317261
  validation loss:		1.289690
  validation accuracy:		54.78 %
Epoch 1274 of 2000 took 0.096s
  training loss:		1.306934
  validation loss:		1.292251
  validation accuracy:		55.00 %
Epoch 1275 of 2000 took 0.097s
  training loss:		1.324194
  validation loss:		1.300357
  validation accuracy:		53.37 %
Epoch 1276 of 2000 took 0.098s
  training loss:		1.311499
  validation loss:		1.289676
  validation accuracy:		53.48 %
Epoch 1277 of 2000 took 0.103s
  training loss:		1.308431
  validation loss:		1.293000
  validation accuracy:		54.67 %
Epoch 1278 of 2000 took 0.102s
  training loss:		1.315792
  validation loss:		1.293085
  validation accuracy:		54.67 %
Epoch 1279 of 2000 took 0.100s
  training loss:		1.316855
  validation loss:		1.327462
  validation accuracy:		52.61 %
Epoch 1280 of 2000 took 0.099s
  training loss:		1.314359
  validation loss:		1.298683
  validation accuracy:		53.59 %
Epoch 1281 of 2000 took 0.099s
  training loss:		1.307473
  validation loss:		1.290206
  validation accuracy:		55.22 %
Epoch 1282 of 2000 took 0.099s
  training loss:		1.311804
  validation loss:		1.287205
  validation accuracy:		54.67 %
Epoch 1283 of 2000 took 0.100s
  training loss:		1.313099
  validation loss:		1.292741
  validation accuracy:		54.89 %
Epoch 1284 of 2000 took 0.099s
  training loss:		1.312171
  validation loss:		1.294960
  validation accuracy:		54.89 %
Epoch 1285 of 2000 took 0.100s
  training loss:		1.309082
  validation loss:		1.290956
  validation accuracy:		54.78 %
Epoch 1286 of 2000 took 0.099s
  training loss:		1.303321
  validation loss:		1.298139
  validation accuracy:		53.37 %
Epoch 1287 of 2000 took 0.096s
  training loss:		1.313060
  validation loss:		1.293269
  validation accuracy:		54.24 %
Epoch 1288 of 2000 took 0.096s
  training loss:		1.318868
  validation loss:		1.293357
  validation accuracy:		54.46 %
Epoch 1289 of 2000 took 0.096s
  training loss:		1.310603
  validation loss:		1.295828
  validation accuracy:		54.67 %
Epoch 1290 of 2000 took 0.096s
  training loss:		1.302120
  validation loss:		1.288786
  validation accuracy:		54.78 %
Epoch 1291 of 2000 took 0.096s
  training loss:		1.298746
  validation loss:		1.304936
  validation accuracy:		53.04 %
Epoch 1292 of 2000 took 0.096s
  training loss:		1.317390
  validation loss:		1.289570
  validation accuracy:		55.43 %
Epoch 1293 of 2000 took 0.096s
  training loss:		1.328968
  validation loss:		1.288722
  validation accuracy:		55.54 %
Epoch 1294 of 2000 took 0.096s
  training loss:		1.306954
  validation loss:		1.297718
  validation accuracy:		54.67 %
Epoch 1295 of 2000 took 0.096s
  training loss:		1.307990
  validation loss:		1.295873
  validation accuracy:		54.46 %
Epoch 1296 of 2000 took 0.096s
  training loss:		1.319581
  validation loss:		1.294132
  validation accuracy:		54.89 %
Epoch 1297 of 2000 took 0.096s
  training loss:		1.310413
  validation loss:		1.290224
  validation accuracy:		55.22 %
Epoch 1298 of 2000 took 0.096s
  training loss:		1.316016
  validation loss:		1.289161
  validation accuracy:		55.22 %
Epoch 1299 of 2000 took 0.096s
  training loss:		1.308445
  validation loss:		1.293740
  validation accuracy:		54.67 %
Epoch 1300 of 2000 took 0.097s
  training loss:		1.304435
  validation loss:		1.302916
  validation accuracy:		53.48 %
Epoch 1301 of 2000 took 0.096s
  training loss:		1.307389
  validation loss:		1.288424
  validation accuracy:		55.00 %
Epoch 1302 of 2000 took 0.096s
  training loss:		1.310987
  validation loss:		1.289077
  validation accuracy:		55.00 %
Epoch 1303 of 2000 took 0.097s
  training loss:		1.300551
  validation loss:		1.299095
  validation accuracy:		54.02 %
Epoch 1304 of 2000 took 0.097s
  training loss:		1.314504
  validation loss:		1.293063
  validation accuracy:		54.46 %
Epoch 1305 of 2000 took 0.096s
  training loss:		1.302121
  validation loss:		1.298951
  validation accuracy:		54.35 %
Epoch 1306 of 2000 took 0.096s
  training loss:		1.313522
  validation loss:		1.290442
  validation accuracy:		54.89 %
Epoch 1307 of 2000 took 0.096s
  training loss:		1.307545
  validation loss:		1.294920
  validation accuracy:		54.35 %
Epoch 1308 of 2000 took 0.096s
  training loss:		1.304022
  validation loss:		1.288568
  validation accuracy:		55.22 %
Epoch 1309 of 2000 took 0.096s
  training loss:		1.322652
  validation loss:		1.298033
  validation accuracy:		53.91 %
Epoch 1310 of 2000 took 0.097s
  training loss:		1.310739
  validation loss:		1.292585
  validation accuracy:		54.89 %
Epoch 1311 of 2000 took 0.096s
  training loss:		1.308602
  validation loss:		1.291798
  validation accuracy:		55.00 %
Epoch 1312 of 2000 took 0.096s
  training loss:		1.313233
  validation loss:		1.296057
  validation accuracy:		54.13 %
Epoch 1313 of 2000 took 0.096s
  training loss:		1.313192
  validation loss:		1.292706
  validation accuracy:		53.70 %
Epoch 1314 of 2000 took 0.097s
  training loss:		1.313775
  validation loss:		1.293008
  validation accuracy:		53.91 %
Epoch 1315 of 2000 took 0.096s
  training loss:		1.317904
  validation loss:		1.289503
  validation accuracy:		54.24 %
Epoch 1316 of 2000 took 0.096s
  training loss:		1.308446
  validation loss:		1.318760
  validation accuracy:		53.37 %
Epoch 1317 of 2000 took 0.096s
  training loss:		1.307804
  validation loss:		1.296733
  validation accuracy:		54.24 %
Epoch 1318 of 2000 took 0.096s
  training loss:		1.306299
  validation loss:		1.294047
  validation accuracy:		54.46 %
Epoch 1319 of 2000 took 0.097s
  training loss:		1.314239
  validation loss:		1.297164
  validation accuracy:		54.57 %
Epoch 1320 of 2000 took 0.096s
  training loss:		1.309360
  validation loss:		1.293193
  validation accuracy:		54.57 %
Epoch 1321 of 2000 took 0.096s
  training loss:		1.318217
  validation loss:		1.290825
  validation accuracy:		54.67 %
Epoch 1322 of 2000 took 0.096s
  training loss:		1.310054
  validation loss:		1.299011
  validation accuracy:		53.91 %
Epoch 1323 of 2000 took 0.096s
  training loss:		1.307626
  validation loss:		1.297318
  validation accuracy:		54.89 %
Epoch 1324 of 2000 took 0.096s
  training loss:		1.309603
  validation loss:		1.288849
  validation accuracy:		55.65 %
Epoch 1325 of 2000 took 0.096s
  training loss:		1.303101
  validation loss:		1.293272
  validation accuracy:		54.02 %
Epoch 1326 of 2000 took 0.096s
  training loss:		1.315031
  validation loss:		1.301230
  validation accuracy:		53.91 %
Epoch 1327 of 2000 took 0.096s
  training loss:		1.313591
  validation loss:		1.293226
  validation accuracy:		54.24 %
Epoch 1328 of 2000 took 0.096s
  training loss:		1.306922
  validation loss:		1.293344
  validation accuracy:		54.46 %
Epoch 1329 of 2000 took 0.096s
  training loss:		1.314502
  validation loss:		1.293279
  validation accuracy:		54.57 %
Epoch 1330 of 2000 took 0.096s
  training loss:		1.310683
  validation loss:		1.291863
  validation accuracy:		54.57 %
Epoch 1331 of 2000 took 0.096s
  training loss:		1.303204
  validation loss:		1.297206
  validation accuracy:		53.37 %
Epoch 1332 of 2000 took 0.096s
  training loss:		1.297143
  validation loss:		1.298957
  validation accuracy:		54.13 %
Epoch 1333 of 2000 took 0.096s
  training loss:		1.320511
  validation loss:		1.289788
  validation accuracy:		55.22 %
Epoch 1334 of 2000 took 0.096s
  training loss:		1.303706
  validation loss:		1.291728
  validation accuracy:		54.13 %
Epoch 1335 of 2000 took 0.096s
  training loss:		1.312406
  validation loss:		1.291809
  validation accuracy:		55.11 %
Epoch 1336 of 2000 took 0.096s
  training loss:		1.317989
  validation loss:		1.293518
  validation accuracy:		54.35 %
Epoch 1337 of 2000 took 0.096s
  training loss:		1.323735
  validation loss:		1.294413
  validation accuracy:		54.35 %
Epoch 1338 of 2000 took 0.096s
  training loss:		1.313630
  validation loss:		1.291392
  validation accuracy:		53.48 %
Epoch 1339 of 2000 took 0.096s
  training loss:		1.323746
  validation loss:		1.296636
  validation accuracy:		54.35 %
Epoch 1340 of 2000 took 0.097s
  training loss:		1.304788
  validation loss:		1.290716
  validation accuracy:		55.43 %
Epoch 1341 of 2000 took 0.097s
  training loss:		1.312122
  validation loss:		1.287902
  validation accuracy:		54.78 %
Epoch 1342 of 2000 took 0.096s
  training loss:		1.303484
  validation loss:		1.287110
  validation accuracy:		55.00 %
Epoch 1343 of 2000 took 0.096s
  training loss:		1.306810
  validation loss:		1.291354
  validation accuracy:		55.00 %
Epoch 1344 of 2000 took 0.096s
  training loss:		1.302704
  validation loss:		1.291489
  validation accuracy:		54.89 %
Epoch 1345 of 2000 took 0.100s
  training loss:		1.310189
  validation loss:		1.292555
  validation accuracy:		54.46 %
Epoch 1346 of 2000 took 0.100s
  training loss:		1.311759
  validation loss:		1.289552
  validation accuracy:		55.33 %
Epoch 1347 of 2000 took 0.099s
  training loss:		1.304445
  validation loss:		1.285137
  validation accuracy:		55.22 %
Epoch 1348 of 2000 took 0.099s
  training loss:		1.308667
  validation loss:		1.287580
  validation accuracy:		55.00 %
Epoch 1349 of 2000 took 0.099s
  training loss:		1.312202
  validation loss:		1.308680
  validation accuracy:		53.59 %
Epoch 1350 of 2000 took 0.101s
  training loss:		1.308425
  validation loss:		1.305414
  validation accuracy:		53.59 %
Epoch 1351 of 2000 took 0.099s
  training loss:		1.306085
  validation loss:		1.293847
  validation accuracy:		54.46 %
Epoch 1352 of 2000 took 0.099s
  training loss:		1.314002
  validation loss:		1.291725
  validation accuracy:		54.78 %
Epoch 1353 of 2000 took 0.099s
  training loss:		1.306654
  validation loss:		1.288466
  validation accuracy:		54.89 %
Epoch 1354 of 2000 took 0.099s
  training loss:		1.307672
  validation loss:		1.293120
  validation accuracy:		54.89 %
Epoch 1355 of 2000 took 0.099s
  training loss:		1.309210
  validation loss:		1.303247
  validation accuracy:		53.91 %
Epoch 1356 of 2000 took 0.100s
  training loss:		1.312011
  validation loss:		1.298303
  validation accuracy:		54.24 %
Epoch 1357 of 2000 took 0.099s
  training loss:		1.314973
  validation loss:		1.289719
  validation accuracy:		55.33 %
Epoch 1358 of 2000 took 0.099s
  training loss:		1.307862
  validation loss:		1.288048
  validation accuracy:		55.00 %
Epoch 1359 of 2000 took 0.099s
  training loss:		1.313079
  validation loss:		1.297154
  validation accuracy:		54.57 %
Epoch 1360 of 2000 took 0.099s
  training loss:		1.303232
  validation loss:		1.289902
  validation accuracy:		55.33 %
Epoch 1361 of 2000 took 0.099s
  training loss:		1.305427
  validation loss:		1.293052
  validation accuracy:		54.24 %
Epoch 1362 of 2000 took 0.099s
  training loss:		1.311595
  validation loss:		1.305754
  validation accuracy:		53.70 %
Epoch 1363 of 2000 took 0.099s
  training loss:		1.318068
  validation loss:		1.293339
  validation accuracy:		54.78 %
Epoch 1364 of 2000 took 0.099s
  training loss:		1.317500
  validation loss:		1.294989
  validation accuracy:		54.35 %
Epoch 1365 of 2000 took 0.099s
  training loss:		1.313717
  validation loss:		1.289037
  validation accuracy:		54.67 %
Epoch 1366 of 2000 took 0.099s
  training loss:		1.308873
  validation loss:		1.293329
  validation accuracy:		53.70 %
Epoch 1367 of 2000 took 0.099s
  training loss:		1.309078
  validation loss:		1.311958
  validation accuracy:		53.48 %
Epoch 1368 of 2000 took 0.099s
  training loss:		1.313362
  validation loss:		1.289094
  validation accuracy:		54.78 %
Epoch 1369 of 2000 took 0.099s
  training loss:		1.308715
  validation loss:		1.294100
  validation accuracy:		55.00 %
Epoch 1370 of 2000 took 0.099s
  training loss:		1.311222
  validation loss:		1.292799
  validation accuracy:		54.35 %
Epoch 1371 of 2000 took 0.099s
  training loss:		1.295748
  validation loss:		1.320100
  validation accuracy:		53.15 %
Epoch 1372 of 2000 took 0.099s
  training loss:		1.319410
  validation loss:		1.288867
  validation accuracy:		54.35 %
Epoch 1373 of 2000 took 0.099s
  training loss:		1.314618
  validation loss:		1.301446
  validation accuracy:		54.35 %
Epoch 1374 of 2000 took 0.100s
  training loss:		1.306608
  validation loss:		1.293334
  validation accuracy:		54.67 %
Epoch 1375 of 2000 took 0.100s
  training loss:		1.309835
  validation loss:		1.293427
  validation accuracy:		54.35 %
Epoch 1376 of 2000 took 0.100s
  training loss:		1.304891
  validation loss:		1.289291
  validation accuracy:		55.43 %
Epoch 1377 of 2000 took 0.100s
  training loss:		1.310286
  validation loss:		1.289667
  validation accuracy:		55.54 %
Epoch 1378 of 2000 took 0.099s
  training loss:		1.308047
  validation loss:		1.296573
  validation accuracy:		53.80 %
Epoch 1379 of 2000 took 0.099s
  training loss:		1.302235
  validation loss:		1.293663
  validation accuracy:		54.67 %
Epoch 1380 of 2000 took 0.099s
  training loss:		1.303133
  validation loss:		1.296794
  validation accuracy:		53.91 %
Epoch 1381 of 2000 took 0.100s
  training loss:		1.315287
  validation loss:		1.290706
  validation accuracy:		55.11 %
Epoch 1382 of 2000 took 0.100s
  training loss:		1.312466
  validation loss:		1.300868
  validation accuracy:		54.57 %
Epoch 1383 of 2000 took 0.099s
  training loss:		1.313871
  validation loss:		1.290540
  validation accuracy:		54.78 %
Epoch 1384 of 2000 took 0.100s
  training loss:		1.304801
  validation loss:		1.294959
  validation accuracy:		54.24 %
Epoch 1385 of 2000 took 0.098s
  training loss:		1.317962
  validation loss:		1.291939
  validation accuracy:		54.57 %
Epoch 1386 of 2000 took 0.097s
  training loss:		1.316946
  validation loss:		1.292076
  validation accuracy:		53.91 %
Epoch 1387 of 2000 took 0.096s
  training loss:		1.302019
  validation loss:		1.287634
  validation accuracy:		55.33 %
Epoch 1388 of 2000 took 0.096s
  training loss:		1.303524
  validation loss:		1.286457
  validation accuracy:		55.65 %
Epoch 1389 of 2000 took 0.096s
  training loss:		1.312473
  validation loss:		1.287749
  validation accuracy:		55.00 %
Epoch 1390 of 2000 took 0.096s
  training loss:		1.307940
  validation loss:		1.291795
  validation accuracy:		54.89 %
Epoch 1391 of 2000 took 0.097s
  training loss:		1.307986
  validation loss:		1.328383
  validation accuracy:		52.50 %
Epoch 1392 of 2000 took 0.096s
  training loss:		1.313585
  validation loss:		1.290044
  validation accuracy:		54.78 %
Epoch 1393 of 2000 took 0.096s
  training loss:		1.310891
  validation loss:		1.292400
  validation accuracy:		54.78 %
Epoch 1394 of 2000 took 0.096s
  training loss:		1.307626
  validation loss:		1.291304
  validation accuracy:		55.76 %
Epoch 1395 of 2000 took 0.096s
  training loss:		1.316276
  validation loss:		1.294695
  validation accuracy:		54.57 %
Epoch 1396 of 2000 took 0.096s
  training loss:		1.309530
  validation loss:		1.290236
  validation accuracy:		56.30 %
Epoch 1397 of 2000 took 0.096s
  training loss:		1.317523
  validation loss:		1.295793
  validation accuracy:		55.00 %
Epoch 1398 of 2000 took 0.096s
  training loss:		1.323094
  validation loss:		1.335409
  validation accuracy:		52.07 %
Epoch 1399 of 2000 took 0.096s
  training loss:		1.313788
  validation loss:		1.293265
  validation accuracy:		55.00 %
Epoch 1400 of 2000 took 0.096s
  training loss:		1.308369
  validation loss:		1.287954
  validation accuracy:		55.11 %
Epoch 1401 of 2000 took 0.096s
  training loss:		1.312239
  validation loss:		1.284820
  validation accuracy:		55.54 %
Epoch 1402 of 2000 took 0.096s
  training loss:		1.311978
  validation loss:		1.287775
  validation accuracy:		54.78 %
Epoch 1403 of 2000 took 0.096s
  training loss:		1.308741
  validation loss:		1.290981
  validation accuracy:		54.46 %
Epoch 1404 of 2000 took 0.096s
  training loss:		1.301670
  validation loss:		1.290561
  validation accuracy:		55.33 %
Epoch 1405 of 2000 took 0.096s
  training loss:		1.310291
  validation loss:		1.295183
  validation accuracy:		54.46 %
Epoch 1406 of 2000 took 0.097s
  training loss:		1.313809
  validation loss:		1.290869
  validation accuracy:		54.78 %
Epoch 1407 of 2000 took 0.097s
  training loss:		1.309180
  validation loss:		1.287573
  validation accuracy:		54.78 %
Epoch 1408 of 2000 took 0.096s
  training loss:		1.321852
  validation loss:		1.297673
  validation accuracy:		54.35 %
Epoch 1409 of 2000 took 0.096s
  training loss:		1.308909
  validation loss:		1.290408
  validation accuracy:		55.87 %
Epoch 1410 of 2000 took 0.097s
  training loss:		1.317026
  validation loss:		1.293399
  validation accuracy:		54.46 %
Epoch 1411 of 2000 took 0.097s
  training loss:		1.305131
  validation loss:		1.306198
  validation accuracy:		53.91 %
Epoch 1412 of 2000 took 0.096s
  training loss:		1.312255
  validation loss:		1.290670
  validation accuracy:		54.35 %
Epoch 1413 of 2000 took 0.096s
  training loss:		1.302547
  validation loss:		1.291361
  validation accuracy:		54.13 %
Epoch 1414 of 2000 took 0.096s
  training loss:		1.305764
  validation loss:		1.290307
  validation accuracy:		55.76 %
Epoch 1415 of 2000 took 0.096s
  training loss:		1.313897
  validation loss:		1.287847
  validation accuracy:		55.54 %
Epoch 1416 of 2000 took 0.096s
  training loss:		1.309083
  validation loss:		1.300642
  validation accuracy:		54.02 %
Epoch 1417 of 2000 took 0.096s
  training loss:		1.300684
  validation loss:		1.287921
  validation accuracy:		54.24 %
Epoch 1418 of 2000 took 0.096s
  training loss:		1.313980
  validation loss:		1.289064
  validation accuracy:		54.67 %
Epoch 1419 of 2000 took 0.096s
  training loss:		1.305741
  validation loss:		1.294030
  validation accuracy:		54.67 %
Epoch 1420 of 2000 took 0.096s
  training loss:		1.311197
  validation loss:		1.290344
  validation accuracy:		55.22 %
Epoch 1421 of 2000 took 0.097s
  training loss:		1.319513
  validation loss:		1.298779
  validation accuracy:		53.59 %
Epoch 1422 of 2000 took 0.096s
  training loss:		1.319793
  validation loss:		1.295037
  validation accuracy:		54.13 %
Epoch 1423 of 2000 took 0.097s
  training loss:		1.304009
  validation loss:		1.294304
  validation accuracy:		53.26 %
Epoch 1424 of 2000 took 0.096s
  training loss:		1.300287
  validation loss:		1.289812
  validation accuracy:		55.54 %
Epoch 1425 of 2000 took 0.096s
  training loss:		1.316194
  validation loss:		1.290290
  validation accuracy:		54.57 %
Epoch 1426 of 2000 took 0.097s
  training loss:		1.317973
  validation loss:		1.289740
  validation accuracy:		55.33 %
Epoch 1427 of 2000 took 0.096s
  training loss:		1.313174
  validation loss:		1.297819
  validation accuracy:		53.91 %
Epoch 1428 of 2000 took 0.096s
  training loss:		1.307604
  validation loss:		1.291963
  validation accuracy:		55.11 %
Epoch 1429 of 2000 took 0.096s
  training loss:		1.312151
  validation loss:		1.313941
  validation accuracy:		53.59 %
Epoch 1430 of 2000 took 0.096s
  training loss:		1.312008
  validation loss:		1.313025
  validation accuracy:		53.91 %
Epoch 1431 of 2000 took 0.096s
  training loss:		1.306886
  validation loss:		1.289511
  validation accuracy:		54.35 %
Epoch 1432 of 2000 took 0.096s
  training loss:		1.318477
  validation loss:		1.289229
  validation accuracy:		54.35 %
Epoch 1433 of 2000 took 0.096s
  training loss:		1.310566
  validation loss:		1.290747
  validation accuracy:		54.13 %
Epoch 1434 of 2000 took 0.096s
  training loss:		1.313653
  validation loss:		1.286541
  validation accuracy:		55.22 %
Epoch 1435 of 2000 took 0.096s
  training loss:		1.307631
  validation loss:		1.293208
  validation accuracy:		54.02 %
Epoch 1436 of 2000 took 0.096s
  training loss:		1.307637
  validation loss:		1.291947
  validation accuracy:		54.78 %
Epoch 1437 of 2000 took 0.096s
  training loss:		1.315159
  validation loss:		1.306165
  validation accuracy:		54.13 %
Epoch 1438 of 2000 took 0.097s
  training loss:		1.308367
  validation loss:		1.302893
  validation accuracy:		53.80 %
Epoch 1439 of 2000 took 0.096s
  training loss:		1.303455
  validation loss:		1.293622
  validation accuracy:		54.13 %
Epoch 1440 of 2000 took 0.096s
  training loss:		1.311057
  validation loss:		1.295460
  validation accuracy:		54.89 %
Epoch 1441 of 2000 took 0.096s
  training loss:		1.310014
  validation loss:		1.294241
  validation accuracy:		53.80 %
Epoch 1442 of 2000 took 0.097s
  training loss:		1.310453
  validation loss:		1.290011
  validation accuracy:		55.11 %
Epoch 1443 of 2000 took 0.096s
  training loss:		1.315099
  validation loss:		1.298468
  validation accuracy:		54.24 %
Epoch 1444 of 2000 took 0.096s
  training loss:		1.311657
  validation loss:		1.292831
  validation accuracy:		55.54 %
Epoch 1445 of 2000 took 0.096s
  training loss:		1.310427
  validation loss:		1.297984
  validation accuracy:		54.02 %
Epoch 1446 of 2000 took 0.096s
  training loss:		1.316618
  validation loss:		1.325660
  validation accuracy:		52.39 %
Epoch 1447 of 2000 took 0.096s
  training loss:		1.315541
  validation loss:		1.291052
  validation accuracy:		54.67 %
Epoch 1448 of 2000 took 0.096s
  training loss:		1.315544
  validation loss:		1.298384
  validation accuracy:		54.35 %
Epoch 1449 of 2000 took 0.096s
  training loss:		1.323951
  validation loss:		1.301417
  validation accuracy:		53.91 %
Epoch 1450 of 2000 took 0.096s
  training loss:		1.301997
  validation loss:		1.301264
  validation accuracy:		53.59 %
Epoch 1451 of 2000 took 0.096s
  training loss:		1.313154
  validation loss:		1.290132
  validation accuracy:		55.11 %
Epoch 1452 of 2000 took 0.096s
  training loss:		1.306100
  validation loss:		1.289620
  validation accuracy:		55.76 %
Epoch 1453 of 2000 took 0.096s
  training loss:		1.316413
  validation loss:		1.294817
  validation accuracy:		54.46 %
Epoch 1454 of 2000 took 0.096s
  training loss:		1.314331
  validation loss:		1.303790
  validation accuracy:		52.93 %
Epoch 1455 of 2000 took 0.096s
  training loss:		1.316110
  validation loss:		1.290151
  validation accuracy:		55.43 %
Epoch 1456 of 2000 took 0.096s
  training loss:		1.315976
  validation loss:		1.312212
  validation accuracy:		53.80 %
Epoch 1457 of 2000 took 0.096s
  training loss:		1.310561
  validation loss:		1.288780
  validation accuracy:		55.00 %
Epoch 1458 of 2000 took 0.096s
  training loss:		1.313473
  validation loss:		1.304075
  validation accuracy:		54.02 %
Epoch 1459 of 2000 took 0.096s
  training loss:		1.313324
  validation loss:		1.304096
  validation accuracy:		54.35 %
Epoch 1460 of 2000 took 0.096s
  training loss:		1.306165
  validation loss:		1.289339
  validation accuracy:		55.11 %
Epoch 1461 of 2000 took 0.096s
  training loss:		1.309665
  validation loss:		1.293227
  validation accuracy:		54.02 %
Epoch 1462 of 2000 took 0.096s
  training loss:		1.303251
  validation loss:		1.295661
  validation accuracy:		53.70 %
Epoch 1463 of 2000 took 0.096s
  training loss:		1.313657
  validation loss:		1.304777
  validation accuracy:		54.02 %
Epoch 1464 of 2000 took 0.096s
  training loss:		1.304398
  validation loss:		1.296414
  validation accuracy:		54.57 %
Epoch 1465 of 2000 took 0.097s
  training loss:		1.308408
  validation loss:		1.289140
  validation accuracy:		54.78 %
Epoch 1466 of 2000 took 0.099s
  training loss:		1.299056
  validation loss:		1.291109
  validation accuracy:		54.35 %
Epoch 1467 of 2000 took 0.097s
  training loss:		1.308571
  validation loss:		1.287442
  validation accuracy:		55.33 %
Epoch 1468 of 2000 took 0.096s
  training loss:		1.302048
  validation loss:		1.291183
  validation accuracy:		55.11 %
Epoch 1469 of 2000 took 0.097s
  training loss:		1.297447
  validation loss:		1.292376
  validation accuracy:		54.89 %
Epoch 1470 of 2000 took 0.096s
  training loss:		1.309716
  validation loss:		1.292937
  validation accuracy:		54.02 %
Epoch 1471 of 2000 took 0.096s
  training loss:		1.311926
  validation loss:		1.298091
  validation accuracy:		53.26 %
Epoch 1472 of 2000 took 0.096s
  training loss:		1.315692
  validation loss:		1.307116
  validation accuracy:		54.46 %
Epoch 1473 of 2000 took 0.096s
  training loss:		1.305447
  validation loss:		1.292062
  validation accuracy:		55.00 %
Epoch 1474 of 2000 took 0.096s
  training loss:		1.311690
  validation loss:		1.296237
  validation accuracy:		54.13 %
Epoch 1475 of 2000 took 0.096s
  training loss:		1.309236
  validation loss:		1.293917
  validation accuracy:		55.11 %
Epoch 1476 of 2000 took 0.096s
  training loss:		1.300667
  validation loss:		1.297207
  validation accuracy:		54.02 %
Epoch 1477 of 2000 took 0.098s
  training loss:		1.315876
  validation loss:		1.294816
  validation accuracy:		54.57 %
Epoch 1478 of 2000 took 0.095s
  training loss:		1.303765
  validation loss:		1.290713
  validation accuracy:		54.78 %
Epoch 1479 of 2000 took 0.095s
  training loss:		1.310596
  validation loss:		1.288398
  validation accuracy:		54.57 %
Epoch 1480 of 2000 took 0.096s
  training loss:		1.302984
  validation loss:		1.288751
  validation accuracy:		55.43 %
Epoch 1481 of 2000 took 0.096s
  training loss:		1.311057
  validation loss:		1.292396
  validation accuracy:		54.78 %
Epoch 1482 of 2000 took 0.096s
  training loss:		1.313678
  validation loss:		1.290709
  validation accuracy:		54.89 %
Epoch 1483 of 2000 took 0.096s
  training loss:		1.307737
  validation loss:		1.290814
  validation accuracy:		54.57 %
Epoch 1484 of 2000 took 0.096s
  training loss:		1.311680
  validation loss:		1.329745
  validation accuracy:		52.28 %
Epoch 1485 of 2000 took 0.096s
  training loss:		1.317952
  validation loss:		1.288738
  validation accuracy:		55.87 %
Epoch 1486 of 2000 took 0.096s
  training loss:		1.308120
  validation loss:		1.300727
  validation accuracy:		53.37 %
Epoch 1487 of 2000 took 0.096s
  training loss:		1.318914
  validation loss:		1.290740
  validation accuracy:		55.43 %
Epoch 1488 of 2000 took 0.096s
  training loss:		1.316323
  validation loss:		1.291976
  validation accuracy:		54.67 %
Epoch 1489 of 2000 took 0.096s
  training loss:		1.310162
  validation loss:		1.288126
  validation accuracy:		55.00 %
Epoch 1490 of 2000 took 0.096s
  training loss:		1.316077
  validation loss:		1.297575
  validation accuracy:		53.48 %
Epoch 1491 of 2000 took 0.096s
  training loss:		1.305160
  validation loss:		1.286465
  validation accuracy:		54.67 %
Epoch 1492 of 2000 took 0.096s
  training loss:		1.314569
  validation loss:		1.299293
  validation accuracy:		54.13 %
Epoch 1493 of 2000 took 0.096s
  training loss:		1.297033
  validation loss:		1.293372
  validation accuracy:		54.57 %
Epoch 1494 of 2000 took 0.096s
  training loss:		1.307839
  validation loss:		1.290255
  validation accuracy:		55.65 %
Epoch 1495 of 2000 took 0.096s
  training loss:		1.311315
  validation loss:		1.293517
  validation accuracy:		55.00 %
Epoch 1496 of 2000 took 0.096s
  training loss:		1.316528
  validation loss:		1.290110
  validation accuracy:		55.11 %
Epoch 1497 of 2000 took 0.096s
  training loss:		1.308536
  validation loss:		1.291191
  validation accuracy:		55.00 %
Epoch 1498 of 2000 took 0.096s
  training loss:		1.308649
  validation loss:		1.291372
  validation accuracy:		54.46 %
Epoch 1499 of 2000 took 0.096s
  training loss:		1.310218
  validation loss:		1.291391
  validation accuracy:		54.78 %
Epoch 1500 of 2000 took 0.097s
  training loss:		1.313386
  validation loss:		1.303389
  validation accuracy:		53.70 %
Epoch 1501 of 2000 took 0.096s
  training loss:		1.312893
  validation loss:		1.291795
  validation accuracy:		54.35 %
Epoch 1502 of 2000 took 0.096s
  training loss:		1.295780
  validation loss:		1.287227
  validation accuracy:		56.30 %
Epoch 1503 of 2000 took 0.096s
  training loss:		1.310252
  validation loss:		1.289901
  validation accuracy:		54.89 %
Epoch 1504 of 2000 took 0.096s
  training loss:		1.307313
  validation loss:		1.294903
  validation accuracy:		54.89 %
Epoch 1505 of 2000 took 0.096s
  training loss:		1.310929
  validation loss:		1.288066
  validation accuracy:		55.33 %
Epoch 1506 of 2000 took 0.096s
  training loss:		1.304597
  validation loss:		1.290817
  validation accuracy:		54.67 %
Epoch 1507 of 2000 took 0.096s
  training loss:		1.304932
  validation loss:		1.297060
  validation accuracy:		53.70 %
Epoch 1508 of 2000 took 0.096s
  training loss:		1.309636
  validation loss:		1.288608
  validation accuracy:		55.76 %
Epoch 1509 of 2000 took 0.096s
  training loss:		1.309919
  validation loss:		1.300619
  validation accuracy:		54.02 %
Epoch 1510 of 2000 took 0.096s
  training loss:		1.310756
  validation loss:		1.297391
  validation accuracy:		54.02 %
Epoch 1511 of 2000 took 0.096s
  training loss:		1.298574
  validation loss:		1.287877
  validation accuracy:		55.33 %
Epoch 1512 of 2000 took 0.096s
  training loss:		1.308432
  validation loss:		1.288927
  validation accuracy:		55.00 %
Epoch 1513 of 2000 took 0.096s
  training loss:		1.312895
  validation loss:		1.296979
  validation accuracy:		53.59 %
Epoch 1514 of 2000 took 0.096s
  training loss:		1.308419
  validation loss:		1.295030
  validation accuracy:		54.46 %
Epoch 1515 of 2000 took 0.096s
  training loss:		1.302366
  validation loss:		1.291695
  validation accuracy:		55.22 %
Epoch 1516 of 2000 took 0.096s
  training loss:		1.316537
  validation loss:		1.296456
  validation accuracy:		54.24 %
Epoch 1517 of 2000 took 0.096s
  training loss:		1.313792
  validation loss:		1.288555
  validation accuracy:		54.89 %
Epoch 1518 of 2000 took 0.096s
  training loss:		1.308249
  validation loss:		1.291291
  validation accuracy:		55.76 %
Epoch 1519 of 2000 took 0.096s
  training loss:		1.308948
  validation loss:		1.295516
  validation accuracy:		55.76 %
Epoch 1520 of 2000 took 0.096s
  training loss:		1.304327
  validation loss:		1.288808
  validation accuracy:		55.33 %
Epoch 1521 of 2000 took 0.096s
  training loss:		1.311423
  validation loss:		1.286812
  validation accuracy:		55.65 %
Epoch 1522 of 2000 took 0.096s
  training loss:		1.309395
  validation loss:		1.298112
  validation accuracy:		54.02 %
Epoch 1523 of 2000 took 0.096s
  training loss:		1.319254
  validation loss:		1.303767
  validation accuracy:		53.70 %
Epoch 1524 of 2000 took 0.096s
  training loss:		1.307995
  validation loss:		1.295120
  validation accuracy:		54.57 %
Epoch 1525 of 2000 took 0.096s
  training loss:		1.311555
  validation loss:		1.289287
  validation accuracy:		56.30 %
Epoch 1526 of 2000 took 0.096s
  training loss:		1.311582
  validation loss:		1.290082
  validation accuracy:		55.22 %
Epoch 1527 of 2000 took 0.096s
  training loss:		1.304179
  validation loss:		1.287289
  validation accuracy:		55.87 %
Epoch 1528 of 2000 took 0.096s
  training loss:		1.305084
  validation loss:		1.299779
  validation accuracy:		53.37 %
Epoch 1529 of 2000 took 0.096s
  training loss:		1.319261
  validation loss:		1.292940
  validation accuracy:		55.33 %
Epoch 1530 of 2000 took 0.096s
  training loss:		1.307389
  validation loss:		1.291935
  validation accuracy:		55.22 %
Epoch 1531 of 2000 took 0.096s
  training loss:		1.319689
  validation loss:		1.294169
  validation accuracy:		54.35 %
Epoch 1532 of 2000 took 0.097s
  training loss:		1.301502
  validation loss:		1.303099
  validation accuracy:		53.80 %
Epoch 1533 of 2000 took 0.096s
  training loss:		1.306876
  validation loss:		1.292062
  validation accuracy:		54.78 %
Epoch 1534 of 2000 took 0.096s
  training loss:		1.312521
  validation loss:		1.300888
  validation accuracy:		54.13 %
Epoch 1535 of 2000 took 0.096s
  training loss:		1.309604
  validation loss:		1.293754
  validation accuracy:		54.57 %
Epoch 1536 of 2000 took 0.096s
  training loss:		1.311229
  validation loss:		1.289007
  validation accuracy:		56.09 %
Epoch 1537 of 2000 took 0.096s
  training loss:		1.303539
  validation loss:		1.288944
  validation accuracy:		55.00 %
Epoch 1538 of 2000 took 0.096s
  training loss:		1.306048
  validation loss:		1.293014
  validation accuracy:		54.24 %
Epoch 1539 of 2000 took 0.096s
  training loss:		1.306721
  validation loss:		1.302496
  validation accuracy:		53.26 %
Epoch 1540 of 2000 took 0.096s
  training loss:		1.316606
  validation loss:		1.330772
  validation accuracy:		52.61 %
Epoch 1541 of 2000 took 0.096s
  training loss:		1.304178
  validation loss:		1.291460
  validation accuracy:		53.91 %
Epoch 1542 of 2000 took 0.096s
  training loss:		1.310704
  validation loss:		1.291653
  validation accuracy:		54.46 %
Epoch 1543 of 2000 took 0.096s
  training loss:		1.309976
  validation loss:		1.289295
  validation accuracy:		55.00 %
Epoch 1544 of 2000 took 0.096s
  training loss:		1.308939
  validation loss:		1.287568
  validation accuracy:		55.87 %
Epoch 1545 of 2000 took 0.096s
  training loss:		1.317227
  validation loss:		1.298465
  validation accuracy:		54.35 %
Epoch 1546 of 2000 took 0.096s
  training loss:		1.316409
  validation loss:		1.294182
  validation accuracy:		54.67 %
Epoch 1547 of 2000 took 0.096s
  training loss:		1.308172
  validation loss:		1.290825
  validation accuracy:		55.22 %
Epoch 1548 of 2000 took 0.096s
  training loss:		1.313108
  validation loss:		1.288800
  validation accuracy:		55.43 %
Epoch 1549 of 2000 took 0.096s
  training loss:		1.306186
  validation loss:		1.288891
  validation accuracy:		54.24 %
Epoch 1550 of 2000 took 0.096s
  training loss:		1.320262
  validation loss:		1.294978
  validation accuracy:		54.13 %
Epoch 1551 of 2000 took 0.096s
  training loss:		1.308927
  validation loss:		1.294811
  validation accuracy:		54.67 %
Epoch 1552 of 2000 took 0.096s
  training loss:		1.315267
  validation loss:		1.322331
  validation accuracy:		53.04 %
Epoch 1553 of 2000 took 0.096s
  training loss:		1.312000
  validation loss:		1.299605
  validation accuracy:		53.80 %
Epoch 1554 of 2000 took 0.096s
  training loss:		1.320862
  validation loss:		1.289252
  validation accuracy:		54.57 %
Epoch 1555 of 2000 took 0.096s
  training loss:		1.309660
  validation loss:		1.288880
  validation accuracy:		56.41 %
Epoch 1556 of 2000 took 0.096s
  training loss:		1.309253
  validation loss:		1.289637
  validation accuracy:		55.22 %
Epoch 1557 of 2000 took 0.096s
  training loss:		1.309813
  validation loss:		1.291600
  validation accuracy:		54.57 %
Epoch 1558 of 2000 took 0.096s
  training loss:		1.307515
  validation loss:		1.287986
  validation accuracy:		55.11 %
Epoch 1559 of 2000 took 0.096s
  training loss:		1.312838
  validation loss:		1.290113
  validation accuracy:		54.57 %
Epoch 1560 of 2000 took 0.096s
  training loss:		1.293498
  validation loss:		1.294946
  validation accuracy:		54.24 %
Epoch 1561 of 2000 took 0.096s
  training loss:		1.309906
  validation loss:		1.288845
  validation accuracy:		55.00 %
Epoch 1562 of 2000 took 0.096s
  training loss:		1.315225
  validation loss:		1.288478
  validation accuracy:		55.43 %
Epoch 1563 of 2000 took 0.097s
  training loss:		1.306923
  validation loss:		1.290790
  validation accuracy:		55.22 %
Epoch 1564 of 2000 took 0.096s
  training loss:		1.307418
  validation loss:		1.293317
  validation accuracy:		55.00 %
Epoch 1565 of 2000 took 0.096s
  training loss:		1.314133
  validation loss:		1.298738
  validation accuracy:		54.02 %
Epoch 1566 of 2000 took 0.096s
  training loss:		1.308651
  validation loss:		1.295796
  validation accuracy:		54.78 %
Epoch 1567 of 2000 took 0.096s
  training loss:		1.303616
  validation loss:		1.287458
  validation accuracy:		55.87 %
Epoch 1568 of 2000 took 0.096s
  training loss:		1.320216
  validation loss:		1.289550
  validation accuracy:		55.43 %
Epoch 1569 of 2000 took 0.096s
  training loss:		1.311366
  validation loss:		1.294789
  validation accuracy:		55.22 %
Epoch 1570 of 2000 took 0.096s
  training loss:		1.303234
  validation loss:		1.304801
  validation accuracy:		53.80 %
Epoch 1571 of 2000 took 0.096s
  training loss:		1.313481
  validation loss:		1.298536
  validation accuracy:		54.02 %
Epoch 1572 of 2000 took 0.096s
  training loss:		1.302887
  validation loss:		1.299598
  validation accuracy:		53.37 %
Epoch 1573 of 2000 took 0.096s
  training loss:		1.305652
  validation loss:		1.290003
  validation accuracy:		55.54 %
Epoch 1574 of 2000 took 0.096s
  training loss:		1.309592
  validation loss:		1.309165
  validation accuracy:		53.37 %
Epoch 1575 of 2000 took 0.096s
  training loss:		1.311815
  validation loss:		1.303720
  validation accuracy:		53.91 %
Epoch 1576 of 2000 took 0.096s
  training loss:		1.314081
  validation loss:		1.306499
  validation accuracy:		54.46 %
Epoch 1577 of 2000 took 0.096s
  training loss:		1.310004
  validation loss:		1.302555
  validation accuracy:		54.46 %
Epoch 1578 of 2000 took 0.096s
  training loss:		1.312270
  validation loss:		1.287880
  validation accuracy:		54.89 %
Epoch 1579 of 2000 took 0.096s
  training loss:		1.307603
  validation loss:		1.299785
  validation accuracy:		52.93 %
Epoch 1580 of 2000 took 0.096s
  training loss:		1.315875
  validation loss:		1.291292
  validation accuracy:		55.22 %
Epoch 1581 of 2000 took 0.096s
  training loss:		1.306481
  validation loss:		1.302217
  validation accuracy:		54.02 %
Epoch 1582 of 2000 took 0.096s
  training loss:		1.313204
  validation loss:		1.296826
  validation accuracy:		54.89 %
Epoch 1583 of 2000 took 0.096s
  training loss:		1.304514
  validation loss:		1.289608
  validation accuracy:		55.22 %
Epoch 1584 of 2000 took 0.096s
  training loss:		1.305188
  validation loss:		1.289472
  validation accuracy:		54.57 %
Epoch 1585 of 2000 took 0.096s
  training loss:		1.308673
  validation loss:		1.288244
  validation accuracy:		55.54 %
Epoch 1586 of 2000 took 0.096s
  training loss:		1.304167
  validation loss:		1.296840
  validation accuracy:		53.26 %
Epoch 1587 of 2000 took 0.096s
  training loss:		1.313272
  validation loss:		1.306743
  validation accuracy:		53.70 %
Epoch 1588 of 2000 took 0.096s
  training loss:		1.308158
  validation loss:		1.298548
  validation accuracy:		53.59 %
Epoch 1589 of 2000 took 0.096s
  training loss:		1.317068
  validation loss:		1.286957
  validation accuracy:		56.74 %
Epoch 1590 of 2000 took 0.096s
  training loss:		1.315490
  validation loss:		1.295847
  validation accuracy:		54.67 %
Epoch 1591 of 2000 took 0.096s
  training loss:		1.310297
  validation loss:		1.294039
  validation accuracy:		54.35 %
Epoch 1592 of 2000 took 0.096s
  training loss:		1.322086
  validation loss:		1.288285
  validation accuracy:		55.33 %
Epoch 1593 of 2000 took 0.096s
  training loss:		1.303250
  validation loss:		1.287207
  validation accuracy:		54.89 %
Epoch 1594 of 2000 took 0.097s
  training loss:		1.304531
  validation loss:		1.296948
  validation accuracy:		54.02 %
Epoch 1595 of 2000 took 0.096s
  training loss:		1.302661
  validation loss:		1.298115
  validation accuracy:		54.13 %
Epoch 1596 of 2000 took 0.096s
  training loss:		1.301091
  validation loss:		1.290365
  validation accuracy:		55.87 %
Epoch 1597 of 2000 took 0.096s
  training loss:		1.314593
  validation loss:		1.300950
  validation accuracy:		54.13 %
Epoch 1598 of 2000 took 0.096s
  training loss:		1.308201
  validation loss:		1.291196
  validation accuracy:		54.46 %
Epoch 1599 of 2000 took 0.096s
  training loss:		1.319009
  validation loss:		1.291935
  validation accuracy:		54.02 %
Epoch 1600 of 2000 took 0.096s
  training loss:		1.311105
  validation loss:		1.293691
  validation accuracy:		54.35 %
Epoch 1601 of 2000 took 0.096s
  training loss:		1.310361
  validation loss:		1.289263
  validation accuracy:		55.00 %
Epoch 1602 of 2000 took 0.096s
  training loss:		1.314230
  validation loss:		1.297223
  validation accuracy:		54.24 %
Epoch 1603 of 2000 took 0.096s
  training loss:		1.309966
  validation loss:		1.289675
  validation accuracy:		55.33 %
Epoch 1604 of 2000 took 0.096s
  training loss:		1.307542
  validation loss:		1.286958
  validation accuracy:		55.00 %
Epoch 1605 of 2000 took 0.096s
  training loss:		1.305712
  validation loss:		1.286341
  validation accuracy:		55.11 %
Epoch 1606 of 2000 took 0.096s
  training loss:		1.308239
  validation loss:		1.288316
  validation accuracy:		54.57 %
Epoch 1607 of 2000 took 0.096s
  training loss:		1.321903
  validation loss:		1.302571
  validation accuracy:		54.02 %
Epoch 1608 of 2000 took 0.096s
  training loss:		1.295842
  validation loss:		1.292021
  validation accuracy:		54.46 %
Epoch 1609 of 2000 took 0.096s
  training loss:		1.312573
  validation loss:		1.289353
  validation accuracy:		54.57 %
Epoch 1610 of 2000 took 0.096s
  training loss:		1.319756
  validation loss:		1.292031
  validation accuracy:		54.24 %
Epoch 1611 of 2000 took 0.096s
  training loss:		1.296850
  validation loss:		1.290090
  validation accuracy:		54.46 %
Epoch 1612 of 2000 took 0.096s
  training loss:		1.306281
  validation loss:		1.287348
  validation accuracy:		55.43 %
Epoch 1613 of 2000 took 0.096s
  training loss:		1.306253
  validation loss:		1.299061
  validation accuracy:		54.24 %
Epoch 1614 of 2000 took 0.096s
  training loss:		1.302471
  validation loss:		1.293937
  validation accuracy:		54.13 %
Epoch 1615 of 2000 took 0.096s
  training loss:		1.309712
  validation loss:		1.292558
  validation accuracy:		54.57 %
Epoch 1616 of 2000 took 0.096s
  training loss:		1.308682
  validation loss:		1.299483
  validation accuracy:		53.70 %
Epoch 1617 of 2000 took 0.096s
  training loss:		1.307886
  validation loss:		1.290749
  validation accuracy:		55.43 %
Epoch 1618 of 2000 took 0.096s
  training loss:		1.299746
  validation loss:		1.289778
  validation accuracy:		55.65 %
Epoch 1619 of 2000 took 0.096s
  training loss:		1.302274
  validation loss:		1.291726
  validation accuracy:		55.22 %
Epoch 1620 of 2000 took 0.096s
  training loss:		1.311787
  validation loss:		1.295664
  validation accuracy:		54.24 %
Epoch 1621 of 2000 took 0.096s
  training loss:		1.308770
  validation loss:		1.296720
  validation accuracy:		54.67 %
Epoch 1622 of 2000 took 0.096s
  training loss:		1.316212
  validation loss:		1.290587
  validation accuracy:		55.00 %
Epoch 1623 of 2000 took 0.096s
  training loss:		1.307938
  validation loss:		1.289831
  validation accuracy:		54.35 %
Epoch 1624 of 2000 took 0.096s
  training loss:		1.309606
  validation loss:		1.305184
  validation accuracy:		54.02 %
Epoch 1625 of 2000 took 0.096s
  training loss:		1.301147
  validation loss:		1.283436
  validation accuracy:		55.11 %
Epoch 1626 of 2000 took 0.097s
  training loss:		1.309361
  validation loss:		1.308739
  validation accuracy:		54.24 %
Epoch 1627 of 2000 took 0.096s
  training loss:		1.311780
  validation loss:		1.299578
  validation accuracy:		54.57 %
Epoch 1628 of 2000 took 0.096s
  training loss:		1.312633
  validation loss:		1.295618
  validation accuracy:		54.35 %
Epoch 1629 of 2000 took 0.096s
  training loss:		1.312556
  validation loss:		1.288211
  validation accuracy:		55.33 %
Epoch 1630 of 2000 took 0.096s
  training loss:		1.305237
  validation loss:		1.285315
  validation accuracy:		54.89 %
Epoch 1631 of 2000 took 0.096s
  training loss:		1.302012
  validation loss:		1.292586
  validation accuracy:		54.46 %
Epoch 1632 of 2000 took 0.096s
  training loss:		1.315776
  validation loss:		1.295193
  validation accuracy:		54.35 %
Epoch 1633 of 2000 took 0.096s
  training loss:		1.317029
  validation loss:		1.297081
  validation accuracy:		54.35 %
Epoch 1634 of 2000 took 0.096s
  training loss:		1.309367
  validation loss:		1.296604
  validation accuracy:		54.57 %
Epoch 1635 of 2000 took 0.096s
  training loss:		1.311829
  validation loss:		1.311225
  validation accuracy:		53.59 %
Epoch 1636 of 2000 took 0.096s
  training loss:		1.307788
  validation loss:		1.287959
  validation accuracy:		54.46 %
Epoch 1637 of 2000 took 0.096s
  training loss:		1.307066
  validation loss:		1.292872
  validation accuracy:		54.35 %
Epoch 1638 of 2000 took 0.096s
  training loss:		1.307710
  validation loss:		1.291150
  validation accuracy:		53.91 %
Epoch 1639 of 2000 took 0.096s
  training loss:		1.306101
  validation loss:		1.291163
  validation accuracy:		54.78 %
Epoch 1640 of 2000 took 0.096s
  training loss:		1.310321
  validation loss:		1.302845
  validation accuracy:		53.91 %
Epoch 1641 of 2000 took 0.096s
  training loss:		1.308901
  validation loss:		1.290469
  validation accuracy:		54.89 %
Epoch 1642 of 2000 took 0.096s
  training loss:		1.298207
  validation loss:		1.286087
  validation accuracy:		55.33 %
Epoch 1643 of 2000 took 0.096s
  training loss:		1.308769
  validation loss:		1.295852
  validation accuracy:		54.67 %
Epoch 1644 of 2000 took 0.096s
  training loss:		1.315334
  validation loss:		1.292835
  validation accuracy:		54.89 %
Epoch 1645 of 2000 took 0.096s
  training loss:		1.313910
  validation loss:		1.290928
  validation accuracy:		54.67 %
Epoch 1646 of 2000 took 0.096s
  training loss:		1.314670
  validation loss:		1.290648
  validation accuracy:		55.22 %
Epoch 1647 of 2000 took 0.096s
  training loss:		1.295801
  validation loss:		1.286775
  validation accuracy:		56.09 %
Epoch 1648 of 2000 took 0.096s
  training loss:		1.313040
  validation loss:		1.298053
  validation accuracy:		53.80 %
Epoch 1649 of 2000 took 0.096s
  training loss:		1.311867
  validation loss:		1.289542
  validation accuracy:		54.89 %
Epoch 1650 of 2000 took 0.096s
  training loss:		1.309080
  validation loss:		1.292780
  validation accuracy:		54.24 %
Epoch 1651 of 2000 took 0.096s
  training loss:		1.320337
  validation loss:		1.287734
  validation accuracy:		55.87 %
Epoch 1652 of 2000 took 0.096s
  training loss:		1.314218
  validation loss:		1.292511
  validation accuracy:		54.67 %
Epoch 1653 of 2000 took 0.096s
  training loss:		1.305213
  validation loss:		1.301407
  validation accuracy:		54.24 %
Epoch 1654 of 2000 took 0.096s
  training loss:		1.309550
  validation loss:		1.284589
  validation accuracy:		55.65 %
Epoch 1655 of 2000 took 0.096s
  training loss:		1.304542
  validation loss:		1.292450
  validation accuracy:		54.57 %
Epoch 1656 of 2000 took 0.096s
  training loss:		1.317525
  validation loss:		1.302395
  validation accuracy:		54.24 %
Epoch 1657 of 2000 took 0.097s
  training loss:		1.303061
  validation loss:		1.290275
  validation accuracy:		55.87 %
Epoch 1658 of 2000 took 0.096s
  training loss:		1.305947
  validation loss:		1.287632
  validation accuracy:		55.11 %
Epoch 1659 of 2000 took 0.096s
  training loss:		1.311710
  validation loss:		1.287741
  validation accuracy:		55.22 %
Epoch 1660 of 2000 took 0.096s
  training loss:		1.310234
  validation loss:		1.291624
  validation accuracy:		54.89 %
Epoch 1661 of 2000 took 0.097s
  training loss:		1.302962
  validation loss:		1.286943
  validation accuracy:		55.65 %
Epoch 1662 of 2000 took 0.096s
  training loss:		1.309511
  validation loss:		1.298785
  validation accuracy:		53.80 %
Epoch 1663 of 2000 took 0.096s
  training loss:		1.315838
  validation loss:		1.287631
  validation accuracy:		55.33 %
Epoch 1664 of 2000 took 0.096s
  training loss:		1.303461
  validation loss:		1.290322
  validation accuracy:		55.54 %
Epoch 1665 of 2000 took 0.096s
  training loss:		1.319599
  validation loss:		1.303525
  validation accuracy:		53.59 %
Epoch 1666 of 2000 took 0.096s
  training loss:		1.307962
  validation loss:		1.293390
  validation accuracy:		54.89 %
Epoch 1667 of 2000 took 0.096s
  training loss:		1.306940
  validation loss:		1.292793
  validation accuracy:		54.67 %
Epoch 1668 of 2000 took 0.096s
  training loss:		1.297892
  validation loss:		1.286605
  validation accuracy:		55.11 %
Epoch 1669 of 2000 took 0.096s
  training loss:		1.315959
  validation loss:		1.289875
  validation accuracy:		55.76 %
Epoch 1670 of 2000 took 0.096s
  training loss:		1.303890
  validation loss:		1.301267
  validation accuracy:		54.24 %
Epoch 1671 of 2000 took 0.096s
  training loss:		1.313639
  validation loss:		1.293446
  validation accuracy:		53.48 %
Epoch 1672 of 2000 took 0.096s
  training loss:		1.311425
  validation loss:		1.289382
  validation accuracy:		55.33 %
Epoch 1673 of 2000 took 0.096s
  training loss:		1.307820
  validation loss:		1.291790
  validation accuracy:		54.57 %
Epoch 1674 of 2000 took 0.096s
  training loss:		1.307532
  validation loss:		1.291157
  validation accuracy:		54.89 %
Epoch 1675 of 2000 took 0.097s
  training loss:		1.305041
  validation loss:		1.296594
  validation accuracy:		54.67 %
Epoch 1676 of 2000 took 0.101s
  training loss:		1.312756
  validation loss:		1.287133
  validation accuracy:		55.98 %
Epoch 1677 of 2000 took 0.102s
  training loss:		1.306708
  validation loss:		1.288762
  validation accuracy:		55.76 %
Epoch 1678 of 2000 took 0.103s
  training loss:		1.307418
  validation loss:		1.289381
  validation accuracy:		55.43 %
Epoch 1679 of 2000 took 0.102s
  training loss:		1.307712
  validation loss:		1.308399
  validation accuracy:		53.59 %
Epoch 1680 of 2000 took 0.102s
  training loss:		1.304934
  validation loss:		1.296644
  validation accuracy:		54.24 %
Epoch 1681 of 2000 took 0.102s
  training loss:		1.312756
  validation loss:		1.295534
  validation accuracy:		53.80 %
Epoch 1682 of 2000 took 0.102s
  training loss:		1.330999
  validation loss:		1.301108
  validation accuracy:		54.13 %
Epoch 1683 of 2000 took 0.102s
  training loss:		1.305513
  validation loss:		1.290493
  validation accuracy:		55.00 %
Epoch 1684 of 2000 took 0.102s
  training loss:		1.299178
  validation loss:		1.290970
  validation accuracy:		55.11 %
Epoch 1685 of 2000 took 0.102s
  training loss:		1.307526
  validation loss:		1.292223
  validation accuracy:		55.54 %
Epoch 1686 of 2000 took 0.102s
  training loss:		1.308891
  validation loss:		1.288701
  validation accuracy:		55.65 %
Epoch 1687 of 2000 took 0.103s
  training loss:		1.310425
  validation loss:		1.293507
  validation accuracy:		54.57 %
Epoch 1688 of 2000 took 0.103s
  training loss:		1.306649
  validation loss:		1.288572
  validation accuracy:		55.54 %
Epoch 1689 of 2000 took 0.102s
  training loss:		1.312255
  validation loss:		1.287861
  validation accuracy:		54.35 %
Epoch 1690 of 2000 took 0.102s
  training loss:		1.305886
  validation loss:		1.288122
  validation accuracy:		55.65 %
Epoch 1691 of 2000 took 0.102s
  training loss:		1.306713
  validation loss:		1.297816
  validation accuracy:		53.70 %
Epoch 1692 of 2000 took 0.102s
  training loss:		1.297091
  validation loss:		1.289296
  validation accuracy:		54.35 %
Epoch 1693 of 2000 took 0.102s
  training loss:		1.306629
  validation loss:		1.290936
  validation accuracy:		55.43 %
Epoch 1694 of 2000 took 0.102s
  training loss:		1.314074
  validation loss:		1.299941
  validation accuracy:		53.80 %
Epoch 1695 of 2000 took 0.102s
  training loss:		1.297417
  validation loss:		1.293366
  validation accuracy:		54.89 %
Epoch 1696 of 2000 took 0.102s
  training loss:		1.314839
  validation loss:		1.298562
  validation accuracy:		53.80 %
Epoch 1697 of 2000 took 0.102s
  training loss:		1.311396
  validation loss:		1.299581
  validation accuracy:		53.59 %
Epoch 1698 of 2000 took 0.102s
  training loss:		1.313727
  validation loss:		1.292831
  validation accuracy:		54.24 %
Epoch 1699 of 2000 took 0.102s
  training loss:		1.312883
  validation loss:		1.290041
  validation accuracy:		54.89 %
Epoch 1700 of 2000 took 0.102s
  training loss:		1.302978
  validation loss:		1.315944
  validation accuracy:		54.02 %
Epoch 1701 of 2000 took 0.102s
  training loss:		1.316392
  validation loss:		1.295061
  validation accuracy:		54.24 %
Epoch 1702 of 2000 took 0.102s
  training loss:		1.303235
  validation loss:		1.290529
  validation accuracy:		55.54 %
Epoch 1703 of 2000 took 0.102s
  training loss:		1.309444
  validation loss:		1.290127
  validation accuracy:		55.11 %
Epoch 1704 of 2000 took 0.102s
  training loss:		1.306148
  validation loss:		1.305630
  validation accuracy:		53.37 %
Epoch 1705 of 2000 took 0.102s
  training loss:		1.308040
  validation loss:		1.302610
  validation accuracy:		54.13 %
Epoch 1706 of 2000 took 0.102s
  training loss:		1.307459
  validation loss:		1.297301
  validation accuracy:		54.02 %
Epoch 1707 of 2000 took 0.102s
  training loss:		1.316479
  validation loss:		1.290277
  validation accuracy:		55.11 %
Epoch 1708 of 2000 took 0.102s
  training loss:		1.298991
  validation loss:		1.298992
  validation accuracy:		53.70 %
Epoch 1709 of 2000 took 0.102s
  training loss:		1.317991
  validation loss:		1.320320
  validation accuracy:		53.26 %
Epoch 1710 of 2000 took 0.102s
  training loss:		1.313470
  validation loss:		1.293753
  validation accuracy:		54.13 %
Epoch 1711 of 2000 took 0.102s
  training loss:		1.311260
  validation loss:		1.298528
  validation accuracy:		54.46 %
Epoch 1712 of 2000 took 0.103s
  training loss:		1.304594
  validation loss:		1.292735
  validation accuracy:		54.89 %
Epoch 1713 of 2000 took 0.102s
  training loss:		1.301485
  validation loss:		1.318109
  validation accuracy:		53.59 %
Epoch 1714 of 2000 took 0.102s
  training loss:		1.307166
  validation loss:		1.298346
  validation accuracy:		53.26 %
Epoch 1715 of 2000 took 0.098s
  training loss:		1.308802
  validation loss:		1.290458
  validation accuracy:		55.22 %
Epoch 1716 of 2000 took 0.096s
  training loss:		1.310616
  validation loss:		1.286306
  validation accuracy:		55.00 %
Epoch 1717 of 2000 took 0.097s
  training loss:		1.314226
  validation loss:		1.285005
  validation accuracy:		55.87 %
Epoch 1718 of 2000 took 0.096s
  training loss:		1.304676
  validation loss:		1.289625
  validation accuracy:		55.11 %
Epoch 1719 of 2000 took 0.096s
  training loss:		1.311196
  validation loss:		1.289553
  validation accuracy:		55.11 %
Epoch 1720 of 2000 took 0.096s
  training loss:		1.304067
  validation loss:		1.304252
  validation accuracy:		53.70 %
Epoch 1721 of 2000 took 0.096s
  training loss:		1.309994
  validation loss:		1.294499
  validation accuracy:		55.00 %
Epoch 1722 of 2000 took 0.096s
  training loss:		1.308433
  validation loss:		1.303008
  validation accuracy:		53.37 %
Epoch 1723 of 2000 took 0.096s
  training loss:		1.310237
  validation loss:		1.289416
  validation accuracy:		55.33 %
Epoch 1724 of 2000 took 0.096s
  training loss:		1.307413
  validation loss:		1.297566
  validation accuracy:		54.35 %
Epoch 1725 of 2000 took 0.096s
  training loss:		1.304999
  validation loss:		1.290400
  validation accuracy:		56.09 %
Epoch 1726 of 2000 took 0.096s
  training loss:		1.303668
  validation loss:		1.295409
  validation accuracy:		54.78 %
Epoch 1727 of 2000 took 0.096s
  training loss:		1.310013
  validation loss:		1.303207
  validation accuracy:		53.80 %
Epoch 1728 of 2000 took 0.096s
  training loss:		1.311075
  validation loss:		1.288612
  validation accuracy:		55.65 %
Epoch 1729 of 2000 took 0.096s
  training loss:		1.310833
  validation loss:		1.286734
  validation accuracy:		55.98 %
Epoch 1730 of 2000 took 0.096s
  training loss:		1.309941
  validation loss:		1.291229
  validation accuracy:		54.57 %
Epoch 1731 of 2000 took 0.096s
  training loss:		1.307182
  validation loss:		1.313255
  validation accuracy:		54.02 %
Epoch 1732 of 2000 took 0.096s
  training loss:		1.310372
  validation loss:		1.289746
  validation accuracy:		55.33 %
Epoch 1733 of 2000 took 0.096s
  training loss:		1.307175
  validation loss:		1.297912
  validation accuracy:		54.46 %
Epoch 1734 of 2000 took 0.096s
  training loss:		1.310459
  validation loss:		1.291384
  validation accuracy:		56.09 %
Epoch 1735 of 2000 took 0.096s
  training loss:		1.308345
  validation loss:		1.294675
  validation accuracy:		54.78 %
Epoch 1736 of 2000 took 0.096s
  training loss:		1.303388
  validation loss:		1.294463
  validation accuracy:		54.24 %
Epoch 1737 of 2000 took 0.096s
  training loss:		1.321950
  validation loss:		1.285977
  validation accuracy:		55.33 %
Epoch 1738 of 2000 took 0.096s
  training loss:		1.306200
  validation loss:		1.289849
  validation accuracy:		54.78 %
Epoch 1739 of 2000 took 0.096s
  training loss:		1.306777
  validation loss:		1.308427
  validation accuracy:		54.02 %
Epoch 1740 of 2000 took 0.096s
  training loss:		1.315625
  validation loss:		1.293107
  validation accuracy:		55.54 %
Epoch 1741 of 2000 took 0.096s
  training loss:		1.304973
  validation loss:		1.290868
  validation accuracy:		55.33 %
Epoch 1742 of 2000 took 0.096s
  training loss:		1.305576
  validation loss:		1.290128
  validation accuracy:		55.11 %
Epoch 1743 of 2000 took 0.096s
  training loss:		1.311831
  validation loss:		1.294498
  validation accuracy:		54.46 %
Epoch 1744 of 2000 took 0.096s
  training loss:		1.313410
  validation loss:		1.294768
  validation accuracy:		54.35 %
Epoch 1745 of 2000 took 0.096s
  training loss:		1.310989
  validation loss:		1.294749
  validation accuracy:		55.00 %
Epoch 1746 of 2000 took 0.096s
  training loss:		1.310274
  validation loss:		1.300721
  validation accuracy:		52.93 %
Epoch 1747 of 2000 took 0.096s
  training loss:		1.308810
  validation loss:		1.301000
  validation accuracy:		53.80 %
Epoch 1748 of 2000 took 0.097s
  training loss:		1.309948
  validation loss:		1.290224
  validation accuracy:		55.11 %
Epoch 1749 of 2000 took 0.096s
  training loss:		1.305135
  validation loss:		1.287365
  validation accuracy:		56.41 %
Epoch 1750 of 2000 took 0.096s
  training loss:		1.313252
  validation loss:		1.288918
  validation accuracy:		55.43 %
Epoch 1751 of 2000 took 0.096s
  training loss:		1.317439
  validation loss:		1.304294
  validation accuracy:		53.48 %
Epoch 1752 of 2000 took 0.096s
  training loss:		1.309653
  validation loss:		1.304068
  validation accuracy:		53.37 %
Epoch 1753 of 2000 took 0.096s
  training loss:		1.314137
  validation loss:		1.291952
  validation accuracy:		54.89 %
Epoch 1754 of 2000 took 0.096s
  training loss:		1.301562
  validation loss:		1.293098
  validation accuracy:		55.00 %
Epoch 1755 of 2000 took 0.096s
  training loss:		1.300452
  validation loss:		1.283778
  validation accuracy:		54.89 %
Epoch 1756 of 2000 took 0.096s
  training loss:		1.310841
  validation loss:		1.292109
  validation accuracy:		54.35 %
Epoch 1757 of 2000 took 0.096s
  training loss:		1.313125
  validation loss:		1.299289
  validation accuracy:		54.02 %
Epoch 1758 of 2000 took 0.096s
  training loss:		1.308930
  validation loss:		1.297667
  validation accuracy:		54.78 %
Epoch 1759 of 2000 took 0.096s
  training loss:		1.305918
  validation loss:		1.288442
  validation accuracy:		54.57 %
Epoch 1760 of 2000 took 0.098s
  training loss:		1.314244
  validation loss:		1.292095
  validation accuracy:		54.57 %
Epoch 1761 of 2000 took 0.096s
  training loss:		1.315510
  validation loss:		1.294858
  validation accuracy:		54.13 %
Epoch 1762 of 2000 took 0.096s
  training loss:		1.308582
  validation loss:		1.288712
  validation accuracy:		54.67 %
Epoch 1763 of 2000 took 0.096s
  training loss:		1.305826
  validation loss:		1.287977
  validation accuracy:		55.65 %
Epoch 1764 of 2000 took 0.096s
  training loss:		1.312656
  validation loss:		1.285667
  validation accuracy:		55.54 %
Epoch 1765 of 2000 took 0.096s
  training loss:		1.318954
  validation loss:		1.290198
  validation accuracy:		55.22 %
Epoch 1766 of 2000 took 0.096s
  training loss:		1.303546
  validation loss:		1.294730
  validation accuracy:		54.02 %
Epoch 1767 of 2000 took 0.096s
  training loss:		1.301856
  validation loss:		1.299475
  validation accuracy:		53.70 %
Epoch 1768 of 2000 took 0.096s
  training loss:		1.306076
  validation loss:		1.292686
  validation accuracy:		54.46 %
Epoch 1769 of 2000 took 0.096s
  training loss:		1.299906
  validation loss:		1.286824
  validation accuracy:		56.09 %
Epoch 1770 of 2000 took 0.096s
  training loss:		1.312960
  validation loss:		1.287675
  validation accuracy:		55.33 %
Epoch 1771 of 2000 took 0.096s
  training loss:		1.306135
  validation loss:		1.288063
  validation accuracy:		55.22 %
Epoch 1772 of 2000 took 0.096s
  training loss:		1.317323
  validation loss:		1.290702
  validation accuracy:		55.33 %
Epoch 1773 of 2000 took 0.096s
  training loss:		1.307893
  validation loss:		1.289027
  validation accuracy:		55.43 %
Epoch 1774 of 2000 took 0.096s
  training loss:		1.307803
  validation loss:		1.288843
  validation accuracy:		55.76 %
Epoch 1775 of 2000 took 0.096s
  training loss:		1.302642
  validation loss:		1.291006
  validation accuracy:		56.09 %
Epoch 1776 of 2000 took 0.096s
  training loss:		1.307939
  validation loss:		1.292383
  validation accuracy:		54.78 %
Epoch 1777 of 2000 took 0.096s
  training loss:		1.321301
  validation loss:		1.290528
  validation accuracy:		55.54 %
Epoch 1778 of 2000 took 0.096s
  training loss:		1.305783
  validation loss:		1.287390
  validation accuracy:		55.65 %
Epoch 1779 of 2000 took 0.096s
  training loss:		1.313172
  validation loss:		1.293769
  validation accuracy:		54.13 %
Epoch 1780 of 2000 took 0.097s
  training loss:		1.307828
  validation loss:		1.300202
  validation accuracy:		53.91 %
Epoch 1781 of 2000 took 0.096s
  training loss:		1.311236
  validation loss:		1.293853
  validation accuracy:		54.24 %
Epoch 1782 of 2000 took 0.096s
  training loss:		1.309227
  validation loss:		1.297854
  validation accuracy:		54.02 %
Epoch 1783 of 2000 took 0.096s
  training loss:		1.313302
  validation loss:		1.287610
  validation accuracy:		55.65 %
Epoch 1784 of 2000 took 0.096s
  training loss:		1.308864
  validation loss:		1.291210
  validation accuracy:		54.57 %
Epoch 1785 of 2000 took 0.096s
  training loss:		1.310481
  validation loss:		1.298706
  validation accuracy:		53.59 %
Epoch 1786 of 2000 took 0.096s
  training loss:		1.319727
  validation loss:		1.297750
  validation accuracy:		54.02 %
Epoch 1787 of 2000 took 0.096s
  training loss:		1.308307
  validation loss:		1.304452
  validation accuracy:		54.13 %
Epoch 1788 of 2000 took 0.096s
  training loss:		1.305040
  validation loss:		1.295009
  validation accuracy:		53.80 %
Epoch 1789 of 2000 took 0.096s
  training loss:		1.302369
  validation loss:		1.289642
  validation accuracy:		55.00 %
Epoch 1790 of 2000 took 0.096s
  training loss:		1.314996
  validation loss:		1.286953
  validation accuracy:		55.54 %
Epoch 1791 of 2000 took 0.096s
  training loss:		1.311732
  validation loss:		1.296822
  validation accuracy:		54.67 %
Epoch 1792 of 2000 took 0.096s
  training loss:		1.314460
  validation loss:		1.293230
  validation accuracy:		55.22 %
Epoch 1793 of 2000 took 0.096s
  training loss:		1.313416
  validation loss:		1.291717
  validation accuracy:		55.11 %
Epoch 1794 of 2000 took 0.096s
  training loss:		1.296498
  validation loss:		1.289483
  validation accuracy:		55.22 %
Epoch 1795 of 2000 took 0.096s
  training loss:		1.314658
  validation loss:		1.287943
  validation accuracy:		55.22 %
Epoch 1796 of 2000 took 0.096s
  training loss:		1.310201
  validation loss:		1.307460
  validation accuracy:		53.37 %
Epoch 1797 of 2000 took 0.096s
  training loss:		1.316211
  validation loss:		1.293196
  validation accuracy:		54.89 %
Epoch 1798 of 2000 took 0.096s
  training loss:		1.318312
  validation loss:		1.290743
  validation accuracy:		55.11 %
Epoch 1799 of 2000 took 0.096s
  training loss:		1.307921
  validation loss:		1.292864
  validation accuracy:		55.22 %
Epoch 1800 of 2000 took 0.099s
  training loss:		1.296830
  validation loss:		1.307453
  validation accuracy:		54.13 %
Epoch 1801 of 2000 took 0.099s
  training loss:		1.314317
  validation loss:		1.292817
  validation accuracy:		54.89 %
Epoch 1802 of 2000 took 0.099s
  training loss:		1.302400
  validation loss:		1.299966
  validation accuracy:		53.59 %
Epoch 1803 of 2000 took 0.099s
  training loss:		1.317731
  validation loss:		1.286154
  validation accuracy:		54.89 %
Epoch 1804 of 2000 took 0.099s
  training loss:		1.310048
  validation loss:		1.290832
  validation accuracy:		55.65 %
Epoch 1805 of 2000 took 0.099s
  training loss:		1.300748
  validation loss:		1.290233
  validation accuracy:		55.33 %
Epoch 1806 of 2000 took 0.099s
  training loss:		1.315184
  validation loss:		1.296266
  validation accuracy:		54.46 %
Epoch 1807 of 2000 took 0.099s
  training loss:		1.302438
  validation loss:		1.292383
  validation accuracy:		54.78 %
Epoch 1808 of 2000 took 0.099s
  training loss:		1.311988
  validation loss:		1.289212
  validation accuracy:		55.22 %
Epoch 1809 of 2000 took 0.099s
  training loss:		1.306902
  validation loss:		1.294126
  validation accuracy:		54.13 %
Epoch 1810 of 2000 took 0.099s
  training loss:		1.303201
  validation loss:		1.289918
  validation accuracy:		56.30 %
Epoch 1811 of 2000 took 0.100s
  training loss:		1.310931
  validation loss:		1.313946
  validation accuracy:		53.91 %
Epoch 1812 of 2000 took 0.099s
  training loss:		1.305650
  validation loss:		1.289590
  validation accuracy:		54.89 %
Epoch 1813 of 2000 took 0.099s
  training loss:		1.306835
  validation loss:		1.288616
  validation accuracy:		54.67 %
Epoch 1814 of 2000 took 0.099s
  training loss:		1.317076
  validation loss:		1.292540
  validation accuracy:		54.35 %
Epoch 1815 of 2000 took 0.099s
  training loss:		1.300942
  validation loss:		1.292344
  validation accuracy:		55.43 %
Epoch 1816 of 2000 took 0.099s
  training loss:		1.309045
  validation loss:		1.291063
  validation accuracy:		55.54 %
Epoch 1817 of 2000 took 0.097s
  training loss:		1.306620
  validation loss:		1.291341
  validation accuracy:		54.24 %
Epoch 1818 of 2000 took 0.096s
  training loss:		1.300067
  validation loss:		1.289526
  validation accuracy:		54.89 %
Epoch 1819 of 2000 took 0.096s
  training loss:		1.301389
  validation loss:		1.290750
  validation accuracy:		55.33 %
Epoch 1820 of 2000 took 0.096s
  training loss:		1.302793
  validation loss:		1.288513
  validation accuracy:		55.11 %
Epoch 1821 of 2000 took 0.096s
  training loss:		1.308119
  validation loss:		1.290524
  validation accuracy:		56.30 %
Epoch 1822 of 2000 took 0.096s
  training loss:		1.316640
  validation loss:		1.308470
  validation accuracy:		54.24 %
Epoch 1823 of 2000 took 0.096s
  training loss:		1.310216
  validation loss:		1.292105
  validation accuracy:		55.00 %
Epoch 1824 of 2000 took 0.096s
  training loss:		1.304977
  validation loss:		1.298256
  validation accuracy:		54.02 %
Epoch 1825 of 2000 took 0.096s
  training loss:		1.317039
  validation loss:		1.292639
  validation accuracy:		54.67 %
Epoch 1826 of 2000 took 0.096s
  training loss:		1.318569
  validation loss:		1.290489
  validation accuracy:		54.78 %
Epoch 1827 of 2000 took 0.096s
  training loss:		1.309102
  validation loss:		1.291393
  validation accuracy:		55.98 %
Epoch 1828 of 2000 took 0.096s
  training loss:		1.311439
  validation loss:		1.295526
  validation accuracy:		54.02 %
Epoch 1829 of 2000 took 0.096s
  training loss:		1.314499
  validation loss:		1.292325
  validation accuracy:		54.67 %
Epoch 1830 of 2000 took 0.096s
  training loss:		1.308271
  validation loss:		1.298771
  validation accuracy:		53.80 %
Epoch 1831 of 2000 took 0.096s
  training loss:		1.318090
  validation loss:		1.294046
  validation accuracy:		54.46 %
Epoch 1832 of 2000 took 0.096s
  training loss:		1.311683
  validation loss:		1.288327
  validation accuracy:		55.43 %
Epoch 1833 of 2000 took 0.096s
  training loss:		1.309323
  validation loss:		1.285897
  validation accuracy:		55.98 %
Epoch 1834 of 2000 took 0.096s
  training loss:		1.306604
  validation loss:		1.299726
  validation accuracy:		53.70 %
Epoch 1835 of 2000 took 0.096s
  training loss:		1.313573
  validation loss:		1.293221
  validation accuracy:		54.24 %
Epoch 1836 of 2000 took 0.096s
  training loss:		1.307320
  validation loss:		1.291299
  validation accuracy:		55.22 %
Epoch 1837 of 2000 took 0.096s
  training loss:		1.303988
  validation loss:		1.289511
  validation accuracy:		55.33 %
Epoch 1838 of 2000 took 0.096s
  training loss:		1.301010
  validation loss:		1.293521
  validation accuracy:		54.67 %
Epoch 1839 of 2000 took 0.096s
  training loss:		1.303060
  validation loss:		1.293016
  validation accuracy:		54.46 %
Epoch 1840 of 2000 took 0.096s
  training loss:		1.298883
  validation loss:		1.287001
  validation accuracy:		55.54 %
Epoch 1841 of 2000 took 0.096s
  training loss:		1.309110
  validation loss:		1.286541
  validation accuracy:		55.87 %
Epoch 1842 of 2000 took 0.097s
  training loss:		1.310549
  validation loss:		1.289146
  validation accuracy:		55.87 %
Epoch 1843 of 2000 took 0.096s
  training loss:		1.305859
  validation loss:		1.290233
  validation accuracy:		55.33 %
Epoch 1844 of 2000 took 0.096s
  training loss:		1.311313
  validation loss:		1.291707
  validation accuracy:		53.91 %
Epoch 1845 of 2000 took 0.096s
  training loss:		1.313450
  validation loss:		1.297087
  validation accuracy:		53.91 %
Epoch 1846 of 2000 took 0.096s
  training loss:		1.307780
  validation loss:		1.289755
  validation accuracy:		55.76 %
Epoch 1847 of 2000 took 0.096s
  training loss:		1.305136
  validation loss:		1.307500
  validation accuracy:		54.24 %
Epoch 1848 of 2000 took 0.096s
  training loss:		1.311210
  validation loss:		1.293212
  validation accuracy:		54.35 %
Epoch 1849 of 2000 took 0.096s
  training loss:		1.311413
  validation loss:		1.306681
  validation accuracy:		54.35 %
Epoch 1850 of 2000 took 0.096s
  training loss:		1.308916
  validation loss:		1.293609
  validation accuracy:		54.57 %
Epoch 1851 of 2000 took 0.096s
  training loss:		1.312939
  validation loss:		1.288747
  validation accuracy:		55.00 %
Epoch 1852 of 2000 took 0.096s
  training loss:		1.312971
  validation loss:		1.287964
  validation accuracy:		55.65 %
Epoch 1853 of 2000 took 0.096s
  training loss:		1.299055
  validation loss:		1.287227
  validation accuracy:		54.02 %
Epoch 1854 of 2000 took 0.096s
  training loss:		1.305708
  validation loss:		1.288062
  validation accuracy:		55.76 %
Epoch 1855 of 2000 took 0.096s
  training loss:		1.317656
  validation loss:		1.309507
  validation accuracy:		53.70 %
Epoch 1856 of 2000 took 0.096s
  training loss:		1.299410
  validation loss:		1.289545
  validation accuracy:		55.11 %
Epoch 1857 of 2000 took 0.096s
  training loss:		1.319920
  validation loss:		1.289145
  validation accuracy:		55.54 %
Epoch 1858 of 2000 took 0.096s
  training loss:		1.312850
  validation loss:		1.290860
  validation accuracy:		54.67 %
Epoch 1859 of 2000 took 0.096s
  training loss:		1.306549
  validation loss:		1.291398
  validation accuracy:		55.33 %
Epoch 1860 of 2000 took 0.096s
  training loss:		1.303919
  validation loss:		1.285610
  validation accuracy:		54.78 %
Epoch 1861 of 2000 took 0.096s
  training loss:		1.301513
  validation loss:		1.287556
  validation accuracy:		54.02 %
Epoch 1862 of 2000 took 0.096s
  training loss:		1.302924
  validation loss:		1.292133
  validation accuracy:		54.67 %
Epoch 1863 of 2000 took 0.096s
  training loss:		1.303516
  validation loss:		1.283794
  validation accuracy:		55.00 %
Epoch 1864 of 2000 took 0.096s
  training loss:		1.305585
  validation loss:		1.292569
  validation accuracy:		54.78 %
Epoch 1865 of 2000 took 0.096s
  training loss:		1.300630
  validation loss:		1.286165
  validation accuracy:		54.57 %
Epoch 1866 of 2000 took 0.096s
  training loss:		1.306688
  validation loss:		1.317824
  validation accuracy:		52.93 %
Epoch 1867 of 2000 took 0.096s
  training loss:		1.322547
  validation loss:		1.300435
  validation accuracy:		54.13 %
Epoch 1868 of 2000 took 0.096s
  training loss:		1.303697
  validation loss:		1.301712
  validation accuracy:		54.46 %
Epoch 1869 of 2000 took 0.096s
  training loss:		1.307670
  validation loss:		1.289477
  validation accuracy:		54.67 %
Epoch 1870 of 2000 took 0.096s
  training loss:		1.313180
  validation loss:		1.292829
  validation accuracy:		54.46 %
Epoch 1871 of 2000 took 0.096s
  training loss:		1.309888
  validation loss:		1.291905
  validation accuracy:		54.78 %
Epoch 1872 of 2000 took 0.096s
  training loss:		1.312013
  validation loss:		1.317558
  validation accuracy:		53.48 %
Epoch 1873 of 2000 took 0.097s
  training loss:		1.311062
  validation loss:		1.294168
  validation accuracy:		55.00 %
Epoch 1874 of 2000 took 0.096s
  training loss:		1.315092
  validation loss:		1.298023
  validation accuracy:		53.70 %
Epoch 1875 of 2000 took 0.096s
  training loss:		1.304437
  validation loss:		1.292381
  validation accuracy:		54.46 %
Epoch 1876 of 2000 took 0.096s
  training loss:		1.307828
  validation loss:		1.290595
  validation accuracy:		54.78 %
Epoch 1877 of 2000 took 0.096s
  training loss:		1.307469
  validation loss:		1.288841
  validation accuracy:		54.67 %
Epoch 1878 of 2000 took 0.096s
  training loss:		1.315154
  validation loss:		1.294500
  validation accuracy:		54.46 %
Epoch 1879 of 2000 took 0.096s
  training loss:		1.310322
  validation loss:		1.291597
  validation accuracy:		54.89 %
Epoch 1880 of 2000 took 0.096s
  training loss:		1.301241
  validation loss:		1.294411
  validation accuracy:		53.91 %
Epoch 1881 of 2000 took 0.096s
  training loss:		1.299500
  validation loss:		1.290902
  validation accuracy:		54.78 %
Epoch 1882 of 2000 took 0.096s
  training loss:		1.306069
  validation loss:		1.292184
  validation accuracy:		55.22 %
Epoch 1883 of 2000 took 0.096s
  training loss:		1.304026
  validation loss:		1.293123
  validation accuracy:		54.67 %
Epoch 1884 of 2000 took 0.096s
  training loss:		1.308341
  validation loss:		1.290874
  validation accuracy:		56.52 %
Epoch 1885 of 2000 took 0.096s
  training loss:		1.309505
  validation loss:		1.295772
  validation accuracy:		54.46 %
Epoch 1886 of 2000 took 0.096s
  training loss:		1.295350
  validation loss:		1.295267
  validation accuracy:		54.67 %
Epoch 1887 of 2000 took 0.096s
  training loss:		1.310276
  validation loss:		1.297640
  validation accuracy:		53.70 %
Epoch 1888 of 2000 took 0.096s
  training loss:		1.314424
  validation loss:		1.289579
  validation accuracy:		55.00 %
Epoch 1889 of 2000 took 0.096s
  training loss:		1.302189
  validation loss:		1.296788
  validation accuracy:		54.57 %
Epoch 1890 of 2000 took 0.096s
  training loss:		1.307629
  validation loss:		1.289566
  validation accuracy:		54.89 %
Epoch 1891 of 2000 took 0.096s
  training loss:		1.309477
  validation loss:		1.289695
  validation accuracy:		55.76 %
Epoch 1892 of 2000 took 0.096s
  training loss:		1.311415
  validation loss:		1.301577
  validation accuracy:		53.80 %
Epoch 1893 of 2000 took 0.096s
  training loss:		1.306239
  validation loss:		1.299850
  validation accuracy:		53.48 %
Epoch 1894 of 2000 took 0.096s
  training loss:		1.306635
  validation loss:		1.292949
  validation accuracy:		54.67 %
Epoch 1895 of 2000 took 0.096s
  training loss:		1.317079
  validation loss:		1.293681
  validation accuracy:		54.57 %
Epoch 1896 of 2000 took 0.096s
  training loss:		1.303546
  validation loss:		1.296186
  validation accuracy:		54.24 %
Epoch 1897 of 2000 took 0.102s
  training loss:		1.312363
  validation loss:		1.293739
  validation accuracy:		54.02 %
Epoch 1898 of 2000 took 0.103s
  training loss:		1.305434
  validation loss:		1.289171
  validation accuracy:		55.22 %
Epoch 1899 of 2000 took 0.102s
  training loss:		1.311191
  validation loss:		1.291710
  validation accuracy:		54.89 %
Epoch 1900 of 2000 took 0.102s
  training loss:		1.319955
  validation loss:		1.288370
  validation accuracy:		55.65 %
Epoch 1901 of 2000 took 0.102s
  training loss:		1.310344
  validation loss:		1.291304
  validation accuracy:		55.87 %
Epoch 1902 of 2000 took 0.102s
  training loss:		1.308114
  validation loss:		1.292498
  validation accuracy:		54.78 %
Epoch 1903 of 2000 took 0.102s
  training loss:		1.306606
  validation loss:		1.289750
  validation accuracy:		55.33 %
Epoch 1904 of 2000 took 0.102s
  training loss:		1.309512
  validation loss:		1.291924
  validation accuracy:		54.89 %
Epoch 1905 of 2000 took 0.099s
  training loss:		1.306433
  validation loss:		1.289730
  validation accuracy:		55.65 %
Epoch 1906 of 2000 took 0.099s
  training loss:		1.303058
  validation loss:		1.299259
  validation accuracy:		53.80 %
Epoch 1907 of 2000 took 0.099s
  training loss:		1.312817
  validation loss:		1.294297
  validation accuracy:		54.35 %
Epoch 1908 of 2000 took 0.099s
  training loss:		1.305212
  validation loss:		1.291638
  validation accuracy:		54.35 %
Epoch 1909 of 2000 took 0.099s
  training loss:		1.303124
  validation loss:		1.286568
  validation accuracy:		54.89 %
Epoch 1910 of 2000 took 0.099s
  training loss:		1.311431
  validation loss:		1.285550
  validation accuracy:		55.43 %
Epoch 1911 of 2000 took 0.099s
  training loss:		1.310644
  validation loss:		1.305735
  validation accuracy:		53.26 %
Epoch 1912 of 2000 took 0.099s
  training loss:		1.308160
  validation loss:		1.294485
  validation accuracy:		55.00 %
Epoch 1913 of 2000 took 0.098s
  training loss:		1.306859
  validation loss:		1.292545
  validation accuracy:		54.67 %
Epoch 1914 of 2000 took 0.096s
  training loss:		1.303590
  validation loss:		1.285149
  validation accuracy:		55.65 %
Epoch 1915 of 2000 took 0.096s
  training loss:		1.309261
  validation loss:		1.292485
  validation accuracy:		54.02 %
Epoch 1916 of 2000 took 0.096s
  training loss:		1.306719
  validation loss:		1.294967
  validation accuracy:		54.57 %
Epoch 1917 of 2000 took 0.096s
  training loss:		1.301794
  validation loss:		1.315354
  validation accuracy:		54.13 %
Epoch 1918 of 2000 took 0.096s
  training loss:		1.317443
  validation loss:		1.313734
  validation accuracy:		54.02 %
Epoch 1919 of 2000 took 0.096s
  training loss:		1.313848
  validation loss:		1.290630
  validation accuracy:		55.65 %
Epoch 1920 of 2000 took 0.096s
  training loss:		1.306657
  validation loss:		1.298153
  validation accuracy:		55.00 %
Epoch 1921 of 2000 took 0.096s
  training loss:		1.307662
  validation loss:		1.288380
  validation accuracy:		56.09 %
Epoch 1922 of 2000 took 0.096s
  training loss:		1.307120
  validation loss:		1.292718
  validation accuracy:		54.78 %
Epoch 1923 of 2000 took 0.096s
  training loss:		1.295114
  validation loss:		1.289736
  validation accuracy:		55.11 %
Epoch 1924 of 2000 took 0.096s
  training loss:		1.305335
  validation loss:		1.295501
  validation accuracy:		54.24 %
Epoch 1925 of 2000 took 0.096s
  training loss:		1.302098
  validation loss:		1.287864
  validation accuracy:		55.43 %
Epoch 1926 of 2000 took 0.096s
  training loss:		1.307874
  validation loss:		1.290244
  validation accuracy:		54.89 %
Epoch 1927 of 2000 took 0.096s
  training loss:		1.306550
  validation loss:		1.300470
  validation accuracy:		54.35 %
Epoch 1928 of 2000 took 0.096s
  training loss:		1.305056
  validation loss:		1.290661
  validation accuracy:		54.89 %
Epoch 1929 of 2000 took 0.096s
  training loss:		1.303547
  validation loss:		1.289284
  validation accuracy:		55.43 %
Epoch 1930 of 2000 took 0.096s
  training loss:		1.310355
  validation loss:		1.296523
  validation accuracy:		54.78 %
Epoch 1931 of 2000 took 0.096s
  training loss:		1.311143
  validation loss:		1.290807
  validation accuracy:		54.89 %
Epoch 1932 of 2000 took 0.096s
  training loss:		1.306718
  validation loss:		1.289398
  validation accuracy:		55.33 %
Epoch 1933 of 2000 took 0.096s
  training loss:		1.314018
  validation loss:		1.297592
  validation accuracy:		54.46 %
Epoch 1934 of 2000 took 0.096s
  training loss:		1.309587
  validation loss:		1.299225
  validation accuracy:		54.78 %
Epoch 1935 of 2000 took 0.097s
  training loss:		1.299456
  validation loss:		1.294888
  validation accuracy:		54.78 %
Epoch 1936 of 2000 took 0.096s
  training loss:		1.305040
  validation loss:		1.288475
  validation accuracy:		54.46 %
Epoch 1937 of 2000 took 0.096s
  training loss:		1.310785
  validation loss:		1.284962
  validation accuracy:		55.00 %
Epoch 1938 of 2000 took 0.096s
  training loss:		1.321933
  validation loss:		1.293405
  validation accuracy:		55.98 %
Epoch 1939 of 2000 took 0.096s
  training loss:		1.311240
  validation loss:		1.290454
  validation accuracy:		55.65 %
Epoch 1940 of 2000 took 0.096s
  training loss:		1.313261
  validation loss:		1.322798
  validation accuracy:		53.59 %
Epoch 1941 of 2000 took 0.096s
  training loss:		1.309799
  validation loss:		1.293435
  validation accuracy:		55.43 %
Epoch 1942 of 2000 took 0.096s
  training loss:		1.314820
  validation loss:		1.293579
  validation accuracy:		54.35 %
Epoch 1943 of 2000 took 0.096s
  training loss:		1.304084
  validation loss:		1.306789
  validation accuracy:		54.46 %
Epoch 1944 of 2000 took 0.096s
  training loss:		1.317824
  validation loss:		1.284405
  validation accuracy:		54.89 %
Epoch 1945 of 2000 took 0.096s
  training loss:		1.300437
  validation loss:		1.286533
  validation accuracy:		55.87 %
Epoch 1946 of 2000 took 0.096s
  training loss:		1.309206
  validation loss:		1.294205
  validation accuracy:		54.78 %
Epoch 1947 of 2000 took 0.096s
  training loss:		1.314466
  validation loss:		1.291893
  validation accuracy:		55.00 %
Epoch 1948 of 2000 took 0.096s
  training loss:		1.309076
  validation loss:		1.291898
  validation accuracy:		54.89 %
Epoch 1949 of 2000 took 0.096s
  training loss:		1.312692
  validation loss:		1.298330
  validation accuracy:		54.24 %
Epoch 1950 of 2000 took 0.096s
  training loss:		1.309753
  validation loss:		1.296207
  validation accuracy:		53.80 %
Epoch 1951 of 2000 took 0.096s
  training loss:		1.316478
  validation loss:		1.290130
  validation accuracy:		54.78 %
Epoch 1952 of 2000 took 0.096s
  training loss:		1.305566
  validation loss:		1.308371
  validation accuracy:		53.59 %
Epoch 1953 of 2000 took 0.096s
  training loss:		1.309356
  validation loss:		1.293438
  validation accuracy:		54.78 %
Epoch 1954 of 2000 took 0.096s
  training loss:		1.309873
  validation loss:		1.293698
  validation accuracy:		54.67 %
Epoch 1955 of 2000 took 0.096s
  training loss:		1.308658
  validation loss:		1.297134
  validation accuracy:		54.46 %
Epoch 1956 of 2000 took 0.096s
  training loss:		1.306737
  validation loss:		1.289491
  validation accuracy:		55.33 %
Epoch 1957 of 2000 took 0.096s
  training loss:		1.313425
  validation loss:		1.307150
  validation accuracy:		53.70 %
Epoch 1958 of 2000 took 0.096s
  training loss:		1.314054
  validation loss:		1.291227
  validation accuracy:		54.89 %
Epoch 1959 of 2000 took 0.096s
  training loss:		1.308707
  validation loss:		1.338711
  validation accuracy:		51.96 %
Epoch 1960 of 2000 took 0.096s
  training loss:		1.303543
  validation loss:		1.292231
  validation accuracy:		54.13 %
Epoch 1961 of 2000 took 0.096s
  training loss:		1.309398
  validation loss:		1.290017
  validation accuracy:		55.54 %
Epoch 1962 of 2000 took 0.096s
  training loss:		1.313389
  validation loss:		1.290257
  validation accuracy:		55.22 %
Epoch 1963 of 2000 took 0.096s
  training loss:		1.313963
  validation loss:		1.286281
  validation accuracy:		54.78 %
Epoch 1964 of 2000 took 0.096s
  training loss:		1.301680
  validation loss:		1.297146
  validation accuracy:		53.59 %
Epoch 1965 of 2000 took 0.096s
  training loss:		1.310378
  validation loss:		1.295761
  validation accuracy:		54.35 %
Epoch 1966 of 2000 took 0.097s
  training loss:		1.315711
  validation loss:		1.290624
  validation accuracy:		55.33 %
Epoch 1967 of 2000 took 0.096s
  training loss:		1.309550
  validation loss:		1.292078
  validation accuracy:		54.46 %
Epoch 1968 of 2000 took 0.096s
  training loss:		1.312869
  validation loss:		1.291448
  validation accuracy:		55.00 %
Epoch 1969 of 2000 took 0.097s
  training loss:		1.317211
  validation loss:		1.291862
  validation accuracy:		55.65 %
Epoch 1970 of 2000 took 0.096s
  training loss:		1.309900
  validation loss:		1.288176
  validation accuracy:		56.20 %
Epoch 1971 of 2000 took 0.096s
  training loss:		1.306893
  validation loss:		1.290816
  validation accuracy:		55.00 %
Epoch 1972 of 2000 took 0.096s
  training loss:		1.310906
  validation loss:		1.288666
  validation accuracy:		55.43 %
Epoch 1973 of 2000 took 0.096s
  training loss:		1.306085
  validation loss:		1.292219
  validation accuracy:		54.13 %
Epoch 1974 of 2000 took 0.096s
  training loss:		1.302869
  validation loss:		1.289076
  validation accuracy:		54.89 %
Epoch 1975 of 2000 took 0.096s
  training loss:		1.307172
  validation loss:		1.309751
  validation accuracy:		54.13 %
Epoch 1976 of 2000 took 0.096s
  training loss:		1.304820
  validation loss:		1.302759
  validation accuracy:		53.80 %
Epoch 1977 of 2000 took 0.096s
  training loss:		1.306225
  validation loss:		1.294967
  validation accuracy:		54.13 %
Epoch 1978 of 2000 took 0.096s
  training loss:		1.314724
  validation loss:		1.291755
  validation accuracy:		54.67 %
Epoch 1979 of 2000 took 0.096s
  training loss:		1.307125
  validation loss:		1.287465
  validation accuracy:		56.63 %
Epoch 1980 of 2000 took 0.096s
  training loss:		1.305175
  validation loss:		1.288303
  validation accuracy:		54.67 %
Epoch 1981 of 2000 took 0.096s
  training loss:		1.308116
  validation loss:		1.286007
  validation accuracy:		56.09 %
Epoch 1982 of 2000 took 0.096s
  training loss:		1.306276
  validation loss:		1.307753
  validation accuracy:		54.24 %
Epoch 1983 of 2000 took 0.096s
  training loss:		1.311328
  validation loss:		1.286928
  validation accuracy:		55.00 %
Epoch 1984 of 2000 took 0.096s
  training loss:		1.296415
  validation loss:		1.293459
  validation accuracy:		54.67 %
Epoch 1985 of 2000 took 0.096s
  training loss:		1.314949
  validation loss:		1.289061
  validation accuracy:		55.00 %
Epoch 1986 of 2000 took 0.096s
  training loss:		1.310499
  validation loss:		1.306376
  validation accuracy:		54.13 %
Epoch 1987 of 2000 took 0.096s
  training loss:		1.314510
  validation loss:		1.295776
  validation accuracy:		54.24 %
Epoch 1988 of 2000 took 0.096s
  training loss:		1.304490
  validation loss:		1.290442
  validation accuracy:		54.89 %
Epoch 1989 of 2000 took 0.096s
  training loss:		1.311804
  validation loss:		1.292264
  validation accuracy:		55.98 %
Epoch 1990 of 2000 took 0.096s
  training loss:		1.309991
  validation loss:		1.290846
  validation accuracy:		55.11 %
Epoch 1991 of 2000 took 0.096s
  training loss:		1.309730
  validation loss:		1.302270
  validation accuracy:		54.02 %
Epoch 1992 of 2000 took 0.096s
  training loss:		1.304282
  validation loss:		1.319469
  validation accuracy:		53.91 %
Epoch 1993 of 2000 took 0.096s
  training loss:		1.310040
  validation loss:		1.291615
  validation accuracy:		55.00 %
Epoch 1994 of 2000 took 0.096s
  training loss:		1.311049
  validation loss:		1.293484
  validation accuracy:		55.00 %
Epoch 1995 of 2000 took 0.096s
  training loss:		1.304556
  validation loss:		1.290491
  validation accuracy:		54.24 %
Epoch 1996 of 2000 took 0.096s
  training loss:		1.303819
  validation loss:		1.309008
  validation accuracy:		53.91 %
Epoch 1997 of 2000 took 0.096s
  training loss:		1.303956
  validation loss:		1.289748
  validation accuracy:		54.67 %
Epoch 1998 of 2000 took 0.097s
  training loss:		1.305107
  validation loss:		1.302681
  validation accuracy:		54.02 %
Epoch 1999 of 2000 took 0.096s
  training loss:		1.304295
  validation loss:		1.291247
  validation accuracy:		55.11 %
Epoch 2000 of 2000 took 0.096s
  training loss:		1.303014
  validation loss:		1.295258
  validation accuracy:		54.89 %
Final results:
  test loss:			1.496434
  test accuracy:		49.63 %
