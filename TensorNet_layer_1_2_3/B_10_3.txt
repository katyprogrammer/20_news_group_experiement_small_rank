Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 200),b=(200,)
w=(200, 200),b=(200,)
w=(200, 200),b=(200,)
decomposing tensor W of shape (3, 200, 200)...
decomposing tensor B of shape (3, 200)...
Starting training...
Epoch 1 of 2000 took 0.051s
  training loss:		2.855520
  validation loss:		2.518143
  validation accuracy:		29.13 %
Epoch 2 of 2000 took 0.043s
  training loss:		2.355192
  validation loss:		2.031351
  validation accuracy:		34.13 %
Epoch 3 of 2000 took 0.040s
  training loss:		2.035979
  validation loss:		1.873248
  validation accuracy:		35.54 %
Epoch 4 of 2000 took 0.038s
  training loss:		1.920552
  validation loss:		1.793016
  validation accuracy:		36.85 %
Epoch 5 of 2000 took 0.038s
  training loss:		1.868087
  validation loss:		1.722326
  validation accuracy:		39.46 %
Epoch 6 of 2000 took 0.038s
  training loss:		1.817947
  validation loss:		1.685839
  validation accuracy:		39.02 %
Epoch 7 of 2000 took 0.037s
  training loss:		1.760301
  validation loss:		1.644383
  validation accuracy:		42.50 %
Epoch 8 of 2000 took 0.037s
  training loss:		1.720726
  validation loss:		1.597422
  validation accuracy:		44.13 %
Epoch 9 of 2000 took 0.038s
  training loss:		1.670437
  validation loss:		1.539241
  validation accuracy:		44.67 %
Epoch 10 of 2000 took 0.043s
  training loss:		1.624883
  validation loss:		1.503929
  validation accuracy:		46.20 %
Epoch 11 of 2000 took 0.054s
  training loss:		1.570537
  validation loss:		1.437243
  validation accuracy:		48.70 %
Epoch 12 of 2000 took 0.044s
  training loss:		1.535913
  validation loss:		1.422920
  validation accuracy:		49.02 %
Epoch 13 of 2000 took 0.041s
  training loss:		1.485068
  validation loss:		1.364404
  validation accuracy:		50.65 %
Epoch 14 of 2000 took 0.038s
  training loss:		1.446250
  validation loss:		1.339113
  validation accuracy:		51.63 %
Epoch 15 of 2000 took 0.038s
  training loss:		1.395458
  validation loss:		1.287612
  validation accuracy:		53.48 %
Epoch 16 of 2000 took 0.038s
  training loss:		1.365101
  validation loss:		1.261883
  validation accuracy:		52.61 %
Epoch 17 of 2000 took 0.038s
  training loss:		1.324230
  validation loss:		1.220846
  validation accuracy:		55.33 %
Epoch 18 of 2000 took 0.038s
  training loss:		1.291342
  validation loss:		1.191002
  validation accuracy:		55.98 %
Epoch 19 of 2000 took 0.038s
  training loss:		1.261050
  validation loss:		1.154071
  validation accuracy:		58.37 %
Epoch 20 of 2000 took 0.038s
  training loss:		1.220900
  validation loss:		1.114985
  validation accuracy:		60.00 %
Epoch 21 of 2000 took 0.038s
  training loss:		1.194925
  validation loss:		1.095601
  validation accuracy:		60.87 %
Epoch 22 of 2000 took 0.038s
  training loss:		1.152240
  validation loss:		1.059548
  validation accuracy:		62.28 %
Epoch 23 of 2000 took 0.039s
  training loss:		1.120397
  validation loss:		1.021321
  validation accuracy:		63.91 %
Epoch 24 of 2000 took 0.038s
  training loss:		1.075688
  validation loss:		0.997212
  validation accuracy:		65.87 %
Epoch 25 of 2000 took 0.037s
  training loss:		1.057469
  validation loss:		0.961583
  validation accuracy:		67.28 %
Epoch 26 of 2000 took 0.035s
  training loss:		1.028937
  validation loss:		0.935691
  validation accuracy:		68.91 %
Epoch 27 of 2000 took 0.035s
  training loss:		1.002726
  validation loss:		0.910299
  validation accuracy:		69.78 %
Epoch 28 of 2000 took 0.035s
  training loss:		0.974869
  validation loss:		0.881111
  validation accuracy:		71.30 %
Epoch 29 of 2000 took 0.035s
  training loss:		0.929130
  validation loss:		0.846130
  validation accuracy:		71.52 %
Epoch 30 of 2000 took 0.035s
  training loss:		0.915131
  validation loss:		0.829566
  validation accuracy:		72.83 %
Epoch 31 of 2000 took 0.035s
  training loss:		0.894286
  validation loss:		0.804746
  validation accuracy:		73.70 %
Epoch 32 of 2000 took 0.035s
  training loss:		0.857956
  validation loss:		0.775032
  validation accuracy:		74.57 %
Epoch 33 of 2000 took 0.035s
  training loss:		0.844619
  validation loss:		0.759898
  validation accuracy:		75.65 %
Epoch 34 of 2000 took 0.035s
  training loss:		0.814383
  validation loss:		0.737251
  validation accuracy:		77.39 %
Epoch 35 of 2000 took 0.035s
  training loss:		0.805483
  validation loss:		0.729528
  validation accuracy:		77.50 %
Epoch 36 of 2000 took 0.035s
  training loss:		0.779129
  validation loss:		0.710522
  validation accuracy:		78.37 %
Epoch 37 of 2000 took 0.035s
  training loss:		0.757535
  validation loss:		0.681700
  validation accuracy:		78.37 %
Epoch 38 of 2000 took 0.035s
  training loss:		0.740993
  validation loss:		0.680823
  validation accuracy:		79.24 %
Epoch 39 of 2000 took 0.035s
  training loss:		0.732955
  validation loss:		0.667537
  validation accuracy:		80.00 %
Epoch 40 of 2000 took 0.035s
  training loss:		0.702875
  validation loss:		0.642958
  validation accuracy:		80.98 %
Epoch 41 of 2000 took 0.035s
  training loss:		0.690499
  validation loss:		0.629833
  validation accuracy:		80.87 %
Epoch 42 of 2000 took 0.035s
  training loss:		0.684346
  validation loss:		0.612312
  validation accuracy:		81.63 %
Epoch 43 of 2000 took 0.035s
  training loss:		0.659397
  validation loss:		0.615652
  validation accuracy:		82.39 %
Epoch 44 of 2000 took 0.035s
  training loss:		0.649169
  validation loss:		0.598397
  validation accuracy:		83.26 %
Epoch 45 of 2000 took 0.035s
  training loss:		0.641315
  validation loss:		0.587397
  validation accuracy:		83.04 %
Epoch 46 of 2000 took 0.035s
  training loss:		0.623175
  validation loss:		0.585195
  validation accuracy:		83.48 %
Epoch 47 of 2000 took 0.035s
  training loss:		0.622702
  validation loss:		0.578201
  validation accuracy:		83.26 %
Epoch 48 of 2000 took 0.035s
  training loss:		0.599037
  validation loss:		0.558310
  validation accuracy:		84.57 %
Epoch 49 of 2000 took 0.035s
  training loss:		0.604019
  validation loss:		0.564226
  validation accuracy:		84.13 %
Epoch 50 of 2000 took 0.035s
  training loss:		0.597703
  validation loss:		0.546351
  validation accuracy:		84.57 %
Epoch 51 of 2000 took 0.035s
  training loss:		0.573100
  validation loss:		0.546619
  validation accuracy:		84.67 %
Epoch 52 of 2000 took 0.035s
  training loss:		0.561982
  validation loss:		0.533405
  validation accuracy:		84.78 %
Epoch 53 of 2000 took 0.035s
  training loss:		0.565856
  validation loss:		0.531235
  validation accuracy:		85.00 %
Epoch 54 of 2000 took 0.035s
  training loss:		0.558722
  validation loss:		0.548844
  validation accuracy:		84.57 %
Epoch 55 of 2000 took 0.035s
  training loss:		0.542969
  validation loss:		0.513217
  validation accuracy:		85.33 %
Epoch 56 of 2000 took 0.035s
  training loss:		0.540399
  validation loss:		0.515306
  validation accuracy:		85.54 %
Epoch 57 of 2000 took 0.035s
  training loss:		0.536944
  validation loss:		0.502197
  validation accuracy:		85.65 %
Epoch 58 of 2000 took 0.035s
  training loss:		0.525870
  validation loss:		0.519631
  validation accuracy:		85.00 %
Epoch 59 of 2000 took 0.035s
  training loss:		0.524320
  validation loss:		0.499770
  validation accuracy:		84.78 %
Epoch 60 of 2000 took 0.035s
  training loss:		0.516265
  validation loss:		0.518050
  validation accuracy:		84.24 %
Epoch 61 of 2000 took 0.035s
  training loss:		0.516931
  validation loss:		0.502474
  validation accuracy:		84.78 %
Epoch 62 of 2000 took 0.035s
  training loss:		0.506820
  validation loss:		0.498624
  validation accuracy:		85.22 %
Epoch 63 of 2000 took 0.035s
  training loss:		0.501423
  validation loss:		0.506368
  validation accuracy:		85.33 %
Epoch 64 of 2000 took 0.035s
  training loss:		0.499079
  validation loss:		0.508215
  validation accuracy:		85.11 %
Epoch 65 of 2000 took 0.035s
  training loss:		0.492603
  validation loss:		0.469983
  validation accuracy:		85.65 %
Epoch 66 of 2000 took 0.035s
  training loss:		0.489158
  validation loss:		0.482557
  validation accuracy:		85.22 %
Epoch 67 of 2000 took 0.035s
  training loss:		0.485445
  validation loss:		0.461501
  validation accuracy:		85.76 %
Epoch 68 of 2000 took 0.035s
  training loss:		0.480207
  validation loss:		0.514803
  validation accuracy:		84.13 %
Epoch 69 of 2000 took 0.035s
  training loss:		0.480695
  validation loss:		0.500169
  validation accuracy:		84.89 %
Epoch 70 of 2000 took 0.035s
  training loss:		0.469523
  validation loss:		0.493575
  validation accuracy:		84.78 %
Epoch 71 of 2000 took 0.035s
  training loss:		0.463850
  validation loss:		0.474590
  validation accuracy:		85.22 %
Epoch 72 of 2000 took 0.035s
  training loss:		0.466175
  validation loss:		0.465011
  validation accuracy:		86.20 %
Epoch 73 of 2000 took 0.037s
  training loss:		0.457622
  validation loss:		0.464900
  validation accuracy:		86.09 %
Epoch 74 of 2000 took 0.035s
  training loss:		0.457352
  validation loss:		0.450541
  validation accuracy:		86.30 %
Epoch 75 of 2000 took 0.035s
  training loss:		0.455544
  validation loss:		0.459423
  validation accuracy:		86.20 %
Epoch 76 of 2000 took 0.035s
  training loss:		0.457335
  validation loss:		0.446126
  validation accuracy:		86.09 %
Epoch 77 of 2000 took 0.035s
  training loss:		0.447669
  validation loss:		0.460801
  validation accuracy:		86.09 %
Epoch 78 of 2000 took 0.035s
  training loss:		0.448951
  validation loss:		0.442481
  validation accuracy:		86.41 %
Epoch 79 of 2000 took 0.035s
  training loss:		0.438788
  validation loss:		0.452840
  validation accuracy:		85.98 %
Epoch 80 of 2000 took 0.035s
  training loss:		0.444059
  validation loss:		0.444377
  validation accuracy:		85.98 %
Epoch 81 of 2000 took 0.035s
  training loss:		0.441109
  validation loss:		0.461348
  validation accuracy:		85.54 %
Epoch 82 of 2000 took 0.035s
  training loss:		0.443142
  validation loss:		0.450808
  validation accuracy:		85.65 %
Epoch 83 of 2000 took 0.035s
  training loss:		0.436665
  validation loss:		0.467297
  validation accuracy:		85.33 %
Epoch 84 of 2000 took 0.035s
  training loss:		0.432048
  validation loss:		0.429830
  validation accuracy:		86.20 %
Epoch 85 of 2000 took 0.035s
  training loss:		0.433896
  validation loss:		0.453265
  validation accuracy:		85.54 %
Epoch 86 of 2000 took 0.035s
  training loss:		0.428048
  validation loss:		0.454082
  validation accuracy:		85.76 %
Epoch 87 of 2000 took 0.035s
  training loss:		0.427619
  validation loss:		0.447710
  validation accuracy:		85.98 %
Epoch 88 of 2000 took 0.035s
  training loss:		0.421885
  validation loss:		0.433968
  validation accuracy:		86.41 %
Epoch 89 of 2000 took 0.035s
  training loss:		0.421800
  validation loss:		0.447477
  validation accuracy:		85.65 %
Epoch 90 of 2000 took 0.035s
  training loss:		0.423879
  validation loss:		0.438428
  validation accuracy:		85.98 %
Epoch 91 of 2000 took 0.035s
  training loss:		0.421320
  validation loss:		0.439722
  validation accuracy:		86.09 %
Epoch 92 of 2000 took 0.035s
  training loss:		0.417667
  validation loss:		0.431063
  validation accuracy:		85.65 %
Epoch 93 of 2000 took 0.035s
  training loss:		0.417367
  validation loss:		0.419619
  validation accuracy:		87.28 %
Epoch 94 of 2000 took 0.035s
  training loss:		0.408744
  validation loss:		0.438861
  validation accuracy:		85.87 %
Epoch 95 of 2000 took 0.035s
  training loss:		0.408750
  validation loss:		0.432956
  validation accuracy:		86.30 %
Epoch 96 of 2000 took 0.035s
  training loss:		0.404755
  validation loss:		0.430095
  validation accuracy:		85.87 %
Epoch 97 of 2000 took 0.035s
  training loss:		0.417022
  validation loss:		0.431914
  validation accuracy:		86.20 %
Epoch 98 of 2000 took 0.035s
  training loss:		0.402793
  validation loss:		0.424963
  validation accuracy:		86.20 %
Epoch 99 of 2000 took 0.035s
  training loss:		0.402153
  validation loss:		0.425776
  validation accuracy:		86.41 %
Epoch 100 of 2000 took 0.035s
  training loss:		0.396935
  validation loss:		0.441474
  validation accuracy:		85.87 %
Epoch 101 of 2000 took 0.035s
  training loss:		0.401249
  validation loss:		0.429949
  validation accuracy:		86.74 %
Epoch 102 of 2000 took 0.035s
  training loss:		0.406070
  validation loss:		0.434936
  validation accuracy:		85.22 %
Epoch 103 of 2000 took 0.035s
  training loss:		0.392392
  validation loss:		0.454290
  validation accuracy:		84.46 %
Epoch 104 of 2000 took 0.035s
  training loss:		0.403228
  validation loss:		0.438789
  validation accuracy:		84.78 %
Epoch 105 of 2000 took 0.035s
  training loss:		0.400456
  validation loss:		0.430368
  validation accuracy:		85.22 %
Epoch 106 of 2000 took 0.035s
  training loss:		0.390106
  validation loss:		0.450358
  validation accuracy:		85.11 %
Epoch 107 of 2000 took 0.035s
  training loss:		0.396785
  validation loss:		0.413649
  validation accuracy:		86.41 %
Epoch 108 of 2000 took 0.035s
  training loss:		0.395208
  validation loss:		0.424433
  validation accuracy:		86.20 %
Epoch 109 of 2000 took 0.035s
  training loss:		0.385549
  validation loss:		0.431367
  validation accuracy:		85.33 %
Epoch 110 of 2000 took 0.035s
  training loss:		0.394047
  validation loss:		0.417380
  validation accuracy:		86.30 %
Epoch 111 of 2000 took 0.035s
  training loss:		0.388740
  validation loss:		0.439348
  validation accuracy:		85.65 %
Epoch 112 of 2000 took 0.035s
  training loss:		0.389523
  validation loss:		0.439821
  validation accuracy:		85.11 %
Epoch 113 of 2000 took 0.035s
  training loss:		0.394846
  validation loss:		0.431735
  validation accuracy:		85.33 %
Epoch 114 of 2000 took 0.035s
  training loss:		0.386380
  validation loss:		0.441229
  validation accuracy:		85.11 %
Epoch 115 of 2000 took 0.035s
  training loss:		0.379649
  validation loss:		0.436651
  validation accuracy:		85.76 %
Epoch 116 of 2000 took 0.035s
  training loss:		0.382758
  validation loss:		0.410446
  validation accuracy:		86.63 %
Epoch 117 of 2000 took 0.035s
  training loss:		0.387333
  validation loss:		0.456304
  validation accuracy:		84.46 %
Epoch 118 of 2000 took 0.035s
  training loss:		0.378317
  validation loss:		0.423912
  validation accuracy:		86.52 %
Epoch 119 of 2000 took 0.035s
  training loss:		0.380234
  validation loss:		0.425448
  validation accuracy:		86.30 %
Epoch 120 of 2000 took 0.035s
  training loss:		0.377806
  validation loss:		0.418502
  validation accuracy:		86.20 %
Epoch 121 of 2000 took 0.035s
  training loss:		0.374949
  validation loss:		0.440075
  validation accuracy:		85.43 %
Epoch 122 of 2000 took 0.035s
  training loss:		0.386038
  validation loss:		0.422622
  validation accuracy:		86.63 %
Epoch 123 of 2000 took 0.035s
  training loss:		0.373626
  validation loss:		0.435291
  validation accuracy:		85.65 %
Epoch 124 of 2000 took 0.035s
  training loss:		0.372109
  validation loss:		0.410863
  validation accuracy:		86.74 %
Epoch 125 of 2000 took 0.035s
  training loss:		0.366845
  validation loss:		0.427367
  validation accuracy:		85.22 %
Epoch 126 of 2000 took 0.035s
  training loss:		0.373964
  validation loss:		0.446443
  validation accuracy:		84.78 %
Epoch 127 of 2000 took 0.035s
  training loss:		0.372693
  validation loss:		0.422606
  validation accuracy:		86.63 %
Epoch 128 of 2000 took 0.035s
  training loss:		0.376621
  validation loss:		0.419161
  validation accuracy:		86.30 %
Epoch 129 of 2000 took 0.035s
  training loss:		0.373735
  validation loss:		0.431470
  validation accuracy:		85.11 %
Epoch 130 of 2000 took 0.035s
  training loss:		0.365525
  validation loss:		0.429844
  validation accuracy:		85.33 %
Epoch 131 of 2000 took 0.035s
  training loss:		0.371666
  validation loss:		0.416053
  validation accuracy:		85.87 %
Epoch 132 of 2000 took 0.035s
  training loss:		0.371007
  validation loss:		0.417577
  validation accuracy:		85.87 %
Epoch 133 of 2000 took 0.035s
  training loss:		0.374131
  validation loss:		0.403274
  validation accuracy:		86.96 %
Epoch 134 of 2000 took 0.035s
  training loss:		0.362729
  validation loss:		0.432502
  validation accuracy:		85.65 %
Epoch 135 of 2000 took 0.036s
  training loss:		0.368795
  validation loss:		0.418077
  validation accuracy:		85.98 %
Epoch 136 of 2000 took 0.035s
  training loss:		0.363228
  validation loss:		0.409720
  validation accuracy:		86.85 %
Epoch 137 of 2000 took 0.035s
  training loss:		0.368384
  validation loss:		0.402109
  validation accuracy:		87.17 %
Epoch 138 of 2000 took 0.035s
  training loss:		0.359434
  validation loss:		0.407695
  validation accuracy:		86.96 %
Epoch 139 of 2000 took 0.035s
  training loss:		0.349968
  validation loss:		0.418691
  validation accuracy:		85.54 %
Epoch 140 of 2000 took 0.035s
  training loss:		0.364069
  validation loss:		0.427365
  validation accuracy:		85.76 %
Epoch 141 of 2000 took 0.035s
  training loss:		0.361645
  validation loss:		0.415958
  validation accuracy:		86.63 %
Epoch 142 of 2000 took 0.035s
  training loss:		0.351378
  validation loss:		0.413069
  validation accuracy:		86.20 %
Epoch 143 of 2000 took 0.035s
  training loss:		0.352567
  validation loss:		0.433453
  validation accuracy:		84.89 %
Epoch 144 of 2000 took 0.035s
  training loss:		0.364784
  validation loss:		0.399485
  validation accuracy:		87.39 %
Epoch 145 of 2000 took 0.035s
  training loss:		0.362299
  validation loss:		0.403400
  validation accuracy:		87.28 %
Epoch 146 of 2000 took 0.035s
  training loss:		0.357769
  validation loss:		0.408971
  validation accuracy:		86.85 %
Epoch 147 of 2000 took 0.035s
  training loss:		0.364021
  validation loss:		0.396998
  validation accuracy:		87.39 %
Epoch 148 of 2000 took 0.035s
  training loss:		0.357845
  validation loss:		0.414972
  validation accuracy:		86.09 %
Epoch 149 of 2000 took 0.035s
  training loss:		0.356481
  validation loss:		0.404843
  validation accuracy:		86.74 %
Epoch 150 of 2000 took 0.035s
  training loss:		0.361628
  validation loss:		0.416810
  validation accuracy:		86.41 %
Epoch 151 of 2000 took 0.035s
  training loss:		0.351268
  validation loss:		0.400686
  validation accuracy:		87.17 %
Epoch 152 of 2000 took 0.035s
  training loss:		0.354485
  validation loss:		0.415483
  validation accuracy:		85.98 %
Epoch 153 of 2000 took 0.035s
  training loss:		0.352964
  validation loss:		0.413328
  validation accuracy:		86.09 %
Epoch 154 of 2000 took 0.035s
  training loss:		0.353240
  validation loss:		0.421665
  validation accuracy:		85.65 %
Epoch 155 of 2000 took 0.035s
  training loss:		0.347215
  validation loss:		0.422709
  validation accuracy:		85.87 %
Epoch 156 of 2000 took 0.035s
  training loss:		0.358254
  validation loss:		0.416825
  validation accuracy:		86.09 %
Epoch 157 of 2000 took 0.035s
  training loss:		0.354270
  validation loss:		0.439418
  validation accuracy:		84.89 %
Epoch 158 of 2000 took 0.035s
  training loss:		0.352654
  validation loss:		0.406190
  validation accuracy:		87.39 %
Epoch 159 of 2000 took 0.035s
  training loss:		0.352273
  validation loss:		0.405534
  validation accuracy:		86.20 %
Epoch 160 of 2000 took 0.035s
  training loss:		0.351881
  validation loss:		0.396069
  validation accuracy:		87.28 %
Epoch 161 of 2000 took 0.035s
  training loss:		0.351803
  validation loss:		0.412316
  validation accuracy:		85.98 %
Epoch 162 of 2000 took 0.035s
  training loss:		0.348789
  validation loss:		0.420353
  validation accuracy:		86.20 %
Epoch 163 of 2000 took 0.035s
  training loss:		0.353996
  validation loss:		0.435767
  validation accuracy:		85.22 %
Epoch 164 of 2000 took 0.035s
  training loss:		0.338644
  validation loss:		0.429340
  validation accuracy:		85.33 %
Epoch 165 of 2000 took 0.035s
  training loss:		0.347839
  validation loss:		0.432820
  validation accuracy:		85.22 %
Epoch 166 of 2000 took 0.035s
  training loss:		0.349025
  validation loss:		0.417127
  validation accuracy:		85.22 %
Epoch 167 of 2000 took 0.035s
  training loss:		0.345904
  validation loss:		0.426640
  validation accuracy:		85.87 %
Epoch 168 of 2000 took 0.035s
  training loss:		0.341932
  validation loss:		0.403282
  validation accuracy:		86.41 %
Epoch 169 of 2000 took 0.035s
  training loss:		0.339975
  validation loss:		0.401197
  validation accuracy:		86.74 %
Epoch 170 of 2000 took 0.035s
  training loss:		0.337794
  validation loss:		0.412393
  validation accuracy:		86.41 %
Epoch 171 of 2000 took 0.035s
  training loss:		0.333937
  validation loss:		0.415141
  validation accuracy:		86.30 %
Epoch 172 of 2000 took 0.035s
  training loss:		0.349684
  validation loss:		0.437161
  validation accuracy:		85.00 %
Epoch 173 of 2000 took 0.035s
  training loss:		0.344665
  validation loss:		0.429844
  validation accuracy:		85.54 %
Epoch 174 of 2000 took 0.035s
  training loss:		0.340408
  validation loss:		0.399122
  validation accuracy:		86.96 %
Epoch 175 of 2000 took 0.035s
  training loss:		0.344258
  validation loss:		0.417620
  validation accuracy:		86.09 %
Epoch 176 of 2000 took 0.035s
  training loss:		0.345268
  validation loss:		0.398588
  validation accuracy:		86.74 %
Epoch 177 of 2000 took 0.035s
  training loss:		0.347292
  validation loss:		0.409257
  validation accuracy:		86.63 %
Epoch 178 of 2000 took 0.035s
  training loss:		0.342569
  validation loss:		0.408424
  validation accuracy:		86.09 %
Epoch 179 of 2000 took 0.035s
  training loss:		0.340402
  validation loss:		0.400720
  validation accuracy:		86.96 %
Epoch 180 of 2000 took 0.035s
  training loss:		0.337433
  validation loss:		0.398489
  validation accuracy:		86.74 %
Epoch 181 of 2000 took 0.035s
  training loss:		0.341535
  validation loss:		0.432017
  validation accuracy:		85.54 %
Epoch 182 of 2000 took 0.035s
  training loss:		0.332008
  validation loss:		0.423240
  validation accuracy:		85.76 %
Epoch 183 of 2000 took 0.035s
  training loss:		0.338042
  validation loss:		0.410211
  validation accuracy:		86.30 %
Epoch 184 of 2000 took 0.035s
  training loss:		0.341087
  validation loss:		0.395605
  validation accuracy:		87.61 %
Epoch 185 of 2000 took 0.035s
  training loss:		0.338915
  validation loss:		0.425674
  validation accuracy:		85.43 %
Epoch 186 of 2000 took 0.035s
  training loss:		0.337108
  validation loss:		0.406424
  validation accuracy:		86.63 %
Epoch 187 of 2000 took 0.035s
  training loss:		0.333579
  validation loss:		0.409402
  validation accuracy:		86.30 %
Epoch 188 of 2000 took 0.035s
  training loss:		0.335108
  validation loss:		0.402292
  validation accuracy:		86.30 %
Epoch 189 of 2000 took 0.035s
  training loss:		0.332274
  validation loss:		0.453287
  validation accuracy:		84.89 %
Epoch 190 of 2000 took 0.035s
  training loss:		0.325398
  validation loss:		0.408944
  validation accuracy:		86.52 %
Epoch 191 of 2000 took 0.035s
  training loss:		0.339097
  validation loss:		0.403746
  validation accuracy:		86.09 %
Epoch 192 of 2000 took 0.035s
  training loss:		0.328089
  validation loss:		0.405449
  validation accuracy:		85.87 %
Epoch 193 of 2000 took 0.035s
  training loss:		0.335192
  validation loss:		0.407772
  validation accuracy:		85.98 %
Epoch 194 of 2000 took 0.035s
  training loss:		0.335357
  validation loss:		0.423215
  validation accuracy:		85.87 %
Epoch 195 of 2000 took 0.035s
  training loss:		0.333291
  validation loss:		0.416871
  validation accuracy:		85.54 %
Epoch 196 of 2000 took 0.035s
  training loss:		0.334546
  validation loss:		0.431178
  validation accuracy:		85.54 %
Epoch 197 of 2000 took 0.035s
  training loss:		0.333352
  validation loss:		0.422066
  validation accuracy:		85.76 %
Epoch 198 of 2000 took 0.035s
  training loss:		0.335862
  validation loss:		0.419867
  validation accuracy:		86.09 %
Epoch 199 of 2000 took 0.035s
  training loss:		0.328903
  validation loss:		0.432258
  validation accuracy:		85.43 %
Epoch 200 of 2000 took 0.035s
  training loss:		0.332748
  validation loss:		0.425887
  validation accuracy:		85.54 %
Epoch 201 of 2000 took 0.035s
  training loss:		0.338938
  validation loss:		0.422086
  validation accuracy:		85.76 %
Epoch 202 of 2000 took 0.035s
  training loss:		0.325743
  validation loss:		0.411416
  validation accuracy:		86.30 %
Epoch 203 of 2000 took 0.035s
  training loss:		0.331142
  validation loss:		0.416143
  validation accuracy:		86.30 %
Epoch 204 of 2000 took 0.035s
  training loss:		0.340875
  validation loss:		0.416438
  validation accuracy:		85.87 %
Epoch 205 of 2000 took 0.035s
  training loss:		0.325179
  validation loss:		0.413231
  validation accuracy:		86.41 %
Epoch 206 of 2000 took 0.035s
  training loss:		0.322441
  validation loss:		0.425588
  validation accuracy:		85.87 %
Epoch 207 of 2000 took 0.035s
  training loss:		0.325137
  validation loss:		0.403309
  validation accuracy:		86.20 %
Epoch 208 of 2000 took 0.035s
  training loss:		0.318286
  validation loss:		0.451651
  validation accuracy:		85.22 %
Epoch 209 of 2000 took 0.035s
  training loss:		0.328422
  validation loss:		0.432288
  validation accuracy:		85.43 %
Epoch 210 of 2000 took 0.035s
  training loss:		0.326129
  validation loss:		0.392739
  validation accuracy:		87.39 %
Epoch 211 of 2000 took 0.035s
  training loss:		0.331018
  validation loss:		0.458450
  validation accuracy:		84.67 %
Epoch 212 of 2000 took 0.035s
  training loss:		0.324236
  validation loss:		0.409822
  validation accuracy:		86.74 %
Epoch 213 of 2000 took 0.035s
  training loss:		0.322060
  validation loss:		0.391037
  validation accuracy:		87.50 %
Epoch 214 of 2000 took 0.035s
  training loss:		0.326526
  validation loss:		0.425983
  validation accuracy:		85.98 %
Epoch 215 of 2000 took 0.035s
  training loss:		0.332089
  validation loss:		0.409439
  validation accuracy:		86.09 %
Epoch 216 of 2000 took 0.035s
  training loss:		0.320795
  validation loss:		0.393148
  validation accuracy:		86.63 %
Epoch 217 of 2000 took 0.035s
  training loss:		0.332814
  validation loss:		0.394928
  validation accuracy:		87.39 %
Epoch 218 of 2000 took 0.035s
  training loss:		0.330361
  validation loss:		0.416367
  validation accuracy:		85.98 %
Epoch 219 of 2000 took 0.035s
  training loss:		0.329286
  validation loss:		0.408256
  validation accuracy:		86.41 %
Epoch 220 of 2000 took 0.035s
  training loss:		0.322346
  validation loss:		0.441289
  validation accuracy:		85.76 %
Epoch 221 of 2000 took 0.035s
  training loss:		0.323405
  validation loss:		0.442372
  validation accuracy:		85.33 %
Epoch 222 of 2000 took 0.035s
  training loss:		0.328278
  validation loss:		0.406677
  validation accuracy:		86.52 %
Epoch 223 of 2000 took 0.035s
  training loss:		0.320922
  validation loss:		0.410004
  validation accuracy:		86.63 %
Epoch 224 of 2000 took 0.035s
  training loss:		0.322964
  validation loss:		0.395348
  validation accuracy:		86.96 %
Epoch 225 of 2000 took 0.035s
  training loss:		0.320142
  validation loss:		0.400611
  validation accuracy:		86.63 %
Epoch 226 of 2000 took 0.035s
  training loss:		0.321782
  validation loss:		0.395795
  validation accuracy:		87.07 %
Epoch 227 of 2000 took 0.035s
  training loss:		0.320077
  validation loss:		0.416657
  validation accuracy:		86.30 %
Epoch 228 of 2000 took 0.037s
  training loss:		0.318574
  validation loss:		0.427141
  validation accuracy:		86.09 %
Epoch 229 of 2000 took 0.035s
  training loss:		0.314337
  validation loss:		0.399650
  validation accuracy:		86.74 %
Epoch 230 of 2000 took 0.035s
  training loss:		0.324786
  validation loss:		0.403164
  validation accuracy:		86.96 %
Epoch 231 of 2000 took 0.035s
  training loss:		0.316980
  validation loss:		0.447399
  validation accuracy:		85.65 %
Epoch 232 of 2000 took 0.035s
  training loss:		0.319775
  validation loss:		0.400853
  validation accuracy:		86.63 %
Epoch 233 of 2000 took 0.035s
  training loss:		0.315859
  validation loss:		0.408523
  validation accuracy:		86.41 %
Epoch 234 of 2000 took 0.035s
  training loss:		0.318431
  validation loss:		0.421339
  validation accuracy:		86.09 %
Epoch 235 of 2000 took 0.035s
  training loss:		0.309555
  validation loss:		0.436021
  validation accuracy:		85.33 %
Epoch 236 of 2000 took 0.035s
  training loss:		0.318371
  validation loss:		0.400379
  validation accuracy:		86.74 %
Epoch 237 of 2000 took 0.035s
  training loss:		0.313258
  validation loss:		0.418526
  validation accuracy:		85.76 %
Epoch 238 of 2000 took 0.035s
  training loss:		0.310738
  validation loss:		0.392971
  validation accuracy:		87.50 %
Epoch 239 of 2000 took 0.035s
  training loss:		0.316935
  validation loss:		0.433098
  validation accuracy:		85.54 %
Epoch 240 of 2000 took 0.035s
  training loss:		0.319873
  validation loss:		0.395514
  validation accuracy:		87.17 %
Epoch 241 of 2000 took 0.035s
  training loss:		0.315910
  validation loss:		0.428188
  validation accuracy:		85.98 %
Epoch 242 of 2000 took 0.035s
  training loss:		0.316260
  validation loss:		0.409745
  validation accuracy:		86.20 %
Epoch 243 of 2000 took 0.035s
  training loss:		0.315249
  validation loss:		0.409935
  validation accuracy:		86.30 %
Epoch 244 of 2000 took 0.035s
  training loss:		0.319020
  validation loss:		0.403672
  validation accuracy:		86.63 %
Epoch 245 of 2000 took 0.035s
  training loss:		0.316201
  validation loss:		0.424195
  validation accuracy:		86.09 %
Epoch 246 of 2000 took 0.035s
  training loss:		0.312832
  validation loss:		0.441691
  validation accuracy:		85.65 %
Epoch 247 of 2000 took 0.035s
  training loss:		0.309994
  validation loss:		0.419381
  validation accuracy:		86.30 %
Epoch 248 of 2000 took 0.035s
  training loss:		0.317168
  validation loss:		0.421432
  validation accuracy:		86.09 %
Epoch 249 of 2000 took 0.035s
  training loss:		0.314840
  validation loss:		0.394335
  validation accuracy:		87.50 %
Epoch 250 of 2000 took 0.035s
  training loss:		0.314546
  validation loss:		0.407496
  validation accuracy:		86.74 %
Epoch 251 of 2000 took 0.035s
  training loss:		0.316071
  validation loss:		0.428462
  validation accuracy:		86.09 %
Epoch 252 of 2000 took 0.035s
  training loss:		0.315778
  validation loss:		0.421040
  validation accuracy:		86.30 %
Epoch 253 of 2000 took 0.035s
  training loss:		0.319938
  validation loss:		0.402632
  validation accuracy:		86.85 %
Epoch 254 of 2000 took 0.035s
  training loss:		0.318590
  validation loss:		0.409979
  validation accuracy:		86.52 %
Epoch 255 of 2000 took 0.035s
  training loss:		0.312058
  validation loss:		0.426436
  validation accuracy:		86.41 %
Epoch 256 of 2000 took 0.035s
  training loss:		0.316211
  validation loss:		0.392082
  validation accuracy:		87.39 %
Epoch 257 of 2000 took 0.035s
  training loss:		0.313905
  validation loss:		0.428091
  validation accuracy:		86.20 %
Epoch 258 of 2000 took 0.035s
  training loss:		0.311355
  validation loss:		0.413200
  validation accuracy:		86.63 %
Epoch 259 of 2000 took 0.035s
  training loss:		0.311917
  validation loss:		0.414637
  validation accuracy:		86.74 %
Epoch 260 of 2000 took 0.035s
  training loss:		0.310838
  validation loss:		0.398861
  validation accuracy:		86.85 %
Epoch 261 of 2000 took 0.035s
  training loss:		0.318660
  validation loss:		0.431942
  validation accuracy:		85.98 %
Epoch 262 of 2000 took 0.035s
  training loss:		0.300987
  validation loss:		0.400333
  validation accuracy:		86.74 %
Epoch 263 of 2000 took 0.035s
  training loss:		0.315669
  validation loss:		0.431948
  validation accuracy:		86.09 %
Epoch 264 of 2000 took 0.035s
  training loss:		0.316330
  validation loss:		0.445372
  validation accuracy:		85.98 %
Epoch 265 of 2000 took 0.035s
  training loss:		0.302982
  validation loss:		0.416203
  validation accuracy:		86.41 %
Epoch 266 of 2000 took 0.035s
  training loss:		0.312896
  validation loss:		0.420691
  validation accuracy:		86.09 %
Epoch 267 of 2000 took 0.035s
  training loss:		0.312519
  validation loss:		0.414550
  validation accuracy:		86.63 %
Epoch 268 of 2000 took 0.035s
  training loss:		0.309192
  validation loss:		0.400660
  validation accuracy:		87.07 %
Epoch 269 of 2000 took 0.035s
  training loss:		0.319523
  validation loss:		0.410099
  validation accuracy:		86.96 %
Epoch 270 of 2000 took 0.035s
  training loss:		0.302991
  validation loss:		0.403065
  validation accuracy:		86.85 %
Epoch 271 of 2000 took 0.035s
  training loss:		0.311030
  validation loss:		0.415231
  validation accuracy:		86.30 %
Epoch 272 of 2000 took 0.035s
  training loss:		0.302991
  validation loss:		0.399373
  validation accuracy:		87.07 %
Epoch 273 of 2000 took 0.035s
  training loss:		0.309770
  validation loss:		0.452692
  validation accuracy:		86.09 %
Epoch 274 of 2000 took 0.035s
  training loss:		0.308070
  validation loss:		0.396503
  validation accuracy:		87.07 %
Epoch 275 of 2000 took 0.035s
  training loss:		0.306142
  validation loss:		0.388785
  validation accuracy:		87.61 %
Epoch 276 of 2000 took 0.035s
  training loss:		0.317171
  validation loss:		0.393705
  validation accuracy:		87.28 %
Epoch 277 of 2000 took 0.035s
  training loss:		0.309009
  validation loss:		0.403871
  validation accuracy:		87.28 %
Epoch 278 of 2000 took 0.035s
  training loss:		0.309169
  validation loss:		0.419776
  validation accuracy:		86.41 %
Epoch 279 of 2000 took 0.035s
  training loss:		0.312719
  validation loss:		0.391779
  validation accuracy:		87.61 %
Epoch 280 of 2000 took 0.035s
  training loss:		0.320766
  validation loss:		0.421765
  validation accuracy:		86.41 %
Epoch 281 of 2000 took 0.035s
  training loss:		0.313222
  validation loss:		0.391810
  validation accuracy:		87.39 %
Epoch 282 of 2000 took 0.035s
  training loss:		0.306771
  validation loss:		0.411291
  validation accuracy:		86.30 %
Epoch 283 of 2000 took 0.035s
  training loss:		0.304111
  validation loss:		0.422618
  validation accuracy:		86.96 %
Epoch 284 of 2000 took 0.035s
  training loss:		0.308695
  validation loss:		0.417653
  validation accuracy:		86.30 %
Epoch 285 of 2000 took 0.035s
  training loss:		0.309144
  validation loss:		0.405182
  validation accuracy:		86.74 %
Epoch 286 of 2000 took 0.035s
  training loss:		0.304343
  validation loss:		0.414950
  validation accuracy:		86.85 %
Epoch 287 of 2000 took 0.035s
  training loss:		0.316274
  validation loss:		0.394174
  validation accuracy:		87.72 %
Epoch 288 of 2000 took 0.035s
  training loss:		0.302004
  validation loss:		0.396443
  validation accuracy:		87.39 %
Epoch 289 of 2000 took 0.035s
  training loss:		0.311042
  validation loss:		0.402866
  validation accuracy:		87.07 %
Epoch 290 of 2000 took 0.035s
  training loss:		0.311284
  validation loss:		0.425090
  validation accuracy:		86.74 %
Epoch 291 of 2000 took 0.035s
  training loss:		0.310974
  validation loss:		0.404626
  validation accuracy:		86.85 %
Epoch 292 of 2000 took 0.035s
  training loss:		0.306593
  validation loss:		0.397024
  validation accuracy:		87.17 %
Epoch 293 of 2000 took 0.035s
  training loss:		0.298987
  validation loss:		0.441375
  validation accuracy:		86.41 %
Epoch 294 of 2000 took 0.035s
  training loss:		0.310063
  validation loss:		0.391393
  validation accuracy:		87.39 %
Epoch 295 of 2000 took 0.035s
  training loss:		0.310266
  validation loss:		0.411977
  validation accuracy:		86.85 %
Epoch 296 of 2000 took 0.035s
  training loss:		0.307353
  validation loss:		0.398266
  validation accuracy:		87.07 %
Epoch 297 of 2000 took 0.035s
  training loss:		0.308852
  validation loss:		0.406725
  validation accuracy:		86.52 %
Epoch 298 of 2000 took 0.035s
  training loss:		0.303169
  validation loss:		0.405859
  validation accuracy:		86.85 %
Epoch 299 of 2000 took 0.035s
  training loss:		0.308342
  validation loss:		0.423033
  validation accuracy:		86.63 %
Epoch 300 of 2000 took 0.035s
  training loss:		0.308352
  validation loss:		0.398342
  validation accuracy:		87.07 %
Epoch 301 of 2000 took 0.035s
  training loss:		0.304935
  validation loss:		0.429868
  validation accuracy:		86.41 %
Epoch 302 of 2000 took 0.035s
  training loss:		0.306735
  validation loss:		0.412159
  validation accuracy:		86.52 %
Epoch 303 of 2000 took 0.035s
  training loss:		0.296120
  validation loss:		0.416390
  validation accuracy:		86.85 %
Epoch 304 of 2000 took 0.035s
  training loss:		0.308984
  validation loss:		0.426499
  validation accuracy:		86.30 %
Epoch 305 of 2000 took 0.035s
  training loss:		0.307402
  validation loss:		0.428936
  validation accuracy:		86.30 %
Epoch 306 of 2000 took 0.035s
  training loss:		0.307919
  validation loss:		0.396914
  validation accuracy:		87.39 %
Epoch 307 of 2000 took 0.035s
  training loss:		0.298608
  validation loss:		0.390016
  validation accuracy:		87.61 %
Epoch 308 of 2000 took 0.035s
  training loss:		0.302505
  validation loss:		0.399402
  validation accuracy:		86.96 %
Epoch 309 of 2000 took 0.035s
  training loss:		0.306461
  validation loss:		0.436229
  validation accuracy:		86.09 %
Epoch 310 of 2000 took 0.035s
  training loss:		0.308805
  validation loss:		0.432726
  validation accuracy:		86.41 %
Epoch 311 of 2000 took 0.035s
  training loss:		0.306516
  validation loss:		0.397568
  validation accuracy:		87.28 %
Epoch 312 of 2000 took 0.035s
  training loss:		0.300446
  validation loss:		0.433058
  validation accuracy:		86.09 %
Epoch 313 of 2000 took 0.035s
  training loss:		0.306063
  validation loss:		0.391655
  validation accuracy:		87.50 %
Epoch 314 of 2000 took 0.035s
  training loss:		0.302064
  validation loss:		0.403614
  validation accuracy:		87.07 %
Epoch 315 of 2000 took 0.035s
  training loss:		0.302121
  validation loss:		0.407900
  validation accuracy:		86.52 %
Epoch 316 of 2000 took 0.035s
  training loss:		0.304673
  validation loss:		0.407281
  validation accuracy:		87.17 %
Epoch 317 of 2000 took 0.035s
  training loss:		0.306477
  validation loss:		0.401275
  validation accuracy:		87.07 %
Epoch 318 of 2000 took 0.035s
  training loss:		0.309612
  validation loss:		0.387665
  validation accuracy:		87.50 %
Epoch 319 of 2000 took 0.035s
  training loss:		0.301153
  validation loss:		0.395823
  validation accuracy:		87.07 %
Epoch 320 of 2000 took 0.035s
  training loss:		0.306426
  validation loss:		0.405994
  validation accuracy:		86.96 %
Epoch 321 of 2000 took 0.035s
  training loss:		0.302325
  validation loss:		0.400784
  validation accuracy:		87.61 %
Epoch 322 of 2000 took 0.035s
  training loss:		0.305554
  validation loss:		0.415378
  validation accuracy:		86.63 %
Epoch 323 of 2000 took 0.035s
  training loss:		0.302696
  validation loss:		0.417314
  validation accuracy:		86.52 %
Epoch 324 of 2000 took 0.035s
  training loss:		0.301799
  validation loss:		0.414240
  validation accuracy:		86.63 %
Epoch 325 of 2000 took 0.035s
  training loss:		0.296909
  validation loss:		0.408815
  validation accuracy:		86.96 %
Epoch 326 of 2000 took 0.035s
  training loss:		0.299930
  validation loss:		0.414373
  validation accuracy:		87.07 %
Epoch 327 of 2000 took 0.035s
  training loss:		0.305313
  validation loss:		0.396252
  validation accuracy:		87.28 %
Epoch 328 of 2000 took 0.035s
  training loss:		0.306362
  validation loss:		0.428275
  validation accuracy:		86.41 %
Epoch 329 of 2000 took 0.035s
  training loss:		0.307400
  validation loss:		0.406041
  validation accuracy:		87.07 %
Epoch 330 of 2000 took 0.035s
  training loss:		0.300887
  validation loss:		0.409356
  validation accuracy:		86.96 %
Epoch 331 of 2000 took 0.035s
  training loss:		0.307673
  validation loss:		0.405440
  validation accuracy:		87.07 %
Epoch 332 of 2000 took 0.035s
  training loss:		0.304490
  validation loss:		0.385950
  validation accuracy:		87.50 %
Epoch 333 of 2000 took 0.035s
  training loss:		0.293587
  validation loss:		0.400837
  validation accuracy:		87.17 %
Epoch 334 of 2000 took 0.035s
  training loss:		0.300893
  validation loss:		0.393358
  validation accuracy:		87.28 %
Epoch 335 of 2000 took 0.035s
  training loss:		0.299461
  validation loss:		0.406353
  validation accuracy:		86.74 %
Epoch 336 of 2000 took 0.035s
  training loss:		0.308220
  validation loss:		0.410729
  validation accuracy:		86.74 %
Epoch 337 of 2000 took 0.035s
  training loss:		0.303696
  validation loss:		0.399544
  validation accuracy:		87.39 %
Epoch 338 of 2000 took 0.035s
  training loss:		0.301457
  validation loss:		0.404249
  validation accuracy:		86.85 %
Epoch 339 of 2000 took 0.035s
  training loss:		0.293507
  validation loss:		0.405674
  validation accuracy:		86.96 %
Epoch 340 of 2000 took 0.035s
  training loss:		0.300154
  validation loss:		0.409991
  validation accuracy:		86.30 %
Epoch 341 of 2000 took 0.035s
  training loss:		0.300545
  validation loss:		0.396153
  validation accuracy:		87.07 %
Epoch 342 of 2000 took 0.035s
  training loss:		0.301098
  validation loss:		0.445631
  validation accuracy:		86.52 %
Epoch 343 of 2000 took 0.035s
  training loss:		0.313405
  validation loss:		0.425011
  validation accuracy:		86.85 %
Epoch 344 of 2000 took 0.035s
  training loss:		0.302474
  validation loss:		0.402067
  validation accuracy:		87.17 %
Epoch 345 of 2000 took 0.035s
  training loss:		0.298709
  validation loss:		0.387805
  validation accuracy:		86.96 %
Epoch 346 of 2000 took 0.035s
  training loss:		0.301656
  validation loss:		0.390111
  validation accuracy:		87.39 %
Epoch 347 of 2000 took 0.035s
  training loss:		0.307127
  validation loss:		0.405690
  validation accuracy:		86.96 %
Epoch 348 of 2000 took 0.035s
  training loss:		0.302837
  validation loss:		0.398258
  validation accuracy:		87.07 %
Epoch 349 of 2000 took 0.035s
  training loss:		0.300914
  validation loss:		0.440044
  validation accuracy:		86.63 %
Epoch 350 of 2000 took 0.035s
  training loss:		0.304107
  validation loss:		0.394984
  validation accuracy:		86.85 %
Epoch 351 of 2000 took 0.035s
  training loss:		0.308324
  validation loss:		0.431842
  validation accuracy:		86.63 %
Epoch 352 of 2000 took 0.035s
  training loss:		0.291717
  validation loss:		0.385709
  validation accuracy:		87.39 %
Epoch 353 of 2000 took 0.035s
  training loss:		0.296393
  validation loss:		0.418880
  validation accuracy:		86.63 %
Epoch 354 of 2000 took 0.035s
  training loss:		0.302389
  validation loss:		0.430361
  validation accuracy:		86.74 %
Epoch 355 of 2000 took 0.035s
  training loss:		0.294699
  validation loss:		0.426735
  validation accuracy:		86.30 %
Epoch 356 of 2000 took 0.035s
  training loss:		0.300437
  validation loss:		0.420850
  validation accuracy:		86.85 %
Epoch 357 of 2000 took 0.035s
  training loss:		0.298991
  validation loss:		0.393317
  validation accuracy:		87.39 %
Epoch 358 of 2000 took 0.035s
  training loss:		0.302549
  validation loss:		0.394174
  validation accuracy:		86.85 %
Epoch 359 of 2000 took 0.035s
  training loss:		0.296630
  validation loss:		0.420638
  validation accuracy:		86.85 %
Epoch 360 of 2000 took 0.035s
  training loss:		0.296766
  validation loss:		0.416463
  validation accuracy:		86.52 %
Epoch 361 of 2000 took 0.035s
  training loss:		0.302211
  validation loss:		0.395966
  validation accuracy:		87.07 %
Epoch 362 of 2000 took 0.035s
  training loss:		0.301256
  validation loss:		0.381954
  validation accuracy:		87.39 %
Epoch 363 of 2000 took 0.035s
  training loss:		0.296187
  validation loss:		0.409752
  validation accuracy:		86.96 %
Epoch 364 of 2000 took 0.035s
  training loss:		0.300534
  validation loss:		0.399741
  validation accuracy:		86.52 %
Epoch 365 of 2000 took 0.035s
  training loss:		0.299300
  validation loss:		0.406119
  validation accuracy:		86.85 %
Epoch 366 of 2000 took 0.035s
  training loss:		0.303984
  validation loss:		0.412870
  validation accuracy:		86.52 %
Epoch 367 of 2000 took 0.035s
  training loss:		0.299950
  validation loss:		0.396592
  validation accuracy:		87.39 %
Epoch 368 of 2000 took 0.035s
  training loss:		0.298841
  validation loss:		0.404192
  validation accuracy:		87.07 %
Epoch 369 of 2000 took 0.035s
  training loss:		0.295551
  validation loss:		0.393812
  validation accuracy:		87.17 %
Epoch 370 of 2000 took 0.035s
  training loss:		0.300118
  validation loss:		0.400092
  validation accuracy:		86.74 %
Epoch 371 of 2000 took 0.035s
  training loss:		0.304628
  validation loss:		0.387591
  validation accuracy:		86.85 %
Epoch 372 of 2000 took 0.035s
  training loss:		0.296616
  validation loss:		0.383397
  validation accuracy:		87.17 %
Epoch 373 of 2000 took 0.035s
  training loss:		0.291806
  validation loss:		0.383788
  validation accuracy:		87.39 %
Epoch 374 of 2000 took 0.035s
  training loss:		0.299630
  validation loss:		0.390932
  validation accuracy:		87.07 %
Epoch 375 of 2000 took 0.035s
  training loss:		0.294188
  validation loss:		0.395777
  validation accuracy:		87.17 %
Epoch 376 of 2000 took 0.035s
  training loss:		0.302299
  validation loss:		0.405660
  validation accuracy:		86.96 %
Epoch 377 of 2000 took 0.035s
  training loss:		0.293017
  validation loss:		0.401773
  validation accuracy:		87.07 %
Epoch 378 of 2000 took 0.035s
  training loss:		0.295147
  validation loss:		0.412637
  validation accuracy:		87.17 %
Epoch 379 of 2000 took 0.035s
  training loss:		0.293874
  validation loss:		0.388440
  validation accuracy:		87.39 %
Epoch 380 of 2000 took 0.035s
  training loss:		0.292113
  validation loss:		0.403744
  validation accuracy:		87.07 %
Epoch 381 of 2000 took 0.035s
  training loss:		0.289924
  validation loss:		0.399667
  validation accuracy:		87.07 %
Epoch 382 of 2000 took 0.035s
  training loss:		0.294428
  validation loss:		0.419985
  validation accuracy:		86.09 %
Epoch 383 of 2000 took 0.035s
  training loss:		0.292570
  validation loss:		0.405007
  validation accuracy:		86.96 %
Epoch 384 of 2000 took 0.035s
  training loss:		0.297719
  validation loss:		0.415569
  validation accuracy:		86.74 %
Epoch 385 of 2000 took 0.035s
  training loss:		0.291331
  validation loss:		0.408151
  validation accuracy:		86.74 %
Epoch 386 of 2000 took 0.035s
  training loss:		0.290362
  validation loss:		0.389147
  validation accuracy:		87.28 %
Epoch 387 of 2000 took 0.035s
  training loss:		0.297502
  validation loss:		0.409773
  validation accuracy:		86.96 %
Epoch 388 of 2000 took 0.035s
  training loss:		0.292474
  validation loss:		0.451404
  validation accuracy:		86.74 %
Epoch 389 of 2000 took 0.035s
  training loss:		0.301415
  validation loss:		0.388048
  validation accuracy:		87.61 %
Epoch 390 of 2000 took 0.035s
  training loss:		0.300648
  validation loss:		0.410792
  validation accuracy:		86.85 %
Epoch 391 of 2000 took 0.035s
  training loss:		0.294295
  validation loss:		0.411882
  validation accuracy:		86.63 %
Epoch 392 of 2000 took 0.035s
  training loss:		0.295056
  validation loss:		0.413419
  validation accuracy:		86.74 %
Epoch 393 of 2000 took 0.035s
  training loss:		0.297069
  validation loss:		0.386837
  validation accuracy:		86.96 %
Epoch 394 of 2000 took 0.035s
  training loss:		0.305096
  validation loss:		0.410027
  validation accuracy:		86.96 %
Epoch 395 of 2000 took 0.035s
  training loss:		0.299124
  validation loss:		0.408719
  validation accuracy:		87.17 %
Epoch 396 of 2000 took 0.035s
  training loss:		0.291158
  validation loss:		0.409301
  validation accuracy:		87.17 %
Epoch 397 of 2000 took 0.035s
  training loss:		0.294998
  validation loss:		0.429161
  validation accuracy:		86.96 %
Epoch 398 of 2000 took 0.035s
  training loss:		0.295050
  validation loss:		0.414815
  validation accuracy:		87.07 %
Epoch 399 of 2000 took 0.035s
  training loss:		0.292205
  validation loss:		0.386914
  validation accuracy:		87.28 %
Epoch 400 of 2000 took 0.035s
  training loss:		0.291300
  validation loss:		0.398613
  validation accuracy:		87.07 %
Epoch 401 of 2000 took 0.035s
  training loss:		0.291958
  validation loss:		0.407512
  validation accuracy:		86.96 %
Epoch 402 of 2000 took 0.035s
  training loss:		0.286920
  validation loss:		0.437328
  validation accuracy:		86.85 %
Epoch 403 of 2000 took 0.035s
  training loss:		0.288274
  validation loss:		0.424891
  validation accuracy:		86.52 %
Epoch 404 of 2000 took 0.035s
  training loss:		0.297040
  validation loss:		0.408345
  validation accuracy:		86.85 %
Epoch 405 of 2000 took 0.035s
  training loss:		0.294194
  validation loss:		0.394603
  validation accuracy:		87.39 %
Epoch 406 of 2000 took 0.035s
  training loss:		0.299498
  validation loss:		0.416161
  validation accuracy:		86.85 %
Epoch 407 of 2000 took 0.035s
  training loss:		0.292991
  validation loss:		0.386895
  validation accuracy:		87.39 %
Epoch 408 of 2000 took 0.035s
  training loss:		0.298021
  validation loss:		0.427817
  validation accuracy:		85.87 %
Epoch 409 of 2000 took 0.035s
  training loss:		0.293468
  validation loss:		0.399479
  validation accuracy:		86.85 %
Epoch 410 of 2000 took 0.035s
  training loss:		0.293639
  validation loss:		0.403149
  validation accuracy:		87.07 %
Epoch 411 of 2000 took 0.035s
  training loss:		0.294036
  validation loss:		0.412490
  validation accuracy:		86.85 %
Epoch 412 of 2000 took 0.035s
  training loss:		0.288157
  validation loss:		0.419019
  validation accuracy:		86.96 %
Epoch 413 of 2000 took 0.035s
  training loss:		0.285732
  validation loss:		0.413070
  validation accuracy:		86.74 %
Epoch 414 of 2000 took 0.035s
  training loss:		0.296822
  validation loss:		0.385643
  validation accuracy:		87.28 %
Epoch 415 of 2000 took 0.035s
  training loss:		0.294617
  validation loss:		0.396928
  validation accuracy:		87.07 %
Epoch 416 of 2000 took 0.035s
  training loss:		0.294235
  validation loss:		0.413093
  validation accuracy:		86.96 %
Epoch 417 of 2000 took 0.035s
  training loss:		0.294633
  validation loss:		0.409005
  validation accuracy:		86.85 %
Epoch 418 of 2000 took 0.035s
  training loss:		0.287577
  validation loss:		0.386325
  validation accuracy:		87.28 %
Epoch 419 of 2000 took 0.035s
  training loss:		0.296060
  validation loss:		0.421193
  validation accuracy:		86.63 %
Epoch 420 of 2000 took 0.035s
  training loss:		0.302826
  validation loss:		0.395443
  validation accuracy:		87.07 %
Epoch 421 of 2000 took 0.035s
  training loss:		0.299067
  validation loss:		0.399380
  validation accuracy:		86.85 %
Epoch 422 of 2000 took 0.035s
  training loss:		0.296394
  validation loss:		0.420747
  validation accuracy:		87.07 %
Epoch 423 of 2000 took 0.035s
  training loss:		0.294796
  validation loss:		0.445695
  validation accuracy:		86.52 %
Epoch 424 of 2000 took 0.035s
  training loss:		0.289586
  validation loss:		0.410513
  validation accuracy:		87.17 %
Epoch 425 of 2000 took 0.035s
  training loss:		0.288292
  validation loss:		0.410893
  validation accuracy:		86.63 %
Epoch 426 of 2000 took 0.035s
  training loss:		0.286209
  validation loss:		0.411205
  validation accuracy:		86.63 %
Epoch 427 of 2000 took 0.035s
  training loss:		0.297759
  validation loss:		0.417854
  validation accuracy:		86.74 %
Epoch 428 of 2000 took 0.035s
  training loss:		0.300036
  validation loss:		0.413627
  validation accuracy:		86.85 %
Epoch 429 of 2000 took 0.035s
  training loss:		0.292112
  validation loss:		0.385908
  validation accuracy:		87.28 %
Epoch 430 of 2000 took 0.035s
  training loss:		0.299323
  validation loss:		0.394869
  validation accuracy:		87.07 %
Epoch 431 of 2000 took 0.035s
  training loss:		0.284986
  validation loss:		0.431278
  validation accuracy:		86.96 %
Epoch 432 of 2000 took 0.035s
  training loss:		0.288005
  validation loss:		0.428118
  validation accuracy:		86.96 %
Epoch 433 of 2000 took 0.035s
  training loss:		0.302582
  validation loss:		0.399034
  validation accuracy:		87.50 %
Epoch 434 of 2000 took 0.035s
  training loss:		0.288414
  validation loss:		0.416673
  validation accuracy:		86.30 %
Epoch 435 of 2000 took 0.035s
  training loss:		0.290224
  validation loss:		0.395795
  validation accuracy:		87.07 %
Epoch 436 of 2000 took 0.035s
  training loss:		0.288451
  validation loss:		0.420441
  validation accuracy:		86.30 %
Epoch 437 of 2000 took 0.035s
  training loss:		0.296451
  validation loss:		0.396728
  validation accuracy:		87.07 %
Epoch 438 of 2000 took 0.035s
  training loss:		0.289809
  validation loss:		0.407393
  validation accuracy:		86.96 %
Epoch 439 of 2000 took 0.035s
  training loss:		0.282771
  validation loss:		0.393493
  validation accuracy:		87.28 %
Epoch 440 of 2000 took 0.035s
  training loss:		0.286795
  validation loss:		0.381535
  validation accuracy:		87.28 %
Epoch 441 of 2000 took 0.035s
  training loss:		0.288691
  validation loss:		0.405542
  validation accuracy:		87.17 %
Epoch 442 of 2000 took 0.035s
  training loss:		0.291233
  validation loss:		0.410322
  validation accuracy:		86.63 %
Epoch 443 of 2000 took 0.035s
  training loss:		0.285062
  validation loss:		0.399198
  validation accuracy:		87.17 %
Epoch 444 of 2000 took 0.035s
  training loss:		0.296368
  validation loss:		0.420998
  validation accuracy:		86.63 %
Epoch 445 of 2000 took 0.035s
  training loss:		0.288849
  validation loss:		0.401765
  validation accuracy:		86.74 %
Epoch 446 of 2000 took 0.035s
  training loss:		0.289264
  validation loss:		0.444579
  validation accuracy:		85.87 %
Epoch 447 of 2000 took 0.035s
  training loss:		0.290774
  validation loss:		0.413425
  validation accuracy:		87.07 %
Epoch 448 of 2000 took 0.035s
  training loss:		0.290898
  validation loss:		0.398004
  validation accuracy:		86.74 %
Epoch 449 of 2000 took 0.035s
  training loss:		0.290013
  validation loss:		0.393458
  validation accuracy:		87.17 %
Epoch 450 of 2000 took 0.035s
  training loss:		0.291333
  validation loss:		0.431422
  validation accuracy:		86.74 %
Epoch 451 of 2000 took 0.035s
  training loss:		0.289515
  validation loss:		0.405502
  validation accuracy:		86.74 %
Epoch 452 of 2000 took 0.035s
  training loss:		0.288539
  validation loss:		0.411198
  validation accuracy:		87.17 %
Epoch 453 of 2000 took 0.035s
  training loss:		0.287703
  validation loss:		0.406187
  validation accuracy:		87.28 %
Epoch 454 of 2000 took 0.035s
  training loss:		0.289436
  validation loss:		0.399618
  validation accuracy:		87.28 %
Epoch 455 of 2000 took 0.035s
  training loss:		0.292006
  validation loss:		0.419565
  validation accuracy:		87.17 %
Epoch 456 of 2000 took 0.035s
  training loss:		0.290500
  validation loss:		0.414774
  validation accuracy:		86.09 %
Epoch 457 of 2000 took 0.035s
  training loss:		0.288777
  validation loss:		0.387478
  validation accuracy:		87.72 %
Epoch 458 of 2000 took 0.035s
  training loss:		0.295951
  validation loss:		0.417344
  validation accuracy:		86.85 %
Epoch 459 of 2000 took 0.035s
  training loss:		0.291716
  validation loss:		0.397626
  validation accuracy:		86.96 %
Epoch 460 of 2000 took 0.035s
  training loss:		0.288957
  validation loss:		0.422501
  validation accuracy:		85.87 %
Epoch 461 of 2000 took 0.035s
  training loss:		0.295074
  validation loss:		0.403686
  validation accuracy:		87.28 %
Epoch 462 of 2000 took 0.035s
  training loss:		0.293609
  validation loss:		0.382397
  validation accuracy:		87.61 %
Epoch 463 of 2000 took 0.035s
  training loss:		0.284543
  validation loss:		0.385439
  validation accuracy:		87.72 %
Epoch 464 of 2000 took 0.035s
  training loss:		0.290217
  validation loss:		0.428462
  validation accuracy:		87.07 %
Epoch 465 of 2000 took 0.035s
  training loss:		0.295348
  validation loss:		0.421471
  validation accuracy:		86.85 %
Epoch 466 of 2000 took 0.035s
  training loss:		0.291086
  validation loss:		0.420814
  validation accuracy:		86.96 %
Epoch 467 of 2000 took 0.035s
  training loss:		0.290223
  validation loss:		0.416216
  validation accuracy:		87.07 %
Epoch 468 of 2000 took 0.035s
  training loss:		0.283286
  validation loss:		0.391583
  validation accuracy:		87.72 %
Epoch 469 of 2000 took 0.035s
  training loss:		0.277491
  validation loss:		0.415975
  validation accuracy:		87.17 %
Epoch 470 of 2000 took 0.035s
  training loss:		0.294716
  validation loss:		0.392694
  validation accuracy:		87.72 %
Epoch 471 of 2000 took 0.035s
  training loss:		0.285524
  validation loss:		0.400686
  validation accuracy:		86.52 %
Epoch 472 of 2000 took 0.035s
  training loss:		0.293315
  validation loss:		0.409511
  validation accuracy:		86.85 %
Epoch 473 of 2000 took 0.035s
  training loss:		0.288521
  validation loss:		0.408992
  validation accuracy:		86.41 %
Epoch 474 of 2000 took 0.035s
  training loss:		0.289697
  validation loss:		0.434824
  validation accuracy:		85.87 %
Epoch 475 of 2000 took 0.037s
  training loss:		0.292397
  validation loss:		0.402397
  validation accuracy:		86.52 %
Epoch 476 of 2000 took 0.035s
  training loss:		0.294575
  validation loss:		0.428149
  validation accuracy:		86.85 %
Epoch 477 of 2000 took 0.035s
  training loss:		0.290080
  validation loss:		0.400914
  validation accuracy:		87.50 %
Epoch 478 of 2000 took 0.035s
  training loss:		0.288199
  validation loss:		0.380937
  validation accuracy:		87.17 %
Epoch 479 of 2000 took 0.035s
  training loss:		0.289602
  validation loss:		0.412382
  validation accuracy:		86.96 %
Epoch 480 of 2000 took 0.035s
  training loss:		0.283028
  validation loss:		0.428167
  validation accuracy:		86.52 %
Epoch 481 of 2000 took 0.035s
  training loss:		0.294121
  validation loss:		0.409024
  validation accuracy:		87.39 %
Epoch 482 of 2000 took 0.035s
  training loss:		0.291338
  validation loss:		0.445234
  validation accuracy:		86.30 %
Epoch 483 of 2000 took 0.035s
  training loss:		0.302082
  validation loss:		0.399032
  validation accuracy:		87.28 %
Epoch 484 of 2000 took 0.035s
  training loss:		0.284278
  validation loss:		0.440372
  validation accuracy:		86.41 %
Epoch 485 of 2000 took 0.035s
  training loss:		0.285128
  validation loss:		0.412618
  validation accuracy:		86.85 %
Epoch 486 of 2000 took 0.035s
  training loss:		0.290720
  validation loss:		0.409110
  validation accuracy:		87.07 %
Epoch 487 of 2000 took 0.035s
  training loss:		0.295723
  validation loss:		0.397132
  validation accuracy:		86.85 %
Epoch 488 of 2000 took 0.035s
  training loss:		0.281404
  validation loss:		0.425409
  validation accuracy:		86.74 %
Epoch 489 of 2000 took 0.035s
  training loss:		0.294439
  validation loss:		0.390807
  validation accuracy:		87.39 %
Epoch 490 of 2000 took 0.035s
  training loss:		0.286317
  validation loss:		0.408743
  validation accuracy:		87.07 %
Epoch 491 of 2000 took 0.035s
  training loss:		0.282109
  validation loss:		0.408674
  validation accuracy:		86.63 %
Epoch 492 of 2000 took 0.035s
  training loss:		0.282722
  validation loss:		0.434908
  validation accuracy:		86.63 %
Epoch 493 of 2000 took 0.035s
  training loss:		0.281458
  validation loss:		0.403181
  validation accuracy:		86.63 %
Epoch 494 of 2000 took 0.035s
  training loss:		0.284293
  validation loss:		0.379687
  validation accuracy:		88.37 %
Epoch 495 of 2000 took 0.035s
  training loss:		0.284365
  validation loss:		0.409921
  validation accuracy:		86.63 %
Epoch 496 of 2000 took 0.035s
  training loss:		0.289694
  validation loss:		0.409791
  validation accuracy:		86.96 %
Epoch 497 of 2000 took 0.035s
  training loss:		0.283465
  validation loss:		0.399976
  validation accuracy:		87.39 %
Epoch 498 of 2000 took 0.035s
  training loss:		0.291508
  validation loss:		0.405344
  validation accuracy:		86.52 %
Epoch 499 of 2000 took 0.035s
  training loss:		0.289788
  validation loss:		0.414849
  validation accuracy:		86.74 %
Epoch 500 of 2000 took 0.035s
  training loss:		0.276946
  validation loss:		0.433148
  validation accuracy:		86.63 %
Epoch 501 of 2000 took 0.035s
  training loss:		0.281122
  validation loss:		0.400650
  validation accuracy:		87.28 %
Epoch 502 of 2000 took 0.035s
  training loss:		0.288293
  validation loss:		0.403982
  validation accuracy:		87.28 %
Epoch 503 of 2000 took 0.035s
  training loss:		0.288380
  validation loss:		0.399594
  validation accuracy:		87.39 %
Epoch 504 of 2000 took 0.035s
  training loss:		0.279784
  validation loss:		0.410343
  validation accuracy:		86.63 %
Epoch 505 of 2000 took 0.035s
  training loss:		0.275471
  validation loss:		0.410319
  validation accuracy:		86.52 %
Epoch 506 of 2000 took 0.035s
  training loss:		0.283701
  validation loss:		0.417958
  validation accuracy:		86.74 %
Epoch 507 of 2000 took 0.035s
  training loss:		0.286300
  validation loss:		0.409732
  validation accuracy:		87.07 %
Epoch 508 of 2000 took 0.035s
  training loss:		0.274310
  validation loss:		0.391390
  validation accuracy:		87.39 %
Epoch 509 of 2000 took 0.035s
  training loss:		0.294357
  validation loss:		0.422121
  validation accuracy:		85.65 %
Epoch 510 of 2000 took 0.035s
  training loss:		0.280755
  validation loss:		0.400744
  validation accuracy:		87.07 %
Epoch 511 of 2000 took 0.035s
  training loss:		0.277174
  validation loss:		0.403872
  validation accuracy:		86.74 %
Epoch 512 of 2000 took 0.035s
  training loss:		0.284454
  validation loss:		0.397508
  validation accuracy:		87.72 %
Epoch 513 of 2000 took 0.035s
  training loss:		0.279952
  validation loss:		0.410467
  validation accuracy:		87.17 %
Epoch 514 of 2000 took 0.035s
  training loss:		0.287102
  validation loss:		0.402785
  validation accuracy:		86.96 %
Epoch 515 of 2000 took 0.035s
  training loss:		0.285599
  validation loss:		0.408388
  validation accuracy:		86.41 %
Epoch 516 of 2000 took 0.035s
  training loss:		0.283905
  validation loss:		0.404115
  validation accuracy:		87.07 %
Epoch 517 of 2000 took 0.035s
  training loss:		0.274476
  validation loss:		0.403853
  validation accuracy:		86.20 %
Epoch 518 of 2000 took 0.035s
  training loss:		0.285384
  validation loss:		0.386980
  validation accuracy:		87.28 %
Epoch 519 of 2000 took 0.035s
  training loss:		0.281818
  validation loss:		0.377461
  validation accuracy:		87.72 %
Epoch 520 of 2000 took 0.035s
  training loss:		0.286121
  validation loss:		0.396457
  validation accuracy:		87.93 %
Epoch 521 of 2000 took 0.035s
  training loss:		0.289755
  validation loss:		0.404459
  validation accuracy:		87.39 %
Epoch 522 of 2000 took 0.035s
  training loss:		0.279267
  validation loss:		0.417518
  validation accuracy:		87.28 %
Epoch 523 of 2000 took 0.035s
  training loss:		0.281612
  validation loss:		0.397512
  validation accuracy:		87.39 %
Epoch 524 of 2000 took 0.035s
  training loss:		0.278914
  validation loss:		0.414936
  validation accuracy:		86.74 %
Epoch 525 of 2000 took 0.035s
  training loss:		0.281693
  validation loss:		0.414089
  validation accuracy:		86.41 %
Epoch 526 of 2000 took 0.035s
  training loss:		0.281940
  validation loss:		0.408969
  validation accuracy:		86.63 %
Epoch 527 of 2000 took 0.035s
  training loss:		0.280393
  validation loss:		0.395241
  validation accuracy:		87.39 %
Epoch 528 of 2000 took 0.035s
  training loss:		0.280780
  validation loss:		0.388447
  validation accuracy:		87.72 %
Epoch 529 of 2000 took 0.035s
  training loss:		0.286563
  validation loss:		0.382322
  validation accuracy:		87.83 %
Epoch 530 of 2000 took 0.035s
  training loss:		0.284932
  validation loss:		0.403376
  validation accuracy:		87.39 %
Epoch 531 of 2000 took 0.035s
  training loss:		0.288683
  validation loss:		0.406779
  validation accuracy:		86.41 %
Epoch 532 of 2000 took 0.035s
  training loss:		0.287164
  validation loss:		0.434288
  validation accuracy:		86.09 %
Epoch 533 of 2000 took 0.035s
  training loss:		0.279726
  validation loss:		0.406003
  validation accuracy:		87.50 %
Epoch 534 of 2000 took 0.035s
  training loss:		0.278167
  validation loss:		0.418439
  validation accuracy:		86.85 %
Epoch 535 of 2000 took 0.035s
  training loss:		0.281985
  validation loss:		0.401306
  validation accuracy:		87.28 %
Epoch 536 of 2000 took 0.035s
  training loss:		0.289209
  validation loss:		0.392845
  validation accuracy:		87.83 %
Epoch 537 of 2000 took 0.035s
  training loss:		0.285588
  validation loss:		0.392144
  validation accuracy:		87.39 %
Epoch 538 of 2000 took 0.035s
  training loss:		0.274476
  validation loss:		0.415058
  validation accuracy:		87.07 %
Epoch 539 of 2000 took 0.035s
  training loss:		0.282592
  validation loss:		0.421130
  validation accuracy:		87.17 %
Epoch 540 of 2000 took 0.035s
  training loss:		0.288977
  validation loss:		0.397631
  validation accuracy:		87.28 %
Epoch 541 of 2000 took 0.035s
  training loss:		0.286654
  validation loss:		0.425434
  validation accuracy:		86.41 %
Epoch 542 of 2000 took 0.035s
  training loss:		0.283697
  validation loss:		0.401846
  validation accuracy:		87.50 %
Epoch 543 of 2000 took 0.035s
  training loss:		0.286053
  validation loss:		0.403641
  validation accuracy:		86.63 %
Epoch 544 of 2000 took 0.035s
  training loss:		0.279728
  validation loss:		0.390066
  validation accuracy:		87.72 %
Epoch 545 of 2000 took 0.035s
  training loss:		0.281955
  validation loss:		0.399451
  validation accuracy:		87.72 %
Epoch 546 of 2000 took 0.035s
  training loss:		0.281361
  validation loss:		0.394814
  validation accuracy:		87.83 %
Epoch 547 of 2000 took 0.035s
  training loss:		0.285778
  validation loss:		0.446286
  validation accuracy:		86.41 %
Epoch 548 of 2000 took 0.035s
  training loss:		0.286301
  validation loss:		0.412578
  validation accuracy:		86.74 %
Epoch 549 of 2000 took 0.035s
  training loss:		0.273689
  validation loss:		0.402989
  validation accuracy:		86.30 %
Epoch 550 of 2000 took 0.035s
  training loss:		0.277610
  validation loss:		0.411718
  validation accuracy:		87.17 %
Epoch 551 of 2000 took 0.035s
  training loss:		0.278580
  validation loss:		0.383059
  validation accuracy:		88.04 %
Epoch 552 of 2000 took 0.035s
  training loss:		0.276424
  validation loss:		0.431070
  validation accuracy:		86.74 %
Epoch 553 of 2000 took 0.035s
  training loss:		0.278968
  validation loss:		0.422500
  validation accuracy:		86.63 %
Epoch 554 of 2000 took 0.035s
  training loss:		0.282218
  validation loss:		0.419058
  validation accuracy:		86.85 %
Epoch 555 of 2000 took 0.035s
  training loss:		0.277953
  validation loss:		0.378477
  validation accuracy:		88.15 %
Epoch 556 of 2000 took 0.035s
  training loss:		0.280515
  validation loss:		0.402924
  validation accuracy:		87.39 %
Epoch 557 of 2000 took 0.035s
  training loss:		0.283966
  validation loss:		0.403994
  validation accuracy:		86.96 %
Epoch 558 of 2000 took 0.035s
  training loss:		0.282597
  validation loss:		0.408827
  validation accuracy:		87.28 %
Epoch 559 of 2000 took 0.035s
  training loss:		0.284271
  validation loss:		0.405998
  validation accuracy:		87.17 %
Epoch 560 of 2000 took 0.035s
  training loss:		0.282286
  validation loss:		0.418558
  validation accuracy:		87.07 %
Epoch 561 of 2000 took 0.035s
  training loss:		0.284844
  validation loss:		0.424067
  validation accuracy:		86.41 %
Epoch 562 of 2000 took 0.035s
  training loss:		0.292277
  validation loss:		0.396651
  validation accuracy:		86.74 %
Epoch 563 of 2000 took 0.035s
  training loss:		0.288454
  validation loss:		0.402847
  validation accuracy:		86.52 %
Epoch 564 of 2000 took 0.035s
  training loss:		0.277803
  validation loss:		0.398640
  validation accuracy:		87.28 %
Epoch 565 of 2000 took 0.035s
  training loss:		0.280996
  validation loss:		0.388223
  validation accuracy:		88.15 %
Epoch 566 of 2000 took 0.035s
  training loss:		0.282659
  validation loss:		0.402499
  validation accuracy:		87.28 %
Epoch 567 of 2000 took 0.035s
  training loss:		0.275132
  validation loss:		0.395247
  validation accuracy:		87.83 %
Epoch 568 of 2000 took 0.035s
  training loss:		0.277916
  validation loss:		0.412750
  validation accuracy:		86.41 %
Epoch 569 of 2000 took 0.035s
  training loss:		0.284518
  validation loss:		0.391189
  validation accuracy:		87.50 %
Epoch 570 of 2000 took 0.035s
  training loss:		0.284039
  validation loss:		0.419492
  validation accuracy:		86.30 %
Epoch 571 of 2000 took 0.035s
  training loss:		0.279101
  validation loss:		0.405357
  validation accuracy:		86.96 %
Epoch 572 of 2000 took 0.035s
  training loss:		0.269918
  validation loss:		0.405572
  validation accuracy:		87.17 %
Epoch 573 of 2000 took 0.035s
  training loss:		0.281703
  validation loss:		0.397425
  validation accuracy:		87.72 %
Epoch 574 of 2000 took 0.035s
  training loss:		0.278540
  validation loss:		0.403088
  validation accuracy:		87.72 %
Epoch 575 of 2000 took 0.035s
  training loss:		0.287573
  validation loss:		0.404540
  validation accuracy:		87.28 %
Epoch 576 of 2000 took 0.035s
  training loss:		0.273187
  validation loss:		0.374638
  validation accuracy:		88.48 %
Epoch 577 of 2000 took 0.035s
  training loss:		0.278858
  validation loss:		0.396785
  validation accuracy:		87.28 %
Epoch 578 of 2000 took 0.035s
  training loss:		0.276320
  validation loss:		0.397884
  validation accuracy:		87.39 %
Epoch 579 of 2000 took 0.035s
  training loss:		0.276457
  validation loss:		0.395488
  validation accuracy:		87.61 %
Epoch 580 of 2000 took 0.035s
  training loss:		0.281172
  validation loss:		0.404338
  validation accuracy:		86.52 %
Epoch 581 of 2000 took 0.035s
  training loss:		0.278710
  validation loss:		0.422609
  validation accuracy:		86.96 %
Epoch 582 of 2000 took 0.035s
  training loss:		0.279261
  validation loss:		0.392027
  validation accuracy:		87.61 %
Epoch 583 of 2000 took 0.035s
  training loss:		0.278761
  validation loss:		0.394769
  validation accuracy:		88.26 %
Epoch 584 of 2000 took 0.035s
  training loss:		0.282522
  validation loss:		0.391491
  validation accuracy:		88.15 %
Epoch 585 of 2000 took 0.035s
  training loss:		0.276180
  validation loss:		0.388686
  validation accuracy:		87.93 %
Epoch 586 of 2000 took 0.035s
  training loss:		0.279099
  validation loss:		0.404392
  validation accuracy:		86.96 %
Epoch 587 of 2000 took 0.035s
  training loss:		0.281333
  validation loss:		0.403686
  validation accuracy:		87.50 %
Epoch 588 of 2000 took 0.035s
  training loss:		0.280645
  validation loss:		0.417120
  validation accuracy:		86.63 %
Epoch 589 of 2000 took 0.035s
  training loss:		0.290331
  validation loss:		0.392949
  validation accuracy:		87.83 %
Epoch 590 of 2000 took 0.035s
  training loss:		0.283324
  validation loss:		0.412638
  validation accuracy:		87.39 %
Epoch 591 of 2000 took 0.035s
  training loss:		0.286664
  validation loss:		0.424674
  validation accuracy:		87.07 %
Epoch 592 of 2000 took 0.035s
  training loss:		0.276845
  validation loss:		0.390422
  validation accuracy:		87.83 %
Epoch 593 of 2000 took 0.035s
  training loss:		0.277517
  validation loss:		0.393580
  validation accuracy:		87.72 %
Epoch 594 of 2000 took 0.035s
  training loss:		0.275552
  validation loss:		0.399513
  validation accuracy:		87.39 %
Epoch 595 of 2000 took 0.035s
  training loss:		0.276329
  validation loss:		0.399998
  validation accuracy:		87.61 %
Epoch 596 of 2000 took 0.035s
  training loss:		0.273775
  validation loss:		0.396256
  validation accuracy:		87.07 %
Epoch 597 of 2000 took 0.035s
  training loss:		0.278701
  validation loss:		0.435195
  validation accuracy:		86.52 %
Epoch 598 of 2000 took 0.035s
  training loss:		0.271682
  validation loss:		0.419750
  validation accuracy:		86.52 %
Epoch 599 of 2000 took 0.035s
  training loss:		0.269180
  validation loss:		0.409964
  validation accuracy:		87.39 %
Epoch 600 of 2000 took 0.035s
  training loss:		0.284792
  validation loss:		0.408621
  validation accuracy:		86.85 %
Epoch 601 of 2000 took 0.035s
  training loss:		0.272263
  validation loss:		0.403025
  validation accuracy:		87.50 %
Epoch 602 of 2000 took 0.035s
  training loss:		0.281431
  validation loss:		0.403100
  validation accuracy:		86.96 %
Epoch 603 of 2000 took 0.035s
  training loss:		0.277704
  validation loss:		0.399093
  validation accuracy:		87.61 %
Epoch 604 of 2000 took 0.035s
  training loss:		0.280124
  validation loss:		0.400844
  validation accuracy:		87.61 %
Epoch 605 of 2000 took 0.035s
  training loss:		0.290262
  validation loss:		0.395624
  validation accuracy:		87.50 %
Epoch 606 of 2000 took 0.035s
  training loss:		0.287345
  validation loss:		0.408775
  validation accuracy:		86.96 %
Epoch 607 of 2000 took 0.035s
  training loss:		0.281782
  validation loss:		0.390826
  validation accuracy:		87.83 %
Epoch 608 of 2000 took 0.035s
  training loss:		0.270613
  validation loss:		0.404126
  validation accuracy:		87.72 %
Epoch 609 of 2000 took 0.035s
  training loss:		0.284067
  validation loss:		0.398177
  validation accuracy:		87.83 %
Epoch 610 of 2000 took 0.035s
  training loss:		0.276799
  validation loss:		0.423839
  validation accuracy:		86.74 %
Epoch 611 of 2000 took 0.035s
  training loss:		0.277529
  validation loss:		0.415526
  validation accuracy:		87.17 %
Epoch 612 of 2000 took 0.035s
  training loss:		0.276148
  validation loss:		0.387574
  validation accuracy:		87.72 %
Epoch 613 of 2000 took 0.035s
  training loss:		0.276043
  validation loss:		0.397039
  validation accuracy:		87.72 %
Epoch 614 of 2000 took 0.035s
  training loss:		0.276015
  validation loss:		0.411621
  validation accuracy:		87.50 %
Epoch 615 of 2000 took 0.035s
  training loss:		0.275390
  validation loss:		0.400448
  validation accuracy:		87.61 %
Epoch 616 of 2000 took 0.035s
  training loss:		0.278227
  validation loss:		0.418561
  validation accuracy:		87.17 %
Epoch 617 of 2000 took 0.035s
  training loss:		0.277174
  validation loss:		0.403863
  validation accuracy:		86.96 %
Epoch 618 of 2000 took 0.035s
  training loss:		0.276244
  validation loss:		0.403754
  validation accuracy:		87.50 %
Epoch 619 of 2000 took 0.035s
  training loss:		0.274320
  validation loss:		0.393220
  validation accuracy:		87.61 %
Epoch 620 of 2000 took 0.035s
  training loss:		0.274980
  validation loss:		0.408193
  validation accuracy:		87.39 %
Epoch 621 of 2000 took 0.035s
  training loss:		0.276671
  validation loss:		0.430696
  validation accuracy:		86.52 %
Epoch 622 of 2000 took 0.035s
  training loss:		0.279793
  validation loss:		0.417025
  validation accuracy:		86.85 %
Epoch 623 of 2000 took 0.035s
  training loss:		0.277485
  validation loss:		0.406981
  validation accuracy:		87.39 %
Epoch 624 of 2000 took 0.035s
  training loss:		0.278895
  validation loss:		0.400810
  validation accuracy:		87.61 %
Epoch 625 of 2000 took 0.035s
  training loss:		0.285914
  validation loss:		0.401744
  validation accuracy:		87.83 %
Epoch 626 of 2000 took 0.035s
  training loss:		0.276817
  validation loss:		0.406578
  validation accuracy:		86.63 %
Epoch 627 of 2000 took 0.035s
  training loss:		0.290520
  validation loss:		0.409269
  validation accuracy:		87.72 %
Epoch 628 of 2000 took 0.035s
  training loss:		0.279763
  validation loss:		0.413813
  validation accuracy:		87.28 %
Epoch 629 of 2000 took 0.035s
  training loss:		0.277729
  validation loss:		0.393672
  validation accuracy:		88.04 %
Epoch 630 of 2000 took 0.035s
  training loss:		0.275724
  validation loss:		0.409683
  validation accuracy:		87.17 %
Epoch 631 of 2000 took 0.035s
  training loss:		0.279230
  validation loss:		0.394598
  validation accuracy:		87.39 %
Epoch 632 of 2000 took 0.035s
  training loss:		0.279774
  validation loss:		0.415102
  validation accuracy:		87.17 %
Epoch 633 of 2000 took 0.035s
  training loss:		0.275031
  validation loss:		0.401512
  validation accuracy:		87.17 %
Epoch 634 of 2000 took 0.035s
  training loss:		0.275894
  validation loss:		0.419573
  validation accuracy:		86.52 %
Epoch 635 of 2000 took 0.035s
  training loss:		0.279731
  validation loss:		0.421395
  validation accuracy:		86.96 %
Epoch 636 of 2000 took 0.035s
  training loss:		0.276713
  validation loss:		0.390731
  validation accuracy:		87.72 %
Epoch 637 of 2000 took 0.035s
  training loss:		0.270529
  validation loss:		0.409041
  validation accuracy:		87.61 %
Epoch 638 of 2000 took 0.035s
  training loss:		0.278942
  validation loss:		0.402335
  validation accuracy:		87.72 %
Epoch 639 of 2000 took 0.035s
  training loss:		0.275837
  validation loss:		0.385185
  validation accuracy:		88.26 %
Epoch 640 of 2000 took 0.035s
  training loss:		0.273445
  validation loss:		0.391384
  validation accuracy:		87.50 %
Epoch 641 of 2000 took 0.035s
  training loss:		0.282501
  validation loss:		0.394844
  validation accuracy:		87.72 %
Epoch 642 of 2000 took 0.035s
  training loss:		0.282879
  validation loss:		0.434092
  validation accuracy:		86.96 %
Epoch 643 of 2000 took 0.035s
  training loss:		0.264179
  validation loss:		0.403548
  validation accuracy:		87.61 %
Epoch 644 of 2000 took 0.035s
  training loss:		0.279204
  validation loss:		0.401653
  validation accuracy:		86.74 %
Epoch 645 of 2000 took 0.035s
  training loss:		0.279670
  validation loss:		0.409128
  validation accuracy:		87.50 %
Epoch 646 of 2000 took 0.035s
  training loss:		0.279565
  validation loss:		0.396126
  validation accuracy:		87.50 %
Epoch 647 of 2000 took 0.035s
  training loss:		0.281991
  validation loss:		0.450924
  validation accuracy:		86.09 %
Epoch 648 of 2000 took 0.035s
  training loss:		0.278247
  validation loss:		0.387771
  validation accuracy:		88.26 %
Epoch 649 of 2000 took 0.035s
  training loss:		0.276902
  validation loss:		0.410080
  validation accuracy:		87.61 %
Epoch 650 of 2000 took 0.035s
  training loss:		0.279479
  validation loss:		0.389006
  validation accuracy:		88.26 %
Epoch 651 of 2000 took 0.035s
  training loss:		0.267569
  validation loss:		0.399857
  validation accuracy:		88.26 %
Epoch 652 of 2000 took 0.035s
  training loss:		0.275425
  validation loss:		0.412720
  validation accuracy:		86.74 %
Epoch 653 of 2000 took 0.035s
  training loss:		0.276490
  validation loss:		0.430422
  validation accuracy:		86.52 %
Epoch 654 of 2000 took 0.035s
  training loss:		0.282925
  validation loss:		0.416041
  validation accuracy:		87.39 %
Epoch 655 of 2000 took 0.035s
  training loss:		0.272962
  validation loss:		0.391284
  validation accuracy:		88.04 %
Epoch 656 of 2000 took 0.035s
  training loss:		0.274314
  validation loss:		0.401221
  validation accuracy:		88.04 %
Epoch 657 of 2000 took 0.035s
  training loss:		0.271672
  validation loss:		0.399234
  validation accuracy:		87.72 %
Epoch 658 of 2000 took 0.035s
  training loss:		0.281688
  validation loss:		0.398347
  validation accuracy:		87.93 %
Epoch 659 of 2000 took 0.035s
  training loss:		0.278504
  validation loss:		0.405382
  validation accuracy:		87.72 %
Epoch 660 of 2000 took 0.035s
  training loss:		0.263974
  validation loss:		0.422633
  validation accuracy:		87.07 %
Epoch 661 of 2000 took 0.035s
  training loss:		0.278681
  validation loss:		0.387838
  validation accuracy:		88.59 %
Epoch 662 of 2000 took 0.035s
  training loss:		0.271479
  validation loss:		0.399272
  validation accuracy:		86.96 %
Epoch 663 of 2000 took 0.035s
  training loss:		0.277761
  validation loss:		0.395792
  validation accuracy:		87.50 %
Epoch 664 of 2000 took 0.035s
  training loss:		0.276566
  validation loss:		0.379890
  validation accuracy:		88.04 %
Epoch 665 of 2000 took 0.035s
  training loss:		0.270322
  validation loss:		0.397377
  validation accuracy:		88.15 %
Epoch 666 of 2000 took 0.035s
  training loss:		0.274696
  validation loss:		0.399338
  validation accuracy:		87.50 %
Epoch 667 of 2000 took 0.035s
  training loss:		0.278991
  validation loss:		0.398636
  validation accuracy:		87.83 %
Epoch 668 of 2000 took 0.035s
  training loss:		0.276273
  validation loss:		0.394060
  validation accuracy:		87.39 %
Epoch 669 of 2000 took 0.035s
  training loss:		0.267400
  validation loss:		0.386071
  validation accuracy:		87.39 %
Epoch 670 of 2000 took 0.035s
  training loss:		0.263634
  validation loss:		0.400825
  validation accuracy:		88.15 %
Epoch 671 of 2000 took 0.035s
  training loss:		0.260142
  validation loss:		0.402861
  validation accuracy:		87.50 %
Epoch 672 of 2000 took 0.035s
  training loss:		0.273334
  validation loss:		0.411651
  validation accuracy:		86.85 %
Epoch 673 of 2000 took 0.035s
  training loss:		0.275062
  validation loss:		0.432341
  validation accuracy:		86.30 %
Epoch 674 of 2000 took 0.035s
  training loss:		0.273523
  validation loss:		0.391075
  validation accuracy:		87.72 %
Epoch 675 of 2000 took 0.035s
  training loss:		0.276695
  validation loss:		0.379274
  validation accuracy:		88.26 %
Epoch 676 of 2000 took 0.035s
  training loss:		0.279076
  validation loss:		0.390976
  validation accuracy:		88.15 %
Epoch 677 of 2000 took 0.035s
  training loss:		0.269382
  validation loss:		0.393257
  validation accuracy:		88.15 %
Epoch 678 of 2000 took 0.035s
  training loss:		0.272228
  validation loss:		0.411327
  validation accuracy:		86.85 %
Epoch 679 of 2000 took 0.035s
  training loss:		0.272424
  validation loss:		0.429256
  validation accuracy:		86.74 %
Epoch 680 of 2000 took 0.035s
  training loss:		0.274763
  validation loss:		0.400738
  validation accuracy:		87.17 %
Epoch 681 of 2000 took 0.035s
  training loss:		0.268131
  validation loss:		0.392819
  validation accuracy:		87.83 %
Epoch 682 of 2000 took 0.035s
  training loss:		0.277906
  validation loss:		0.386186
  validation accuracy:		88.15 %
Epoch 683 of 2000 took 0.035s
  training loss:		0.274947
  validation loss:		0.402076
  validation accuracy:		87.39 %
Epoch 684 of 2000 took 0.035s
  training loss:		0.271710
  validation loss:		0.398209
  validation accuracy:		87.07 %
Epoch 685 of 2000 took 0.035s
  training loss:		0.276073
  validation loss:		0.390540
  validation accuracy:		87.83 %
Epoch 686 of 2000 took 0.035s
  training loss:		0.270899
  validation loss:		0.394520
  validation accuracy:		87.93 %
Epoch 687 of 2000 took 0.035s
  training loss:		0.275214
  validation loss:		0.383976
  validation accuracy:		88.59 %
Epoch 688 of 2000 took 0.035s
  training loss:		0.272347
  validation loss:		0.395970
  validation accuracy:		87.61 %
Epoch 689 of 2000 took 0.035s
  training loss:		0.273869
  validation loss:		0.413643
  validation accuracy:		87.61 %
Epoch 690 of 2000 took 0.035s
  training loss:		0.273654
  validation loss:		0.396232
  validation accuracy:		88.59 %
Epoch 691 of 2000 took 0.035s
  training loss:		0.279001
  validation loss:		0.403072
  validation accuracy:		87.72 %
Epoch 692 of 2000 took 0.035s
  training loss:		0.271684
  validation loss:		0.397538
  validation accuracy:		88.26 %
Epoch 693 of 2000 took 0.035s
  training loss:		0.272991
  validation loss:		0.399371
  validation accuracy:		88.04 %
Epoch 694 of 2000 took 0.035s
  training loss:		0.273413
  validation loss:		0.418890
  validation accuracy:		87.17 %
Epoch 695 of 2000 took 0.035s
  training loss:		0.271612
  validation loss:		0.406511
  validation accuracy:		87.93 %
Epoch 696 of 2000 took 0.035s
  training loss:		0.270413
  validation loss:		0.388540
  validation accuracy:		88.26 %
Epoch 697 of 2000 took 0.035s
  training loss:		0.272804
  validation loss:		0.397827
  validation accuracy:		88.04 %
Epoch 698 of 2000 took 0.035s
  training loss:		0.271087
  validation loss:		0.398991
  validation accuracy:		87.28 %
Epoch 699 of 2000 took 0.035s
  training loss:		0.265372
  validation loss:		0.439418
  validation accuracy:		86.74 %
Epoch 700 of 2000 took 0.035s
  training loss:		0.277613
  validation loss:		0.412166
  validation accuracy:		87.28 %
Epoch 701 of 2000 took 0.035s
  training loss:		0.270553
  validation loss:		0.397406
  validation accuracy:		87.83 %
Epoch 702 of 2000 took 0.035s
  training loss:		0.285943
  validation loss:		0.390507
  validation accuracy:		87.83 %
Epoch 703 of 2000 took 0.035s
  training loss:		0.276288
  validation loss:		0.399714
  validation accuracy:		88.04 %
Epoch 704 of 2000 took 0.035s
  training loss:		0.270180
  validation loss:		0.388936
  validation accuracy:		88.70 %
Epoch 705 of 2000 took 0.035s
  training loss:		0.269862
  validation loss:		0.397701
  validation accuracy:		88.48 %
Epoch 706 of 2000 took 0.035s
  training loss:		0.266705
  validation loss:		0.388100
  validation accuracy:		87.50 %
Epoch 707 of 2000 took 0.035s
  training loss:		0.265869
  validation loss:		0.413295
  validation accuracy:		87.17 %
Epoch 708 of 2000 took 0.035s
  training loss:		0.269978
  validation loss:		0.392874
  validation accuracy:		88.26 %
Epoch 709 of 2000 took 0.035s
  training loss:		0.267985
  validation loss:		0.412463
  validation accuracy:		87.50 %
Epoch 710 of 2000 took 0.035s
  training loss:		0.268273
  validation loss:		0.411051
  validation accuracy:		87.28 %
Epoch 711 of 2000 took 0.035s
  training loss:		0.266889
  validation loss:		0.392856
  validation accuracy:		87.39 %
Epoch 712 of 2000 took 0.035s
  training loss:		0.270093
  validation loss:		0.417423
  validation accuracy:		87.28 %
Epoch 713 of 2000 took 0.035s
  training loss:		0.265180
  validation loss:		0.388886
  validation accuracy:		87.93 %
Epoch 714 of 2000 took 0.035s
  training loss:		0.271445
  validation loss:		0.417376
  validation accuracy:		87.07 %
Epoch 715 of 2000 took 0.035s
  training loss:		0.270737
  validation loss:		0.395985
  validation accuracy:		88.04 %
Epoch 716 of 2000 took 0.035s
  training loss:		0.267354
  validation loss:		0.395801
  validation accuracy:		87.93 %
Epoch 717 of 2000 took 0.035s
  training loss:		0.271793
  validation loss:		0.381636
  validation accuracy:		88.15 %
Epoch 718 of 2000 took 0.035s
  training loss:		0.270952
  validation loss:		0.391312
  validation accuracy:		88.04 %
Epoch 719 of 2000 took 0.035s
  training loss:		0.274431
  validation loss:		0.405803
  validation accuracy:		86.96 %
Epoch 720 of 2000 took 0.035s
  training loss:		0.269036
  validation loss:		0.411238
  validation accuracy:		87.50 %
Epoch 721 of 2000 took 0.035s
  training loss:		0.259244
  validation loss:		0.407565
  validation accuracy:		87.17 %
Epoch 722 of 2000 took 0.035s
  training loss:		0.272021
  validation loss:		0.388357
  validation accuracy:		87.72 %
Epoch 723 of 2000 took 0.035s
  training loss:		0.270880
  validation loss:		0.409731
  validation accuracy:		87.72 %
Epoch 724 of 2000 took 0.035s
  training loss:		0.264704
  validation loss:		0.386711
  validation accuracy:		88.59 %
Epoch 725 of 2000 took 0.035s
  training loss:		0.264368
  validation loss:		0.388494
  validation accuracy:		87.83 %
Epoch 726 of 2000 took 0.035s
  training loss:		0.271968
  validation loss:		0.391268
  validation accuracy:		88.48 %
Epoch 727 of 2000 took 0.035s
  training loss:		0.274363
  validation loss:		0.418756
  validation accuracy:		87.72 %
Epoch 728 of 2000 took 0.035s
  training loss:		0.270339
  validation loss:		0.426715
  validation accuracy:		86.63 %
Epoch 729 of 2000 took 0.035s
  training loss:		0.278297
  validation loss:		0.397404
  validation accuracy:		87.50 %
Epoch 730 of 2000 took 0.035s
  training loss:		0.264461
  validation loss:		0.394552
  validation accuracy:		88.37 %
Epoch 731 of 2000 took 0.035s
  training loss:		0.267980
  validation loss:		0.429690
  validation accuracy:		86.41 %
Epoch 732 of 2000 took 0.035s
  training loss:		0.273673
  validation loss:		0.403393
  validation accuracy:		87.50 %
Epoch 733 of 2000 took 0.035s
  training loss:		0.265831
  validation loss:		0.426128
  validation accuracy:		86.63 %
Epoch 734 of 2000 took 0.035s
  training loss:		0.267743
  validation loss:		0.406898
  validation accuracy:		87.83 %
Epoch 735 of 2000 took 0.035s
  training loss:		0.268004
  validation loss:		0.412192
  validation accuracy:		87.07 %
Epoch 736 of 2000 took 0.035s
  training loss:		0.264738
  validation loss:		0.413688
  validation accuracy:		87.50 %
Epoch 737 of 2000 took 0.035s
  training loss:		0.267192
  validation loss:		0.407184
  validation accuracy:		87.39 %
Epoch 738 of 2000 took 0.035s
  training loss:		0.270845
  validation loss:		0.393849
  validation accuracy:		88.70 %
Epoch 739 of 2000 took 0.035s
  training loss:		0.262181
  validation loss:		0.383423
  validation accuracy:		88.04 %
Epoch 740 of 2000 took 0.035s
  training loss:		0.267493
  validation loss:		0.399340
  validation accuracy:		87.17 %
Epoch 741 of 2000 took 0.035s
  training loss:		0.258934
  validation loss:		0.404066
  validation accuracy:		86.96 %
Epoch 742 of 2000 took 0.035s
  training loss:		0.266345
  validation loss:		0.390722
  validation accuracy:		87.83 %
Epoch 743 of 2000 took 0.035s
  training loss:		0.261371
  validation loss:		0.388158
  validation accuracy:		87.83 %
Epoch 744 of 2000 took 0.035s
  training loss:		0.273873
  validation loss:		0.374789
  validation accuracy:		88.26 %
Epoch 745 of 2000 took 0.035s
  training loss:		0.276346
  validation loss:		0.422487
  validation accuracy:		86.52 %
Epoch 746 of 2000 took 0.035s
  training loss:		0.263182
  validation loss:		0.391199
  validation accuracy:		88.26 %
Epoch 747 of 2000 took 0.035s
  training loss:		0.262738
  validation loss:		0.388969
  validation accuracy:		88.04 %
Epoch 748 of 2000 took 0.035s
  training loss:		0.265967
  validation loss:		0.405657
  validation accuracy:		87.61 %
Epoch 749 of 2000 took 0.035s
  training loss:		0.262388
  validation loss:		0.400439
  validation accuracy:		87.93 %
Epoch 750 of 2000 took 0.035s
  training loss:		0.262567
  validation loss:		0.386090
  validation accuracy:		88.37 %
Epoch 751 of 2000 took 0.035s
  training loss:		0.259697
  validation loss:		0.405647
  validation accuracy:		87.28 %
Epoch 752 of 2000 took 0.035s
  training loss:		0.263526
  validation loss:		0.385583
  validation accuracy:		87.83 %
Epoch 753 of 2000 took 0.035s
  training loss:		0.260444
  validation loss:		0.380039
  validation accuracy:		87.83 %
Epoch 754 of 2000 took 0.035s
  training loss:		0.257327
  validation loss:		0.403326
  validation accuracy:		86.96 %
Epoch 755 of 2000 took 0.035s
  training loss:		0.259626
  validation loss:		0.387498
  validation accuracy:		88.59 %
Epoch 756 of 2000 took 0.035s
  training loss:		0.260838
  validation loss:		0.398408
  validation accuracy:		88.15 %
Epoch 757 of 2000 took 0.035s
  training loss:		0.265954
  validation loss:		0.393105
  validation accuracy:		87.39 %
Epoch 758 of 2000 took 0.035s
  training loss:		0.264733
  validation loss:		0.400037
  validation accuracy:		88.04 %
Epoch 759 of 2000 took 0.035s
  training loss:		0.267819
  validation loss:		0.393842
  validation accuracy:		88.59 %
Epoch 760 of 2000 took 0.035s
  training loss:		0.257899
  validation loss:		0.386199
  validation accuracy:		88.70 %
Epoch 761 of 2000 took 0.035s
  training loss:		0.259081
  validation loss:		0.386862
  validation accuracy:		88.04 %
Epoch 762 of 2000 took 0.035s
  training loss:		0.263499
  validation loss:		0.394213
  validation accuracy:		87.61 %
Epoch 763 of 2000 took 0.035s
  training loss:		0.263765
  validation loss:		0.386717
  validation accuracy:		88.70 %
Epoch 764 of 2000 took 0.035s
  training loss:		0.260612
  validation loss:		0.388870
  validation accuracy:		88.26 %
Epoch 765 of 2000 took 0.035s
  training loss:		0.261063
  validation loss:		0.404699
  validation accuracy:		88.04 %
Epoch 766 of 2000 took 0.035s
  training loss:		0.260646
  validation loss:		0.391145
  validation accuracy:		87.93 %
Epoch 767 of 2000 took 0.035s
  training loss:		0.264915
  validation loss:		0.403647
  validation accuracy:		87.72 %
Epoch 768 of 2000 took 0.035s
  training loss:		0.264313
  validation loss:		0.398342
  validation accuracy:		88.04 %
Epoch 769 of 2000 took 0.035s
  training loss:		0.259142
  validation loss:		0.391380
  validation accuracy:		87.93 %
Epoch 770 of 2000 took 0.035s
  training loss:		0.255064
  validation loss:		0.397972
  validation accuracy:		87.39 %
Epoch 771 of 2000 took 0.035s
  training loss:		0.263836
  validation loss:		0.403720
  validation accuracy:		88.26 %
Epoch 772 of 2000 took 0.035s
  training loss:		0.252555
  validation loss:		0.392426
  validation accuracy:		87.50 %
Epoch 773 of 2000 took 0.035s
  training loss:		0.261712
  validation loss:		0.393285
  validation accuracy:		88.04 %
Epoch 774 of 2000 took 0.035s
  training loss:		0.262270
  validation loss:		0.412056
  validation accuracy:		88.04 %
Epoch 775 of 2000 took 0.035s
  training loss:		0.262180
  validation loss:		0.403632
  validation accuracy:		87.28 %
Epoch 776 of 2000 took 0.035s
  training loss:		0.260498
  validation loss:		0.400355
  validation accuracy:		88.59 %
Epoch 777 of 2000 took 0.035s
  training loss:		0.257523
  validation loss:		0.389339
  validation accuracy:		87.93 %
Epoch 778 of 2000 took 0.035s
  training loss:		0.260086
  validation loss:		0.382128
  validation accuracy:		88.26 %
Epoch 779 of 2000 took 0.035s
  training loss:		0.254684
  validation loss:		0.403590
  validation accuracy:		88.48 %
Epoch 780 of 2000 took 0.035s
  training loss:		0.259624
  validation loss:		0.429104
  validation accuracy:		87.17 %
Epoch 781 of 2000 took 0.035s
  training loss:		0.259929
  validation loss:		0.401211
  validation accuracy:		87.50 %
Epoch 782 of 2000 took 0.035s
  training loss:		0.256571
  validation loss:		0.387034
  validation accuracy:		88.26 %
Epoch 783 of 2000 took 0.035s
  training loss:		0.254967
  validation loss:		0.391107
  validation accuracy:		87.93 %
Epoch 784 of 2000 took 0.035s
  training loss:		0.258940
  validation loss:		0.396452
  validation accuracy:		88.59 %
Epoch 785 of 2000 took 0.035s
  training loss:		0.263086
  validation loss:		0.385525
  validation accuracy:		87.83 %
Epoch 786 of 2000 took 0.035s
  training loss:		0.256790
  validation loss:		0.405377
  validation accuracy:		87.50 %
Epoch 787 of 2000 took 0.035s
  training loss:		0.262505
  validation loss:		0.424044
  validation accuracy:		87.28 %
Epoch 788 of 2000 took 0.035s
  training loss:		0.261171
  validation loss:		0.381320
  validation accuracy:		88.26 %
Epoch 789 of 2000 took 0.035s
  training loss:		0.258753
  validation loss:		0.407407
  validation accuracy:		88.48 %
Epoch 790 of 2000 took 0.035s
  training loss:		0.254880
  validation loss:		0.403377
  validation accuracy:		87.50 %
Epoch 791 of 2000 took 0.035s
  training loss:		0.254947
  validation loss:		0.409640
  validation accuracy:		87.07 %
Epoch 792 of 2000 took 0.035s
  training loss:		0.251547
  validation loss:		0.406724
  validation accuracy:		87.39 %
Epoch 793 of 2000 took 0.035s
  training loss:		0.258951
  validation loss:		0.392506
  validation accuracy:		87.50 %
Epoch 794 of 2000 took 0.035s
  training loss:		0.249442
  validation loss:		0.382833
  validation accuracy:		88.37 %
Epoch 795 of 2000 took 0.035s
  training loss:		0.251734
  validation loss:		0.387874
  validation accuracy:		88.26 %
Epoch 796 of 2000 took 0.035s
  training loss:		0.254592
  validation loss:		0.381689
  validation accuracy:		88.15 %
Epoch 797 of 2000 took 0.035s
  training loss:		0.251046
  validation loss:		0.392398
  validation accuracy:		87.83 %
Epoch 798 of 2000 took 0.035s
  training loss:		0.257430
  validation loss:		0.401803
  validation accuracy:		88.48 %
Epoch 799 of 2000 took 0.035s
  training loss:		0.252816
  validation loss:		0.395465
  validation accuracy:		88.04 %
Epoch 800 of 2000 took 0.035s
  training loss:		0.257633
  validation loss:		0.394203
  validation accuracy:		88.48 %
Epoch 801 of 2000 took 0.035s
  training loss:		0.252422
  validation loss:		0.369252
  validation accuracy:		89.46 %
Epoch 802 of 2000 took 0.035s
  training loss:		0.252980
  validation loss:		0.374152
  validation accuracy:		88.80 %
Epoch 803 of 2000 took 0.035s
  training loss:		0.250952
  validation loss:		0.390115
  validation accuracy:		88.37 %
Epoch 804 of 2000 took 0.035s
  training loss:		0.258835
  validation loss:		0.395093
  validation accuracy:		88.26 %
Epoch 805 of 2000 took 0.035s
  training loss:		0.254729
  validation loss:		0.385979
  validation accuracy:		88.48 %
Epoch 806 of 2000 took 0.035s
  training loss:		0.254546
  validation loss:		0.399705
  validation accuracy:		88.37 %
Epoch 807 of 2000 took 0.035s
  training loss:		0.253327
  validation loss:		0.393464
  validation accuracy:		87.61 %
Epoch 808 of 2000 took 0.035s
  training loss:		0.253111
  validation loss:		0.404344
  validation accuracy:		87.28 %
Epoch 809 of 2000 took 0.035s
  training loss:		0.245389
  validation loss:		0.412576
  validation accuracy:		87.28 %
Epoch 810 of 2000 took 0.035s
  training loss:		0.253763
  validation loss:		0.425578
  validation accuracy:		86.52 %
Epoch 811 of 2000 took 0.035s
  training loss:		0.257255
  validation loss:		0.384349
  validation accuracy:		88.04 %
Epoch 812 of 2000 took 0.035s
  training loss:		0.248619
  validation loss:		0.399432
  validation accuracy:		88.48 %
Epoch 813 of 2000 took 0.035s
  training loss:		0.259731
  validation loss:		0.400796
  validation accuracy:		88.26 %
Epoch 814 of 2000 took 0.035s
  training loss:		0.255472
  validation loss:		0.393357
  validation accuracy:		88.48 %
Epoch 815 of 2000 took 0.035s
  training loss:		0.254133
  validation loss:		0.380261
  validation accuracy:		88.59 %
Epoch 816 of 2000 took 0.035s
  training loss:		0.258758
  validation loss:		0.400862
  validation accuracy:		87.83 %
Epoch 817 of 2000 took 0.035s
  training loss:		0.254976
  validation loss:		0.385319
  validation accuracy:		88.15 %
Epoch 818 of 2000 took 0.035s
  training loss:		0.253019
  validation loss:		0.425918
  validation accuracy:		87.17 %
Epoch 819 of 2000 took 0.035s
  training loss:		0.252988
  validation loss:		0.389255
  validation accuracy:		87.72 %
Epoch 820 of 2000 took 0.035s
  training loss:		0.250872
  validation loss:		0.372877
  validation accuracy:		88.70 %
Epoch 821 of 2000 took 0.035s
  training loss:		0.247877
  validation loss:		0.379656
  validation accuracy:		88.26 %
Epoch 822 of 2000 took 0.035s
  training loss:		0.253340
  validation loss:		0.389367
  validation accuracy:		88.91 %
Epoch 823 of 2000 took 0.035s
  training loss:		0.249293
  validation loss:		0.385642
  validation accuracy:		88.15 %
Epoch 824 of 2000 took 0.035s
  training loss:		0.250056
  validation loss:		0.394988
  validation accuracy:		88.37 %
Epoch 825 of 2000 took 0.035s
  training loss:		0.250263
  validation loss:		0.390238
  validation accuracy:		87.72 %
Epoch 826 of 2000 took 0.035s
  training loss:		0.245445
  validation loss:		0.387196
  validation accuracy:		88.37 %
Epoch 827 of 2000 took 0.035s
  training loss:		0.249110
  validation loss:		0.368214
  validation accuracy:		89.02 %
Epoch 828 of 2000 took 0.035s
  training loss:		0.249218
  validation loss:		0.377473
  validation accuracy:		87.83 %
Epoch 829 of 2000 took 0.035s
  training loss:		0.253250
  validation loss:		0.372965
  validation accuracy:		88.59 %
Epoch 830 of 2000 took 0.035s
  training loss:		0.250695
  validation loss:		0.387402
  validation accuracy:		89.02 %
Epoch 831 of 2000 took 0.035s
  training loss:		0.251604
  validation loss:		0.392299
  validation accuracy:		89.02 %
Epoch 832 of 2000 took 0.035s
  training loss:		0.239666
  validation loss:		0.385954
  validation accuracy:		88.48 %
Epoch 833 of 2000 took 0.035s
  training loss:		0.245616
  validation loss:		0.400880
  validation accuracy:		87.50 %
Epoch 834 of 2000 took 0.035s
  training loss:		0.247575
  validation loss:		0.391823
  validation accuracy:		87.50 %
Epoch 835 of 2000 took 0.035s
  training loss:		0.245535
  validation loss:		0.395239
  validation accuracy:		88.15 %
Epoch 836 of 2000 took 0.035s
  training loss:		0.242913
  validation loss:		0.375925
  validation accuracy:		89.13 %
Epoch 837 of 2000 took 0.035s
  training loss:		0.247640
  validation loss:		0.388936
  validation accuracy:		89.02 %
Epoch 838 of 2000 took 0.035s
  training loss:		0.238321
  validation loss:		0.380654
  validation accuracy:		88.37 %
Epoch 839 of 2000 took 0.035s
  training loss:		0.240873
  validation loss:		0.377706
  validation accuracy:		88.04 %
Epoch 840 of 2000 took 0.035s
  training loss:		0.247909
  validation loss:		0.379632
  validation accuracy:		88.37 %
Epoch 841 of 2000 took 0.035s
  training loss:		0.240376
  validation loss:		0.391259
  validation accuracy:		87.93 %
Epoch 842 of 2000 took 0.035s
  training loss:		0.248553
  validation loss:		0.383193
  validation accuracy:		88.48 %
Epoch 843 of 2000 took 0.035s
  training loss:		0.252172
  validation loss:		0.387511
  validation accuracy:		88.26 %
Epoch 844 of 2000 took 0.035s
  training loss:		0.252531
  validation loss:		0.398080
  validation accuracy:		87.72 %
Epoch 845 of 2000 took 0.035s
  training loss:		0.249589
  validation loss:		0.387473
  validation accuracy:		88.48 %
Epoch 846 of 2000 took 0.035s
  training loss:		0.251928
  validation loss:		0.391841
  validation accuracy:		87.72 %
Epoch 847 of 2000 took 0.035s
  training loss:		0.243672
  validation loss:		0.387452
  validation accuracy:		89.02 %
Epoch 848 of 2000 took 0.035s
  training loss:		0.250779
  validation loss:		0.398875
  validation accuracy:		88.15 %
Epoch 849 of 2000 took 0.035s
  training loss:		0.249910
  validation loss:		0.391657
  validation accuracy:		87.61 %
Epoch 850 of 2000 took 0.035s
  training loss:		0.240567
  validation loss:		0.392742
  validation accuracy:		88.48 %
Epoch 851 of 2000 took 0.035s
  training loss:		0.246310
  validation loss:		0.392231
  validation accuracy:		88.70 %
Epoch 852 of 2000 took 0.035s
  training loss:		0.248373
  validation loss:		0.403523
  validation accuracy:		88.26 %
Epoch 853 of 2000 took 0.035s
  training loss:		0.243615
  validation loss:		0.389047
  validation accuracy:		88.04 %
Epoch 854 of 2000 took 0.035s
  training loss:		0.241614
  validation loss:		0.390669
  validation accuracy:		88.15 %
Epoch 855 of 2000 took 0.035s
  training loss:		0.247698
  validation loss:		0.397897
  validation accuracy:		87.83 %
Epoch 856 of 2000 took 0.035s
  training loss:		0.239534
  validation loss:		0.385981
  validation accuracy:		88.37 %
Epoch 857 of 2000 took 0.035s
  training loss:		0.248683
  validation loss:		0.381050
  validation accuracy:		88.59 %
Epoch 858 of 2000 took 0.035s
  training loss:		0.243884
  validation loss:		0.391527
  validation accuracy:		88.04 %
Epoch 859 of 2000 took 0.035s
  training loss:		0.244584
  validation loss:		0.390360
  validation accuracy:		87.93 %
Epoch 860 of 2000 took 0.035s
  training loss:		0.243398
  validation loss:		0.391886
  validation accuracy:		87.72 %
Epoch 861 of 2000 took 0.035s
  training loss:		0.239143
  validation loss:		0.401438
  validation accuracy:		87.28 %
Epoch 862 of 2000 took 0.035s
  training loss:		0.253746
  validation loss:		0.377134
  validation accuracy:		89.13 %
Epoch 863 of 2000 took 0.035s
  training loss:		0.248857
  validation loss:		0.389654
  validation accuracy:		88.48 %
Epoch 864 of 2000 took 0.035s
  training loss:		0.243842
  validation loss:		0.399088
  validation accuracy:		88.48 %
Epoch 865 of 2000 took 0.035s
  training loss:		0.236365
  validation loss:		0.374477
  validation accuracy:		88.48 %
Epoch 866 of 2000 took 0.035s
  training loss:		0.239903
  validation loss:		0.376280
  validation accuracy:		88.70 %
Epoch 867 of 2000 took 0.035s
  training loss:		0.241466
  validation loss:		0.382794
  validation accuracy:		88.70 %
Epoch 868 of 2000 took 0.035s
  training loss:		0.232566
  validation loss:		0.375403
  validation accuracy:		89.02 %
Epoch 869 of 2000 took 0.035s
  training loss:		0.238937
  validation loss:		0.379429
  validation accuracy:		88.26 %
Epoch 870 of 2000 took 0.037s
  training loss:		0.235964
  validation loss:		0.374580
  validation accuracy:		88.91 %
Epoch 871 of 2000 took 0.035s
  training loss:		0.244986
  validation loss:		0.386002
  validation accuracy:		88.26 %
Epoch 872 of 2000 took 0.035s
  training loss:		0.246824
  validation loss:		0.367762
  validation accuracy:		88.91 %
Epoch 873 of 2000 took 0.035s
  training loss:		0.241796
  validation loss:		0.379465
  validation accuracy:		88.04 %
Epoch 874 of 2000 took 0.035s
  training loss:		0.242939
  validation loss:		0.394325
  validation accuracy:		88.70 %
Epoch 875 of 2000 took 0.035s
  training loss:		0.241156
  validation loss:		0.384634
  validation accuracy:		88.26 %
Epoch 876 of 2000 took 0.035s
  training loss:		0.238811
  validation loss:		0.374045
  validation accuracy:		88.80 %
Epoch 877 of 2000 took 0.035s
  training loss:		0.239034
  validation loss:		0.404127
  validation accuracy:		88.04 %
Epoch 878 of 2000 took 0.035s
  training loss:		0.242976
  validation loss:		0.383626
  validation accuracy:		88.59 %
Epoch 879 of 2000 took 0.035s
  training loss:		0.238764
  validation loss:		0.394983
  validation accuracy:		87.93 %
Epoch 880 of 2000 took 0.035s
  training loss:		0.238745
  validation loss:		0.397697
  validation accuracy:		87.93 %
Epoch 881 of 2000 took 0.035s
  training loss:		0.237996
  validation loss:		0.380967
  validation accuracy:		88.59 %
Epoch 882 of 2000 took 0.035s
  training loss:		0.236917
  validation loss:		0.385448
  validation accuracy:		88.80 %
Epoch 883 of 2000 took 0.035s
  training loss:		0.236917
  validation loss:		0.382259
  validation accuracy:		88.59 %
Epoch 884 of 2000 took 0.035s
  training loss:		0.234948
  validation loss:		0.380031
  validation accuracy:		88.59 %
Epoch 885 of 2000 took 0.035s
  training loss:		0.239535
  validation loss:		0.384126
  validation accuracy:		88.59 %
Epoch 886 of 2000 took 0.035s
  training loss:		0.238486
  validation loss:		0.391941
  validation accuracy:		87.93 %
Epoch 887 of 2000 took 0.035s
  training loss:		0.233167
  validation loss:		0.379081
  validation accuracy:		88.80 %
Epoch 888 of 2000 took 0.035s
  training loss:		0.233468
  validation loss:		0.393952
  validation accuracy:		88.37 %
Epoch 889 of 2000 took 0.035s
  training loss:		0.233893
  validation loss:		0.379625
  validation accuracy:		88.48 %
Epoch 890 of 2000 took 0.035s
  training loss:		0.238401
  validation loss:		0.372535
  validation accuracy:		88.91 %
Epoch 891 of 2000 took 0.035s
  training loss:		0.239055
  validation loss:		0.393309
  validation accuracy:		88.37 %
Epoch 892 of 2000 took 0.035s
  training loss:		0.236941
  validation loss:		0.385773
  validation accuracy:		88.04 %
Epoch 893 of 2000 took 0.035s
  training loss:		0.240099
  validation loss:		0.380765
  validation accuracy:		88.04 %
Epoch 894 of 2000 took 0.035s
  training loss:		0.239564
  validation loss:		0.387721
  validation accuracy:		87.61 %
Epoch 895 of 2000 took 0.035s
  training loss:		0.238320
  validation loss:		0.396278
  validation accuracy:		87.93 %
Epoch 896 of 2000 took 0.035s
  training loss:		0.236420
  validation loss:		0.389972
  validation accuracy:		88.26 %
Epoch 897 of 2000 took 0.035s
  training loss:		0.241465
  validation loss:		0.396587
  validation accuracy:		88.70 %
Epoch 898 of 2000 took 0.035s
  training loss:		0.228073
  validation loss:		0.370494
  validation accuracy:		88.70 %
Epoch 899 of 2000 took 0.035s
  training loss:		0.239244
  validation loss:		0.384867
  validation accuracy:		88.59 %
Epoch 900 of 2000 took 0.035s
  training loss:		0.238299
  validation loss:		0.392137
  validation accuracy:		88.48 %
Epoch 901 of 2000 took 0.035s
  training loss:		0.233178
  validation loss:		0.392775
  validation accuracy:		87.93 %
Epoch 902 of 2000 took 0.035s
  training loss:		0.241611
  validation loss:		0.363586
  validation accuracy:		88.70 %
Epoch 903 of 2000 took 0.035s
  training loss:		0.237956
  validation loss:		0.383998
  validation accuracy:		88.04 %
Epoch 904 of 2000 took 0.035s
  training loss:		0.240911
  validation loss:		0.376362
  validation accuracy:		89.02 %
Epoch 905 of 2000 took 0.035s
  training loss:		0.229820
  validation loss:		0.373987
  validation accuracy:		88.80 %
Epoch 906 of 2000 took 0.035s
  training loss:		0.236717
  validation loss:		0.384522
  validation accuracy:		88.48 %
Epoch 907 of 2000 took 0.035s
  training loss:		0.235767
  validation loss:		0.383213
  validation accuracy:		87.93 %
Epoch 908 of 2000 took 0.035s
  training loss:		0.234585
  validation loss:		0.382349
  validation accuracy:		88.70 %
Epoch 909 of 2000 took 0.035s
  training loss:		0.233368
  validation loss:		0.364723
  validation accuracy:		89.13 %
Epoch 910 of 2000 took 0.035s
  training loss:		0.229011
  validation loss:		0.378090
  validation accuracy:		88.59 %
Epoch 911 of 2000 took 0.035s
  training loss:		0.235343
  validation loss:		0.369809
  validation accuracy:		88.80 %
Epoch 912 of 2000 took 0.035s
  training loss:		0.232350
  validation loss:		0.377567
  validation accuracy:		88.04 %
Epoch 913 of 2000 took 0.035s
  training loss:		0.230339
  validation loss:		0.374291
  validation accuracy:		88.91 %
Epoch 914 of 2000 took 0.035s
  training loss:		0.231596
  validation loss:		0.417034
  validation accuracy:		87.72 %
Epoch 915 of 2000 took 0.035s
  training loss:		0.234804
  validation loss:		0.380903
  validation accuracy:		88.59 %
Epoch 916 of 2000 took 0.035s
  training loss:		0.234534
  validation loss:		0.395221
  validation accuracy:		87.93 %
Epoch 917 of 2000 took 0.035s
  training loss:		0.237346
  validation loss:		0.385755
  validation accuracy:		88.48 %
Epoch 918 of 2000 took 0.035s
  training loss:		0.233131
  validation loss:		0.385401
  validation accuracy:		88.37 %
Epoch 919 of 2000 took 0.035s
  training loss:		0.233222
  validation loss:		0.364417
  validation accuracy:		88.80 %
Epoch 920 of 2000 took 0.035s
  training loss:		0.230077
  validation loss:		0.406907
  validation accuracy:		87.83 %
Epoch 921 of 2000 took 0.035s
  training loss:		0.232970
  validation loss:		0.375071
  validation accuracy:		88.70 %
Epoch 922 of 2000 took 0.035s
  training loss:		0.231531
  validation loss:		0.374360
  validation accuracy:		89.02 %
Epoch 923 of 2000 took 0.035s
  training loss:		0.220965
  validation loss:		0.378895
  validation accuracy:		88.48 %
Epoch 924 of 2000 took 0.035s
  training loss:		0.233445
  validation loss:		0.382742
  validation accuracy:		88.70 %
Epoch 925 of 2000 took 0.035s
  training loss:		0.229600
  validation loss:		0.367400
  validation accuracy:		89.35 %
Epoch 926 of 2000 took 0.035s
  training loss:		0.236481
  validation loss:		0.371389
  validation accuracy:		88.48 %
Epoch 927 of 2000 took 0.035s
  training loss:		0.231836
  validation loss:		0.374192
  validation accuracy:		88.59 %
Epoch 928 of 2000 took 0.035s
  training loss:		0.225414
  validation loss:		0.394533
  validation accuracy:		87.72 %
Epoch 929 of 2000 took 0.035s
  training loss:		0.232031
  validation loss:		0.383819
  validation accuracy:		88.37 %
Epoch 930 of 2000 took 0.035s
  training loss:		0.224800
  validation loss:		0.370984
  validation accuracy:		88.59 %
Epoch 931 of 2000 took 0.035s
  training loss:		0.224839
  validation loss:		0.396793
  validation accuracy:		88.15 %
Epoch 932 of 2000 took 0.035s
  training loss:		0.230346
  validation loss:		0.378346
  validation accuracy:		87.93 %
Epoch 933 of 2000 took 0.035s
  training loss:		0.232164
  validation loss:		0.373728
  validation accuracy:		88.59 %
Epoch 934 of 2000 took 0.035s
  training loss:		0.223977
  validation loss:		0.382811
  validation accuracy:		88.59 %
Epoch 935 of 2000 took 0.035s
  training loss:		0.226991
  validation loss:		0.386822
  validation accuracy:		88.48 %
Epoch 936 of 2000 took 0.035s
  training loss:		0.229574
  validation loss:		0.371507
  validation accuracy:		88.80 %
Epoch 937 of 2000 took 0.035s
  training loss:		0.226105
  validation loss:		0.373675
  validation accuracy:		88.91 %
Epoch 938 of 2000 took 0.035s
  training loss:		0.228411
  validation loss:		0.391688
  validation accuracy:		88.26 %
Epoch 939 of 2000 took 0.035s
  training loss:		0.228687
  validation loss:		0.387410
  validation accuracy:		87.61 %
Epoch 940 of 2000 took 0.035s
  training loss:		0.219451
  validation loss:		0.381221
  validation accuracy:		88.48 %
Epoch 941 of 2000 took 0.035s
  training loss:		0.238038
  validation loss:		0.388710
  validation accuracy:		88.59 %
Epoch 942 of 2000 took 0.035s
  training loss:		0.227699
  validation loss:		0.380088
  validation accuracy:		88.37 %
Epoch 943 of 2000 took 0.035s
  training loss:		0.224256
  validation loss:		0.385947
  validation accuracy:		87.83 %
Epoch 944 of 2000 took 0.035s
  training loss:		0.231479
  validation loss:		0.382300
  validation accuracy:		88.59 %
Epoch 945 of 2000 took 0.035s
  training loss:		0.224481
  validation loss:		0.384787
  validation accuracy:		88.70 %
Epoch 946 of 2000 took 0.035s
  training loss:		0.223838
  validation loss:		0.378947
  validation accuracy:		88.48 %
Epoch 947 of 2000 took 0.035s
  training loss:		0.236309
  validation loss:		0.392012
  validation accuracy:		88.80 %
Epoch 948 of 2000 took 0.035s
  training loss:		0.229551
  validation loss:		0.387449
  validation accuracy:		88.15 %
Epoch 949 of 2000 took 0.035s
  training loss:		0.229906
  validation loss:		0.376080
  validation accuracy:		88.70 %
Epoch 950 of 2000 took 0.035s
  training loss:		0.224209
  validation loss:		0.383321
  validation accuracy:		87.93 %
Epoch 951 of 2000 took 0.035s
  training loss:		0.224706
  validation loss:		0.390422
  validation accuracy:		87.61 %
Epoch 952 of 2000 took 0.035s
  training loss:		0.227258
  validation loss:		0.388673
  validation accuracy:		87.72 %
Epoch 953 of 2000 took 0.035s
  training loss:		0.224612
  validation loss:		0.385118
  validation accuracy:		88.70 %
Epoch 954 of 2000 took 0.035s
  training loss:		0.229672
  validation loss:		0.386183
  validation accuracy:		88.37 %
Epoch 955 of 2000 took 0.035s
  training loss:		0.229231
  validation loss:		0.380285
  validation accuracy:		88.37 %
Epoch 956 of 2000 took 0.035s
  training loss:		0.230772
  validation loss:		0.422609
  validation accuracy:		87.50 %
Epoch 957 of 2000 took 0.035s
  training loss:		0.224912
  validation loss:		0.378682
  validation accuracy:		88.70 %
Epoch 958 of 2000 took 0.035s
  training loss:		0.224730
  validation loss:		0.384831
  validation accuracy:		87.93 %
Epoch 959 of 2000 took 0.035s
  training loss:		0.227426
  validation loss:		0.393439
  validation accuracy:		87.61 %
Epoch 960 of 2000 took 0.035s
  training loss:		0.224983
  validation loss:		0.364920
  validation accuracy:		88.91 %
Epoch 961 of 2000 took 0.035s
  training loss:		0.225321
  validation loss:		0.385143
  validation accuracy:		87.72 %
Epoch 962 of 2000 took 0.035s
  training loss:		0.231221
  validation loss:		0.388139
  validation accuracy:		87.93 %
Epoch 963 of 2000 took 0.035s
  training loss:		0.219392
  validation loss:		0.380689
  validation accuracy:		88.59 %
Epoch 964 of 2000 took 0.035s
  training loss:		0.227038
  validation loss:		0.387916
  validation accuracy:		88.70 %
Epoch 965 of 2000 took 0.035s
  training loss:		0.222928
  validation loss:		0.389188
  validation accuracy:		88.15 %
Epoch 966 of 2000 took 0.035s
  training loss:		0.224701
  validation loss:		0.377196
  validation accuracy:		88.37 %
Epoch 967 of 2000 took 0.035s
  training loss:		0.221383
  validation loss:		0.394026
  validation accuracy:		88.70 %
Epoch 968 of 2000 took 0.035s
  training loss:		0.228393
  validation loss:		0.383025
  validation accuracy:		88.04 %
Epoch 969 of 2000 took 0.035s
  training loss:		0.223347
  validation loss:		0.390209
  validation accuracy:		88.26 %
Epoch 970 of 2000 took 0.035s
  training loss:		0.221509
  validation loss:		0.388946
  validation accuracy:		88.04 %
Epoch 971 of 2000 took 0.035s
  training loss:		0.218784
  validation loss:		0.391047
  validation accuracy:		87.83 %
Epoch 972 of 2000 took 0.035s
  training loss:		0.225598
  validation loss:		0.390225
  validation accuracy:		87.83 %
Epoch 973 of 2000 took 0.035s
  training loss:		0.224168
  validation loss:		0.374355
  validation accuracy:		88.91 %
Epoch 974 of 2000 took 0.035s
  training loss:		0.225787
  validation loss:		0.378506
  validation accuracy:		88.48 %
Epoch 975 of 2000 took 0.035s
  training loss:		0.223948
  validation loss:		0.394308
  validation accuracy:		87.72 %
Epoch 976 of 2000 took 0.035s
  training loss:		0.222523
  validation loss:		0.396870
  validation accuracy:		87.93 %
Epoch 977 of 2000 took 0.035s
  training loss:		0.219390
  validation loss:		0.380511
  validation accuracy:		88.80 %
Epoch 978 of 2000 took 0.035s
  training loss:		0.224039
  validation loss:		0.385743
  validation accuracy:		88.15 %
Epoch 979 of 2000 took 0.035s
  training loss:		0.220336
  validation loss:		0.381729
  validation accuracy:		88.91 %
Epoch 980 of 2000 took 0.035s
  training loss:		0.220014
  validation loss:		0.385535
  validation accuracy:		88.15 %
Epoch 981 of 2000 took 0.035s
  training loss:		0.221290
  validation loss:		0.391543
  validation accuracy:		88.15 %
Epoch 982 of 2000 took 0.035s
  training loss:		0.220118
  validation loss:		0.374033
  validation accuracy:		88.59 %
Epoch 983 of 2000 took 0.035s
  training loss:		0.218196
  validation loss:		0.383779
  validation accuracy:		88.48 %
Epoch 984 of 2000 took 0.035s
  training loss:		0.213704
  validation loss:		0.389511
  validation accuracy:		88.15 %
Epoch 985 of 2000 took 0.035s
  training loss:		0.221148
  validation loss:		0.381329
  validation accuracy:		88.37 %
Epoch 986 of 2000 took 0.035s
  training loss:		0.220223
  validation loss:		0.370116
  validation accuracy:		88.70 %
Epoch 987 of 2000 took 0.035s
  training loss:		0.215704
  validation loss:		0.396194
  validation accuracy:		88.26 %
Epoch 988 of 2000 took 0.035s
  training loss:		0.225781
  validation loss:		0.373591
  validation accuracy:		88.59 %
Epoch 989 of 2000 took 0.035s
  training loss:		0.225527
  validation loss:		0.388732
  validation accuracy:		88.70 %
Epoch 990 of 2000 took 0.035s
  training loss:		0.215567
  validation loss:		0.383495
  validation accuracy:		88.37 %
Epoch 991 of 2000 took 0.035s
  training loss:		0.222102
  validation loss:		0.391430
  validation accuracy:		87.72 %
Epoch 992 of 2000 took 0.035s
  training loss:		0.219405
  validation loss:		0.380565
  validation accuracy:		87.93 %
Epoch 993 of 2000 took 0.035s
  training loss:		0.221000
  validation loss:		0.386324
  validation accuracy:		88.26 %
Epoch 994 of 2000 took 0.035s
  training loss:		0.219246
  validation loss:		0.379803
  validation accuracy:		88.15 %
Epoch 995 of 2000 took 0.035s
  training loss:		0.216906
  validation loss:		0.381427
  validation accuracy:		88.15 %
Epoch 996 of 2000 took 0.035s
  training loss:		0.218634
  validation loss:		0.391128
  validation accuracy:		88.37 %
Epoch 997 of 2000 took 0.035s
  training loss:		0.213103
  validation loss:		0.379671
  validation accuracy:		88.91 %
Epoch 998 of 2000 took 0.035s
  training loss:		0.220406
  validation loss:		0.382831
  validation accuracy:		88.15 %
Epoch 999 of 2000 took 0.035s
  training loss:		0.212666
  validation loss:		0.382919
  validation accuracy:		88.70 %
Epoch 1000 of 2000 took 0.035s
  training loss:		0.215665
  validation loss:		0.372567
  validation accuracy:		88.48 %
Epoch 1001 of 2000 took 0.035s
  training loss:		0.212301
  validation loss:		0.369852
  validation accuracy:		88.91 %
Epoch 1002 of 2000 took 0.035s
  training loss:		0.211807
  validation loss:		0.393605
  validation accuracy:		88.26 %
Epoch 1003 of 2000 took 0.035s
  training loss:		0.215519
  validation loss:		0.410916
  validation accuracy:		87.93 %
Epoch 1004 of 2000 took 0.035s
  training loss:		0.217646
  validation loss:		0.376988
  validation accuracy:		88.48 %
Epoch 1005 of 2000 took 0.035s
  training loss:		0.220212
  validation loss:		0.371234
  validation accuracy:		89.24 %
Epoch 1006 of 2000 took 0.035s
  training loss:		0.213398
  validation loss:		0.390912
  validation accuracy:		88.70 %
Epoch 1007 of 2000 took 0.035s
  training loss:		0.211898
  validation loss:		0.388107
  validation accuracy:		88.70 %
Epoch 1008 of 2000 took 0.035s
  training loss:		0.222296
  validation loss:		0.380576
  validation accuracy:		88.04 %
Epoch 1009 of 2000 took 0.035s
  training loss:		0.213399
  validation loss:		0.397165
  validation accuracy:		87.72 %
Epoch 1010 of 2000 took 0.035s
  training loss:		0.220902
  validation loss:		0.366442
  validation accuracy:		89.02 %
Epoch 1011 of 2000 took 0.035s
  training loss:		0.219345
  validation loss:		0.404502
  validation accuracy:		88.26 %
Epoch 1012 of 2000 took 0.035s
  training loss:		0.214833
  validation loss:		0.378773
  validation accuracy:		88.59 %
Epoch 1013 of 2000 took 0.035s
  training loss:		0.209129
  validation loss:		0.391903
  validation accuracy:		88.59 %
Epoch 1014 of 2000 took 0.035s
  training loss:		0.218512
  validation loss:		0.384139
  validation accuracy:		88.48 %
Epoch 1015 of 2000 took 0.035s
  training loss:		0.214164
  validation loss:		0.386483
  validation accuracy:		88.26 %
Epoch 1016 of 2000 took 0.035s
  training loss:		0.213550
  validation loss:		0.393725
  validation accuracy:		87.61 %
Epoch 1017 of 2000 took 0.035s
  training loss:		0.217066
  validation loss:		0.397360
  validation accuracy:		87.72 %
Epoch 1018 of 2000 took 0.035s
  training loss:		0.207175
  validation loss:		0.374054
  validation accuracy:		88.59 %
Epoch 1019 of 2000 took 0.035s
  training loss:		0.213417
  validation loss:		0.377889
  validation accuracy:		88.59 %
Epoch 1020 of 2000 took 0.035s
  training loss:		0.211226
  validation loss:		0.393649
  validation accuracy:		87.72 %
Epoch 1021 of 2000 took 0.035s
  training loss:		0.214297
  validation loss:		0.373569
  validation accuracy:		88.37 %
Epoch 1022 of 2000 took 0.035s
  training loss:		0.214391
  validation loss:		0.389731
  validation accuracy:		88.04 %
Epoch 1023 of 2000 took 0.035s
  training loss:		0.205905
  validation loss:		0.382956
  validation accuracy:		88.04 %
Epoch 1024 of 2000 took 0.035s
  training loss:		0.214901
  validation loss:		0.395502
  validation accuracy:		87.83 %
Epoch 1025 of 2000 took 0.035s
  training loss:		0.211957
  validation loss:		0.378414
  validation accuracy:		88.48 %
Epoch 1026 of 2000 took 0.035s
  training loss:		0.208991
  validation loss:		0.392834
  validation accuracy:		88.04 %
Epoch 1027 of 2000 took 0.035s
  training loss:		0.211547
  validation loss:		0.370321
  validation accuracy:		89.02 %
Epoch 1028 of 2000 took 0.035s
  training loss:		0.214811
  validation loss:		0.386137
  validation accuracy:		89.02 %
Epoch 1029 of 2000 took 0.035s
  training loss:		0.208098
  validation loss:		0.380922
  validation accuracy:		88.04 %
Epoch 1030 of 2000 took 0.035s
  training loss:		0.207300
  validation loss:		0.377895
  validation accuracy:		88.91 %
Epoch 1031 of 2000 took 0.035s
  training loss:		0.216415
  validation loss:		0.389570
  validation accuracy:		88.59 %
Epoch 1032 of 2000 took 0.035s
  training loss:		0.210994
  validation loss:		0.395459
  validation accuracy:		88.04 %
Epoch 1033 of 2000 took 0.035s
  training loss:		0.208172
  validation loss:		0.387176
  validation accuracy:		88.37 %
Epoch 1034 of 2000 took 0.035s
  training loss:		0.211311
  validation loss:		0.380760
  validation accuracy:		88.15 %
Epoch 1035 of 2000 took 0.035s
  training loss:		0.213568
  validation loss:		0.389356
  validation accuracy:		88.04 %
Epoch 1036 of 2000 took 0.035s
  training loss:		0.210009
  validation loss:		0.393589
  validation accuracy:		87.61 %
Epoch 1037 of 2000 took 0.035s
  training loss:		0.209306
  validation loss:		0.375537
  validation accuracy:		88.37 %
Epoch 1038 of 2000 took 0.035s
  training loss:		0.212614
  validation loss:		0.395966
  validation accuracy:		88.04 %
Epoch 1039 of 2000 took 0.035s
  training loss:		0.209702
  validation loss:		0.385402
  validation accuracy:		88.59 %
Epoch 1040 of 2000 took 0.035s
  training loss:		0.208601
  validation loss:		0.391214
  validation accuracy:		87.93 %
Epoch 1041 of 2000 took 0.035s
  training loss:		0.210317
  validation loss:		0.378467
  validation accuracy:		88.48 %
Epoch 1042 of 2000 took 0.035s
  training loss:		0.205887
  validation loss:		0.383797
  validation accuracy:		88.48 %
Epoch 1043 of 2000 took 0.035s
  training loss:		0.210782
  validation loss:		0.370493
  validation accuracy:		89.13 %
Epoch 1044 of 2000 took 0.035s
  training loss:		0.208684
  validation loss:		0.389219
  validation accuracy:		87.83 %
Epoch 1045 of 2000 took 0.035s
  training loss:		0.207719
  validation loss:		0.374954
  validation accuracy:		88.48 %
Epoch 1046 of 2000 took 0.035s
  training loss:		0.211802
  validation loss:		0.396818
  validation accuracy:		88.59 %
Epoch 1047 of 2000 took 0.035s
  training loss:		0.209292
  validation loss:		0.389578
  validation accuracy:		87.83 %
Epoch 1048 of 2000 took 0.035s
  training loss:		0.213868
  validation loss:		0.383268
  validation accuracy:		88.70 %
Epoch 1049 of 2000 took 0.035s
  training loss:		0.202923
  validation loss:		0.366572
  validation accuracy:		88.80 %
Epoch 1050 of 2000 took 0.035s
  training loss:		0.210997
  validation loss:		0.386205
  validation accuracy:		88.26 %
Epoch 1051 of 2000 took 0.035s
  training loss:		0.208517
  validation loss:		0.376552
  validation accuracy:		89.02 %
Epoch 1052 of 2000 took 0.035s
  training loss:		0.211846
  validation loss:		0.384895
  validation accuracy:		88.48 %
Epoch 1053 of 2000 took 0.035s
  training loss:		0.207882
  validation loss:		0.405787
  validation accuracy:		87.61 %
Epoch 1054 of 2000 took 0.035s
  training loss:		0.210027
  validation loss:		0.380471
  validation accuracy:		88.59 %
Epoch 1055 of 2000 took 0.035s
  training loss:		0.206990
  validation loss:		0.381193
  validation accuracy:		87.93 %
Epoch 1056 of 2000 took 0.035s
  training loss:		0.212343
  validation loss:		0.393098
  validation accuracy:		87.93 %
Epoch 1057 of 2000 took 0.035s
  training loss:		0.200125
  validation loss:		0.388768
  validation accuracy:		87.83 %
Epoch 1058 of 2000 took 0.035s
  training loss:		0.207192
  validation loss:		0.387914
  validation accuracy:		88.04 %
Epoch 1059 of 2000 took 0.035s
  training loss:		0.209620
  validation loss:		0.388728
  validation accuracy:		87.72 %
Epoch 1060 of 2000 took 0.035s
  training loss:		0.207119
  validation loss:		0.370100
  validation accuracy:		88.80 %
Epoch 1061 of 2000 took 0.035s
  training loss:		0.210246
  validation loss:		0.379852
  validation accuracy:		88.70 %
Epoch 1062 of 2000 took 0.035s
  training loss:		0.205547
  validation loss:		0.376937
  validation accuracy:		89.02 %
Epoch 1063 of 2000 took 0.035s
  training loss:		0.205181
  validation loss:		0.390812
  validation accuracy:		88.15 %
Epoch 1064 of 2000 took 0.035s
  training loss:		0.208658
  validation loss:		0.390269
  validation accuracy:		87.83 %
Epoch 1065 of 2000 took 0.035s
  training loss:		0.204359
  validation loss:		0.397369
  validation accuracy:		87.28 %
Epoch 1066 of 2000 took 0.035s
  training loss:		0.203515
  validation loss:		0.370217
  validation accuracy:		88.70 %
Epoch 1067 of 2000 took 0.035s
  training loss:		0.208296
  validation loss:		0.378393
  validation accuracy:		88.15 %
Epoch 1068 of 2000 took 0.035s
  training loss:		0.197738
  validation loss:		0.390125
  validation accuracy:		87.93 %
Epoch 1069 of 2000 took 0.035s
  training loss:		0.204094
  validation loss:		0.387255
  validation accuracy:		88.80 %
Epoch 1070 of 2000 took 0.035s
  training loss:		0.206397
  validation loss:		0.393441
  validation accuracy:		88.70 %
Epoch 1071 of 2000 took 0.035s
  training loss:		0.198950
  validation loss:		0.379460
  validation accuracy:		87.83 %
Epoch 1072 of 2000 took 0.035s
  training loss:		0.207276
  validation loss:		0.394363
  validation accuracy:		88.15 %
Epoch 1073 of 2000 took 0.035s
  training loss:		0.204054
  validation loss:		0.382057
  validation accuracy:		88.26 %
Epoch 1074 of 2000 took 0.035s
  training loss:		0.199130
  validation loss:		0.394491
  validation accuracy:		88.37 %
Epoch 1075 of 2000 took 0.035s
  training loss:		0.209529
  validation loss:		0.378189
  validation accuracy:		88.26 %
Epoch 1076 of 2000 took 0.035s
  training loss:		0.204635
  validation loss:		0.374346
  validation accuracy:		88.91 %
Epoch 1077 of 2000 took 0.035s
  training loss:		0.207162
  validation loss:		0.382555
  validation accuracy:		87.83 %
Epoch 1078 of 2000 took 0.035s
  training loss:		0.209170
  validation loss:		0.378619
  validation accuracy:		88.70 %
Epoch 1079 of 2000 took 0.035s
  training loss:		0.207601
  validation loss:		0.371269
  validation accuracy:		88.80 %
Epoch 1080 of 2000 took 0.035s
  training loss:		0.206156
  validation loss:		0.383278
  validation accuracy:		88.80 %
Epoch 1081 of 2000 took 0.035s
  training loss:		0.203206
  validation loss:		0.400311
  validation accuracy:		88.15 %
Epoch 1082 of 2000 took 0.035s
  training loss:		0.200460
  validation loss:		0.378998
  validation accuracy:		88.80 %
Epoch 1083 of 2000 took 0.035s
  training loss:		0.204798
  validation loss:		0.379155
  validation accuracy:		88.04 %
Epoch 1084 of 2000 took 0.035s
  training loss:		0.199806
  validation loss:		0.388642
  validation accuracy:		88.26 %
Epoch 1085 of 2000 took 0.035s
  training loss:		0.204318
  validation loss:		0.402439
  validation accuracy:		87.72 %
Epoch 1086 of 2000 took 0.035s
  training loss:		0.197189
  validation loss:		0.397092
  validation accuracy:		88.15 %
Epoch 1087 of 2000 took 0.035s
  training loss:		0.203920
  validation loss:		0.381982
  validation accuracy:		88.80 %
Epoch 1088 of 2000 took 0.035s
  training loss:		0.203677
  validation loss:		0.387272
  validation accuracy:		88.37 %
Epoch 1089 of 2000 took 0.035s
  training loss:		0.200207
  validation loss:		0.390100
  validation accuracy:		87.93 %
Epoch 1090 of 2000 took 0.035s
  training loss:		0.201570
  validation loss:		0.392965
  validation accuracy:		87.61 %
Epoch 1091 of 2000 took 0.035s
  training loss:		0.200843
  validation loss:		0.389217
  validation accuracy:		88.37 %
Epoch 1092 of 2000 took 0.035s
  training loss:		0.203628
  validation loss:		0.388560
  validation accuracy:		87.93 %
Epoch 1093 of 2000 took 0.035s
  training loss:		0.207153
  validation loss:		0.368267
  validation accuracy:		89.13 %
Epoch 1094 of 2000 took 0.035s
  training loss:		0.199616
  validation loss:		0.372806
  validation accuracy:		88.70 %
Epoch 1095 of 2000 took 0.035s
  training loss:		0.203668
  validation loss:		0.394687
  validation accuracy:		88.59 %
Epoch 1096 of 2000 took 0.035s
  training loss:		0.200786
  validation loss:		0.381617
  validation accuracy:		88.15 %
Epoch 1097 of 2000 took 0.035s
  training loss:		0.203890
  validation loss:		0.402775
  validation accuracy:		88.04 %
Epoch 1098 of 2000 took 0.035s
  training loss:		0.206689
  validation loss:		0.382064
  validation accuracy:		88.59 %
Epoch 1099 of 2000 took 0.035s
  training loss:		0.196708
  validation loss:		0.381867
  validation accuracy:		87.83 %
Epoch 1100 of 2000 took 0.035s
  training loss:		0.196810
  validation loss:		0.380700
  validation accuracy:		88.91 %
Epoch 1101 of 2000 took 0.035s
  training loss:		0.205207
  validation loss:		0.364404
  validation accuracy:		89.24 %
Epoch 1102 of 2000 took 0.035s
  training loss:		0.198345
  validation loss:		0.396868
  validation accuracy:		87.50 %
Epoch 1103 of 2000 took 0.035s
  training loss:		0.193062
  validation loss:		0.391104
  validation accuracy:		87.83 %
Epoch 1104 of 2000 took 0.035s
  training loss:		0.206985
  validation loss:		0.380331
  validation accuracy:		88.70 %
Epoch 1105 of 2000 took 0.035s
  training loss:		0.197984
  validation loss:		0.385913
  validation accuracy:		87.72 %
Epoch 1106 of 2000 took 0.035s
  training loss:		0.199571
  validation loss:		0.404307
  validation accuracy:		87.39 %
Epoch 1107 of 2000 took 0.035s
  training loss:		0.200724
  validation loss:		0.372511
  validation accuracy:		89.13 %
Epoch 1108 of 2000 took 0.035s
  training loss:		0.202257
  validation loss:		0.388154
  validation accuracy:		88.04 %
Epoch 1109 of 2000 took 0.035s
  training loss:		0.205076
  validation loss:		0.384685
  validation accuracy:		88.91 %
Epoch 1110 of 2000 took 0.035s
  training loss:		0.200384
  validation loss:		0.379796
  validation accuracy:		88.48 %
Epoch 1111 of 2000 took 0.035s
  training loss:		0.196522
  validation loss:		0.383169
  validation accuracy:		87.93 %
Epoch 1112 of 2000 took 0.035s
  training loss:		0.196325
  validation loss:		0.383019
  validation accuracy:		88.48 %
Epoch 1113 of 2000 took 0.035s
  training loss:		0.196367
  validation loss:		0.380392
  validation accuracy:		89.02 %
Epoch 1114 of 2000 took 0.035s
  training loss:		0.198080
  validation loss:		0.378431
  validation accuracy:		88.59 %
Epoch 1115 of 2000 took 0.035s
  training loss:		0.196447
  validation loss:		0.388057
  validation accuracy:		89.24 %
Epoch 1116 of 2000 took 0.035s
  training loss:		0.202183
  validation loss:		0.375876
  validation accuracy:		88.80 %
Epoch 1117 of 2000 took 0.035s
  training loss:		0.192214
  validation loss:		0.379030
  validation accuracy:		88.70 %
Epoch 1118 of 2000 took 0.035s
  training loss:		0.191165
  validation loss:		0.402975
  validation accuracy:		87.39 %
Epoch 1119 of 2000 took 0.035s
  training loss:		0.199246
  validation loss:		0.383696
  validation accuracy:		88.26 %
Epoch 1120 of 2000 took 0.035s
  training loss:		0.192287
  validation loss:		0.398541
  validation accuracy:		88.15 %
Epoch 1121 of 2000 took 0.035s
  training loss:		0.196206
  validation loss:		0.368983
  validation accuracy:		88.80 %
Epoch 1122 of 2000 took 0.035s
  training loss:		0.199557
  validation loss:		0.392787
  validation accuracy:		87.93 %
Epoch 1123 of 2000 took 0.035s
  training loss:		0.199563
  validation loss:		0.377384
  validation accuracy:		88.80 %
Epoch 1124 of 2000 took 0.035s
  training loss:		0.195455
  validation loss:		0.408945
  validation accuracy:		88.04 %
Epoch 1125 of 2000 took 0.035s
  training loss:		0.200987
  validation loss:		0.381403
  validation accuracy:		88.26 %
Epoch 1126 of 2000 took 0.035s
  training loss:		0.194815
  validation loss:		0.393503
  validation accuracy:		87.39 %
Epoch 1127 of 2000 took 0.035s
  training loss:		0.198017
  validation loss:		0.380572
  validation accuracy:		88.80 %
Epoch 1128 of 2000 took 0.035s
  training loss:		0.196715
  validation loss:		0.392165
  validation accuracy:		88.48 %
Epoch 1129 of 2000 took 0.035s
  training loss:		0.187493
  validation loss:		0.391914
  validation accuracy:		87.93 %
Epoch 1130 of 2000 took 0.035s
  training loss:		0.201643
  validation loss:		0.379068
  validation accuracy:		88.80 %
Epoch 1131 of 2000 took 0.035s
  training loss:		0.190291
  validation loss:		0.369892
  validation accuracy:		89.13 %
Epoch 1132 of 2000 took 0.035s
  training loss:		0.190816
  validation loss:		0.423034
  validation accuracy:		87.93 %
Epoch 1133 of 2000 took 0.035s
  training loss:		0.195755
  validation loss:		0.381377
  validation accuracy:		88.70 %
Epoch 1134 of 2000 took 0.035s
  training loss:		0.197647
  validation loss:		0.385844
  validation accuracy:		88.26 %
Epoch 1135 of 2000 took 0.035s
  training loss:		0.198079
  validation loss:		0.379600
  validation accuracy:		88.48 %
Epoch 1136 of 2000 took 0.035s
  training loss:		0.195805
  validation loss:		0.382420
  validation accuracy:		88.91 %
Epoch 1137 of 2000 took 0.035s
  training loss:		0.187533
  validation loss:		0.373734
  validation accuracy:		88.91 %
Epoch 1138 of 2000 took 0.035s
  training loss:		0.195830
  validation loss:		0.379275
  validation accuracy:		88.91 %
Epoch 1139 of 2000 took 0.035s
  training loss:		0.193280
  validation loss:		0.374267
  validation accuracy:		88.70 %
Epoch 1140 of 2000 took 0.035s
  training loss:		0.195524
  validation loss:		0.396768
  validation accuracy:		88.48 %
Epoch 1141 of 2000 took 0.035s
  training loss:		0.190930
  validation loss:		0.404530
  validation accuracy:		87.17 %
Epoch 1142 of 2000 took 0.035s
  training loss:		0.196233
  validation loss:		0.392560
  validation accuracy:		88.59 %
Epoch 1143 of 2000 took 0.035s
  training loss:		0.193286
  validation loss:		0.395400
  validation accuracy:		87.39 %
Epoch 1144 of 2000 took 0.035s
  training loss:		0.189751
  validation loss:		0.384825
  validation accuracy:		88.37 %
Epoch 1145 of 2000 took 0.035s
  training loss:		0.190290
  validation loss:		0.375250
  validation accuracy:		89.13 %
Epoch 1146 of 2000 took 0.035s
  training loss:		0.193389
  validation loss:		0.385655
  validation accuracy:		88.48 %
Epoch 1147 of 2000 took 0.035s
  training loss:		0.192018
  validation loss:		0.383982
  validation accuracy:		88.48 %
Epoch 1148 of 2000 took 0.035s
  training loss:		0.193086
  validation loss:		0.389707
  validation accuracy:		88.70 %
Epoch 1149 of 2000 took 0.035s
  training loss:		0.192460
  validation loss:		0.384919
  validation accuracy:		88.15 %
Epoch 1150 of 2000 took 0.035s
  training loss:		0.188091
  validation loss:		0.370114
  validation accuracy:		89.13 %
Epoch 1151 of 2000 took 0.035s
  training loss:		0.196717
  validation loss:		0.395013
  validation accuracy:		88.15 %
Epoch 1152 of 2000 took 0.035s
  training loss:		0.192281
  validation loss:		0.375662
  validation accuracy:		88.91 %
Epoch 1153 of 2000 took 0.035s
  training loss:		0.190328
  validation loss:		0.380219
  validation accuracy:		89.13 %
Epoch 1154 of 2000 took 0.035s
  training loss:		0.191370
  validation loss:		0.384618
  validation accuracy:		88.15 %
Epoch 1155 of 2000 took 0.035s
  training loss:		0.188936
  validation loss:		0.383916
  validation accuracy:		88.80 %
Epoch 1156 of 2000 took 0.035s
  training loss:		0.194535
  validation loss:		0.377873
  validation accuracy:		89.02 %
Epoch 1157 of 2000 took 0.035s
  training loss:		0.189430
  validation loss:		0.379646
  validation accuracy:		89.13 %
Epoch 1158 of 2000 took 0.035s
  training loss:		0.190055
  validation loss:		0.395341
  validation accuracy:		88.48 %
Epoch 1159 of 2000 took 0.035s
  training loss:		0.192073
  validation loss:		0.386532
  validation accuracy:		88.59 %
Epoch 1160 of 2000 took 0.035s
  training loss:		0.186789
  validation loss:		0.395541
  validation accuracy:		87.83 %
Epoch 1161 of 2000 took 0.035s
  training loss:		0.191310
  validation loss:		0.385631
  validation accuracy:		88.91 %
Epoch 1162 of 2000 took 0.035s
  training loss:		0.190200
  validation loss:		0.388207
  validation accuracy:		88.59 %
Epoch 1163 of 2000 took 0.035s
  training loss:		0.185666
  validation loss:		0.381483
  validation accuracy:		89.02 %
Epoch 1164 of 2000 took 0.035s
  training loss:		0.191401
  validation loss:		0.381361
  validation accuracy:		89.02 %
Epoch 1165 of 2000 took 0.035s
  training loss:		0.194018
  validation loss:		0.378654
  validation accuracy:		88.70 %
Epoch 1166 of 2000 took 0.035s
  training loss:		0.187230
  validation loss:		0.389674
  validation accuracy:		87.93 %
Epoch 1167 of 2000 took 0.035s
  training loss:		0.191125
  validation loss:		0.394955
  validation accuracy:		88.48 %
Epoch 1168 of 2000 took 0.035s
  training loss:		0.188837
  validation loss:		0.383532
  validation accuracy:		88.26 %
Epoch 1169 of 2000 took 0.035s
  training loss:		0.190330
  validation loss:		0.386736
  validation accuracy:		87.93 %
Epoch 1170 of 2000 took 0.035s
  training loss:		0.188039
  validation loss:		0.375885
  validation accuracy:		88.80 %
Epoch 1171 of 2000 took 0.035s
  training loss:		0.191535
  validation loss:		0.383860
  validation accuracy:		88.91 %
Epoch 1172 of 2000 took 0.035s
  training loss:		0.194734
  validation loss:		0.379742
  validation accuracy:		89.24 %
Epoch 1173 of 2000 took 0.035s
  training loss:		0.191546
  validation loss:		0.392441
  validation accuracy:		88.26 %
Epoch 1174 of 2000 took 0.035s
  training loss:		0.188248
  validation loss:		0.390714
  validation accuracy:		88.59 %
Epoch 1175 of 2000 took 0.035s
  training loss:		0.193830
  validation loss:		0.396084
  validation accuracy:		88.37 %
Epoch 1176 of 2000 took 0.035s
  training loss:		0.189855
  validation loss:		0.398434
  validation accuracy:		87.72 %
Epoch 1177 of 2000 took 0.035s
  training loss:		0.191596
  validation loss:		0.404505
  validation accuracy:		87.93 %
Epoch 1178 of 2000 took 0.035s
  training loss:		0.189392
  validation loss:		0.410482
  validation accuracy:		87.61 %
Epoch 1179 of 2000 took 0.035s
  training loss:		0.193435
  validation loss:		0.388368
  validation accuracy:		88.37 %
Epoch 1180 of 2000 took 0.035s
  training loss:		0.186981
  validation loss:		0.387865
  validation accuracy:		88.37 %
Epoch 1181 of 2000 took 0.035s
  training loss:		0.192739
  validation loss:		0.381014
  validation accuracy:		89.24 %
Epoch 1182 of 2000 took 0.035s
  training loss:		0.186786
  validation loss:		0.384793
  validation accuracy:		89.02 %
Epoch 1183 of 2000 took 0.035s
  training loss:		0.183053
  validation loss:		0.379086
  validation accuracy:		89.24 %
Epoch 1184 of 2000 took 0.035s
  training loss:		0.187682
  validation loss:		0.391048
  validation accuracy:		88.59 %
Epoch 1185 of 2000 took 0.035s
  training loss:		0.188890
  validation loss:		0.381467
  validation accuracy:		89.02 %
Epoch 1186 of 2000 took 0.035s
  training loss:		0.194481
  validation loss:		0.392346
  validation accuracy:		88.80 %
Epoch 1187 of 2000 took 0.035s
  training loss:		0.183877
  validation loss:		0.390948
  validation accuracy:		88.37 %
Epoch 1188 of 2000 took 0.035s
  training loss:		0.181804
  validation loss:		0.383683
  validation accuracy:		88.70 %
Epoch 1189 of 2000 took 0.035s
  training loss:		0.189999
  validation loss:		0.408907
  validation accuracy:		88.04 %
Epoch 1190 of 2000 took 0.035s
  training loss:		0.191359
  validation loss:		0.389308
  validation accuracy:		88.26 %
Epoch 1191 of 2000 took 0.035s
  training loss:		0.183639
  validation loss:		0.399142
  validation accuracy:		88.37 %
Epoch 1192 of 2000 took 0.035s
  training loss:		0.185550
  validation loss:		0.388018
  validation accuracy:		88.59 %
Epoch 1193 of 2000 took 0.035s
  training loss:		0.187420
  validation loss:		0.392454
  validation accuracy:		88.48 %
Epoch 1194 of 2000 took 0.035s
  training loss:		0.185913
  validation loss:		0.380950
  validation accuracy:		89.02 %
Epoch 1195 of 2000 took 0.035s
  training loss:		0.187237
  validation loss:		0.396754
  validation accuracy:		88.70 %
Epoch 1196 of 2000 took 0.035s
  training loss:		0.186558
  validation loss:		0.418070
  validation accuracy:		87.28 %
Epoch 1197 of 2000 took 0.035s
  training loss:		0.187580
  validation loss:		0.391090
  validation accuracy:		88.48 %
Epoch 1198 of 2000 took 0.035s
  training loss:		0.183510
  validation loss:		0.390644
  validation accuracy:		88.70 %
Epoch 1199 of 2000 took 0.035s
  training loss:		0.188854
  validation loss:		0.398516
  validation accuracy:		88.70 %
Epoch 1200 of 2000 took 0.035s
  training loss:		0.187591
  validation loss:		0.390371
  validation accuracy:		88.26 %
Epoch 1201 of 2000 took 0.035s
  training loss:		0.183909
  validation loss:		0.384154
  validation accuracy:		88.80 %
Epoch 1202 of 2000 took 0.035s
  training loss:		0.191646
  validation loss:		0.386500
  validation accuracy:		88.59 %
Epoch 1203 of 2000 took 0.035s
  training loss:		0.184530
  validation loss:		0.406853
  validation accuracy:		88.04 %
Epoch 1204 of 2000 took 0.035s
  training loss:		0.186441
  validation loss:		0.384732
  validation accuracy:		88.80 %
Epoch 1205 of 2000 took 0.035s
  training loss:		0.189161
  validation loss:		0.395674
  validation accuracy:		88.48 %
Epoch 1206 of 2000 took 0.035s
  training loss:		0.185575
  validation loss:		0.376748
  validation accuracy:		88.91 %
Epoch 1207 of 2000 took 0.035s
  training loss:		0.186722
  validation loss:		0.374734
  validation accuracy:		89.67 %
Epoch 1208 of 2000 took 0.035s
  training loss:		0.183014
  validation loss:		0.395670
  validation accuracy:		88.26 %
Epoch 1209 of 2000 took 0.035s
  training loss:		0.184597
  validation loss:		0.383963
  validation accuracy:		89.13 %
Epoch 1210 of 2000 took 0.035s
  training loss:		0.192398
  validation loss:		0.387444
  validation accuracy:		88.91 %
Epoch 1211 of 2000 took 0.035s
  training loss:		0.184776
  validation loss:		0.372726
  validation accuracy:		89.35 %
Epoch 1212 of 2000 took 0.035s
  training loss:		0.179425
  validation loss:		0.383302
  validation accuracy:		88.59 %
Epoch 1213 of 2000 took 0.035s
  training loss:		0.181949
  validation loss:		0.397510
  validation accuracy:		88.80 %
Epoch 1214 of 2000 took 0.035s
  training loss:		0.189678
  validation loss:		0.394148
  validation accuracy:		87.83 %
Epoch 1215 of 2000 took 0.035s
  training loss:		0.181491
  validation loss:		0.381494
  validation accuracy:		89.67 %
Epoch 1216 of 2000 took 0.035s
  training loss:		0.181759
  validation loss:		0.375882
  validation accuracy:		89.24 %
Epoch 1217 of 2000 took 0.035s
  training loss:		0.183349
  validation loss:		0.382722
  validation accuracy:		89.13 %
Epoch 1218 of 2000 took 0.035s
  training loss:		0.186379
  validation loss:		0.388527
  validation accuracy:		87.93 %
Epoch 1219 of 2000 took 0.035s
  training loss:		0.188137
  validation loss:		0.411429
  validation accuracy:		87.93 %
Epoch 1220 of 2000 took 0.035s
  training loss:		0.189366
  validation loss:		0.388656
  validation accuracy:		89.13 %
Epoch 1221 of 2000 took 0.035s
  training loss:		0.181189
  validation loss:		0.402560
  validation accuracy:		87.83 %
Epoch 1222 of 2000 took 0.035s
  training loss:		0.176157
  validation loss:		0.381799
  validation accuracy:		89.02 %
Epoch 1223 of 2000 took 0.035s
  training loss:		0.180283
  validation loss:		0.391871
  validation accuracy:		88.91 %
Epoch 1224 of 2000 took 0.035s
  training loss:		0.186604
  validation loss:		0.397738
  validation accuracy:		88.80 %
Epoch 1225 of 2000 took 0.035s
  training loss:		0.187160
  validation loss:		0.388533
  validation accuracy:		89.02 %
Epoch 1226 of 2000 took 0.035s
  training loss:		0.183738
  validation loss:		0.386835
  validation accuracy:		89.13 %
Epoch 1227 of 2000 took 0.035s
  training loss:		0.185320
  validation loss:		0.388766
  validation accuracy:		88.80 %
Epoch 1228 of 2000 took 0.035s
  training loss:		0.179933
  validation loss:		0.390707
  validation accuracy:		88.48 %
Epoch 1229 of 2000 took 0.035s
  training loss:		0.174099
  validation loss:		0.392823
  validation accuracy:		88.70 %
Epoch 1230 of 2000 took 0.035s
  training loss:		0.180941
  validation loss:		0.400366
  validation accuracy:		87.93 %
Epoch 1231 of 2000 took 0.035s
  training loss:		0.187200
  validation loss:		0.386399
  validation accuracy:		88.80 %
Epoch 1232 of 2000 took 0.035s
  training loss:		0.187477
  validation loss:		0.392879
  validation accuracy:		89.13 %
Epoch 1233 of 2000 took 0.035s
  training loss:		0.185844
  validation loss:		0.401794
  validation accuracy:		88.59 %
Epoch 1234 of 2000 took 0.035s
  training loss:		0.185068
  validation loss:		0.396242
  validation accuracy:		89.02 %
Epoch 1235 of 2000 took 0.035s
  training loss:		0.179608
  validation loss:		0.394539
  validation accuracy:		88.70 %
Epoch 1236 of 2000 took 0.035s
  training loss:		0.184443
  validation loss:		0.399388
  validation accuracy:		88.80 %
Epoch 1237 of 2000 took 0.035s
  training loss:		0.178157
  validation loss:		0.409741
  validation accuracy:		87.93 %
Epoch 1238 of 2000 took 0.035s
  training loss:		0.181602
  validation loss:		0.386738
  validation accuracy:		88.91 %
Epoch 1239 of 2000 took 0.035s
  training loss:		0.181556
  validation loss:		0.392615
  validation accuracy:		89.24 %
Epoch 1240 of 2000 took 0.035s
  training loss:		0.177853
  validation loss:		0.395503
  validation accuracy:		89.13 %
Epoch 1241 of 2000 took 0.035s
  training loss:		0.184204
  validation loss:		0.383537
  validation accuracy:		89.24 %
Epoch 1242 of 2000 took 0.035s
  training loss:		0.186081
  validation loss:		0.399385
  validation accuracy:		87.93 %
Epoch 1243 of 2000 took 0.035s
  training loss:		0.185510
  validation loss:		0.413099
  validation accuracy:		88.04 %
Epoch 1244 of 2000 took 0.035s
  training loss:		0.179235
  validation loss:		0.394863
  validation accuracy:		88.70 %
Epoch 1245 of 2000 took 0.035s
  training loss:		0.183059
  validation loss:		0.397589
  validation accuracy:		88.70 %
Epoch 1246 of 2000 took 0.035s
  training loss:		0.172916
  validation loss:		0.408119
  validation accuracy:		88.26 %
Epoch 1247 of 2000 took 0.035s
  training loss:		0.183509
  validation loss:		0.392050
  validation accuracy:		88.70 %
Epoch 1248 of 2000 took 0.035s
  training loss:		0.175072
  validation loss:		0.405033
  validation accuracy:		88.04 %
Epoch 1249 of 2000 took 0.035s
  training loss:		0.184051
  validation loss:		0.397795
  validation accuracy:		89.02 %
Epoch 1250 of 2000 took 0.035s
  training loss:		0.175691
  validation loss:		0.385141
  validation accuracy:		89.46 %
Epoch 1251 of 2000 took 0.035s
  training loss:		0.179396
  validation loss:		0.400725
  validation accuracy:		88.91 %
Epoch 1252 of 2000 took 0.035s
  training loss:		0.180155
  validation loss:		0.395223
  validation accuracy:		88.70 %
Epoch 1253 of 2000 took 0.035s
  training loss:		0.181461
  validation loss:		0.385845
  validation accuracy:		88.80 %
Epoch 1254 of 2000 took 0.035s
  training loss:		0.177679
  validation loss:		0.380715
  validation accuracy:		89.57 %
Epoch 1255 of 2000 took 0.035s
  training loss:		0.182582
  validation loss:		0.388424
  validation accuracy:		88.91 %
Epoch 1256 of 2000 took 0.035s
  training loss:		0.183917
  validation loss:		0.384908
  validation accuracy:		89.02 %
Epoch 1257 of 2000 took 0.035s
  training loss:		0.184235
  validation loss:		0.391010
  validation accuracy:		89.02 %
Epoch 1258 of 2000 took 0.035s
  training loss:		0.173967
  validation loss:		0.388685
  validation accuracy:		88.91 %
Epoch 1259 of 2000 took 0.035s
  training loss:		0.184275
  validation loss:		0.386132
  validation accuracy:		88.37 %
Epoch 1260 of 2000 took 0.035s
  training loss:		0.179294
  validation loss:		0.404811
  validation accuracy:		88.26 %
Epoch 1261 of 2000 took 0.035s
  training loss:		0.185143
  validation loss:		0.407898
  validation accuracy:		88.48 %
Epoch 1262 of 2000 took 0.035s
  training loss:		0.172483
  validation loss:		0.398418
  validation accuracy:		88.70 %
Epoch 1263 of 2000 took 0.035s
  training loss:		0.179448
  validation loss:		0.397518
  validation accuracy:		88.59 %
Epoch 1264 of 2000 took 0.035s
  training loss:		0.182774
  validation loss:		0.390027
  validation accuracy:		89.24 %
Epoch 1265 of 2000 took 0.035s
  training loss:		0.179725
  validation loss:		0.405881
  validation accuracy:		88.59 %
Epoch 1266 of 2000 took 0.035s
  training loss:		0.180396
  validation loss:		0.385556
  validation accuracy:		89.02 %
Epoch 1267 of 2000 took 0.035s
  training loss:		0.182368
  validation loss:		0.394500
  validation accuracy:		88.37 %
Epoch 1268 of 2000 took 0.035s
  training loss:		0.180296
  validation loss:		0.399343
  validation accuracy:		88.48 %
Epoch 1269 of 2000 took 0.035s
  training loss:		0.173525
  validation loss:		0.399118
  validation accuracy:		89.24 %
Epoch 1270 of 2000 took 0.035s
  training loss:		0.176251
  validation loss:		0.390709
  validation accuracy:		89.35 %
Epoch 1271 of 2000 took 0.035s
  training loss:		0.178076
  validation loss:		0.394193
  validation accuracy:		88.59 %
Epoch 1272 of 2000 took 0.035s
  training loss:		0.177989
  validation loss:		0.375689
  validation accuracy:		89.46 %
Epoch 1273 of 2000 took 0.035s
  training loss:		0.175980
  validation loss:		0.394194
  validation accuracy:		89.02 %
Epoch 1274 of 2000 took 0.035s
  training loss:		0.178884
  validation loss:		0.390992
  validation accuracy:		88.59 %
Epoch 1275 of 2000 took 0.035s
  training loss:		0.180704
  validation loss:		0.392646
  validation accuracy:		89.13 %
Epoch 1276 of 2000 took 0.035s
  training loss:		0.177383
  validation loss:		0.398491
  validation accuracy:		88.91 %
Epoch 1277 of 2000 took 0.035s
  training loss:		0.173368
  validation loss:		0.394848
  validation accuracy:		89.13 %
Epoch 1278 of 2000 took 0.035s
  training loss:		0.171234
  validation loss:		0.410442
  validation accuracy:		88.70 %
Epoch 1279 of 2000 took 0.035s
  training loss:		0.176915
  validation loss:		0.381118
  validation accuracy:		88.91 %
Epoch 1280 of 2000 took 0.035s
  training loss:		0.177510
  validation loss:		0.412490
  validation accuracy:		87.93 %
Epoch 1281 of 2000 took 0.035s
  training loss:		0.176241
  validation loss:		0.407313
  validation accuracy:		88.80 %
Epoch 1282 of 2000 took 0.035s
  training loss:		0.176621
  validation loss:		0.391996
  validation accuracy:		88.91 %
Epoch 1283 of 2000 took 0.035s
  training loss:		0.178040
  validation loss:		0.400058
  validation accuracy:		88.70 %
Epoch 1284 of 2000 took 0.035s
  training loss:		0.177364
  validation loss:		0.394604
  validation accuracy:		88.80 %
Epoch 1285 of 2000 took 0.035s
  training loss:		0.176217
  validation loss:		0.396385
  validation accuracy:		89.02 %
Epoch 1286 of 2000 took 0.035s
  training loss:		0.184059
  validation loss:		0.395025
  validation accuracy:		89.02 %
Epoch 1287 of 2000 took 0.035s
  training loss:		0.186806
  validation loss:		0.396165
  validation accuracy:		88.91 %
Epoch 1288 of 2000 took 0.035s
  training loss:		0.177868
  validation loss:		0.392097
  validation accuracy:		89.24 %
Epoch 1289 of 2000 took 0.035s
  training loss:		0.178933
  validation loss:		0.408463
  validation accuracy:		88.80 %
Epoch 1290 of 2000 took 0.035s
  training loss:		0.176159
  validation loss:		0.389084
  validation accuracy:		89.13 %
Epoch 1291 of 2000 took 0.035s
  training loss:		0.174628
  validation loss:		0.394516
  validation accuracy:		89.35 %
Epoch 1292 of 2000 took 0.035s
  training loss:		0.177358
  validation loss:		0.399180
  validation accuracy:		88.70 %
Epoch 1293 of 2000 took 0.035s
  training loss:		0.181433
  validation loss:		0.409120
  validation accuracy:		88.26 %
Epoch 1294 of 2000 took 0.035s
  training loss:		0.172605
  validation loss:		0.388690
  validation accuracy:		89.02 %
Epoch 1295 of 2000 took 0.035s
  training loss:		0.178835
  validation loss:		0.398779
  validation accuracy:		88.91 %
Epoch 1296 of 2000 took 0.035s
  training loss:		0.182470
  validation loss:		0.405904
  validation accuracy:		88.80 %
Epoch 1297 of 2000 took 0.035s
  training loss:		0.182754
  validation loss:		0.399768
  validation accuracy:		88.80 %
Epoch 1298 of 2000 took 0.035s
  training loss:		0.181933
  validation loss:		0.416079
  validation accuracy:		88.37 %
Epoch 1299 of 2000 took 0.035s
  training loss:		0.178804
  validation loss:		0.404548
  validation accuracy:		88.26 %
Epoch 1300 of 2000 took 0.035s
  training loss:		0.176314
  validation loss:		0.392030
  validation accuracy:		89.02 %
Epoch 1301 of 2000 took 0.035s
  training loss:		0.179191
  validation loss:		0.392935
  validation accuracy:		88.91 %
Epoch 1302 of 2000 took 0.035s
  training loss:		0.170557
  validation loss:		0.397964
  validation accuracy:		89.13 %
Epoch 1303 of 2000 took 0.035s
  training loss:		0.177854
  validation loss:		0.393472
  validation accuracy:		88.91 %
Epoch 1304 of 2000 took 0.035s
  training loss:		0.174955
  validation loss:		0.386194
  validation accuracy:		89.13 %
Epoch 1305 of 2000 took 0.035s
  training loss:		0.174588
  validation loss:		0.387459
  validation accuracy:		88.91 %
Epoch 1306 of 2000 took 0.035s
  training loss:		0.172413
  validation loss:		0.395840
  validation accuracy:		89.13 %
Epoch 1307 of 2000 took 0.035s
  training loss:		0.178596
  validation loss:		0.400231
  validation accuracy:		88.80 %
Epoch 1308 of 2000 took 0.035s
  training loss:		0.172250
  validation loss:		0.408127
  validation accuracy:		88.91 %
Epoch 1309 of 2000 took 0.035s
  training loss:		0.174698
  validation loss:		0.410554
  validation accuracy:		88.37 %
Epoch 1310 of 2000 took 0.035s
  training loss:		0.174955
  validation loss:		0.401815
  validation accuracy:		89.02 %
Epoch 1311 of 2000 took 0.035s
  training loss:		0.175964
  validation loss:		0.404556
  validation accuracy:		88.91 %
Epoch 1312 of 2000 took 0.035s
  training loss:		0.176350
  validation loss:		0.383520
  validation accuracy:		89.13 %
Epoch 1313 of 2000 took 0.035s
  training loss:		0.174980
  validation loss:		0.402722
  validation accuracy:		88.59 %
Epoch 1314 of 2000 took 0.035s
  training loss:		0.171645
  validation loss:		0.398526
  validation accuracy:		88.37 %
Epoch 1315 of 2000 took 0.035s
  training loss:		0.181004
  validation loss:		0.408046
  validation accuracy:		88.15 %
Epoch 1316 of 2000 took 0.035s
  training loss:		0.175411
  validation loss:		0.399660
  validation accuracy:		89.02 %
Epoch 1317 of 2000 took 0.035s
  training loss:		0.177363
  validation loss:		0.398709
  validation accuracy:		89.02 %
Epoch 1318 of 2000 took 0.035s
  training loss:		0.171343
  validation loss:		0.435421
  validation accuracy:		88.26 %
Epoch 1319 of 2000 took 0.035s
  training loss:		0.181711
  validation loss:		0.390252
  validation accuracy:		89.35 %
Epoch 1320 of 2000 took 0.035s
  training loss:		0.174684
  validation loss:		0.412909
  validation accuracy:		88.91 %
Epoch 1321 of 2000 took 0.035s
  training loss:		0.174139
  validation loss:		0.410503
  validation accuracy:		88.37 %
Epoch 1322 of 2000 took 0.035s
  training loss:		0.179726
  validation loss:		0.393834
  validation accuracy:		88.91 %
Epoch 1323 of 2000 took 0.035s
  training loss:		0.173528
  validation loss:		0.404315
  validation accuracy:		88.15 %
Epoch 1324 of 2000 took 0.035s
  training loss:		0.174354
  validation loss:		0.408371
  validation accuracy:		88.37 %
Epoch 1325 of 2000 took 0.035s
  training loss:		0.171823
  validation loss:		0.391899
  validation accuracy:		89.24 %
Epoch 1326 of 2000 took 0.035s
  training loss:		0.175322
  validation loss:		0.393972
  validation accuracy:		89.02 %
Epoch 1327 of 2000 took 0.035s
  training loss:		0.165224
  validation loss:		0.416325
  validation accuracy:		88.15 %
Epoch 1328 of 2000 took 0.035s
  training loss:		0.171487
  validation loss:		0.400076
  validation accuracy:		88.70 %
Epoch 1329 of 2000 took 0.035s
  training loss:		0.176934
  validation loss:		0.422400
  validation accuracy:		87.83 %
Epoch 1330 of 2000 took 0.035s
  training loss:		0.173037
  validation loss:		0.399929
  validation accuracy:		88.91 %
Epoch 1331 of 2000 took 0.035s
  training loss:		0.169572
  validation loss:		0.410287
  validation accuracy:		87.83 %
Epoch 1332 of 2000 took 0.035s
  training loss:		0.175461
  validation loss:		0.402878
  validation accuracy:		88.59 %
Epoch 1333 of 2000 took 0.035s
  training loss:		0.174376
  validation loss:		0.406386
  validation accuracy:		88.91 %
Epoch 1334 of 2000 took 0.035s
  training loss:		0.172589
  validation loss:		0.395281
  validation accuracy:		88.91 %
Epoch 1335 of 2000 took 0.035s
  training loss:		0.170130
  validation loss:		0.389189
  validation accuracy:		89.13 %
Epoch 1336 of 2000 took 0.035s
  training loss:		0.177086
  validation loss:		0.412560
  validation accuracy:		87.83 %
Epoch 1337 of 2000 took 0.035s
  training loss:		0.170093
  validation loss:		0.405427
  validation accuracy:		88.91 %
Epoch 1338 of 2000 took 0.035s
  training loss:		0.171735
  validation loss:		0.400517
  validation accuracy:		89.02 %
Epoch 1339 of 2000 took 0.035s
  training loss:		0.175949
  validation loss:		0.396999
  validation accuracy:		88.91 %
Epoch 1340 of 2000 took 0.035s
  training loss:		0.173446
  validation loss:		0.394852
  validation accuracy:		88.37 %
Epoch 1341 of 2000 took 0.035s
  training loss:		0.173337
  validation loss:		0.411048
  validation accuracy:		88.70 %
Epoch 1342 of 2000 took 0.035s
  training loss:		0.173535
  validation loss:		0.407547
  validation accuracy:		87.93 %
Epoch 1343 of 2000 took 0.035s
  training loss:		0.177981
  validation loss:		0.384497
  validation accuracy:		89.24 %
Epoch 1344 of 2000 took 0.035s
  training loss:		0.171542
  validation loss:		0.398707
  validation accuracy:		89.13 %
Epoch 1345 of 2000 took 0.035s
  training loss:		0.173529
  validation loss:		0.395190
  validation accuracy:		88.59 %
Epoch 1346 of 2000 took 0.035s
  training loss:		0.171829
  validation loss:		0.392006
  validation accuracy:		89.02 %
Epoch 1347 of 2000 took 0.035s
  training loss:		0.170340
  validation loss:		0.413018
  validation accuracy:		88.91 %
Epoch 1348 of 2000 took 0.035s
  training loss:		0.173427
  validation loss:		0.429506
  validation accuracy:		87.28 %
Epoch 1349 of 2000 took 0.035s
  training loss:		0.173930
  validation loss:		0.412080
  validation accuracy:		88.70 %
Epoch 1350 of 2000 took 0.035s
  training loss:		0.170603
  validation loss:		0.391379
  validation accuracy:		89.13 %
Epoch 1351 of 2000 took 0.035s
  training loss:		0.174801
  validation loss:		0.408726
  validation accuracy:		88.70 %
Epoch 1352 of 2000 took 0.035s
  training loss:		0.171874
  validation loss:		0.404814
  validation accuracy:		88.91 %
Epoch 1353 of 2000 took 0.035s
  training loss:		0.172913
  validation loss:		0.407902
  validation accuracy:		88.15 %
Epoch 1354 of 2000 took 0.035s
  training loss:		0.177382
  validation loss:		0.427368
  validation accuracy:		88.04 %
Epoch 1355 of 2000 took 0.035s
  training loss:		0.171407
  validation loss:		0.392333
  validation accuracy:		89.02 %
Epoch 1356 of 2000 took 0.035s
  training loss:		0.171142
  validation loss:		0.431542
  validation accuracy:		88.26 %
Epoch 1357 of 2000 took 0.035s
  training loss:		0.170498
  validation loss:		0.396411
  validation accuracy:		88.80 %
Epoch 1358 of 2000 took 0.035s
  training loss:		0.171451
  validation loss:		0.395850
  validation accuracy:		89.13 %
Epoch 1359 of 2000 took 0.035s
  training loss:		0.164783
  validation loss:		0.417173
  validation accuracy:		88.91 %
Epoch 1360 of 2000 took 0.035s
  training loss:		0.171711
  validation loss:		0.402453
  validation accuracy:		88.70 %
Epoch 1361 of 2000 took 0.035s
  training loss:		0.170453
  validation loss:		0.423126
  validation accuracy:		87.39 %
Epoch 1362 of 2000 took 0.035s
  training loss:		0.173096
  validation loss:		0.412050
  validation accuracy:		89.35 %
Epoch 1363 of 2000 took 0.035s
  training loss:		0.171985
  validation loss:		0.413572
  validation accuracy:		88.26 %
Epoch 1364 of 2000 took 0.035s
  training loss:		0.166789
  validation loss:		0.388002
  validation accuracy:		89.57 %
Epoch 1365 of 2000 took 0.035s
  training loss:		0.171307
  validation loss:		0.402566
  validation accuracy:		88.70 %
Epoch 1366 of 2000 took 0.035s
  training loss:		0.169282
  validation loss:		0.413543
  validation accuracy:		88.15 %
Epoch 1367 of 2000 took 0.035s
  training loss:		0.172356
  validation loss:		0.402370
  validation accuracy:		88.80 %
Epoch 1368 of 2000 took 0.035s
  training loss:		0.172861
  validation loss:		0.413758
  validation accuracy:		88.91 %
Epoch 1369 of 2000 took 0.035s
  training loss:		0.171102
  validation loss:		0.399577
  validation accuracy:		88.48 %
Epoch 1370 of 2000 took 0.035s
  training loss:		0.175226
  validation loss:		0.392297
  validation accuracy:		89.35 %
Epoch 1371 of 2000 took 0.035s
  training loss:		0.170551
  validation loss:		0.402471
  validation accuracy:		88.37 %
Epoch 1372 of 2000 took 0.035s
  training loss:		0.178227
  validation loss:		0.408803
  validation accuracy:		88.15 %
Epoch 1373 of 2000 took 0.035s
  training loss:		0.172285
  validation loss:		0.427267
  validation accuracy:		88.48 %
Epoch 1374 of 2000 took 0.035s
  training loss:		0.170850
  validation loss:		0.441109
  validation accuracy:		87.72 %
Epoch 1375 of 2000 took 0.035s
  training loss:		0.172353
  validation loss:		0.415471
  validation accuracy:		88.80 %
Epoch 1376 of 2000 took 0.035s
  training loss:		0.171964
  validation loss:		0.400439
  validation accuracy:		89.02 %
Epoch 1377 of 2000 took 0.035s
  training loss:		0.167081
  validation loss:		0.395918
  validation accuracy:		88.91 %
Epoch 1378 of 2000 took 0.035s
  training loss:		0.169098
  validation loss:		0.398762
  validation accuracy:		89.13 %
Epoch 1379 of 2000 took 0.035s
  training loss:		0.171659
  validation loss:		0.400159
  validation accuracy:		88.70 %
Epoch 1380 of 2000 took 0.035s
  training loss:		0.171735
  validation loss:		0.404056
  validation accuracy:		88.59 %
Epoch 1381 of 2000 took 0.035s
  training loss:		0.171034
  validation loss:		0.398425
  validation accuracy:		88.59 %
Epoch 1382 of 2000 took 0.035s
  training loss:		0.165141
  validation loss:		0.403836
  validation accuracy:		89.02 %
Epoch 1383 of 2000 took 0.035s
  training loss:		0.168007
  validation loss:		0.402382
  validation accuracy:		88.80 %
Epoch 1384 of 2000 took 0.035s
  training loss:		0.166262
  validation loss:		0.413806
  validation accuracy:		88.70 %
Epoch 1385 of 2000 took 0.035s
  training loss:		0.166365
  validation loss:		0.414125
  validation accuracy:		87.83 %
Epoch 1386 of 2000 took 0.035s
  training loss:		0.168730
  validation loss:		0.400460
  validation accuracy:		88.80 %
Epoch 1387 of 2000 took 0.035s
  training loss:		0.172380
  validation loss:		0.394884
  validation accuracy:		88.91 %
Epoch 1388 of 2000 took 0.035s
  training loss:		0.165880
  validation loss:		0.400817
  validation accuracy:		89.02 %
Epoch 1389 of 2000 took 0.035s
  training loss:		0.171479
  validation loss:		0.402274
  validation accuracy:		88.59 %
Epoch 1390 of 2000 took 0.035s
  training loss:		0.167731
  validation loss:		0.409687
  validation accuracy:		88.04 %
Epoch 1391 of 2000 took 0.035s
  training loss:		0.170373
  validation loss:		0.410261
  validation accuracy:		88.48 %
Epoch 1392 of 2000 took 0.035s
  training loss:		0.167773
  validation loss:		0.406410
  validation accuracy:		88.48 %
Epoch 1393 of 2000 took 0.035s
  training loss:		0.176054
  validation loss:		0.393715
  validation accuracy:		88.48 %
Epoch 1394 of 2000 took 0.035s
  training loss:		0.167150
  validation loss:		0.398173
  validation accuracy:		88.91 %
Epoch 1395 of 2000 took 0.035s
  training loss:		0.171115
  validation loss:		0.401139
  validation accuracy:		88.91 %
Epoch 1396 of 2000 took 0.035s
  training loss:		0.165446
  validation loss:		0.405635
  validation accuracy:		89.13 %
Epoch 1397 of 2000 took 0.035s
  training loss:		0.168593
  validation loss:		0.402415
  validation accuracy:		88.15 %
Epoch 1398 of 2000 took 0.035s
  training loss:		0.165565
  validation loss:		0.406701
  validation accuracy:		88.48 %
Epoch 1399 of 2000 took 0.035s
  training loss:		0.170440
  validation loss:		0.402641
  validation accuracy:		88.26 %
Epoch 1400 of 2000 took 0.035s
  training loss:		0.170722
  validation loss:		0.397817
  validation accuracy:		89.13 %
Epoch 1401 of 2000 took 0.035s
  training loss:		0.168961
  validation loss:		0.404049
  validation accuracy:		88.91 %
Epoch 1402 of 2000 took 0.035s
  training loss:		0.164158
  validation loss:		0.413584
  validation accuracy:		88.48 %
Epoch 1403 of 2000 took 0.035s
  training loss:		0.168610
  validation loss:		0.397278
  validation accuracy:		89.13 %
Epoch 1404 of 2000 took 0.035s
  training loss:		0.163665
  validation loss:		0.405803
  validation accuracy:		88.59 %
Epoch 1405 of 2000 took 0.035s
  training loss:		0.166234
  validation loss:		0.418073
  validation accuracy:		88.70 %
Epoch 1406 of 2000 took 0.035s
  training loss:		0.169010
  validation loss:		0.409746
  validation accuracy:		89.24 %
Epoch 1407 of 2000 took 0.035s
  training loss:		0.164027
  validation loss:		0.406206
  validation accuracy:		88.80 %
Epoch 1408 of 2000 took 0.035s
  training loss:		0.170353
  validation loss:		0.413735
  validation accuracy:		88.26 %
Epoch 1409 of 2000 took 0.035s
  training loss:		0.163600
  validation loss:		0.408221
  validation accuracy:		88.91 %
Epoch 1410 of 2000 took 0.035s
  training loss:		0.170433
  validation loss:		0.395650
  validation accuracy:		89.13 %
Epoch 1411 of 2000 took 0.035s
  training loss:		0.172609
  validation loss:		0.407851
  validation accuracy:		88.48 %
Epoch 1412 of 2000 took 0.035s
  training loss:		0.168017
  validation loss:		0.422191
  validation accuracy:		88.59 %
Epoch 1413 of 2000 took 0.035s
  training loss:		0.164897
  validation loss:		0.407974
  validation accuracy:		88.37 %
Epoch 1414 of 2000 took 0.035s
  training loss:		0.170442
  validation loss:		0.395850
  validation accuracy:		88.80 %
Epoch 1415 of 2000 took 0.035s
  training loss:		0.175104
  validation loss:		0.414633
  validation accuracy:		88.48 %
Epoch 1416 of 2000 took 0.035s
  training loss:		0.166292
  validation loss:		0.414277
  validation accuracy:		87.72 %
Epoch 1417 of 2000 took 0.035s
  training loss:		0.169359
  validation loss:		0.409385
  validation accuracy:		88.91 %
Epoch 1418 of 2000 took 0.035s
  training loss:		0.172930
  validation loss:		0.413046
  validation accuracy:		88.91 %
Epoch 1419 of 2000 took 0.035s
  training loss:		0.167255
  validation loss:		0.416842
  validation accuracy:		88.26 %
Epoch 1420 of 2000 took 0.035s
  training loss:		0.170243
  validation loss:		0.417389
  validation accuracy:		88.59 %
Epoch 1421 of 2000 took 0.035s
  training loss:		0.168087
  validation loss:		0.423871
  validation accuracy:		88.26 %
Epoch 1422 of 2000 took 0.035s
  training loss:		0.167227
  validation loss:		0.422494
  validation accuracy:		88.26 %
Epoch 1423 of 2000 took 0.035s
  training loss:		0.169296
  validation loss:		0.412885
  validation accuracy:		88.59 %
Epoch 1424 of 2000 took 0.035s
  training loss:		0.171106
  validation loss:		0.402709
  validation accuracy:		89.02 %
Epoch 1425 of 2000 took 0.035s
  training loss:		0.168499
  validation loss:		0.418914
  validation accuracy:		88.70 %
Epoch 1426 of 2000 took 0.035s
  training loss:		0.172420
  validation loss:		0.409675
  validation accuracy:		88.80 %
Epoch 1427 of 2000 took 0.035s
  training loss:		0.169954
  validation loss:		0.398353
  validation accuracy:		89.46 %
Epoch 1428 of 2000 took 0.035s
  training loss:		0.166298
  validation loss:		0.411251
  validation accuracy:		88.59 %
Epoch 1429 of 2000 took 0.035s
  training loss:		0.167262
  validation loss:		0.415055
  validation accuracy:		88.70 %
Epoch 1430 of 2000 took 0.035s
  training loss:		0.166848
  validation loss:		0.402628
  validation accuracy:		89.02 %
Epoch 1431 of 2000 took 0.035s
  training loss:		0.163768
  validation loss:		0.416602
  validation accuracy:		88.15 %
Epoch 1432 of 2000 took 0.035s
  training loss:		0.168282
  validation loss:		0.399063
  validation accuracy:		88.91 %
Epoch 1433 of 2000 took 0.035s
  training loss:		0.163252
  validation loss:		0.407816
  validation accuracy:		88.70 %
Epoch 1434 of 2000 took 0.035s
  training loss:		0.166752
  validation loss:		0.402318
  validation accuracy:		88.91 %
Epoch 1435 of 2000 took 0.035s
  training loss:		0.165257
  validation loss:		0.415661
  validation accuracy:		87.61 %
Epoch 1436 of 2000 took 0.035s
  training loss:		0.166878
  validation loss:		0.430993
  validation accuracy:		87.72 %
Epoch 1437 of 2000 took 0.035s
  training loss:		0.170077
  validation loss:		0.396590
  validation accuracy:		89.24 %
Epoch 1438 of 2000 took 0.035s
  training loss:		0.167731
  validation loss:		0.402089
  validation accuracy:		88.59 %
Epoch 1439 of 2000 took 0.035s
  training loss:		0.178905
  validation loss:		0.409971
  validation accuracy:		88.37 %
Epoch 1440 of 2000 took 0.035s
  training loss:		0.169391
  validation loss:		0.403936
  validation accuracy:		88.59 %
Epoch 1441 of 2000 took 0.035s
  training loss:		0.166234
  validation loss:		0.405731
  validation accuracy:		88.59 %
Epoch 1442 of 2000 took 0.035s
  training loss:		0.164547
  validation loss:		0.429910
  validation accuracy:		87.61 %
Epoch 1443 of 2000 took 0.035s
  training loss:		0.168272
  validation loss:		0.422060
  validation accuracy:		88.15 %
Epoch 1444 of 2000 took 0.035s
  training loss:		0.167740
  validation loss:		0.411563
  validation accuracy:		88.70 %
Epoch 1445 of 2000 took 0.035s
  training loss:		0.166129
  validation loss:		0.406788
  validation accuracy:		88.48 %
Epoch 1446 of 2000 took 0.035s
  training loss:		0.168580
  validation loss:		0.414404
  validation accuracy:		88.37 %
Epoch 1447 of 2000 took 0.035s
  training loss:		0.164002
  validation loss:		0.432073
  validation accuracy:		88.59 %
Epoch 1448 of 2000 took 0.035s
  training loss:		0.174801
  validation loss:		0.413278
  validation accuracy:		88.04 %
Epoch 1449 of 2000 took 0.035s
  training loss:		0.164853
  validation loss:		0.400546
  validation accuracy:		89.24 %
Epoch 1450 of 2000 took 0.035s
  training loss:		0.167979
  validation loss:		0.409849
  validation accuracy:		88.91 %
Epoch 1451 of 2000 took 0.035s
  training loss:		0.166752
  validation loss:		0.413936
  validation accuracy:		88.80 %
Epoch 1452 of 2000 took 0.035s
  training loss:		0.168740
  validation loss:		0.413592
  validation accuracy:		87.93 %
Epoch 1453 of 2000 took 0.035s
  training loss:		0.163451
  validation loss:		0.409777
  validation accuracy:		88.80 %
Epoch 1454 of 2000 took 0.035s
  training loss:		0.167982
  validation loss:		0.443643
  validation accuracy:		88.48 %
Epoch 1455 of 2000 took 0.035s
  training loss:		0.168019
  validation loss:		0.422238
  validation accuracy:		88.48 %
Epoch 1456 of 2000 took 0.035s
  training loss:		0.165796
  validation loss:		0.415125
  validation accuracy:		88.15 %
Epoch 1457 of 2000 took 0.035s
  training loss:		0.162961
  validation loss:		0.413556
  validation accuracy:		88.26 %
Epoch 1458 of 2000 took 0.035s
  training loss:		0.165423
  validation loss:		0.420825
  validation accuracy:		88.04 %
Epoch 1459 of 2000 took 0.035s
  training loss:		0.169316
  validation loss:		0.412014
  validation accuracy:		88.37 %
Epoch 1460 of 2000 took 0.035s
  training loss:		0.174951
  validation loss:		0.419934
  validation accuracy:		88.37 %
Epoch 1461 of 2000 took 0.035s
  training loss:		0.166713
  validation loss:		0.402687
  validation accuracy:		88.80 %
Epoch 1462 of 2000 took 0.035s
  training loss:		0.168220
  validation loss:		0.432015
  validation accuracy:		88.59 %
Epoch 1463 of 2000 took 0.035s
  training loss:		0.166715
  validation loss:		0.446987
  validation accuracy:		87.07 %
Epoch 1464 of 2000 took 0.035s
  training loss:		0.160383
  validation loss:		0.416686
  validation accuracy:		88.59 %
Epoch 1465 of 2000 took 0.035s
  training loss:		0.166350
  validation loss:		0.400322
  validation accuracy:		89.57 %
Epoch 1466 of 2000 took 0.035s
  training loss:		0.170420
  validation loss:		0.401054
  validation accuracy:		89.35 %
Epoch 1467 of 2000 took 0.035s
  training loss:		0.164040
  validation loss:		0.415371
  validation accuracy:		88.80 %
Epoch 1468 of 2000 took 0.035s
  training loss:		0.170860
  validation loss:		0.403759
  validation accuracy:		89.02 %
Epoch 1469 of 2000 took 0.035s
  training loss:		0.168619
  validation loss:		0.406653
  validation accuracy:		88.70 %
Epoch 1470 of 2000 took 0.035s
  training loss:		0.164475
  validation loss:		0.422999
  validation accuracy:		88.59 %
Epoch 1471 of 2000 took 0.035s
  training loss:		0.163922
  validation loss:		0.405950
  validation accuracy:		88.70 %
Epoch 1472 of 2000 took 0.035s
  training loss:		0.170032
  validation loss:		0.418434
  validation accuracy:		88.26 %
Epoch 1473 of 2000 took 0.035s
  training loss:		0.166974
  validation loss:		0.431672
  validation accuracy:		87.17 %
Epoch 1474 of 2000 took 0.035s
  training loss:		0.170643
  validation loss:		0.418134
  validation accuracy:		88.37 %
Epoch 1475 of 2000 took 0.035s
  training loss:		0.166051
  validation loss:		0.410559
  validation accuracy:		88.04 %
Epoch 1476 of 2000 took 0.035s
  training loss:		0.166324
  validation loss:		0.407614
  validation accuracy:		88.59 %
Epoch 1477 of 2000 took 0.035s
  training loss:		0.160036
  validation loss:		0.420595
  validation accuracy:		88.59 %
Epoch 1478 of 2000 took 0.035s
  training loss:		0.173711
  validation loss:		0.408990
  validation accuracy:		88.70 %
Epoch 1479 of 2000 took 0.035s
  training loss:		0.168128
  validation loss:		0.409011
  validation accuracy:		89.24 %
Epoch 1480 of 2000 took 0.035s
  training loss:		0.164445
  validation loss:		0.434019
  validation accuracy:		87.72 %
Epoch 1481 of 2000 took 0.035s
  training loss:		0.158477
  validation loss:		0.420267
  validation accuracy:		88.80 %
Epoch 1482 of 2000 took 0.035s
  training loss:		0.169165
  validation loss:		0.431802
  validation accuracy:		87.39 %
Epoch 1483 of 2000 took 0.035s
  training loss:		0.161211
  validation loss:		0.405672
  validation accuracy:		88.59 %
Epoch 1484 of 2000 took 0.035s
  training loss:		0.167846
  validation loss:		0.434430
  validation accuracy:		87.83 %
Epoch 1485 of 2000 took 0.035s
  training loss:		0.169255
  validation loss:		0.407640
  validation accuracy:		88.48 %
Epoch 1486 of 2000 took 0.035s
  training loss:		0.162702
  validation loss:		0.434235
  validation accuracy:		87.61 %
Epoch 1487 of 2000 took 0.035s
  training loss:		0.173146
  validation loss:		0.421005
  validation accuracy:		88.48 %
Epoch 1488 of 2000 took 0.035s
  training loss:		0.164365
  validation loss:		0.419745
  validation accuracy:		88.15 %
Epoch 1489 of 2000 took 0.035s
  training loss:		0.163730
  validation loss:		0.417010
  validation accuracy:		88.26 %
Epoch 1490 of 2000 took 0.035s
  training loss:		0.167870
  validation loss:		0.405928
  validation accuracy:		88.91 %
Epoch 1491 of 2000 took 0.035s
  training loss:		0.166359
  validation loss:		0.421764
  validation accuracy:		88.80 %
Epoch 1492 of 2000 took 0.035s
  training loss:		0.160514
  validation loss:		0.414653
  validation accuracy:		88.37 %
Epoch 1493 of 2000 took 0.035s
  training loss:		0.165423
  validation loss:		0.417999
  validation accuracy:		88.91 %
Epoch 1494 of 2000 took 0.035s
  training loss:		0.165620
  validation loss:		0.417986
  validation accuracy:		88.37 %
Epoch 1495 of 2000 took 0.035s
  training loss:		0.162908
  validation loss:		0.421635
  validation accuracy:		88.48 %
Epoch 1496 of 2000 took 0.035s
  training loss:		0.164288
  validation loss:		0.411850
  validation accuracy:		89.35 %
Epoch 1497 of 2000 took 0.035s
  training loss:		0.167065
  validation loss:		0.436809
  validation accuracy:		88.15 %
Epoch 1498 of 2000 took 0.035s
  training loss:		0.167431
  validation loss:		0.418516
  validation accuracy:		88.91 %
Epoch 1499 of 2000 took 0.035s
  training loss:		0.166974
  validation loss:		0.401554
  validation accuracy:		88.80 %
Epoch 1500 of 2000 took 0.035s
  training loss:		0.165409
  validation loss:		0.434420
  validation accuracy:		87.39 %
Epoch 1501 of 2000 took 0.035s
  training loss:		0.166881
  validation loss:		0.427536
  validation accuracy:		88.04 %
Epoch 1502 of 2000 took 0.037s
  training loss:		0.165317
  validation loss:		0.443198
  validation accuracy:		87.61 %
Epoch 1503 of 2000 took 0.035s
  training loss:		0.164322
  validation loss:		0.409297
  validation accuracy:		88.48 %
Epoch 1504 of 2000 took 0.035s
  training loss:		0.160478
  validation loss:		0.452390
  validation accuracy:		87.28 %
Epoch 1505 of 2000 took 0.035s
  training loss:		0.159776
  validation loss:		0.411403
  validation accuracy:		88.48 %
Epoch 1506 of 2000 took 0.035s
  training loss:		0.167681
  validation loss:		0.442120
  validation accuracy:		88.80 %
Epoch 1507 of 2000 took 0.035s
  training loss:		0.170530
  validation loss:		0.421768
  validation accuracy:		88.37 %
Epoch 1508 of 2000 took 0.035s
  training loss:		0.168920
  validation loss:		0.425979
  validation accuracy:		88.70 %
Epoch 1509 of 2000 took 0.035s
  training loss:		0.167499
  validation loss:		0.421734
  validation accuracy:		87.93 %
Epoch 1510 of 2000 took 0.035s
  training loss:		0.158064
  validation loss:		0.419103
  validation accuracy:		89.02 %
Epoch 1511 of 2000 took 0.035s
  training loss:		0.165205
  validation loss:		0.426665
  validation accuracy:		88.91 %
Epoch 1512 of 2000 took 0.035s
  training loss:		0.162708
  validation loss:		0.422254
  validation accuracy:		88.37 %
Epoch 1513 of 2000 took 0.035s
  training loss:		0.165029
  validation loss:		0.423845
  validation accuracy:		88.80 %
Epoch 1514 of 2000 took 0.035s
  training loss:		0.166635
  validation loss:		0.414458
  validation accuracy:		88.26 %
Epoch 1515 of 2000 took 0.035s
  training loss:		0.162313
  validation loss:		0.430557
  validation accuracy:		87.83 %
Epoch 1516 of 2000 took 0.035s
  training loss:		0.160853
  validation loss:		0.417371
  validation accuracy:		88.80 %
Epoch 1517 of 2000 took 0.035s
  training loss:		0.166939
  validation loss:		0.416118
  validation accuracy:		88.59 %
Epoch 1518 of 2000 took 0.035s
  training loss:		0.166842
  validation loss:		0.427797
  validation accuracy:		88.91 %
Epoch 1519 of 2000 took 0.035s
  training loss:		0.164319
  validation loss:		0.412651
  validation accuracy:		88.70 %
Epoch 1520 of 2000 took 0.035s
  training loss:		0.166922
  validation loss:		0.424618
  validation accuracy:		88.15 %
Epoch 1521 of 2000 took 0.035s
  training loss:		0.160661
  validation loss:		0.421420
  validation accuracy:		88.37 %
Epoch 1522 of 2000 took 0.035s
  training loss:		0.157785
  validation loss:		0.420559
  validation accuracy:		88.48 %
Epoch 1523 of 2000 took 0.035s
  training loss:		0.162346
  validation loss:		0.416466
  validation accuracy:		88.70 %
Epoch 1524 of 2000 took 0.035s
  training loss:		0.162442
  validation loss:		0.419092
  validation accuracy:		88.48 %
Epoch 1525 of 2000 took 0.035s
  training loss:		0.169446
  validation loss:		0.419200
  validation accuracy:		89.13 %
Epoch 1526 of 2000 took 0.035s
  training loss:		0.168397
  validation loss:		0.427907
  validation accuracy:		87.93 %
Epoch 1527 of 2000 took 0.035s
  training loss:		0.166146
  validation loss:		0.409595
  validation accuracy:		88.91 %
Epoch 1528 of 2000 took 0.035s
  training loss:		0.160130
  validation loss:		0.438803
  validation accuracy:		87.61 %
Epoch 1529 of 2000 took 0.035s
  training loss:		0.158032
  validation loss:		0.423926
  validation accuracy:		88.59 %
Epoch 1530 of 2000 took 0.035s
  training loss:		0.163225
  validation loss:		0.418618
  validation accuracy:		87.61 %
Epoch 1531 of 2000 took 0.035s
  training loss:		0.162161
  validation loss:		0.431737
  validation accuracy:		88.59 %
Epoch 1532 of 2000 took 0.036s
  training loss:		0.168898
  validation loss:		0.426540
  validation accuracy:		87.72 %
Epoch 1533 of 2000 took 0.037s
  training loss:		0.162492
  validation loss:		0.423769
  validation accuracy:		87.61 %
Epoch 1534 of 2000 took 0.037s
  training loss:		0.159854
  validation loss:		0.420672
  validation accuracy:		88.37 %
Epoch 1535 of 2000 took 0.036s
  training loss:		0.161887
  validation loss:		0.428936
  validation accuracy:		88.04 %
Epoch 1536 of 2000 took 0.037s
  training loss:		0.164543
  validation loss:		0.420120
  validation accuracy:		88.48 %
Epoch 1537 of 2000 took 0.036s
  training loss:		0.170332
  validation loss:		0.417948
  validation accuracy:		88.37 %
Epoch 1538 of 2000 took 0.036s
  training loss:		0.163273
  validation loss:		0.424252
  validation accuracy:		88.15 %
Epoch 1539 of 2000 took 0.036s
  training loss:		0.164260
  validation loss:		0.446113
  validation accuracy:		87.50 %
Epoch 1540 of 2000 took 0.036s
  training loss:		0.160759
  validation loss:		0.446552
  validation accuracy:		87.28 %
Epoch 1541 of 2000 took 0.036s
  training loss:		0.160807
  validation loss:		0.427230
  validation accuracy:		88.15 %
Epoch 1542 of 2000 took 0.036s
  training loss:		0.162363
  validation loss:		0.417377
  validation accuracy:		89.57 %
Epoch 1543 of 2000 took 0.036s
  training loss:		0.160300
  validation loss:		0.417239
  validation accuracy:		88.59 %
Epoch 1544 of 2000 took 0.036s
  training loss:		0.157070
  validation loss:		0.438699
  validation accuracy:		87.39 %
Epoch 1545 of 2000 took 0.036s
  training loss:		0.165390
  validation loss:		0.419412
  validation accuracy:		88.26 %
Epoch 1546 of 2000 took 0.036s
  training loss:		0.158449
  validation loss:		0.430510
  validation accuracy:		89.02 %
Epoch 1547 of 2000 took 0.036s
  training loss:		0.159881
  validation loss:		0.430873
  validation accuracy:		88.15 %
Epoch 1548 of 2000 took 0.036s
  training loss:		0.160070
  validation loss:		0.426496
  validation accuracy:		89.24 %
Epoch 1549 of 2000 took 0.036s
  training loss:		0.166251
  validation loss:		0.417657
  validation accuracy:		88.48 %
Epoch 1550 of 2000 took 0.036s
  training loss:		0.162104
  validation loss:		0.433555
  validation accuracy:		88.37 %
Epoch 1551 of 2000 took 0.036s
  training loss:		0.164013
  validation loss:		0.434961
  validation accuracy:		87.83 %
Epoch 1552 of 2000 took 0.036s
  training loss:		0.164425
  validation loss:		0.413193
  validation accuracy:		89.13 %
Epoch 1553 of 2000 took 0.036s
  training loss:		0.164393
  validation loss:		0.415721
  validation accuracy:		88.80 %
Epoch 1554 of 2000 took 0.036s
  training loss:		0.166464
  validation loss:		0.443053
  validation accuracy:		88.70 %
Epoch 1555 of 2000 took 0.036s
  training loss:		0.155993
  validation loss:		0.411419
  validation accuracy:		88.59 %
Epoch 1556 of 2000 took 0.036s
  training loss:		0.160245
  validation loss:		0.429091
  validation accuracy:		88.37 %
Epoch 1557 of 2000 took 0.036s
  training loss:		0.158725
  validation loss:		0.423071
  validation accuracy:		88.48 %
Epoch 1558 of 2000 took 0.036s
  training loss:		0.161993
  validation loss:		0.436465
  validation accuracy:		87.39 %
Epoch 1559 of 2000 took 0.036s
  training loss:		0.157183
  validation loss:		0.427262
  validation accuracy:		88.37 %
Epoch 1560 of 2000 took 0.036s
  training loss:		0.158637
  validation loss:		0.413262
  validation accuracy:		88.70 %
Epoch 1561 of 2000 took 0.036s
  training loss:		0.157065
  validation loss:		0.417719
  validation accuracy:		89.67 %
Epoch 1562 of 2000 took 0.036s
  training loss:		0.165980
  validation loss:		0.434949
  validation accuracy:		87.72 %
Epoch 1563 of 2000 took 0.036s
  training loss:		0.160820
  validation loss:		0.420977
  validation accuracy:		88.59 %
Epoch 1564 of 2000 took 0.036s
  training loss:		0.162350
  validation loss:		0.434239
  validation accuracy:		87.72 %
Epoch 1565 of 2000 took 0.036s
  training loss:		0.162224
  validation loss:		0.438130
  validation accuracy:		87.93 %
Epoch 1566 of 2000 took 0.036s
  training loss:		0.160728
  validation loss:		0.434017
  validation accuracy:		87.72 %
Epoch 1567 of 2000 took 0.036s
  training loss:		0.162174
  validation loss:		0.443353
  validation accuracy:		87.72 %
Epoch 1568 of 2000 took 0.036s
  training loss:		0.160998
  validation loss:		0.438606
  validation accuracy:		88.26 %
Epoch 1569 of 2000 took 0.036s
  training loss:		0.163630
  validation loss:		0.414201
  validation accuracy:		89.13 %
Epoch 1570 of 2000 took 0.036s
  training loss:		0.159671
  validation loss:		0.414686
  validation accuracy:		89.24 %
Epoch 1571 of 2000 took 0.036s
  training loss:		0.157376
  validation loss:		0.426112
  validation accuracy:		88.48 %
Epoch 1572 of 2000 took 0.036s
  training loss:		0.155606
  validation loss:		0.443658
  validation accuracy:		87.28 %
Epoch 1573 of 2000 took 0.036s
  training loss:		0.163157
  validation loss:		0.440746
  validation accuracy:		87.50 %
Epoch 1574 of 2000 took 0.036s
  training loss:		0.161205
  validation loss:		0.419232
  validation accuracy:		88.70 %
Epoch 1575 of 2000 took 0.036s
  training loss:		0.163014
  validation loss:		0.415048
  validation accuracy:		88.59 %
Epoch 1576 of 2000 took 0.036s
  training loss:		0.163337
  validation loss:		0.432836
  validation accuracy:		88.48 %
Epoch 1577 of 2000 took 0.036s
  training loss:		0.161822
  validation loss:		0.440254
  validation accuracy:		87.61 %
Epoch 1578 of 2000 took 0.036s
  training loss:		0.163474
  validation loss:		0.421189
  validation accuracy:		88.59 %
Epoch 1579 of 2000 took 0.036s
  training loss:		0.160883
  validation loss:		0.442878
  validation accuracy:		87.61 %
Epoch 1580 of 2000 took 0.036s
  training loss:		0.161716
  validation loss:		0.435682
  validation accuracy:		88.59 %
Epoch 1581 of 2000 took 0.036s
  training loss:		0.152677
  validation loss:		0.431415
  validation accuracy:		88.15 %
Epoch 1582 of 2000 took 0.036s
  training loss:		0.158376
  validation loss:		0.428185
  validation accuracy:		87.93 %
Epoch 1583 of 2000 took 0.036s
  training loss:		0.162931
  validation loss:		0.413988
  validation accuracy:		89.13 %
Epoch 1584 of 2000 took 0.036s
  training loss:		0.159438
  validation loss:		0.429890
  validation accuracy:		88.59 %
Epoch 1585 of 2000 took 0.036s
  training loss:		0.161189
  validation loss:		0.409539
  validation accuracy:		89.35 %
Epoch 1586 of 2000 took 0.036s
  training loss:		0.163950
  validation loss:		0.424390
  validation accuracy:		88.59 %
Epoch 1587 of 2000 took 0.036s
  training loss:		0.162855
  validation loss:		0.428571
  validation accuracy:		88.59 %
Epoch 1588 of 2000 took 0.036s
  training loss:		0.159675
  validation loss:		0.416604
  validation accuracy:		88.91 %
Epoch 1589 of 2000 took 0.036s
  training loss:		0.158303
  validation loss:		0.459983
  validation accuracy:		87.50 %
Epoch 1590 of 2000 took 0.036s
  training loss:		0.163207
  validation loss:		0.428189
  validation accuracy:		88.37 %
Epoch 1591 of 2000 took 0.036s
  training loss:		0.157479
  validation loss:		0.434461
  validation accuracy:		88.59 %
Epoch 1592 of 2000 took 0.036s
  training loss:		0.156102
  validation loss:		0.418689
  validation accuracy:		89.35 %
Epoch 1593 of 2000 took 0.036s
  training loss:		0.159205
  validation loss:		0.435894
  validation accuracy:		88.70 %
Epoch 1594 of 2000 took 0.036s
  training loss:		0.162088
  validation loss:		0.423749
  validation accuracy:		88.48 %
Epoch 1595 of 2000 took 0.036s
  training loss:		0.159028
  validation loss:		0.423507
  validation accuracy:		88.04 %
Epoch 1596 of 2000 took 0.036s
  training loss:		0.160064
  validation loss:		0.417025
  validation accuracy:		89.02 %
Epoch 1597 of 2000 took 0.036s
  training loss:		0.166107
  validation loss:		0.416074
  validation accuracy:		88.91 %
Epoch 1598 of 2000 took 0.036s
  training loss:		0.163231
  validation loss:		0.421651
  validation accuracy:		88.80 %
Epoch 1599 of 2000 took 0.036s
  training loss:		0.157575
  validation loss:		0.449890
  validation accuracy:		87.39 %
Epoch 1600 of 2000 took 0.036s
  training loss:		0.163207
  validation loss:		0.432753
  validation accuracy:		88.26 %
Epoch 1601 of 2000 took 0.036s
  training loss:		0.159962
  validation loss:		0.430910
  validation accuracy:		88.15 %
Epoch 1602 of 2000 took 0.036s
  training loss:		0.165946
  validation loss:		0.429338
  validation accuracy:		87.72 %
Epoch 1603 of 2000 took 0.036s
  training loss:		0.159571
  validation loss:		0.438381
  validation accuracy:		88.26 %
Epoch 1604 of 2000 took 0.036s
  training loss:		0.160825
  validation loss:		0.426287
  validation accuracy:		89.13 %
Epoch 1605 of 2000 took 0.036s
  training loss:		0.150995
  validation loss:		0.429140
  validation accuracy:		88.15 %
Epoch 1606 of 2000 took 0.036s
  training loss:		0.157481
  validation loss:		0.427168
  validation accuracy:		88.59 %
Epoch 1607 of 2000 took 0.036s
  training loss:		0.162140
  validation loss:		0.440339
  validation accuracy:		88.48 %
Epoch 1608 of 2000 took 0.036s
  training loss:		0.156314
  validation loss:		0.425364
  validation accuracy:		88.80 %
Epoch 1609 of 2000 took 0.036s
  training loss:		0.155260
  validation loss:		0.457931
  validation accuracy:		87.93 %
Epoch 1610 of 2000 took 0.036s
  training loss:		0.167421
  validation loss:		0.427617
  validation accuracy:		89.24 %
Epoch 1611 of 2000 took 0.036s
  training loss:		0.158989
  validation loss:		0.436330
  validation accuracy:		88.48 %
Epoch 1612 of 2000 took 0.036s
  training loss:		0.156656
  validation loss:		0.438959
  validation accuracy:		87.72 %
Epoch 1613 of 2000 took 0.036s
  training loss:		0.158296
  validation loss:		0.437318
  validation accuracy:		88.48 %
Epoch 1614 of 2000 took 0.036s
  training loss:		0.161229
  validation loss:		0.426932
  validation accuracy:		88.37 %
Epoch 1615 of 2000 took 0.036s
  training loss:		0.160646
  validation loss:		0.448331
  validation accuracy:		87.39 %
Epoch 1616 of 2000 took 0.036s
  training loss:		0.162680
  validation loss:		0.433417
  validation accuracy:		88.37 %
Epoch 1617 of 2000 took 0.036s
  training loss:		0.162020
  validation loss:		0.421967
  validation accuracy:		88.59 %
Epoch 1618 of 2000 took 0.036s
  training loss:		0.160084
  validation loss:		0.429817
  validation accuracy:		88.15 %
Epoch 1619 of 2000 took 0.036s
  training loss:		0.156814
  validation loss:		0.434437
  validation accuracy:		88.59 %
Epoch 1620 of 2000 took 0.036s
  training loss:		0.158998
  validation loss:		0.433843
  validation accuracy:		88.04 %
Epoch 1621 of 2000 took 0.036s
  training loss:		0.157580
  validation loss:		0.414157
  validation accuracy:		88.59 %
Epoch 1622 of 2000 took 0.035s
  training loss:		0.157228
  validation loss:		0.420903
  validation accuracy:		88.91 %
Epoch 1623 of 2000 took 0.035s
  training loss:		0.163124
  validation loss:		0.437932
  validation accuracy:		88.26 %
Epoch 1624 of 2000 took 0.035s
  training loss:		0.159326
  validation loss:		0.442749
  validation accuracy:		88.15 %
Epoch 1625 of 2000 took 0.035s
  training loss:		0.161757
  validation loss:		0.436385
  validation accuracy:		87.93 %
Epoch 1626 of 2000 took 0.035s
  training loss:		0.158059
  validation loss:		0.433378
  validation accuracy:		88.37 %
Epoch 1627 of 2000 took 0.035s
  training loss:		0.160566
  validation loss:		0.443842
  validation accuracy:		87.61 %
Epoch 1628 of 2000 took 0.035s
  training loss:		0.164505
  validation loss:		0.423244
  validation accuracy:		88.37 %
Epoch 1629 of 2000 took 0.035s
  training loss:		0.158835
  validation loss:		0.424589
  validation accuracy:		88.80 %
Epoch 1630 of 2000 took 0.035s
  training loss:		0.159155
  validation loss:		0.440611
  validation accuracy:		87.61 %
Epoch 1631 of 2000 took 0.035s
  training loss:		0.158074
  validation loss:		0.443739
  validation accuracy:		87.83 %
Epoch 1632 of 2000 took 0.035s
  training loss:		0.156459
  validation loss:		0.435434
  validation accuracy:		88.04 %
Epoch 1633 of 2000 took 0.035s
  training loss:		0.156973
  validation loss:		0.431321
  validation accuracy:		88.15 %
Epoch 1634 of 2000 took 0.035s
  training loss:		0.156775
  validation loss:		0.457110
  validation accuracy:		86.74 %
Epoch 1635 of 2000 took 0.035s
  training loss:		0.160168
  validation loss:		0.441630
  validation accuracy:		88.15 %
Epoch 1636 of 2000 took 0.035s
  training loss:		0.159347
  validation loss:		0.431197
  validation accuracy:		88.91 %
Epoch 1637 of 2000 took 0.035s
  training loss:		0.164924
  validation loss:		0.439629
  validation accuracy:		88.26 %
Epoch 1638 of 2000 took 0.035s
  training loss:		0.159506
  validation loss:		0.446954
  validation accuracy:		87.61 %
Epoch 1639 of 2000 took 0.035s
  training loss:		0.157262
  validation loss:		0.446340
  validation accuracy:		88.04 %
Epoch 1640 of 2000 took 0.035s
  training loss:		0.158368
  validation loss:		0.438119
  validation accuracy:		88.15 %
Epoch 1641 of 2000 took 0.035s
  training loss:		0.166872
  validation loss:		0.443394
  validation accuracy:		88.04 %
Epoch 1642 of 2000 took 0.035s
  training loss:		0.163718
  validation loss:		0.437671
  validation accuracy:		88.37 %
Epoch 1643 of 2000 took 0.035s
  training loss:		0.156283
  validation loss:		0.427967
  validation accuracy:		88.48 %
Epoch 1644 of 2000 took 0.035s
  training loss:		0.158284
  validation loss:		0.428900
  validation accuracy:		87.93 %
Epoch 1645 of 2000 took 0.035s
  training loss:		0.161532
  validation loss:		0.439619
  validation accuracy:		87.93 %
Epoch 1646 of 2000 took 0.035s
  training loss:		0.158146
  validation loss:		0.425254
  validation accuracy:		87.93 %
Epoch 1647 of 2000 took 0.035s
  training loss:		0.162871
  validation loss:		0.429648
  validation accuracy:		88.37 %
Epoch 1648 of 2000 took 0.035s
  training loss:		0.157158
  validation loss:		0.442135
  validation accuracy:		87.17 %
Epoch 1649 of 2000 took 0.035s
  training loss:		0.154667
  validation loss:		0.435818
  validation accuracy:		88.48 %
Epoch 1650 of 2000 took 0.035s
  training loss:		0.157142
  validation loss:		0.428972
  validation accuracy:		89.02 %
Epoch 1651 of 2000 took 0.035s
  training loss:		0.161076
  validation loss:		0.428450
  validation accuracy:		88.37 %
Epoch 1652 of 2000 took 0.035s
  training loss:		0.159506
  validation loss:		0.430135
  validation accuracy:		88.48 %
Epoch 1653 of 2000 took 0.035s
  training loss:		0.158606
  validation loss:		0.474972
  validation accuracy:		86.52 %
Epoch 1654 of 2000 took 0.035s
  training loss:		0.163106
  validation loss:		0.440406
  validation accuracy:		88.04 %
Epoch 1655 of 2000 took 0.035s
  training loss:		0.157272
  validation loss:		0.446144
  validation accuracy:		87.83 %
Epoch 1656 of 2000 took 0.035s
  training loss:		0.153882
  validation loss:		0.434670
  validation accuracy:		88.37 %
Epoch 1657 of 2000 took 0.035s
  training loss:		0.155948
  validation loss:		0.429598
  validation accuracy:		88.04 %
Epoch 1658 of 2000 took 0.035s
  training loss:		0.156931
  validation loss:		0.451467
  validation accuracy:		88.48 %
Epoch 1659 of 2000 took 0.035s
  training loss:		0.164420
  validation loss:		0.439485
  validation accuracy:		88.59 %
Epoch 1660 of 2000 took 0.035s
  training loss:		0.159389
  validation loss:		0.430225
  validation accuracy:		88.80 %
Epoch 1661 of 2000 took 0.035s
  training loss:		0.156193
  validation loss:		0.434720
  validation accuracy:		88.48 %
Epoch 1662 of 2000 took 0.035s
  training loss:		0.160053
  validation loss:		0.444009
  validation accuracy:		87.72 %
Epoch 1663 of 2000 took 0.035s
  training loss:		0.157572
  validation loss:		0.442806
  validation accuracy:		88.26 %
Epoch 1664 of 2000 took 0.035s
  training loss:		0.154002
  validation loss:		0.437379
  validation accuracy:		88.37 %
Epoch 1665 of 2000 took 0.035s
  training loss:		0.163573
  validation loss:		0.421551
  validation accuracy:		88.70 %
Epoch 1666 of 2000 took 0.035s
  training loss:		0.156856
  validation loss:		0.437304
  validation accuracy:		88.04 %
Epoch 1667 of 2000 took 0.035s
  training loss:		0.164371
  validation loss:		0.435200
  validation accuracy:		88.26 %
Epoch 1668 of 2000 took 0.035s
  training loss:		0.158206
  validation loss:		0.428952
  validation accuracy:		88.48 %
Epoch 1669 of 2000 took 0.035s
  training loss:		0.157477
  validation loss:		0.432964
  validation accuracy:		88.04 %
Epoch 1670 of 2000 took 0.035s
  training loss:		0.159901
  validation loss:		0.445998
  validation accuracy:		88.04 %
Epoch 1671 of 2000 took 0.035s
  training loss:		0.154875
  validation loss:		0.446210
  validation accuracy:		88.48 %
Epoch 1672 of 2000 took 0.035s
  training loss:		0.154640
  validation loss:		0.438990
  validation accuracy:		88.04 %
Epoch 1673 of 2000 took 0.035s
  training loss:		0.160276
  validation loss:		0.448839
  validation accuracy:		88.48 %
Epoch 1674 of 2000 took 0.035s
  training loss:		0.164008
  validation loss:		0.445928
  validation accuracy:		88.15 %
Epoch 1675 of 2000 took 0.035s
  training loss:		0.156043
  validation loss:		0.446795
  validation accuracy:		87.61 %
Epoch 1676 of 2000 took 0.035s
  training loss:		0.159101
  validation loss:		0.457183
  validation accuracy:		87.17 %
Epoch 1677 of 2000 took 0.035s
  training loss:		0.163810
  validation loss:		0.453890
  validation accuracy:		87.83 %
Epoch 1678 of 2000 took 0.035s
  training loss:		0.162131
  validation loss:		0.448985
  validation accuracy:		88.70 %
Epoch 1679 of 2000 took 0.035s
  training loss:		0.155370
  validation loss:		0.446798
  validation accuracy:		87.50 %
Epoch 1680 of 2000 took 0.035s
  training loss:		0.156161
  validation loss:		0.434249
  validation accuracy:		88.59 %
Epoch 1681 of 2000 took 0.035s
  training loss:		0.154496
  validation loss:		0.455809
  validation accuracy:		87.93 %
Epoch 1682 of 2000 took 0.035s
  training loss:		0.161396
  validation loss:		0.433114
  validation accuracy:		88.26 %
Epoch 1683 of 2000 took 0.035s
  training loss:		0.155869
  validation loss:		0.438760
  validation accuracy:		88.70 %
Epoch 1684 of 2000 took 0.035s
  training loss:		0.155109
  validation loss:		0.439665
  validation accuracy:		87.83 %
Epoch 1685 of 2000 took 0.035s
  training loss:		0.161630
  validation loss:		0.447069
  validation accuracy:		87.93 %
Epoch 1686 of 2000 took 0.035s
  training loss:		0.159205
  validation loss:		0.433415
  validation accuracy:		89.46 %
Epoch 1687 of 2000 took 0.035s
  training loss:		0.159134
  validation loss:		0.424414
  validation accuracy:		90.00 %
Epoch 1688 of 2000 took 0.035s
  training loss:		0.161115
  validation loss:		0.425199
  validation accuracy:		88.48 %
Epoch 1689 of 2000 took 0.035s
  training loss:		0.156998
  validation loss:		0.428490
  validation accuracy:		88.37 %
Epoch 1690 of 2000 took 0.035s
  training loss:		0.156503
  validation loss:		0.427386
  validation accuracy:		88.15 %
Epoch 1691 of 2000 took 0.035s
  training loss:		0.160593
  validation loss:		0.421579
  validation accuracy:		89.57 %
Epoch 1692 of 2000 took 0.035s
  training loss:		0.158706
  validation loss:		0.447348
  validation accuracy:		87.83 %
Epoch 1693 of 2000 took 0.035s
  training loss:		0.158157
  validation loss:		0.426169
  validation accuracy:		89.13 %
Epoch 1694 of 2000 took 0.035s
  training loss:		0.156895
  validation loss:		0.453425
  validation accuracy:		87.50 %
Epoch 1695 of 2000 took 0.035s
  training loss:		0.159732
  validation loss:		0.432500
  validation accuracy:		88.80 %
Epoch 1696 of 2000 took 0.035s
  training loss:		0.154885
  validation loss:		0.461718
  validation accuracy:		87.17 %
Epoch 1697 of 2000 took 0.035s
  training loss:		0.161452
  validation loss:		0.437239
  validation accuracy:		88.37 %
Epoch 1698 of 2000 took 0.035s
  training loss:		0.159416
  validation loss:		0.429216
  validation accuracy:		88.59 %
Epoch 1699 of 2000 took 0.035s
  training loss:		0.158962
  validation loss:		0.449101
  validation accuracy:		88.59 %
Epoch 1700 of 2000 took 0.035s
  training loss:		0.159963
  validation loss:		0.455528
  validation accuracy:		87.28 %
Epoch 1701 of 2000 took 0.035s
  training loss:		0.163842
  validation loss:		0.442006
  validation accuracy:		87.72 %
Epoch 1702 of 2000 took 0.035s
  training loss:		0.156486
  validation loss:		0.437698
  validation accuracy:		88.70 %
Epoch 1703 of 2000 took 0.035s
  training loss:		0.158273
  validation loss:		0.452273
  validation accuracy:		87.72 %
Epoch 1704 of 2000 took 0.035s
  training loss:		0.154389
  validation loss:		0.469491
  validation accuracy:		88.15 %
Epoch 1705 of 2000 took 0.035s
  training loss:		0.153604
  validation loss:		0.439712
  validation accuracy:		88.37 %
Epoch 1706 of 2000 took 0.035s
  training loss:		0.148475
  validation loss:		0.440361
  validation accuracy:		88.91 %
Epoch 1707 of 2000 took 0.035s
  training loss:		0.154736
  validation loss:		0.444187
  validation accuracy:		87.93 %
Epoch 1708 of 2000 took 0.035s
  training loss:		0.156483
  validation loss:		0.451514
  validation accuracy:		88.15 %
Epoch 1709 of 2000 took 0.035s
  training loss:		0.157530
  validation loss:		0.447321
  validation accuracy:		87.61 %
Epoch 1710 of 2000 took 0.035s
  training loss:		0.163601
  validation loss:		0.447524
  validation accuracy:		88.70 %
Epoch 1711 of 2000 took 0.035s
  training loss:		0.154046
  validation loss:		0.447016
  validation accuracy:		88.37 %
Epoch 1712 of 2000 took 0.035s
  training loss:		0.153848
  validation loss:		0.450795
  validation accuracy:		87.83 %
Epoch 1713 of 2000 took 0.035s
  training loss:		0.157120
  validation loss:		0.441798
  validation accuracy:		89.35 %
Epoch 1714 of 2000 took 0.035s
  training loss:		0.160440
  validation loss:		0.430811
  validation accuracy:		88.91 %
Epoch 1715 of 2000 took 0.035s
  training loss:		0.161834
  validation loss:		0.437227
  validation accuracy:		88.26 %
Epoch 1716 of 2000 took 0.035s
  training loss:		0.158566
  validation loss:		0.425437
  validation accuracy:		88.70 %
Epoch 1717 of 2000 took 0.035s
  training loss:		0.154075
  validation loss:		0.442906
  validation accuracy:		88.15 %
Epoch 1718 of 2000 took 0.035s
  training loss:		0.158870
  validation loss:		0.441141
  validation accuracy:		88.48 %
Epoch 1719 of 2000 took 0.035s
  training loss:		0.157827
  validation loss:		0.439239
  validation accuracy:		87.93 %
Epoch 1720 of 2000 took 0.035s
  training loss:		0.156964
  validation loss:		0.444624
  validation accuracy:		88.26 %
Epoch 1721 of 2000 took 0.035s
  training loss:		0.156067
  validation loss:		0.428627
  validation accuracy:		89.24 %
Epoch 1722 of 2000 took 0.035s
  training loss:		0.156739
  validation loss:		0.474802
  validation accuracy:		87.39 %
Epoch 1723 of 2000 took 0.035s
  training loss:		0.157607
  validation loss:		0.449500
  validation accuracy:		87.72 %
Epoch 1724 of 2000 took 0.035s
  training loss:		0.160655
  validation loss:		0.443232
  validation accuracy:		87.93 %
Epoch 1725 of 2000 took 0.035s
  training loss:		0.156913
  validation loss:		0.436524
  validation accuracy:		88.59 %
Epoch 1726 of 2000 took 0.035s
  training loss:		0.154536
  validation loss:		0.428043
  validation accuracy:		89.24 %
Epoch 1727 of 2000 took 0.035s
  training loss:		0.160603
  validation loss:		0.429163
  validation accuracy:		88.70 %
Epoch 1728 of 2000 took 0.035s
  training loss:		0.156682
  validation loss:		0.449249
  validation accuracy:		88.70 %
Epoch 1729 of 2000 took 0.035s
  training loss:		0.157368
  validation loss:		0.450742
  validation accuracy:		88.80 %
Epoch 1730 of 2000 took 0.035s
  training loss:		0.150750
  validation loss:		0.442284
  validation accuracy:		88.15 %
Epoch 1731 of 2000 took 0.035s
  training loss:		0.156263
  validation loss:		0.463733
  validation accuracy:		87.39 %
Epoch 1732 of 2000 took 0.035s
  training loss:		0.159717
  validation loss:		0.455850
  validation accuracy:		87.17 %
Epoch 1733 of 2000 took 0.035s
  training loss:		0.160016
  validation loss:		0.439885
  validation accuracy:		88.48 %
Epoch 1734 of 2000 took 0.035s
  training loss:		0.159224
  validation loss:		0.449899
  validation accuracy:		88.15 %
Epoch 1735 of 2000 took 0.035s
  training loss:		0.158184
  validation loss:		0.447963
  validation accuracy:		87.83 %
Epoch 1736 of 2000 took 0.035s
  training loss:		0.158695
  validation loss:		0.436880
  validation accuracy:		89.24 %
Epoch 1737 of 2000 took 0.035s
  training loss:		0.160049
  validation loss:		0.436033
  validation accuracy:		88.48 %
Epoch 1738 of 2000 took 0.035s
  training loss:		0.158396
  validation loss:		0.466860
  validation accuracy:		87.17 %
Epoch 1739 of 2000 took 0.035s
  training loss:		0.162539
  validation loss:		0.450789
  validation accuracy:		88.80 %
Epoch 1740 of 2000 took 0.035s
  training loss:		0.162939
  validation loss:		0.435082
  validation accuracy:		88.48 %
Epoch 1741 of 2000 took 0.035s
  training loss:		0.153509
  validation loss:		0.458783
  validation accuracy:		88.37 %
Epoch 1742 of 2000 took 0.035s
  training loss:		0.156902
  validation loss:		0.461788
  validation accuracy:		88.70 %
Epoch 1743 of 2000 took 0.035s
  training loss:		0.160544
  validation loss:		0.453751
  validation accuracy:		87.50 %
Epoch 1744 of 2000 took 0.035s
  training loss:		0.153173
  validation loss:		0.431329
  validation accuracy:		88.91 %
Epoch 1745 of 2000 took 0.035s
  training loss:		0.155335
  validation loss:		0.454227
  validation accuracy:		87.50 %
Epoch 1746 of 2000 took 0.035s
  training loss:		0.154211
  validation loss:		0.443323
  validation accuracy:		88.48 %
Epoch 1747 of 2000 took 0.035s
  training loss:		0.153249
  validation loss:		0.449275
  validation accuracy:		88.59 %
Epoch 1748 of 2000 took 0.035s
  training loss:		0.155927
  validation loss:		0.452038
  validation accuracy:		87.83 %
Epoch 1749 of 2000 took 0.035s
  training loss:		0.154872
  validation loss:		0.460859
  validation accuracy:		87.50 %
Epoch 1750 of 2000 took 0.035s
  training loss:		0.155222
  validation loss:		0.462490
  validation accuracy:		87.28 %
Epoch 1751 of 2000 took 0.035s
  training loss:		0.153799
  validation loss:		0.455639
  validation accuracy:		88.04 %
Epoch 1752 of 2000 took 0.035s
  training loss:		0.158053
  validation loss:		0.455516
  validation accuracy:		87.72 %
Epoch 1753 of 2000 took 0.035s
  training loss:		0.158728
  validation loss:		0.463117
  validation accuracy:		87.83 %
Epoch 1754 of 2000 took 0.035s
  training loss:		0.166187
  validation loss:		0.462425
  validation accuracy:		87.72 %
Epoch 1755 of 2000 took 0.035s
  training loss:		0.154801
  validation loss:		0.436800
  validation accuracy:		88.26 %
Epoch 1756 of 2000 took 0.035s
  training loss:		0.150675
  validation loss:		0.456095
  validation accuracy:		87.61 %
Epoch 1757 of 2000 took 0.035s
  training loss:		0.152906
  validation loss:		0.440321
  validation accuracy:		88.26 %
Epoch 1758 of 2000 took 0.035s
  training loss:		0.158864
  validation loss:		0.457086
  validation accuracy:		87.39 %
Epoch 1759 of 2000 took 0.035s
  training loss:		0.156120
  validation loss:		0.445379
  validation accuracy:		87.83 %
Epoch 1760 of 2000 took 0.035s
  training loss:		0.163084
  validation loss:		0.458728
  validation accuracy:		87.50 %
Epoch 1761 of 2000 took 0.035s
  training loss:		0.157575
  validation loss:		0.427420
  validation accuracy:		89.13 %
Epoch 1762 of 2000 took 0.035s
  training loss:		0.154396
  validation loss:		0.449341
  validation accuracy:		87.61 %
Epoch 1763 of 2000 took 0.035s
  training loss:		0.155438
  validation loss:		0.443706
  validation accuracy:		87.93 %
Epoch 1764 of 2000 took 0.035s
  training loss:		0.153886
  validation loss:		0.455113
  validation accuracy:		87.83 %
Epoch 1765 of 2000 took 0.035s
  training loss:		0.152747
  validation loss:		0.438244
  validation accuracy:		89.46 %
Epoch 1766 of 2000 took 0.035s
  training loss:		0.152666
  validation loss:		0.453274
  validation accuracy:		87.61 %
Epoch 1767 of 2000 took 0.035s
  training loss:		0.154384
  validation loss:		0.456636
  validation accuracy:		88.04 %
Epoch 1768 of 2000 took 0.035s
  training loss:		0.153073
  validation loss:		0.454691
  validation accuracy:		87.61 %
Epoch 1769 of 2000 took 0.035s
  training loss:		0.154864
  validation loss:		0.436209
  validation accuracy:		88.48 %
Epoch 1770 of 2000 took 0.035s
  training loss:		0.159688
  validation loss:		0.436625
  validation accuracy:		89.24 %
Epoch 1771 of 2000 took 0.035s
  training loss:		0.159767
  validation loss:		0.472962
  validation accuracy:		88.70 %
Epoch 1772 of 2000 took 0.035s
  training loss:		0.157461
  validation loss:		0.441508
  validation accuracy:		87.93 %
Epoch 1773 of 2000 took 0.035s
  training loss:		0.155529
  validation loss:		0.449760
  validation accuracy:		87.72 %
Epoch 1774 of 2000 took 0.035s
  training loss:		0.154869
  validation loss:		0.438117
  validation accuracy:		89.13 %
Epoch 1775 of 2000 took 0.035s
  training loss:		0.155158
  validation loss:		0.437622
  validation accuracy:		88.59 %
Epoch 1776 of 2000 took 0.035s
  training loss:		0.151190
  validation loss:		0.451254
  validation accuracy:		88.80 %
Epoch 1777 of 2000 took 0.035s
  training loss:		0.158821
  validation loss:		0.436996
  validation accuracy:		88.48 %
Epoch 1778 of 2000 took 0.035s
  training loss:		0.156364
  validation loss:		0.434809
  validation accuracy:		88.80 %
Epoch 1779 of 2000 took 0.035s
  training loss:		0.152859
  validation loss:		0.440299
  validation accuracy:		88.91 %
Epoch 1780 of 2000 took 0.035s
  training loss:		0.159383
  validation loss:		0.453896
  validation accuracy:		87.50 %
Epoch 1781 of 2000 took 0.035s
  training loss:		0.157029
  validation loss:		0.436678
  validation accuracy:		88.70 %
Epoch 1782 of 2000 took 0.035s
  training loss:		0.156131
  validation loss:		0.442588
  validation accuracy:		88.37 %
Epoch 1783 of 2000 took 0.035s
  training loss:		0.155342
  validation loss:		0.448401
  validation accuracy:		89.13 %
Epoch 1784 of 2000 took 0.035s
  training loss:		0.154598
  validation loss:		0.450532
  validation accuracy:		88.15 %
Epoch 1785 of 2000 took 0.035s
  training loss:		0.153160
  validation loss:		0.446217
  validation accuracy:		88.26 %
Epoch 1786 of 2000 took 0.035s
  training loss:		0.147676
  validation loss:		0.461813
  validation accuracy:		87.61 %
Epoch 1787 of 2000 took 0.035s
  training loss:		0.158066
  validation loss:		0.449986
  validation accuracy:		88.59 %
Epoch 1788 of 2000 took 0.035s
  training loss:		0.158555
  validation loss:		0.440865
  validation accuracy:		88.70 %
Epoch 1789 of 2000 took 0.035s
  training loss:		0.157725
  validation loss:		0.452512
  validation accuracy:		87.72 %
Epoch 1790 of 2000 took 0.035s
  training loss:		0.153020
  validation loss:		0.448337
  validation accuracy:		87.93 %
Epoch 1791 of 2000 took 0.035s
  training loss:		0.159989
  validation loss:		0.448148
  validation accuracy:		87.61 %
Epoch 1792 of 2000 took 0.035s
  training loss:		0.155856
  validation loss:		0.461880
  validation accuracy:		87.50 %
Epoch 1793 of 2000 took 0.035s
  training loss:		0.152782
  validation loss:		0.447416
  validation accuracy:		88.04 %
Epoch 1794 of 2000 took 0.035s
  training loss:		0.149029
  validation loss:		0.447283
  validation accuracy:		88.37 %
Epoch 1795 of 2000 took 0.035s
  training loss:		0.154498
  validation loss:		0.445273
  validation accuracy:		88.80 %
Epoch 1796 of 2000 took 0.035s
  training loss:		0.154956
  validation loss:		0.453837
  validation accuracy:		87.61 %
Epoch 1797 of 2000 took 0.035s
  training loss:		0.156411
  validation loss:		0.475951
  validation accuracy:		87.17 %
Epoch 1798 of 2000 took 0.035s
  training loss:		0.152339
  validation loss:		0.439950
  validation accuracy:		89.02 %
Epoch 1799 of 2000 took 0.035s
  training loss:		0.154703
  validation loss:		0.451458
  validation accuracy:		87.83 %
Epoch 1800 of 2000 took 0.035s
  training loss:		0.156168
  validation loss:		0.435569
  validation accuracy:		89.02 %
Epoch 1801 of 2000 took 0.035s
  training loss:		0.156893
  validation loss:		0.468697
  validation accuracy:		87.28 %
Epoch 1802 of 2000 took 0.035s
  training loss:		0.157497
  validation loss:		0.441096
  validation accuracy:		88.26 %
Epoch 1803 of 2000 took 0.035s
  training loss:		0.148673
  validation loss:		0.449814
  validation accuracy:		87.61 %
Epoch 1804 of 2000 took 0.035s
  training loss:		0.154072
  validation loss:		0.443978
  validation accuracy:		88.70 %
Epoch 1805 of 2000 took 0.035s
  training loss:		0.156823
  validation loss:		0.446610
  validation accuracy:		88.26 %
Epoch 1806 of 2000 took 0.035s
  training loss:		0.151350
  validation loss:		0.437511
  validation accuracy:		89.24 %
Epoch 1807 of 2000 took 0.035s
  training loss:		0.150983
  validation loss:		0.447474
  validation accuracy:		88.70 %
Epoch 1808 of 2000 took 0.035s
  training loss:		0.161161
  validation loss:		0.447825
  validation accuracy:		88.48 %
Epoch 1809 of 2000 took 0.035s
  training loss:		0.149761
  validation loss:		0.465953
  validation accuracy:		87.61 %
Epoch 1810 of 2000 took 0.035s
  training loss:		0.153382
  validation loss:		0.462020
  validation accuracy:		87.39 %
Epoch 1811 of 2000 took 0.035s
  training loss:		0.156443
  validation loss:		0.465539
  validation accuracy:		87.17 %
Epoch 1812 of 2000 took 0.035s
  training loss:		0.154756
  validation loss:		0.469095
  validation accuracy:		88.04 %
Epoch 1813 of 2000 took 0.035s
  training loss:		0.155546
  validation loss:		0.479424
  validation accuracy:		87.50 %
Epoch 1814 of 2000 took 0.035s
  training loss:		0.155482
  validation loss:		0.460197
  validation accuracy:		88.91 %
Epoch 1815 of 2000 took 0.035s
  training loss:		0.156705
  validation loss:		0.462340
  validation accuracy:		87.72 %
Epoch 1816 of 2000 took 0.035s
  training loss:		0.157255
  validation loss:		0.453691
  validation accuracy:		88.15 %
Epoch 1817 of 2000 took 0.035s
  training loss:		0.159613
  validation loss:		0.460626
  validation accuracy:		88.48 %
Epoch 1818 of 2000 took 0.035s
  training loss:		0.157218
  validation loss:		0.466820
  validation accuracy:		88.37 %
Epoch 1819 of 2000 took 0.035s
  training loss:		0.156181
  validation loss:		0.457265
  validation accuracy:		88.80 %
Epoch 1820 of 2000 took 0.035s
  training loss:		0.161392
  validation loss:		0.444775
  validation accuracy:		88.80 %
Epoch 1821 of 2000 took 0.035s
  training loss:		0.148208
  validation loss:		0.468008
  validation accuracy:		88.91 %
Epoch 1822 of 2000 took 0.035s
  training loss:		0.160584
  validation loss:		0.444723
  validation accuracy:		88.37 %
Epoch 1823 of 2000 took 0.035s
  training loss:		0.156563
  validation loss:		0.449154
  validation accuracy:		88.04 %
Epoch 1824 of 2000 took 0.035s
  training loss:		0.152691
  validation loss:		0.451864
  validation accuracy:		87.72 %
Epoch 1825 of 2000 took 0.035s
  training loss:		0.153002
  validation loss:		0.450334
  validation accuracy:		88.48 %
Epoch 1826 of 2000 took 0.035s
  training loss:		0.154487
  validation loss:		0.444495
  validation accuracy:		88.37 %
Epoch 1827 of 2000 took 0.035s
  training loss:		0.152426
  validation loss:		0.476957
  validation accuracy:		87.93 %
Epoch 1828 of 2000 took 0.035s
  training loss:		0.157662
  validation loss:		0.445296
  validation accuracy:		88.26 %
Epoch 1829 of 2000 took 0.035s
  training loss:		0.156646
  validation loss:		0.451394
  validation accuracy:		88.37 %
Epoch 1830 of 2000 took 0.035s
  training loss:		0.153831
  validation loss:		0.441808
  validation accuracy:		88.91 %
Epoch 1831 of 2000 took 0.035s
  training loss:		0.147800
  validation loss:		0.452448
  validation accuracy:		88.04 %
Epoch 1832 of 2000 took 0.035s
  training loss:		0.155582
  validation loss:		0.459475
  validation accuracy:		88.04 %
Epoch 1833 of 2000 took 0.035s
  training loss:		0.153413
  validation loss:		0.460069
  validation accuracy:		88.04 %
Epoch 1834 of 2000 took 0.035s
  training loss:		0.151156
  validation loss:		0.470663
  validation accuracy:		86.74 %
Epoch 1835 of 2000 took 0.035s
  training loss:		0.153998
  validation loss:		0.476433
  validation accuracy:		87.50 %
Epoch 1836 of 2000 took 0.035s
  training loss:		0.156053
  validation loss:		0.462442
  validation accuracy:		87.93 %
Epoch 1837 of 2000 took 0.036s
  training loss:		0.152929
  validation loss:		0.451049
  validation accuracy:		88.15 %
Epoch 1838 of 2000 took 0.035s
  training loss:		0.153170
  validation loss:		0.464719
  validation accuracy:		88.48 %
Epoch 1839 of 2000 took 0.035s
  training loss:		0.159568
  validation loss:		0.449549
  validation accuracy:		89.02 %
Epoch 1840 of 2000 took 0.035s
  training loss:		0.152314
  validation loss:		0.440598
  validation accuracy:		89.35 %
Epoch 1841 of 2000 took 0.035s
  training loss:		0.150306
  validation loss:		0.454729
  validation accuracy:		88.59 %
Epoch 1842 of 2000 took 0.035s
  training loss:		0.158263
  validation loss:		0.445276
  validation accuracy:		88.91 %
Epoch 1843 of 2000 took 0.035s
  training loss:		0.151264
  validation loss:		0.443965
  validation accuracy:		88.37 %
Epoch 1844 of 2000 took 0.035s
  training loss:		0.158021
  validation loss:		0.447513
  validation accuracy:		88.80 %
Epoch 1845 of 2000 took 0.035s
  training loss:		0.159487
  validation loss:		0.445252
  validation accuracy:		88.37 %
Epoch 1846 of 2000 took 0.035s
  training loss:		0.161243
  validation loss:		0.454179
  validation accuracy:		88.04 %
Epoch 1847 of 2000 took 0.035s
  training loss:		0.160896
  validation loss:		0.442763
  validation accuracy:		89.24 %
Epoch 1848 of 2000 took 0.035s
  training loss:		0.152003
  validation loss:		0.458305
  validation accuracy:		87.61 %
Epoch 1849 of 2000 took 0.035s
  training loss:		0.152325
  validation loss:		0.455656
  validation accuracy:		88.37 %
Epoch 1850 of 2000 took 0.035s
  training loss:		0.159320
  validation loss:		0.456565
  validation accuracy:		87.72 %
Epoch 1851 of 2000 took 0.035s
  training loss:		0.150836
  validation loss:		0.457357
  validation accuracy:		88.48 %
Epoch 1852 of 2000 took 0.035s
  training loss:		0.156581
  validation loss:		0.458412
  validation accuracy:		87.61 %
Epoch 1853 of 2000 took 0.035s
  training loss:		0.160153
  validation loss:		0.477953
  validation accuracy:		87.72 %
Epoch 1854 of 2000 took 0.035s
  training loss:		0.157346
  validation loss:		0.454336
  validation accuracy:		88.48 %
Epoch 1855 of 2000 took 0.035s
  training loss:		0.151036
  validation loss:		0.442295
  validation accuracy:		88.48 %
Epoch 1856 of 2000 took 0.035s
  training loss:		0.152258
  validation loss:		0.456857
  validation accuracy:		89.57 %
Epoch 1857 of 2000 took 0.035s
  training loss:		0.157444
  validation loss:		0.448816
  validation accuracy:		89.13 %
Epoch 1858 of 2000 took 0.035s
  training loss:		0.155354
  validation loss:		0.446091
  validation accuracy:		88.15 %
Epoch 1859 of 2000 took 0.035s
  training loss:		0.159021
  validation loss:		0.472626
  validation accuracy:		88.70 %
Epoch 1860 of 2000 took 0.035s
  training loss:		0.151941
  validation loss:		0.463897
  validation accuracy:		87.28 %
Epoch 1861 of 2000 took 0.035s
  training loss:		0.152666
  validation loss:		0.463242
  validation accuracy:		87.83 %
Epoch 1862 of 2000 took 0.035s
  training loss:		0.155502
  validation loss:		0.481581
  validation accuracy:		87.07 %
Epoch 1863 of 2000 took 0.035s
  training loss:		0.154414
  validation loss:		0.504741
  validation accuracy:		87.50 %
Epoch 1864 of 2000 took 0.035s
  training loss:		0.166519
  validation loss:		0.479995
  validation accuracy:		88.59 %
Epoch 1865 of 2000 took 0.035s
  training loss:		0.154466
  validation loss:		0.460318
  validation accuracy:		88.48 %
Epoch 1866 of 2000 took 0.035s
  training loss:		0.146552
  validation loss:		0.462958
  validation accuracy:		88.70 %
Epoch 1867 of 2000 took 0.035s
  training loss:		0.154289
  validation loss:		0.461996
  validation accuracy:		87.39 %
Epoch 1868 of 2000 took 0.035s
  training loss:		0.154194
  validation loss:		0.449510
  validation accuracy:		89.24 %
Epoch 1869 of 2000 took 0.035s
  training loss:		0.152648
  validation loss:		0.456920
  validation accuracy:		88.37 %
Epoch 1870 of 2000 took 0.035s
  training loss:		0.154151
  validation loss:		0.442153
  validation accuracy:		88.70 %
Epoch 1871 of 2000 took 0.035s
  training loss:		0.153936
  validation loss:		0.449265
  validation accuracy:		88.04 %
Epoch 1872 of 2000 took 0.035s
  training loss:		0.151198
  validation loss:		0.474857
  validation accuracy:		87.28 %
Epoch 1873 of 2000 took 0.035s
  training loss:		0.154294
  validation loss:		0.457308
  validation accuracy:		88.80 %
Epoch 1874 of 2000 took 0.035s
  training loss:		0.155117
  validation loss:		0.485938
  validation accuracy:		86.63 %
Epoch 1875 of 2000 took 0.035s
  training loss:		0.151617
  validation loss:		0.451803
  validation accuracy:		88.48 %
Epoch 1876 of 2000 took 0.035s
  training loss:		0.157120
  validation loss:		0.470015
  validation accuracy:		87.50 %
Epoch 1877 of 2000 took 0.035s
  training loss:		0.151273
  validation loss:		0.472743
  validation accuracy:		88.15 %
Epoch 1878 of 2000 took 0.035s
  training loss:		0.156979
  validation loss:		0.445231
  validation accuracy:		88.48 %
Epoch 1879 of 2000 took 0.035s
  training loss:		0.150223
  validation loss:		0.455423
  validation accuracy:		88.59 %
Epoch 1880 of 2000 took 0.035s
  training loss:		0.152742
  validation loss:		0.450788
  validation accuracy:		89.02 %
Epoch 1881 of 2000 took 0.035s
  training loss:		0.154867
  validation loss:		0.459434
  validation accuracy:		87.61 %
Epoch 1882 of 2000 took 0.035s
  training loss:		0.154747
  validation loss:		0.477969
  validation accuracy:		87.72 %
Epoch 1883 of 2000 took 0.035s
  training loss:		0.153565
  validation loss:		0.463362
  validation accuracy:		87.39 %
Epoch 1884 of 2000 took 0.035s
  training loss:		0.155572
  validation loss:		0.487702
  validation accuracy:		87.83 %
Epoch 1885 of 2000 took 0.035s
  training loss:		0.151465
  validation loss:		0.448214
  validation accuracy:		88.91 %
Epoch 1886 of 2000 took 0.035s
  training loss:		0.155159
  validation loss:		0.444502
  validation accuracy:		88.48 %
Epoch 1887 of 2000 took 0.035s
  training loss:		0.149800
  validation loss:		0.459216
  validation accuracy:		88.04 %
Epoch 1888 of 2000 took 0.035s
  training loss:		0.155128
  validation loss:		0.451007
  validation accuracy:		88.15 %
Epoch 1889 of 2000 took 0.035s
  training loss:		0.154634
  validation loss:		0.442654
  validation accuracy:		89.02 %
Epoch 1890 of 2000 took 0.035s
  training loss:		0.149908
  validation loss:		0.463558
  validation accuracy:		87.83 %
Epoch 1891 of 2000 took 0.035s
  training loss:		0.152306
  validation loss:		0.476154
  validation accuracy:		88.37 %
Epoch 1892 of 2000 took 0.035s
  training loss:		0.144552
  validation loss:		0.452732
  validation accuracy:		87.93 %
Epoch 1893 of 2000 took 0.035s
  training loss:		0.147878
  validation loss:		0.450709
  validation accuracy:		88.37 %
Epoch 1894 of 2000 took 0.035s
  training loss:		0.150683
  validation loss:		0.455148
  validation accuracy:		88.59 %
Epoch 1895 of 2000 took 0.035s
  training loss:		0.153192
  validation loss:		0.466624
  validation accuracy:		86.96 %
Epoch 1896 of 2000 took 0.035s
  training loss:		0.156443
  validation loss:		0.462980
  validation accuracy:		88.15 %
Epoch 1897 of 2000 took 0.035s
  training loss:		0.152990
  validation loss:		0.472266
  validation accuracy:		87.83 %
Epoch 1898 of 2000 took 0.035s
  training loss:		0.157581
  validation loss:		0.456366
  validation accuracy:		88.91 %
Epoch 1899 of 2000 took 0.035s
  training loss:		0.146838
  validation loss:		0.472648
  validation accuracy:		88.80 %
Epoch 1900 of 2000 took 0.035s
  training loss:		0.158268
  validation loss:		0.460543
  validation accuracy:		87.93 %
Epoch 1901 of 2000 took 0.035s
  training loss:		0.149489
  validation loss:		0.469151
  validation accuracy:		88.04 %
Epoch 1902 of 2000 took 0.035s
  training loss:		0.146116
  validation loss:		0.456077
  validation accuracy:		88.15 %
Epoch 1903 of 2000 took 0.035s
  training loss:		0.149710
  validation loss:		0.449949
  validation accuracy:		88.48 %
Epoch 1904 of 2000 took 0.035s
  training loss:		0.154830
  validation loss:		0.468240
  validation accuracy:		88.04 %
Epoch 1905 of 2000 took 0.035s
  training loss:		0.146887
  validation loss:		0.473473
  validation accuracy:		87.61 %
Epoch 1906 of 2000 took 0.035s
  training loss:		0.155806
  validation loss:		0.465352
  validation accuracy:		88.04 %
Epoch 1907 of 2000 took 0.035s
  training loss:		0.154621
  validation loss:		0.444227
  validation accuracy:		90.00 %
Epoch 1908 of 2000 took 0.035s
  training loss:		0.159391
  validation loss:		0.498846
  validation accuracy:		87.61 %
Epoch 1909 of 2000 took 0.035s
  training loss:		0.151422
  validation loss:		0.449193
  validation accuracy:		88.37 %
Epoch 1910 of 2000 took 0.035s
  training loss:		0.145005
  validation loss:		0.452696
  validation accuracy:		88.26 %
Epoch 1911 of 2000 took 0.035s
  training loss:		0.156923
  validation loss:		0.466213
  validation accuracy:		87.83 %
Epoch 1912 of 2000 took 0.035s
  training loss:		0.155921
  validation loss:		0.458590
  validation accuracy:		88.15 %
Epoch 1913 of 2000 took 0.035s
  training loss:		0.152949
  validation loss:		0.461833
  validation accuracy:		87.83 %
Epoch 1914 of 2000 took 0.035s
  training loss:		0.149988
  validation loss:		0.472937
  validation accuracy:		87.28 %
Epoch 1915 of 2000 took 0.035s
  training loss:		0.149292
  validation loss:		0.451281
  validation accuracy:		88.48 %
Epoch 1916 of 2000 took 0.035s
  training loss:		0.157012
  validation loss:		0.461494
  validation accuracy:		89.02 %
Epoch 1917 of 2000 took 0.035s
  training loss:		0.158800
  validation loss:		0.456307
  validation accuracy:		89.57 %
Epoch 1918 of 2000 took 0.035s
  training loss:		0.149451
  validation loss:		0.457575
  validation accuracy:		89.24 %
Epoch 1919 of 2000 took 0.035s
  training loss:		0.154916
  validation loss:		0.466903
  validation accuracy:		88.48 %
Epoch 1920 of 2000 took 0.035s
  training loss:		0.150797
  validation loss:		0.449011
  validation accuracy:		88.70 %
Epoch 1921 of 2000 took 0.035s
  training loss:		0.147487
  validation loss:		0.464003
  validation accuracy:		87.50 %
Epoch 1922 of 2000 took 0.035s
  training loss:		0.151889
  validation loss:		0.452428
  validation accuracy:		88.26 %
Epoch 1923 of 2000 took 0.035s
  training loss:		0.154581
  validation loss:		0.474950
  validation accuracy:		88.59 %
Epoch 1924 of 2000 took 0.035s
  training loss:		0.153529
  validation loss:		0.450521
  validation accuracy:		89.24 %
Epoch 1925 of 2000 took 0.035s
  training loss:		0.151101
  validation loss:		0.455164
  validation accuracy:		88.80 %
Epoch 1926 of 2000 took 0.035s
  training loss:		0.152584
  validation loss:		0.458669
  validation accuracy:		88.91 %
Epoch 1927 of 2000 took 0.035s
  training loss:		0.157380
  validation loss:		0.453375
  validation accuracy:		89.13 %
Epoch 1928 of 2000 took 0.035s
  training loss:		0.154641
  validation loss:		0.466359
  validation accuracy:		88.15 %
Epoch 1929 of 2000 took 0.035s
  training loss:		0.156078
  validation loss:		0.461887
  validation accuracy:		88.91 %
Epoch 1930 of 2000 took 0.035s
  training loss:		0.147447
  validation loss:		0.453387
  validation accuracy:		88.80 %
Epoch 1931 of 2000 took 0.035s
  training loss:		0.149738
  validation loss:		0.453287
  validation accuracy:		88.26 %
Epoch 1932 of 2000 took 0.035s
  training loss:		0.152389
  validation loss:		0.476998
  validation accuracy:		89.24 %
Epoch 1933 of 2000 took 0.035s
  training loss:		0.148948
  validation loss:		0.453814
  validation accuracy:		89.24 %
Epoch 1934 of 2000 took 0.035s
  training loss:		0.147342
  validation loss:		0.455782
  validation accuracy:		88.04 %
Epoch 1935 of 2000 took 0.035s
  training loss:		0.153304
  validation loss:		0.449196
  validation accuracy:		88.91 %
Epoch 1936 of 2000 took 0.035s
  training loss:		0.154482
  validation loss:		0.449584
  validation accuracy:		88.80 %
Epoch 1937 of 2000 took 0.035s
  training loss:		0.154402
  validation loss:		0.456082
  validation accuracy:		89.02 %
Epoch 1938 of 2000 took 0.035s
  training loss:		0.157802
  validation loss:		0.462076
  validation accuracy:		88.26 %
Epoch 1939 of 2000 took 0.035s
  training loss:		0.155679
  validation loss:		0.469033
  validation accuracy:		88.26 %
Epoch 1940 of 2000 took 0.035s
  training loss:		0.149400
  validation loss:		0.460564
  validation accuracy:		88.59 %
Epoch 1941 of 2000 took 0.035s
  training loss:		0.155077
  validation loss:		0.448336
  validation accuracy:		88.70 %
Epoch 1942 of 2000 took 0.035s
  training loss:		0.151539
  validation loss:		0.451450
  validation accuracy:		88.26 %
Epoch 1943 of 2000 took 0.035s
  training loss:		0.151266
  validation loss:		0.463965
  validation accuracy:		88.48 %
Epoch 1944 of 2000 took 0.035s
  training loss:		0.151715
  validation loss:		0.447657
  validation accuracy:		89.24 %
Epoch 1945 of 2000 took 0.035s
  training loss:		0.144655
  validation loss:		0.464690
  validation accuracy:		87.39 %
Epoch 1946 of 2000 took 0.035s
  training loss:		0.150277
  validation loss:		0.468926
  validation accuracy:		88.04 %
Epoch 1947 of 2000 took 0.035s
  training loss:		0.154917
  validation loss:		0.456004
  validation accuracy:		89.57 %
Epoch 1948 of 2000 took 0.035s
  training loss:		0.152413
  validation loss:		0.466990
  validation accuracy:		88.04 %
Epoch 1949 of 2000 took 0.035s
  training loss:		0.153905
  validation loss:		0.453994
  validation accuracy:		88.26 %
Epoch 1950 of 2000 took 0.035s
  training loss:		0.148188
  validation loss:		0.460883
  validation accuracy:		88.37 %
Epoch 1951 of 2000 took 0.035s
  training loss:		0.153152
  validation loss:		0.469218
  validation accuracy:		87.83 %
Epoch 1952 of 2000 took 0.035s
  training loss:		0.152403
  validation loss:		0.457150
  validation accuracy:		88.37 %
Epoch 1953 of 2000 took 0.035s
  training loss:		0.153492
  validation loss:		0.454633
  validation accuracy:		88.48 %
Epoch 1954 of 2000 took 0.035s
  training loss:		0.153460
  validation loss:		0.480005
  validation accuracy:		87.28 %
Epoch 1955 of 2000 took 0.035s
  training loss:		0.149704
  validation loss:		0.481921
  validation accuracy:		87.07 %
Epoch 1956 of 2000 took 0.035s
  training loss:		0.154972
  validation loss:		0.476769
  validation accuracy:		89.02 %
Epoch 1957 of 2000 took 0.035s
  training loss:		0.156287
  validation loss:		0.452308
  validation accuracy:		88.91 %
Epoch 1958 of 2000 took 0.035s
  training loss:		0.148682
  validation loss:		0.462142
  validation accuracy:		87.61 %
Epoch 1959 of 2000 took 0.035s
  training loss:		0.151200
  validation loss:		0.455916
  validation accuracy:		88.80 %
Epoch 1960 of 2000 took 0.035s
  training loss:		0.150766
  validation loss:		0.463025
  validation accuracy:		87.61 %
Epoch 1961 of 2000 took 0.035s
  training loss:		0.151894
  validation loss:		0.458339
  validation accuracy:		88.15 %
Epoch 1962 of 2000 took 0.035s
  training loss:		0.152597
  validation loss:		0.450248
  validation accuracy:		88.80 %
Epoch 1963 of 2000 took 0.035s
  training loss:		0.152030
  validation loss:		0.470731
  validation accuracy:		87.28 %
Epoch 1964 of 2000 took 0.035s
  training loss:		0.152885
  validation loss:		0.449269
  validation accuracy:		89.46 %
Epoch 1965 of 2000 took 0.035s
  training loss:		0.151387
  validation loss:		0.461742
  validation accuracy:		88.26 %
Epoch 1966 of 2000 took 0.035s
  training loss:		0.147080
  validation loss:		0.454528
  validation accuracy:		89.13 %
Epoch 1967 of 2000 took 0.035s
  training loss:		0.149833
  validation loss:		0.474417
  validation accuracy:		87.61 %
Epoch 1968 of 2000 took 0.035s
  training loss:		0.150310
  validation loss:		0.465480
  validation accuracy:		88.80 %
Epoch 1969 of 2000 took 0.035s
  training loss:		0.155261
  validation loss:		0.466288
  validation accuracy:		88.26 %
Epoch 1970 of 2000 took 0.035s
  training loss:		0.154324
  validation loss:		0.489834
  validation accuracy:		86.96 %
Epoch 1971 of 2000 took 0.035s
  training loss:		0.154479
  validation loss:		0.456260
  validation accuracy:		88.80 %
Epoch 1972 of 2000 took 0.035s
  training loss:		0.158586
  validation loss:		0.478116
  validation accuracy:		87.50 %
Epoch 1973 of 2000 took 0.035s
  training loss:		0.152582
  validation loss:		0.456683
  validation accuracy:		88.59 %
Epoch 1974 of 2000 took 0.035s
  training loss:		0.147936
  validation loss:		0.462596
  validation accuracy:		87.93 %
Epoch 1975 of 2000 took 0.035s
  training loss:		0.153502
  validation loss:		0.451898
  validation accuracy:		88.91 %
Epoch 1976 of 2000 took 0.035s
  training loss:		0.147945
  validation loss:		0.461568
  validation accuracy:		87.93 %
Epoch 1977 of 2000 took 0.035s
  training loss:		0.147917
  validation loss:		0.470914
  validation accuracy:		87.61 %
Epoch 1978 of 2000 took 0.035s
  training loss:		0.150821
  validation loss:		0.465905
  validation accuracy:		87.72 %
Epoch 1979 of 2000 took 0.035s
  training loss:		0.142846
  validation loss:		0.467522
  validation accuracy:		88.04 %
Epoch 1980 of 2000 took 0.035s
  training loss:		0.152392
  validation loss:		0.476230
  validation accuracy:		88.59 %
Epoch 1981 of 2000 took 0.035s
  training loss:		0.149325
  validation loss:		0.451529
  validation accuracy:		88.70 %
Epoch 1982 of 2000 took 0.035s
  training loss:		0.154270
  validation loss:		0.466599
  validation accuracy:		87.61 %
Epoch 1983 of 2000 took 0.035s
  training loss:		0.151852
  validation loss:		0.457034
  validation accuracy:		88.59 %
Epoch 1984 of 2000 took 0.035s
  training loss:		0.153835
  validation loss:		0.453619
  validation accuracy:		88.80 %
Epoch 1985 of 2000 took 0.035s
  training loss:		0.150602
  validation loss:		0.455475
  validation accuracy:		89.02 %
Epoch 1986 of 2000 took 0.035s
  training loss:		0.148176
  validation loss:		0.465195
  validation accuracy:		88.26 %
Epoch 1987 of 2000 took 0.035s
  training loss:		0.144903
  validation loss:		0.466074
  validation accuracy:		89.78 %
Epoch 1988 of 2000 took 0.035s
  training loss:		0.151864
  validation loss:		0.490866
  validation accuracy:		88.26 %
Epoch 1989 of 2000 took 0.035s
  training loss:		0.153972
  validation loss:		0.464765
  validation accuracy:		88.04 %
Epoch 1990 of 2000 took 0.035s
  training loss:		0.155791
  validation loss:		0.471333
  validation accuracy:		88.26 %
Epoch 1991 of 2000 took 0.035s
  training loss:		0.146970
  validation loss:		0.459291
  validation accuracy:		89.24 %
Epoch 1992 of 2000 took 0.035s
  training loss:		0.154576
  validation loss:		0.471743
  validation accuracy:		88.37 %
Epoch 1993 of 2000 took 0.035s
  training loss:		0.152364
  validation loss:		0.459006
  validation accuracy:		89.57 %
Epoch 1994 of 2000 took 0.035s
  training loss:		0.151958
  validation loss:		0.450204
  validation accuracy:		89.02 %
Epoch 1995 of 2000 took 0.035s
  training loss:		0.145577
  validation loss:		0.473329
  validation accuracy:		88.04 %
Epoch 1996 of 2000 took 0.035s
  training loss:		0.153748
  validation loss:		0.461512
  validation accuracy:		88.80 %
Epoch 1997 of 2000 took 0.035s
  training loss:		0.149871
  validation loss:		0.466855
  validation accuracy:		89.46 %
Epoch 1998 of 2000 took 0.035s
  training loss:		0.156654
  validation loss:		0.452430
  validation accuracy:		89.24 %
Epoch 1999 of 2000 took 0.035s
  training loss:		0.161774
  validation loss:		0.474975
  validation accuracy:		88.04 %
Epoch 2000 of 2000 took 0.035s
  training loss:		0.156219
  validation loss:		0.479898
  validation accuracy:		87.07 %
Final results:
  test loss:			0.978662
  test accuracy:		80.40 %
