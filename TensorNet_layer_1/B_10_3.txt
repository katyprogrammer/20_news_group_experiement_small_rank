Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 200),b=(200,)
decomposing tensor W of shape (1, 200, 200)...
decomposing tensor B of shape (1, 200)...
Starting training...
Epoch 1 of 2000 took 0.043s
  training loss:		2.960870
  validation loss:		2.867937
  validation accuracy:		23.48 %
Epoch 2 of 2000 took 0.038s
  training loss:		2.796229
  validation loss:		2.661333
  validation accuracy:		28.59 %
Epoch 3 of 2000 took 0.035s
  training loss:		2.604138
  validation loss:		2.452055
  validation accuracy:		32.39 %
Epoch 4 of 2000 took 0.035s
  training loss:		2.434927
  validation loss:		2.290850
  validation accuracy:		40.98 %
Epoch 5 of 2000 took 0.035s
  training loss:		2.320121
  validation loss:		2.208278
  validation accuracy:		48.37 %
Epoch 6 of 2000 took 0.035s
  training loss:		2.256101
  validation loss:		2.173127
  validation accuracy:		50.76 %
Epoch 7 of 2000 took 0.035s
  training loss:		2.215999
  validation loss:		2.140556
  validation accuracy:		48.26 %
Epoch 8 of 2000 took 0.035s
  training loss:		2.184591
  validation loss:		2.109277
  validation accuracy:		52.28 %
Epoch 9 of 2000 took 0.035s
  training loss:		2.157098
  validation loss:		2.077260
  validation accuracy:		56.74 %
Epoch 10 of 2000 took 0.035s
  training loss:		2.129869
  validation loss:		2.054055
  validation accuracy:		54.67 %
Epoch 11 of 2000 took 0.035s
  training loss:		2.100303
  validation loss:		2.017714
  validation accuracy:		54.78 %
Epoch 12 of 2000 took 0.035s
  training loss:		2.068389
  validation loss:		1.983029
  validation accuracy:		58.59 %
Epoch 13 of 2000 took 0.035s
  training loss:		2.032252
  validation loss:		1.936229
  validation accuracy:		57.83 %
Epoch 14 of 2000 took 0.035s
  training loss:		1.996599
  validation loss:		1.905550
  validation accuracy:		56.41 %
Epoch 15 of 2000 took 0.035s
  training loss:		1.953169
  validation loss:		1.851653
  validation accuracy:		59.24 %
Epoch 16 of 2000 took 0.035s
  training loss:		1.909256
  validation loss:		1.802054
  validation accuracy:		59.78 %
Epoch 17 of 2000 took 0.038s
  training loss:		1.860933
  validation loss:		1.753217
  validation accuracy:		60.65 %
Epoch 18 of 2000 took 0.035s
  training loss:		1.806621
  validation loss:		1.697940
  validation accuracy:		60.98 %
Epoch 19 of 2000 took 0.035s
  training loss:		1.753333
  validation loss:		1.635074
  validation accuracy:		65.00 %
Epoch 20 of 2000 took 0.035s
  training loss:		1.694666
  validation loss:		1.572459
  validation accuracy:		64.46 %
Epoch 21 of 2000 took 0.035s
  training loss:		1.639446
  validation loss:		1.518107
  validation accuracy:		66.09 %
Epoch 22 of 2000 took 0.035s
  training loss:		1.581394
  validation loss:		1.455248
  validation accuracy:		67.61 %
Epoch 23 of 2000 took 0.035s
  training loss:		1.519912
  validation loss:		1.398986
  validation accuracy:		67.17 %
Epoch 24 of 2000 took 0.035s
  training loss:		1.466484
  validation loss:		1.345150
  validation accuracy:		70.00 %
Epoch 25 of 2000 took 0.035s
  training loss:		1.414963
  validation loss:		1.291553
  validation accuracy:		70.43 %
Epoch 26 of 2000 took 0.035s
  training loss:		1.357742
  validation loss:		1.238052
  validation accuracy:		69.35 %
Epoch 27 of 2000 took 0.035s
  training loss:		1.308209
  validation loss:		1.197863
  validation accuracy:		71.85 %
Epoch 28 of 2000 took 0.035s
  training loss:		1.267184
  validation loss:		1.157085
  validation accuracy:		73.80 %
Epoch 29 of 2000 took 0.035s
  training loss:		1.219177
  validation loss:		1.114158
  validation accuracy:		73.70 %
Epoch 30 of 2000 took 0.035s
  training loss:		1.181510
  validation loss:		1.078044
  validation accuracy:		74.02 %
Epoch 31 of 2000 took 0.035s
  training loss:		1.143655
  validation loss:		1.047232
  validation accuracy:		72.93 %
Epoch 32 of 2000 took 0.035s
  training loss:		1.110554
  validation loss:		1.015523
  validation accuracy:		74.57 %
Epoch 33 of 2000 took 0.035s
  training loss:		1.073305
  validation loss:		0.972865
  validation accuracy:		75.54 %
Epoch 34 of 2000 took 0.035s
  training loss:		1.039122
  validation loss:		0.939160
  validation accuracy:		76.63 %
Epoch 35 of 2000 took 0.035s
  training loss:		1.006763
  validation loss:		0.926384
  validation accuracy:		76.85 %
Epoch 36 of 2000 took 0.035s
  training loss:		0.973783
  validation loss:		0.890177
  validation accuracy:		77.72 %
Epoch 37 of 2000 took 0.035s
  training loss:		0.947390
  validation loss:		0.863158
  validation accuracy:		77.39 %
Epoch 38 of 2000 took 0.035s
  training loss:		0.922655
  validation loss:		0.832236
  validation accuracy:		78.37 %
Epoch 39 of 2000 took 0.035s
  training loss:		0.900148
  validation loss:		0.807622
  validation accuracy:		78.26 %
Epoch 40 of 2000 took 0.035s
  training loss:		0.873240
  validation loss:		0.784644
  validation accuracy:		79.67 %
Epoch 41 of 2000 took 0.035s
  training loss:		0.848269
  validation loss:		0.775613
  validation accuracy:		79.24 %
Epoch 42 of 2000 took 0.035s
  training loss:		0.828553
  validation loss:		0.735559
  validation accuracy:		80.65 %
Epoch 43 of 2000 took 0.035s
  training loss:		0.804405
  validation loss:		0.734128
  validation accuracy:		80.43 %
Epoch 44 of 2000 took 0.035s
  training loss:		0.774419
  validation loss:		0.702163
  validation accuracy:		81.30 %
Epoch 45 of 2000 took 0.035s
  training loss:		0.761399
  validation loss:		0.684310
  validation accuracy:		82.39 %
Epoch 46 of 2000 took 0.035s
  training loss:		0.745309
  validation loss:		0.677923
  validation accuracy:		81.52 %
Epoch 47 of 2000 took 0.035s
  training loss:		0.724039
  validation loss:		0.660363
  validation accuracy:		83.04 %
Epoch 48 of 2000 took 0.035s
  training loss:		0.702601
  validation loss:		0.642628
  validation accuracy:		83.15 %
Epoch 49 of 2000 took 0.035s
  training loss:		0.685291
  validation loss:		0.612902
  validation accuracy:		84.02 %
Epoch 50 of 2000 took 0.035s
  training loss:		0.667524
  validation loss:		0.600883
  validation accuracy:		84.67 %
Epoch 51 of 2000 took 0.035s
  training loss:		0.652356
  validation loss:		0.590406
  validation accuracy:		85.22 %
Epoch 52 of 2000 took 0.035s
  training loss:		0.634146
  validation loss:		0.581094
  validation accuracy:		84.13 %
Epoch 53 of 2000 took 0.035s
  training loss:		0.613699
  validation loss:		0.554484
  validation accuracy:		85.76 %
Epoch 54 of 2000 took 0.035s
  training loss:		0.598899
  validation loss:		0.547486
  validation accuracy:		85.11 %
Epoch 55 of 2000 took 0.035s
  training loss:		0.587437
  validation loss:		0.533607
  validation accuracy:		86.09 %
Epoch 56 of 2000 took 0.035s
  training loss:		0.573347
  validation loss:		0.521148
  validation accuracy:		86.41 %
Epoch 57 of 2000 took 0.035s
  training loss:		0.561658
  validation loss:		0.507184
  validation accuracy:		86.30 %
Epoch 58 of 2000 took 0.035s
  training loss:		0.553027
  validation loss:		0.506206
  validation accuracy:		85.98 %
Epoch 59 of 2000 took 0.035s
  training loss:		0.539132
  validation loss:		0.485399
  validation accuracy:		87.50 %
Epoch 60 of 2000 took 0.035s
  training loss:		0.527185
  validation loss:		0.474947
  validation accuracy:		87.83 %
Epoch 61 of 2000 took 0.035s
  training loss:		0.517510
  validation loss:		0.462716
  validation accuracy:		87.72 %
Epoch 62 of 2000 took 0.035s
  training loss:		0.501495
  validation loss:		0.456761
  validation accuracy:		87.83 %
Epoch 63 of 2000 took 0.035s
  training loss:		0.496745
  validation loss:		0.448745
  validation accuracy:		88.04 %
Epoch 64 of 2000 took 0.035s
  training loss:		0.491304
  validation loss:		0.434726
  validation accuracy:		88.37 %
Epoch 65 of 2000 took 0.035s
  training loss:		0.474147
  validation loss:		0.433804
  validation accuracy:		88.26 %
Epoch 66 of 2000 took 0.035s
  training loss:		0.466043
  validation loss:		0.421126
  validation accuracy:		88.37 %
Epoch 67 of 2000 took 0.035s
  training loss:		0.460468
  validation loss:		0.414947
  validation accuracy:		88.37 %
Epoch 68 of 2000 took 0.035s
  training loss:		0.452034
  validation loss:		0.409131
  validation accuracy:		88.70 %
Epoch 69 of 2000 took 0.035s
  training loss:		0.445694
  validation loss:		0.411610
  validation accuracy:		88.37 %
Epoch 70 of 2000 took 0.035s
  training loss:		0.437476
  validation loss:		0.411672
  validation accuracy:		88.48 %
Epoch 71 of 2000 took 0.035s
  training loss:		0.427637
  validation loss:		0.396106
  validation accuracy:		88.48 %
Epoch 72 of 2000 took 0.035s
  training loss:		0.425265
  validation loss:		0.383589
  validation accuracy:		89.67 %
Epoch 73 of 2000 took 0.035s
  training loss:		0.410015
  validation loss:		0.385691
  validation accuracy:		89.13 %
Epoch 74 of 2000 took 0.035s
  training loss:		0.410846
  validation loss:		0.385024
  validation accuracy:		88.91 %
Epoch 75 of 2000 took 0.035s
  training loss:		0.405917
  validation loss:		0.379705
  validation accuracy:		89.35 %
Epoch 76 of 2000 took 0.035s
  training loss:		0.398074
  validation loss:		0.361270
  validation accuracy:		89.35 %
Epoch 77 of 2000 took 0.035s
  training loss:		0.386912
  validation loss:		0.360729
  validation accuracy:		88.91 %
Epoch 78 of 2000 took 0.035s
  training loss:		0.381936
  validation loss:		0.364344
  validation accuracy:		89.78 %
Epoch 79 of 2000 took 0.035s
  training loss:		0.376825
  validation loss:		0.346037
  validation accuracy:		89.35 %
Epoch 80 of 2000 took 0.035s
  training loss:		0.374346
  validation loss:		0.359044
  validation accuracy:		89.78 %
Epoch 81 of 2000 took 0.037s
  training loss:		0.364692
  validation loss:		0.349656
  validation accuracy:		89.78 %
Epoch 82 of 2000 took 0.035s
  training loss:		0.362397
  validation loss:		0.336912
  validation accuracy:		90.22 %
Epoch 83 of 2000 took 0.035s
  training loss:		0.361302
  validation loss:		0.333033
  validation accuracy:		90.87 %
Epoch 84 of 2000 took 0.035s
  training loss:		0.353707
  validation loss:		0.344431
  validation accuracy:		89.89 %
Epoch 85 of 2000 took 0.035s
  training loss:		0.353689
  validation loss:		0.327585
  validation accuracy:		90.87 %
Epoch 86 of 2000 took 0.035s
  training loss:		0.348541
  validation loss:		0.324179
  validation accuracy:		90.33 %
Epoch 87 of 2000 took 0.035s
  training loss:		0.338997
  validation loss:		0.323556
  validation accuracy:		90.43 %
Epoch 88 of 2000 took 0.035s
  training loss:		0.341550
  validation loss:		0.329998
  validation accuracy:		90.33 %
Epoch 89 of 2000 took 0.035s
  training loss:		0.330289
  validation loss:		0.323920
  validation accuracy:		90.43 %
Epoch 90 of 2000 took 0.035s
  training loss:		0.333365
  validation loss:		0.331112
  validation accuracy:		90.22 %
Epoch 91 of 2000 took 0.035s
  training loss:		0.329551
  validation loss:		0.317680
  validation accuracy:		90.76 %
Epoch 92 of 2000 took 0.035s
  training loss:		0.324428
  validation loss:		0.313628
  validation accuracy:		91.09 %
Epoch 93 of 2000 took 0.035s
  training loss:		0.326349
  validation loss:		0.310135
  validation accuracy:		90.76 %
Epoch 94 of 2000 took 0.035s
  training loss:		0.315062
  validation loss:		0.313411
  validation accuracy:		91.30 %
Epoch 95 of 2000 took 0.035s
  training loss:		0.316830
  validation loss:		0.310818
  validation accuracy:		91.20 %
Epoch 96 of 2000 took 0.035s
  training loss:		0.312776
  validation loss:		0.301743
  validation accuracy:		91.52 %
Epoch 97 of 2000 took 0.035s
  training loss:		0.310556
  validation loss:		0.307028
  validation accuracy:		91.41 %
Epoch 98 of 2000 took 0.035s
  training loss:		0.307188
  validation loss:		0.296553
  validation accuracy:		91.41 %
Epoch 99 of 2000 took 0.035s
  training loss:		0.304738
  validation loss:		0.295206
  validation accuracy:		90.98 %
Epoch 100 of 2000 took 0.035s
  training loss:		0.297560
  validation loss:		0.299038
  validation accuracy:		91.30 %
Epoch 101 of 2000 took 0.035s
  training loss:		0.294892
  validation loss:		0.293623
  validation accuracy:		91.52 %
Epoch 102 of 2000 took 0.035s
  training loss:		0.293023
  validation loss:		0.285619
  validation accuracy:		91.41 %
Epoch 103 of 2000 took 0.035s
  training loss:		0.289571
  validation loss:		0.287393
  validation accuracy:		91.85 %
Epoch 104 of 2000 took 0.035s
  training loss:		0.284384
  validation loss:		0.288147
  validation accuracy:		91.52 %
Epoch 105 of 2000 took 0.035s
  training loss:		0.285600
  validation loss:		0.279372
  validation accuracy:		91.74 %
Epoch 106 of 2000 took 0.035s
  training loss:		0.285767
  validation loss:		0.274681
  validation accuracy:		91.74 %
Epoch 107 of 2000 took 0.035s
  training loss:		0.281850
  validation loss:		0.282421
  validation accuracy:		91.52 %
Epoch 108 of 2000 took 0.035s
  training loss:		0.281238
  validation loss:		0.282612
  validation accuracy:		91.74 %
Epoch 109 of 2000 took 0.035s
  training loss:		0.274207
  validation loss:		0.274735
  validation accuracy:		92.07 %
Epoch 110 of 2000 took 0.035s
  training loss:		0.275174
  validation loss:		0.274401
  validation accuracy:		91.63 %
Epoch 111 of 2000 took 0.035s
  training loss:		0.273987
  validation loss:		0.275404
  validation accuracy:		92.07 %
Epoch 112 of 2000 took 0.035s
  training loss:		0.267990
  validation loss:		0.264934
  validation accuracy:		92.28 %
Epoch 113 of 2000 took 0.035s
  training loss:		0.266493
  validation loss:		0.268699
  validation accuracy:		92.17 %
Epoch 114 of 2000 took 0.035s
  training loss:		0.267468
  validation loss:		0.270483
  validation accuracy:		92.17 %
Epoch 115 of 2000 took 0.035s
  training loss:		0.259838
  validation loss:		0.268788
  validation accuracy:		92.07 %
Epoch 116 of 2000 took 0.035s
  training loss:		0.261337
  validation loss:		0.268959
  validation accuracy:		92.17 %
Epoch 117 of 2000 took 0.035s
  training loss:		0.260928
  validation loss:		0.269790
  validation accuracy:		92.39 %
Epoch 118 of 2000 took 0.035s
  training loss:		0.257576
  validation loss:		0.270218
  validation accuracy:		91.96 %
Epoch 119 of 2000 took 0.035s
  training loss:		0.257194
  validation loss:		0.264974
  validation accuracy:		92.28 %
Epoch 120 of 2000 took 0.035s
  training loss:		0.253408
  validation loss:		0.263560
  validation accuracy:		92.61 %
Epoch 121 of 2000 took 0.035s
  training loss:		0.251932
  validation loss:		0.261346
  validation accuracy:		92.39 %
Epoch 122 of 2000 took 0.035s
  training loss:		0.241576
  validation loss:		0.255563
  validation accuracy:		92.93 %
Epoch 123 of 2000 took 0.035s
  training loss:		0.253150
  validation loss:		0.260128
  validation accuracy:		92.39 %
Epoch 124 of 2000 took 0.035s
  training loss:		0.248617
  validation loss:		0.256362
  validation accuracy:		92.61 %
Epoch 125 of 2000 took 0.035s
  training loss:		0.245997
  validation loss:		0.255427
  validation accuracy:		92.50 %
Epoch 126 of 2000 took 0.035s
  training loss:		0.242149
  validation loss:		0.263755
  validation accuracy:		91.96 %
Epoch 127 of 2000 took 0.035s
  training loss:		0.240063
  validation loss:		0.254249
  validation accuracy:		92.61 %
Epoch 128 of 2000 took 0.035s
  training loss:		0.241764
  validation loss:		0.256269
  validation accuracy:		92.50 %
Epoch 129 of 2000 took 0.035s
  training loss:		0.239783
  validation loss:		0.248115
  validation accuracy:		92.83 %
Epoch 130 of 2000 took 0.035s
  training loss:		0.231845
  validation loss:		0.249337
  validation accuracy:		92.83 %
Epoch 131 of 2000 took 0.035s
  training loss:		0.233106
  validation loss:		0.255803
  validation accuracy:		92.50 %
Epoch 132 of 2000 took 0.035s
  training loss:		0.230372
  validation loss:		0.244542
  validation accuracy:		92.72 %
Epoch 133 of 2000 took 0.035s
  training loss:		0.228869
  validation loss:		0.246612
  validation accuracy:		93.04 %
Epoch 134 of 2000 took 0.035s
  training loss:		0.234257
  validation loss:		0.243783
  validation accuracy:		92.72 %
Epoch 135 of 2000 took 0.035s
  training loss:		0.230226
  validation loss:		0.248001
  validation accuracy:		92.83 %
Epoch 136 of 2000 took 0.035s
  training loss:		0.230663
  validation loss:		0.243027
  validation accuracy:		93.04 %
Epoch 137 of 2000 took 0.035s
  training loss:		0.227778
  validation loss:		0.247431
  validation accuracy:		92.93 %
Epoch 138 of 2000 took 0.035s
  training loss:		0.224757
  validation loss:		0.240766
  validation accuracy:		92.93 %
Epoch 139 of 2000 took 0.035s
  training loss:		0.218431
  validation loss:		0.242112
  validation accuracy:		92.83 %
Epoch 140 of 2000 took 0.035s
  training loss:		0.219055
  validation loss:		0.237836
  validation accuracy:		93.26 %
Epoch 141 of 2000 took 0.035s
  training loss:		0.219495
  validation loss:		0.237514
  validation accuracy:		92.93 %
Epoch 142 of 2000 took 0.035s
  training loss:		0.214704
  validation loss:		0.246342
  validation accuracy:		92.93 %
Epoch 143 of 2000 took 0.035s
  training loss:		0.219941
  validation loss:		0.235700
  validation accuracy:		92.93 %
Epoch 144 of 2000 took 0.035s
  training loss:		0.217506
  validation loss:		0.234258
  validation accuracy:		93.04 %
Epoch 145 of 2000 took 0.035s
  training loss:		0.214096
  validation loss:		0.236302
  validation accuracy:		93.26 %
Epoch 146 of 2000 took 0.035s
  training loss:		0.211459
  validation loss:		0.229912
  validation accuracy:		93.26 %
Epoch 147 of 2000 took 0.035s
  training loss:		0.211970
  validation loss:		0.244458
  validation accuracy:		92.50 %
Epoch 148 of 2000 took 0.035s
  training loss:		0.209704
  validation loss:		0.233684
  validation accuracy:		93.04 %
Epoch 149 of 2000 took 0.035s
  training loss:		0.209755
  validation loss:		0.232584
  validation accuracy:		93.26 %
Epoch 150 of 2000 took 0.035s
  training loss:		0.211620
  validation loss:		0.235927
  validation accuracy:		93.26 %
Epoch 151 of 2000 took 0.035s
  training loss:		0.207505
  validation loss:		0.237773
  validation accuracy:		92.61 %
Epoch 152 of 2000 took 0.035s
  training loss:		0.206145
  validation loss:		0.236429
  validation accuracy:		93.04 %
Epoch 153 of 2000 took 0.035s
  training loss:		0.207530
  validation loss:		0.238018
  validation accuracy:		93.15 %
Epoch 154 of 2000 took 0.035s
  training loss:		0.207516
  validation loss:		0.238820
  validation accuracy:		92.50 %
Epoch 155 of 2000 took 0.035s
  training loss:		0.202956
  validation loss:		0.231232
  validation accuracy:		93.26 %
Epoch 156 of 2000 took 0.035s
  training loss:		0.203248
  validation loss:		0.237876
  validation accuracy:		92.83 %
Epoch 157 of 2000 took 0.035s
  training loss:		0.199320
  validation loss:		0.233019
  validation accuracy:		92.83 %
Epoch 158 of 2000 took 0.035s
  training loss:		0.197105
  validation loss:		0.230606
  validation accuracy:		92.72 %
Epoch 159 of 2000 took 0.035s
  training loss:		0.200775
  validation loss:		0.227007
  validation accuracy:		93.15 %
Epoch 160 of 2000 took 0.035s
  training loss:		0.192278
  validation loss:		0.226898
  validation accuracy:		93.15 %
Epoch 161 of 2000 took 0.035s
  training loss:		0.193933
  validation loss:		0.226721
  validation accuracy:		93.15 %
Epoch 162 of 2000 took 0.035s
  training loss:		0.196694
  validation loss:		0.232155
  validation accuracy:		92.83 %
Epoch 163 of 2000 took 0.035s
  training loss:		0.192308
  validation loss:		0.227532
  validation accuracy:		93.26 %
Epoch 164 of 2000 took 0.035s
  training loss:		0.191437
  validation loss:		0.230980
  validation accuracy:		93.04 %
Epoch 165 of 2000 took 0.035s
  training loss:		0.188573
  validation loss:		0.235659
  validation accuracy:		92.50 %
Epoch 166 of 2000 took 0.035s
  training loss:		0.195738
  validation loss:		0.221172
  validation accuracy:		93.37 %
Epoch 167 of 2000 took 0.035s
  training loss:		0.189407
  validation loss:		0.231684
  validation accuracy:		92.93 %
Epoch 168 of 2000 took 0.035s
  training loss:		0.183780
  validation loss:		0.227527
  validation accuracy:		93.26 %
Epoch 169 of 2000 took 0.035s
  training loss:		0.190831
  validation loss:		0.232804
  validation accuracy:		93.37 %
Epoch 170 of 2000 took 0.035s
  training loss:		0.188694
  validation loss:		0.217857
  validation accuracy:		93.37 %
Epoch 171 of 2000 took 0.035s
  training loss:		0.185327
  validation loss:		0.224503
  validation accuracy:		93.37 %
Epoch 172 of 2000 took 0.035s
  training loss:		0.180166
  validation loss:		0.230944
  validation accuracy:		92.93 %
Epoch 173 of 2000 took 0.035s
  training loss:		0.183760
  validation loss:		0.221769
  validation accuracy:		93.15 %
Epoch 174 of 2000 took 0.035s
  training loss:		0.184789
  validation loss:		0.223855
  validation accuracy:		93.15 %
Epoch 175 of 2000 took 0.035s
  training loss:		0.185477
  validation loss:		0.226686
  validation accuracy:		93.04 %
Epoch 176 of 2000 took 0.035s
  training loss:		0.182005
  validation loss:		0.218544
  validation accuracy:		93.26 %
Epoch 177 of 2000 took 0.035s
  training loss:		0.180178
  validation loss:		0.213908
  validation accuracy:		93.59 %
Epoch 178 of 2000 took 0.035s
  training loss:		0.181255
  validation loss:		0.219799
  validation accuracy:		93.48 %
Epoch 179 of 2000 took 0.035s
  training loss:		0.180389
  validation loss:		0.222060
  validation accuracy:		93.37 %
Epoch 180 of 2000 took 0.035s
  training loss:		0.180915
  validation loss:		0.230266
  validation accuracy:		92.93 %
Epoch 181 of 2000 took 0.035s
  training loss:		0.176969
  validation loss:		0.221553
  validation accuracy:		93.04 %
Epoch 182 of 2000 took 0.035s
  training loss:		0.178709
  validation loss:		0.217907
  validation accuracy:		93.48 %
Epoch 183 of 2000 took 0.035s
  training loss:		0.176552
  validation loss:		0.216386
  validation accuracy:		93.70 %
Epoch 184 of 2000 took 0.035s
  training loss:		0.172860
  validation loss:		0.212596
  validation accuracy:		93.59 %
Epoch 185 of 2000 took 0.035s
  training loss:		0.174052
  validation loss:		0.215061
  validation accuracy:		93.48 %
Epoch 186 of 2000 took 0.035s
  training loss:		0.175989
  validation loss:		0.219782
  validation accuracy:		93.15 %
Epoch 187 of 2000 took 0.035s
  training loss:		0.172752
  validation loss:		0.219781
  validation accuracy:		93.04 %
Epoch 188 of 2000 took 0.035s
  training loss:		0.172378
  validation loss:		0.212443
  validation accuracy:		93.59 %
Epoch 189 of 2000 took 0.035s
  training loss:		0.168360
  validation loss:		0.213475
  validation accuracy:		93.59 %
Epoch 190 of 2000 took 0.035s
  training loss:		0.170236
  validation loss:		0.214875
  validation accuracy:		93.48 %
Epoch 191 of 2000 took 0.035s
  training loss:		0.172463
  validation loss:		0.215493
  validation accuracy:		93.37 %
Epoch 192 of 2000 took 0.035s
  training loss:		0.169096
  validation loss:		0.212842
  validation accuracy:		93.48 %
Epoch 193 of 2000 took 0.035s
  training loss:		0.169632
  validation loss:		0.211764
  validation accuracy:		93.59 %
Epoch 194 of 2000 took 0.035s
  training loss:		0.168645
  validation loss:		0.219545
  validation accuracy:		93.04 %
Epoch 195 of 2000 took 0.035s
  training loss:		0.165033
  validation loss:		0.217656
  validation accuracy:		93.15 %
Epoch 196 of 2000 took 0.035s
  training loss:		0.162748
  validation loss:		0.211495
  validation accuracy:		93.37 %
Epoch 197 of 2000 took 0.035s
  training loss:		0.165381
  validation loss:		0.216181
  validation accuracy:		93.26 %
Epoch 198 of 2000 took 0.035s
  training loss:		0.165972
  validation loss:		0.219728
  validation accuracy:		93.15 %
Epoch 199 of 2000 took 0.035s
  training loss:		0.160721
  validation loss:		0.210900
  validation accuracy:		93.59 %
Epoch 200 of 2000 took 0.035s
  training loss:		0.161012
  validation loss:		0.213552
  validation accuracy:		93.70 %
Epoch 201 of 2000 took 0.035s
  training loss:		0.160159
  validation loss:		0.210907
  validation accuracy:		93.48 %
Epoch 202 of 2000 took 0.035s
  training loss:		0.160440
  validation loss:		0.210094
  validation accuracy:		93.59 %
Epoch 203 of 2000 took 0.035s
  training loss:		0.160547
  validation loss:		0.213844
  validation accuracy:		93.59 %
Epoch 204 of 2000 took 0.035s
  training loss:		0.157090
  validation loss:		0.208215
  validation accuracy:		93.48 %
Epoch 205 of 2000 took 0.035s
  training loss:		0.159706
  validation loss:		0.214684
  validation accuracy:		93.37 %
Epoch 206 of 2000 took 0.035s
  training loss:		0.156740
  validation loss:		0.207471
  validation accuracy:		93.48 %
Epoch 207 of 2000 took 0.035s
  training loss:		0.159920
  validation loss:		0.210661
  validation accuracy:		93.59 %
Epoch 208 of 2000 took 0.035s
  training loss:		0.159118
  validation loss:		0.211800
  validation accuracy:		93.70 %
Epoch 209 of 2000 took 0.035s
  training loss:		0.155243
  validation loss:		0.209389
  validation accuracy:		93.48 %
Epoch 210 of 2000 took 0.035s
  training loss:		0.156171
  validation loss:		0.205711
  validation accuracy:		93.59 %
Epoch 211 of 2000 took 0.035s
  training loss:		0.155915
  validation loss:		0.218520
  validation accuracy:		93.04 %
Epoch 212 of 2000 took 0.035s
  training loss:		0.155748
  validation loss:		0.208771
  validation accuracy:		93.48 %
Epoch 213 of 2000 took 0.035s
  training loss:		0.156883
  validation loss:		0.212144
  validation accuracy:		93.26 %
Epoch 214 of 2000 took 0.035s
  training loss:		0.154354
  validation loss:		0.213558
  validation accuracy:		93.15 %
Epoch 215 of 2000 took 0.035s
  training loss:		0.154952
  validation loss:		0.206125
  validation accuracy:		93.80 %
Epoch 216 of 2000 took 0.035s
  training loss:		0.153857
  validation loss:		0.216611
  validation accuracy:		93.59 %
Epoch 217 of 2000 took 0.035s
  training loss:		0.150471
  validation loss:		0.218991
  validation accuracy:		92.93 %
Epoch 218 of 2000 took 0.035s
  training loss:		0.150935
  validation loss:		0.207184
  validation accuracy:		93.59 %
Epoch 219 of 2000 took 0.035s
  training loss:		0.150417
  validation loss:		0.205820
  validation accuracy:		93.59 %
Epoch 220 of 2000 took 0.035s
  training loss:		0.152251
  validation loss:		0.204875
  validation accuracy:		93.37 %
Epoch 221 of 2000 took 0.035s
  training loss:		0.147994
  validation loss:		0.212550
  validation accuracy:		93.59 %
Epoch 222 of 2000 took 0.035s
  training loss:		0.151345
  validation loss:		0.210142
  validation accuracy:		93.37 %
Epoch 223 of 2000 took 0.035s
  training loss:		0.151126
  validation loss:		0.210339
  validation accuracy:		93.59 %
Epoch 224 of 2000 took 0.035s
  training loss:		0.143613
  validation loss:		0.203304
  validation accuracy:		93.48 %
Epoch 225 of 2000 took 0.035s
  training loss:		0.151208
  validation loss:		0.211707
  validation accuracy:		93.80 %
Epoch 226 of 2000 took 0.037s
  training loss:		0.146047
  validation loss:		0.208308
  validation accuracy:		93.59 %
Epoch 227 of 2000 took 0.035s
  training loss:		0.144124
  validation loss:		0.206156
  validation accuracy:		93.59 %
Epoch 228 of 2000 took 0.035s
  training loss:		0.146278
  validation loss:		0.204308
  validation accuracy:		93.48 %
Epoch 229 of 2000 took 0.035s
  training loss:		0.143926
  validation loss:		0.207887
  validation accuracy:		93.37 %
Epoch 230 of 2000 took 0.035s
  training loss:		0.145724
  validation loss:		0.213122
  validation accuracy:		93.48 %
Epoch 231 of 2000 took 0.035s
  training loss:		0.144032
  validation loss:		0.219620
  validation accuracy:		93.04 %
Epoch 232 of 2000 took 0.035s
  training loss:		0.140701
  validation loss:		0.209053
  validation accuracy:		93.59 %
Epoch 233 of 2000 took 0.035s
  training loss:		0.144148
  validation loss:		0.208283
  validation accuracy:		93.48 %
Epoch 234 of 2000 took 0.035s
  training loss:		0.139686
  validation loss:		0.212200
  validation accuracy:		93.48 %
Epoch 235 of 2000 took 0.035s
  training loss:		0.143121
  validation loss:		0.201068
  validation accuracy:		93.80 %
Epoch 236 of 2000 took 0.035s
  training loss:		0.143608
  validation loss:		0.207676
  validation accuracy:		93.26 %
Epoch 237 of 2000 took 0.035s
  training loss:		0.140626
  validation loss:		0.205891
  validation accuracy:		93.37 %
Epoch 238 of 2000 took 0.035s
  training loss:		0.136914
  validation loss:		0.200861
  validation accuracy:		93.80 %
Epoch 239 of 2000 took 0.035s
  training loss:		0.139151
  validation loss:		0.207921
  validation accuracy:		93.70 %
Epoch 240 of 2000 took 0.035s
  training loss:		0.138492
  validation loss:		0.208932
  validation accuracy:		93.26 %
Epoch 241 of 2000 took 0.035s
  training loss:		0.140200
  validation loss:		0.209696
  validation accuracy:		93.26 %
Epoch 242 of 2000 took 0.035s
  training loss:		0.140619
  validation loss:		0.203662
  validation accuracy:		93.26 %
Epoch 243 of 2000 took 0.035s
  training loss:		0.137364
  validation loss:		0.212332
  validation accuracy:		93.37 %
Epoch 244 of 2000 took 0.035s
  training loss:		0.137029
  validation loss:		0.201521
  validation accuracy:		93.37 %
Epoch 245 of 2000 took 0.035s
  training loss:		0.135579
  validation loss:		0.208138
  validation accuracy:		93.70 %
Epoch 246 of 2000 took 0.035s
  training loss:		0.132802
  validation loss:		0.207889
  validation accuracy:		93.26 %
Epoch 247 of 2000 took 0.035s
  training loss:		0.133888
  validation loss:		0.205033
  validation accuracy:		93.48 %
Epoch 248 of 2000 took 0.035s
  training loss:		0.131739
  validation loss:		0.199043
  validation accuracy:		93.59 %
Epoch 249 of 2000 took 0.035s
  training loss:		0.136074
  validation loss:		0.197419
  validation accuracy:		93.59 %
Epoch 250 of 2000 took 0.035s
  training loss:		0.135617
  validation loss:		0.208393
  validation accuracy:		93.26 %
Epoch 251 of 2000 took 0.035s
  training loss:		0.130976
  validation loss:		0.204670
  validation accuracy:		93.37 %
Epoch 252 of 2000 took 0.035s
  training loss:		0.132914
  validation loss:		0.205252
  validation accuracy:		93.59 %
Epoch 253 of 2000 took 0.035s
  training loss:		0.132541
  validation loss:		0.207569
  validation accuracy:		93.59 %
Epoch 254 of 2000 took 0.035s
  training loss:		0.131213
  validation loss:		0.206162
  validation accuracy:		93.26 %
Epoch 255 of 2000 took 0.035s
  training loss:		0.133804
  validation loss:		0.210001
  validation accuracy:		93.26 %
Epoch 256 of 2000 took 0.035s
  training loss:		0.133602
  validation loss:		0.205366
  validation accuracy:		93.48 %
Epoch 257 of 2000 took 0.035s
  training loss:		0.131694
  validation loss:		0.206713
  validation accuracy:		93.59 %
Epoch 258 of 2000 took 0.035s
  training loss:		0.129609
  validation loss:		0.210784
  validation accuracy:		93.37 %
Epoch 259 of 2000 took 0.035s
  training loss:		0.130452
  validation loss:		0.207166
  validation accuracy:		93.37 %
Epoch 260 of 2000 took 0.035s
  training loss:		0.129677
  validation loss:		0.204574
  validation accuracy:		93.70 %
Epoch 261 of 2000 took 0.035s
  training loss:		0.129727
  validation loss:		0.205039
  validation accuracy:		93.80 %
Epoch 262 of 2000 took 0.035s
  training loss:		0.127836
  validation loss:		0.206631
  validation accuracy:		93.70 %
Epoch 263 of 2000 took 0.035s
  training loss:		0.128765
  validation loss:		0.202070
  validation accuracy:		93.48 %
Epoch 264 of 2000 took 0.035s
  training loss:		0.126466
  validation loss:		0.205426
  validation accuracy:		93.80 %
Epoch 265 of 2000 took 0.035s
  training loss:		0.125539
  validation loss:		0.203286
  validation accuracy:		93.26 %
Epoch 266 of 2000 took 0.035s
  training loss:		0.126062
  validation loss:		0.201351
  validation accuracy:		93.59 %
Epoch 267 of 2000 took 0.035s
  training loss:		0.121467
  validation loss:		0.203001
  validation accuracy:		93.59 %
Epoch 268 of 2000 took 0.035s
  training loss:		0.127790
  validation loss:		0.200053
  validation accuracy:		93.59 %
Epoch 269 of 2000 took 0.035s
  training loss:		0.127474
  validation loss:		0.204838
  validation accuracy:		93.91 %
Epoch 270 of 2000 took 0.035s
  training loss:		0.122498
  validation loss:		0.206427
  validation accuracy:		93.70 %
Epoch 271 of 2000 took 0.035s
  training loss:		0.124386
  validation loss:		0.201292
  validation accuracy:		93.70 %
Epoch 272 of 2000 took 0.035s
  training loss:		0.124947
  validation loss:		0.209475
  validation accuracy:		93.59 %
Epoch 273 of 2000 took 0.035s
  training loss:		0.123206
  validation loss:		0.204930
  validation accuracy:		93.26 %
Epoch 274 of 2000 took 0.035s
  training loss:		0.124170
  validation loss:		0.204111
  validation accuracy:		93.48 %
Epoch 275 of 2000 took 0.035s
  training loss:		0.122376
  validation loss:		0.203039
  validation accuracy:		93.70 %
Epoch 276 of 2000 took 0.035s
  training loss:		0.123972
  validation loss:		0.201453
  validation accuracy:		93.91 %
Epoch 277 of 2000 took 0.035s
  training loss:		0.120092
  validation loss:		0.203374
  validation accuracy:		93.59 %
Epoch 278 of 2000 took 0.035s
  training loss:		0.117820
  validation loss:		0.205466
  validation accuracy:		93.70 %
Epoch 279 of 2000 took 0.035s
  training loss:		0.119350
  validation loss:		0.198945
  validation accuracy:		94.02 %
Epoch 280 of 2000 took 0.035s
  training loss:		0.120760
  validation loss:		0.209106
  validation accuracy:		93.70 %
Epoch 281 of 2000 took 0.035s
  training loss:		0.122216
  validation loss:		0.201489
  validation accuracy:		93.37 %
Epoch 282 of 2000 took 0.035s
  training loss:		0.120501
  validation loss:		0.210940
  validation accuracy:		93.37 %
Epoch 283 of 2000 took 0.035s
  training loss:		0.119382
  validation loss:		0.203414
  validation accuracy:		93.48 %
Epoch 284 of 2000 took 0.035s
  training loss:		0.120233
  validation loss:		0.204076
  validation accuracy:		93.80 %
Epoch 285 of 2000 took 0.035s
  training loss:		0.116976
  validation loss:		0.209710
  validation accuracy:		93.26 %
Epoch 286 of 2000 took 0.035s
  training loss:		0.116290
  validation loss:		0.200344
  validation accuracy:		93.37 %
Epoch 287 of 2000 took 0.035s
  training loss:		0.119997
  validation loss:		0.204131
  validation accuracy:		93.91 %
Epoch 288 of 2000 took 0.035s
  training loss:		0.116166
  validation loss:		0.198774
  validation accuracy:		93.80 %
Epoch 289 of 2000 took 0.035s
  training loss:		0.116825
  validation loss:		0.204484
  validation accuracy:		93.48 %
Epoch 290 of 2000 took 0.035s
  training loss:		0.114079
  validation loss:		0.202400
  validation accuracy:		93.80 %
Epoch 291 of 2000 took 0.035s
  training loss:		0.116280
  validation loss:		0.199881
  validation accuracy:		93.91 %
Epoch 292 of 2000 took 0.035s
  training loss:		0.116399
  validation loss:		0.204507
  validation accuracy:		93.70 %
Epoch 293 of 2000 took 0.035s
  training loss:		0.113791
  validation loss:		0.196435
  validation accuracy:		93.91 %
Epoch 294 of 2000 took 0.035s
  training loss:		0.117415
  validation loss:		0.212171
  validation accuracy:		93.26 %
Epoch 295 of 2000 took 0.035s
  training loss:		0.114829
  validation loss:		0.204201
  validation accuracy:		93.37 %
Epoch 296 of 2000 took 0.035s
  training loss:		0.116267
  validation loss:		0.208720
  validation accuracy:		93.59 %
Epoch 297 of 2000 took 0.035s
  training loss:		0.112781
  validation loss:		0.205314
  validation accuracy:		93.70 %
Epoch 298 of 2000 took 0.035s
  training loss:		0.115715
  validation loss:		0.217985
  validation accuracy:		93.37 %
Epoch 299 of 2000 took 0.035s
  training loss:		0.115838
  validation loss:		0.210957
  validation accuracy:		93.48 %
Epoch 300 of 2000 took 0.035s
  training loss:		0.115135
  validation loss:		0.204053
  validation accuracy:		93.80 %
Epoch 301 of 2000 took 0.035s
  training loss:		0.115815
  validation loss:		0.201808
  validation accuracy:		94.02 %
Epoch 302 of 2000 took 0.035s
  training loss:		0.114020
  validation loss:		0.209010
  validation accuracy:		93.37 %
Epoch 303 of 2000 took 0.035s
  training loss:		0.112787
  validation loss:		0.207873
  validation accuracy:		93.48 %
Epoch 304 of 2000 took 0.035s
  training loss:		0.114603
  validation loss:		0.205501
  validation accuracy:		93.91 %
Epoch 305 of 2000 took 0.035s
  training loss:		0.111211
  validation loss:		0.205990
  validation accuracy:		93.91 %
Epoch 306 of 2000 took 0.035s
  training loss:		0.110225
  validation loss:		0.207309
  validation accuracy:		93.48 %
Epoch 307 of 2000 took 0.035s
  training loss:		0.109430
  validation loss:		0.206472
  validation accuracy:		93.80 %
Epoch 308 of 2000 took 0.035s
  training loss:		0.108614
  validation loss:		0.203716
  validation accuracy:		93.91 %
Epoch 309 of 2000 took 0.035s
  training loss:		0.109396
  validation loss:		0.199178
  validation accuracy:		94.02 %
Epoch 310 of 2000 took 0.035s
  training loss:		0.108463
  validation loss:		0.200475
  validation accuracy:		93.70 %
Epoch 311 of 2000 took 0.035s
  training loss:		0.111104
  validation loss:		0.197516
  validation accuracy:		93.91 %
Epoch 312 of 2000 took 0.035s
  training loss:		0.106785
  validation loss:		0.197065
  validation accuracy:		94.13 %
Epoch 313 of 2000 took 0.035s
  training loss:		0.111046
  validation loss:		0.200220
  validation accuracy:		93.80 %
Epoch 314 of 2000 took 0.035s
  training loss:		0.110044
  validation loss:		0.202818
  validation accuracy:		93.80 %
Epoch 315 of 2000 took 0.035s
  training loss:		0.107104
  validation loss:		0.208810
  validation accuracy:		93.70 %
Epoch 316 of 2000 took 0.035s
  training loss:		0.109132
  validation loss:		0.203786
  validation accuracy:		93.91 %
Epoch 317 of 2000 took 0.035s
  training loss:		0.107105
  validation loss:		0.203240
  validation accuracy:		93.80 %
Epoch 318 of 2000 took 0.035s
  training loss:		0.105569
  validation loss:		0.205672
  validation accuracy:		94.02 %
Epoch 319 of 2000 took 0.035s
  training loss:		0.105706
  validation loss:		0.203914
  validation accuracy:		93.70 %
Epoch 320 of 2000 took 0.035s
  training loss:		0.105232
  validation loss:		0.200423
  validation accuracy:		93.91 %
Epoch 321 of 2000 took 0.035s
  training loss:		0.107028
  validation loss:		0.208227
  validation accuracy:		93.80 %
Epoch 322 of 2000 took 0.035s
  training loss:		0.108554
  validation loss:		0.201925
  validation accuracy:		94.24 %
Epoch 323 of 2000 took 0.035s
  training loss:		0.105709
  validation loss:		0.204758
  validation accuracy:		93.80 %
Epoch 324 of 2000 took 0.035s
  training loss:		0.105985
  validation loss:		0.203268
  validation accuracy:		93.91 %
Epoch 325 of 2000 took 0.035s
  training loss:		0.105603
  validation loss:		0.207326
  validation accuracy:		93.91 %
Epoch 326 of 2000 took 0.035s
  training loss:		0.106464
  validation loss:		0.212789
  validation accuracy:		93.59 %
Epoch 327 of 2000 took 0.035s
  training loss:		0.104925
  validation loss:		0.203132
  validation accuracy:		94.02 %
Epoch 328 of 2000 took 0.035s
  training loss:		0.106697
  validation loss:		0.203145
  validation accuracy:		94.24 %
Epoch 329 of 2000 took 0.035s
  training loss:		0.103552
  validation loss:		0.200894
  validation accuracy:		94.02 %
Epoch 330 of 2000 took 0.035s
  training loss:		0.105724
  validation loss:		0.197461
  validation accuracy:		94.02 %
Epoch 331 of 2000 took 0.035s
  training loss:		0.104179
  validation loss:		0.205726
  validation accuracy:		93.70 %
Epoch 332 of 2000 took 0.035s
  training loss:		0.103716
  validation loss:		0.220215
  validation accuracy:		93.15 %
Epoch 333 of 2000 took 0.035s
  training loss:		0.101672
  validation loss:		0.209736
  validation accuracy:		93.80 %
Epoch 334 of 2000 took 0.035s
  training loss:		0.104363
  validation loss:		0.210899
  validation accuracy:		93.80 %
Epoch 335 of 2000 took 0.035s
  training loss:		0.101828
  validation loss:		0.203337
  validation accuracy:		93.91 %
Epoch 336 of 2000 took 0.035s
  training loss:		0.100368
  validation loss:		0.209262
  validation accuracy:		93.48 %
Epoch 337 of 2000 took 0.035s
  training loss:		0.101081
  validation loss:		0.209400
  validation accuracy:		93.70 %
Epoch 338 of 2000 took 0.035s
  training loss:		0.103977
  validation loss:		0.205144
  validation accuracy:		93.80 %
Epoch 339 of 2000 took 0.035s
  training loss:		0.100925
  validation loss:		0.206592
  validation accuracy:		93.80 %
Epoch 340 of 2000 took 0.035s
  training loss:		0.100710
  validation loss:		0.209179
  validation accuracy:		93.91 %
Epoch 341 of 2000 took 0.035s
  training loss:		0.099670
  validation loss:		0.199876
  validation accuracy:		94.24 %
Epoch 342 of 2000 took 0.035s
  training loss:		0.097347
  validation loss:		0.217378
  validation accuracy:		93.70 %
Epoch 343 of 2000 took 0.035s
  training loss:		0.099175
  validation loss:		0.210843
  validation accuracy:		93.91 %
Epoch 344 of 2000 took 0.035s
  training loss:		0.100426
  validation loss:		0.202973
  validation accuracy:		93.91 %
Epoch 345 of 2000 took 0.035s
  training loss:		0.100283
  validation loss:		0.213882
  validation accuracy:		93.70 %
Epoch 346 of 2000 took 0.035s
  training loss:		0.099258
  validation loss:		0.211358
  validation accuracy:		93.91 %
Epoch 347 of 2000 took 0.035s
  training loss:		0.097455
  validation loss:		0.203165
  validation accuracy:		94.02 %
Epoch 348 of 2000 took 0.035s
  training loss:		0.097528
  validation loss:		0.205782
  validation accuracy:		93.91 %
Epoch 349 of 2000 took 0.035s
  training loss:		0.100968
  validation loss:		0.207292
  validation accuracy:		93.80 %
Epoch 350 of 2000 took 0.035s
  training loss:		0.096700
  validation loss:		0.215018
  validation accuracy:		93.70 %
Epoch 351 of 2000 took 0.035s
  training loss:		0.097106
  validation loss:		0.206779
  validation accuracy:		94.02 %
Epoch 352 of 2000 took 0.035s
  training loss:		0.096168
  validation loss:		0.213872
  validation accuracy:		93.70 %
Epoch 353 of 2000 took 0.035s
  training loss:		0.095997
  validation loss:		0.204617
  validation accuracy:		94.02 %
Epoch 354 of 2000 took 0.035s
  training loss:		0.094883
  validation loss:		0.201996
  validation accuracy:		93.91 %
Epoch 355 of 2000 took 0.035s
  training loss:		0.094732
  validation loss:		0.205971
  validation accuracy:		94.46 %
Epoch 356 of 2000 took 0.035s
  training loss:		0.095451
  validation loss:		0.205483
  validation accuracy:		94.02 %
Epoch 357 of 2000 took 0.035s
  training loss:		0.093705
  validation loss:		0.200971
  validation accuracy:		93.91 %
Epoch 358 of 2000 took 0.035s
  training loss:		0.097011
  validation loss:		0.201610
  validation accuracy:		93.80 %
Epoch 359 of 2000 took 0.035s
  training loss:		0.096117
  validation loss:		0.209008
  validation accuracy:		93.70 %
Epoch 360 of 2000 took 0.035s
  training loss:		0.094478
  validation loss:		0.205302
  validation accuracy:		94.13 %
Epoch 361 of 2000 took 0.035s
  training loss:		0.095638
  validation loss:		0.207107
  validation accuracy:		94.13 %
Epoch 362 of 2000 took 0.035s
  training loss:		0.096681
  validation loss:		0.205429
  validation accuracy:		93.59 %
Epoch 363 of 2000 took 0.035s
  training loss:		0.095038
  validation loss:		0.204914
  validation accuracy:		93.80 %
Epoch 364 of 2000 took 0.035s
  training loss:		0.091293
  validation loss:		0.213060
  validation accuracy:		93.91 %
Epoch 365 of 2000 took 0.035s
  training loss:		0.094950
  validation loss:		0.206098
  validation accuracy:		94.02 %
Epoch 366 of 2000 took 0.035s
  training loss:		0.094461
  validation loss:		0.206408
  validation accuracy:		93.70 %
Epoch 367 of 2000 took 0.035s
  training loss:		0.091541
  validation loss:		0.206257
  validation accuracy:		94.13 %
Epoch 368 of 2000 took 0.035s
  training loss:		0.092673
  validation loss:		0.206647
  validation accuracy:		93.59 %
Epoch 369 of 2000 took 0.035s
  training loss:		0.092924
  validation loss:		0.205372
  validation accuracy:		93.80 %
Epoch 370 of 2000 took 0.035s
  training loss:		0.090230
  validation loss:		0.205651
  validation accuracy:		94.02 %
Epoch 371 of 2000 took 0.035s
  training loss:		0.086226
  validation loss:		0.206749
  validation accuracy:		93.91 %
Epoch 372 of 2000 took 0.035s
  training loss:		0.092957
  validation loss:		0.209753
  validation accuracy:		94.24 %
Epoch 373 of 2000 took 0.035s
  training loss:		0.092534
  validation loss:		0.211311
  validation accuracy:		93.80 %
Epoch 374 of 2000 took 0.035s
  training loss:		0.091450
  validation loss:		0.208091
  validation accuracy:		93.91 %
Epoch 375 of 2000 took 0.035s
  training loss:		0.091773
  validation loss:		0.204931
  validation accuracy:		93.80 %
Epoch 376 of 2000 took 0.035s
  training loss:		0.092446
  validation loss:		0.206372
  validation accuracy:		93.91 %
Epoch 377 of 2000 took 0.035s
  training loss:		0.091502
  validation loss:		0.213800
  validation accuracy:		94.24 %
Epoch 378 of 2000 took 0.035s
  training loss:		0.092042
  validation loss:		0.207400
  validation accuracy:		93.59 %
Epoch 379 of 2000 took 0.035s
  training loss:		0.092337
  validation loss:		0.213395
  validation accuracy:		93.91 %
Epoch 380 of 2000 took 0.035s
  training loss:		0.089236
  validation loss:		0.210543
  validation accuracy:		93.59 %
Epoch 381 of 2000 took 0.035s
  training loss:		0.086086
  validation loss:		0.205460
  validation accuracy:		94.24 %
Epoch 382 of 2000 took 0.035s
  training loss:		0.088272
  validation loss:		0.210306
  validation accuracy:		93.59 %
Epoch 383 of 2000 took 0.035s
  training loss:		0.088258
  validation loss:		0.208568
  validation accuracy:		94.02 %
Epoch 384 of 2000 took 0.035s
  training loss:		0.090047
  validation loss:		0.210332
  validation accuracy:		93.80 %
Epoch 385 of 2000 took 0.035s
  training loss:		0.091388
  validation loss:		0.219550
  validation accuracy:		93.37 %
Epoch 386 of 2000 took 0.035s
  training loss:		0.090724
  validation loss:		0.214667
  validation accuracy:		93.91 %
Epoch 387 of 2000 took 0.035s
  training loss:		0.087555
  validation loss:		0.202398
  validation accuracy:		93.80 %
Epoch 388 of 2000 took 0.035s
  training loss:		0.087504
  validation loss:		0.205739
  validation accuracy:		94.35 %
Epoch 389 of 2000 took 0.035s
  training loss:		0.086881
  validation loss:		0.208536
  validation accuracy:		93.91 %
Epoch 390 of 2000 took 0.035s
  training loss:		0.087345
  validation loss:		0.204795
  validation accuracy:		94.02 %
Epoch 391 of 2000 took 0.035s
  training loss:		0.085564
  validation loss:		0.218100
  validation accuracy:		93.80 %
Epoch 392 of 2000 took 0.035s
  training loss:		0.087348
  validation loss:		0.206567
  validation accuracy:		93.80 %
Epoch 393 of 2000 took 0.035s
  training loss:		0.085155
  validation loss:		0.215611
  validation accuracy:		93.37 %
Epoch 394 of 2000 took 0.035s
  training loss:		0.087729
  validation loss:		0.207330
  validation accuracy:		94.13 %
Epoch 395 of 2000 took 0.035s
  training loss:		0.086615
  validation loss:		0.213007
  validation accuracy:		94.13 %
Epoch 396 of 2000 took 0.035s
  training loss:		0.085090
  validation loss:		0.209408
  validation accuracy:		93.80 %
Epoch 397 of 2000 took 0.035s
  training loss:		0.087591
  validation loss:		0.213668
  validation accuracy:		93.91 %
Epoch 398 of 2000 took 0.035s
  training loss:		0.085901
  validation loss:		0.212056
  validation accuracy:		93.91 %
Epoch 399 of 2000 took 0.035s
  training loss:		0.084599
  validation loss:		0.205511
  validation accuracy:		93.91 %
Epoch 400 of 2000 took 0.035s
  training loss:		0.084291
  validation loss:		0.211273
  validation accuracy:		93.70 %
Epoch 401 of 2000 took 0.035s
  training loss:		0.087068
  validation loss:		0.209031
  validation accuracy:		93.80 %
Epoch 402 of 2000 took 0.035s
  training loss:		0.084498
  validation loss:		0.207862
  validation accuracy:		93.91 %
Epoch 403 of 2000 took 0.035s
  training loss:		0.085497
  validation loss:		0.219372
  validation accuracy:		93.91 %
Epoch 404 of 2000 took 0.035s
  training loss:		0.083323
  validation loss:		0.208226
  validation accuracy:		93.59 %
Epoch 405 of 2000 took 0.035s
  training loss:		0.085116
  validation loss:		0.211318
  validation accuracy:		93.80 %
Epoch 406 of 2000 took 0.035s
  training loss:		0.081318
  validation loss:		0.210440
  validation accuracy:		94.24 %
Epoch 407 of 2000 took 0.035s
  training loss:		0.082247
  validation loss:		0.217189
  validation accuracy:		94.24 %
Epoch 408 of 2000 took 0.035s
  training loss:		0.082770
  validation loss:		0.212219
  validation accuracy:		94.02 %
Epoch 409 of 2000 took 0.035s
  training loss:		0.082129
  validation loss:		0.204845
  validation accuracy:		93.91 %
Epoch 410 of 2000 took 0.035s
  training loss:		0.083663
  validation loss:		0.214979
  validation accuracy:		93.91 %
Epoch 411 of 2000 took 0.035s
  training loss:		0.082586
  validation loss:		0.212255
  validation accuracy:		93.70 %
Epoch 412 of 2000 took 0.035s
  training loss:		0.079006
  validation loss:		0.209364
  validation accuracy:		94.02 %
Epoch 413 of 2000 took 0.035s
  training loss:		0.083400
  validation loss:		0.215702
  validation accuracy:		94.24 %
Epoch 414 of 2000 took 0.035s
  training loss:		0.083269
  validation loss:		0.211429
  validation accuracy:		94.13 %
Epoch 415 of 2000 took 0.035s
  training loss:		0.080834
  validation loss:		0.221651
  validation accuracy:		93.91 %
Epoch 416 of 2000 took 0.035s
  training loss:		0.082808
  validation loss:		0.210956
  validation accuracy:		94.24 %
Epoch 417 of 2000 took 0.035s
  training loss:		0.078062
  validation loss:		0.217436
  validation accuracy:		93.91 %
Epoch 418 of 2000 took 0.035s
  training loss:		0.082310
  validation loss:		0.213174
  validation accuracy:		93.80 %
Epoch 419 of 2000 took 0.035s
  training loss:		0.080856
  validation loss:		0.223999
  validation accuracy:		93.37 %
Epoch 420 of 2000 took 0.035s
  training loss:		0.083995
  validation loss:		0.210574
  validation accuracy:		94.24 %
Epoch 421 of 2000 took 0.035s
  training loss:		0.080260
  validation loss:		0.210472
  validation accuracy:		93.91 %
Epoch 422 of 2000 took 0.035s
  training loss:		0.078085
  validation loss:		0.212204
  validation accuracy:		93.91 %
Epoch 423 of 2000 took 0.035s
  training loss:		0.081599
  validation loss:		0.215863
  validation accuracy:		93.70 %
Epoch 424 of 2000 took 0.035s
  training loss:		0.080844
  validation loss:		0.219526
  validation accuracy:		93.80 %
Epoch 425 of 2000 took 0.035s
  training loss:		0.078857
  validation loss:		0.217090
  validation accuracy:		93.80 %
Epoch 426 of 2000 took 0.035s
  training loss:		0.081402
  validation loss:		0.212541
  validation accuracy:		93.91 %
Epoch 427 of 2000 took 0.035s
  training loss:		0.079471
  validation loss:		0.217413
  validation accuracy:		93.59 %
Epoch 428 of 2000 took 0.035s
  training loss:		0.078816
  validation loss:		0.213849
  validation accuracy:		93.80 %
Epoch 429 of 2000 took 0.035s
  training loss:		0.079407
  validation loss:		0.214131
  validation accuracy:		93.80 %
Epoch 430 of 2000 took 0.035s
  training loss:		0.077021
  validation loss:		0.217156
  validation accuracy:		93.59 %
Epoch 431 of 2000 took 0.035s
  training loss:		0.076724
  validation loss:		0.212741
  validation accuracy:		93.91 %
Epoch 432 of 2000 took 0.035s
  training loss:		0.077875
  validation loss:		0.214902
  validation accuracy:		93.80 %
Epoch 433 of 2000 took 0.035s
  training loss:		0.078508
  validation loss:		0.211009
  validation accuracy:		94.02 %
Epoch 434 of 2000 took 0.035s
  training loss:		0.077785
  validation loss:		0.216990
  validation accuracy:		93.91 %
Epoch 435 of 2000 took 0.035s
  training loss:		0.076098
  validation loss:		0.219927
  validation accuracy:		94.24 %
Epoch 436 of 2000 took 0.035s
  training loss:		0.077129
  validation loss:		0.213642
  validation accuracy:		93.80 %
Epoch 437 of 2000 took 0.035s
  training loss:		0.077662
  validation loss:		0.212437
  validation accuracy:		94.02 %
Epoch 438 of 2000 took 0.035s
  training loss:		0.075103
  validation loss:		0.223458
  validation accuracy:		93.59 %
Epoch 439 of 2000 took 0.035s
  training loss:		0.077368
  validation loss:		0.216710
  validation accuracy:		93.80 %
Epoch 440 of 2000 took 0.035s
  training loss:		0.074131
  validation loss:		0.213599
  validation accuracy:		93.70 %
Epoch 441 of 2000 took 0.035s
  training loss:		0.076318
  validation loss:		0.213737
  validation accuracy:		93.80 %
Epoch 442 of 2000 took 0.035s
  training loss:		0.074370
  validation loss:		0.217830
  validation accuracy:		93.91 %
Epoch 443 of 2000 took 0.035s
  training loss:		0.075568
  validation loss:		0.216515
  validation accuracy:		93.70 %
Epoch 444 of 2000 took 0.035s
  training loss:		0.077499
  validation loss:		0.214489
  validation accuracy:		94.13 %
Epoch 445 of 2000 took 0.035s
  training loss:		0.070881
  validation loss:		0.213940
  validation accuracy:		93.70 %
Epoch 446 of 2000 took 0.035s
  training loss:		0.075923
  validation loss:		0.210123
  validation accuracy:		93.80 %
Epoch 447 of 2000 took 0.035s
  training loss:		0.074387
  validation loss:		0.226338
  validation accuracy:		93.37 %
Epoch 448 of 2000 took 0.036s
  training loss:		0.076975
  validation loss:		0.218665
  validation accuracy:		93.91 %
Epoch 449 of 2000 took 0.035s
  training loss:		0.073527
  validation loss:		0.214558
  validation accuracy:		93.70 %
Epoch 450 of 2000 took 0.035s
  training loss:		0.074448
  validation loss:		0.215222
  validation accuracy:		93.70 %
Epoch 451 of 2000 took 0.035s
  training loss:		0.074038
  validation loss:		0.225151
  validation accuracy:		93.59 %
Epoch 452 of 2000 took 0.035s
  training loss:		0.073693
  validation loss:		0.219797
  validation accuracy:		93.91 %
Epoch 453 of 2000 took 0.035s
  training loss:		0.075432
  validation loss:		0.219423
  validation accuracy:		93.91 %
Epoch 454 of 2000 took 0.035s
  training loss:		0.073686
  validation loss:		0.232528
  validation accuracy:		93.26 %
Epoch 455 of 2000 took 0.035s
  training loss:		0.072349
  validation loss:		0.218049
  validation accuracy:		93.91 %
Epoch 456 of 2000 took 0.035s
  training loss:		0.073550
  validation loss:		0.226844
  validation accuracy:		93.59 %
Epoch 457 of 2000 took 0.035s
  training loss:		0.074160
  validation loss:		0.220295
  validation accuracy:		94.13 %
Epoch 458 of 2000 took 0.035s
  training loss:		0.072190
  validation loss:		0.221081
  validation accuracy:		93.91 %
Epoch 459 of 2000 took 0.037s
  training loss:		0.072091
  validation loss:		0.218935
  validation accuracy:		93.70 %
Epoch 460 of 2000 took 0.035s
  training loss:		0.073319
  validation loss:		0.228027
  validation accuracy:		93.37 %
Epoch 461 of 2000 took 0.035s
  training loss:		0.074241
  validation loss:		0.221603
  validation accuracy:		93.80 %
Epoch 462 of 2000 took 0.035s
  training loss:		0.072479
  validation loss:		0.219367
  validation accuracy:		93.48 %
Epoch 463 of 2000 took 0.035s
  training loss:		0.071473
  validation loss:		0.219819
  validation accuracy:		93.80 %
Epoch 464 of 2000 took 0.035s
  training loss:		0.071676
  validation loss:		0.217045
  validation accuracy:		93.80 %
Epoch 465 of 2000 took 0.035s
  training loss:		0.071016
  validation loss:		0.218185
  validation accuracy:		93.70 %
Epoch 466 of 2000 took 0.035s
  training loss:		0.069577
  validation loss:		0.221906
  validation accuracy:		93.70 %
Epoch 467 of 2000 took 0.035s
  training loss:		0.072470
  validation loss:		0.217395
  validation accuracy:		94.02 %
Epoch 468 of 2000 took 0.035s
  training loss:		0.071092
  validation loss:		0.219447
  validation accuracy:		93.70 %
Epoch 469 of 2000 took 0.035s
  training loss:		0.070443
  validation loss:		0.224299
  validation accuracy:		93.70 %
Epoch 470 of 2000 took 0.035s
  training loss:		0.072972
  validation loss:		0.219652
  validation accuracy:		94.02 %
Epoch 471 of 2000 took 0.035s
  training loss:		0.069225
  validation loss:		0.225812
  validation accuracy:		94.13 %
Epoch 472 of 2000 took 0.035s
  training loss:		0.069569
  validation loss:		0.219426
  validation accuracy:		93.70 %
Epoch 473 of 2000 took 0.035s
  training loss:		0.070197
  validation loss:		0.223617
  validation accuracy:		93.70 %
Epoch 474 of 2000 took 0.035s
  training loss:		0.067664
  validation loss:		0.216304
  validation accuracy:		93.70 %
Epoch 475 of 2000 took 0.035s
  training loss:		0.069995
  validation loss:		0.226747
  validation accuracy:		93.59 %
Epoch 476 of 2000 took 0.035s
  training loss:		0.070220
  validation loss:		0.212102
  validation accuracy:		93.70 %
Epoch 477 of 2000 took 0.035s
  training loss:		0.067919
  validation loss:		0.217580
  validation accuracy:		93.59 %
Epoch 478 of 2000 took 0.035s
  training loss:		0.070735
  validation loss:		0.227771
  validation accuracy:		93.48 %
Epoch 479 of 2000 took 0.035s
  training loss:		0.069434
  validation loss:		0.218239
  validation accuracy:		93.70 %
Epoch 480 of 2000 took 0.035s
  training loss:		0.069715
  validation loss:		0.222155
  validation accuracy:		93.91 %
Epoch 481 of 2000 took 0.035s
  training loss:		0.067783
  validation loss:		0.224690
  validation accuracy:		93.48 %
Epoch 482 of 2000 took 0.035s
  training loss:		0.068655
  validation loss:		0.220290
  validation accuracy:		93.80 %
Epoch 483 of 2000 took 0.035s
  training loss:		0.069414
  validation loss:		0.228417
  validation accuracy:		93.59 %
Epoch 484 of 2000 took 0.035s
  training loss:		0.068525
  validation loss:		0.232602
  validation accuracy:		93.48 %
Epoch 485 of 2000 took 0.035s
  training loss:		0.068170
  validation loss:		0.222931
  validation accuracy:		93.59 %
Epoch 486 of 2000 took 0.035s
  training loss:		0.068042
  validation loss:		0.226388
  validation accuracy:		93.70 %
Epoch 487 of 2000 took 0.035s
  training loss:		0.068711
  validation loss:		0.222015
  validation accuracy:		93.70 %
Epoch 488 of 2000 took 0.035s
  training loss:		0.065470
  validation loss:		0.229175
  validation accuracy:		93.15 %
Epoch 489 of 2000 took 0.035s
  training loss:		0.068694
  validation loss:		0.222832
  validation accuracy:		93.26 %
Epoch 490 of 2000 took 0.035s
  training loss:		0.068242
  validation loss:		0.223509
  validation accuracy:		93.59 %
Epoch 491 of 2000 took 0.035s
  training loss:		0.065840
  validation loss:		0.221673
  validation accuracy:		93.59 %
Epoch 492 of 2000 took 0.035s
  training loss:		0.064712
  validation loss:		0.222475
  validation accuracy:		93.80 %
Epoch 493 of 2000 took 0.035s
  training loss:		0.066080
  validation loss:		0.231940
  validation accuracy:		93.59 %
Epoch 494 of 2000 took 0.035s
  training loss:		0.066970
  validation loss:		0.225410
  validation accuracy:		93.37 %
Epoch 495 of 2000 took 0.035s
  training loss:		0.068356
  validation loss:		0.223456
  validation accuracy:		93.91 %
Epoch 496 of 2000 took 0.035s
  training loss:		0.064756
  validation loss:		0.225349
  validation accuracy:		93.48 %
Epoch 497 of 2000 took 0.035s
  training loss:		0.065835
  validation loss:		0.227018
  validation accuracy:		93.70 %
Epoch 498 of 2000 took 0.035s
  training loss:		0.063823
  validation loss:		0.215199
  validation accuracy:		93.70 %
Epoch 499 of 2000 took 0.035s
  training loss:		0.062598
  validation loss:		0.232750
  validation accuracy:		93.70 %
Epoch 500 of 2000 took 0.035s
  training loss:		0.064984
  validation loss:		0.226002
  validation accuracy:		93.59 %
Epoch 501 of 2000 took 0.035s
  training loss:		0.064584
  validation loss:		0.219991
  validation accuracy:		93.91 %
Epoch 502 of 2000 took 0.035s
  training loss:		0.065466
  validation loss:		0.220779
  validation accuracy:		93.59 %
Epoch 503 of 2000 took 0.035s
  training loss:		0.065897
  validation loss:		0.229705
  validation accuracy:		93.48 %
Epoch 504 of 2000 took 0.035s
  training loss:		0.063222
  validation loss:		0.222317
  validation accuracy:		93.70 %
Epoch 505 of 2000 took 0.035s
  training loss:		0.063955
  validation loss:		0.226651
  validation accuracy:		93.59 %
Epoch 506 of 2000 took 0.035s
  training loss:		0.064216
  validation loss:		0.235456
  validation accuracy:		93.26 %
Epoch 507 of 2000 took 0.035s
  training loss:		0.064970
  validation loss:		0.233367
  validation accuracy:		93.59 %
Epoch 508 of 2000 took 0.035s
  training loss:		0.066004
  validation loss:		0.234256
  validation accuracy:		93.91 %
Epoch 509 of 2000 took 0.035s
  training loss:		0.065545
  validation loss:		0.226556
  validation accuracy:		93.80 %
Epoch 510 of 2000 took 0.035s
  training loss:		0.060827
  validation loss:		0.227640
  validation accuracy:		93.70 %
Epoch 511 of 2000 took 0.035s
  training loss:		0.064401
  validation loss:		0.235054
  validation accuracy:		93.59 %
Epoch 512 of 2000 took 0.035s
  training loss:		0.062781
  validation loss:		0.243831
  validation accuracy:		93.48 %
Epoch 513 of 2000 took 0.035s
  training loss:		0.061862
  validation loss:		0.220633
  validation accuracy:		93.80 %
Epoch 514 of 2000 took 0.035s
  training loss:		0.060081
  validation loss:		0.227941
  validation accuracy:		93.70 %
Epoch 515 of 2000 took 0.035s
  training loss:		0.062923
  validation loss:		0.223860
  validation accuracy:		93.70 %
Epoch 516 of 2000 took 0.035s
  training loss:		0.062773
  validation loss:		0.229308
  validation accuracy:		93.59 %
Epoch 517 of 2000 took 0.035s
  training loss:		0.062135
  validation loss:		0.228223
  validation accuracy:		93.48 %
Epoch 518 of 2000 took 0.035s
  training loss:		0.062529
  validation loss:		0.224550
  validation accuracy:		93.70 %
Epoch 519 of 2000 took 0.035s
  training loss:		0.060334
  validation loss:		0.232267
  validation accuracy:		93.91 %
Epoch 520 of 2000 took 0.035s
  training loss:		0.060784
  validation loss:		0.225904
  validation accuracy:		93.80 %
Epoch 521 of 2000 took 0.035s
  training loss:		0.062754
  validation loss:		0.231263
  validation accuracy:		93.26 %
Epoch 522 of 2000 took 0.035s
  training loss:		0.061061
  validation loss:		0.227629
  validation accuracy:		93.80 %
Epoch 523 of 2000 took 0.035s
  training loss:		0.062242
  validation loss:		0.241756
  validation accuracy:		93.37 %
Epoch 524 of 2000 took 0.035s
  training loss:		0.061947
  validation loss:		0.227757
  validation accuracy:		93.91 %
Epoch 525 of 2000 took 0.035s
  training loss:		0.060659
  validation loss:		0.230488
  validation accuracy:		93.37 %
Epoch 526 of 2000 took 0.035s
  training loss:		0.062069
  validation loss:		0.229098
  validation accuracy:		93.70 %
Epoch 527 of 2000 took 0.035s
  training loss:		0.061558
  validation loss:		0.232021
  validation accuracy:		93.59 %
Epoch 528 of 2000 took 0.035s
  training loss:		0.059461
  validation loss:		0.227432
  validation accuracy:		93.48 %
Epoch 529 of 2000 took 0.035s
  training loss:		0.060256
  validation loss:		0.229815
  validation accuracy:		94.02 %
Epoch 530 of 2000 took 0.035s
  training loss:		0.060918
  validation loss:		0.239181
  validation accuracy:		93.26 %
Epoch 531 of 2000 took 0.035s
  training loss:		0.058916
  validation loss:		0.237083
  validation accuracy:		93.59 %
Epoch 532 of 2000 took 0.035s
  training loss:		0.059038
  validation loss:		0.234124
  validation accuracy:		93.59 %
Epoch 533 of 2000 took 0.035s
  training loss:		0.061498
  validation loss:		0.228306
  validation accuracy:		93.91 %
Epoch 534 of 2000 took 0.035s
  training loss:		0.058727
  validation loss:		0.229750
  validation accuracy:		93.37 %
Epoch 535 of 2000 took 0.035s
  training loss:		0.059688
  validation loss:		0.227894
  validation accuracy:		93.59 %
Epoch 536 of 2000 took 0.035s
  training loss:		0.058633
  validation loss:		0.232356
  validation accuracy:		93.37 %
Epoch 537 of 2000 took 0.035s
  training loss:		0.061017
  validation loss:		0.242513
  validation accuracy:		93.80 %
Epoch 538 of 2000 took 0.035s
  training loss:		0.060514
  validation loss:		0.237500
  validation accuracy:		93.59 %
Epoch 539 of 2000 took 0.035s
  training loss:		0.058074
  validation loss:		0.229585
  validation accuracy:		93.70 %
Epoch 540 of 2000 took 0.035s
  training loss:		0.057458
  validation loss:		0.235381
  validation accuracy:		93.59 %
Epoch 541 of 2000 took 0.035s
  training loss:		0.058791
  validation loss:		0.232460
  validation accuracy:		93.48 %
Epoch 542 of 2000 took 0.035s
  training loss:		0.059892
  validation loss:		0.232461
  validation accuracy:		93.80 %
Epoch 543 of 2000 took 0.035s
  training loss:		0.058473
  validation loss:		0.239684
  validation accuracy:		93.59 %
Epoch 544 of 2000 took 0.035s
  training loss:		0.057183
  validation loss:		0.233099
  validation accuracy:		93.70 %
Epoch 545 of 2000 took 0.035s
  training loss:		0.059153
  validation loss:		0.234710
  validation accuracy:		93.70 %
Epoch 546 of 2000 took 0.035s
  training loss:		0.057989
  validation loss:		0.239186
  validation accuracy:		93.59 %
Epoch 547 of 2000 took 0.035s
  training loss:		0.057868
  validation loss:		0.242538
  validation accuracy:		93.59 %
Epoch 548 of 2000 took 0.035s
  training loss:		0.056564
  validation loss:		0.230893
  validation accuracy:		93.59 %
Epoch 549 of 2000 took 0.035s
  training loss:		0.058448
  validation loss:		0.236286
  validation accuracy:		93.70 %
Epoch 550 of 2000 took 0.035s
  training loss:		0.054169
  validation loss:		0.234895
  validation accuracy:		93.80 %
Epoch 551 of 2000 took 0.035s
  training loss:		0.057555
  validation loss:		0.238063
  validation accuracy:		93.59 %
Epoch 552 of 2000 took 0.035s
  training loss:		0.057556
  validation loss:		0.240441
  validation accuracy:		93.37 %
Epoch 553 of 2000 took 0.035s
  training loss:		0.057690
  validation loss:		0.232785
  validation accuracy:		93.80 %
Epoch 554 of 2000 took 0.035s
  training loss:		0.056819
  validation loss:		0.239560
  validation accuracy:		93.48 %
Epoch 555 of 2000 took 0.035s
  training loss:		0.056858
  validation loss:		0.229647
  validation accuracy:		93.59 %
Epoch 556 of 2000 took 0.035s
  training loss:		0.056412
  validation loss:		0.232066
  validation accuracy:		93.70 %
Epoch 557 of 2000 took 0.035s
  training loss:		0.054647
  validation loss:		0.235302
  validation accuracy:		93.70 %
Epoch 558 of 2000 took 0.035s
  training loss:		0.056346
  validation loss:		0.239261
  validation accuracy:		93.48 %
Epoch 559 of 2000 took 0.035s
  training loss:		0.055648
  validation loss:		0.230750
  validation accuracy:		93.91 %
Epoch 560 of 2000 took 0.035s
  training loss:		0.056983
  validation loss:		0.242273
  validation accuracy:		93.15 %
Epoch 561 of 2000 took 0.035s
  training loss:		0.057099
  validation loss:		0.242264
  validation accuracy:		93.91 %
Epoch 562 of 2000 took 0.035s
  training loss:		0.056081
  validation loss:		0.232203
  validation accuracy:		93.59 %
Epoch 563 of 2000 took 0.035s
  training loss:		0.055724
  validation loss:		0.241138
  validation accuracy:		93.59 %
Epoch 564 of 2000 took 0.035s
  training loss:		0.055967
  validation loss:		0.237318
  validation accuracy:		93.70 %
Epoch 565 of 2000 took 0.035s
  training loss:		0.056018
  validation loss:		0.240590
  validation accuracy:		93.37 %
Epoch 566 of 2000 took 0.035s
  training loss:		0.055926
  validation loss:		0.238671
  validation accuracy:		93.59 %
Epoch 567 of 2000 took 0.035s
  training loss:		0.054566
  validation loss:		0.242665
  validation accuracy:		93.48 %
Epoch 568 of 2000 took 0.035s
  training loss:		0.053227
  validation loss:		0.240167
  validation accuracy:		93.80 %
Epoch 569 of 2000 took 0.035s
  training loss:		0.055254
  validation loss:		0.251197
  validation accuracy:		93.26 %
Epoch 570 of 2000 took 0.035s
  training loss:		0.057001
  validation loss:		0.235601
  validation accuracy:		93.37 %
Epoch 571 of 2000 took 0.035s
  training loss:		0.054203
  validation loss:		0.241332
  validation accuracy:		93.70 %
Epoch 572 of 2000 took 0.035s
  training loss:		0.053616
  validation loss:		0.235935
  validation accuracy:		93.59 %
Epoch 573 of 2000 took 0.035s
  training loss:		0.051655
  validation loss:		0.239840
  validation accuracy:		93.70 %
Epoch 574 of 2000 took 0.035s
  training loss:		0.053826
  validation loss:		0.236687
  validation accuracy:		93.59 %
Epoch 575 of 2000 took 0.035s
  training loss:		0.051402
  validation loss:		0.241696
  validation accuracy:		93.59 %
Epoch 576 of 2000 took 0.035s
  training loss:		0.052665
  validation loss:		0.236519
  validation accuracy:		93.80 %
Epoch 577 of 2000 took 0.035s
  training loss:		0.051129
  validation loss:		0.239674
  validation accuracy:		93.70 %
Epoch 578 of 2000 took 0.035s
  training loss:		0.052385
  validation loss:		0.233384
  validation accuracy:		93.70 %
Epoch 579 of 2000 took 0.035s
  training loss:		0.052499
  validation loss:		0.238428
  validation accuracy:		93.80 %
Epoch 580 of 2000 took 0.035s
  training loss:		0.052768
  validation loss:		0.250928
  validation accuracy:		93.48 %
Epoch 581 of 2000 took 0.035s
  training loss:		0.051073
  validation loss:		0.241995
  validation accuracy:		93.59 %
Epoch 582 of 2000 took 0.035s
  training loss:		0.051749
  validation loss:		0.248130
  validation accuracy:		93.48 %
Epoch 583 of 2000 took 0.035s
  training loss:		0.053283
  validation loss:		0.241475
  validation accuracy:		93.48 %
Epoch 584 of 2000 took 0.035s
  training loss:		0.053430
  validation loss:		0.236443
  validation accuracy:		93.70 %
Epoch 585 of 2000 took 0.035s
  training loss:		0.051634
  validation loss:		0.240231
  validation accuracy:		93.59 %
Epoch 586 of 2000 took 0.035s
  training loss:		0.052142
  validation loss:		0.243647
  validation accuracy:		93.59 %
Epoch 587 of 2000 took 0.035s
  training loss:		0.052311
  validation loss:		0.250149
  validation accuracy:		93.37 %
Epoch 588 of 2000 took 0.035s
  training loss:		0.052449
  validation loss:		0.243415
  validation accuracy:		93.48 %
Epoch 589 of 2000 took 0.035s
  training loss:		0.053139
  validation loss:		0.254959
  validation accuracy:		93.26 %
Epoch 590 of 2000 took 0.035s
  training loss:		0.051629
  validation loss:		0.249633
  validation accuracy:		93.70 %
Epoch 591 of 2000 took 0.035s
  training loss:		0.049143
  validation loss:		0.249097
  validation accuracy:		93.37 %
Epoch 592 of 2000 took 0.035s
  training loss:		0.052016
  validation loss:		0.249291
  validation accuracy:		93.48 %
Epoch 593 of 2000 took 0.035s
  training loss:		0.050818
  validation loss:		0.246166
  validation accuracy:		93.48 %
Epoch 594 of 2000 took 0.035s
  training loss:		0.050197
  validation loss:		0.250116
  validation accuracy:		93.48 %
Epoch 595 of 2000 took 0.035s
  training loss:		0.051792
  validation loss:		0.244402
  validation accuracy:		93.59 %
Epoch 596 of 2000 took 0.035s
  training loss:		0.051116
  validation loss:		0.243625
  validation accuracy:		93.48 %
Epoch 597 of 2000 took 0.035s
  training loss:		0.051420
  validation loss:		0.243150
  validation accuracy:		93.70 %
Epoch 598 of 2000 took 0.035s
  training loss:		0.049323
  validation loss:		0.236217
  validation accuracy:		93.59 %
Epoch 599 of 2000 took 0.035s
  training loss:		0.048970
  validation loss:		0.248722
  validation accuracy:		93.59 %
Epoch 600 of 2000 took 0.035s
  training loss:		0.050085
  validation loss:		0.248915
  validation accuracy:		93.37 %
Epoch 601 of 2000 took 0.035s
  training loss:		0.050726
  validation loss:		0.245631
  validation accuracy:		93.80 %
Epoch 602 of 2000 took 0.035s
  training loss:		0.049034
  validation loss:		0.247566
  validation accuracy:		93.37 %
Epoch 603 of 2000 took 0.035s
  training loss:		0.049137
  validation loss:		0.245877
  validation accuracy:		93.37 %
Epoch 604 of 2000 took 0.035s
  training loss:		0.049751
  validation loss:		0.249022
  validation accuracy:		93.15 %
Epoch 605 of 2000 took 0.035s
  training loss:		0.051066
  validation loss:		0.245970
  validation accuracy:		93.48 %
Epoch 606 of 2000 took 0.035s
  training loss:		0.050345
  validation loss:		0.247710
  validation accuracy:		93.59 %
Epoch 607 of 2000 took 0.035s
  training loss:		0.049759
  validation loss:		0.240918
  validation accuracy:		93.70 %
Epoch 608 of 2000 took 0.035s
  training loss:		0.049943
  validation loss:		0.252095
  validation accuracy:		93.48 %
Epoch 609 of 2000 took 0.035s
  training loss:		0.049597
  validation loss:		0.256577
  validation accuracy:		93.26 %
Epoch 610 of 2000 took 0.035s
  training loss:		0.048868
  validation loss:		0.243567
  validation accuracy:		93.59 %
Epoch 611 of 2000 took 0.035s
  training loss:		0.048862
  validation loss:		0.254298
  validation accuracy:		93.15 %
Epoch 612 of 2000 took 0.035s
  training loss:		0.047940
  validation loss:		0.247497
  validation accuracy:		93.70 %
Epoch 613 of 2000 took 0.035s
  training loss:		0.049094
  validation loss:		0.252628
  validation accuracy:		93.48 %
Epoch 614 of 2000 took 0.035s
  training loss:		0.049854
  validation loss:		0.256798
  validation accuracy:		93.37 %
Epoch 615 of 2000 took 0.035s
  training loss:		0.047897
  validation loss:		0.250429
  validation accuracy:		93.48 %
Epoch 616 of 2000 took 0.035s
  training loss:		0.048213
  validation loss:		0.257044
  validation accuracy:		93.26 %
Epoch 617 of 2000 took 0.035s
  training loss:		0.046585
  validation loss:		0.242007
  validation accuracy:		93.59 %
Epoch 618 of 2000 took 0.035s
  training loss:		0.048406
  validation loss:		0.259639
  validation accuracy:		92.93 %
Epoch 619 of 2000 took 0.035s
  training loss:		0.047253
  validation loss:		0.252942
  validation accuracy:		93.37 %
Epoch 620 of 2000 took 0.035s
  training loss:		0.046366
  validation loss:		0.241462
  validation accuracy:		93.59 %
Epoch 621 of 2000 took 0.035s
  training loss:		0.047982
  validation loss:		0.250847
  validation accuracy:		93.70 %
Epoch 622 of 2000 took 0.035s
  training loss:		0.044431
  validation loss:		0.263946
  validation accuracy:		93.26 %
Epoch 623 of 2000 took 0.035s
  training loss:		0.047433
  validation loss:		0.250266
  validation accuracy:		93.37 %
Epoch 624 of 2000 took 0.035s
  training loss:		0.048456
  validation loss:		0.248034
  validation accuracy:		93.48 %
Epoch 625 of 2000 took 0.035s
  training loss:		0.045734
  validation loss:		0.251125
  validation accuracy:		93.48 %
Epoch 626 of 2000 took 0.035s
  training loss:		0.046058
  validation loss:		0.253078
  validation accuracy:		93.70 %
Epoch 627 of 2000 took 0.035s
  training loss:		0.047445
  validation loss:		0.249342
  validation accuracy:		93.48 %
Epoch 628 of 2000 took 0.035s
  training loss:		0.046475
  validation loss:		0.258307
  validation accuracy:		93.59 %
Epoch 629 of 2000 took 0.035s
  training loss:		0.046921
  validation loss:		0.258628
  validation accuracy:		93.48 %
Epoch 630 of 2000 took 0.035s
  training loss:		0.046459
  validation loss:		0.247860
  validation accuracy:		93.59 %
Epoch 631 of 2000 took 0.035s
  training loss:		0.046331
  validation loss:		0.250515
  validation accuracy:		93.48 %
Epoch 632 of 2000 took 0.035s
  training loss:		0.044987
  validation loss:		0.247513
  validation accuracy:		93.59 %
Epoch 633 of 2000 took 0.035s
  training loss:		0.048022
  validation loss:		0.259069
  validation accuracy:		93.26 %
Epoch 634 of 2000 took 0.035s
  training loss:		0.045263
  validation loss:		0.248643
  validation accuracy:		93.48 %
Epoch 635 of 2000 took 0.035s
  training loss:		0.044332
  validation loss:		0.249556
  validation accuracy:		93.80 %
Epoch 636 of 2000 took 0.035s
  training loss:		0.044002
  validation loss:		0.248617
  validation accuracy:		93.70 %
Epoch 637 of 2000 took 0.035s
  training loss:		0.046021
  validation loss:		0.245450
  validation accuracy:		93.48 %
Epoch 638 of 2000 took 0.035s
  training loss:		0.046106
  validation loss:		0.256757
  validation accuracy:		93.37 %
Epoch 639 of 2000 took 0.035s
  training loss:		0.046159
  validation loss:		0.256670
  validation accuracy:		93.70 %
Epoch 640 of 2000 took 0.035s
  training loss:		0.044647
  validation loss:		0.256858
  validation accuracy:		93.26 %
Epoch 641 of 2000 took 0.035s
  training loss:		0.045710
  validation loss:		0.257104
  validation accuracy:		93.70 %
Epoch 642 of 2000 took 0.035s
  training loss:		0.044500
  validation loss:		0.255038
  validation accuracy:		93.48 %
Epoch 643 of 2000 took 0.035s
  training loss:		0.044601
  validation loss:		0.255073
  validation accuracy:		93.59 %
Epoch 644 of 2000 took 0.035s
  training loss:		0.045101
  validation loss:		0.259710
  validation accuracy:		93.48 %
Epoch 645 of 2000 took 0.035s
  training loss:		0.043961
  validation loss:		0.256467
  validation accuracy:		93.26 %
Epoch 646 of 2000 took 0.035s
  training loss:		0.042808
  validation loss:		0.252596
  validation accuracy:		93.37 %
Epoch 647 of 2000 took 0.035s
  training loss:		0.045557
  validation loss:		0.252194
  validation accuracy:		93.48 %
Epoch 648 of 2000 took 0.035s
  training loss:		0.042775
  validation loss:		0.248822
  validation accuracy:		93.48 %
Epoch 649 of 2000 took 0.035s
  training loss:		0.044523
  validation loss:		0.257306
  validation accuracy:		93.59 %
Epoch 650 of 2000 took 0.035s
  training loss:		0.045148
  validation loss:		0.258544
  validation accuracy:		93.48 %
Epoch 651 of 2000 took 0.035s
  training loss:		0.044423
  validation loss:		0.257540
  validation accuracy:		93.48 %
Epoch 652 of 2000 took 0.035s
  training loss:		0.042828
  validation loss:		0.267713
  validation accuracy:		93.04 %
Epoch 653 of 2000 took 0.035s
  training loss:		0.043147
  validation loss:		0.251667
  validation accuracy:		93.70 %
Epoch 654 of 2000 took 0.035s
  training loss:		0.042201
  validation loss:		0.260860
  validation accuracy:		93.48 %
Epoch 655 of 2000 took 0.035s
  training loss:		0.044183
  validation loss:		0.258463
  validation accuracy:		93.48 %
Epoch 656 of 2000 took 0.035s
  training loss:		0.041848
  validation loss:		0.257762
  validation accuracy:		93.37 %
Epoch 657 of 2000 took 0.035s
  training loss:		0.044833
  validation loss:		0.268148
  validation accuracy:		93.04 %
Epoch 658 of 2000 took 0.035s
  training loss:		0.042424
  validation loss:		0.260764
  validation accuracy:		93.59 %
Epoch 659 of 2000 took 0.035s
  training loss:		0.041650
  validation loss:		0.258394
  validation accuracy:		93.37 %
Epoch 660 of 2000 took 0.035s
  training loss:		0.043610
  validation loss:		0.259669
  validation accuracy:		93.59 %
Epoch 661 of 2000 took 0.035s
  training loss:		0.043208
  validation loss:		0.260827
  validation accuracy:		93.37 %
Epoch 662 of 2000 took 0.035s
  training loss:		0.043127
  validation loss:		0.257051
  validation accuracy:		93.70 %
Epoch 663 of 2000 took 0.035s
  training loss:		0.040683
  validation loss:		0.263304
  validation accuracy:		93.48 %
Epoch 664 of 2000 took 0.035s
  training loss:		0.042944
  validation loss:		0.260897
  validation accuracy:		93.59 %
Epoch 665 of 2000 took 0.035s
  training loss:		0.040257
  validation loss:		0.256571
  validation accuracy:		93.48 %
Epoch 666 of 2000 took 0.035s
  training loss:		0.042144
  validation loss:		0.268452
  validation accuracy:		93.37 %
Epoch 667 of 2000 took 0.035s
  training loss:		0.040191
  validation loss:		0.261446
  validation accuracy:		93.70 %
Epoch 668 of 2000 took 0.035s
  training loss:		0.042377
  validation loss:		0.257205
  validation accuracy:		93.48 %
Epoch 669 of 2000 took 0.035s
  training loss:		0.042120
  validation loss:		0.267893
  validation accuracy:		93.37 %
Epoch 670 of 2000 took 0.035s
  training loss:		0.041976
  validation loss:		0.266174
  validation accuracy:		93.15 %
Epoch 671 of 2000 took 0.035s
  training loss:		0.040240
  validation loss:		0.257625
  validation accuracy:		93.37 %
Epoch 672 of 2000 took 0.035s
  training loss:		0.040889
  validation loss:		0.261305
  validation accuracy:		93.15 %
Epoch 673 of 2000 took 0.035s
  training loss:		0.041567
  validation loss:		0.258264
  validation accuracy:		93.15 %
Epoch 674 of 2000 took 0.035s
  training loss:		0.041377
  validation loss:		0.263400
  validation accuracy:		93.48 %
Epoch 675 of 2000 took 0.035s
  training loss:		0.039643
  validation loss:		0.262024
  validation accuracy:		93.37 %
Epoch 676 of 2000 took 0.035s
  training loss:		0.040353
  validation loss:		0.268484
  validation accuracy:		93.15 %
Epoch 677 of 2000 took 0.035s
  training loss:		0.041176
  validation loss:		0.265418
  validation accuracy:		93.26 %
Epoch 678 of 2000 took 0.035s
  training loss:		0.038755
  validation loss:		0.265634
  validation accuracy:		93.15 %
Epoch 679 of 2000 took 0.035s
  training loss:		0.041853
  validation loss:		0.262094
  validation accuracy:		93.59 %
Epoch 680 of 2000 took 0.035s
  training loss:		0.039417
  validation loss:		0.270511
  validation accuracy:		93.37 %
Epoch 681 of 2000 took 0.035s
  training loss:		0.041413
  validation loss:		0.266190
  validation accuracy:		93.26 %
Epoch 682 of 2000 took 0.035s
  training loss:		0.038488
  validation loss:		0.253511
  validation accuracy:		93.48 %
Epoch 683 of 2000 took 0.035s
  training loss:		0.041517
  validation loss:		0.272525
  validation accuracy:		93.04 %
Epoch 684 of 2000 took 0.035s
  training loss:		0.041942
  validation loss:		0.267143
  validation accuracy:		93.48 %
Epoch 685 of 2000 took 0.035s
  training loss:		0.040364
  validation loss:		0.266258
  validation accuracy:		93.37 %
Epoch 686 of 2000 took 0.035s
  training loss:		0.039947
  validation loss:		0.270242
  validation accuracy:		93.37 %
Epoch 687 of 2000 took 0.035s
  training loss:		0.039949
  validation loss:		0.262571
  validation accuracy:		93.48 %
Epoch 688 of 2000 took 0.035s
  training loss:		0.039447
  validation loss:		0.265623
  validation accuracy:		93.26 %
Epoch 689 of 2000 took 0.035s
  training loss:		0.039891
  validation loss:		0.267205
  validation accuracy:		93.37 %
Epoch 690 of 2000 took 0.035s
  training loss:		0.038542
  validation loss:		0.261425
  validation accuracy:		93.48 %
Epoch 691 of 2000 took 0.035s
  training loss:		0.041031
  validation loss:		0.262381
  validation accuracy:		93.37 %
Epoch 692 of 2000 took 0.035s
  training loss:		0.039202
  validation loss:		0.270557
  validation accuracy:		93.15 %
Epoch 693 of 2000 took 0.035s
  training loss:		0.039888
  validation loss:		0.273376
  validation accuracy:		93.48 %
Epoch 694 of 2000 took 0.035s
  training loss:		0.037955
  validation loss:		0.266289
  validation accuracy:		93.48 %
Epoch 695 of 2000 took 0.035s
  training loss:		0.040206
  validation loss:		0.277662
  validation accuracy:		93.37 %
Epoch 696 of 2000 took 0.035s
  training loss:		0.039695
  validation loss:		0.269879
  validation accuracy:		93.59 %
Epoch 697 of 2000 took 0.035s
  training loss:		0.038703
  validation loss:		0.265054
  validation accuracy:		93.59 %
Epoch 698 of 2000 took 0.035s
  training loss:		0.037624
  validation loss:		0.275928
  validation accuracy:		93.26 %
Epoch 699 of 2000 took 0.035s
  training loss:		0.037963
  validation loss:		0.268342
  validation accuracy:		93.37 %
Epoch 700 of 2000 took 0.035s
  training loss:		0.038658
  validation loss:		0.271811
  validation accuracy:		93.37 %
Epoch 701 of 2000 took 0.035s
  training loss:		0.039082
  validation loss:		0.270438
  validation accuracy:		93.15 %
Epoch 702 of 2000 took 0.035s
  training loss:		0.039014
  validation loss:		0.276074
  validation accuracy:		93.37 %
Epoch 703 of 2000 took 0.035s
  training loss:		0.038226
  validation loss:		0.269170
  validation accuracy:		93.59 %
Epoch 704 of 2000 took 0.035s
  training loss:		0.038739
  validation loss:		0.276948
  validation accuracy:		93.04 %
Epoch 705 of 2000 took 0.035s
  training loss:		0.037988
  validation loss:		0.273202
  validation accuracy:		93.37 %
Epoch 706 of 2000 took 0.035s
  training loss:		0.038387
  validation loss:		0.281596
  validation accuracy:		93.15 %
Epoch 707 of 2000 took 0.035s
  training loss:		0.037064
  validation loss:		0.273048
  validation accuracy:		93.37 %
Epoch 708 of 2000 took 0.035s
  training loss:		0.036965
  validation loss:		0.266899
  validation accuracy:		93.37 %
Epoch 709 of 2000 took 0.035s
  training loss:		0.037860
  validation loss:		0.277386
  validation accuracy:		93.37 %
Epoch 710 of 2000 took 0.035s
  training loss:		0.038319
  validation loss:		0.281794
  validation accuracy:		93.15 %
Epoch 711 of 2000 took 0.035s
  training loss:		0.037743
  validation loss:		0.274924
  validation accuracy:		93.26 %
Epoch 712 of 2000 took 0.035s
  training loss:		0.036468
  validation loss:		0.265026
  validation accuracy:		93.37 %
Epoch 713 of 2000 took 0.035s
  training loss:		0.038453
  validation loss:		0.277321
  validation accuracy:		93.15 %
Epoch 714 of 2000 took 0.035s
  training loss:		0.037262
  validation loss:		0.283018
  validation accuracy:		93.15 %
Epoch 715 of 2000 took 0.035s
  training loss:		0.037375
  validation loss:		0.271504
  validation accuracy:		93.26 %
Epoch 716 of 2000 took 0.035s
  training loss:		0.037073
  validation loss:		0.277101
  validation accuracy:		93.37 %
Epoch 717 of 2000 took 0.035s
  training loss:		0.036349
  validation loss:		0.269067
  validation accuracy:		93.37 %
Epoch 718 of 2000 took 0.035s
  training loss:		0.036492
  validation loss:		0.277003
  validation accuracy:		93.15 %
Epoch 719 of 2000 took 0.035s
  training loss:		0.037389
  validation loss:		0.268670
  validation accuracy:		93.48 %
Epoch 720 of 2000 took 0.035s
  training loss:		0.037748
  validation loss:		0.277939
  validation accuracy:		93.37 %
Epoch 721 of 2000 took 0.035s
  training loss:		0.035780
  validation loss:		0.286059
  validation accuracy:		92.93 %
Epoch 722 of 2000 took 0.035s
  training loss:		0.037518
  validation loss:		0.276758
  validation accuracy:		93.26 %
Epoch 723 of 2000 took 0.035s
  training loss:		0.035906
  validation loss:		0.276782
  validation accuracy:		93.26 %
Epoch 724 of 2000 took 0.035s
  training loss:		0.036519
  validation loss:		0.279271
  validation accuracy:		93.26 %
Epoch 725 of 2000 took 0.035s
  training loss:		0.037338
  validation loss:		0.278372
  validation accuracy:		93.26 %
Epoch 726 of 2000 took 0.035s
  training loss:		0.034652
  validation loss:		0.273787
  validation accuracy:		93.48 %
Epoch 727 of 2000 took 0.035s
  training loss:		0.035515
  validation loss:		0.277477
  validation accuracy:		92.93 %
Epoch 728 of 2000 took 0.035s
  training loss:		0.035492
  validation loss:		0.282631
  validation accuracy:		93.04 %
Epoch 729 of 2000 took 0.035s
  training loss:		0.036259
  validation loss:		0.282171
  validation accuracy:		93.26 %
Epoch 730 of 2000 took 0.035s
  training loss:		0.035776
  validation loss:		0.285137
  validation accuracy:		93.04 %
Epoch 731 of 2000 took 0.035s
  training loss:		0.036734
  validation loss:		0.291490
  validation accuracy:		93.15 %
Epoch 732 of 2000 took 0.035s
  training loss:		0.035972
  validation loss:		0.275266
  validation accuracy:		93.48 %
Epoch 733 of 2000 took 0.035s
  training loss:		0.035362
  validation loss:		0.285771
  validation accuracy:		92.93 %
Epoch 734 of 2000 took 0.035s
  training loss:		0.035930
  validation loss:		0.275368
  validation accuracy:		93.26 %
Epoch 735 of 2000 took 0.035s
  training loss:		0.033746
  validation loss:		0.271281
  validation accuracy:		93.48 %
Epoch 736 of 2000 took 0.035s
  training loss:		0.033979
  validation loss:		0.277981
  validation accuracy:		93.59 %
Epoch 737 of 2000 took 0.035s
  training loss:		0.035719
  validation loss:		0.273173
  validation accuracy:		93.37 %
Epoch 738 of 2000 took 0.035s
  training loss:		0.035476
  validation loss:		0.280724
  validation accuracy:		93.37 %
Epoch 739 of 2000 took 0.035s
  training loss:		0.035828
  validation loss:		0.277793
  validation accuracy:		93.37 %
Epoch 740 of 2000 took 0.035s
  training loss:		0.035062
  validation loss:		0.282022
  validation accuracy:		93.37 %
Epoch 741 of 2000 took 0.035s
  training loss:		0.034414
  validation loss:		0.285031
  validation accuracy:		93.04 %
Epoch 742 of 2000 took 0.035s
  training loss:		0.032568
  validation loss:		0.287090
  validation accuracy:		93.15 %
Epoch 743 of 2000 took 0.035s
  training loss:		0.034660
  validation loss:		0.277809
  validation accuracy:		93.04 %
Epoch 744 of 2000 took 0.035s
  training loss:		0.034409
  validation loss:		0.287815
  validation accuracy:		93.37 %
Epoch 745 of 2000 took 0.035s
  training loss:		0.034390
  validation loss:		0.285162
  validation accuracy:		93.04 %
Epoch 746 of 2000 took 0.035s
  training loss:		0.031456
  validation loss:		0.286219
  validation accuracy:		92.93 %
Epoch 747 of 2000 took 0.035s
  training loss:		0.035845
  validation loss:		0.282997
  validation accuracy:		93.15 %
Epoch 748 of 2000 took 0.035s
  training loss:		0.033586
  validation loss:		0.280037
  validation accuracy:		93.15 %
Epoch 749 of 2000 took 0.035s
  training loss:		0.034025
  validation loss:		0.281325
  validation accuracy:		93.04 %
Epoch 750 of 2000 took 0.035s
  training loss:		0.034209
  validation loss:		0.283989
  validation accuracy:		92.93 %
Epoch 751 of 2000 took 0.035s
  training loss:		0.033777
  validation loss:		0.286236
  validation accuracy:		93.26 %
Epoch 752 of 2000 took 0.035s
  training loss:		0.033724
  validation loss:		0.288359
  validation accuracy:		93.37 %
Epoch 753 of 2000 took 0.035s
  training loss:		0.033344
  validation loss:		0.282578
  validation accuracy:		93.04 %
Epoch 754 of 2000 took 0.035s
  training loss:		0.033585
  validation loss:		0.283487
  validation accuracy:		93.37 %
Epoch 755 of 2000 took 0.035s
  training loss:		0.034764
  validation loss:		0.282132
  validation accuracy:		93.15 %
Epoch 756 of 2000 took 0.035s
  training loss:		0.033074
  validation loss:		0.286867
  validation accuracy:		93.04 %
Epoch 757 of 2000 took 0.035s
  training loss:		0.032747
  validation loss:		0.287459
  validation accuracy:		93.04 %
Epoch 758 of 2000 took 0.035s
  training loss:		0.033346
  validation loss:		0.284413
  validation accuracy:		93.04 %
Epoch 759 of 2000 took 0.035s
  training loss:		0.033334
  validation loss:		0.279707
  validation accuracy:		93.59 %
Epoch 760 of 2000 took 0.035s
  training loss:		0.033745
  validation loss:		0.293309
  validation accuracy:		93.15 %
Epoch 761 of 2000 took 0.035s
  training loss:		0.032890
  validation loss:		0.290064
  validation accuracy:		93.26 %
Epoch 762 of 2000 took 0.035s
  training loss:		0.032419
  validation loss:		0.288521
  validation accuracy:		93.15 %
Epoch 763 of 2000 took 0.035s
  training loss:		0.032201
  validation loss:		0.284691
  validation accuracy:		93.26 %
Epoch 764 of 2000 took 0.035s
  training loss:		0.034228
  validation loss:		0.289974
  validation accuracy:		93.15 %
Epoch 765 of 2000 took 0.035s
  training loss:		0.033218
  validation loss:		0.290006
  validation accuracy:		93.26 %
Epoch 766 of 2000 took 0.035s
  training loss:		0.033388
  validation loss:		0.285619
  validation accuracy:		93.26 %
Epoch 767 of 2000 took 0.035s
  training loss:		0.032352
  validation loss:		0.282503
  validation accuracy:		93.26 %
Epoch 768 of 2000 took 0.035s
  training loss:		0.032067
  validation loss:		0.294471
  validation accuracy:		92.93 %
Epoch 769 of 2000 took 0.035s
  training loss:		0.033187
  validation loss:		0.284559
  validation accuracy:		93.26 %
Epoch 770 of 2000 took 0.035s
  training loss:		0.029655
  validation loss:		0.290286
  validation accuracy:		93.15 %
Epoch 771 of 2000 took 0.035s
  training loss:		0.032675
  validation loss:		0.282365
  validation accuracy:		93.37 %
Epoch 772 of 2000 took 0.035s
  training loss:		0.031060
  validation loss:		0.291924
  validation accuracy:		93.26 %
Epoch 773 of 2000 took 0.035s
  training loss:		0.032028
  validation loss:		0.291628
  validation accuracy:		93.04 %
Epoch 774 of 2000 took 0.035s
  training loss:		0.032254
  validation loss:		0.291445
  validation accuracy:		93.37 %
Epoch 775 of 2000 took 0.035s
  training loss:		0.032136
  validation loss:		0.288247
  validation accuracy:		93.15 %
Epoch 776 of 2000 took 0.035s
  training loss:		0.031753
  validation loss:		0.282280
  validation accuracy:		93.15 %
Epoch 777 of 2000 took 0.035s
  training loss:		0.030847
  validation loss:		0.291190
  validation accuracy:		93.15 %
Epoch 778 of 2000 took 0.035s
  training loss:		0.032601
  validation loss:		0.283782
  validation accuracy:		93.48 %
Epoch 779 of 2000 took 0.035s
  training loss:		0.030740
  validation loss:		0.289807
  validation accuracy:		93.15 %
Epoch 780 of 2000 took 0.035s
  training loss:		0.030142
  validation loss:		0.290104
  validation accuracy:		93.04 %
Epoch 781 of 2000 took 0.035s
  training loss:		0.031324
  validation loss:		0.296803
  validation accuracy:		93.04 %
Epoch 782 of 2000 took 0.035s
  training loss:		0.031477
  validation loss:		0.301183
  validation accuracy:		93.04 %
Epoch 783 of 2000 took 0.035s
  training loss:		0.031054
  validation loss:		0.289299
  validation accuracy:		93.26 %
Epoch 784 of 2000 took 0.035s
  training loss:		0.029949
  validation loss:		0.298512
  validation accuracy:		93.26 %
Epoch 785 of 2000 took 0.035s
  training loss:		0.031790
  validation loss:		0.288128
  validation accuracy:		93.26 %
Epoch 786 of 2000 took 0.035s
  training loss:		0.031235
  validation loss:		0.297153
  validation accuracy:		93.26 %
Epoch 787 of 2000 took 0.035s
  training loss:		0.031109
  validation loss:		0.299520
  validation accuracy:		92.83 %
Epoch 788 of 2000 took 0.035s
  training loss:		0.030121
  validation loss:		0.290778
  validation accuracy:		92.83 %
Epoch 789 of 2000 took 0.035s
  training loss:		0.030502
  validation loss:		0.299683
  validation accuracy:		93.04 %
Epoch 790 of 2000 took 0.035s
  training loss:		0.031380
  validation loss:		0.294685
  validation accuracy:		93.15 %
Epoch 791 of 2000 took 0.035s
  training loss:		0.029726
  validation loss:		0.296596
  validation accuracy:		93.15 %
Epoch 792 of 2000 took 0.035s
  training loss:		0.029748
  validation loss:		0.296620
  validation accuracy:		93.04 %
Epoch 793 of 2000 took 0.035s
  training loss:		0.029010
  validation loss:		0.291044
  validation accuracy:		93.04 %
Epoch 794 of 2000 took 0.035s
  training loss:		0.029774
  validation loss:		0.287174
  validation accuracy:		93.04 %
Epoch 795 of 2000 took 0.035s
  training loss:		0.030357
  validation loss:		0.295213
  validation accuracy:		93.15 %
Epoch 796 of 2000 took 0.035s
  training loss:		0.030350
  validation loss:		0.298683
  validation accuracy:		93.15 %
Epoch 797 of 2000 took 0.035s
  training loss:		0.029794
  validation loss:		0.298154
  validation accuracy:		92.93 %
Epoch 798 of 2000 took 0.035s
  training loss:		0.030939
  validation loss:		0.294824
  validation accuracy:		93.15 %
Epoch 799 of 2000 took 0.035s
  training loss:		0.030196
  validation loss:		0.295316
  validation accuracy:		93.04 %
Epoch 800 of 2000 took 0.035s
  training loss:		0.029461
  validation loss:		0.298530
  validation accuracy:		92.83 %
Epoch 801 of 2000 took 0.035s
  training loss:		0.030409
  validation loss:		0.305683
  validation accuracy:		92.83 %
Epoch 802 of 2000 took 0.035s
  training loss:		0.029567
  validation loss:		0.292262
  validation accuracy:		92.93 %
Epoch 803 of 2000 took 0.035s
  training loss:		0.028835
  validation loss:		0.297472
  validation accuracy:		93.15 %
Epoch 804 of 2000 took 0.035s
  training loss:		0.029063
  validation loss:		0.293805
  validation accuracy:		93.37 %
Epoch 805 of 2000 took 0.035s
  training loss:		0.028846
  validation loss:		0.301668
  validation accuracy:		92.93 %
Epoch 806 of 2000 took 0.035s
  training loss:		0.030193
  validation loss:		0.296641
  validation accuracy:		93.37 %
Epoch 807 of 2000 took 0.035s
  training loss:		0.029176
  validation loss:		0.303779
  validation accuracy:		92.93 %
Epoch 808 of 2000 took 0.035s
  training loss:		0.029991
  validation loss:		0.299735
  validation accuracy:		93.26 %
Epoch 809 of 2000 took 0.035s
  training loss:		0.029629
  validation loss:		0.310342
  validation accuracy:		93.04 %
Epoch 810 of 2000 took 0.035s
  training loss:		0.029238
  validation loss:		0.299401
  validation accuracy:		92.93 %
Epoch 811 of 2000 took 0.035s
  training loss:		0.028298
  validation loss:		0.298953
  validation accuracy:		92.93 %
Epoch 812 of 2000 took 0.035s
  training loss:		0.028638
  validation loss:		0.303034
  validation accuracy:		92.83 %
Epoch 813 of 2000 took 0.035s
  training loss:		0.028533
  validation loss:		0.302102
  validation accuracy:		92.93 %
Epoch 814 of 2000 took 0.035s
  training loss:		0.029468
  validation loss:		0.300029
  validation accuracy:		93.04 %
Epoch 815 of 2000 took 0.035s
  training loss:		0.028261
  validation loss:		0.306049
  validation accuracy:		93.04 %
Epoch 816 of 2000 took 0.035s
  training loss:		0.028381
  validation loss:		0.303472
  validation accuracy:		93.04 %
Epoch 817 of 2000 took 0.035s
  training loss:		0.027480
  validation loss:		0.299838
  validation accuracy:		93.15 %
Epoch 818 of 2000 took 0.035s
  training loss:		0.028392
  validation loss:		0.298964
  validation accuracy:		92.93 %
Epoch 819 of 2000 took 0.035s
  training loss:		0.026753
  validation loss:		0.299969
  validation accuracy:		93.04 %
Epoch 820 of 2000 took 0.035s
  training loss:		0.027490
  validation loss:		0.307915
  validation accuracy:		92.83 %
Epoch 821 of 2000 took 0.035s
  training loss:		0.028404
  validation loss:		0.300980
  validation accuracy:		93.15 %
Epoch 822 of 2000 took 0.035s
  training loss:		0.027101
  validation loss:		0.307718
  validation accuracy:		93.04 %
Epoch 823 of 2000 took 0.035s
  training loss:		0.027610
  validation loss:		0.293443
  validation accuracy:		93.37 %
Epoch 824 of 2000 took 0.035s
  training loss:		0.027458
  validation loss:		0.300216
  validation accuracy:		93.26 %
Epoch 825 of 2000 took 0.035s
  training loss:		0.027853
  validation loss:		0.307886
  validation accuracy:		93.15 %
Epoch 826 of 2000 took 0.035s
  training loss:		0.027423
  validation loss:		0.306693
  validation accuracy:		92.93 %
Epoch 827 of 2000 took 0.035s
  training loss:		0.026820
  validation loss:		0.303689
  validation accuracy:		93.37 %
Epoch 828 of 2000 took 0.035s
  training loss:		0.027224
  validation loss:		0.305331
  validation accuracy:		92.93 %
Epoch 829 of 2000 took 0.035s
  training loss:		0.026836
  validation loss:		0.310118
  validation accuracy:		92.93 %
Epoch 830 of 2000 took 0.035s
  training loss:		0.027109
  validation loss:		0.315387
  validation accuracy:		93.04 %
Epoch 831 of 2000 took 0.037s
  training loss:		0.026680
  validation loss:		0.304745
  validation accuracy:		92.93 %
Epoch 832 of 2000 took 0.035s
  training loss:		0.027676
  validation loss:		0.306470
  validation accuracy:		93.04 %
Epoch 833 of 2000 took 0.035s
  training loss:		0.026622
  validation loss:		0.300816
  validation accuracy:		92.72 %
Epoch 834 of 2000 took 0.035s
  training loss:		0.026659
  validation loss:		0.305338
  validation accuracy:		92.83 %
Epoch 835 of 2000 took 0.035s
  training loss:		0.026977
  validation loss:		0.308347
  validation accuracy:		93.04 %
Epoch 836 of 2000 took 0.035s
  training loss:		0.027203
  validation loss:		0.309191
  validation accuracy:		92.93 %
Epoch 837 of 2000 took 0.035s
  training loss:		0.026256
  validation loss:		0.307003
  validation accuracy:		93.15 %
Epoch 838 of 2000 took 0.035s
  training loss:		0.027186
  validation loss:		0.312853
  validation accuracy:		92.93 %
Epoch 839 of 2000 took 0.035s
  training loss:		0.026901
  validation loss:		0.312685
  validation accuracy:		92.83 %
Epoch 840 of 2000 took 0.035s
  training loss:		0.026537
  validation loss:		0.309331
  validation accuracy:		93.04 %
Epoch 841 of 2000 took 0.035s
  training loss:		0.026988
  validation loss:		0.310308
  validation accuracy:		93.15 %
Epoch 842 of 2000 took 0.035s
  training loss:		0.026540
  validation loss:		0.317686
  validation accuracy:		92.61 %
Epoch 843 of 2000 took 0.035s
  training loss:		0.025735
  validation loss:		0.307777
  validation accuracy:		93.04 %
Epoch 844 of 2000 took 0.035s
  training loss:		0.025899
  validation loss:		0.308125
  validation accuracy:		92.83 %
Epoch 845 of 2000 took 0.035s
  training loss:		0.026124
  validation loss:		0.302206
  validation accuracy:		93.04 %
Epoch 846 of 2000 took 0.035s
  training loss:		0.026950
  validation loss:		0.306655
  validation accuracy:		93.15 %
Epoch 847 of 2000 took 0.035s
  training loss:		0.026266
  validation loss:		0.299219
  validation accuracy:		93.04 %
Epoch 848 of 2000 took 0.035s
  training loss:		0.025418
  validation loss:		0.304598
  validation accuracy:		93.04 %
Epoch 849 of 2000 took 0.035s
  training loss:		0.025877
  validation loss:		0.304709
  validation accuracy:		93.04 %
Epoch 850 of 2000 took 0.035s
  training loss:		0.025213
  validation loss:		0.305610
  validation accuracy:		93.26 %
Epoch 851 of 2000 took 0.035s
  training loss:		0.025874
  validation loss:		0.310807
  validation accuracy:		92.72 %
Epoch 852 of 2000 took 0.035s
  training loss:		0.026265
  validation loss:		0.316478
  validation accuracy:		92.93 %
Epoch 853 of 2000 took 0.035s
  training loss:		0.026461
  validation loss:		0.316497
  validation accuracy:		92.93 %
Epoch 854 of 2000 took 0.035s
  training loss:		0.025981
  validation loss:		0.306310
  validation accuracy:		92.93 %
Epoch 855 of 2000 took 0.035s
  training loss:		0.025338
  validation loss:		0.309150
  validation accuracy:		92.83 %
Epoch 856 of 2000 took 0.035s
  training loss:		0.025248
  validation loss:		0.311953
  validation accuracy:		93.04 %
Epoch 857 of 2000 took 0.035s
  training loss:		0.025490
  validation loss:		0.305281
  validation accuracy:		92.93 %
Epoch 858 of 2000 took 0.035s
  training loss:		0.025960
  validation loss:		0.315513
  validation accuracy:		92.83 %
Epoch 859 of 2000 took 0.035s
  training loss:		0.026068
  validation loss:		0.310454
  validation accuracy:		93.26 %
Epoch 860 of 2000 took 0.035s
  training loss:		0.024014
  validation loss:		0.306876
  validation accuracy:		93.37 %
Epoch 861 of 2000 took 0.035s
  training loss:		0.025536
  validation loss:		0.308579
  validation accuracy:		92.93 %
Epoch 862 of 2000 took 0.035s
  training loss:		0.025709
  validation loss:		0.308223
  validation accuracy:		92.93 %
Epoch 863 of 2000 took 0.035s
  training loss:		0.025191
  validation loss:		0.315177
  validation accuracy:		92.72 %
Epoch 864 of 2000 took 0.035s
  training loss:		0.024266
  validation loss:		0.319122
  validation accuracy:		92.93 %
Epoch 865 of 2000 took 0.035s
  training loss:		0.025712
  validation loss:		0.314810
  validation accuracy:		92.93 %
Epoch 866 of 2000 took 0.035s
  training loss:		0.025173
  validation loss:		0.312143
  validation accuracy:		92.93 %
Epoch 867 of 2000 took 0.035s
  training loss:		0.024937
  validation loss:		0.317420
  validation accuracy:		92.83 %
Epoch 868 of 2000 took 0.035s
  training loss:		0.024739
  validation loss:		0.306155
  validation accuracy:		92.83 %
Epoch 869 of 2000 took 0.035s
  training loss:		0.025508
  validation loss:		0.324779
  validation accuracy:		93.15 %
Epoch 870 of 2000 took 0.035s
  training loss:		0.024740
  validation loss:		0.315533
  validation accuracy:		93.04 %
Epoch 871 of 2000 took 0.035s
  training loss:		0.024105
  validation loss:		0.315213
  validation accuracy:		93.15 %
Epoch 872 of 2000 took 0.035s
  training loss:		0.024111
  validation loss:		0.318270
  validation accuracy:		93.04 %
Epoch 873 of 2000 took 0.035s
  training loss:		0.023676
  validation loss:		0.321595
  validation accuracy:		92.93 %
Epoch 874 of 2000 took 0.035s
  training loss:		0.024022
  validation loss:		0.317284
  validation accuracy:		92.93 %
Epoch 875 of 2000 took 0.035s
  training loss:		0.024442
  validation loss:		0.334169
  validation accuracy:		92.93 %
Epoch 876 of 2000 took 0.035s
  training loss:		0.024431
  validation loss:		0.313641
  validation accuracy:		92.83 %
Epoch 877 of 2000 took 0.035s
  training loss:		0.024473
  validation loss:		0.314578
  validation accuracy:		92.93 %
Epoch 878 of 2000 took 0.035s
  training loss:		0.023892
  validation loss:		0.321268
  validation accuracy:		93.04 %
Epoch 879 of 2000 took 0.035s
  training loss:		0.023447
  validation loss:		0.313686
  validation accuracy:		93.15 %
Epoch 880 of 2000 took 0.035s
  training loss:		0.023871
  validation loss:		0.320500
  validation accuracy:		92.93 %
Epoch 881 of 2000 took 0.035s
  training loss:		0.023512
  validation loss:		0.317857
  validation accuracy:		92.83 %
Epoch 882 of 2000 took 0.035s
  training loss:		0.023743
  validation loss:		0.313815
  validation accuracy:		93.15 %
Epoch 883 of 2000 took 0.035s
  training loss:		0.023934
  validation loss:		0.315750
  validation accuracy:		93.26 %
Epoch 884 of 2000 took 0.035s
  training loss:		0.024501
  validation loss:		0.320957
  validation accuracy:		92.83 %
Epoch 885 of 2000 took 0.035s
  training loss:		0.023773
  validation loss:		0.311704
  validation accuracy:		93.04 %
Epoch 886 of 2000 took 0.035s
  training loss:		0.022891
  validation loss:		0.319160
  validation accuracy:		93.04 %
Epoch 887 of 2000 took 0.035s
  training loss:		0.022675
  validation loss:		0.318516
  validation accuracy:		92.83 %
Epoch 888 of 2000 took 0.035s
  training loss:		0.022169
  validation loss:		0.318733
  validation accuracy:		93.15 %
Epoch 889 of 2000 took 0.035s
  training loss:		0.024071
  validation loss:		0.312898
  validation accuracy:		92.83 %
Epoch 890 of 2000 took 0.035s
  training loss:		0.023451
  validation loss:		0.324248
  validation accuracy:		92.72 %
Epoch 891 of 2000 took 0.035s
  training loss:		0.023140
  validation loss:		0.312326
  validation accuracy:		92.72 %
Epoch 892 of 2000 took 0.035s
  training loss:		0.023603
  validation loss:		0.312042
  validation accuracy:		92.93 %
Epoch 893 of 2000 took 0.035s
  training loss:		0.022457
  validation loss:		0.319817
  validation accuracy:		92.72 %
Epoch 894 of 2000 took 0.035s
  training loss:		0.021909
  validation loss:		0.318967
  validation accuracy:		93.26 %
Epoch 895 of 2000 took 0.035s
  training loss:		0.023212
  validation loss:		0.314122
  validation accuracy:		93.04 %
Epoch 896 of 2000 took 0.035s
  training loss:		0.023065
  validation loss:		0.325632
  validation accuracy:		92.83 %
Epoch 897 of 2000 took 0.035s
  training loss:		0.022484
  validation loss:		0.320968
  validation accuracy:		92.83 %
Epoch 898 of 2000 took 0.035s
  training loss:		0.023267
  validation loss:		0.322837
  validation accuracy:		92.93 %
Epoch 899 of 2000 took 0.035s
  training loss:		0.023236
  validation loss:		0.328719
  validation accuracy:		93.26 %
Epoch 900 of 2000 took 0.035s
  training loss:		0.022566
  validation loss:		0.320210
  validation accuracy:		92.83 %
Epoch 901 of 2000 took 0.035s
  training loss:		0.022377
  validation loss:		0.331236
  validation accuracy:		92.72 %
Epoch 902 of 2000 took 0.035s
  training loss:		0.023556
  validation loss:		0.322251
  validation accuracy:		92.83 %
Epoch 903 of 2000 took 0.035s
  training loss:		0.023157
  validation loss:		0.333397
  validation accuracy:		92.83 %
Epoch 904 of 2000 took 0.035s
  training loss:		0.022260
  validation loss:		0.324032
  validation accuracy:		92.61 %
Epoch 905 of 2000 took 0.035s
  training loss:		0.022794
  validation loss:		0.335775
  validation accuracy:		93.15 %
Epoch 906 of 2000 took 0.035s
  training loss:		0.023059
  validation loss:		0.325374
  validation accuracy:		92.83 %
Epoch 907 of 2000 took 0.035s
  training loss:		0.022717
  validation loss:		0.318631
  validation accuracy:		93.15 %
Epoch 908 of 2000 took 0.035s
  training loss:		0.022939
  validation loss:		0.322491
  validation accuracy:		92.61 %
Epoch 909 of 2000 took 0.035s
  training loss:		0.022759
  validation loss:		0.322944
  validation accuracy:		93.04 %
Epoch 910 of 2000 took 0.035s
  training loss:		0.022718
  validation loss:		0.316741
  validation accuracy:		93.04 %
Epoch 911 of 2000 took 0.035s
  training loss:		0.022331
  validation loss:		0.325527
  validation accuracy:		92.93 %
Epoch 912 of 2000 took 0.035s
  training loss:		0.023071
  validation loss:		0.322485
  validation accuracy:		93.04 %
Epoch 913 of 2000 took 0.035s
  training loss:		0.022519
  validation loss:		0.337118
  validation accuracy:		92.93 %
Epoch 914 of 2000 took 0.035s
  training loss:		0.022156
  validation loss:		0.327114
  validation accuracy:		92.83 %
Epoch 915 of 2000 took 0.035s
  training loss:		0.021944
  validation loss:		0.329068
  validation accuracy:		92.72 %
Epoch 916 of 2000 took 0.035s
  training loss:		0.021880
  validation loss:		0.318266
  validation accuracy:		93.26 %
Epoch 917 of 2000 took 0.035s
  training loss:		0.021967
  validation loss:		0.322413
  validation accuracy:		92.83 %
Epoch 918 of 2000 took 0.035s
  training loss:		0.022011
  validation loss:		0.320671
  validation accuracy:		93.26 %
Epoch 919 of 2000 took 0.035s
  training loss:		0.022064
  validation loss:		0.326495
  validation accuracy:		92.83 %
Epoch 920 of 2000 took 0.035s
  training loss:		0.020950
  validation loss:		0.333694
  validation accuracy:		92.83 %
Epoch 921 of 2000 took 0.035s
  training loss:		0.022563
  validation loss:		0.329681
  validation accuracy:		92.72 %
Epoch 922 of 2000 took 0.035s
  training loss:		0.022124
  validation loss:		0.329427
  validation accuracy:		92.72 %
Epoch 923 of 2000 took 0.035s
  training loss:		0.020535
  validation loss:		0.330001
  validation accuracy:		92.93 %
Epoch 924 of 2000 took 0.035s
  training loss:		0.021367
  validation loss:		0.323895
  validation accuracy:		92.72 %
Epoch 925 of 2000 took 0.035s
  training loss:		0.021444
  validation loss:		0.318432
  validation accuracy:		92.93 %
Epoch 926 of 2000 took 0.035s
  training loss:		0.021280
  validation loss:		0.329133
  validation accuracy:		92.83 %
Epoch 927 of 2000 took 0.035s
  training loss:		0.020720
  validation loss:		0.327039
  validation accuracy:		93.04 %
Epoch 928 of 2000 took 0.035s
  training loss:		0.021375
  validation loss:		0.334504
  validation accuracy:		92.83 %
Epoch 929 of 2000 took 0.035s
  training loss:		0.021217
  validation loss:		0.326574
  validation accuracy:		92.61 %
Epoch 930 of 2000 took 0.035s
  training loss:		0.021224
  validation loss:		0.332429
  validation accuracy:		92.83 %
Epoch 931 of 2000 took 0.035s
  training loss:		0.020801
  validation loss:		0.330952
  validation accuracy:		92.72 %
Epoch 932 of 2000 took 0.035s
  training loss:		0.019945
  validation loss:		0.331914
  validation accuracy:		92.83 %
Epoch 933 of 2000 took 0.035s
  training loss:		0.021115
  validation loss:		0.329795
  validation accuracy:		92.83 %
Epoch 934 of 2000 took 0.035s
  training loss:		0.021277
  validation loss:		0.341388
  validation accuracy:		92.83 %
Epoch 935 of 2000 took 0.035s
  training loss:		0.021360
  validation loss:		0.326533
  validation accuracy:		93.04 %
Epoch 936 of 2000 took 0.035s
  training loss:		0.020917
  validation loss:		0.334389
  validation accuracy:		92.93 %
Epoch 937 of 2000 took 0.035s
  training loss:		0.020415
  validation loss:		0.329580
  validation accuracy:		92.93 %
Epoch 938 of 2000 took 0.035s
  training loss:		0.020592
  validation loss:		0.333541
  validation accuracy:		92.93 %
Epoch 939 of 2000 took 0.035s
  training loss:		0.020294
  validation loss:		0.331779
  validation accuracy:		92.93 %
Epoch 940 of 2000 took 0.035s
  training loss:		0.019052
  validation loss:		0.335638
  validation accuracy:		93.15 %
Epoch 941 of 2000 took 0.035s
  training loss:		0.020026
  validation loss:		0.337683
  validation accuracy:		93.04 %
Epoch 942 of 2000 took 0.035s
  training loss:		0.021031
  validation loss:		0.335603
  validation accuracy:		92.72 %
Epoch 943 of 2000 took 0.035s
  training loss:		0.020350
  validation loss:		0.333141
  validation accuracy:		92.83 %
Epoch 944 of 2000 took 0.035s
  training loss:		0.020699
  validation loss:		0.338068
  validation accuracy:		92.72 %
Epoch 945 of 2000 took 0.035s
  training loss:		0.020323
  validation loss:		0.328068
  validation accuracy:		92.83 %
Epoch 946 of 2000 took 0.035s
  training loss:		0.020408
  validation loss:		0.337442
  validation accuracy:		92.83 %
Epoch 947 of 2000 took 0.035s
  training loss:		0.020438
  validation loss:		0.334382
  validation accuracy:		92.93 %
Epoch 948 of 2000 took 0.035s
  training loss:		0.020637
  validation loss:		0.340218
  validation accuracy:		92.72 %
Epoch 949 of 2000 took 0.035s
  training loss:		0.020617
  validation loss:		0.341537
  validation accuracy:		92.72 %
Epoch 950 of 2000 took 0.035s
  training loss:		0.019527
  validation loss:		0.340642
  validation accuracy:		92.72 %
Epoch 951 of 2000 took 0.035s
  training loss:		0.020576
  validation loss:		0.342112
  validation accuracy:		92.93 %
Epoch 952 of 2000 took 0.035s
  training loss:		0.020468
  validation loss:		0.339045
  validation accuracy:		92.83 %
Epoch 953 of 2000 took 0.035s
  training loss:		0.020804
  validation loss:		0.332679
  validation accuracy:		92.83 %
Epoch 954 of 2000 took 0.035s
  training loss:		0.019953
  validation loss:		0.333311
  validation accuracy:		92.72 %
Epoch 955 of 2000 took 0.035s
  training loss:		0.019532
  validation loss:		0.343325
  validation accuracy:		92.83 %
Epoch 956 of 2000 took 0.035s
  training loss:		0.019702
  validation loss:		0.333511
  validation accuracy:		92.72 %
Epoch 957 of 2000 took 0.035s
  training loss:		0.020056
  validation loss:		0.342867
  validation accuracy:		92.83 %
Epoch 958 of 2000 took 0.035s
  training loss:		0.018052
  validation loss:		0.340181
  validation accuracy:		92.83 %
Epoch 959 of 2000 took 0.035s
  training loss:		0.019819
  validation loss:		0.338566
  validation accuracy:		92.72 %
Epoch 960 of 2000 took 0.035s
  training loss:		0.019013
  validation loss:		0.344800
  validation accuracy:		92.72 %
Epoch 961 of 2000 took 0.035s
  training loss:		0.019636
  validation loss:		0.347509
  validation accuracy:		92.83 %
Epoch 962 of 2000 took 0.035s
  training loss:		0.019559
  validation loss:		0.339341
  validation accuracy:		92.83 %
Epoch 963 of 2000 took 0.035s
  training loss:		0.019804
  validation loss:		0.342482
  validation accuracy:		93.04 %
Epoch 964 of 2000 took 0.035s
  training loss:		0.019643
  validation loss:		0.346226
  validation accuracy:		92.83 %
Epoch 965 of 2000 took 0.035s
  training loss:		0.019792
  validation loss:		0.341673
  validation accuracy:		92.83 %
Epoch 966 of 2000 took 0.035s
  training loss:		0.019279
  validation loss:		0.339494
  validation accuracy:		93.04 %
Epoch 967 of 2000 took 0.035s
  training loss:		0.018074
  validation loss:		0.348848
  validation accuracy:		92.83 %
Epoch 968 of 2000 took 0.035s
  training loss:		0.019563
  validation loss:		0.339188
  validation accuracy:		92.61 %
Epoch 969 of 2000 took 0.035s
  training loss:		0.019329
  validation loss:		0.341601
  validation accuracy:		92.93 %
Epoch 970 of 2000 took 0.035s
  training loss:		0.019755
  validation loss:		0.339670
  validation accuracy:		92.72 %
Epoch 971 of 2000 took 0.035s
  training loss:		0.019348
  validation loss:		0.345337
  validation accuracy:		92.72 %
Epoch 972 of 2000 took 0.035s
  training loss:		0.019392
  validation loss:		0.340442
  validation accuracy:		92.93 %
Epoch 973 of 2000 took 0.035s
  training loss:		0.019266
  validation loss:		0.349835
  validation accuracy:		92.83 %
Epoch 974 of 2000 took 0.035s
  training loss:		0.019385
  validation loss:		0.338224
  validation accuracy:		92.93 %
Epoch 975 of 2000 took 0.035s
  training loss:		0.018783
  validation loss:		0.339021
  validation accuracy:		93.04 %
Epoch 976 of 2000 took 0.035s
  training loss:		0.018945
  validation loss:		0.345716
  validation accuracy:		92.72 %
Epoch 977 of 2000 took 0.035s
  training loss:		0.018125
  validation loss:		0.347449
  validation accuracy:		92.72 %
Epoch 978 of 2000 took 0.035s
  training loss:		0.019847
  validation loss:		0.343422
  validation accuracy:		93.04 %
Epoch 979 of 2000 took 0.035s
  training loss:		0.018978
  validation loss:		0.344281
  validation accuracy:		92.61 %
Epoch 980 of 2000 took 0.035s
  training loss:		0.017398
  validation loss:		0.350432
  validation accuracy:		92.93 %
Epoch 981 of 2000 took 0.035s
  training loss:		0.018570
  validation loss:		0.339535
  validation accuracy:		92.72 %
Epoch 982 of 2000 took 0.035s
  training loss:		0.018544
  validation loss:		0.344456
  validation accuracy:		92.83 %
Epoch 983 of 2000 took 0.035s
  training loss:		0.018524
  validation loss:		0.349010
  validation accuracy:		92.83 %
Epoch 984 of 2000 took 0.035s
  training loss:		0.018522
  validation loss:		0.350457
  validation accuracy:		92.93 %
Epoch 985 of 2000 took 0.035s
  training loss:		0.018887
  validation loss:		0.336655
  validation accuracy:		93.04 %
Epoch 986 of 2000 took 0.035s
  training loss:		0.018862
  validation loss:		0.344006
  validation accuracy:		92.83 %
Epoch 987 of 2000 took 0.035s
  training loss:		0.018237
  validation loss:		0.353377
  validation accuracy:		92.72 %
Epoch 988 of 2000 took 0.035s
  training loss:		0.017894
  validation loss:		0.351643
  validation accuracy:		92.83 %
Epoch 989 of 2000 took 0.035s
  training loss:		0.018824
  validation loss:		0.339082
  validation accuracy:		92.72 %
Epoch 990 of 2000 took 0.035s
  training loss:		0.017348
  validation loss:		0.352749
  validation accuracy:		92.72 %
Epoch 991 of 2000 took 0.035s
  training loss:		0.018093
  validation loss:		0.345073
  validation accuracy:		92.72 %
Epoch 992 of 2000 took 0.035s
  training loss:		0.018320
  validation loss:		0.342110
  validation accuracy:		92.93 %
Epoch 993 of 2000 took 0.035s
  training loss:		0.018546
  validation loss:		0.350217
  validation accuracy:		92.83 %
Epoch 994 of 2000 took 0.035s
  training loss:		0.017935
  validation loss:		0.346650
  validation accuracy:		92.72 %
Epoch 995 of 2000 took 0.035s
  training loss:		0.018348
  validation loss:		0.343849
  validation accuracy:		92.83 %
Epoch 996 of 2000 took 0.035s
  training loss:		0.018039
  validation loss:		0.347221
  validation accuracy:		92.72 %
Epoch 997 of 2000 took 0.035s
  training loss:		0.017468
  validation loss:		0.359857
  validation accuracy:		92.39 %
Epoch 998 of 2000 took 0.035s
  training loss:		0.018445
  validation loss:		0.347946
  validation accuracy:		92.83 %
Epoch 999 of 2000 took 0.035s
  training loss:		0.016889
  validation loss:		0.353911
  validation accuracy:		92.61 %
Epoch 1000 of 2000 took 0.035s
  training loss:		0.017651
  validation loss:		0.356224
  validation accuracy:		92.61 %
Epoch 1001 of 2000 took 0.035s
  training loss:		0.018128
  validation loss:		0.354108
  validation accuracy:		92.72 %
Epoch 1002 of 2000 took 0.035s
  training loss:		0.017565
  validation loss:		0.350013
  validation accuracy:		92.72 %
Epoch 1003 of 2000 took 0.035s
  training loss:		0.018008
  validation loss:		0.349065
  validation accuracy:		92.72 %
Epoch 1004 of 2000 took 0.035s
  training loss:		0.018010
  validation loss:		0.355559
  validation accuracy:		92.83 %
Epoch 1005 of 2000 took 0.035s
  training loss:		0.017136
  validation loss:		0.354429
  validation accuracy:		92.72 %
Epoch 1006 of 2000 took 0.035s
  training loss:		0.017300
  validation loss:		0.356459
  validation accuracy:		92.83 %
Epoch 1007 of 2000 took 0.035s
  training loss:		0.017748
  validation loss:		0.346470
  validation accuracy:		92.61 %
Epoch 1008 of 2000 took 0.035s
  training loss:		0.017322
  validation loss:		0.358856
  validation accuracy:		92.72 %
Epoch 1009 of 2000 took 0.035s
  training loss:		0.017298
  validation loss:		0.355221
  validation accuracy:		92.83 %
Epoch 1010 of 2000 took 0.035s
  training loss:		0.017323
  validation loss:		0.364263
  validation accuracy:		92.83 %
Epoch 1011 of 2000 took 0.035s
  training loss:		0.017521
  validation loss:		0.350589
  validation accuracy:		92.72 %
Epoch 1012 of 2000 took 0.035s
  training loss:		0.017740
  validation loss:		0.351432
  validation accuracy:		92.72 %
Epoch 1013 of 2000 took 0.035s
  training loss:		0.017269
  validation loss:		0.347975
  validation accuracy:		93.04 %
Epoch 1014 of 2000 took 0.035s
  training loss:		0.017579
  validation loss:		0.357631
  validation accuracy:		92.72 %
Epoch 1015 of 2000 took 0.035s
  training loss:		0.017286
  validation loss:		0.353947
  validation accuracy:		92.61 %
Epoch 1016 of 2000 took 0.035s
  training loss:		0.017356
  validation loss:		0.352371
  validation accuracy:		92.83 %
Epoch 1017 of 2000 took 0.035s
  training loss:		0.017438
  validation loss:		0.355124
  validation accuracy:		92.83 %
Epoch 1018 of 2000 took 0.035s
  training loss:		0.017017
  validation loss:		0.357747
  validation accuracy:		92.72 %
Epoch 1019 of 2000 took 0.035s
  training loss:		0.017304
  validation loss:		0.352521
  validation accuracy:		92.83 %
Epoch 1020 of 2000 took 0.035s
  training loss:		0.017105
  validation loss:		0.353669
  validation accuracy:		92.72 %
Epoch 1021 of 2000 took 0.035s
  training loss:		0.017353
  validation loss:		0.357972
  validation accuracy:		92.72 %
Epoch 1022 of 2000 took 0.035s
  training loss:		0.016430
  validation loss:		0.357000
  validation accuracy:		92.72 %
Epoch 1023 of 2000 took 0.035s
  training loss:		0.016795
  validation loss:		0.356796
  validation accuracy:		92.72 %
Epoch 1024 of 2000 took 0.035s
  training loss:		0.017395
  validation loss:		0.356833
  validation accuracy:		92.72 %
Epoch 1025 of 2000 took 0.035s
  training loss:		0.016107
  validation loss:		0.354525
  validation accuracy:		92.61 %
Epoch 1026 of 2000 took 0.035s
  training loss:		0.016477
  validation loss:		0.355305
  validation accuracy:		93.04 %
Epoch 1027 of 2000 took 0.035s
  training loss:		0.016962
  validation loss:		0.355560
  validation accuracy:		92.72 %
Epoch 1028 of 2000 took 0.035s
  training loss:		0.016874
  validation loss:		0.360152
  validation accuracy:		92.61 %
Epoch 1029 of 2000 took 0.035s
  training loss:		0.016836
  validation loss:		0.356478
  validation accuracy:		92.83 %
Epoch 1030 of 2000 took 0.035s
  training loss:		0.016469
  validation loss:		0.366408
  validation accuracy:		92.72 %
Epoch 1031 of 2000 took 0.035s
  training loss:		0.016987
  validation loss:		0.361203
  validation accuracy:		92.61 %
Epoch 1032 of 2000 took 0.035s
  training loss:		0.016608
  validation loss:		0.361074
  validation accuracy:		92.83 %
Epoch 1033 of 2000 took 0.035s
  training loss:		0.016796
  validation loss:		0.362114
  validation accuracy:		92.61 %
Epoch 1034 of 2000 took 0.035s
  training loss:		0.015996
  validation loss:		0.360868
  validation accuracy:		92.83 %
Epoch 1035 of 2000 took 0.035s
  training loss:		0.016662
  validation loss:		0.355707
  validation accuracy:		92.83 %
Epoch 1036 of 2000 took 0.035s
  training loss:		0.016498
  validation loss:		0.364119
  validation accuracy:		92.72 %
Epoch 1037 of 2000 took 0.035s
  training loss:		0.016889
  validation loss:		0.356615
  validation accuracy:		92.72 %
Epoch 1038 of 2000 took 0.035s
  training loss:		0.016603
  validation loss:		0.355965
  validation accuracy:		92.72 %
Epoch 1039 of 2000 took 0.035s
  training loss:		0.016475
  validation loss:		0.359166
  validation accuracy:		92.72 %
Epoch 1040 of 2000 took 0.035s
  training loss:		0.016063
  validation loss:		0.362631
  validation accuracy:		92.72 %
Epoch 1041 of 2000 took 0.035s
  training loss:		0.015901
  validation loss:		0.364705
  validation accuracy:		92.61 %
Epoch 1042 of 2000 took 0.035s
  training loss:		0.015897
  validation loss:		0.359867
  validation accuracy:		92.61 %
Epoch 1043 of 2000 took 0.035s
  training loss:		0.016712
  validation loss:		0.363086
  validation accuracy:		92.72 %
Epoch 1044 of 2000 took 0.035s
  training loss:		0.016266
  validation loss:		0.352370
  validation accuracy:		92.72 %
Epoch 1045 of 2000 took 0.035s
  training loss:		0.016507
  validation loss:		0.358182
  validation accuracy:		92.61 %
Epoch 1046 of 2000 took 0.035s
  training loss:		0.015794
  validation loss:		0.362332
  validation accuracy:		92.93 %
Epoch 1047 of 2000 took 0.035s
  training loss:		0.016463
  validation loss:		0.354463
  validation accuracy:		92.72 %
Epoch 1048 of 2000 took 0.035s
  training loss:		0.016169
  validation loss:		0.363357
  validation accuracy:		92.72 %
Epoch 1049 of 2000 took 0.035s
  training loss:		0.016069
  validation loss:		0.366862
  validation accuracy:		92.83 %
Epoch 1050 of 2000 took 0.035s
  training loss:		0.015845
  validation loss:		0.361249
  validation accuracy:		92.72 %
Epoch 1051 of 2000 took 0.035s
  training loss:		0.015479
  validation loss:		0.358865
  validation accuracy:		92.83 %
Epoch 1052 of 2000 took 0.035s
  training loss:		0.015663
  validation loss:		0.360861
  validation accuracy:		92.72 %
Epoch 1053 of 2000 took 0.035s
  training loss:		0.015704
  validation loss:		0.367718
  validation accuracy:		92.72 %
Epoch 1054 of 2000 took 0.035s
  training loss:		0.015652
  validation loss:		0.358018
  validation accuracy:		92.83 %
Epoch 1055 of 2000 took 0.035s
  training loss:		0.015716
  validation loss:		0.368907
  validation accuracy:		92.61 %
Epoch 1056 of 2000 took 0.035s
  training loss:		0.016172
  validation loss:		0.361972
  validation accuracy:		92.83 %
Epoch 1057 of 2000 took 0.035s
  training loss:		0.015222
  validation loss:		0.361021
  validation accuracy:		92.72 %
Epoch 1058 of 2000 took 0.035s
  training loss:		0.015393
  validation loss:		0.360535
  validation accuracy:		92.72 %
Epoch 1059 of 2000 took 0.035s
  training loss:		0.016104
  validation loss:		0.366995
  validation accuracy:		92.72 %
Epoch 1060 of 2000 took 0.035s
  training loss:		0.015660
  validation loss:		0.357499
  validation accuracy:		92.83 %
Epoch 1061 of 2000 took 0.035s
  training loss:		0.015642
  validation loss:		0.361218
  validation accuracy:		92.72 %
Epoch 1062 of 2000 took 0.035s
  training loss:		0.015933
  validation loss:		0.373490
  validation accuracy:		92.83 %
Epoch 1063 of 2000 took 0.035s
  training loss:		0.015402
  validation loss:		0.362160
  validation accuracy:		92.72 %
Epoch 1064 of 2000 took 0.035s
  training loss:		0.015300
  validation loss:		0.358502
  validation accuracy:		92.72 %
Epoch 1065 of 2000 took 0.035s
  training loss:		0.015072
  validation loss:		0.367615
  validation accuracy:		92.61 %
Epoch 1066 of 2000 took 0.035s
  training loss:		0.015294
  validation loss:		0.365298
  validation accuracy:		92.72 %
Epoch 1067 of 2000 took 0.035s
  training loss:		0.015540
  validation loss:		0.361926
  validation accuracy:		92.72 %
Epoch 1068 of 2000 took 0.035s
  training loss:		0.015551
  validation loss:		0.371403
  validation accuracy:		92.61 %
Epoch 1069 of 2000 took 0.035s
  training loss:		0.014983
  validation loss:		0.357558
  validation accuracy:		92.72 %
Epoch 1070 of 2000 took 0.035s
  training loss:		0.016007
  validation loss:		0.362634
  validation accuracy:		92.83 %
Epoch 1071 of 2000 took 0.035s
  training loss:		0.015051
  validation loss:		0.363809
  validation accuracy:		92.72 %
Epoch 1072 of 2000 took 0.035s
  training loss:		0.015151
  validation loss:		0.362895
  validation accuracy:		92.83 %
Epoch 1073 of 2000 took 0.035s
  training loss:		0.014354
  validation loss:		0.365602
  validation accuracy:		92.61 %
Epoch 1074 of 2000 took 0.035s
  training loss:		0.015034
  validation loss:		0.362200
  validation accuracy:		92.83 %
Epoch 1075 of 2000 took 0.035s
  training loss:		0.014708
  validation loss:		0.370071
  validation accuracy:		92.61 %
Epoch 1076 of 2000 took 0.035s
  training loss:		0.014607
  validation loss:		0.372339
  validation accuracy:		92.72 %
Epoch 1077 of 2000 took 0.035s
  training loss:		0.014074
  validation loss:		0.367460
  validation accuracy:		92.50 %
Epoch 1078 of 2000 took 0.035s
  training loss:		0.015222
  validation loss:		0.369192
  validation accuracy:		92.72 %
Epoch 1079 of 2000 took 0.035s
  training loss:		0.014799
  validation loss:		0.368931
  validation accuracy:		92.50 %
Epoch 1080 of 2000 took 0.035s
  training loss:		0.013981
  validation loss:		0.369080
  validation accuracy:		92.72 %
Epoch 1081 of 2000 took 0.035s
  training loss:		0.014402
  validation loss:		0.366194
  validation accuracy:		92.72 %
Epoch 1082 of 2000 took 0.035s
  training loss:		0.014906
  validation loss:		0.374688
  validation accuracy:		92.83 %
Epoch 1083 of 2000 took 0.035s
  training loss:		0.014979
  validation loss:		0.371392
  validation accuracy:		92.50 %
Epoch 1084 of 2000 took 0.035s
  training loss:		0.014973
  validation loss:		0.364917
  validation accuracy:		92.72 %
Epoch 1085 of 2000 took 0.035s
  training loss:		0.015212
  validation loss:		0.368579
  validation accuracy:		92.61 %
Epoch 1086 of 2000 took 0.035s
  training loss:		0.014985
  validation loss:		0.374952
  validation accuracy:		92.61 %
Epoch 1087 of 2000 took 0.035s
  training loss:		0.014895
  validation loss:		0.364256
  validation accuracy:		92.61 %
Epoch 1088 of 2000 took 0.035s
  training loss:		0.014399
  validation loss:		0.376934
  validation accuracy:		92.61 %
Epoch 1089 of 2000 took 0.035s
  training loss:		0.014542
  validation loss:		0.372901
  validation accuracy:		92.61 %
Epoch 1090 of 2000 took 0.035s
  training loss:		0.014532
  validation loss:		0.366726
  validation accuracy:		92.93 %
Epoch 1091 of 2000 took 0.035s
  training loss:		0.014210
  validation loss:		0.368321
  validation accuracy:		92.83 %
Epoch 1092 of 2000 took 0.035s
  training loss:		0.014682
  validation loss:		0.375055
  validation accuracy:		92.61 %
Epoch 1093 of 2000 took 0.035s
  training loss:		0.014732
  validation loss:		0.369024
  validation accuracy:		92.72 %
Epoch 1094 of 2000 took 0.035s
  training loss:		0.014174
  validation loss:		0.379397
  validation accuracy:		92.72 %
Epoch 1095 of 2000 took 0.035s
  training loss:		0.014612
  validation loss:		0.369154
  validation accuracy:		92.72 %
Epoch 1096 of 2000 took 0.035s
  training loss:		0.014431
  validation loss:		0.370260
  validation accuracy:		92.61 %
Epoch 1097 of 2000 took 0.035s
  training loss:		0.014042
  validation loss:		0.375239
  validation accuracy:		92.50 %
Epoch 1098 of 2000 took 0.035s
  training loss:		0.014221
  validation loss:		0.371820
  validation accuracy:		92.83 %
Epoch 1099 of 2000 took 0.035s
  training loss:		0.014068
  validation loss:		0.372204
  validation accuracy:		92.61 %
Epoch 1100 of 2000 took 0.035s
  training loss:		0.014730
  validation loss:		0.380055
  validation accuracy:		92.72 %
Epoch 1101 of 2000 took 0.035s
  training loss:		0.014133
  validation loss:		0.379185
  validation accuracy:		92.72 %
Epoch 1102 of 2000 took 0.035s
  training loss:		0.013498
  validation loss:		0.366140
  validation accuracy:		92.93 %
Epoch 1103 of 2000 took 0.035s
  training loss:		0.014096
  validation loss:		0.374500
  validation accuracy:		92.61 %
Epoch 1104 of 2000 took 0.035s
  training loss:		0.013690
  validation loss:		0.369163
  validation accuracy:		92.61 %
Epoch 1105 of 2000 took 0.035s
  training loss:		0.013574
  validation loss:		0.374524
  validation accuracy:		92.61 %
Epoch 1106 of 2000 took 0.035s
  training loss:		0.014037
  validation loss:		0.376604
  validation accuracy:		92.72 %
Epoch 1107 of 2000 took 0.035s
  training loss:		0.014114
  validation loss:		0.380958
  validation accuracy:		92.72 %
Epoch 1108 of 2000 took 0.035s
  training loss:		0.014043
  validation loss:		0.379728
  validation accuracy:		92.72 %
Epoch 1109 of 2000 took 0.035s
  training loss:		0.013921
  validation loss:		0.380419
  validation accuracy:		92.61 %
Epoch 1110 of 2000 took 0.035s
  training loss:		0.013677
  validation loss:		0.370967
  validation accuracy:		92.61 %
Epoch 1111 of 2000 took 0.035s
  training loss:		0.013457
  validation loss:		0.376778
  validation accuracy:		92.50 %
Epoch 1112 of 2000 took 0.035s
  training loss:		0.014156
  validation loss:		0.373827
  validation accuracy:		93.04 %
Epoch 1113 of 2000 took 0.035s
  training loss:		0.013951
  validation loss:		0.379899
  validation accuracy:		92.72 %
Epoch 1114 of 2000 took 0.035s
  training loss:		0.014031
  validation loss:		0.370549
  validation accuracy:		92.83 %
Epoch 1115 of 2000 took 0.035s
  training loss:		0.013594
  validation loss:		0.380568
  validation accuracy:		92.61 %
Epoch 1116 of 2000 took 0.035s
  training loss:		0.013673
  validation loss:		0.383474
  validation accuracy:		92.72 %
Epoch 1117 of 2000 took 0.035s
  training loss:		0.014099
  validation loss:		0.377986
  validation accuracy:		92.61 %
Epoch 1118 of 2000 took 0.035s
  training loss:		0.013556
  validation loss:		0.386226
  validation accuracy:		92.61 %
Epoch 1119 of 2000 took 0.035s
  training loss:		0.013792
  validation loss:		0.382510
  validation accuracy:		92.61 %
Epoch 1120 of 2000 took 0.035s
  training loss:		0.013783
  validation loss:		0.379231
  validation accuracy:		92.61 %
Epoch 1121 of 2000 took 0.035s
  training loss:		0.013448
  validation loss:		0.381872
  validation accuracy:		92.61 %
Epoch 1122 of 2000 took 0.035s
  training loss:		0.013364
  validation loss:		0.379918
  validation accuracy:		92.83 %
Epoch 1123 of 2000 took 0.035s
  training loss:		0.013522
  validation loss:		0.377815
  validation accuracy:		92.72 %
Epoch 1124 of 2000 took 0.035s
  training loss:		0.013332
  validation loss:		0.379771
  validation accuracy:		92.61 %
Epoch 1125 of 2000 took 0.035s
  training loss:		0.013406
  validation loss:		0.392044
  validation accuracy:		92.28 %
Epoch 1126 of 2000 took 0.035s
  training loss:		0.013380
  validation loss:		0.378615
  validation accuracy:		92.72 %
Epoch 1127 of 2000 took 0.035s
  training loss:		0.013630
  validation loss:		0.383425
  validation accuracy:		92.50 %
Epoch 1128 of 2000 took 0.035s
  training loss:		0.013504
  validation loss:		0.377639
  validation accuracy:		92.72 %
Epoch 1129 of 2000 took 0.035s
  training loss:		0.013435
  validation loss:		0.388240
  validation accuracy:		92.72 %
Epoch 1130 of 2000 took 0.035s
  training loss:		0.013149
  validation loss:		0.381263
  validation accuracy:		92.72 %
Epoch 1131 of 2000 took 0.035s
  training loss:		0.012554
  validation loss:		0.384606
  validation accuracy:		92.72 %
Epoch 1132 of 2000 took 0.035s
  training loss:		0.013262
  validation loss:		0.379074
  validation accuracy:		92.61 %
Epoch 1133 of 2000 took 0.035s
  training loss:		0.013266
  validation loss:		0.378979
  validation accuracy:		92.50 %
Epoch 1134 of 2000 took 0.035s
  training loss:		0.013169
  validation loss:		0.388579
  validation accuracy:		92.61 %
Epoch 1135 of 2000 took 0.035s
  training loss:		0.012617
  validation loss:		0.380530
  validation accuracy:		92.72 %
Epoch 1136 of 2000 took 0.035s
  training loss:		0.012914
  validation loss:		0.383546
  validation accuracy:		92.61 %
Epoch 1137 of 2000 took 0.035s
  training loss:		0.013159
  validation loss:		0.380372
  validation accuracy:		92.50 %
Epoch 1138 of 2000 took 0.035s
  training loss:		0.012666
  validation loss:		0.388794
  validation accuracy:		92.83 %
Epoch 1139 of 2000 took 0.035s
  training loss:		0.013167
  validation loss:		0.387847
  validation accuracy:		92.83 %
Epoch 1140 of 2000 took 0.035s
  training loss:		0.012980
  validation loss:		0.386805
  validation accuracy:		92.61 %
Epoch 1141 of 2000 took 0.035s
  training loss:		0.013974
  validation loss:		0.391539
  validation accuracy:		92.72 %
Epoch 1142 of 2000 took 0.035s
  training loss:		0.012716
  validation loss:		0.380727
  validation accuracy:		92.61 %
Epoch 1143 of 2000 took 0.035s
  training loss:		0.013312
  validation loss:		0.381814
  validation accuracy:		92.83 %
Epoch 1144 of 2000 took 0.035s
  training loss:		0.012880
  validation loss:		0.382299
  validation accuracy:		92.50 %
Epoch 1145 of 2000 took 0.035s
  training loss:		0.012725
  validation loss:		0.386583
  validation accuracy:		92.72 %
Epoch 1146 of 2000 took 0.035s
  training loss:		0.012969
  validation loss:		0.381099
  validation accuracy:		92.72 %
Epoch 1147 of 2000 took 0.035s
  training loss:		0.012685
  validation loss:		0.383142
  validation accuracy:		92.72 %
Epoch 1148 of 2000 took 0.035s
  training loss:		0.012524
  validation loss:		0.391362
  validation accuracy:		92.83 %
Epoch 1149 of 2000 took 0.035s
  training loss:		0.013099
  validation loss:		0.386954
  validation accuracy:		92.83 %
Epoch 1150 of 2000 took 0.035s
  training loss:		0.012835
  validation loss:		0.387473
  validation accuracy:		92.83 %
Epoch 1151 of 2000 took 0.035s
  training loss:		0.012028
  validation loss:		0.386007
  validation accuracy:		92.93 %
Epoch 1152 of 2000 took 0.035s
  training loss:		0.012370
  validation loss:		0.394047
  validation accuracy:		92.50 %
Epoch 1153 of 2000 took 0.035s
  training loss:		0.012890
  validation loss:		0.385606
  validation accuracy:		92.61 %
Epoch 1154 of 2000 took 0.035s
  training loss:		0.013006
  validation loss:		0.390299
  validation accuracy:		92.93 %
Epoch 1155 of 2000 took 0.035s
  training loss:		0.012455
  validation loss:		0.384917
  validation accuracy:		92.72 %
Epoch 1156 of 2000 took 0.035s
  training loss:		0.012703
  validation loss:		0.391978
  validation accuracy:		92.61 %
Epoch 1157 of 2000 took 0.035s
  training loss:		0.012755
  validation loss:		0.387901
  validation accuracy:		92.83 %
Epoch 1158 of 2000 took 0.035s
  training loss:		0.012624
  validation loss:		0.392002
  validation accuracy:		92.61 %
Epoch 1159 of 2000 took 0.035s
  training loss:		0.012418
  validation loss:		0.385245
  validation accuracy:		92.72 %
Epoch 1160 of 2000 took 0.035s
  training loss:		0.012783
  validation loss:		0.392296
  validation accuracy:		92.83 %
Epoch 1161 of 2000 took 0.035s
  training loss:		0.012071
  validation loss:		0.389871
  validation accuracy:		92.72 %
Epoch 1162 of 2000 took 0.035s
  training loss:		0.011988
  validation loss:		0.383369
  validation accuracy:		92.72 %
Epoch 1163 of 2000 took 0.035s
  training loss:		0.012317
  validation loss:		0.397696
  validation accuracy:		92.50 %
Epoch 1164 of 2000 took 0.035s
  training loss:		0.012125
  validation loss:		0.377072
  validation accuracy:		92.93 %
Epoch 1165 of 2000 took 0.035s
  training loss:		0.012389
  validation loss:		0.390252
  validation accuracy:		92.61 %
Epoch 1166 of 2000 took 0.035s
  training loss:		0.012327
  validation loss:		0.389470
  validation accuracy:		92.72 %
Epoch 1167 of 2000 took 0.035s
  training loss:		0.012210
  validation loss:		0.393177
  validation accuracy:		92.83 %
Epoch 1168 of 2000 took 0.035s
  training loss:		0.012384
  validation loss:		0.387076
  validation accuracy:		92.61 %
Epoch 1169 of 2000 took 0.035s
  training loss:		0.012288
  validation loss:		0.397486
  validation accuracy:		92.61 %
Epoch 1170 of 2000 took 0.035s
  training loss:		0.012459
  validation loss:		0.386243
  validation accuracy:		92.61 %
Epoch 1171 of 2000 took 0.035s
  training loss:		0.012612
  validation loss:		0.391284
  validation accuracy:		92.72 %
Epoch 1172 of 2000 took 0.035s
  training loss:		0.011211
  validation loss:		0.388743
  validation accuracy:		92.72 %
Epoch 1173 of 2000 took 0.035s
  training loss:		0.011899
  validation loss:		0.389329
  validation accuracy:		92.61 %
Epoch 1174 of 2000 took 0.035s
  training loss:		0.012218
  validation loss:		0.393119
  validation accuracy:		92.61 %
Epoch 1175 of 2000 took 0.035s
  training loss:		0.011958
  validation loss:		0.387373
  validation accuracy:		92.83 %
Epoch 1176 of 2000 took 0.035s
  training loss:		0.011164
  validation loss:		0.391965
  validation accuracy:		92.61 %
Epoch 1177 of 2000 took 0.035s
  training loss:		0.012021
  validation loss:		0.390096
  validation accuracy:		92.83 %
Epoch 1178 of 2000 took 0.035s
  training loss:		0.011733
  validation loss:		0.392888
  validation accuracy:		92.50 %
Epoch 1179 of 2000 took 0.035s
  training loss:		0.011878
  validation loss:		0.382185
  validation accuracy:		92.72 %
Epoch 1180 of 2000 took 0.035s
  training loss:		0.011916
  validation loss:		0.389916
  validation accuracy:		92.72 %
Epoch 1181 of 2000 took 0.035s
  training loss:		0.011551
  validation loss:		0.401133
  validation accuracy:		92.72 %
Epoch 1182 of 2000 took 0.035s
  training loss:		0.011590
  validation loss:		0.394874
  validation accuracy:		92.83 %
Epoch 1183 of 2000 took 0.035s
  training loss:		0.011939
  validation loss:		0.387329
  validation accuracy:		92.72 %
Epoch 1184 of 2000 took 0.035s
  training loss:		0.011950
  validation loss:		0.393362
  validation accuracy:		92.61 %
Epoch 1185 of 2000 took 0.035s
  training loss:		0.011563
  validation loss:		0.395737
  validation accuracy:		92.93 %
Epoch 1186 of 2000 took 0.035s
  training loss:		0.011284
  validation loss:		0.389253
  validation accuracy:		92.93 %
Epoch 1187 of 2000 took 0.035s
  training loss:		0.011446
  validation loss:		0.381436
  validation accuracy:		92.61 %
Epoch 1188 of 2000 took 0.035s
  training loss:		0.011584
  validation loss:		0.397604
  validation accuracy:		92.83 %
Epoch 1189 of 2000 took 0.035s
  training loss:		0.011466
  validation loss:		0.391558
  validation accuracy:		92.61 %
Epoch 1190 of 2000 took 0.035s
  training loss:		0.011996
  validation loss:		0.392258
  validation accuracy:		92.72 %
Epoch 1191 of 2000 took 0.035s
  training loss:		0.011688
  validation loss:		0.399366
  validation accuracy:		92.61 %
Epoch 1192 of 2000 took 0.035s
  training loss:		0.011906
  validation loss:		0.406190
  validation accuracy:		92.72 %
Epoch 1193 of 2000 took 0.035s
  training loss:		0.011535
  validation loss:		0.386411
  validation accuracy:		92.72 %
Epoch 1194 of 2000 took 0.035s
  training loss:		0.011679
  validation loss:		0.398382
  validation accuracy:		92.83 %
Epoch 1195 of 2000 took 0.035s
  training loss:		0.011721
  validation loss:		0.393433
  validation accuracy:		92.72 %
Epoch 1196 of 2000 took 0.035s
  training loss:		0.011222
  validation loss:		0.397789
  validation accuracy:		92.61 %
Epoch 1197 of 2000 took 0.035s
  training loss:		0.011546
  validation loss:		0.397365
  validation accuracy:		92.72 %
Epoch 1198 of 2000 took 0.035s
  training loss:		0.011524
  validation loss:		0.395483
  validation accuracy:		92.72 %
Epoch 1199 of 2000 took 0.035s
  training loss:		0.011219
  validation loss:		0.389534
  validation accuracy:		92.61 %
Epoch 1200 of 2000 took 0.035s
  training loss:		0.011580
  validation loss:		0.392999
  validation accuracy:		92.72 %
Epoch 1201 of 2000 took 0.035s
  training loss:		0.011121
  validation loss:		0.401571
  validation accuracy:		92.61 %
Epoch 1202 of 2000 took 0.035s
  training loss:		0.011742
  validation loss:		0.394231
  validation accuracy:		92.83 %
Epoch 1203 of 2000 took 0.035s
  training loss:		0.011240
  validation loss:		0.396243
  validation accuracy:		92.61 %
Epoch 1204 of 2000 took 0.035s
  training loss:		0.011317
  validation loss:		0.396951
  validation accuracy:		92.72 %
Epoch 1205 of 2000 took 0.035s
  training loss:		0.011188
  validation loss:		0.396059
  validation accuracy:		92.72 %
Epoch 1206 of 2000 took 0.035s
  training loss:		0.010875
  validation loss:		0.401273
  validation accuracy:		92.83 %
Epoch 1207 of 2000 took 0.035s
  training loss:		0.011149
  validation loss:		0.397975
  validation accuracy:		92.61 %
Epoch 1208 of 2000 took 0.035s
  training loss:		0.011009
  validation loss:		0.394112
  validation accuracy:		92.72 %
Epoch 1209 of 2000 took 0.035s
  training loss:		0.011088
  validation loss:		0.395092
  validation accuracy:		92.61 %
Epoch 1210 of 2000 took 0.035s
  training loss:		0.010880
  validation loss:		0.400104
  validation accuracy:		92.61 %
Epoch 1211 of 2000 took 0.035s
  training loss:		0.010763
  validation loss:		0.393707
  validation accuracy:		92.83 %
Epoch 1212 of 2000 took 0.035s
  training loss:		0.011041
  validation loss:		0.396631
  validation accuracy:		92.72 %
Epoch 1213 of 2000 took 0.035s
  training loss:		0.011340
  validation loss:		0.401213
  validation accuracy:		92.72 %
Epoch 1214 of 2000 took 0.035s
  training loss:		0.011424
  validation loss:		0.398937
  validation accuracy:		92.83 %
Epoch 1215 of 2000 took 0.035s
  training loss:		0.011319
  validation loss:		0.395538
  validation accuracy:		92.61 %
Epoch 1216 of 2000 took 0.035s
  training loss:		0.011030
  validation loss:		0.396315
  validation accuracy:		92.83 %
Epoch 1217 of 2000 took 0.035s
  training loss:		0.010933
  validation loss:		0.398921
  validation accuracy:		92.83 %
Epoch 1218 of 2000 took 0.035s
  training loss:		0.010928
  validation loss:		0.395282
  validation accuracy:		92.61 %
Epoch 1219 of 2000 took 0.035s
  training loss:		0.010989
  validation loss:		0.395718
  validation accuracy:		92.83 %
Epoch 1220 of 2000 took 0.035s
  training loss:		0.011114
  validation loss:		0.399051
  validation accuracy:		92.72 %
Epoch 1221 of 2000 took 0.035s
  training loss:		0.010622
  validation loss:		0.400559
  validation accuracy:		92.72 %
Epoch 1222 of 2000 took 0.035s
  training loss:		0.010958
  validation loss:		0.399495
  validation accuracy:		92.93 %
Epoch 1223 of 2000 took 0.035s
  training loss:		0.010910
  validation loss:		0.399457
  validation accuracy:		92.50 %
Epoch 1224 of 2000 took 0.035s
  training loss:		0.010441
  validation loss:		0.395737
  validation accuracy:		92.83 %
Epoch 1225 of 2000 took 0.035s
  training loss:		0.010439
  validation loss:		0.397836
  validation accuracy:		92.93 %
Epoch 1226 of 2000 took 0.035s
  training loss:		0.011014
  validation loss:		0.398834
  validation accuracy:		92.50 %
Epoch 1227 of 2000 took 0.035s
  training loss:		0.010206
  validation loss:		0.397764
  validation accuracy:		92.61 %
Epoch 1228 of 2000 took 0.035s
  training loss:		0.010893
  validation loss:		0.406633
  validation accuracy:		92.83 %
Epoch 1229 of 2000 took 0.035s
  training loss:		0.010977
  validation loss:		0.409303
  validation accuracy:		92.83 %
Epoch 1230 of 2000 took 0.035s
  training loss:		0.010496
  validation loss:		0.403384
  validation accuracy:		92.83 %
Epoch 1231 of 2000 took 0.035s
  training loss:		0.010595
  validation loss:		0.402932
  validation accuracy:		92.83 %
Epoch 1232 of 2000 took 0.035s
  training loss:		0.010593
  validation loss:		0.410892
  validation accuracy:		92.83 %
Epoch 1233 of 2000 took 0.035s
  training loss:		0.010614
  validation loss:		0.403294
  validation accuracy:		92.83 %
Epoch 1234 of 2000 took 0.035s
  training loss:		0.010293
  validation loss:		0.407496
  validation accuracy:		92.61 %
Epoch 1235 of 2000 took 0.035s
  training loss:		0.010278
  validation loss:		0.401853
  validation accuracy:		92.50 %
Epoch 1236 of 2000 took 0.035s
  training loss:		0.010695
  validation loss:		0.400899
  validation accuracy:		92.61 %
Epoch 1237 of 2000 took 0.035s
  training loss:		0.010295
  validation loss:		0.407237
  validation accuracy:		92.83 %
Epoch 1238 of 2000 took 0.035s
  training loss:		0.010356
  validation loss:		0.416634
  validation accuracy:		92.39 %
Epoch 1239 of 2000 took 0.035s
  training loss:		0.010462
  validation loss:		0.404027
  validation accuracy:		92.93 %
Epoch 1240 of 2000 took 0.035s
  training loss:		0.010305
  validation loss:		0.402609
  validation accuracy:		92.61 %
Epoch 1241 of 2000 took 0.035s
  training loss:		0.010585
  validation loss:		0.409679
  validation accuracy:		92.61 %
Epoch 1242 of 2000 took 0.035s
  training loss:		0.010535
  validation loss:		0.399219
  validation accuracy:		92.72 %
Epoch 1243 of 2000 took 0.035s
  training loss:		0.010620
  validation loss:		0.411518
  validation accuracy:		92.61 %
Epoch 1244 of 2000 took 0.035s
  training loss:		0.010049
  validation loss:		0.401984
  validation accuracy:		92.93 %
Epoch 1245 of 2000 took 0.035s
  training loss:		0.009926
  validation loss:		0.409671
  validation accuracy:		92.83 %
Epoch 1246 of 2000 took 0.035s
  training loss:		0.010013
  validation loss:		0.406148
  validation accuracy:		92.72 %
Epoch 1247 of 2000 took 0.035s
  training loss:		0.010416
  validation loss:		0.415153
  validation accuracy:		92.83 %
Epoch 1248 of 2000 took 0.035s
  training loss:		0.010733
  validation loss:		0.402162
  validation accuracy:		92.83 %
Epoch 1249 of 2000 took 0.035s
  training loss:		0.010788
  validation loss:		0.407510
  validation accuracy:		92.61 %
Epoch 1250 of 2000 took 0.035s
  training loss:		0.010072
  validation loss:		0.411633
  validation accuracy:		92.83 %
Epoch 1251 of 2000 took 0.035s
  training loss:		0.010254
  validation loss:		0.405523
  validation accuracy:		92.72 %
Epoch 1252 of 2000 took 0.035s
  training loss:		0.009992
  validation loss:		0.409536
  validation accuracy:		92.50 %
Epoch 1253 of 2000 took 0.035s
  training loss:		0.010175
  validation loss:		0.405474
  validation accuracy:		92.83 %
Epoch 1254 of 2000 took 0.035s
  training loss:		0.009992
  validation loss:		0.414931
  validation accuracy:		92.83 %
Epoch 1255 of 2000 took 0.035s
  training loss:		0.010108
  validation loss:		0.411415
  validation accuracy:		92.50 %
Epoch 1256 of 2000 took 0.035s
  training loss:		0.009940
  validation loss:		0.405286
  validation accuracy:		92.83 %
Epoch 1257 of 2000 took 0.035s
  training loss:		0.010059
  validation loss:		0.404167
  validation accuracy:		92.83 %
Epoch 1258 of 2000 took 0.035s
  training loss:		0.010282
  validation loss:		0.411518
  validation accuracy:		92.72 %
Epoch 1259 of 2000 took 0.035s
  training loss:		0.010111
  validation loss:		0.408675
  validation accuracy:		92.61 %
Epoch 1260 of 2000 took 0.036s
  training loss:		0.010193
  validation loss:		0.404102
  validation accuracy:		92.83 %
Epoch 1261 of 2000 took 0.035s
  training loss:		0.009621
  validation loss:		0.407104
  validation accuracy:		92.61 %
Epoch 1262 of 2000 took 0.035s
  training loss:		0.009941
  validation loss:		0.409524
  validation accuracy:		92.61 %
Epoch 1263 of 2000 took 0.035s
  training loss:		0.010076
  validation loss:		0.412151
  validation accuracy:		92.93 %
Epoch 1264 of 2000 took 0.035s
  training loss:		0.009998
  validation loss:		0.417676
  validation accuracy:		92.72 %
Epoch 1265 of 2000 took 0.035s
  training loss:		0.009977
  validation loss:		0.406173
  validation accuracy:		92.83 %
Epoch 1266 of 2000 took 0.035s
  training loss:		0.009809
  validation loss:		0.414111
  validation accuracy:		92.61 %
Epoch 1267 of 2000 took 0.035s
  training loss:		0.009909
  validation loss:		0.412772
  validation accuracy:		92.72 %
Epoch 1268 of 2000 took 0.035s
  training loss:		0.009407
  validation loss:		0.418595
  validation accuracy:		92.50 %
Epoch 1269 of 2000 took 0.035s
  training loss:		0.009826
  validation loss:		0.414181
  validation accuracy:		92.93 %
Epoch 1270 of 2000 took 0.035s
  training loss:		0.009660
  validation loss:		0.412803
  validation accuracy:		92.61 %
Epoch 1271 of 2000 took 0.035s
  training loss:		0.009500
  validation loss:		0.412173
  validation accuracy:		92.93 %
Epoch 1272 of 2000 took 0.035s
  training loss:		0.009635
  validation loss:		0.407660
  validation accuracy:		92.83 %
Epoch 1273 of 2000 took 0.035s
  training loss:		0.009529
  validation loss:		0.411074
  validation accuracy:		92.72 %
Epoch 1274 of 2000 took 0.035s
  training loss:		0.009702
  validation loss:		0.415598
  validation accuracy:		92.83 %
Epoch 1275 of 2000 took 0.035s
  training loss:		0.009412
  validation loss:		0.411020
  validation accuracy:		92.83 %
Epoch 1276 of 2000 took 0.035s
  training loss:		0.009687
  validation loss:		0.418587
  validation accuracy:		92.61 %
Epoch 1277 of 2000 took 0.035s
  training loss:		0.009707
  validation loss:		0.414350
  validation accuracy:		92.93 %
Epoch 1278 of 2000 took 0.035s
  training loss:		0.009303
  validation loss:		0.413169
  validation accuracy:		92.72 %
Epoch 1279 of 2000 took 0.035s
  training loss:		0.009578
  validation loss:		0.412347
  validation accuracy:		92.93 %
Epoch 1280 of 2000 took 0.035s
  training loss:		0.009719
  validation loss:		0.411447
  validation accuracy:		92.93 %
Epoch 1281 of 2000 took 0.035s
  training loss:		0.009874
  validation loss:		0.415193
  validation accuracy:		92.83 %
Epoch 1282 of 2000 took 0.035s
  training loss:		0.009516
  validation loss:		0.420440
  validation accuracy:		92.61 %
Epoch 1283 of 2000 took 0.035s
  training loss:		0.009446
  validation loss:		0.414893
  validation accuracy:		92.83 %
Epoch 1284 of 2000 took 0.035s
  training loss:		0.009629
  validation loss:		0.408492
  validation accuracy:		92.83 %
Epoch 1285 of 2000 took 0.035s
  training loss:		0.009318
  validation loss:		0.420895
  validation accuracy:		92.83 %
Epoch 1286 of 2000 took 0.035s
  training loss:		0.009723
  validation loss:		0.411700
  validation accuracy:		92.61 %
Epoch 1287 of 2000 took 0.035s
  training loss:		0.009283
  validation loss:		0.415717
  validation accuracy:		92.83 %
Epoch 1288 of 2000 took 0.035s
  training loss:		0.009336
  validation loss:		0.423851
  validation accuracy:		92.50 %
Epoch 1289 of 2000 took 0.035s
  training loss:		0.009026
  validation loss:		0.414781
  validation accuracy:		92.83 %
Epoch 1290 of 2000 took 0.035s
  training loss:		0.009373
  validation loss:		0.420770
  validation accuracy:		92.83 %
Epoch 1291 of 2000 took 0.035s
  training loss:		0.009454
  validation loss:		0.417956
  validation accuracy:		92.83 %
Epoch 1292 of 2000 took 0.035s
  training loss:		0.009526
  validation loss:		0.413981
  validation accuracy:		92.72 %
Epoch 1293 of 2000 took 0.035s
  training loss:		0.009286
  validation loss:		0.410678
  validation accuracy:		92.50 %
Epoch 1294 of 2000 took 0.035s
  training loss:		0.009373
  validation loss:		0.422852
  validation accuracy:		92.83 %
Epoch 1295 of 2000 took 0.035s
  training loss:		0.009202
  validation loss:		0.417759
  validation accuracy:		92.50 %
Epoch 1296 of 2000 took 0.035s
  training loss:		0.009414
  validation loss:		0.417641
  validation accuracy:		92.83 %
Epoch 1297 of 2000 took 0.035s
  training loss:		0.009158
  validation loss:		0.419024
  validation accuracy:		92.50 %
Epoch 1298 of 2000 took 0.035s
  training loss:		0.009349
  validation loss:		0.421651
  validation accuracy:		92.83 %
Epoch 1299 of 2000 took 0.035s
  training loss:		0.009245
  validation loss:		0.415076
  validation accuracy:		92.72 %
Epoch 1300 of 2000 took 0.036s
  training loss:		0.009238
  validation loss:		0.415028
  validation accuracy:		92.83 %
Epoch 1301 of 2000 took 0.035s
  training loss:		0.008872
  validation loss:		0.418604
  validation accuracy:		92.61 %
Epoch 1302 of 2000 took 0.035s
  training loss:		0.009439
  validation loss:		0.419090
  validation accuracy:		92.93 %
Epoch 1303 of 2000 took 0.035s
  training loss:		0.009294
  validation loss:		0.420473
  validation accuracy:		92.83 %
Epoch 1304 of 2000 took 0.035s
  training loss:		0.009161
  validation loss:		0.423194
  validation accuracy:		92.93 %
Epoch 1305 of 2000 took 0.035s
  training loss:		0.009285
  validation loss:		0.420224
  validation accuracy:		92.83 %
Epoch 1306 of 2000 took 0.035s
  training loss:		0.008865
  validation loss:		0.429666
  validation accuracy:		92.72 %
Epoch 1307 of 2000 took 0.035s
  training loss:		0.009335
  validation loss:		0.424707
  validation accuracy:		92.72 %
Epoch 1308 of 2000 took 0.035s
  training loss:		0.009264
  validation loss:		0.421779
  validation accuracy:		92.83 %
Epoch 1309 of 2000 took 0.035s
  training loss:		0.009279
  validation loss:		0.424829
  validation accuracy:		92.72 %
Epoch 1310 of 2000 took 0.035s
  training loss:		0.008872
  validation loss:		0.413065
  validation accuracy:		92.72 %
Epoch 1311 of 2000 took 0.035s
  training loss:		0.009009
  validation loss:		0.418360
  validation accuracy:		92.83 %
Epoch 1312 of 2000 took 0.035s
  training loss:		0.008576
  validation loss:		0.420501
  validation accuracy:		92.72 %
Epoch 1313 of 2000 took 0.035s
  training loss:		0.008952
  validation loss:		0.425567
  validation accuracy:		92.83 %
Epoch 1314 of 2000 took 0.035s
  training loss:		0.009055
  validation loss:		0.416605
  validation accuracy:		92.83 %
Epoch 1315 of 2000 took 0.035s
  training loss:		0.008609
  validation loss:		0.416709
  validation accuracy:		92.72 %
Epoch 1316 of 2000 took 0.035s
  training loss:		0.009200
  validation loss:		0.424072
  validation accuracy:		92.72 %
Epoch 1317 of 2000 took 0.035s
  training loss:		0.009169
  validation loss:		0.421206
  validation accuracy:		92.93 %
Epoch 1318 of 2000 took 0.035s
  training loss:		0.009130
  validation loss:		0.415106
  validation accuracy:		92.83 %
Epoch 1319 of 2000 took 0.035s
  training loss:		0.008638
  validation loss:		0.422977
  validation accuracy:		92.83 %
Epoch 1320 of 2000 took 0.035s
  training loss:		0.009263
  validation loss:		0.420662
  validation accuracy:		92.93 %
Epoch 1321 of 2000 took 0.035s
  training loss:		0.008586
  validation loss:		0.417074
  validation accuracy:		92.72 %
Epoch 1322 of 2000 took 0.035s
  training loss:		0.008799
  validation loss:		0.430470
  validation accuracy:		92.83 %
Epoch 1323 of 2000 took 0.035s
  training loss:		0.008811
  validation loss:		0.425494
  validation accuracy:		92.61 %
Epoch 1324 of 2000 took 0.035s
  training loss:		0.008889
  validation loss:		0.416955
  validation accuracy:		92.72 %
Epoch 1325 of 2000 took 0.035s
  training loss:		0.008728
  validation loss:		0.422949
  validation accuracy:		92.93 %
Epoch 1326 of 2000 took 0.035s
  training loss:		0.008835
  validation loss:		0.423077
  validation accuracy:		92.93 %
Epoch 1327 of 2000 took 0.035s
  training loss:		0.008749
  validation loss:		0.422083
  validation accuracy:		92.72 %
Epoch 1328 of 2000 took 0.035s
  training loss:		0.008780
  validation loss:		0.419902
  validation accuracy:		92.83 %
Epoch 1329 of 2000 took 0.035s
  training loss:		0.008941
  validation loss:		0.426098
  validation accuracy:		92.83 %
Epoch 1330 of 2000 took 0.035s
  training loss:		0.008085
  validation loss:		0.427196
  validation accuracy:		92.61 %
Epoch 1331 of 2000 took 0.035s
  training loss:		0.008698
  validation loss:		0.412810
  validation accuracy:		92.83 %
Epoch 1332 of 2000 took 0.035s
  training loss:		0.008758
  validation loss:		0.422767
  validation accuracy:		92.83 %
Epoch 1333 of 2000 took 0.035s
  training loss:		0.008777
  validation loss:		0.424239
  validation accuracy:		92.93 %
Epoch 1334 of 2000 took 0.035s
  training loss:		0.008755
  validation loss:		0.429206
  validation accuracy:		92.72 %
Epoch 1335 of 2000 took 0.035s
  training loss:		0.008539
  validation loss:		0.419546
  validation accuracy:		92.83 %
Epoch 1336 of 2000 took 0.035s
  training loss:		0.008498
  validation loss:		0.424134
  validation accuracy:		92.83 %
Epoch 1337 of 2000 took 0.035s
  training loss:		0.008699
  validation loss:		0.422045
  validation accuracy:		92.83 %
Epoch 1338 of 2000 took 0.035s
  training loss:		0.008791
  validation loss:		0.422630
  validation accuracy:		92.72 %
Epoch 1339 of 2000 took 0.035s
  training loss:		0.008582
  validation loss:		0.427036
  validation accuracy:		92.83 %
Epoch 1340 of 2000 took 0.035s
  training loss:		0.008617
  validation loss:		0.429691
  validation accuracy:		92.93 %
Epoch 1341 of 2000 took 0.035s
  training loss:		0.008308
  validation loss:		0.423426
  validation accuracy:		92.72 %
Epoch 1342 of 2000 took 0.035s
  training loss:		0.008130
  validation loss:		0.423285
  validation accuracy:		92.83 %
Epoch 1343 of 2000 took 0.035s
  training loss:		0.008309
  validation loss:		0.439832
  validation accuracy:		92.72 %
Epoch 1344 of 2000 took 0.035s
  training loss:		0.008739
  validation loss:		0.426753
  validation accuracy:		92.72 %
Epoch 1345 of 2000 took 0.035s
  training loss:		0.008107
  validation loss:		0.426384
  validation accuracy:		92.83 %
Epoch 1346 of 2000 took 0.035s
  training loss:		0.008644
  validation loss:		0.423964
  validation accuracy:		92.72 %
Epoch 1347 of 2000 took 0.035s
  training loss:		0.008428
  validation loss:		0.429391
  validation accuracy:		92.83 %
Epoch 1348 of 2000 took 0.035s
  training loss:		0.008268
  validation loss:		0.429282
  validation accuracy:		92.83 %
Epoch 1349 of 2000 took 0.035s
  training loss:		0.008075
  validation loss:		0.423351
  validation accuracy:		92.72 %
Epoch 1350 of 2000 took 0.035s
  training loss:		0.008392
  validation loss:		0.434189
  validation accuracy:		92.50 %
Epoch 1351 of 2000 took 0.035s
  training loss:		0.008470
  validation loss:		0.434567
  validation accuracy:		92.83 %
Epoch 1352 of 2000 took 0.035s
  training loss:		0.008047
  validation loss:		0.433370
  validation accuracy:		92.93 %
Epoch 1353 of 2000 took 0.035s
  training loss:		0.008502
  validation loss:		0.429765
  validation accuracy:		92.61 %
Epoch 1354 of 2000 took 0.035s
  training loss:		0.008357
  validation loss:		0.427919
  validation accuracy:		92.83 %
Epoch 1355 of 2000 took 0.035s
  training loss:		0.008280
  validation loss:		0.429876
  validation accuracy:		92.93 %
Epoch 1356 of 2000 took 0.035s
  training loss:		0.008316
  validation loss:		0.428370
  validation accuracy:		92.93 %
Epoch 1357 of 2000 took 0.035s
  training loss:		0.008470
  validation loss:		0.425561
  validation accuracy:		92.72 %
Epoch 1358 of 2000 took 0.035s
  training loss:		0.008485
  validation loss:		0.424531
  validation accuracy:		92.93 %
Epoch 1359 of 2000 took 0.035s
  training loss:		0.007847
  validation loss:		0.429988
  validation accuracy:		92.50 %
Epoch 1360 of 2000 took 0.035s
  training loss:		0.007818
  validation loss:		0.429359
  validation accuracy:		92.83 %
Epoch 1361 of 2000 took 0.035s
  training loss:		0.008037
  validation loss:		0.423449
  validation accuracy:		92.93 %
Epoch 1362 of 2000 took 0.035s
  training loss:		0.008457
  validation loss:		0.437143
  validation accuracy:		92.83 %
Epoch 1363 of 2000 took 0.035s
  training loss:		0.008029
  validation loss:		0.428024
  validation accuracy:		92.93 %
Epoch 1364 of 2000 took 0.035s
  training loss:		0.007686
  validation loss:		0.430931
  validation accuracy:		92.83 %
Epoch 1365 of 2000 took 0.035s
  training loss:		0.008033
  validation loss:		0.441215
  validation accuracy:		92.61 %
Epoch 1366 of 2000 took 0.035s
  training loss:		0.008010
  validation loss:		0.432036
  validation accuracy:		92.72 %
Epoch 1367 of 2000 took 0.035s
  training loss:		0.008115
  validation loss:		0.431978
  validation accuracy:		92.93 %
Epoch 1368 of 2000 took 0.035s
  training loss:		0.008088
  validation loss:		0.433217
  validation accuracy:		92.83 %
Epoch 1369 of 2000 took 0.035s
  training loss:		0.007852
  validation loss:		0.428586
  validation accuracy:		92.72 %
Epoch 1370 of 2000 took 0.035s
  training loss:		0.007778
  validation loss:		0.435335
  validation accuracy:		92.72 %
Epoch 1371 of 2000 took 0.035s
  training loss:		0.007823
  validation loss:		0.434352
  validation accuracy:		92.83 %
Epoch 1372 of 2000 took 0.035s
  training loss:		0.007850
  validation loss:		0.428579
  validation accuracy:		92.83 %
Epoch 1373 of 2000 took 0.035s
  training loss:		0.008150
  validation loss:		0.433170
  validation accuracy:		92.83 %
Epoch 1374 of 2000 took 0.035s
  training loss:		0.008081
  validation loss:		0.431472
  validation accuracy:		92.72 %
Epoch 1375 of 2000 took 0.035s
  training loss:		0.007937
  validation loss:		0.429605
  validation accuracy:		92.72 %
Epoch 1376 of 2000 took 0.035s
  training loss:		0.007774
  validation loss:		0.434125
  validation accuracy:		92.72 %
Epoch 1377 of 2000 took 0.035s
  training loss:		0.007838
  validation loss:		0.438549
  validation accuracy:		92.93 %
Epoch 1378 of 2000 took 0.035s
  training loss:		0.007793
  validation loss:		0.433087
  validation accuracy:		92.61 %
Epoch 1379 of 2000 took 0.035s
  training loss:		0.007964
  validation loss:		0.433104
  validation accuracy:		92.72 %
Epoch 1380 of 2000 took 0.035s
  training loss:		0.007909
  validation loss:		0.433660
  validation accuracy:		92.72 %
Epoch 1381 of 2000 took 0.035s
  training loss:		0.007763
  validation loss:		0.434647
  validation accuracy:		92.93 %
Epoch 1382 of 2000 took 0.035s
  training loss:		0.008134
  validation loss:		0.433154
  validation accuracy:		92.72 %
Epoch 1383 of 2000 took 0.035s
  training loss:		0.007612
  validation loss:		0.432394
  validation accuracy:		92.83 %
Epoch 1384 of 2000 took 0.035s
  training loss:		0.007369
  validation loss:		0.436891
  validation accuracy:		92.72 %
Epoch 1385 of 2000 took 0.035s
  training loss:		0.007916
  validation loss:		0.433013
  validation accuracy:		92.93 %
Epoch 1386 of 2000 took 0.035s
  training loss:		0.007830
  validation loss:		0.426383
  validation accuracy:		92.83 %
Epoch 1387 of 2000 took 0.035s
  training loss:		0.007775
  validation loss:		0.436834
  validation accuracy:		92.83 %
Epoch 1388 of 2000 took 0.035s
  training loss:		0.007771
  validation loss:		0.439880
  validation accuracy:		92.72 %
Epoch 1389 of 2000 took 0.035s
  training loss:		0.007864
  validation loss:		0.433881
  validation accuracy:		92.83 %
Epoch 1390 of 2000 took 0.035s
  training loss:		0.007674
  validation loss:		0.437044
  validation accuracy:		92.93 %
Epoch 1391 of 2000 took 0.035s
  training loss:		0.007386
  validation loss:		0.437181
  validation accuracy:		92.83 %
Epoch 1392 of 2000 took 0.035s
  training loss:		0.007630
  validation loss:		0.436067
  validation accuracy:		92.72 %
Epoch 1393 of 2000 took 0.035s
  training loss:		0.007364
  validation loss:		0.443967
  validation accuracy:		92.72 %
Epoch 1394 of 2000 took 0.035s
  training loss:		0.007881
  validation loss:		0.440684
  validation accuracy:		92.83 %
Epoch 1395 of 2000 took 0.035s
  training loss:		0.007570
  validation loss:		0.439295
  validation accuracy:		92.72 %
Epoch 1396 of 2000 took 0.035s
  training loss:		0.007637
  validation loss:		0.434476
  validation accuracy:		92.93 %
Epoch 1397 of 2000 took 0.035s
  training loss:		0.007711
  validation loss:		0.437052
  validation accuracy:		92.72 %
Epoch 1398 of 2000 took 0.035s
  training loss:		0.007562
  validation loss:		0.438981
  validation accuracy:		92.83 %
Epoch 1399 of 2000 took 0.035s
  training loss:		0.007708
  validation loss:		0.433331
  validation accuracy:		92.83 %
Epoch 1400 of 2000 took 0.035s
  training loss:		0.007660
  validation loss:		0.443917
  validation accuracy:		92.83 %
Epoch 1401 of 2000 took 0.035s
  training loss:		0.007461
  validation loss:		0.437325
  validation accuracy:		92.83 %
Epoch 1402 of 2000 took 0.035s
  training loss:		0.007521
  validation loss:		0.438535
  validation accuracy:		92.83 %
Epoch 1403 of 2000 took 0.035s
  training loss:		0.007276
  validation loss:		0.438253
  validation accuracy:		92.72 %
Epoch 1404 of 2000 took 0.035s
  training loss:		0.007330
  validation loss:		0.442129
  validation accuracy:		92.83 %
Epoch 1405 of 2000 took 0.035s
  training loss:		0.007518
  validation loss:		0.436959
  validation accuracy:		92.93 %
Epoch 1406 of 2000 took 0.035s
  training loss:		0.007454
  validation loss:		0.443290
  validation accuracy:		92.93 %
Epoch 1407 of 2000 took 0.035s
  training loss:		0.007559
  validation loss:		0.437724
  validation accuracy:		92.83 %
Epoch 1408 of 2000 took 0.035s
  training loss:		0.007313
  validation loss:		0.433828
  validation accuracy:		92.83 %
Epoch 1409 of 2000 took 0.035s
  training loss:		0.007501
  validation loss:		0.438488
  validation accuracy:		92.83 %
Epoch 1410 of 2000 took 0.035s
  training loss:		0.007488
  validation loss:		0.439380
  validation accuracy:		92.72 %
Epoch 1411 of 2000 took 0.035s
  training loss:		0.007322
  validation loss:		0.437959
  validation accuracy:		92.83 %
Epoch 1412 of 2000 took 0.035s
  training loss:		0.007202
  validation loss:		0.439669
  validation accuracy:		92.93 %
Epoch 1413 of 2000 took 0.035s
  training loss:		0.007901
  validation loss:		0.445381
  validation accuracy:		92.72 %
Epoch 1414 of 2000 took 0.035s
  training loss:		0.007165
  validation loss:		0.439481
  validation accuracy:		92.83 %
Epoch 1415 of 2000 took 0.035s
  training loss:		0.007581
  validation loss:		0.438348
  validation accuracy:		92.72 %
Epoch 1416 of 2000 took 0.035s
  training loss:		0.007405
  validation loss:		0.440569
  validation accuracy:		92.93 %
Epoch 1417 of 2000 took 0.035s
  training loss:		0.007267
  validation loss:		0.447701
  validation accuracy:		92.83 %
Epoch 1418 of 2000 took 0.035s
  training loss:		0.007302
  validation loss:		0.440479
  validation accuracy:		92.93 %
Epoch 1419 of 2000 took 0.035s
  training loss:		0.007481
  validation loss:		0.443214
  validation accuracy:		92.72 %
Epoch 1420 of 2000 took 0.035s
  training loss:		0.007405
  validation loss:		0.447071
  validation accuracy:		92.83 %
Epoch 1421 of 2000 took 0.035s
  training loss:		0.007404
  validation loss:		0.439186
  validation accuracy:		92.72 %
Epoch 1422 of 2000 took 0.035s
  training loss:		0.007388
  validation loss:		0.439080
  validation accuracy:		92.72 %
Epoch 1423 of 2000 took 0.035s
  training loss:		0.007439
  validation loss:		0.439416
  validation accuracy:		92.83 %
Epoch 1424 of 2000 took 0.035s
  training loss:		0.007235
  validation loss:		0.441219
  validation accuracy:		92.93 %
Epoch 1425 of 2000 took 0.035s
  training loss:		0.007150
  validation loss:		0.442087
  validation accuracy:		92.83 %
Epoch 1426 of 2000 took 0.035s
  training loss:		0.006989
  validation loss:		0.443493
  validation accuracy:		92.93 %
Epoch 1427 of 2000 took 0.037s
  training loss:		0.007253
  validation loss:		0.440640
  validation accuracy:		92.83 %
Epoch 1428 of 2000 took 0.035s
  training loss:		0.007264
  validation loss:		0.448215
  validation accuracy:		92.83 %
Epoch 1429 of 2000 took 0.035s
  training loss:		0.007172
  validation loss:		0.447092
  validation accuracy:		92.93 %
Epoch 1430 of 2000 took 0.035s
  training loss:		0.007102
  validation loss:		0.444090
  validation accuracy:		92.83 %
Epoch 1431 of 2000 took 0.035s
  training loss:		0.006737
  validation loss:		0.445028
  validation accuracy:		92.83 %
Epoch 1432 of 2000 took 0.035s
  training loss:		0.007310
  validation loss:		0.445689
  validation accuracy:		92.72 %
Epoch 1433 of 2000 took 0.035s
  training loss:		0.007286
  validation loss:		0.442839
  validation accuracy:		92.72 %
Epoch 1434 of 2000 took 0.035s
  training loss:		0.006814
  validation loss:		0.449636
  validation accuracy:		92.72 %
Epoch 1435 of 2000 took 0.035s
  training loss:		0.007075
  validation loss:		0.446751
  validation accuracy:		92.83 %
Epoch 1436 of 2000 took 0.035s
  training loss:		0.007067
  validation loss:		0.446328
  validation accuracy:		92.72 %
Epoch 1437 of 2000 took 0.035s
  training loss:		0.007035
  validation loss:		0.443885
  validation accuracy:		92.83 %
Epoch 1438 of 2000 took 0.035s
  training loss:		0.006814
  validation loss:		0.446387
  validation accuracy:		92.93 %
Epoch 1439 of 2000 took 0.035s
  training loss:		0.006973
  validation loss:		0.445950
  validation accuracy:		92.93 %
Epoch 1440 of 2000 took 0.035s
  training loss:		0.006998
  validation loss:		0.446709
  validation accuracy:		92.72 %
Epoch 1441 of 2000 took 0.035s
  training loss:		0.006994
  validation loss:		0.448196
  validation accuracy:		92.93 %
Epoch 1442 of 2000 took 0.035s
  training loss:		0.007378
  validation loss:		0.446497
  validation accuracy:		92.83 %
Epoch 1443 of 2000 took 0.035s
  training loss:		0.007100
  validation loss:		0.450089
  validation accuracy:		92.61 %
Epoch 1444 of 2000 took 0.035s
  training loss:		0.007084
  validation loss:		0.447299
  validation accuracy:		92.93 %
Epoch 1445 of 2000 took 0.035s
  training loss:		0.006891
  validation loss:		0.448516
  validation accuracy:		92.93 %
Epoch 1446 of 2000 took 0.035s
  training loss:		0.006726
  validation loss:		0.449491
  validation accuracy:		92.83 %
Epoch 1447 of 2000 took 0.035s
  training loss:		0.006761
  validation loss:		0.444965
  validation accuracy:		92.83 %
Epoch 1448 of 2000 took 0.035s
  training loss:		0.006929
  validation loss:		0.439223
  validation accuracy:		92.72 %
Epoch 1449 of 2000 took 0.035s
  training loss:		0.006894
  validation loss:		0.451263
  validation accuracy:		92.93 %
Epoch 1450 of 2000 took 0.035s
  training loss:		0.007046
  validation loss:		0.449561
  validation accuracy:		92.93 %
Epoch 1451 of 2000 took 0.035s
  training loss:		0.007249
  validation loss:		0.453228
  validation accuracy:		92.93 %
Epoch 1452 of 2000 took 0.035s
  training loss:		0.006613
  validation loss:		0.444729
  validation accuracy:		92.83 %
Epoch 1453 of 2000 took 0.035s
  training loss:		0.006850
  validation loss:		0.445855
  validation accuracy:		92.83 %
Epoch 1454 of 2000 took 0.035s
  training loss:		0.006776
  validation loss:		0.449236
  validation accuracy:		92.93 %
Epoch 1455 of 2000 took 0.035s
  training loss:		0.006661
  validation loss:		0.446645
  validation accuracy:		92.83 %
Epoch 1456 of 2000 took 0.035s
  training loss:		0.007119
  validation loss:		0.452103
  validation accuracy:		92.83 %
Epoch 1457 of 2000 took 0.035s
  training loss:		0.006724
  validation loss:		0.446770
  validation accuracy:		92.83 %
Epoch 1458 of 2000 took 0.035s
  training loss:		0.006854
  validation loss:		0.452049
  validation accuracy:		92.83 %
Epoch 1459 of 2000 took 0.035s
  training loss:		0.006829
  validation loss:		0.442875
  validation accuracy:		92.72 %
Epoch 1460 of 2000 took 0.035s
  training loss:		0.006896
  validation loss:		0.447634
  validation accuracy:		92.93 %
Epoch 1461 of 2000 took 0.035s
  training loss:		0.006968
  validation loss:		0.450969
  validation accuracy:		92.72 %
Epoch 1462 of 2000 took 0.035s
  training loss:		0.006720
  validation loss:		0.452460
  validation accuracy:		92.93 %
Epoch 1463 of 2000 took 0.035s
  training loss:		0.006838
  validation loss:		0.451223
  validation accuracy:		92.93 %
Epoch 1464 of 2000 took 0.035s
  training loss:		0.006824
  validation loss:		0.454908
  validation accuracy:		92.72 %
Epoch 1465 of 2000 took 0.035s
  training loss:		0.006692
  validation loss:		0.449077
  validation accuracy:		92.83 %
Epoch 1466 of 2000 took 0.035s
  training loss:		0.006860
  validation loss:		0.449982
  validation accuracy:		92.93 %
Epoch 1467 of 2000 took 0.035s
  training loss:		0.006703
  validation loss:		0.453708
  validation accuracy:		92.83 %
Epoch 1468 of 2000 took 0.035s
  training loss:		0.006512
  validation loss:		0.453864
  validation accuracy:		92.93 %
Epoch 1469 of 2000 took 0.035s
  training loss:		0.006861
  validation loss:		0.459829
  validation accuracy:		92.83 %
Epoch 1470 of 2000 took 0.035s
  training loss:		0.007036
  validation loss:		0.452750
  validation accuracy:		92.83 %
Epoch 1471 of 2000 took 0.035s
  training loss:		0.006800
  validation loss:		0.451810
  validation accuracy:		92.93 %
Epoch 1472 of 2000 took 0.035s
  training loss:		0.006354
  validation loss:		0.451359
  validation accuracy:		92.93 %
Epoch 1473 of 2000 took 0.035s
  training loss:		0.006739
  validation loss:		0.447044
  validation accuracy:		92.93 %
Epoch 1474 of 2000 took 0.035s
  training loss:		0.006597
  validation loss:		0.454872
  validation accuracy:		92.83 %
Epoch 1475 of 2000 took 0.035s
  training loss:		0.006440
  validation loss:		0.449399
  validation accuracy:		92.93 %
Epoch 1476 of 2000 took 0.035s
  training loss:		0.006597
  validation loss:		0.452968
  validation accuracy:		92.83 %
Epoch 1477 of 2000 took 0.035s
  training loss:		0.006803
  validation loss:		0.455501
  validation accuracy:		92.83 %
Epoch 1478 of 2000 took 0.035s
  training loss:		0.006474
  validation loss:		0.458020
  validation accuracy:		92.72 %
Epoch 1479 of 2000 took 0.035s
  training loss:		0.006441
  validation loss:		0.454465
  validation accuracy:		92.93 %
Epoch 1480 of 2000 took 0.035s
  training loss:		0.006480
  validation loss:		0.461134
  validation accuracy:		92.72 %
Epoch 1481 of 2000 took 0.035s
  training loss:		0.006393
  validation loss:		0.447668
  validation accuracy:		92.72 %
Epoch 1482 of 2000 took 0.035s
  training loss:		0.006696
  validation loss:		0.448963
  validation accuracy:		92.93 %
Epoch 1483 of 2000 took 0.035s
  training loss:		0.006564
  validation loss:		0.451731
  validation accuracy:		92.93 %
Epoch 1484 of 2000 took 0.035s
  training loss:		0.006613
  validation loss:		0.461729
  validation accuracy:		92.83 %
Epoch 1485 of 2000 took 0.035s
  training loss:		0.006550
  validation loss:		0.455153
  validation accuracy:		92.93 %
Epoch 1486 of 2000 took 0.035s
  training loss:		0.006422
  validation loss:		0.456601
  validation accuracy:		92.83 %
Epoch 1487 of 2000 took 0.035s
  training loss:		0.006339
  validation loss:		0.450698
  validation accuracy:		92.72 %
Epoch 1488 of 2000 took 0.035s
  training loss:		0.006494
  validation loss:		0.454838
  validation accuracy:		92.83 %
Epoch 1489 of 2000 took 0.035s
  training loss:		0.006589
  validation loss:		0.452999
  validation accuracy:		92.93 %
Epoch 1490 of 2000 took 0.035s
  training loss:		0.006380
  validation loss:		0.453237
  validation accuracy:		92.72 %
Epoch 1491 of 2000 took 0.035s
  training loss:		0.006423
  validation loss:		0.455858
  validation accuracy:		92.83 %
Epoch 1492 of 2000 took 0.035s
  training loss:		0.006415
  validation loss:		0.453666
  validation accuracy:		92.72 %
Epoch 1493 of 2000 took 0.035s
  training loss:		0.006452
  validation loss:		0.461833
  validation accuracy:		92.83 %
Epoch 1494 of 2000 took 0.035s
  training loss:		0.006504
  validation loss:		0.455180
  validation accuracy:		92.72 %
Epoch 1495 of 2000 took 0.035s
  training loss:		0.006261
  validation loss:		0.448618
  validation accuracy:		92.93 %
Epoch 1496 of 2000 took 0.035s
  training loss:		0.006399
  validation loss:		0.460474
  validation accuracy:		92.61 %
Epoch 1497 of 2000 took 0.035s
  training loss:		0.006295
  validation loss:		0.455413
  validation accuracy:		92.93 %
Epoch 1498 of 2000 took 0.035s
  training loss:		0.006343
  validation loss:		0.455736
  validation accuracy:		92.83 %
Epoch 1499 of 2000 took 0.035s
  training loss:		0.006422
  validation loss:		0.459175
  validation accuracy:		92.72 %
Epoch 1500 of 2000 took 0.035s
  training loss:		0.006330
  validation loss:		0.458252
  validation accuracy:		92.72 %
Epoch 1501 of 2000 took 0.035s
  training loss:		0.006298
  validation loss:		0.459847
  validation accuracy:		92.83 %
Epoch 1502 of 2000 took 0.035s
  training loss:		0.006460
  validation loss:		0.453630
  validation accuracy:		92.72 %
Epoch 1503 of 2000 took 0.035s
  training loss:		0.006390
  validation loss:		0.455940
  validation accuracy:		92.72 %
Epoch 1504 of 2000 took 0.035s
  training loss:		0.006217
  validation loss:		0.456051
  validation accuracy:		92.83 %
Epoch 1505 of 2000 took 0.035s
  training loss:		0.006276
  validation loss:		0.456277
  validation accuracy:		92.83 %
Epoch 1506 of 2000 took 0.035s
  training loss:		0.006176
  validation loss:		0.452048
  validation accuracy:		92.72 %
Epoch 1507 of 2000 took 0.035s
  training loss:		0.006346
  validation loss:		0.455232
  validation accuracy:		92.83 %
Epoch 1508 of 2000 took 0.035s
  training loss:		0.006368
  validation loss:		0.462545
  validation accuracy:		92.93 %
Epoch 1509 of 2000 took 0.035s
  training loss:		0.006339
  validation loss:		0.462202
  validation accuracy:		92.72 %
Epoch 1510 of 2000 took 0.035s
  training loss:		0.006404
  validation loss:		0.465000
  validation accuracy:		92.83 %
Epoch 1511 of 2000 took 0.035s
  training loss:		0.005918
  validation loss:		0.456862
  validation accuracy:		92.83 %
Epoch 1512 of 2000 took 0.035s
  training loss:		0.006290
  validation loss:		0.460031
  validation accuracy:		92.83 %
Epoch 1513 of 2000 took 0.035s
  training loss:		0.006045
  validation loss:		0.459752
  validation accuracy:		92.93 %
Epoch 1514 of 2000 took 0.035s
  training loss:		0.006148
  validation loss:		0.458213
  validation accuracy:		92.83 %
Epoch 1515 of 2000 took 0.035s
  training loss:		0.006118
  validation loss:		0.460754
  validation accuracy:		92.72 %
Epoch 1516 of 2000 took 0.035s
  training loss:		0.006112
  validation loss:		0.460689
  validation accuracy:		92.83 %
Epoch 1517 of 2000 took 0.035s
  training loss:		0.006114
  validation loss:		0.460883
  validation accuracy:		92.83 %
Epoch 1518 of 2000 took 0.035s
  training loss:		0.006044
  validation loss:		0.461554
  validation accuracy:		92.83 %
Epoch 1519 of 2000 took 0.035s
  training loss:		0.006106
  validation loss:		0.461671
  validation accuracy:		92.93 %
Epoch 1520 of 2000 took 0.035s
  training loss:		0.006196
  validation loss:		0.456221
  validation accuracy:		92.72 %
Epoch 1521 of 2000 took 0.035s
  training loss:		0.006359
  validation loss:		0.463703
  validation accuracy:		92.83 %
Epoch 1522 of 2000 took 0.035s
  training loss:		0.006255
  validation loss:		0.462569
  validation accuracy:		92.93 %
Epoch 1523 of 2000 took 0.035s
  training loss:		0.006145
  validation loss:		0.468542
  validation accuracy:		92.61 %
Epoch 1524 of 2000 took 0.035s
  training loss:		0.006254
  validation loss:		0.463269
  validation accuracy:		92.72 %
Epoch 1525 of 2000 took 0.035s
  training loss:		0.006014
  validation loss:		0.456395
  validation accuracy:		92.83 %
Epoch 1526 of 2000 took 0.035s
  training loss:		0.006202
  validation loss:		0.463499
  validation accuracy:		92.83 %
Epoch 1527 of 2000 took 0.035s
  training loss:		0.005999
  validation loss:		0.462439
  validation accuracy:		92.83 %
Epoch 1528 of 2000 took 0.035s
  training loss:		0.005990
  validation loss:		0.464211
  validation accuracy:		92.93 %
Epoch 1529 of 2000 took 0.035s
  training loss:		0.006182
  validation loss:		0.464398
  validation accuracy:		92.83 %
Epoch 1530 of 2000 took 0.035s
  training loss:		0.005940
  validation loss:		0.466498
  validation accuracy:		92.83 %
Epoch 1531 of 2000 took 0.035s
  training loss:		0.006060
  validation loss:		0.459180
  validation accuracy:		92.93 %
Epoch 1532 of 2000 took 0.035s
  training loss:		0.006066
  validation loss:		0.465317
  validation accuracy:		92.93 %
Epoch 1533 of 2000 took 0.035s
  training loss:		0.006030
  validation loss:		0.465197
  validation accuracy:		92.72 %
Epoch 1534 of 2000 took 0.035s
  training loss:		0.006098
  validation loss:		0.465229
  validation accuracy:		92.83 %
Epoch 1535 of 2000 took 0.035s
  training loss:		0.005946
  validation loss:		0.466994
  validation accuracy:		92.83 %
Epoch 1536 of 2000 took 0.035s
  training loss:		0.006131
  validation loss:		0.466828
  validation accuracy:		92.83 %
Epoch 1537 of 2000 took 0.035s
  training loss:		0.005872
  validation loss:		0.464466
  validation accuracy:		93.04 %
Epoch 1538 of 2000 took 0.035s
  training loss:		0.006051
  validation loss:		0.460589
  validation accuracy:		92.83 %
Epoch 1539 of 2000 took 0.035s
  training loss:		0.005998
  validation loss:		0.465734
  validation accuracy:		92.83 %
Epoch 1540 of 2000 took 0.035s
  training loss:		0.005912
  validation loss:		0.462100
  validation accuracy:		92.83 %
Epoch 1541 of 2000 took 0.035s
  training loss:		0.005928
  validation loss:		0.468234
  validation accuracy:		92.72 %
Epoch 1542 of 2000 took 0.035s
  training loss:		0.005988
  validation loss:		0.470633
  validation accuracy:		92.83 %
Epoch 1543 of 2000 took 0.035s
  training loss:		0.005984
  validation loss:		0.464186
  validation accuracy:		92.83 %
Epoch 1544 of 2000 took 0.035s
  training loss:		0.005740
  validation loss:		0.466097
  validation accuracy:		92.83 %
Epoch 1545 of 2000 took 0.035s
  training loss:		0.005813
  validation loss:		0.460756
  validation accuracy:		92.72 %
Epoch 1546 of 2000 took 0.035s
  training loss:		0.005939
  validation loss:		0.465751
  validation accuracy:		92.83 %
Epoch 1547 of 2000 took 0.035s
  training loss:		0.005932
  validation loss:		0.465452
  validation accuracy:		92.83 %
Epoch 1548 of 2000 took 0.035s
  training loss:		0.005906
  validation loss:		0.464410
  validation accuracy:		92.93 %
Epoch 1549 of 2000 took 0.035s
  training loss:		0.005728
  validation loss:		0.463757
  validation accuracy:		92.72 %
Epoch 1550 of 2000 took 0.035s
  training loss:		0.005726
  validation loss:		0.468880
  validation accuracy:		92.83 %
Epoch 1551 of 2000 took 0.035s
  training loss:		0.005848
  validation loss:		0.472498
  validation accuracy:		92.72 %
Epoch 1552 of 2000 took 0.035s
  training loss:		0.005833
  validation loss:		0.464469
  validation accuracy:		92.83 %
Epoch 1553 of 2000 took 0.035s
  training loss:		0.005920
  validation loss:		0.464629
  validation accuracy:		92.93 %
Epoch 1554 of 2000 took 0.035s
  training loss:		0.005811
  validation loss:		0.472328
  validation accuracy:		92.61 %
Epoch 1555 of 2000 took 0.035s
  training loss:		0.005872
  validation loss:		0.467274
  validation accuracy:		92.83 %
Epoch 1556 of 2000 took 0.035s
  training loss:		0.005756
  validation loss:		0.466181
  validation accuracy:		92.83 %
Epoch 1557 of 2000 took 0.035s
  training loss:		0.005672
  validation loss:		0.468545
  validation accuracy:		92.83 %
Epoch 1558 of 2000 took 0.035s
  training loss:		0.005694
  validation loss:		0.465006
  validation accuracy:		92.83 %
Epoch 1559 of 2000 took 0.035s
  training loss:		0.005506
  validation loss:		0.469809
  validation accuracy:		92.72 %
Epoch 1560 of 2000 took 0.035s
  training loss:		0.005715
  validation loss:		0.478756
  validation accuracy:		92.61 %
Epoch 1561 of 2000 took 0.035s
  training loss:		0.005682
  validation loss:		0.461851
  validation accuracy:		92.93 %
Epoch 1562 of 2000 took 0.035s
  training loss:		0.005960
  validation loss:		0.475643
  validation accuracy:		92.83 %
Epoch 1563 of 2000 took 0.035s
  training loss:		0.005663
  validation loss:		0.470950
  validation accuracy:		92.61 %
Epoch 1564 of 2000 took 0.035s
  training loss:		0.005856
  validation loss:		0.470416
  validation accuracy:		92.72 %
Epoch 1565 of 2000 took 0.035s
  training loss:		0.005727
  validation loss:		0.474194
  validation accuracy:		92.72 %
Epoch 1566 of 2000 took 0.035s
  training loss:		0.005701
  validation loss:		0.467897
  validation accuracy:		92.93 %
Epoch 1567 of 2000 took 0.035s
  training loss:		0.005749
  validation loss:		0.465112
  validation accuracy:		92.72 %
Epoch 1568 of 2000 took 0.035s
  training loss:		0.005318
  validation loss:		0.470085
  validation accuracy:		92.83 %
Epoch 1569 of 2000 took 0.035s
  training loss:		0.005422
  validation loss:		0.473523
  validation accuracy:		92.83 %
Epoch 1570 of 2000 took 0.035s
  training loss:		0.005432
  validation loss:		0.474657
  validation accuracy:		92.83 %
Epoch 1571 of 2000 took 0.035s
  training loss:		0.005596
  validation loss:		0.471190
  validation accuracy:		92.72 %
Epoch 1572 of 2000 took 0.035s
  training loss:		0.005644
  validation loss:		0.475997
  validation accuracy:		92.72 %
Epoch 1573 of 2000 took 0.035s
  training loss:		0.005532
  validation loss:		0.469860
  validation accuracy:		92.93 %
Epoch 1574 of 2000 took 0.035s
  training loss:		0.005786
  validation loss:		0.466023
  validation accuracy:		92.83 %
Epoch 1575 of 2000 took 0.035s
  training loss:		0.005570
  validation loss:		0.469634
  validation accuracy:		92.83 %
Epoch 1576 of 2000 took 0.035s
  training loss:		0.005656
  validation loss:		0.472791
  validation accuracy:		92.93 %
Epoch 1577 of 2000 took 0.035s
  training loss:		0.005420
  validation loss:		0.466668
  validation accuracy:		92.93 %
Epoch 1578 of 2000 took 0.035s
  training loss:		0.005527
  validation loss:		0.471168
  validation accuracy:		92.83 %
Epoch 1579 of 2000 took 0.035s
  training loss:		0.005361
  validation loss:		0.470942
  validation accuracy:		92.83 %
Epoch 1580 of 2000 took 0.035s
  training loss:		0.005422
  validation loss:		0.466369
  validation accuracy:		92.83 %
Epoch 1581 of 2000 took 0.035s
  training loss:		0.005630
  validation loss:		0.477590
  validation accuracy:		92.83 %
Epoch 1582 of 2000 took 0.035s
  training loss:		0.005574
  validation loss:		0.470731
  validation accuracy:		92.72 %
Epoch 1583 of 2000 took 0.035s
  training loss:		0.005520
  validation loss:		0.469642
  validation accuracy:		92.83 %
Epoch 1584 of 2000 took 0.035s
  training loss:		0.005608
  validation loss:		0.472016
  validation accuracy:		92.93 %
Epoch 1585 of 2000 took 0.035s
  training loss:		0.005686
  validation loss:		0.476379
  validation accuracy:		92.83 %
Epoch 1586 of 2000 took 0.035s
  training loss:		0.005339
  validation loss:		0.468414
  validation accuracy:		92.93 %
Epoch 1587 of 2000 took 0.035s
  training loss:		0.005601
  validation loss:		0.470179
  validation accuracy:		92.93 %
Epoch 1588 of 2000 took 0.035s
  training loss:		0.005564
  validation loss:		0.471613
  validation accuracy:		92.83 %
Epoch 1589 of 2000 took 0.035s
  training loss:		0.005340
  validation loss:		0.467767
  validation accuracy:		92.93 %
Epoch 1590 of 2000 took 0.035s
  training loss:		0.005549
  validation loss:		0.476288
  validation accuracy:		92.83 %
Epoch 1591 of 2000 took 0.035s
  training loss:		0.005458
  validation loss:		0.470712
  validation accuracy:		92.83 %
Epoch 1592 of 2000 took 0.035s
  training loss:		0.005331
  validation loss:		0.474980
  validation accuracy:		92.93 %
Epoch 1593 of 2000 took 0.035s
  training loss:		0.005446
  validation loss:		0.468139
  validation accuracy:		92.83 %
Epoch 1594 of 2000 took 0.035s
  training loss:		0.005466
  validation loss:		0.474821
  validation accuracy:		92.83 %
Epoch 1595 of 2000 took 0.035s
  training loss:		0.005324
  validation loss:		0.472430
  validation accuracy:		92.93 %
Epoch 1596 of 2000 took 0.036s
  training loss:		0.005396
  validation loss:		0.476417
  validation accuracy:		92.72 %
Epoch 1597 of 2000 took 0.036s
  training loss:		0.005387
  validation loss:		0.469318
  validation accuracy:		92.93 %
Epoch 1598 of 2000 took 0.036s
  training loss:		0.005368
  validation loss:		0.477845
  validation accuracy:		92.72 %
Epoch 1599 of 2000 took 0.035s
  training loss:		0.005310
  validation loss:		0.465285
  validation accuracy:		92.83 %
Epoch 1600 of 2000 took 0.035s
  training loss:		0.005503
  validation loss:		0.474304
  validation accuracy:		92.93 %
Epoch 1601 of 2000 took 0.035s
  training loss:		0.005373
  validation loss:		0.476289
  validation accuracy:		92.83 %
Epoch 1602 of 2000 took 0.035s
  training loss:		0.005638
  validation loss:		0.478199
  validation accuracy:		92.83 %
Epoch 1603 of 2000 took 0.035s
  training loss:		0.005429
  validation loss:		0.474373
  validation accuracy:		92.83 %
Epoch 1604 of 2000 took 0.035s
  training loss:		0.005407
  validation loss:		0.470690
  validation accuracy:		92.83 %
Epoch 1605 of 2000 took 0.035s
  training loss:		0.005372
  validation loss:		0.478579
  validation accuracy:		92.83 %
Epoch 1606 of 2000 took 0.035s
  training loss:		0.005426
  validation loss:		0.475980
  validation accuracy:		92.83 %
Epoch 1607 of 2000 took 0.035s
  training loss:		0.005229
  validation loss:		0.481418
  validation accuracy:		92.72 %
Epoch 1608 of 2000 took 0.035s
  training loss:		0.004995
  validation loss:		0.478255
  validation accuracy:		92.83 %
Epoch 1609 of 2000 took 0.035s
  training loss:		0.005284
  validation loss:		0.473020
  validation accuracy:		92.83 %
Epoch 1610 of 2000 took 0.035s
  training loss:		0.005241
  validation loss:		0.481076
  validation accuracy:		92.72 %
Epoch 1611 of 2000 took 0.035s
  training loss:		0.005424
  validation loss:		0.477879
  validation accuracy:		92.83 %
Epoch 1612 of 2000 took 0.035s
  training loss:		0.005074
  validation loss:		0.470137
  validation accuracy:		92.83 %
Epoch 1613 of 2000 took 0.035s
  training loss:		0.005185
  validation loss:		0.476161
  validation accuracy:		92.83 %
Epoch 1614 of 2000 took 0.035s
  training loss:		0.005237
  validation loss:		0.479403
  validation accuracy:		92.83 %
Epoch 1615 of 2000 took 0.035s
  training loss:		0.005150
  validation loss:		0.479428
  validation accuracy:		92.83 %
Epoch 1616 of 2000 took 0.035s
  training loss:		0.005246
  validation loss:		0.476307
  validation accuracy:		92.93 %
Epoch 1617 of 2000 took 0.035s
  training loss:		0.005176
  validation loss:		0.472055
  validation accuracy:		92.83 %
Epoch 1618 of 2000 took 0.035s
  training loss:		0.005317
  validation loss:		0.478725
  validation accuracy:		92.83 %
Epoch 1619 of 2000 took 0.035s
  training loss:		0.005267
  validation loss:		0.475567
  validation accuracy:		92.93 %
Epoch 1620 of 2000 took 0.035s
  training loss:		0.005245
  validation loss:		0.476172
  validation accuracy:		92.83 %
Epoch 1621 of 2000 took 0.035s
  training loss:		0.005154
  validation loss:		0.481181
  validation accuracy:		92.93 %
Epoch 1622 of 2000 took 0.035s
  training loss:		0.005170
  validation loss:		0.476354
  validation accuracy:		92.72 %
Epoch 1623 of 2000 took 0.035s
  training loss:		0.005247
  validation loss:		0.480378
  validation accuracy:		92.83 %
Epoch 1624 of 2000 took 0.035s
  training loss:		0.005062
  validation loss:		0.476688
  validation accuracy:		92.72 %
Epoch 1625 of 2000 took 0.035s
  training loss:		0.005263
  validation loss:		0.477634
  validation accuracy:		92.83 %
Epoch 1626 of 2000 took 0.035s
  training loss:		0.005134
  validation loss:		0.480490
  validation accuracy:		92.83 %
Epoch 1627 of 2000 took 0.035s
  training loss:		0.005139
  validation loss:		0.477449
  validation accuracy:		92.83 %
Epoch 1628 of 2000 took 0.035s
  training loss:		0.005199
  validation loss:		0.478533
  validation accuracy:		92.83 %
Epoch 1629 of 2000 took 0.035s
  training loss:		0.005170
  validation loss:		0.480096
  validation accuracy:		92.83 %
Epoch 1630 of 2000 took 0.035s
  training loss:		0.005194
  validation loss:		0.479122
  validation accuracy:		92.93 %
Epoch 1631 of 2000 took 0.035s
  training loss:		0.005064
  validation loss:		0.479187
  validation accuracy:		92.93 %
Epoch 1632 of 2000 took 0.035s
  training loss:		0.005110
  validation loss:		0.474322
  validation accuracy:		92.83 %
Epoch 1633 of 2000 took 0.035s
  training loss:		0.004970
  validation loss:		0.484403
  validation accuracy:		92.83 %
Epoch 1634 of 2000 took 0.035s
  training loss:		0.005215
  validation loss:		0.480369
  validation accuracy:		92.72 %
Epoch 1635 of 2000 took 0.035s
  training loss:		0.005007
  validation loss:		0.481085
  validation accuracy:		92.83 %
Epoch 1636 of 2000 took 0.035s
  training loss:		0.005041
  validation loss:		0.478862
  validation accuracy:		92.83 %
Epoch 1637 of 2000 took 0.035s
  training loss:		0.005106
  validation loss:		0.478942
  validation accuracy:		92.93 %
Epoch 1638 of 2000 took 0.035s
  training loss:		0.004924
  validation loss:		0.479572
  validation accuracy:		92.83 %
Epoch 1639 of 2000 took 0.035s
  training loss:		0.005160
  validation loss:		0.484598
  validation accuracy:		92.83 %
Epoch 1640 of 2000 took 0.035s
  training loss:		0.005090
  validation loss:		0.487340
  validation accuracy:		92.83 %
Epoch 1641 of 2000 took 0.035s
  training loss:		0.004965
  validation loss:		0.480978
  validation accuracy:		92.83 %
Epoch 1642 of 2000 took 0.035s
  training loss:		0.005009
  validation loss:		0.483774
  validation accuracy:		92.83 %
Epoch 1643 of 2000 took 0.035s
  training loss:		0.005036
  validation loss:		0.487111
  validation accuracy:		92.72 %
Epoch 1644 of 2000 took 0.035s
  training loss:		0.005092
  validation loss:		0.482486
  validation accuracy:		92.83 %
Epoch 1645 of 2000 took 0.035s
  training loss:		0.004963
  validation loss:		0.481661
  validation accuracy:		92.83 %
Epoch 1646 of 2000 took 0.035s
  training loss:		0.004770
  validation loss:		0.485076
  validation accuracy:		92.72 %
Epoch 1647 of 2000 took 0.035s
  training loss:		0.004996
  validation loss:		0.479328
  validation accuracy:		92.83 %
Epoch 1648 of 2000 took 0.035s
  training loss:		0.004980
  validation loss:		0.484580
  validation accuracy:		92.83 %
Epoch 1649 of 2000 took 0.035s
  training loss:		0.005031
  validation loss:		0.480292
  validation accuracy:		92.83 %
Epoch 1650 of 2000 took 0.035s
  training loss:		0.005023
  validation loss:		0.483343
  validation accuracy:		92.83 %
Epoch 1651 of 2000 took 0.035s
  training loss:		0.005019
  validation loss:		0.482066
  validation accuracy:		92.93 %
Epoch 1652 of 2000 took 0.035s
  training loss:		0.004899
  validation loss:		0.485764
  validation accuracy:		92.83 %
Epoch 1653 of 2000 took 0.035s
  training loss:		0.004806
  validation loss:		0.481949
  validation accuracy:		92.93 %
Epoch 1654 of 2000 took 0.035s
  training loss:		0.004887
  validation loss:		0.478923
  validation accuracy:		92.83 %
Epoch 1655 of 2000 took 0.035s
  training loss:		0.004801
  validation loss:		0.487084
  validation accuracy:		92.83 %
Epoch 1656 of 2000 took 0.035s
  training loss:		0.004898
  validation loss:		0.481575
  validation accuracy:		92.83 %
Epoch 1657 of 2000 took 0.035s
  training loss:		0.005030
  validation loss:		0.481530
  validation accuracy:		92.72 %
Epoch 1658 of 2000 took 0.035s
  training loss:		0.005025
  validation loss:		0.484948
  validation accuracy:		92.83 %
Epoch 1659 of 2000 took 0.035s
  training loss:		0.005083
  validation loss:		0.482715
  validation accuracy:		92.72 %
Epoch 1660 of 2000 took 0.035s
  training loss:		0.004880
  validation loss:		0.487272
  validation accuracy:		92.83 %
Epoch 1661 of 2000 took 0.035s
  training loss:		0.004890
  validation loss:		0.482711
  validation accuracy:		92.83 %
Epoch 1662 of 2000 took 0.035s
  training loss:		0.004889
  validation loss:		0.486413
  validation accuracy:		92.83 %
Epoch 1663 of 2000 took 0.035s
  training loss:		0.004866
  validation loss:		0.485046
  validation accuracy:		92.83 %
Epoch 1664 of 2000 took 0.035s
  training loss:		0.004887
  validation loss:		0.484706
  validation accuracy:		92.83 %
Epoch 1665 of 2000 took 0.035s
  training loss:		0.004924
  validation loss:		0.487007
  validation accuracy:		92.83 %
Epoch 1666 of 2000 took 0.035s
  training loss:		0.004909
  validation loss:		0.488137
  validation accuracy:		92.83 %
Epoch 1667 of 2000 took 0.035s
  training loss:		0.004760
  validation loss:		0.479855
  validation accuracy:		92.83 %
Epoch 1668 of 2000 took 0.035s
  training loss:		0.004739
  validation loss:		0.485937
  validation accuracy:		92.83 %
Epoch 1669 of 2000 took 0.035s
  training loss:		0.004929
  validation loss:		0.487600
  validation accuracy:		92.83 %
Epoch 1670 of 2000 took 0.035s
  training loss:		0.004916
  validation loss:		0.489262
  validation accuracy:		92.72 %
Epoch 1671 of 2000 took 0.035s
  training loss:		0.004833
  validation loss:		0.484156
  validation accuracy:		92.83 %
Epoch 1672 of 2000 took 0.035s
  training loss:		0.004822
  validation loss:		0.484136
  validation accuracy:		92.83 %
Epoch 1673 of 2000 took 0.035s
  training loss:		0.004874
  validation loss:		0.488609
  validation accuracy:		92.83 %
Epoch 1674 of 2000 took 0.035s
  training loss:		0.004873
  validation loss:		0.490734
  validation accuracy:		92.72 %
Epoch 1675 of 2000 took 0.035s
  training loss:		0.004781
  validation loss:		0.487034
  validation accuracy:		92.83 %
Epoch 1676 of 2000 took 0.035s
  training loss:		0.004782
  validation loss:		0.489166
  validation accuracy:		92.83 %
Epoch 1677 of 2000 took 0.035s
  training loss:		0.004831
  validation loss:		0.488575
  validation accuracy:		92.83 %
Epoch 1678 of 2000 took 0.035s
  training loss:		0.004599
  validation loss:		0.487462
  validation accuracy:		92.83 %
Epoch 1679 of 2000 took 0.035s
  training loss:		0.004599
  validation loss:		0.490051
  validation accuracy:		92.83 %
Epoch 1680 of 2000 took 0.035s
  training loss:		0.004732
  validation loss:		0.485338
  validation accuracy:		92.83 %
Epoch 1681 of 2000 took 0.035s
  training loss:		0.004702
  validation loss:		0.491177
  validation accuracy:		92.83 %
Epoch 1682 of 2000 took 0.035s
  training loss:		0.004704
  validation loss:		0.490267
  validation accuracy:		92.83 %
Epoch 1683 of 2000 took 0.035s
  training loss:		0.004843
  validation loss:		0.482111
  validation accuracy:		92.83 %
Epoch 1684 of 2000 took 0.035s
  training loss:		0.004611
  validation loss:		0.488102
  validation accuracy:		92.83 %
Epoch 1685 of 2000 took 0.035s
  training loss:		0.004741
  validation loss:		0.491975
  validation accuracy:		92.83 %
Epoch 1686 of 2000 took 0.035s
  training loss:		0.004639
  validation loss:		0.486555
  validation accuracy:		92.83 %
Epoch 1687 of 2000 took 0.035s
  training loss:		0.004659
  validation loss:		0.492306
  validation accuracy:		92.72 %
Epoch 1688 of 2000 took 0.035s
  training loss:		0.004811
  validation loss:		0.486271
  validation accuracy:		92.83 %
Epoch 1689 of 2000 took 0.035s
  training loss:		0.004685
  validation loss:		0.485178
  validation accuracy:		92.93 %
Epoch 1690 of 2000 took 0.035s
  training loss:		0.004577
  validation loss:		0.497246
  validation accuracy:		92.72 %
Epoch 1691 of 2000 took 0.035s
  training loss:		0.004766
  validation loss:		0.492203
  validation accuracy:		92.83 %
Epoch 1692 of 2000 took 0.035s
  training loss:		0.004641
  validation loss:		0.490291
  validation accuracy:		92.83 %
Epoch 1693 of 2000 took 0.035s
  training loss:		0.004672
  validation loss:		0.489963
  validation accuracy:		92.83 %
Epoch 1694 of 2000 took 0.035s
  training loss:		0.004619
  validation loss:		0.484033
  validation accuracy:		92.93 %
Epoch 1695 of 2000 took 0.035s
  training loss:		0.004518
  validation loss:		0.494641
  validation accuracy:		92.83 %
Epoch 1696 of 2000 took 0.035s
  training loss:		0.004593
  validation loss:		0.489723
  validation accuracy:		92.83 %
Epoch 1697 of 2000 took 0.035s
  training loss:		0.004715
  validation loss:		0.487907
  validation accuracy:		92.83 %
Epoch 1698 of 2000 took 0.035s
  training loss:		0.004699
  validation loss:		0.487707
  validation accuracy:		92.83 %
Epoch 1699 of 2000 took 0.035s
  training loss:		0.004488
  validation loss:		0.491537
  validation accuracy:		92.83 %
Epoch 1700 of 2000 took 0.035s
  training loss:		0.004660
  validation loss:		0.490089
  validation accuracy:		92.83 %
Epoch 1701 of 2000 took 0.035s
  training loss:		0.004650
  validation loss:		0.490848
  validation accuracy:		92.83 %
Epoch 1702 of 2000 took 0.035s
  training loss:		0.004572
  validation loss:		0.486739
  validation accuracy:		92.83 %
Epoch 1703 of 2000 took 0.035s
  training loss:		0.004507
  validation loss:		0.490174
  validation accuracy:		92.83 %
Epoch 1704 of 2000 took 0.035s
  training loss:		0.004669
  validation loss:		0.495086
  validation accuracy:		92.72 %
Epoch 1705 of 2000 took 0.035s
  training loss:		0.004579
  validation loss:		0.489211
  validation accuracy:		92.83 %
Epoch 1706 of 2000 took 0.035s
  training loss:		0.004339
  validation loss:		0.487659
  validation accuracy:		92.93 %
Epoch 1707 of 2000 took 0.035s
  training loss:		0.004482
  validation loss:		0.490805
  validation accuracy:		92.83 %
Epoch 1708 of 2000 took 0.035s
  training loss:		0.004377
  validation loss:		0.489970
  validation accuracy:		92.83 %
Epoch 1709 of 2000 took 0.035s
  training loss:		0.004602
  validation loss:		0.488282
  validation accuracy:		92.93 %
Epoch 1710 of 2000 took 0.035s
  training loss:		0.004407
  validation loss:		0.495295
  validation accuracy:		92.72 %
Epoch 1711 of 2000 took 0.035s
  training loss:		0.004342
  validation loss:		0.494546
  validation accuracy:		92.83 %
Epoch 1712 of 2000 took 0.035s
  training loss:		0.004757
  validation loss:		0.492818
  validation accuracy:		92.83 %
Epoch 1713 of 2000 took 0.035s
  training loss:		0.004715
  validation loss:		0.482535
  validation accuracy:		92.93 %
Epoch 1714 of 2000 took 0.035s
  training loss:		0.004629
  validation loss:		0.489272
  validation accuracy:		92.83 %
Epoch 1715 of 2000 took 0.035s
  training loss:		0.004569
  validation loss:		0.494854
  validation accuracy:		92.83 %
Epoch 1716 of 2000 took 0.035s
  training loss:		0.004544
  validation loss:		0.488992
  validation accuracy:		92.93 %
Epoch 1717 of 2000 took 0.035s
  training loss:		0.004569
  validation loss:		0.496491
  validation accuracy:		92.83 %
Epoch 1718 of 2000 took 0.035s
  training loss:		0.004423
  validation loss:		0.491755
  validation accuracy:		92.93 %
Epoch 1719 of 2000 took 0.035s
  training loss:		0.004322
  validation loss:		0.490092
  validation accuracy:		92.83 %
Epoch 1720 of 2000 took 0.035s
  training loss:		0.004684
  validation loss:		0.493688
  validation accuracy:		92.83 %
Epoch 1721 of 2000 took 0.035s
  training loss:		0.004487
  validation loss:		0.498995
  validation accuracy:		92.93 %
Epoch 1722 of 2000 took 0.035s
  training loss:		0.004742
  validation loss:		0.490538
  validation accuracy:		92.72 %
Epoch 1723 of 2000 took 0.035s
  training loss:		0.004458
  validation loss:		0.495924
  validation accuracy:		92.83 %
Epoch 1724 of 2000 took 0.035s
  training loss:		0.004454
  validation loss:		0.492143
  validation accuracy:		92.83 %
Epoch 1725 of 2000 took 0.035s
  training loss:		0.004376
  validation loss:		0.493158
  validation accuracy:		92.93 %
Epoch 1726 of 2000 took 0.035s
  training loss:		0.004502
  validation loss:		0.496100
  validation accuracy:		92.72 %
Epoch 1727 of 2000 took 0.035s
  training loss:		0.004397
  validation loss:		0.492284
  validation accuracy:		92.83 %
Epoch 1728 of 2000 took 0.035s
  training loss:		0.004521
  validation loss:		0.497027
  validation accuracy:		92.83 %
Epoch 1729 of 2000 took 0.035s
  training loss:		0.004464
  validation loss:		0.493484
  validation accuracy:		92.83 %
Epoch 1730 of 2000 took 0.035s
  training loss:		0.004320
  validation loss:		0.496863
  validation accuracy:		92.83 %
Epoch 1731 of 2000 took 0.035s
  training loss:		0.004340
  validation loss:		0.495733
  validation accuracy:		92.83 %
Epoch 1732 of 2000 took 0.035s
  training loss:		0.004311
  validation loss:		0.495649
  validation accuracy:		92.83 %
Epoch 1733 of 2000 took 0.035s
  training loss:		0.004256
  validation loss:		0.491979
  validation accuracy:		92.93 %
Epoch 1734 of 2000 took 0.035s
  training loss:		0.004324
  validation loss:		0.498670
  validation accuracy:		92.83 %
Epoch 1735 of 2000 took 0.035s
  training loss:		0.004546
  validation loss:		0.497316
  validation accuracy:		92.83 %
Epoch 1736 of 2000 took 0.035s
  training loss:		0.004372
  validation loss:		0.492436
  validation accuracy:		92.93 %
Epoch 1737 of 2000 took 0.035s
  training loss:		0.004431
  validation loss:		0.497977
  validation accuracy:		92.72 %
Epoch 1738 of 2000 took 0.035s
  training loss:		0.004243
  validation loss:		0.497007
  validation accuracy:		92.72 %
Epoch 1739 of 2000 took 0.035s
  training loss:		0.004344
  validation loss:		0.493483
  validation accuracy:		92.83 %
Epoch 1740 of 2000 took 0.035s
  training loss:		0.004347
  validation loss:		0.503101
  validation accuracy:		92.72 %
Epoch 1741 of 2000 took 0.035s
  training loss:		0.004283
  validation loss:		0.494126
  validation accuracy:		92.83 %
Epoch 1742 of 2000 took 0.035s
  training loss:		0.004351
  validation loss:		0.497051
  validation accuracy:		92.83 %
Epoch 1743 of 2000 took 0.035s
  training loss:		0.004433
  validation loss:		0.495728
  validation accuracy:		92.83 %
Epoch 1744 of 2000 took 0.035s
  training loss:		0.004439
  validation loss:		0.500780
  validation accuracy:		92.83 %
Epoch 1745 of 2000 took 0.035s
  training loss:		0.004425
  validation loss:		0.495134
  validation accuracy:		92.83 %
Epoch 1746 of 2000 took 0.035s
  training loss:		0.004250
  validation loss:		0.501328
  validation accuracy:		92.83 %
Epoch 1747 of 2000 took 0.035s
  training loss:		0.004371
  validation loss:		0.499639
  validation accuracy:		92.83 %
Epoch 1748 of 2000 took 0.035s
  training loss:		0.004289
  validation loss:		0.501859
  validation accuracy:		92.72 %
Epoch 1749 of 2000 took 0.035s
  training loss:		0.004491
  validation loss:		0.498613
  validation accuracy:		92.83 %
Epoch 1750 of 2000 took 0.035s
  training loss:		0.004226
  validation loss:		0.501432
  validation accuracy:		92.72 %
Epoch 1751 of 2000 took 0.035s
  training loss:		0.004268
  validation loss:		0.496885
  validation accuracy:		92.83 %
Epoch 1752 of 2000 took 0.035s
  training loss:		0.004146
  validation loss:		0.496578
  validation accuracy:		92.83 %
Epoch 1753 of 2000 took 0.035s
  training loss:		0.004370
  validation loss:		0.499946
  validation accuracy:		92.83 %
Epoch 1754 of 2000 took 0.035s
  training loss:		0.004277
  validation loss:		0.498091
  validation accuracy:		92.83 %
Epoch 1755 of 2000 took 0.035s
  training loss:		0.004109
  validation loss:		0.499943
  validation accuracy:		92.83 %
Epoch 1756 of 2000 took 0.035s
  training loss:		0.004178
  validation loss:		0.504084
  validation accuracy:		92.72 %
Epoch 1757 of 2000 took 0.035s
  training loss:		0.004261
  validation loss:		0.499018
  validation accuracy:		92.83 %
Epoch 1758 of 2000 took 0.035s
  training loss:		0.004346
  validation loss:		0.499528
  validation accuracy:		92.83 %
Epoch 1759 of 2000 took 0.035s
  training loss:		0.004215
  validation loss:		0.498406
  validation accuracy:		92.83 %
Epoch 1760 of 2000 took 0.035s
  training loss:		0.004235
  validation loss:		0.500910
  validation accuracy:		92.83 %
Epoch 1761 of 2000 took 0.035s
  training loss:		0.004187
  validation loss:		0.500680
  validation accuracy:		92.83 %
Epoch 1762 of 2000 took 0.035s
  training loss:		0.004244
  validation loss:		0.500297
  validation accuracy:		92.93 %
Epoch 1763 of 2000 took 0.035s
  training loss:		0.004296
  validation loss:		0.498949
  validation accuracy:		92.83 %
Epoch 1764 of 2000 took 0.035s
  training loss:		0.004259
  validation loss:		0.500856
  validation accuracy:		92.72 %
Epoch 1765 of 2000 took 0.035s
  training loss:		0.004064
  validation loss:		0.498529
  validation accuracy:		92.83 %
Epoch 1766 of 2000 took 0.035s
  training loss:		0.004250
  validation loss:		0.501296
  validation accuracy:		92.83 %
Epoch 1767 of 2000 took 0.035s
  training loss:		0.004274
  validation loss:		0.501241
  validation accuracy:		92.83 %
Epoch 1768 of 2000 took 0.035s
  training loss:		0.004347
  validation loss:		0.506261
  validation accuracy:		92.72 %
Epoch 1769 of 2000 took 0.035s
  training loss:		0.004239
  validation loss:		0.501110
  validation accuracy:		92.83 %
Epoch 1770 of 2000 took 0.035s
  training loss:		0.004140
  validation loss:		0.497274
  validation accuracy:		92.93 %
Epoch 1771 of 2000 took 0.035s
  training loss:		0.004189
  validation loss:		0.497933
  validation accuracy:		92.83 %
Epoch 1772 of 2000 took 0.035s
  training loss:		0.004139
  validation loss:		0.504150
  validation accuracy:		92.83 %
Epoch 1773 of 2000 took 0.035s
  training loss:		0.004226
  validation loss:		0.504355
  validation accuracy:		92.72 %
Epoch 1774 of 2000 took 0.035s
  training loss:		0.004180
  validation loss:		0.504859
  validation accuracy:		92.83 %
Epoch 1775 of 2000 took 0.035s
  training loss:		0.004186
  validation loss:		0.502151
  validation accuracy:		92.83 %
Epoch 1776 of 2000 took 0.035s
  training loss:		0.004137
  validation loss:		0.498695
  validation accuracy:		92.83 %
Epoch 1777 of 2000 took 0.035s
  training loss:		0.004162
  validation loss:		0.500055
  validation accuracy:		92.83 %
Epoch 1778 of 2000 took 0.035s
  training loss:		0.004201
  validation loss:		0.502455
  validation accuracy:		92.83 %
Epoch 1779 of 2000 took 0.035s
  training loss:		0.004186
  validation loss:		0.501569
  validation accuracy:		92.93 %
Epoch 1780 of 2000 took 0.035s
  training loss:		0.004155
  validation loss:		0.501547
  validation accuracy:		92.83 %
Epoch 1781 of 2000 took 0.035s
  training loss:		0.004070
  validation loss:		0.502548
  validation accuracy:		92.83 %
Epoch 1782 of 2000 took 0.035s
  training loss:		0.004071
  validation loss:		0.502384
  validation accuracy:		92.83 %
Epoch 1783 of 2000 took 0.035s
  training loss:		0.004123
  validation loss:		0.503972
  validation accuracy:		92.72 %
Epoch 1784 of 2000 took 0.035s
  training loss:		0.004155
  validation loss:		0.503507
  validation accuracy:		92.83 %
Epoch 1785 of 2000 took 0.035s
  training loss:		0.004071
  validation loss:		0.503448
  validation accuracy:		92.83 %
Epoch 1786 of 2000 took 0.035s
  training loss:		0.004026
  validation loss:		0.499375
  validation accuracy:		92.83 %
Epoch 1787 of 2000 took 0.035s
  training loss:		0.004282
  validation loss:		0.510939
  validation accuracy:		92.61 %
Epoch 1788 of 2000 took 0.035s
  training loss:		0.004218
  validation loss:		0.503192
  validation accuracy:		92.83 %
Epoch 1789 of 2000 took 0.035s
  training loss:		0.003960
  validation loss:		0.505728
  validation accuracy:		92.72 %
Epoch 1790 of 2000 took 0.035s
  training loss:		0.004114
  validation loss:		0.502278
  validation accuracy:		92.83 %
Epoch 1791 of 2000 took 0.035s
  training loss:		0.004028
  validation loss:		0.504073
  validation accuracy:		92.83 %
Epoch 1792 of 2000 took 0.035s
  training loss:		0.003981
  validation loss:		0.504020
  validation accuracy:		92.83 %
Epoch 1793 of 2000 took 0.035s
  training loss:		0.004103
  validation loss:		0.508513
  validation accuracy:		92.72 %
Epoch 1794 of 2000 took 0.035s
  training loss:		0.003949
  validation loss:		0.499560
  validation accuracy:		92.93 %
Epoch 1795 of 2000 took 0.035s
  training loss:		0.004068
  validation loss:		0.505991
  validation accuracy:		92.83 %
Epoch 1796 of 2000 took 0.035s
  training loss:		0.004039
  validation loss:		0.505846
  validation accuracy:		92.83 %
Epoch 1797 of 2000 took 0.035s
  training loss:		0.004093
  validation loss:		0.504778
  validation accuracy:		92.83 %
Epoch 1798 of 2000 took 0.035s
  training loss:		0.003985
  validation loss:		0.503089
  validation accuracy:		92.83 %
Epoch 1799 of 2000 took 0.035s
  training loss:		0.004064
  validation loss:		0.506593
  validation accuracy:		92.72 %
Epoch 1800 of 2000 took 0.035s
  training loss:		0.003949
  validation loss:		0.504172
  validation accuracy:		92.83 %
Epoch 1801 of 2000 took 0.035s
  training loss:		0.003963
  validation loss:		0.507729
  validation accuracy:		92.83 %
Epoch 1802 of 2000 took 0.035s
  training loss:		0.004003
  validation loss:		0.504413
  validation accuracy:		92.93 %
Epoch 1803 of 2000 took 0.035s
  training loss:		0.004070
  validation loss:		0.503164
  validation accuracy:		92.93 %
Epoch 1804 of 2000 took 0.035s
  training loss:		0.003939
  validation loss:		0.503489
  validation accuracy:		92.83 %
Epoch 1805 of 2000 took 0.035s
  training loss:		0.004033
  validation loss:		0.506833
  validation accuracy:		92.83 %
Epoch 1806 of 2000 took 0.035s
  training loss:		0.003957
  validation loss:		0.505507
  validation accuracy:		92.83 %
Epoch 1807 of 2000 took 0.035s
  training loss:		0.004028
  validation loss:		0.503314
  validation accuracy:		92.83 %
Epoch 1808 of 2000 took 0.035s
  training loss:		0.003892
  validation loss:		0.509328
  validation accuracy:		92.83 %
Epoch 1809 of 2000 took 0.035s
  training loss:		0.003943
  validation loss:		0.505767
  validation accuracy:		92.72 %
Epoch 1810 of 2000 took 0.035s
  training loss:		0.003989
  validation loss:		0.508710
  validation accuracy:		92.72 %
Epoch 1811 of 2000 took 0.035s
  training loss:		0.004079
  validation loss:		0.505412
  validation accuracy:		92.83 %
Epoch 1812 of 2000 took 0.035s
  training loss:		0.003993
  validation loss:		0.509673
  validation accuracy:		92.72 %
Epoch 1813 of 2000 took 0.035s
  training loss:		0.003814
  validation loss:		0.501645
  validation accuracy:		92.83 %
Epoch 1814 of 2000 took 0.035s
  training loss:		0.003805
  validation loss:		0.508687
  validation accuracy:		92.93 %
Epoch 1815 of 2000 took 0.035s
  training loss:		0.004152
  validation loss:		0.506644
  validation accuracy:		92.83 %
Epoch 1816 of 2000 took 0.035s
  training loss:		0.003956
  validation loss:		0.507985
  validation accuracy:		92.83 %
Epoch 1817 of 2000 took 0.035s
  training loss:		0.003924
  validation loss:		0.508873
  validation accuracy:		92.83 %
Epoch 1818 of 2000 took 0.035s
  training loss:		0.003917
  validation loss:		0.509220
  validation accuracy:		92.83 %
Epoch 1819 of 2000 took 0.035s
  training loss:		0.003884
  validation loss:		0.507089
  validation accuracy:		92.83 %
Epoch 1820 of 2000 took 0.035s
  training loss:		0.003884
  validation loss:		0.506419
  validation accuracy:		92.83 %
Epoch 1821 of 2000 took 0.035s
  training loss:		0.003920
  validation loss:		0.513182
  validation accuracy:		92.83 %
Epoch 1822 of 2000 took 0.035s
  training loss:		0.003948
  validation loss:		0.508255
  validation accuracy:		92.83 %
Epoch 1823 of 2000 took 0.035s
  training loss:		0.003861
  validation loss:		0.506975
  validation accuracy:		92.83 %
Epoch 1824 of 2000 took 0.035s
  training loss:		0.004000
  validation loss:		0.509876
  validation accuracy:		92.83 %
Epoch 1825 of 2000 took 0.035s
  training loss:		0.003860
  validation loss:		0.507913
  validation accuracy:		92.93 %
Epoch 1826 of 2000 took 0.035s
  training loss:		0.003926
  validation loss:		0.504838
  validation accuracy:		92.93 %
Epoch 1827 of 2000 took 0.035s
  training loss:		0.003932
  validation loss:		0.512080
  validation accuracy:		92.72 %
Epoch 1828 of 2000 took 0.035s
  training loss:		0.003943
  validation loss:		0.510212
  validation accuracy:		92.83 %
Epoch 1829 of 2000 took 0.035s
  training loss:		0.003928
  validation loss:		0.506336
  validation accuracy:		92.83 %
Epoch 1830 of 2000 took 0.035s
  training loss:		0.003735
  validation loss:		0.513759
  validation accuracy:		92.83 %
Epoch 1831 of 2000 took 0.035s
  training loss:		0.003806
  validation loss:		0.507204
  validation accuracy:		92.93 %
Epoch 1832 of 2000 took 0.035s
  training loss:		0.003895
  validation loss:		0.504850
  validation accuracy:		92.83 %
Epoch 1833 of 2000 took 0.035s
  training loss:		0.003817
  validation loss:		0.515463
  validation accuracy:		92.72 %
Epoch 1834 of 2000 took 0.035s
  training loss:		0.003969
  validation loss:		0.508094
  validation accuracy:		92.83 %
Epoch 1835 of 2000 took 0.035s
  training loss:		0.003721
  validation loss:		0.508761
  validation accuracy:		92.83 %
Epoch 1836 of 2000 took 0.035s
  training loss:		0.003881
  validation loss:		0.513593
  validation accuracy:		92.83 %
Epoch 1837 of 2000 took 0.035s
  training loss:		0.003783
  validation loss:		0.511031
  validation accuracy:		92.83 %
Epoch 1838 of 2000 took 0.035s
  training loss:		0.003911
  validation loss:		0.510593
  validation accuracy:		92.83 %
Epoch 1839 of 2000 took 0.035s
  training loss:		0.003826
  validation loss:		0.510211
  validation accuracy:		92.83 %
Epoch 1840 of 2000 took 0.035s
  training loss:		0.003860
  validation loss:		0.508101
  validation accuracy:		92.93 %
Epoch 1841 of 2000 took 0.035s
  training loss:		0.003907
  validation loss:		0.513032
  validation accuracy:		92.72 %
Epoch 1842 of 2000 took 0.035s
  training loss:		0.003748
  validation loss:		0.512917
  validation accuracy:		92.72 %
Epoch 1843 of 2000 took 0.035s
  training loss:		0.003764
  validation loss:		0.509860
  validation accuracy:		92.83 %
Epoch 1844 of 2000 took 0.035s
  training loss:		0.003789
  validation loss:		0.515063
  validation accuracy:		92.83 %
Epoch 1845 of 2000 took 0.035s
  training loss:		0.003825
  validation loss:		0.514717
  validation accuracy:		92.72 %
Epoch 1846 of 2000 took 0.035s
  training loss:		0.003940
  validation loss:		0.511227
  validation accuracy:		92.83 %
Epoch 1847 of 2000 took 0.035s
  training loss:		0.003812
  validation loss:		0.506236
  validation accuracy:		92.83 %
Epoch 1848 of 2000 took 0.035s
  training loss:		0.003846
  validation loss:		0.511054
  validation accuracy:		92.83 %
Epoch 1849 of 2000 took 0.035s
  training loss:		0.003678
  validation loss:		0.511389
  validation accuracy:		92.83 %
Epoch 1850 of 2000 took 0.035s
  training loss:		0.003801
  validation loss:		0.511422
  validation accuracy:		92.83 %
Epoch 1851 of 2000 took 0.035s
  training loss:		0.003848
  validation loss:		0.511028
  validation accuracy:		92.93 %
Epoch 1852 of 2000 took 0.035s
  training loss:		0.003805
  validation loss:		0.512058
  validation accuracy:		92.83 %
Epoch 1853 of 2000 took 0.035s
  training loss:		0.003780
  validation loss:		0.513101
  validation accuracy:		92.83 %
Epoch 1854 of 2000 took 0.035s
  training loss:		0.003794
  validation loss:		0.513613
  validation accuracy:		92.83 %
Epoch 1855 of 2000 took 0.035s
  training loss:		0.003757
  validation loss:		0.513903
  validation accuracy:		92.83 %
Epoch 1856 of 2000 took 0.035s
  training loss:		0.003765
  validation loss:		0.515611
  validation accuracy:		92.72 %
Epoch 1857 of 2000 took 0.035s
  training loss:		0.003560
  validation loss:		0.515878
  validation accuracy:		92.72 %
Epoch 1858 of 2000 took 0.035s
  training loss:		0.003685
  validation loss:		0.513054
  validation accuracy:		92.72 %
Epoch 1859 of 2000 took 0.035s
  training loss:		0.003741
  validation loss:		0.514101
  validation accuracy:		92.83 %
Epoch 1860 of 2000 took 0.035s
  training loss:		0.003751
  validation loss:		0.516281
  validation accuracy:		92.72 %
Epoch 1861 of 2000 took 0.035s
  training loss:		0.003686
  validation loss:		0.512287
  validation accuracy:		92.93 %
Epoch 1862 of 2000 took 0.035s
  training loss:		0.003727
  validation loss:		0.519855
  validation accuracy:		92.72 %
Epoch 1863 of 2000 took 0.035s
  training loss:		0.003599
  validation loss:		0.512828
  validation accuracy:		92.83 %
Epoch 1864 of 2000 took 0.035s
  training loss:		0.003712
  validation loss:		0.512491
  validation accuracy:		92.83 %
Epoch 1865 of 2000 took 0.035s
  training loss:		0.003625
  validation loss:		0.513408
  validation accuracy:		92.83 %
Epoch 1866 of 2000 took 0.035s
  training loss:		0.003795
  validation loss:		0.515260
  validation accuracy:		92.83 %
Epoch 1867 of 2000 took 0.035s
  training loss:		0.003730
  validation loss:		0.517352
  validation accuracy:		92.83 %
Epoch 1868 of 2000 took 0.035s
  training loss:		0.003740
  validation loss:		0.513872
  validation accuracy:		92.83 %
Epoch 1869 of 2000 took 0.035s
  training loss:		0.003685
  validation loss:		0.510938
  validation accuracy:		92.83 %
Epoch 1870 of 2000 took 0.035s
  training loss:		0.003632
  validation loss:		0.515826
  validation accuracy:		92.72 %
Epoch 1871 of 2000 took 0.035s
  training loss:		0.003635
  validation loss:		0.514162
  validation accuracy:		92.83 %
Epoch 1872 of 2000 took 0.035s
  training loss:		0.003764
  validation loss:		0.512429
  validation accuracy:		92.83 %
Epoch 1873 of 2000 took 0.035s
  training loss:		0.003706
  validation loss:		0.515674
  validation accuracy:		92.83 %
Epoch 1874 of 2000 took 0.035s
  training loss:		0.003623
  validation loss:		0.510682
  validation accuracy:		92.93 %
Epoch 1875 of 2000 took 0.035s
  training loss:		0.003584
  validation loss:		0.521582
  validation accuracy:		92.61 %
Epoch 1876 of 2000 took 0.035s
  training loss:		0.003666
  validation loss:		0.515514
  validation accuracy:		92.83 %
Epoch 1877 of 2000 took 0.035s
  training loss:		0.003615
  validation loss:		0.512247
  validation accuracy:		92.83 %
Epoch 1878 of 2000 took 0.035s
  training loss:		0.003645
  validation loss:		0.517141
  validation accuracy:		92.83 %
Epoch 1879 of 2000 took 0.035s
  training loss:		0.003698
  validation loss:		0.516924
  validation accuracy:		92.72 %
Epoch 1880 of 2000 took 0.035s
  training loss:		0.003532
  validation loss:		0.521832
  validation accuracy:		92.72 %
Epoch 1881 of 2000 took 0.035s
  training loss:		0.003722
  validation loss:		0.520983
  validation accuracy:		92.72 %
Epoch 1882 of 2000 took 0.035s
  training loss:		0.003455
  validation loss:		0.514858
  validation accuracy:		92.83 %
Epoch 1883 of 2000 took 0.035s
  training loss:		0.003623
  validation loss:		0.509011
  validation accuracy:		92.93 %
Epoch 1884 of 2000 took 0.035s
  training loss:		0.003590
  validation loss:		0.521592
  validation accuracy:		92.72 %
Epoch 1885 of 2000 took 0.035s
  training loss:		0.003622
  validation loss:		0.515040
  validation accuracy:		92.93 %
Epoch 1886 of 2000 took 0.035s
  training loss:		0.003524
  validation loss:		0.518830
  validation accuracy:		92.72 %
Epoch 1887 of 2000 took 0.035s
  training loss:		0.003431
  validation loss:		0.517655
  validation accuracy:		92.83 %
Epoch 1888 of 2000 took 0.035s
  training loss:		0.003497
  validation loss:		0.519069
  validation accuracy:		92.72 %
Epoch 1889 of 2000 took 0.035s
  training loss:		0.003685
  validation loss:		0.517466
  validation accuracy:		92.83 %
Epoch 1890 of 2000 took 0.035s
  training loss:		0.003589
  validation loss:		0.518524
  validation accuracy:		92.83 %
Epoch 1891 of 2000 took 0.035s
  training loss:		0.003451
  validation loss:		0.518437
  validation accuracy:		92.83 %
Epoch 1892 of 2000 took 0.035s
  training loss:		0.003537
  validation loss:		0.522375
  validation accuracy:		92.72 %
Epoch 1893 of 2000 took 0.035s
  training loss:		0.003600
  validation loss:		0.515412
  validation accuracy:		92.93 %
Epoch 1894 of 2000 took 0.035s
  training loss:		0.003549
  validation loss:		0.516713
  validation accuracy:		92.83 %
Epoch 1895 of 2000 took 0.035s
  training loss:		0.003610
  validation loss:		0.518489
  validation accuracy:		92.83 %
Epoch 1896 of 2000 took 0.035s
  training loss:		0.003623
  validation loss:		0.521125
  validation accuracy:		92.83 %
Epoch 1897 of 2000 took 0.035s
  training loss:		0.003530
  validation loss:		0.516141
  validation accuracy:		92.93 %
Epoch 1898 of 2000 took 0.035s
  training loss:		0.003519
  validation loss:		0.520839
  validation accuracy:		92.83 %
Epoch 1899 of 2000 took 0.035s
  training loss:		0.003581
  validation loss:		0.514968
  validation accuracy:		93.04 %
Epoch 1900 of 2000 took 0.035s
  training loss:		0.003555
  validation loss:		0.520162
  validation accuracy:		92.83 %
Epoch 1901 of 2000 took 0.035s
  training loss:		0.003518
  validation loss:		0.515708
  validation accuracy:		92.93 %
Epoch 1902 of 2000 took 0.035s
  training loss:		0.003553
  validation loss:		0.520820
  validation accuracy:		92.61 %
Epoch 1903 of 2000 took 0.035s
  training loss:		0.003561
  validation loss:		0.522246
  validation accuracy:		92.72 %
Epoch 1904 of 2000 took 0.035s
  training loss:		0.003519
  validation loss:		0.516990
  validation accuracy:		92.93 %
Epoch 1905 of 2000 took 0.035s
  training loss:		0.003498
  validation loss:		0.520848
  validation accuracy:		92.83 %
Epoch 1906 of 2000 took 0.035s
  training loss:		0.003438
  validation loss:		0.519800
  validation accuracy:		92.83 %
Epoch 1907 of 2000 took 0.035s
  training loss:		0.003441
  validation loss:		0.516725
  validation accuracy:		93.04 %
Epoch 1908 of 2000 took 0.035s
  training loss:		0.003485
  validation loss:		0.523564
  validation accuracy:		92.72 %
Epoch 1909 of 2000 took 0.035s
  training loss:		0.003559
  validation loss:		0.520331
  validation accuracy:		92.83 %
Epoch 1910 of 2000 took 0.035s
  training loss:		0.003493
  validation loss:		0.519869
  validation accuracy:		92.83 %
Epoch 1911 of 2000 took 0.035s
  training loss:		0.003383
  validation loss:		0.524176
  validation accuracy:		92.83 %
Epoch 1912 of 2000 took 0.035s
  training loss:		0.003557
  validation loss:		0.521258
  validation accuracy:		92.83 %
Epoch 1913 of 2000 took 0.035s
  training loss:		0.003370
  validation loss:		0.523043
  validation accuracy:		92.83 %
Epoch 1914 of 2000 took 0.035s
  training loss:		0.003531
  validation loss:		0.516173
  validation accuracy:		92.93 %
Epoch 1915 of 2000 took 0.035s
  training loss:		0.003471
  validation loss:		0.523214
  validation accuracy:		92.72 %
Epoch 1916 of 2000 took 0.035s
  training loss:		0.003501
  validation loss:		0.520856
  validation accuracy:		92.83 %
Epoch 1917 of 2000 took 0.035s
  training loss:		0.003409
  validation loss:		0.518308
  validation accuracy:		92.83 %
Epoch 1918 of 2000 took 0.035s
  training loss:		0.003479
  validation loss:		0.523385
  validation accuracy:		92.72 %
Epoch 1919 of 2000 took 0.035s
  training loss:		0.003440
  validation loss:		0.521207
  validation accuracy:		92.83 %
Epoch 1920 of 2000 took 0.035s
  training loss:		0.003338
  validation loss:		0.526366
  validation accuracy:		92.72 %
Epoch 1921 of 2000 took 0.035s
  training loss:		0.003554
  validation loss:		0.526127
  validation accuracy:		92.72 %
Epoch 1922 of 2000 took 0.035s
  training loss:		0.003467
  validation loss:		0.518788
  validation accuracy:		92.93 %
Epoch 1923 of 2000 took 0.035s
  training loss:		0.003502
  validation loss:		0.523761
  validation accuracy:		92.83 %
Epoch 1924 of 2000 took 0.035s
  training loss:		0.003455
  validation loss:		0.523073
  validation accuracy:		92.72 %
Epoch 1925 of 2000 took 0.035s
  training loss:		0.003464
  validation loss:		0.524404
  validation accuracy:		92.83 %
Epoch 1926 of 2000 took 0.035s
  training loss:		0.003374
  validation loss:		0.522304
  validation accuracy:		92.83 %
Epoch 1927 of 2000 took 0.035s
  training loss:		0.003499
  validation loss:		0.522393
  validation accuracy:		92.83 %
Epoch 1928 of 2000 took 0.035s
  training loss:		0.003444
  validation loss:		0.523365
  validation accuracy:		92.83 %
Epoch 1929 of 2000 took 0.035s
  training loss:		0.003418
  validation loss:		0.522569
  validation accuracy:		92.83 %
Epoch 1930 of 2000 took 0.035s
  training loss:		0.003417
  validation loss:		0.520622
  validation accuracy:		92.93 %
Epoch 1931 of 2000 took 0.035s
  training loss:		0.003244
  validation loss:		0.523502
  validation accuracy:		92.83 %
Epoch 1932 of 2000 took 0.035s
  training loss:		0.003368
  validation loss:		0.520772
  validation accuracy:		92.83 %
Epoch 1933 of 2000 took 0.035s
  training loss:		0.003325
  validation loss:		0.522313
  validation accuracy:		92.83 %
Epoch 1934 of 2000 took 0.035s
  training loss:		0.003316
  validation loss:		0.527720
  validation accuracy:		92.61 %
Epoch 1935 of 2000 took 0.035s
  training loss:		0.003421
  validation loss:		0.522837
  validation accuracy:		92.83 %
Epoch 1936 of 2000 took 0.035s
  training loss:		0.003374
  validation loss:		0.523134
  validation accuracy:		92.83 %
Epoch 1937 of 2000 took 0.035s
  training loss:		0.003362
  validation loss:		0.522273
  validation accuracy:		92.72 %
Epoch 1938 of 2000 took 0.035s
  training loss:		0.003459
  validation loss:		0.524774
  validation accuracy:		92.83 %
Epoch 1939 of 2000 took 0.035s
  training loss:		0.003400
  validation loss:		0.525970
  validation accuracy:		92.72 %
Epoch 1940 of 2000 took 0.035s
  training loss:		0.003378
  validation loss:		0.521582
  validation accuracy:		92.93 %
Epoch 1941 of 2000 took 0.035s
  training loss:		0.003264
  validation loss:		0.524845
  validation accuracy:		92.83 %
Epoch 1942 of 2000 took 0.035s
  training loss:		0.003308
  validation loss:		0.524929
  validation accuracy:		92.72 %
Epoch 1943 of 2000 took 0.035s
  training loss:		0.003331
  validation loss:		0.520821
  validation accuracy:		92.93 %
Epoch 1944 of 2000 took 0.035s
  training loss:		0.003402
  validation loss:		0.523949
  validation accuracy:		92.83 %
Epoch 1945 of 2000 took 0.035s
  training loss:		0.003324
  validation loss:		0.524631
  validation accuracy:		92.83 %
Epoch 1946 of 2000 took 0.035s
  training loss:		0.003369
  validation loss:		0.523034
  validation accuracy:		92.83 %
Epoch 1947 of 2000 took 0.035s
  training loss:		0.003300
  validation loss:		0.525414
  validation accuracy:		92.83 %
Epoch 1948 of 2000 took 0.035s
  training loss:		0.003331
  validation loss:		0.524818
  validation accuracy:		92.83 %
Epoch 1949 of 2000 took 0.035s
  training loss:		0.003266
  validation loss:		0.526510
  validation accuracy:		92.83 %
Epoch 1950 of 2000 took 0.035s
  training loss:		0.003385
  validation loss:		0.526658
  validation accuracy:		92.83 %
Epoch 1951 of 2000 took 0.035s
  training loss:		0.003274
  validation loss:		0.525872
  validation accuracy:		92.72 %
Epoch 1952 of 2000 took 0.035s
  training loss:		0.003386
  validation loss:		0.527960
  validation accuracy:		92.83 %
Epoch 1953 of 2000 took 0.035s
  training loss:		0.003362
  validation loss:		0.527432
  validation accuracy:		92.93 %
Epoch 1954 of 2000 took 0.035s
  training loss:		0.003415
  validation loss:		0.524905
  validation accuracy:		92.83 %
Epoch 1955 of 2000 took 0.035s
  training loss:		0.003400
  validation loss:		0.529310
  validation accuracy:		92.72 %
Epoch 1956 of 2000 took 0.035s
  training loss:		0.003270
  validation loss:		0.526645
  validation accuracy:		92.83 %
Epoch 1957 of 2000 took 0.035s
  training loss:		0.003294
  validation loss:		0.527063
  validation accuracy:		92.83 %
Epoch 1958 of 2000 took 0.035s
  training loss:		0.003176
  validation loss:		0.527004
  validation accuracy:		92.83 %
Epoch 1959 of 2000 took 0.035s
  training loss:		0.003256
  validation loss:		0.527828
  validation accuracy:		92.83 %
Epoch 1960 of 2000 took 0.035s
  training loss:		0.003264
  validation loss:		0.528413
  validation accuracy:		92.83 %
Epoch 1961 of 2000 took 0.035s
  training loss:		0.003312
  validation loss:		0.526855
  validation accuracy:		92.93 %
Epoch 1962 of 2000 took 0.035s
  training loss:		0.003216
  validation loss:		0.526279
  validation accuracy:		92.72 %
Epoch 1963 of 2000 took 0.035s
  training loss:		0.003259
  validation loss:		0.529355
  validation accuracy:		92.83 %
Epoch 1964 of 2000 took 0.035s
  training loss:		0.003320
  validation loss:		0.528733
  validation accuracy:		92.83 %
Epoch 1965 of 2000 took 0.035s
  training loss:		0.003342
  validation loss:		0.529907
  validation accuracy:		92.83 %
Epoch 1966 of 2000 took 0.035s
  training loss:		0.003200
  validation loss:		0.524796
  validation accuracy:		92.93 %
Epoch 1967 of 2000 took 0.035s
  training loss:		0.003057
  validation loss:		0.526628
  validation accuracy:		92.83 %
Epoch 1968 of 2000 took 0.035s
  training loss:		0.003253
  validation loss:		0.530530
  validation accuracy:		92.72 %
Epoch 1969 of 2000 took 0.035s
  training loss:		0.003329
  validation loss:		0.528655
  validation accuracy:		92.83 %
Epoch 1970 of 2000 took 0.035s
  training loss:		0.003364
  validation loss:		0.526411
  validation accuracy:		92.93 %
Epoch 1971 of 2000 took 0.035s
  training loss:		0.003249
  validation loss:		0.529194
  validation accuracy:		92.83 %
Epoch 1972 of 2000 took 0.035s
  training loss:		0.003292
  validation loss:		0.530125
  validation accuracy:		92.83 %
Epoch 1973 of 2000 took 0.035s
  training loss:		0.003294
  validation loss:		0.526338
  validation accuracy:		92.93 %
Epoch 1974 of 2000 took 0.035s
  training loss:		0.003221
  validation loss:		0.530549
  validation accuracy:		92.72 %
Epoch 1975 of 2000 took 0.035s
  training loss:		0.003180
  validation loss:		0.528304
  validation accuracy:		92.83 %
Epoch 1976 of 2000 took 0.035s
  training loss:		0.003289
  validation loss:		0.529727
  validation accuracy:		92.83 %
Epoch 1977 of 2000 took 0.035s
  training loss:		0.003151
  validation loss:		0.527780
  validation accuracy:		92.83 %
Epoch 1978 of 2000 took 0.035s
  training loss:		0.003261
  validation loss:		0.532543
  validation accuracy:		92.61 %
Epoch 1979 of 2000 took 0.035s
  training loss:		0.003230
  validation loss:		0.528772
  validation accuracy:		92.93 %
Epoch 1980 of 2000 took 0.035s
  training loss:		0.003200
  validation loss:		0.523519
  validation accuracy:		92.93 %
Epoch 1981 of 2000 took 0.035s
  training loss:		0.003164
  validation loss:		0.530137
  validation accuracy:		92.61 %
Epoch 1982 of 2000 took 0.035s
  training loss:		0.003165
  validation loss:		0.529984
  validation accuracy:		92.83 %
Epoch 1983 of 2000 took 0.035s
  training loss:		0.003185
  validation loss:		0.528925
  validation accuracy:		92.83 %
Epoch 1984 of 2000 took 0.035s
  training loss:		0.003207
  validation loss:		0.535769
  validation accuracy:		92.61 %
Epoch 1985 of 2000 took 0.035s
  training loss:		0.003277
  validation loss:		0.526403
  validation accuracy:		92.83 %
Epoch 1986 of 2000 took 0.035s
  training loss:		0.003110
  validation loss:		0.528051
  validation accuracy:		92.83 %
Epoch 1987 of 2000 took 0.035s
  training loss:		0.003174
  validation loss:		0.532150
  validation accuracy:		92.93 %
Epoch 1988 of 2000 took 0.035s
  training loss:		0.003192
  validation loss:		0.532895
  validation accuracy:		92.83 %
Epoch 1989 of 2000 took 0.035s
  training loss:		0.003166
  validation loss:		0.533690
  validation accuracy:		92.72 %
Epoch 1990 of 2000 took 0.035s
  training loss:		0.003230
  validation loss:		0.534603
  validation accuracy:		92.83 %
Epoch 1991 of 2000 took 0.035s
  training loss:		0.003176
  validation loss:		0.529720
  validation accuracy:		92.83 %
Epoch 1992 of 2000 took 0.035s
  training loss:		0.003201
  validation loss:		0.533700
  validation accuracy:		92.72 %
Epoch 1993 of 2000 took 0.035s
  training loss:		0.003215
  validation loss:		0.533283
  validation accuracy:		92.72 %
Epoch 1994 of 2000 took 0.035s
  training loss:		0.003119
  validation loss:		0.528238
  validation accuracy:		92.93 %
Epoch 1995 of 2000 took 0.035s
  training loss:		0.003135
  validation loss:		0.531938
  validation accuracy:		92.93 %
Epoch 1996 of 2000 took 0.035s
  training loss:		0.003198
  validation loss:		0.532478
  validation accuracy:		92.83 %
Epoch 1997 of 2000 took 0.035s
  training loss:		0.003126
  validation loss:		0.528761
  validation accuracy:		92.83 %
Epoch 1998 of 2000 took 0.035s
  training loss:		0.003218
  validation loss:		0.529963
  validation accuracy:		92.93 %
Epoch 1999 of 2000 took 0.035s
  training loss:		0.003141
  validation loss:		0.532528
  validation accuracy:		92.83 %
Epoch 2000 of 2000 took 0.035s
  training loss:		0.003089
  validation loss:		0.532631
  validation accuracy:		92.83 %
Final results:
  test loss:			1.267643
  test accuracy:		84.32 %
