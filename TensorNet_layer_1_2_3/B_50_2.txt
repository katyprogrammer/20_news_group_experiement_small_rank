Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 200),b=(200,)
w=(200, 200),b=(200,)
w=(200, 200),b=(200,)
decomposing tensor W of shape (3, 200, 200)...
decomposing tensor B of shape (3, 200)...
Starting training...
Epoch 1 of 2000 took 0.038s
  training loss:		2.937379
  validation loss:		2.057557
  validation accuracy:		33.70 %
Epoch 2 of 2000 took 0.035s
  training loss:		1.852207
  validation loss:		1.510565
  validation accuracy:		52.17 %
Epoch 3 of 2000 took 0.035s
  training loss:		1.504441
  validation loss:		1.339854
  validation accuracy:		55.33 %
Epoch 4 of 2000 took 0.035s
  training loss:		1.375334
  validation loss:		1.234840
  validation accuracy:		59.24 %
Epoch 5 of 2000 took 0.035s
  training loss:		1.289697
  validation loss:		1.159455
  validation accuracy:		61.09 %
Epoch 6 of 2000 took 0.035s
  training loss:		1.216161
  validation loss:		1.097027
  validation accuracy:		63.80 %
Epoch 7 of 2000 took 0.035s
  training loss:		1.148493
  validation loss:		1.056400
  validation accuracy:		65.33 %
Epoch 8 of 2000 took 0.035s
  training loss:		1.095783
  validation loss:		0.997253
  validation accuracy:		66.63 %
Epoch 9 of 2000 took 0.035s
  training loss:		1.041994
  validation loss:		0.943696
  validation accuracy:		68.37 %
Epoch 10 of 2000 took 0.035s
  training loss:		0.995066
  validation loss:		0.902772
  validation accuracy:		69.35 %
Epoch 11 of 2000 took 0.035s
  training loss:		0.957297
  validation loss:		0.861725
  validation accuracy:		71.09 %
Epoch 12 of 2000 took 0.035s
  training loss:		0.902541
  validation loss:		0.829042
  validation accuracy:		72.28 %
Epoch 13 of 2000 took 0.035s
  training loss:		0.867359
  validation loss:		0.784383
  validation accuracy:		73.91 %
Epoch 14 of 2000 took 0.035s
  training loss:		0.835779
  validation loss:		0.777940
  validation accuracy:		74.46 %
Epoch 15 of 2000 took 0.035s
  training loss:		0.802142
  validation loss:		0.741541
  validation accuracy:		76.20 %
Epoch 16 of 2000 took 0.035s
  training loss:		0.771694
  validation loss:		0.716105
  validation accuracy:		77.17 %
Epoch 17 of 2000 took 0.035s
  training loss:		0.743930
  validation loss:		0.689671
  validation accuracy:		79.35 %
Epoch 18 of 2000 took 0.035s
  training loss:		0.715977
  validation loss:		0.673820
  validation accuracy:		78.91 %
Epoch 19 of 2000 took 0.035s
  training loss:		0.690049
  validation loss:		0.637826
  validation accuracy:		79.57 %
Epoch 20 of 2000 took 0.035s
  training loss:		0.669089
  validation loss:		0.608362
  validation accuracy:		79.78 %
Epoch 21 of 2000 took 0.035s
  training loss:		0.645323
  validation loss:		0.594888
  validation accuracy:		80.98 %
Epoch 22 of 2000 took 0.035s
  training loss:		0.626934
  validation loss:		0.587571
  validation accuracy:		81.63 %
Epoch 23 of 2000 took 0.035s
  training loss:		0.613658
  validation loss:		0.563427
  validation accuracy:		82.61 %
Epoch 24 of 2000 took 0.036s
  training loss:		0.586759
  validation loss:		0.556672
  validation accuracy:		82.72 %
Epoch 25 of 2000 took 0.035s
  training loss:		0.577111
  validation loss:		0.546601
  validation accuracy:		83.37 %
Epoch 26 of 2000 took 0.035s
  training loss:		0.565714
  validation loss:		0.523717
  validation accuracy:		84.13 %
Epoch 27 of 2000 took 0.035s
  training loss:		0.545150
  validation loss:		0.503391
  validation accuracy:		84.13 %
Epoch 28 of 2000 took 0.035s
  training loss:		0.529098
  validation loss:		0.492914
  validation accuracy:		84.78 %
Epoch 29 of 2000 took 0.035s
  training loss:		0.521459
  validation loss:		0.492407
  validation accuracy:		85.11 %
Epoch 30 of 2000 took 0.035s
  training loss:		0.510323
  validation loss:		0.479173
  validation accuracy:		85.22 %
Epoch 31 of 2000 took 0.035s
  training loss:		0.501397
  validation loss:		0.471079
  validation accuracy:		86.52 %
Epoch 32 of 2000 took 0.035s
  training loss:		0.482510
  validation loss:		0.464103
  validation accuracy:		86.20 %
Epoch 33 of 2000 took 0.035s
  training loss:		0.480649
  validation loss:		0.460937
  validation accuracy:		86.20 %
Epoch 34 of 2000 took 0.035s
  training loss:		0.469647
  validation loss:		0.443323
  validation accuracy:		87.17 %
Epoch 35 of 2000 took 0.035s
  training loss:		0.458002
  validation loss:		0.442964
  validation accuracy:		86.74 %
Epoch 36 of 2000 took 0.035s
  training loss:		0.453559
  validation loss:		0.433864
  validation accuracy:		86.74 %
Epoch 37 of 2000 took 0.035s
  training loss:		0.436589
  validation loss:		0.432401
  validation accuracy:		87.28 %
Epoch 38 of 2000 took 0.035s
  training loss:		0.441278
  validation loss:		0.430202
  validation accuracy:		86.96 %
Epoch 39 of 2000 took 0.035s
  training loss:		0.427485
  validation loss:		0.415394
  validation accuracy:		87.17 %
Epoch 40 of 2000 took 0.035s
  training loss:		0.421290
  validation loss:		0.408732
  validation accuracy:		88.15 %
Epoch 41 of 2000 took 0.035s
  training loss:		0.407320
  validation loss:		0.409104
  validation accuracy:		88.15 %
Epoch 42 of 2000 took 0.036s
  training loss:		0.408778
  validation loss:		0.404548
  validation accuracy:		87.28 %
Epoch 43 of 2000 took 0.036s
  training loss:		0.407695
  validation loss:		0.385557
  validation accuracy:		88.70 %
Epoch 44 of 2000 took 0.036s
  training loss:		0.398244
  validation loss:		0.387373
  validation accuracy:		88.91 %
Epoch 45 of 2000 took 0.036s
  training loss:		0.389002
  validation loss:		0.380751
  validation accuracy:		89.02 %
Epoch 46 of 2000 took 0.036s
  training loss:		0.388502
  validation loss:		0.396027
  validation accuracy:		88.26 %
Epoch 47 of 2000 took 0.036s
  training loss:		0.375823
  validation loss:		0.380127
  validation accuracy:		88.70 %
Epoch 48 of 2000 took 0.036s
  training loss:		0.376632
  validation loss:		0.384695
  validation accuracy:		88.70 %
Epoch 49 of 2000 took 0.036s
  training loss:		0.372087
  validation loss:		0.371197
  validation accuracy:		89.35 %
Epoch 50 of 2000 took 0.036s
  training loss:		0.371051
  validation loss:		0.374937
  validation accuracy:		88.80 %
Epoch 51 of 2000 took 0.036s
  training loss:		0.368801
  validation loss:		0.371136
  validation accuracy:		89.46 %
Epoch 52 of 2000 took 0.036s
  training loss:		0.363429
  validation loss:		0.362892
  validation accuracy:		89.67 %
Epoch 53 of 2000 took 0.036s
  training loss:		0.356676
  validation loss:		0.358644
  validation accuracy:		89.46 %
Epoch 54 of 2000 took 0.036s
  training loss:		0.350408
  validation loss:		0.348988
  validation accuracy:		89.78 %
Epoch 55 of 2000 took 0.036s
  training loss:		0.343774
  validation loss:		0.348631
  validation accuracy:		89.89 %
Epoch 56 of 2000 took 0.036s
  training loss:		0.341814
  validation loss:		0.351959
  validation accuracy:		89.02 %
Epoch 57 of 2000 took 0.036s
  training loss:		0.339974
  validation loss:		0.343304
  validation accuracy:		90.11 %
Epoch 58 of 2000 took 0.036s
  training loss:		0.341953
  validation loss:		0.340076
  validation accuracy:		90.00 %
Epoch 59 of 2000 took 0.036s
  training loss:		0.333969
  validation loss:		0.341354
  validation accuracy:		89.46 %
Epoch 60 of 2000 took 0.036s
  training loss:		0.330192
  validation loss:		0.347899
  validation accuracy:		89.24 %
Epoch 61 of 2000 took 0.036s
  training loss:		0.326907
  validation loss:		0.342176
  validation accuracy:		89.78 %
Epoch 62 of 2000 took 0.036s
  training loss:		0.321535
  validation loss:		0.325267
  validation accuracy:		90.22 %
Epoch 63 of 2000 took 0.036s
  training loss:		0.311468
  validation loss:		0.348916
  validation accuracy:		89.78 %
Epoch 64 of 2000 took 0.036s
  training loss:		0.319139
  validation loss:		0.340160
  validation accuracy:		90.33 %
Epoch 65 of 2000 took 0.036s
  training loss:		0.310589
  validation loss:		0.342299
  validation accuracy:		90.33 %
Epoch 66 of 2000 took 0.036s
  training loss:		0.305559
  validation loss:		0.329717
  validation accuracy:		90.11 %
Epoch 67 of 2000 took 0.036s
  training loss:		0.305078
  validation loss:		0.314260
  validation accuracy:		91.30 %
Epoch 68 of 2000 took 0.036s
  training loss:		0.303991
  validation loss:		0.334864
  validation accuracy:		90.00 %
Epoch 69 of 2000 took 0.036s
  training loss:		0.301296
  validation loss:		0.323982
  validation accuracy:		90.43 %
Epoch 70 of 2000 took 0.036s
  training loss:		0.304021
  validation loss:		0.323192
  validation accuracy:		90.65 %
Epoch 71 of 2000 took 0.036s
  training loss:		0.291912
  validation loss:		0.314983
  validation accuracy:		90.11 %
Epoch 72 of 2000 took 0.036s
  training loss:		0.296326
  validation loss:		0.317735
  validation accuracy:		90.65 %
Epoch 73 of 2000 took 0.036s
  training loss:		0.289628
  validation loss:		0.312348
  validation accuracy:		90.43 %
Epoch 74 of 2000 took 0.036s
  training loss:		0.290578
  validation loss:		0.312541
  validation accuracy:		90.33 %
Epoch 75 of 2000 took 0.036s
  training loss:		0.288516
  validation loss:		0.310395
  validation accuracy:		90.87 %
Epoch 76 of 2000 took 0.036s
  training loss:		0.285731
  validation loss:		0.304470
  validation accuracy:		91.09 %
Epoch 77 of 2000 took 0.036s
  training loss:		0.281050
  validation loss:		0.314142
  validation accuracy:		90.87 %
Epoch 78 of 2000 took 0.036s
  training loss:		0.280880
  validation loss:		0.310203
  validation accuracy:		90.98 %
Epoch 79 of 2000 took 0.036s
  training loss:		0.281421
  validation loss:		0.312509
  validation accuracy:		90.65 %
Epoch 80 of 2000 took 0.036s
  training loss:		0.272725
  validation loss:		0.306489
  validation accuracy:		91.09 %
Epoch 81 of 2000 took 0.035s
  training loss:		0.272583
  validation loss:		0.300357
  validation accuracy:		91.09 %
Epoch 82 of 2000 took 0.035s
  training loss:		0.270950
  validation loss:		0.303417
  validation accuracy:		91.30 %
Epoch 83 of 2000 took 0.035s
  training loss:		0.270424
  validation loss:		0.304380
  validation accuracy:		90.76 %
Epoch 84 of 2000 took 0.035s
  training loss:		0.271341
  validation loss:		0.305248
  validation accuracy:		90.65 %
Epoch 85 of 2000 took 0.035s
  training loss:		0.261831
  validation loss:		0.302029
  validation accuracy:		90.98 %
Epoch 86 of 2000 took 0.035s
  training loss:		0.268681
  validation loss:		0.302352
  validation accuracy:		91.09 %
Epoch 87 of 2000 took 0.035s
  training loss:		0.269153
  validation loss:		0.300389
  validation accuracy:		91.20 %
Epoch 88 of 2000 took 0.035s
  training loss:		0.266858
  validation loss:		0.306003
  validation accuracy:		90.65 %
Epoch 89 of 2000 took 0.035s
  training loss:		0.259111
  validation loss:		0.289535
  validation accuracy:		91.41 %
Epoch 90 of 2000 took 0.035s
  training loss:		0.253645
  validation loss:		0.289720
  validation accuracy:		91.63 %
Epoch 91 of 2000 took 0.035s
  training loss:		0.257959
  validation loss:		0.286971
  validation accuracy:		91.41 %
Epoch 92 of 2000 took 0.035s
  training loss:		0.255614
  validation loss:		0.309346
  validation accuracy:		90.54 %
Epoch 93 of 2000 took 0.035s
  training loss:		0.256533
  validation loss:		0.297026
  validation accuracy:		91.20 %
Epoch 94 of 2000 took 0.035s
  training loss:		0.248566
  validation loss:		0.289687
  validation accuracy:		91.41 %
Epoch 95 of 2000 took 0.035s
  training loss:		0.253205
  validation loss:		0.285053
  validation accuracy:		91.30 %
Epoch 96 of 2000 took 0.035s
  training loss:		0.246829
  validation loss:		0.296196
  validation accuracy:		90.87 %
Epoch 97 of 2000 took 0.035s
  training loss:		0.252001
  validation loss:		0.286122
  validation accuracy:		91.41 %
Epoch 98 of 2000 took 0.035s
  training loss:		0.242938
  validation loss:		0.294275
  validation accuracy:		90.98 %
Epoch 99 of 2000 took 0.035s
  training loss:		0.249342
  validation loss:		0.284875
  validation accuracy:		91.41 %
Epoch 100 of 2000 took 0.035s
  training loss:		0.244718
  validation loss:		0.297198
  validation accuracy:		90.87 %
Epoch 101 of 2000 took 0.035s
  training loss:		0.239779
  validation loss:		0.277455
  validation accuracy:		91.85 %
Epoch 102 of 2000 took 0.035s
  training loss:		0.236905
  validation loss:		0.283985
  validation accuracy:		91.09 %
Epoch 103 of 2000 took 0.035s
  training loss:		0.236082
  validation loss:		0.284706
  validation accuracy:		91.52 %
Epoch 104 of 2000 took 0.035s
  training loss:		0.235440
  validation loss:		0.290869
  validation accuracy:		91.20 %
Epoch 105 of 2000 took 0.035s
  training loss:		0.230880
  validation loss:		0.277934
  validation accuracy:		91.96 %
Epoch 106 of 2000 took 0.035s
  training loss:		0.234225
  validation loss:		0.285493
  validation accuracy:		91.41 %
Epoch 107 of 2000 took 0.035s
  training loss:		0.233554
  validation loss:		0.280321
  validation accuracy:		91.52 %
Epoch 108 of 2000 took 0.035s
  training loss:		0.234902
  validation loss:		0.275382
  validation accuracy:		92.07 %
Epoch 109 of 2000 took 0.035s
  training loss:		0.227473
  validation loss:		0.275939
  validation accuracy:		91.63 %
Epoch 110 of 2000 took 0.035s
  training loss:		0.226250
  validation loss:		0.272173
  validation accuracy:		91.74 %
Epoch 111 of 2000 took 0.035s
  training loss:		0.227662
  validation loss:		0.283537
  validation accuracy:		91.09 %
Epoch 112 of 2000 took 0.035s
  training loss:		0.226704
  validation loss:		0.278909
  validation accuracy:		91.63 %
Epoch 113 of 2000 took 0.035s
  training loss:		0.227240
  validation loss:		0.275553
  validation accuracy:		91.52 %
Epoch 114 of 2000 took 0.035s
  training loss:		0.225360
  validation loss:		0.281991
  validation accuracy:		91.41 %
Epoch 115 of 2000 took 0.035s
  training loss:		0.223234
  validation loss:		0.271387
  validation accuracy:		92.07 %
Epoch 116 of 2000 took 0.035s
  training loss:		0.225726
  validation loss:		0.276390
  validation accuracy:		91.85 %
Epoch 117 of 2000 took 0.035s
  training loss:		0.221386
  validation loss:		0.273492
  validation accuracy:		91.63 %
Epoch 118 of 2000 took 0.035s
  training loss:		0.214849
  validation loss:		0.262871
  validation accuracy:		92.07 %
Epoch 119 of 2000 took 0.035s
  training loss:		0.212258
  validation loss:		0.283821
  validation accuracy:		91.09 %
Epoch 120 of 2000 took 0.035s
  training loss:		0.216197
  validation loss:		0.271552
  validation accuracy:		91.85 %
Epoch 121 of 2000 took 0.035s
  training loss:		0.211457
  validation loss:		0.266743
  validation accuracy:		92.07 %
Epoch 122 of 2000 took 0.035s
  training loss:		0.213723
  validation loss:		0.275522
  validation accuracy:		91.63 %
Epoch 123 of 2000 took 0.035s
  training loss:		0.212673
  validation loss:		0.277950
  validation accuracy:		91.41 %
Epoch 124 of 2000 took 0.035s
  training loss:		0.215268
  validation loss:		0.262275
  validation accuracy:		92.17 %
Epoch 125 of 2000 took 0.035s
  training loss:		0.210572
  validation loss:		0.274913
  validation accuracy:		91.74 %
Epoch 126 of 2000 took 0.035s
  training loss:		0.202179
  validation loss:		0.268461
  validation accuracy:		92.17 %
Epoch 127 of 2000 took 0.035s
  training loss:		0.206245
  validation loss:		0.273338
  validation accuracy:		91.09 %
Epoch 128 of 2000 took 0.035s
  training loss:		0.209252
  validation loss:		0.278283
  validation accuracy:		91.09 %
Epoch 129 of 2000 took 0.035s
  training loss:		0.208901
  validation loss:		0.272399
  validation accuracy:		91.41 %
Epoch 130 of 2000 took 0.035s
  training loss:		0.207786
  validation loss:		0.267502
  validation accuracy:		91.96 %
Epoch 131 of 2000 took 0.035s
  training loss:		0.202776
  validation loss:		0.270473
  validation accuracy:		91.41 %
Epoch 132 of 2000 took 0.035s
  training loss:		0.200182
  validation loss:		0.258212
  validation accuracy:		92.50 %
Epoch 133 of 2000 took 0.035s
  training loss:		0.201974
  validation loss:		0.263290
  validation accuracy:		92.07 %
Epoch 134 of 2000 took 0.035s
  training loss:		0.197814
  validation loss:		0.265878
  validation accuracy:		92.17 %
Epoch 135 of 2000 took 0.035s
  training loss:		0.196793
  validation loss:		0.265327
  validation accuracy:		91.96 %
Epoch 136 of 2000 took 0.035s
  training loss:		0.193998
  validation loss:		0.263356
  validation accuracy:		92.07 %
Epoch 137 of 2000 took 0.035s
  training loss:		0.195949
  validation loss:		0.263347
  validation accuracy:		91.85 %
Epoch 138 of 2000 took 0.035s
  training loss:		0.199721
  validation loss:		0.258719
  validation accuracy:		92.39 %
Epoch 139 of 2000 took 0.035s
  training loss:		0.192069
  validation loss:		0.265908
  validation accuracy:		91.63 %
Epoch 140 of 2000 took 0.035s
  training loss:		0.188995
  validation loss:		0.274605
  validation accuracy:		91.41 %
Epoch 141 of 2000 took 0.035s
  training loss:		0.193086
  validation loss:		0.265693
  validation accuracy:		91.96 %
Epoch 142 of 2000 took 0.035s
  training loss:		0.197486
  validation loss:		0.253328
  validation accuracy:		92.50 %
Epoch 143 of 2000 took 0.035s
  training loss:		0.191865
  validation loss:		0.274655
  validation accuracy:		91.30 %
Epoch 144 of 2000 took 0.035s
  training loss:		0.190375
  validation loss:		0.258060
  validation accuracy:		91.96 %
Epoch 145 of 2000 took 0.035s
  training loss:		0.191485
  validation loss:		0.259212
  validation accuracy:		92.28 %
Epoch 146 of 2000 took 0.035s
  training loss:		0.189683
  validation loss:		0.269487
  validation accuracy:		91.52 %
Epoch 147 of 2000 took 0.035s
  training loss:		0.188190
  validation loss:		0.261449
  validation accuracy:		91.74 %
Epoch 148 of 2000 took 0.035s
  training loss:		0.189331
  validation loss:		0.252944
  validation accuracy:		92.39 %
Epoch 149 of 2000 took 0.035s
  training loss:		0.185589
  validation loss:		0.255467
  validation accuracy:		92.39 %
Epoch 150 of 2000 took 0.036s
  training loss:		0.188051
  validation loss:		0.279897
  validation accuracy:		91.74 %
Epoch 151 of 2000 took 0.035s
  training loss:		0.185082
  validation loss:		0.261956
  validation accuracy:		91.85 %
Epoch 152 of 2000 took 0.035s
  training loss:		0.181134
  validation loss:		0.274315
  validation accuracy:		91.09 %
Epoch 153 of 2000 took 0.035s
  training loss:		0.187654
  validation loss:		0.255742
  validation accuracy:		92.17 %
Epoch 154 of 2000 took 0.035s
  training loss:		0.180634
  validation loss:		0.255877
  validation accuracy:		92.28 %
Epoch 155 of 2000 took 0.035s
  training loss:		0.175554
  validation loss:		0.255181
  validation accuracy:		92.17 %
Epoch 156 of 2000 took 0.035s
  training loss:		0.177808
  validation loss:		0.264732
  validation accuracy:		91.74 %
Epoch 157 of 2000 took 0.035s
  training loss:		0.180056
  validation loss:		0.252109
  validation accuracy:		92.61 %
Epoch 158 of 2000 took 0.035s
  training loss:		0.178327
  validation loss:		0.258957
  validation accuracy:		92.17 %
Epoch 159 of 2000 took 0.035s
  training loss:		0.174916
  validation loss:		0.256296
  validation accuracy:		92.39 %
Epoch 160 of 2000 took 0.035s
  training loss:		0.177320
  validation loss:		0.261456
  validation accuracy:		91.85 %
Epoch 161 of 2000 took 0.035s
  training loss:		0.173421
  validation loss:		0.258136
  validation accuracy:		92.39 %
Epoch 162 of 2000 took 0.035s
  training loss:		0.176861
  validation loss:		0.254225
  validation accuracy:		92.39 %
Epoch 163 of 2000 took 0.035s
  training loss:		0.169915
  validation loss:		0.263889
  validation accuracy:		91.96 %
Epoch 164 of 2000 took 0.035s
  training loss:		0.172030
  validation loss:		0.252485
  validation accuracy:		92.72 %
Epoch 165 of 2000 took 0.035s
  training loss:		0.174061
  validation loss:		0.259961
  validation accuracy:		91.85 %
Epoch 166 of 2000 took 0.035s
  training loss:		0.169792
  validation loss:		0.264397
  validation accuracy:		92.07 %
Epoch 167 of 2000 took 0.035s
  training loss:		0.169572
  validation loss:		0.249088
  validation accuracy:		92.50 %
Epoch 168 of 2000 took 0.035s
  training loss:		0.171172
  validation loss:		0.268475
  validation accuracy:		91.85 %
Epoch 169 of 2000 took 0.035s
  training loss:		0.166733
  validation loss:		0.259988
  validation accuracy:		91.96 %
Epoch 170 of 2000 took 0.035s
  training loss:		0.169499
  validation loss:		0.254761
  validation accuracy:		92.28 %
Epoch 171 of 2000 took 0.035s
  training loss:		0.168776
  validation loss:		0.250116
  validation accuracy:		92.61 %
Epoch 172 of 2000 took 0.035s
  training loss:		0.170823
  validation loss:		0.260471
  validation accuracy:		92.28 %
Epoch 173 of 2000 took 0.035s
  training loss:		0.163949
  validation loss:		0.266171
  validation accuracy:		91.85 %
Epoch 174 of 2000 took 0.035s
  training loss:		0.160933
  validation loss:		0.255999
  validation accuracy:		91.96 %
Epoch 175 of 2000 took 0.035s
  training loss:		0.167507
  validation loss:		0.263788
  validation accuracy:		91.74 %
Epoch 176 of 2000 took 0.035s
  training loss:		0.164253
  validation loss:		0.249723
  validation accuracy:		92.50 %
Epoch 177 of 2000 took 0.035s
  training loss:		0.163045
  validation loss:		0.261900
  validation accuracy:		91.85 %
Epoch 178 of 2000 took 0.035s
  training loss:		0.158916
  validation loss:		0.262377
  validation accuracy:		92.07 %
Epoch 179 of 2000 took 0.035s
  training loss:		0.160763
  validation loss:		0.252964
  validation accuracy:		92.61 %
Epoch 180 of 2000 took 0.035s
  training loss:		0.162398
  validation loss:		0.251530
  validation accuracy:		92.72 %
Epoch 181 of 2000 took 0.035s
  training loss:		0.160292
  validation loss:		0.260431
  validation accuracy:		91.96 %
Epoch 182 of 2000 took 0.035s
  training loss:		0.160931
  validation loss:		0.256860
  validation accuracy:		92.50 %
Epoch 183 of 2000 took 0.035s
  training loss:		0.159226
  validation loss:		0.251529
  validation accuracy:		92.50 %
Epoch 184 of 2000 took 0.035s
  training loss:		0.161456
  validation loss:		0.255968
  validation accuracy:		92.39 %
Epoch 185 of 2000 took 0.035s
  training loss:		0.160272
  validation loss:		0.265866
  validation accuracy:		91.74 %
Epoch 186 of 2000 took 0.035s
  training loss:		0.152299
  validation loss:		0.243197
  validation accuracy:		93.04 %
Epoch 187 of 2000 took 0.035s
  training loss:		0.156581
  validation loss:		0.271490
  validation accuracy:		91.41 %
Epoch 188 of 2000 took 0.035s
  training loss:		0.157099
  validation loss:		0.253629
  validation accuracy:		92.72 %
Epoch 189 of 2000 took 0.035s
  training loss:		0.151862
  validation loss:		0.254582
  validation accuracy:		92.83 %
Epoch 190 of 2000 took 0.035s
  training loss:		0.158402
  validation loss:		0.254407
  validation accuracy:		92.50 %
Epoch 191 of 2000 took 0.035s
  training loss:		0.154176
  validation loss:		0.249188
  validation accuracy:		92.39 %
Epoch 192 of 2000 took 0.035s
  training loss:		0.153559
  validation loss:		0.253670
  validation accuracy:		92.07 %
Epoch 193 of 2000 took 0.035s
  training loss:		0.153498
  validation loss:		0.261005
  validation accuracy:		92.07 %
Epoch 194 of 2000 took 0.035s
  training loss:		0.155498
  validation loss:		0.250261
  validation accuracy:		92.93 %
Epoch 195 of 2000 took 0.035s
  training loss:		0.151702
  validation loss:		0.253468
  validation accuracy:		92.17 %
Epoch 196 of 2000 took 0.035s
  training loss:		0.147599
  validation loss:		0.264174
  validation accuracy:		91.96 %
Epoch 197 of 2000 took 0.035s
  training loss:		0.146912
  validation loss:		0.249070
  validation accuracy:		92.61 %
Epoch 198 of 2000 took 0.035s
  training loss:		0.144892
  validation loss:		0.249542
  validation accuracy:		92.72 %
Epoch 199 of 2000 took 0.035s
  training loss:		0.152757
  validation loss:		0.243266
  validation accuracy:		92.83 %
Epoch 200 of 2000 took 0.035s
  training loss:		0.152243
  validation loss:		0.256974
  validation accuracy:		91.74 %
Epoch 201 of 2000 took 0.035s
  training loss:		0.146818
  validation loss:		0.265643
  validation accuracy:		91.74 %
Epoch 202 of 2000 took 0.035s
  training loss:		0.148170
  validation loss:		0.250009
  validation accuracy:		92.72 %
Epoch 203 of 2000 took 0.035s
  training loss:		0.147768
  validation loss:		0.246103
  validation accuracy:		92.61 %
Epoch 204 of 2000 took 0.035s
  training loss:		0.146409
  validation loss:		0.250658
  validation accuracy:		92.61 %
Epoch 205 of 2000 took 0.035s
  training loss:		0.144086
  validation loss:		0.274135
  validation accuracy:		91.52 %
Epoch 206 of 2000 took 0.035s
  training loss:		0.145362
  validation loss:		0.246089
  validation accuracy:		93.15 %
Epoch 207 of 2000 took 0.035s
  training loss:		0.145950
  validation loss:		0.247649
  validation accuracy:		93.04 %
Epoch 208 of 2000 took 0.035s
  training loss:		0.142985
  validation loss:		0.264822
  validation accuracy:		92.28 %
Epoch 209 of 2000 took 0.035s
  training loss:		0.146434
  validation loss:		0.256794
  validation accuracy:		92.72 %
Epoch 210 of 2000 took 0.035s
  training loss:		0.139440
  validation loss:		0.256996
  validation accuracy:		91.85 %
Epoch 211 of 2000 took 0.035s
  training loss:		0.143643
  validation loss:		0.249555
  validation accuracy:		92.83 %
Epoch 212 of 2000 took 0.035s
  training loss:		0.140468
  validation loss:		0.262745
  validation accuracy:		91.52 %
Epoch 213 of 2000 took 0.035s
  training loss:		0.140112
  validation loss:		0.248747
  validation accuracy:		92.61 %
Epoch 214 of 2000 took 0.035s
  training loss:		0.144885
  validation loss:		0.252285
  validation accuracy:		92.83 %
Epoch 215 of 2000 took 0.035s
  training loss:		0.142086
  validation loss:		0.260498
  validation accuracy:		91.96 %
Epoch 216 of 2000 took 0.035s
  training loss:		0.143076
  validation loss:		0.252423
  validation accuracy:		92.07 %
Epoch 217 of 2000 took 0.035s
  training loss:		0.138704
  validation loss:		0.246684
  validation accuracy:		92.83 %
Epoch 218 of 2000 took 0.035s
  training loss:		0.137727
  validation loss:		0.247204
  validation accuracy:		93.26 %
Epoch 219 of 2000 took 0.035s
  training loss:		0.141566
  validation loss:		0.259805
  validation accuracy:		91.96 %
Epoch 220 of 2000 took 0.035s
  training loss:		0.137934
  validation loss:		0.244192
  validation accuracy:		92.61 %
Epoch 221 of 2000 took 0.035s
  training loss:		0.138068
  validation loss:		0.263887
  validation accuracy:		91.52 %
Epoch 222 of 2000 took 0.035s
  training loss:		0.137195
  validation loss:		0.254686
  validation accuracy:		92.72 %
Epoch 223 of 2000 took 0.035s
  training loss:		0.138336
  validation loss:		0.253658
  validation accuracy:		92.39 %
Epoch 224 of 2000 took 0.035s
  training loss:		0.134067
  validation loss:		0.254476
  validation accuracy:		92.72 %
Epoch 225 of 2000 took 0.035s
  training loss:		0.134018
  validation loss:		0.250547
  validation accuracy:		92.61 %
Epoch 226 of 2000 took 0.035s
  training loss:		0.134467
  validation loss:		0.256775
  validation accuracy:		92.83 %
Epoch 227 of 2000 took 0.035s
  training loss:		0.134561
  validation loss:		0.247647
  validation accuracy:		92.61 %
Epoch 228 of 2000 took 0.035s
  training loss:		0.131985
  validation loss:		0.250867
  validation accuracy:		92.72 %
Epoch 229 of 2000 took 0.035s
  training loss:		0.135460
  validation loss:		0.252176
  validation accuracy:		93.04 %
Epoch 230 of 2000 took 0.035s
  training loss:		0.131620
  validation loss:		0.252884
  validation accuracy:		92.28 %
Epoch 231 of 2000 took 0.035s
  training loss:		0.130861
  validation loss:		0.262918
  validation accuracy:		91.96 %
Epoch 232 of 2000 took 0.038s
  training loss:		0.131881
  validation loss:		0.252891
  validation accuracy:		92.28 %
Epoch 233 of 2000 took 0.036s
  training loss:		0.133414
  validation loss:		0.253100
  validation accuracy:		92.50 %
Epoch 234 of 2000 took 0.035s
  training loss:		0.128996
  validation loss:		0.251966
  validation accuracy:		92.83 %
Epoch 235 of 2000 took 0.035s
  training loss:		0.129314
  validation loss:		0.268532
  validation accuracy:		91.74 %
Epoch 236 of 2000 took 0.035s
  training loss:		0.128332
  validation loss:		0.247877
  validation accuracy:		92.83 %
Epoch 237 of 2000 took 0.035s
  training loss:		0.131601
  validation loss:		0.253350
  validation accuracy:		92.28 %
Epoch 238 of 2000 took 0.035s
  training loss:		0.130090
  validation loss:		0.260012
  validation accuracy:		91.96 %
Epoch 239 of 2000 took 0.035s
  training loss:		0.129452
  validation loss:		0.259711
  validation accuracy:		92.17 %
Epoch 240 of 2000 took 0.035s
  training loss:		0.130856
  validation loss:		0.243921
  validation accuracy:		92.61 %
Epoch 241 of 2000 took 0.035s
  training loss:		0.125348
  validation loss:		0.258413
  validation accuracy:		92.17 %
Epoch 242 of 2000 took 0.035s
  training loss:		0.127081
  validation loss:		0.251079
  validation accuracy:		92.50 %
Epoch 243 of 2000 took 0.035s
  training loss:		0.126651
  validation loss:		0.260040
  validation accuracy:		91.85 %
Epoch 244 of 2000 took 0.035s
  training loss:		0.122934
  validation loss:		0.249519
  validation accuracy:		93.15 %
Epoch 245 of 2000 took 0.035s
  training loss:		0.127371
  validation loss:		0.258063
  validation accuracy:		91.96 %
Epoch 246 of 2000 took 0.035s
  training loss:		0.121829
  validation loss:		0.256609
  validation accuracy:		92.50 %
Epoch 247 of 2000 took 0.035s
  training loss:		0.124652
  validation loss:		0.249674
  validation accuracy:		93.04 %
Epoch 248 of 2000 took 0.035s
  training loss:		0.122027
  validation loss:		0.256102
  validation accuracy:		92.28 %
Epoch 249 of 2000 took 0.035s
  training loss:		0.122516
  validation loss:		0.261018
  validation accuracy:		91.85 %
Epoch 250 of 2000 took 0.035s
  training loss:		0.124467
  validation loss:		0.249637
  validation accuracy:		93.04 %
Epoch 251 of 2000 took 0.035s
  training loss:		0.127896
  validation loss:		0.252510
  validation accuracy:		92.61 %
Epoch 252 of 2000 took 0.035s
  training loss:		0.124211
  validation loss:		0.250267
  validation accuracy:		93.04 %
Epoch 253 of 2000 took 0.035s
  training loss:		0.119009
  validation loss:		0.250215
  validation accuracy:		93.15 %
Epoch 254 of 2000 took 0.035s
  training loss:		0.117935
  validation loss:		0.254128
  validation accuracy:		93.04 %
Epoch 255 of 2000 took 0.035s
  training loss:		0.123887
  validation loss:		0.250965
  validation accuracy:		92.61 %
Epoch 256 of 2000 took 0.035s
  training loss:		0.122731
  validation loss:		0.258466
  validation accuracy:		91.96 %
Epoch 257 of 2000 took 0.035s
  training loss:		0.121025
  validation loss:		0.248822
  validation accuracy:		92.72 %
Epoch 258 of 2000 took 0.035s
  training loss:		0.122053
  validation loss:		0.268348
  validation accuracy:		91.96 %
Epoch 259 of 2000 took 0.035s
  training loss:		0.120789
  validation loss:		0.249343
  validation accuracy:		93.26 %
Epoch 260 of 2000 took 0.035s
  training loss:		0.117261
  validation loss:		0.260107
  validation accuracy:		92.50 %
Epoch 261 of 2000 took 0.035s
  training loss:		0.116002
  validation loss:		0.253158
  validation accuracy:		92.72 %
Epoch 262 of 2000 took 0.035s
  training loss:		0.117262
  validation loss:		0.251019
  validation accuracy:		93.37 %
Epoch 263 of 2000 took 0.035s
  training loss:		0.118541
  validation loss:		0.255000
  validation accuracy:		92.61 %
Epoch 264 of 2000 took 0.035s
  training loss:		0.120663
  validation loss:		0.255614
  validation accuracy:		92.50 %
Epoch 265 of 2000 took 0.035s
  training loss:		0.119452
  validation loss:		0.261842
  validation accuracy:		92.17 %
Epoch 266 of 2000 took 0.035s
  training loss:		0.117168
  validation loss:		0.260266
  validation accuracy:		92.39 %
Epoch 267 of 2000 took 0.035s
  training loss:		0.118927
  validation loss:		0.246327
  validation accuracy:		92.83 %
Epoch 268 of 2000 took 0.035s
  training loss:		0.114680
  validation loss:		0.258565
  validation accuracy:		92.61 %
Epoch 269 of 2000 took 0.035s
  training loss:		0.113980
  validation loss:		0.248128
  validation accuracy:		92.83 %
Epoch 270 of 2000 took 0.035s
  training loss:		0.116358
  validation loss:		0.265306
  validation accuracy:		92.07 %
Epoch 271 of 2000 took 0.035s
  training loss:		0.111819
  validation loss:		0.251395
  validation accuracy:		93.04 %
Epoch 272 of 2000 took 0.035s
  training loss:		0.117128
  validation loss:		0.247536
  validation accuracy:		92.72 %
Epoch 273 of 2000 took 0.035s
  training loss:		0.113850
  validation loss:		0.255200
  validation accuracy:		92.50 %
Epoch 274 of 2000 took 0.035s
  training loss:		0.111069
  validation loss:		0.263348
  validation accuracy:		92.39 %
Epoch 275 of 2000 took 0.035s
  training loss:		0.111888
  validation loss:		0.256427
  validation accuracy:		92.83 %
Epoch 276 of 2000 took 0.035s
  training loss:		0.112785
  validation loss:		0.262098
  validation accuracy:		92.50 %
Epoch 277 of 2000 took 0.035s
  training loss:		0.107280
  validation loss:		0.256769
  validation accuracy:		92.39 %
Epoch 278 of 2000 took 0.035s
  training loss:		0.112970
  validation loss:		0.254223
  validation accuracy:		92.83 %
Epoch 279 of 2000 took 0.035s
  training loss:		0.112339
  validation loss:		0.258877
  validation accuracy:		92.61 %
Epoch 280 of 2000 took 0.035s
  training loss:		0.113373
  validation loss:		0.251649
  validation accuracy:		92.93 %
Epoch 281 of 2000 took 0.035s
  training loss:		0.108591
  validation loss:		0.257145
  validation accuracy:		92.61 %
Epoch 282 of 2000 took 0.035s
  training loss:		0.111289
  validation loss:		0.252795
  validation accuracy:		92.72 %
Epoch 283 of 2000 took 0.035s
  training loss:		0.112471
  validation loss:		0.256430
  validation accuracy:		92.72 %
Epoch 284 of 2000 took 0.035s
  training loss:		0.109590
  validation loss:		0.262057
  validation accuracy:		92.50 %
Epoch 285 of 2000 took 0.035s
  training loss:		0.110869
  validation loss:		0.256234
  validation accuracy:		92.39 %
Epoch 286 of 2000 took 0.035s
  training loss:		0.106524
  validation loss:		0.252604
  validation accuracy:		93.26 %
Epoch 287 of 2000 took 0.035s
  training loss:		0.109827
  validation loss:		0.263748
  validation accuracy:		92.17 %
Epoch 288 of 2000 took 0.035s
  training loss:		0.107752
  validation loss:		0.255262
  validation accuracy:		92.39 %
Epoch 289 of 2000 took 0.035s
  training loss:		0.111549
  validation loss:		0.254477
  validation accuracy:		93.15 %
Epoch 290 of 2000 took 0.035s
  training loss:		0.107480
  validation loss:		0.268926
  validation accuracy:		92.50 %
Epoch 291 of 2000 took 0.035s
  training loss:		0.107255
  validation loss:		0.265893
  validation accuracy:		92.72 %
Epoch 292 of 2000 took 0.035s
  training loss:		0.107000
  validation loss:		0.267303
  validation accuracy:		92.50 %
Epoch 293 of 2000 took 0.035s
  training loss:		0.107329
  validation loss:		0.264567
  validation accuracy:		92.50 %
Epoch 294 of 2000 took 0.035s
  training loss:		0.107169
  validation loss:		0.259111
  validation accuracy:		92.93 %
Epoch 295 of 2000 took 0.035s
  training loss:		0.105237
  validation loss:		0.270887
  validation accuracy:		92.17 %
Epoch 296 of 2000 took 0.035s
  training loss:		0.102207
  validation loss:		0.250442
  validation accuracy:		93.04 %
Epoch 297 of 2000 took 0.035s
  training loss:		0.104334
  validation loss:		0.270382
  validation accuracy:		91.96 %
Epoch 298 of 2000 took 0.035s
  training loss:		0.107991
  validation loss:		0.261517
  validation accuracy:		92.61 %
Epoch 299 of 2000 took 0.035s
  training loss:		0.105477
  validation loss:		0.265313
  validation accuracy:		92.72 %
Epoch 300 of 2000 took 0.035s
  training loss:		0.107468
  validation loss:		0.250427
  validation accuracy:		93.26 %
Epoch 301 of 2000 took 0.035s
  training loss:		0.104267
  validation loss:		0.253617
  validation accuracy:		93.37 %
Epoch 302 of 2000 took 0.035s
  training loss:		0.106084
  validation loss:		0.261736
  validation accuracy:		92.61 %
Epoch 303 of 2000 took 0.035s
  training loss:		0.102448
  validation loss:		0.252278
  validation accuracy:		93.26 %
Epoch 304 of 2000 took 0.035s
  training loss:		0.103985
  validation loss:		0.263605
  validation accuracy:		92.39 %
Epoch 305 of 2000 took 0.035s
  training loss:		0.105154
  validation loss:		0.257113
  validation accuracy:		93.26 %
Epoch 306 of 2000 took 0.035s
  training loss:		0.104147
  validation loss:		0.265550
  validation accuracy:		92.61 %
Epoch 307 of 2000 took 0.036s
  training loss:		0.101583
  validation loss:		0.266030
  validation accuracy:		93.26 %
Epoch 308 of 2000 took 0.035s
  training loss:		0.102632
  validation loss:		0.269980
  validation accuracy:		92.50 %
Epoch 309 of 2000 took 0.035s
  training loss:		0.102784
  validation loss:		0.261460
  validation accuracy:		92.93 %
Epoch 310 of 2000 took 0.035s
  training loss:		0.102817
  validation loss:		0.266802
  validation accuracy:		92.61 %
Epoch 311 of 2000 took 0.035s
  training loss:		0.100447
  validation loss:		0.255256
  validation accuracy:		93.15 %
Epoch 312 of 2000 took 0.035s
  training loss:		0.098620
  validation loss:		0.270141
  validation accuracy:		92.50 %
Epoch 313 of 2000 took 0.035s
  training loss:		0.101691
  validation loss:		0.262483
  validation accuracy:		92.83 %
Epoch 314 of 2000 took 0.035s
  training loss:		0.102415
  validation loss:		0.259746
  validation accuracy:		92.83 %
Epoch 315 of 2000 took 0.035s
  training loss:		0.099343
  validation loss:		0.272308
  validation accuracy:		92.61 %
Epoch 316 of 2000 took 0.035s
  training loss:		0.099555
  validation loss:		0.263960
  validation accuracy:		92.83 %
Epoch 317 of 2000 took 0.035s
  training loss:		0.100497
  validation loss:		0.260728
  validation accuracy:		92.93 %
Epoch 318 of 2000 took 0.035s
  training loss:		0.096237
  validation loss:		0.264896
  validation accuracy:		92.93 %
Epoch 319 of 2000 took 0.035s
  training loss:		0.098876
  validation loss:		0.262197
  validation accuracy:		93.04 %
Epoch 320 of 2000 took 0.035s
  training loss:		0.101209
  validation loss:		0.261974
  validation accuracy:		92.83 %
Epoch 321 of 2000 took 0.035s
  training loss:		0.101144
  validation loss:		0.251594
  validation accuracy:		93.26 %
Epoch 322 of 2000 took 0.035s
  training loss:		0.095621
  validation loss:		0.278401
  validation accuracy:		92.72 %
Epoch 323 of 2000 took 0.035s
  training loss:		0.095200
  validation loss:		0.258077
  validation accuracy:		93.15 %
Epoch 324 of 2000 took 0.035s
  training loss:		0.096007
  validation loss:		0.270376
  validation accuracy:		92.39 %
Epoch 325 of 2000 took 0.035s
  training loss:		0.101323
  validation loss:		0.279631
  validation accuracy:		92.17 %
Epoch 326 of 2000 took 0.035s
  training loss:		0.096122
  validation loss:		0.267326
  validation accuracy:		92.83 %
Epoch 327 of 2000 took 0.035s
  training loss:		0.097200
  validation loss:		0.265458
  validation accuracy:		92.72 %
Epoch 328 of 2000 took 0.035s
  training loss:		0.097609
  validation loss:		0.267606
  validation accuracy:		92.93 %
Epoch 329 of 2000 took 0.035s
  training loss:		0.094211
  validation loss:		0.259049
  validation accuracy:		93.26 %
Epoch 330 of 2000 took 0.035s
  training loss:		0.095393
  validation loss:		0.273980
  validation accuracy:		92.83 %
Epoch 331 of 2000 took 0.035s
  training loss:		0.096442
  validation loss:		0.264939
  validation accuracy:		93.04 %
Epoch 332 of 2000 took 0.035s
  training loss:		0.095578
  validation loss:		0.265984
  validation accuracy:		92.39 %
Epoch 333 of 2000 took 0.035s
  training loss:		0.096573
  validation loss:		0.268516
  validation accuracy:		92.83 %
Epoch 334 of 2000 took 0.035s
  training loss:		0.096950
  validation loss:		0.268767
  validation accuracy:		92.72 %
Epoch 335 of 2000 took 0.035s
  training loss:		0.093930
  validation loss:		0.271651
  validation accuracy:		92.39 %
Epoch 336 of 2000 took 0.035s
  training loss:		0.095213
  validation loss:		0.267926
  validation accuracy:		92.83 %
Epoch 337 of 2000 took 0.035s
  training loss:		0.094722
  validation loss:		0.269846
  validation accuracy:		92.93 %
Epoch 338 of 2000 took 0.035s
  training loss:		0.093225
  validation loss:		0.265318
  validation accuracy:		92.72 %
Epoch 339 of 2000 took 0.035s
  training loss:		0.093227
  validation loss:		0.267040
  validation accuracy:		92.93 %
Epoch 340 of 2000 took 0.035s
  training loss:		0.092747
  validation loss:		0.257458
  validation accuracy:		93.04 %
Epoch 341 of 2000 took 0.035s
  training loss:		0.089389
  validation loss:		0.267429
  validation accuracy:		92.83 %
Epoch 342 of 2000 took 0.035s
  training loss:		0.094697
  validation loss:		0.274145
  validation accuracy:		92.39 %
Epoch 343 of 2000 took 0.035s
  training loss:		0.091503
  validation loss:		0.261577
  validation accuracy:		93.15 %
Epoch 344 of 2000 took 0.035s
  training loss:		0.095736
  validation loss:		0.280885
  validation accuracy:		92.61 %
Epoch 345 of 2000 took 0.035s
  training loss:		0.089224
  validation loss:		0.272293
  validation accuracy:		92.61 %
Epoch 346 of 2000 took 0.035s
  training loss:		0.092816
  validation loss:		0.274208
  validation accuracy:		92.93 %
Epoch 347 of 2000 took 0.035s
  training loss:		0.088091
  validation loss:		0.261735
  validation accuracy:		93.15 %
Epoch 348 of 2000 took 0.035s
  training loss:		0.089143
  validation loss:		0.274829
  validation accuracy:		92.72 %
Epoch 349 of 2000 took 0.035s
  training loss:		0.091641
  validation loss:		0.264313
  validation accuracy:		92.83 %
Epoch 350 of 2000 took 0.035s
  training loss:		0.089122
  validation loss:		0.267119
  validation accuracy:		92.72 %
Epoch 351 of 2000 took 0.035s
  training loss:		0.090334
  validation loss:		0.276303
  validation accuracy:		92.61 %
Epoch 352 of 2000 took 0.035s
  training loss:		0.091262
  validation loss:		0.275239
  validation accuracy:		92.61 %
Epoch 353 of 2000 took 0.035s
  training loss:		0.092663
  validation loss:		0.274198
  validation accuracy:		92.50 %
Epoch 354 of 2000 took 0.035s
  training loss:		0.091074
  validation loss:		0.269667
  validation accuracy:		93.04 %
Epoch 355 of 2000 took 0.035s
  training loss:		0.087870
  validation loss:		0.267125
  validation accuracy:		92.72 %
Epoch 356 of 2000 took 0.035s
  training loss:		0.088060
  validation loss:		0.266909
  validation accuracy:		93.15 %
Epoch 357 of 2000 took 0.035s
  training loss:		0.086269
  validation loss:		0.273440
  validation accuracy:		93.04 %
Epoch 358 of 2000 took 0.035s
  training loss:		0.087247
  validation loss:		0.280056
  validation accuracy:		92.61 %
Epoch 359 of 2000 took 0.035s
  training loss:		0.089297
  validation loss:		0.273495
  validation accuracy:		92.83 %
Epoch 360 of 2000 took 0.035s
  training loss:		0.085377
  validation loss:		0.264546
  validation accuracy:		93.15 %
Epoch 361 of 2000 took 0.035s
  training loss:		0.087363
  validation loss:		0.280856
  validation accuracy:		92.61 %
Epoch 362 of 2000 took 0.035s
  training loss:		0.085815
  validation loss:		0.266125
  validation accuracy:		93.15 %
Epoch 363 of 2000 took 0.035s
  training loss:		0.088090
  validation loss:		0.269420
  validation accuracy:		92.83 %
Epoch 364 of 2000 took 0.035s
  training loss:		0.087927
  validation loss:		0.279374
  validation accuracy:		92.28 %
Epoch 365 of 2000 took 0.035s
  training loss:		0.086755
  validation loss:		0.266871
  validation accuracy:		93.04 %
Epoch 366 of 2000 took 0.035s
  training loss:		0.085342
  validation loss:		0.271920
  validation accuracy:		93.04 %
Epoch 367 of 2000 took 0.035s
  training loss:		0.089184
  validation loss:		0.269325
  validation accuracy:		92.61 %
Epoch 368 of 2000 took 0.035s
  training loss:		0.086810
  validation loss:		0.268922
  validation accuracy:		93.04 %
Epoch 369 of 2000 took 0.035s
  training loss:		0.081561
  validation loss:		0.269237
  validation accuracy:		92.72 %
Epoch 370 of 2000 took 0.035s
  training loss:		0.084362
  validation loss:		0.277647
  validation accuracy:		93.04 %
Epoch 371 of 2000 took 0.035s
  training loss:		0.087640
  validation loss:		0.277423
  validation accuracy:		92.61 %
Epoch 372 of 2000 took 0.035s
  training loss:		0.083150
  validation loss:		0.270130
  validation accuracy:		93.15 %
Epoch 373 of 2000 took 0.035s
  training loss:		0.083317
  validation loss:		0.279447
  validation accuracy:		92.83 %
Epoch 374 of 2000 took 0.035s
  training loss:		0.084149
  validation loss:		0.275985
  validation accuracy:		93.04 %
Epoch 375 of 2000 took 0.035s
  training loss:		0.084727
  validation loss:		0.277771
  validation accuracy:		92.72 %
Epoch 376 of 2000 took 0.035s
  training loss:		0.083892
  validation loss:		0.281428
  validation accuracy:		93.04 %
Epoch 377 of 2000 took 0.035s
  training loss:		0.082218
  validation loss:		0.280426
  validation accuracy:		93.04 %
Epoch 378 of 2000 took 0.035s
  training loss:		0.083415
  validation loss:		0.270317
  validation accuracy:		93.26 %
Epoch 379 of 2000 took 0.035s
  training loss:		0.082025
  validation loss:		0.274029
  validation accuracy:		92.93 %
Epoch 380 of 2000 took 0.035s
  training loss:		0.085186
  validation loss:		0.276472
  validation accuracy:		92.83 %
Epoch 381 of 2000 took 0.035s
  training loss:		0.080321
  validation loss:		0.270275
  validation accuracy:		93.15 %
Epoch 382 of 2000 took 0.035s
  training loss:		0.082525
  validation loss:		0.269591
  validation accuracy:		93.04 %
Epoch 383 of 2000 took 0.035s
  training loss:		0.083003
  validation loss:		0.277877
  validation accuracy:		92.93 %
Epoch 384 of 2000 took 0.035s
  training loss:		0.081330
  validation loss:		0.282903
  validation accuracy:		92.72 %
Epoch 385 of 2000 took 0.035s
  training loss:		0.082568
  validation loss:		0.275227
  validation accuracy:		92.83 %
Epoch 386 of 2000 took 0.035s
  training loss:		0.082401
  validation loss:		0.268777
  validation accuracy:		93.26 %
Epoch 387 of 2000 took 0.035s
  training loss:		0.081465
  validation loss:		0.271630
  validation accuracy:		93.04 %
Epoch 388 of 2000 took 0.035s
  training loss:		0.081538
  validation loss:		0.274957
  validation accuracy:		93.04 %
Epoch 389 of 2000 took 0.035s
  training loss:		0.081850
  validation loss:		0.275569
  validation accuracy:		93.15 %
Epoch 390 of 2000 took 0.035s
  training loss:		0.079365
  validation loss:		0.282610
  validation accuracy:		92.72 %
Epoch 391 of 2000 took 0.035s
  training loss:		0.081211
  validation loss:		0.278721
  validation accuracy:		92.72 %
Epoch 392 of 2000 took 0.035s
  training loss:		0.081955
  validation loss:		0.277773
  validation accuracy:		92.93 %
Epoch 393 of 2000 took 0.035s
  training loss:		0.081251
  validation loss:		0.280439
  validation accuracy:		93.04 %
Epoch 394 of 2000 took 0.035s
  training loss:		0.081984
  validation loss:		0.289359
  validation accuracy:		92.61 %
Epoch 395 of 2000 took 0.035s
  training loss:		0.079928
  validation loss:		0.275125
  validation accuracy:		92.83 %
Epoch 396 of 2000 took 0.035s
  training loss:		0.080246
  validation loss:		0.273206
  validation accuracy:		93.15 %
Epoch 397 of 2000 took 0.035s
  training loss:		0.078722
  validation loss:		0.280776
  validation accuracy:		92.93 %
Epoch 398 of 2000 took 0.035s
  training loss:		0.078578
  validation loss:		0.274442
  validation accuracy:		93.15 %
Epoch 399 of 2000 took 0.035s
  training loss:		0.081247
  validation loss:		0.286490
  validation accuracy:		92.61 %
Epoch 400 of 2000 took 0.035s
  training loss:		0.079264
  validation loss:		0.282156
  validation accuracy:		92.72 %
Epoch 401 of 2000 took 0.035s
  training loss:		0.080251
  validation loss:		0.276789
  validation accuracy:		93.04 %
Epoch 402 of 2000 took 0.035s
  training loss:		0.076626
  validation loss:		0.270037
  validation accuracy:		93.37 %
Epoch 403 of 2000 took 0.035s
  training loss:		0.078132
  validation loss:		0.284008
  validation accuracy:		92.93 %
Epoch 404 of 2000 took 0.035s
  training loss:		0.074252
  validation loss:		0.294093
  validation accuracy:		92.61 %
Epoch 405 of 2000 took 0.035s
  training loss:		0.077696
  validation loss:		0.289417
  validation accuracy:		92.83 %
Epoch 406 of 2000 took 0.035s
  training loss:		0.079263
  validation loss:		0.269381
  validation accuracy:		93.37 %
Epoch 407 of 2000 took 0.035s
  training loss:		0.079316
  validation loss:		0.278830
  validation accuracy:		92.83 %
Epoch 408 of 2000 took 0.035s
  training loss:		0.079253
  validation loss:		0.282704
  validation accuracy:		92.93 %
Epoch 409 of 2000 took 0.035s
  training loss:		0.079234
  validation loss:		0.282959
  validation accuracy:		92.83 %
Epoch 410 of 2000 took 0.035s
  training loss:		0.078373
  validation loss:		0.278874
  validation accuracy:		93.04 %
Epoch 411 of 2000 took 0.035s
  training loss:		0.077092
  validation loss:		0.278503
  validation accuracy:		92.93 %
Epoch 412 of 2000 took 0.035s
  training loss:		0.076608
  validation loss:		0.282612
  validation accuracy:		92.93 %
Epoch 413 of 2000 took 0.037s
  training loss:		0.074639
  validation loss:		0.269827
  validation accuracy:		92.93 %
Epoch 414 of 2000 took 0.035s
  training loss:		0.076631
  validation loss:		0.283775
  validation accuracy:		92.72 %
Epoch 415 of 2000 took 0.035s
  training loss:		0.076259
  validation loss:		0.285301
  validation accuracy:		92.93 %
Epoch 416 of 2000 took 0.035s
  training loss:		0.077167
  validation loss:		0.284457
  validation accuracy:		92.93 %
Epoch 417 of 2000 took 0.035s
  training loss:		0.074482
  validation loss:		0.289197
  validation accuracy:		92.72 %
Epoch 418 of 2000 took 0.035s
  training loss:		0.071399
  validation loss:		0.280037
  validation accuracy:		93.26 %
Epoch 419 of 2000 took 0.035s
  training loss:		0.075798
  validation loss:		0.289747
  validation accuracy:		92.72 %
Epoch 420 of 2000 took 0.035s
  training loss:		0.077025
  validation loss:		0.292354
  validation accuracy:		92.50 %
Epoch 421 of 2000 took 0.035s
  training loss:		0.073445
  validation loss:		0.288076
  validation accuracy:		92.93 %
Epoch 422 of 2000 took 0.035s
  training loss:		0.076762
  validation loss:		0.289368
  validation accuracy:		92.72 %
Epoch 423 of 2000 took 0.035s
  training loss:		0.073534
  validation loss:		0.276334
  validation accuracy:		93.04 %
Epoch 424 of 2000 took 0.035s
  training loss:		0.072025
  validation loss:		0.280626
  validation accuracy:		92.83 %
Epoch 425 of 2000 took 0.035s
  training loss:		0.072839
  validation loss:		0.291207
  validation accuracy:		92.61 %
Epoch 426 of 2000 took 0.035s
  training loss:		0.074572
  validation loss:		0.286928
  validation accuracy:		92.93 %
Epoch 427 of 2000 took 0.035s
  training loss:		0.072098
  validation loss:		0.299190
  validation accuracy:		92.50 %
Epoch 428 of 2000 took 0.035s
  training loss:		0.073355
  validation loss:		0.279851
  validation accuracy:		93.15 %
Epoch 429 of 2000 took 0.035s
  training loss:		0.071814
  validation loss:		0.292748
  validation accuracy:		92.93 %
Epoch 430 of 2000 took 0.035s
  training loss:		0.073483
  validation loss:		0.295551
  validation accuracy:		92.83 %
Epoch 431 of 2000 took 0.035s
  training loss:		0.070577
  validation loss:		0.288213
  validation accuracy:		92.83 %
Epoch 432 of 2000 took 0.035s
  training loss:		0.072331
  validation loss:		0.299671
  validation accuracy:		92.72 %
Epoch 433 of 2000 took 0.035s
  training loss:		0.070496
  validation loss:		0.285458
  validation accuracy:		92.93 %
Epoch 434 of 2000 took 0.035s
  training loss:		0.072661
  validation loss:		0.291473
  validation accuracy:		92.72 %
Epoch 435 of 2000 took 0.035s
  training loss:		0.074353
  validation loss:		0.294259
  validation accuracy:		92.39 %
Epoch 436 of 2000 took 0.035s
  training loss:		0.070993
  validation loss:		0.284312
  validation accuracy:		93.04 %
Epoch 437 of 2000 took 0.035s
  training loss:		0.072772
  validation loss:		0.286253
  validation accuracy:		92.83 %
Epoch 438 of 2000 took 0.035s
  training loss:		0.071420
  validation loss:		0.294504
  validation accuracy:		92.72 %
Epoch 439 of 2000 took 0.035s
  training loss:		0.070108
  validation loss:		0.288371
  validation accuracy:		92.72 %
Epoch 440 of 2000 took 0.035s
  training loss:		0.071884
  validation loss:		0.296630
  validation accuracy:		92.72 %
Epoch 441 of 2000 took 0.035s
  training loss:		0.069660
  validation loss:		0.290023
  validation accuracy:		92.72 %
Epoch 442 of 2000 took 0.035s
  training loss:		0.068920
  validation loss:		0.294054
  validation accuracy:		92.72 %
Epoch 443 of 2000 took 0.035s
  training loss:		0.069459
  validation loss:		0.295703
  validation accuracy:		92.93 %
Epoch 444 of 2000 took 0.035s
  training loss:		0.070357
  validation loss:		0.288400
  validation accuracy:		93.04 %
Epoch 445 of 2000 took 0.035s
  training loss:		0.068283
  validation loss:		0.294226
  validation accuracy:		92.61 %
Epoch 446 of 2000 took 0.035s
  training loss:		0.068044
  validation loss:		0.289225
  validation accuracy:		92.93 %
Epoch 447 of 2000 took 0.035s
  training loss:		0.069843
  validation loss:		0.301269
  validation accuracy:		92.61 %
Epoch 448 of 2000 took 0.035s
  training loss:		0.069529
  validation loss:		0.281842
  validation accuracy:		93.15 %
Epoch 449 of 2000 took 0.035s
  training loss:		0.068694
  validation loss:		0.292359
  validation accuracy:		92.61 %
Epoch 450 of 2000 took 0.035s
  training loss:		0.069012
  validation loss:		0.284775
  validation accuracy:		92.72 %
Epoch 451 of 2000 took 0.035s
  training loss:		0.070660
  validation loss:		0.286781
  validation accuracy:		93.15 %
Epoch 452 of 2000 took 0.035s
  training loss:		0.067999
  validation loss:		0.292601
  validation accuracy:		93.04 %
Epoch 453 of 2000 took 0.035s
  training loss:		0.069324
  validation loss:		0.293737
  validation accuracy:		92.72 %
Epoch 454 of 2000 took 0.035s
  training loss:		0.070445
  validation loss:		0.298304
  validation accuracy:		92.50 %
Epoch 455 of 2000 took 0.035s
  training loss:		0.068175
  validation loss:		0.288153
  validation accuracy:		93.15 %
Epoch 456 of 2000 took 0.035s
  training loss:		0.067879
  validation loss:		0.307859
  validation accuracy:		92.50 %
Epoch 457 of 2000 took 0.035s
  training loss:		0.067862
  validation loss:		0.289067
  validation accuracy:		92.93 %
Epoch 458 of 2000 took 0.035s
  training loss:		0.064244
  validation loss:		0.302907
  validation accuracy:		92.72 %
Epoch 459 of 2000 took 0.035s
  training loss:		0.069346
  validation loss:		0.280884
  validation accuracy:		93.04 %
Epoch 460 of 2000 took 0.035s
  training loss:		0.065779
  validation loss:		0.292788
  validation accuracy:		92.83 %
Epoch 461 of 2000 took 0.035s
  training loss:		0.068520
  validation loss:		0.296219
  validation accuracy:		92.93 %
Epoch 462 of 2000 took 0.035s
  training loss:		0.068119
  validation loss:		0.290300
  validation accuracy:		92.83 %
Epoch 463 of 2000 took 0.035s
  training loss:		0.068368
  validation loss:		0.296678
  validation accuracy:		92.72 %
Epoch 464 of 2000 took 0.035s
  training loss:		0.065058
  validation loss:		0.302777
  validation accuracy:		92.28 %
Epoch 465 of 2000 took 0.035s
  training loss:		0.067042
  validation loss:		0.296215
  validation accuracy:		92.83 %
Epoch 466 of 2000 took 0.035s
  training loss:		0.066656
  validation loss:		0.301567
  validation accuracy:		92.72 %
Epoch 467 of 2000 took 0.035s
  training loss:		0.066034
  validation loss:		0.296039
  validation accuracy:		92.50 %
Epoch 468 of 2000 took 0.035s
  training loss:		0.068100
  validation loss:		0.306083
  validation accuracy:		92.50 %
Epoch 469 of 2000 took 0.035s
  training loss:		0.058133
  validation loss:		0.290653
  validation accuracy:		92.83 %
Epoch 470 of 2000 took 0.035s
  training loss:		0.063428
  validation loss:		0.293255
  validation accuracy:		92.61 %
Epoch 471 of 2000 took 0.035s
  training loss:		0.064061
  validation loss:		0.295252
  validation accuracy:		92.83 %
Epoch 472 of 2000 took 0.035s
  training loss:		0.064841
  validation loss:		0.297613
  validation accuracy:		92.83 %
Epoch 473 of 2000 took 0.035s
  training loss:		0.064460
  validation loss:		0.294695
  validation accuracy:		92.50 %
Epoch 474 of 2000 took 0.035s
  training loss:		0.064838
  validation loss:		0.299061
  validation accuracy:		92.72 %
Epoch 475 of 2000 took 0.035s
  training loss:		0.063970
  validation loss:		0.305754
  validation accuracy:		92.39 %
Epoch 476 of 2000 took 0.035s
  training loss:		0.065826
  validation loss:		0.297077
  validation accuracy:		92.72 %
Epoch 477 of 2000 took 0.035s
  training loss:		0.066403
  validation loss:		0.288549
  validation accuracy:		92.83 %
Epoch 478 of 2000 took 0.035s
  training loss:		0.063299
  validation loss:		0.288362
  validation accuracy:		92.93 %
Epoch 479 of 2000 took 0.035s
  training loss:		0.063977
  validation loss:		0.302716
  validation accuracy:		92.50 %
Epoch 480 of 2000 took 0.035s
  training loss:		0.064783
  validation loss:		0.295716
  validation accuracy:		92.83 %
Epoch 481 of 2000 took 0.035s
  training loss:		0.064252
  validation loss:		0.309742
  validation accuracy:		92.72 %
Epoch 482 of 2000 took 0.035s
  training loss:		0.063233
  validation loss:		0.299757
  validation accuracy:		92.72 %
Epoch 483 of 2000 took 0.035s
  training loss:		0.063264
  validation loss:		0.288965
  validation accuracy:		92.61 %
Epoch 484 of 2000 took 0.035s
  training loss:		0.060542
  validation loss:		0.305093
  validation accuracy:		92.61 %
Epoch 485 of 2000 took 0.035s
  training loss:		0.064178
  validation loss:		0.306323
  validation accuracy:		92.72 %
Epoch 486 of 2000 took 0.035s
  training loss:		0.063583
  validation loss:		0.297322
  validation accuracy:		92.61 %
Epoch 487 of 2000 took 0.035s
  training loss:		0.061759
  validation loss:		0.306289
  validation accuracy:		92.28 %
Epoch 488 of 2000 took 0.035s
  training loss:		0.063220
  validation loss:		0.308712
  validation accuracy:		92.28 %
Epoch 489 of 2000 took 0.035s
  training loss:		0.062630
  validation loss:		0.296215
  validation accuracy:		92.93 %
Epoch 490 of 2000 took 0.035s
  training loss:		0.062761
  validation loss:		0.310585
  validation accuracy:		92.50 %
Epoch 491 of 2000 took 0.035s
  training loss:		0.062070
  validation loss:		0.302698
  validation accuracy:		92.72 %
Epoch 492 of 2000 took 0.035s
  training loss:		0.061434
  validation loss:		0.304902
  validation accuracy:		92.72 %
Epoch 493 of 2000 took 0.035s
  training loss:		0.062121
  validation loss:		0.305177
  validation accuracy:		92.61 %
Epoch 494 of 2000 took 0.035s
  training loss:		0.061215
  validation loss:		0.313424
  validation accuracy:		92.39 %
Epoch 495 of 2000 took 0.035s
  training loss:		0.060676
  validation loss:		0.300920
  validation accuracy:		92.50 %
Epoch 496 of 2000 took 0.035s
  training loss:		0.060817
  validation loss:		0.310205
  validation accuracy:		92.83 %
Epoch 497 of 2000 took 0.035s
  training loss:		0.060414
  validation loss:		0.296057
  validation accuracy:		92.83 %
Epoch 498 of 2000 took 0.035s
  training loss:		0.059083
  validation loss:		0.306321
  validation accuracy:		92.83 %
Epoch 499 of 2000 took 0.035s
  training loss:		0.061850
  validation loss:		0.300232
  validation accuracy:		92.61 %
Epoch 500 of 2000 took 0.035s
  training loss:		0.061079
  validation loss:		0.308519
  validation accuracy:		92.83 %
Epoch 501 of 2000 took 0.035s
  training loss:		0.061075
  validation loss:		0.314182
  validation accuracy:		92.28 %
Epoch 502 of 2000 took 0.035s
  training loss:		0.059287
  validation loss:		0.299546
  validation accuracy:		92.72 %
Epoch 503 of 2000 took 0.035s
  training loss:		0.059487
  validation loss:		0.296300
  validation accuracy:		92.93 %
Epoch 504 of 2000 took 0.035s
  training loss:		0.056982
  validation loss:		0.304593
  validation accuracy:		92.83 %
Epoch 505 of 2000 took 0.035s
  training loss:		0.061124
  validation loss:		0.299272
  validation accuracy:		92.83 %
Epoch 506 of 2000 took 0.035s
  training loss:		0.055846
  validation loss:		0.316647
  validation accuracy:		92.28 %
Epoch 507 of 2000 took 0.035s
  training loss:		0.062160
  validation loss:		0.311117
  validation accuracy:		92.61 %
Epoch 508 of 2000 took 0.035s
  training loss:		0.057607
  validation loss:		0.320460
  validation accuracy:		92.61 %
Epoch 509 of 2000 took 0.035s
  training loss:		0.060899
  validation loss:		0.307291
  validation accuracy:		92.39 %
Epoch 510 of 2000 took 0.035s
  training loss:		0.059314
  validation loss:		0.313579
  validation accuracy:		92.61 %
Epoch 511 of 2000 took 0.035s
  training loss:		0.059797
  validation loss:		0.316257
  validation accuracy:		92.50 %
Epoch 512 of 2000 took 0.035s
  training loss:		0.059690
  validation loss:		0.301752
  validation accuracy:		92.61 %
Epoch 513 of 2000 took 0.035s
  training loss:		0.056832
  validation loss:		0.316986
  validation accuracy:		92.72 %
Epoch 514 of 2000 took 0.035s
  training loss:		0.057426
  validation loss:		0.320594
  validation accuracy:		92.50 %
Epoch 515 of 2000 took 0.035s
  training loss:		0.059177
  validation loss:		0.316292
  validation accuracy:		92.72 %
Epoch 516 of 2000 took 0.035s
  training loss:		0.058269
  validation loss:		0.309706
  validation accuracy:		92.50 %
Epoch 517 of 2000 took 0.035s
  training loss:		0.058069
  validation loss:		0.320738
  validation accuracy:		92.50 %
Epoch 518 of 2000 took 0.035s
  training loss:		0.059471
  validation loss:		0.319437
  validation accuracy:		92.39 %
Epoch 519 of 2000 took 0.035s
  training loss:		0.052218
  validation loss:		0.305061
  validation accuracy:		93.04 %
Epoch 520 of 2000 took 0.035s
  training loss:		0.057008
  validation loss:		0.310389
  validation accuracy:		92.61 %
Epoch 521 of 2000 took 0.035s
  training loss:		0.056604
  validation loss:		0.310438
  validation accuracy:		92.50 %
Epoch 522 of 2000 took 0.035s
  training loss:		0.054689
  validation loss:		0.318997
  validation accuracy:		92.72 %
Epoch 523 of 2000 took 0.035s
  training loss:		0.058695
  validation loss:		0.321695
  validation accuracy:		92.39 %
Epoch 524 of 2000 took 0.035s
  training loss:		0.056511
  validation loss:		0.305409
  validation accuracy:		92.61 %
Epoch 525 of 2000 took 0.035s
  training loss:		0.058924
  validation loss:		0.309506
  validation accuracy:		92.72 %
Epoch 526 of 2000 took 0.035s
  training loss:		0.057844
  validation loss:		0.328707
  validation accuracy:		92.28 %
Epoch 527 of 2000 took 0.035s
  training loss:		0.058126
  validation loss:		0.317622
  validation accuracy:		92.39 %
Epoch 528 of 2000 took 0.035s
  training loss:		0.057507
  validation loss:		0.302950
  validation accuracy:		93.04 %
Epoch 529 of 2000 took 0.035s
  training loss:		0.057541
  validation loss:		0.312006
  validation accuracy:		92.50 %
Epoch 530 of 2000 took 0.035s
  training loss:		0.056878
  validation loss:		0.309225
  validation accuracy:		92.72 %
Epoch 531 of 2000 took 0.035s
  training loss:		0.057276
  validation loss:		0.314612
  validation accuracy:		92.17 %
Epoch 532 of 2000 took 0.035s
  training loss:		0.057012
  validation loss:		0.323764
  validation accuracy:		92.83 %
Epoch 533 of 2000 took 0.035s
  training loss:		0.057021
  validation loss:		0.309684
  validation accuracy:		92.83 %
Epoch 534 of 2000 took 0.035s
  training loss:		0.057267
  validation loss:		0.326057
  validation accuracy:		92.28 %
Epoch 535 of 2000 took 0.035s
  training loss:		0.055905
  validation loss:		0.320872
  validation accuracy:		92.50 %
Epoch 536 of 2000 took 0.035s
  training loss:		0.055230
  validation loss:		0.321161
  validation accuracy:		92.61 %
Epoch 537 of 2000 took 0.035s
  training loss:		0.055577
  validation loss:		0.310657
  validation accuracy:		92.50 %
Epoch 538 of 2000 took 0.035s
  training loss:		0.054785
  validation loss:		0.307336
  validation accuracy:		92.93 %
Epoch 539 of 2000 took 0.035s
  training loss:		0.057847
  validation loss:		0.327009
  validation accuracy:		92.39 %
Epoch 540 of 2000 took 0.035s
  training loss:		0.054147
  validation loss:		0.308031
  validation accuracy:		92.61 %
Epoch 541 of 2000 took 0.035s
  training loss:		0.054589
  validation loss:		0.319709
  validation accuracy:		92.72 %
Epoch 542 of 2000 took 0.035s
  training loss:		0.052454
  validation loss:		0.344509
  validation accuracy:		92.39 %
Epoch 543 of 2000 took 0.035s
  training loss:		0.055288
  validation loss:		0.311173
  validation accuracy:		92.72 %
Epoch 544 of 2000 took 0.035s
  training loss:		0.054571
  validation loss:		0.325262
  validation accuracy:		92.28 %
Epoch 545 of 2000 took 0.037s
  training loss:		0.053213
  validation loss:		0.319567
  validation accuracy:		92.50 %
Epoch 546 of 2000 took 0.035s
  training loss:		0.052490
  validation loss:		0.315658
  validation accuracy:		92.83 %
Epoch 547 of 2000 took 0.035s
  training loss:		0.052945
  validation loss:		0.324285
  validation accuracy:		92.61 %
Epoch 548 of 2000 took 0.035s
  training loss:		0.052722
  validation loss:		0.330292
  validation accuracy:		92.28 %
Epoch 549 of 2000 took 0.035s
  training loss:		0.054538
  validation loss:		0.314709
  validation accuracy:		92.72 %
Epoch 550 of 2000 took 0.035s
  training loss:		0.053655
  validation loss:		0.326745
  validation accuracy:		92.39 %
Epoch 551 of 2000 took 0.035s
  training loss:		0.053007
  validation loss:		0.315030
  validation accuracy:		92.83 %
Epoch 552 of 2000 took 0.035s
  training loss:		0.053955
  validation loss:		0.326228
  validation accuracy:		92.83 %
Epoch 553 of 2000 took 0.035s
  training loss:		0.053143
  validation loss:		0.324889
  validation accuracy:		93.04 %
Epoch 554 of 2000 took 0.035s
  training loss:		0.052128
  validation loss:		0.329284
  validation accuracy:		92.28 %
Epoch 555 of 2000 took 0.035s
  training loss:		0.052653
  validation loss:		0.322814
  validation accuracy:		92.39 %
Epoch 556 of 2000 took 0.035s
  training loss:		0.053494
  validation loss:		0.323440
  validation accuracy:		92.72 %
Epoch 557 of 2000 took 0.035s
  training loss:		0.051856
  validation loss:		0.322713
  validation accuracy:		92.17 %
Epoch 558 of 2000 took 0.035s
  training loss:		0.051938
  validation loss:		0.328098
  validation accuracy:		92.39 %
Epoch 559 of 2000 took 0.035s
  training loss:		0.053681
  validation loss:		0.314972
  validation accuracy:		92.61 %
Epoch 560 of 2000 took 0.035s
  training loss:		0.050959
  validation loss:		0.323519
  validation accuracy:		92.50 %
Epoch 561 of 2000 took 0.035s
  training loss:		0.053470
  validation loss:		0.327308
  validation accuracy:		92.72 %
Epoch 562 of 2000 took 0.035s
  training loss:		0.052902
  validation loss:		0.332854
  validation accuracy:		92.17 %
Epoch 563 of 2000 took 0.035s
  training loss:		0.051134
  validation loss:		0.326381
  validation accuracy:		92.61 %
Epoch 564 of 2000 took 0.035s
  training loss:		0.052227
  validation loss:		0.329245
  validation accuracy:		92.07 %
Epoch 565 of 2000 took 0.035s
  training loss:		0.048663
  validation loss:		0.319634
  validation accuracy:		93.04 %
Epoch 566 of 2000 took 0.035s
  training loss:		0.052239
  validation loss:		0.329889
  validation accuracy:		92.83 %
Epoch 567 of 2000 took 0.035s
  training loss:		0.050447
  validation loss:		0.327347
  validation accuracy:		92.72 %
Epoch 568 of 2000 took 0.035s
  training loss:		0.051809
  validation loss:		0.323956
  validation accuracy:		92.61 %
Epoch 569 of 2000 took 0.035s
  training loss:		0.050647
  validation loss:		0.333511
  validation accuracy:		92.72 %
Epoch 570 of 2000 took 0.035s
  training loss:		0.051232
  validation loss:		0.331647
  validation accuracy:		92.61 %
Epoch 571 of 2000 took 0.035s
  training loss:		0.049888
  validation loss:		0.327775
  validation accuracy:		92.72 %
Epoch 572 of 2000 took 0.035s
  training loss:		0.051177
  validation loss:		0.335615
  validation accuracy:		91.96 %
Epoch 573 of 2000 took 0.035s
  training loss:		0.049338
  validation loss:		0.336824
  validation accuracy:		92.39 %
Epoch 574 of 2000 took 0.035s
  training loss:		0.048672
  validation loss:		0.321972
  validation accuracy:		92.61 %
Epoch 575 of 2000 took 0.035s
  training loss:		0.051701
  validation loss:		0.337444
  validation accuracy:		92.50 %
Epoch 576 of 2000 took 0.035s
  training loss:		0.048611
  validation loss:		0.337958
  validation accuracy:		92.61 %
Epoch 577 of 2000 took 0.035s
  training loss:		0.050795
  validation loss:		0.335528
  validation accuracy:		92.28 %
Epoch 578 of 2000 took 0.035s
  training loss:		0.049998
  validation loss:		0.339561
  validation accuracy:		92.50 %
Epoch 579 of 2000 took 0.035s
  training loss:		0.046314
  validation loss:		0.327360
  validation accuracy:		92.83 %
Epoch 580 of 2000 took 0.035s
  training loss:		0.050225
  validation loss:		0.323313
  validation accuracy:		92.72 %
Epoch 581 of 2000 took 0.035s
  training loss:		0.049946
  validation loss:		0.327171
  validation accuracy:		92.93 %
Epoch 582 of 2000 took 0.035s
  training loss:		0.048052
  validation loss:		0.322318
  validation accuracy:		92.83 %
Epoch 583 of 2000 took 0.035s
  training loss:		0.047515
  validation loss:		0.344298
  validation accuracy:		92.28 %
Epoch 584 of 2000 took 0.035s
  training loss:		0.048558
  validation loss:		0.325586
  validation accuracy:		93.04 %
Epoch 585 of 2000 took 0.035s
  training loss:		0.048703
  validation loss:		0.339196
  validation accuracy:		92.39 %
Epoch 586 of 2000 took 0.035s
  training loss:		0.046179
  validation loss:		0.336130
  validation accuracy:		92.83 %
Epoch 587 of 2000 took 0.035s
  training loss:		0.048348
  validation loss:		0.323319
  validation accuracy:		92.93 %
Epoch 588 of 2000 took 0.035s
  training loss:		0.047457
  validation loss:		0.343601
  validation accuracy:		92.72 %
Epoch 589 of 2000 took 0.035s
  training loss:		0.047954
  validation loss:		0.325544
  validation accuracy:		92.83 %
Epoch 590 of 2000 took 0.035s
  training loss:		0.049319
  validation loss:		0.339776
  validation accuracy:		92.61 %
Epoch 591 of 2000 took 0.035s
  training loss:		0.048159
  validation loss:		0.331593
  validation accuracy:		92.72 %
Epoch 592 of 2000 took 0.035s
  training loss:		0.048974
  validation loss:		0.332670
  validation accuracy:		92.83 %
Epoch 593 of 2000 took 0.035s
  training loss:		0.047607
  validation loss:		0.347697
  validation accuracy:		91.96 %
Epoch 594 of 2000 took 0.035s
  training loss:		0.047563
  validation loss:		0.337071
  validation accuracy:		92.39 %
Epoch 595 of 2000 took 0.035s
  training loss:		0.047635
  validation loss:		0.348912
  validation accuracy:		92.61 %
Epoch 596 of 2000 took 0.035s
  training loss:		0.048519
  validation loss:		0.337634
  validation accuracy:		92.72 %
Epoch 597 of 2000 took 0.035s
  training loss:		0.047726
  validation loss:		0.350004
  validation accuracy:		92.39 %
Epoch 598 of 2000 took 0.035s
  training loss:		0.045869
  validation loss:		0.328480
  validation accuracy:		92.83 %
Epoch 599 of 2000 took 0.035s
  training loss:		0.046702
  validation loss:		0.342758
  validation accuracy:		92.28 %
Epoch 600 of 2000 took 0.035s
  training loss:		0.048080
  validation loss:		0.340999
  validation accuracy:		92.72 %
Epoch 601 of 2000 took 0.035s
  training loss:		0.045957
  validation loss:		0.333195
  validation accuracy:		92.39 %
Epoch 602 of 2000 took 0.035s
  training loss:		0.047796
  validation loss:		0.344266
  validation accuracy:		92.93 %
Epoch 603 of 2000 took 0.035s
  training loss:		0.046306
  validation loss:		0.342928
  validation accuracy:		92.61 %
Epoch 604 of 2000 took 0.035s
  training loss:		0.046312
  validation loss:		0.336655
  validation accuracy:		92.72 %
Epoch 605 of 2000 took 0.035s
  training loss:		0.046458
  validation loss:		0.347356
  validation accuracy:		92.28 %
Epoch 606 of 2000 took 0.035s
  training loss:		0.046834
  validation loss:		0.341601
  validation accuracy:		92.50 %
Epoch 607 of 2000 took 0.035s
  training loss:		0.045654
  validation loss:		0.337112
  validation accuracy:		92.61 %
Epoch 608 of 2000 took 0.035s
  training loss:		0.046218
  validation loss:		0.333373
  validation accuracy:		92.61 %
Epoch 609 of 2000 took 0.035s
  training loss:		0.047759
  validation loss:		0.341659
  validation accuracy:		92.93 %
Epoch 610 of 2000 took 0.035s
  training loss:		0.047484
  validation loss:		0.350764
  validation accuracy:		92.39 %
Epoch 611 of 2000 took 0.035s
  training loss:		0.045613
  validation loss:		0.328141
  validation accuracy:		92.61 %
Epoch 612 of 2000 took 0.035s
  training loss:		0.045762
  validation loss:		0.344886
  validation accuracy:		92.72 %
Epoch 613 of 2000 took 0.035s
  training loss:		0.044106
  validation loss:		0.333510
  validation accuracy:		92.93 %
Epoch 614 of 2000 took 0.035s
  training loss:		0.044853
  validation loss:		0.353699
  validation accuracy:		92.39 %
Epoch 615 of 2000 took 0.035s
  training loss:		0.045954
  validation loss:		0.343447
  validation accuracy:		92.50 %
Epoch 616 of 2000 took 0.035s
  training loss:		0.044398
  validation loss:		0.349649
  validation accuracy:		92.61 %
Epoch 617 of 2000 took 0.035s
  training loss:		0.046333
  validation loss:		0.350365
  validation accuracy:		91.85 %
Epoch 618 of 2000 took 0.035s
  training loss:		0.045287
  validation loss:		0.337866
  validation accuracy:		92.83 %
Epoch 619 of 2000 took 0.035s
  training loss:		0.045773
  validation loss:		0.340195
  validation accuracy:		92.72 %
Epoch 620 of 2000 took 0.035s
  training loss:		0.044250
  validation loss:		0.348834
  validation accuracy:		92.50 %
Epoch 621 of 2000 took 0.035s
  training loss:		0.045057
  validation loss:		0.337447
  validation accuracy:		92.83 %
Epoch 622 of 2000 took 0.035s
  training loss:		0.045033
  validation loss:		0.352295
  validation accuracy:		92.17 %
Epoch 623 of 2000 took 0.035s
  training loss:		0.045716
  validation loss:		0.340442
  validation accuracy:		92.50 %
Epoch 624 of 2000 took 0.035s
  training loss:		0.044100
  validation loss:		0.342470
  validation accuracy:		92.83 %
Epoch 625 of 2000 took 0.035s
  training loss:		0.042942
  validation loss:		0.335228
  validation accuracy:		92.83 %
Epoch 626 of 2000 took 0.035s
  training loss:		0.044299
  validation loss:		0.347007
  validation accuracy:		92.93 %
Epoch 627 of 2000 took 0.035s
  training loss:		0.044314
  validation loss:		0.340932
  validation accuracy:		92.83 %
Epoch 628 of 2000 took 0.035s
  training loss:		0.044127
  validation loss:		0.341454
  validation accuracy:		92.50 %
Epoch 629 of 2000 took 0.035s
  training loss:		0.044091
  validation loss:		0.354289
  validation accuracy:		92.93 %
Epoch 630 of 2000 took 0.035s
  training loss:		0.040656
  validation loss:		0.337165
  validation accuracy:		92.83 %
Epoch 631 of 2000 took 0.035s
  training loss:		0.043181
  validation loss:		0.348334
  validation accuracy:		92.39 %
Epoch 632 of 2000 took 0.035s
  training loss:		0.041998
  validation loss:		0.339668
  validation accuracy:		92.93 %
Epoch 633 of 2000 took 0.035s
  training loss:		0.041108
  validation loss:		0.349066
  validation accuracy:		92.93 %
Epoch 634 of 2000 took 0.035s
  training loss:		0.042900
  validation loss:		0.338721
  validation accuracy:		92.93 %
Epoch 635 of 2000 took 0.035s
  training loss:		0.040765
  validation loss:		0.337789
  validation accuracy:		93.04 %
Epoch 636 of 2000 took 0.035s
  training loss:		0.041156
  validation loss:		0.353612
  validation accuracy:		92.61 %
Epoch 637 of 2000 took 0.035s
  training loss:		0.042785
  validation loss:		0.363069
  validation accuracy:		92.28 %
Epoch 638 of 2000 took 0.035s
  training loss:		0.043224
  validation loss:		0.346338
  validation accuracy:		92.83 %
Epoch 639 of 2000 took 0.035s
  training loss:		0.042653
  validation loss:		0.346082
  validation accuracy:		92.83 %
Epoch 640 of 2000 took 0.035s
  training loss:		0.042856
  validation loss:		0.357969
  validation accuracy:		92.50 %
Epoch 641 of 2000 took 0.035s
  training loss:		0.043003
  validation loss:		0.356751
  validation accuracy:		92.39 %
Epoch 642 of 2000 took 0.035s
  training loss:		0.040976
  validation loss:		0.358696
  validation accuracy:		92.61 %
Epoch 643 of 2000 took 0.035s
  training loss:		0.041138
  validation loss:		0.342000
  validation accuracy:		92.72 %
Epoch 644 of 2000 took 0.035s
  training loss:		0.042164
  validation loss:		0.350284
  validation accuracy:		92.50 %
Epoch 645 of 2000 took 0.035s
  training loss:		0.042839
  validation loss:		0.355459
  validation accuracy:		92.83 %
Epoch 646 of 2000 took 0.035s
  training loss:		0.042027
  validation loss:		0.348755
  validation accuracy:		92.50 %
Epoch 647 of 2000 took 0.035s
  training loss:		0.042971
  validation loss:		0.348278
  validation accuracy:		92.83 %
Epoch 648 of 2000 took 0.035s
  training loss:		0.041715
  validation loss:		0.350835
  validation accuracy:		92.83 %
Epoch 649 of 2000 took 0.035s
  training loss:		0.041941
  validation loss:		0.361061
  validation accuracy:		92.28 %
Epoch 650 of 2000 took 0.035s
  training loss:		0.040497
  validation loss:		0.353027
  validation accuracy:		92.72 %
Epoch 651 of 2000 took 0.035s
  training loss:		0.041734
  validation loss:		0.354199
  validation accuracy:		92.83 %
Epoch 652 of 2000 took 0.035s
  training loss:		0.041943
  validation loss:		0.360753
  validation accuracy:		92.28 %
Epoch 653 of 2000 took 0.035s
  training loss:		0.040274
  validation loss:		0.353243
  validation accuracy:		92.83 %
Epoch 654 of 2000 took 0.035s
  training loss:		0.041830
  validation loss:		0.346846
  validation accuracy:		92.72 %
Epoch 655 of 2000 took 0.035s
  training loss:		0.039541
  validation loss:		0.355086
  validation accuracy:		92.28 %
Epoch 656 of 2000 took 0.035s
  training loss:		0.039061
  validation loss:		0.354207
  validation accuracy:		92.93 %
Epoch 657 of 2000 took 0.035s
  training loss:		0.040003
  validation loss:		0.367398
  validation accuracy:		92.61 %
Epoch 658 of 2000 took 0.035s
  training loss:		0.040420
  validation loss:		0.365580
  validation accuracy:		92.72 %
Epoch 659 of 2000 took 0.035s
  training loss:		0.038500
  validation loss:		0.357725
  validation accuracy:		92.50 %
Epoch 660 of 2000 took 0.035s
  training loss:		0.037823
  validation loss:		0.366497
  validation accuracy:		92.93 %
Epoch 661 of 2000 took 0.035s
  training loss:		0.041586
  validation loss:		0.352498
  validation accuracy:		92.72 %
Epoch 662 of 2000 took 0.035s
  training loss:		0.039737
  validation loss:		0.355569
  validation accuracy:		92.61 %
Epoch 663 of 2000 took 0.036s
  training loss:		0.040314
  validation loss:		0.365702
  validation accuracy:		92.28 %
Epoch 664 of 2000 took 0.038s
  training loss:		0.041137
  validation loss:		0.361160
  validation accuracy:		92.50 %
Epoch 665 of 2000 took 0.037s
  training loss:		0.038031
  validation loss:		0.349922
  validation accuracy:		92.72 %
Epoch 666 of 2000 took 0.036s
  training loss:		0.040089
  validation loss:		0.352462
  validation accuracy:		92.50 %
Epoch 667 of 2000 took 0.036s
  training loss:		0.038477
  validation loss:		0.373144
  validation accuracy:		92.50 %
Epoch 668 of 2000 took 0.036s
  training loss:		0.036840
  validation loss:		0.347651
  validation accuracy:		92.72 %
Epoch 669 of 2000 took 0.036s
  training loss:		0.037947
  validation loss:		0.367440
  validation accuracy:		92.50 %
Epoch 670 of 2000 took 0.036s
  training loss:		0.039326
  validation loss:		0.366474
  validation accuracy:		92.50 %
Epoch 671 of 2000 took 0.036s
  training loss:		0.039374
  validation loss:		0.354009
  validation accuracy:		92.83 %
Epoch 672 of 2000 took 0.036s
  training loss:		0.039692
  validation loss:		0.353034
  validation accuracy:		92.72 %
Epoch 673 of 2000 took 0.036s
  training loss:		0.037696
  validation loss:		0.364627
  validation accuracy:		92.72 %
Epoch 674 of 2000 took 0.036s
  training loss:		0.037363
  validation loss:		0.365928
  validation accuracy:		92.28 %
Epoch 675 of 2000 took 0.036s
  training loss:		0.038653
  validation loss:		0.361327
  validation accuracy:		92.39 %
Epoch 676 of 2000 took 0.035s
  training loss:		0.039549
  validation loss:		0.358616
  validation accuracy:		92.83 %
Epoch 677 of 2000 took 0.035s
  training loss:		0.038134
  validation loss:		0.355123
  validation accuracy:		92.61 %
Epoch 678 of 2000 took 0.035s
  training loss:		0.039330
  validation loss:		0.357889
  validation accuracy:		92.83 %
Epoch 679 of 2000 took 0.035s
  training loss:		0.038702
  validation loss:		0.365325
  validation accuracy:		92.28 %
Epoch 680 of 2000 took 0.035s
  training loss:		0.037776
  validation loss:		0.366042
  validation accuracy:		92.28 %
Epoch 681 of 2000 took 0.035s
  training loss:		0.038474
  validation loss:		0.367628
  validation accuracy:		92.39 %
Epoch 682 of 2000 took 0.035s
  training loss:		0.037747
  validation loss:		0.373916
  validation accuracy:		92.50 %
Epoch 683 of 2000 took 0.035s
  training loss:		0.037657
  validation loss:		0.356049
  validation accuracy:		92.61 %
Epoch 684 of 2000 took 0.035s
  training loss:		0.037715
  validation loss:		0.366621
  validation accuracy:		92.61 %
Epoch 685 of 2000 took 0.035s
  training loss:		0.037566
  validation loss:		0.369563
  validation accuracy:		92.61 %
Epoch 686 of 2000 took 0.035s
  training loss:		0.035969
  validation loss:		0.364461
  validation accuracy:		92.50 %
Epoch 687 of 2000 took 0.035s
  training loss:		0.035410
  validation loss:		0.356814
  validation accuracy:		92.72 %
Epoch 688 of 2000 took 0.035s
  training loss:		0.036125
  validation loss:		0.359931
  validation accuracy:		93.04 %
Epoch 689 of 2000 took 0.035s
  training loss:		0.037888
  validation loss:		0.372640
  validation accuracy:		92.17 %
Epoch 690 of 2000 took 0.035s
  training loss:		0.036390
  validation loss:		0.355346
  validation accuracy:		92.72 %
Epoch 691 of 2000 took 0.035s
  training loss:		0.036340
  validation loss:		0.375237
  validation accuracy:		92.83 %
Epoch 692 of 2000 took 0.035s
  training loss:		0.037753
  validation loss:		0.380933
  validation accuracy:		92.07 %
Epoch 693 of 2000 took 0.035s
  training loss:		0.034497
  validation loss:		0.367394
  validation accuracy:		93.04 %
Epoch 694 of 2000 took 0.035s
  training loss:		0.036659
  validation loss:		0.369789
  validation accuracy:		92.17 %
Epoch 695 of 2000 took 0.035s
  training loss:		0.036558
  validation loss:		0.370715
  validation accuracy:		92.50 %
Epoch 696 of 2000 took 0.035s
  training loss:		0.035319
  validation loss:		0.366755
  validation accuracy:		92.50 %
Epoch 697 of 2000 took 0.035s
  training loss:		0.035531
  validation loss:		0.369095
  validation accuracy:		92.83 %
Epoch 698 of 2000 took 0.035s
  training loss:		0.035722
  validation loss:		0.375967
  validation accuracy:		92.17 %
Epoch 699 of 2000 took 0.035s
  training loss:		0.035311
  validation loss:		0.377585
  validation accuracy:		92.17 %
Epoch 700 of 2000 took 0.035s
  training loss:		0.036356
  validation loss:		0.378082
  validation accuracy:		92.50 %
Epoch 701 of 2000 took 0.035s
  training loss:		0.035308
  validation loss:		0.365798
  validation accuracy:		92.61 %
Epoch 702 of 2000 took 0.035s
  training loss:		0.035094
  validation loss:		0.388224
  validation accuracy:		92.28 %
Epoch 703 of 2000 took 0.036s
  training loss:		0.035652
  validation loss:		0.371750
  validation accuracy:		92.61 %
Epoch 704 of 2000 took 0.035s
  training loss:		0.035895
  validation loss:		0.370859
  validation accuracy:		92.39 %
Epoch 705 of 2000 took 0.035s
  training loss:		0.035983
  validation loss:		0.374830
  validation accuracy:		92.83 %
Epoch 706 of 2000 took 0.035s
  training loss:		0.034176
  validation loss:		0.362302
  validation accuracy:		92.28 %
Epoch 707 of 2000 took 0.035s
  training loss:		0.034818
  validation loss:		0.377635
  validation accuracy:		92.39 %
Epoch 708 of 2000 took 0.035s
  training loss:		0.035164
  validation loss:		0.365493
  validation accuracy:		92.50 %
Epoch 709 of 2000 took 0.035s
  training loss:		0.033977
  validation loss:		0.385318
  validation accuracy:		92.50 %
Epoch 710 of 2000 took 0.035s
  training loss:		0.034406
  validation loss:		0.372707
  validation accuracy:		92.39 %
Epoch 711 of 2000 took 0.035s
  training loss:		0.035506
  validation loss:		0.377187
  validation accuracy:		92.72 %
Epoch 712 of 2000 took 0.035s
  training loss:		0.032170
  validation loss:		0.369674
  validation accuracy:		92.83 %
Epoch 713 of 2000 took 0.035s
  training loss:		0.034479
  validation loss:		0.367245
  validation accuracy:		92.50 %
Epoch 714 of 2000 took 0.035s
  training loss:		0.034720
  validation loss:		0.379095
  validation accuracy:		92.50 %
Epoch 715 of 2000 took 0.035s
  training loss:		0.032877
  validation loss:		0.375555
  validation accuracy:		92.61 %
Epoch 716 of 2000 took 0.035s
  training loss:		0.035152
  validation loss:		0.371048
  validation accuracy:		92.61 %
Epoch 717 of 2000 took 0.035s
  training loss:		0.035282
  validation loss:		0.366827
  validation accuracy:		92.72 %
Epoch 718 of 2000 took 0.035s
  training loss:		0.033056
  validation loss:		0.370511
  validation accuracy:		92.39 %
Epoch 719 of 2000 took 0.035s
  training loss:		0.034250
  validation loss:		0.391889
  validation accuracy:		92.50 %
Epoch 720 of 2000 took 0.035s
  training loss:		0.034384
  validation loss:		0.388637
  validation accuracy:		92.07 %
Epoch 721 of 2000 took 0.035s
  training loss:		0.034083
  validation loss:		0.365611
  validation accuracy:		92.72 %
Epoch 722 of 2000 took 0.035s
  training loss:		0.034155
  validation loss:		0.386311
  validation accuracy:		92.39 %
Epoch 723 of 2000 took 0.035s
  training loss:		0.030816
  validation loss:		0.369393
  validation accuracy:		92.72 %
Epoch 724 of 2000 took 0.035s
  training loss:		0.033275
  validation loss:		0.383850
  validation accuracy:		92.61 %
Epoch 725 of 2000 took 0.035s
  training loss:		0.033889
  validation loss:		0.370091
  validation accuracy:		92.61 %
Epoch 726 of 2000 took 0.035s
  training loss:		0.034408
  validation loss:		0.380339
  validation accuracy:		92.28 %
Epoch 727 of 2000 took 0.035s
  training loss:		0.033429
  validation loss:		0.385846
  validation accuracy:		92.39 %
Epoch 728 of 2000 took 0.035s
  training loss:		0.033516
  validation loss:		0.372090
  validation accuracy:		92.61 %
Epoch 729 of 2000 took 0.035s
  training loss:		0.035111
  validation loss:		0.382564
  validation accuracy:		92.17 %
Epoch 730 of 2000 took 0.035s
  training loss:		0.032571
  validation loss:		0.383935
  validation accuracy:		92.28 %
Epoch 731 of 2000 took 0.035s
  training loss:		0.033369
  validation loss:		0.383377
  validation accuracy:		92.17 %
Epoch 732 of 2000 took 0.035s
  training loss:		0.032413
  validation loss:		0.380040
  validation accuracy:		92.72 %
Epoch 733 of 2000 took 0.035s
  training loss:		0.033719
  validation loss:		0.378824
  validation accuracy:		92.28 %
Epoch 734 of 2000 took 0.035s
  training loss:		0.033022
  validation loss:		0.385317
  validation accuracy:		92.61 %
Epoch 735 of 2000 took 0.035s
  training loss:		0.033070
  validation loss:		0.380046
  validation accuracy:		92.28 %
Epoch 736 of 2000 took 0.035s
  training loss:		0.032479
  validation loss:		0.386287
  validation accuracy:		92.50 %
Epoch 737 of 2000 took 0.035s
  training loss:		0.031837
  validation loss:		0.385568
  validation accuracy:		92.61 %
Epoch 738 of 2000 took 0.035s
  training loss:		0.032443
  validation loss:		0.384934
  validation accuracy:		92.28 %
Epoch 739 of 2000 took 0.035s
  training loss:		0.030545
  validation loss:		0.388212
  validation accuracy:		92.50 %
Epoch 740 of 2000 took 0.035s
  training loss:		0.031649
  validation loss:		0.386967
  validation accuracy:		92.39 %
Epoch 741 of 2000 took 0.035s
  training loss:		0.032856
  validation loss:		0.385717
  validation accuracy:		92.61 %
Epoch 742 of 2000 took 0.035s
  training loss:		0.030668
  validation loss:		0.394711
  validation accuracy:		92.07 %
Epoch 743 of 2000 took 0.035s
  training loss:		0.031728
  validation loss:		0.384269
  validation accuracy:		92.28 %
Epoch 744 of 2000 took 0.035s
  training loss:		0.031516
  validation loss:		0.397948
  validation accuracy:		92.17 %
Epoch 745 of 2000 took 0.035s
  training loss:		0.032312
  validation loss:		0.399201
  validation accuracy:		92.07 %
Epoch 746 of 2000 took 0.035s
  training loss:		0.032260
  validation loss:		0.395346
  validation accuracy:		92.50 %
Epoch 747 of 2000 took 0.035s
  training loss:		0.032060
  validation loss:		0.394961
  validation accuracy:		92.17 %
Epoch 748 of 2000 took 0.035s
  training loss:		0.032376
  validation loss:		0.402577
  validation accuracy:		92.72 %
Epoch 749 of 2000 took 0.035s
  training loss:		0.030390
  validation loss:		0.377204
  validation accuracy:		92.50 %
Epoch 750 of 2000 took 0.035s
  training loss:		0.030100
  validation loss:		0.393506
  validation accuracy:		92.50 %
Epoch 751 of 2000 took 0.035s
  training loss:		0.031097
  validation loss:		0.378546
  validation accuracy:		92.61 %
Epoch 752 of 2000 took 0.035s
  training loss:		0.032282
  validation loss:		0.389255
  validation accuracy:		92.61 %
Epoch 753 of 2000 took 0.035s
  training loss:		0.030452
  validation loss:		0.388321
  validation accuracy:		92.61 %
Epoch 754 of 2000 took 0.035s
  training loss:		0.030671
  validation loss:		0.383476
  validation accuracy:		92.61 %
Epoch 755 of 2000 took 0.035s
  training loss:		0.029014
  validation loss:		0.386370
  validation accuracy:		92.61 %
Epoch 756 of 2000 took 0.035s
  training loss:		0.029959
  validation loss:		0.384694
  validation accuracy:		92.17 %
Epoch 757 of 2000 took 0.035s
  training loss:		0.031761
  validation loss:		0.385344
  validation accuracy:		92.39 %
Epoch 758 of 2000 took 0.035s
  training loss:		0.031570
  validation loss:		0.392741
  validation accuracy:		92.61 %
Epoch 759 of 2000 took 0.035s
  training loss:		0.031550
  validation loss:		0.388772
  validation accuracy:		92.50 %
Epoch 760 of 2000 took 0.035s
  training loss:		0.030323
  validation loss:		0.392586
  validation accuracy:		92.50 %
Epoch 761 of 2000 took 0.035s
  training loss:		0.030944
  validation loss:		0.392253
  validation accuracy:		92.28 %
Epoch 762 of 2000 took 0.035s
  training loss:		0.030300
  validation loss:		0.402167
  validation accuracy:		92.61 %
Epoch 763 of 2000 took 0.035s
  training loss:		0.031100
  validation loss:		0.398738
  validation accuracy:		92.17 %
Epoch 764 of 2000 took 0.035s
  training loss:		0.031954
  validation loss:		0.388013
  validation accuracy:		92.50 %
Epoch 765 of 2000 took 0.035s
  training loss:		0.029923
  validation loss:		0.403145
  validation accuracy:		92.28 %
Epoch 766 of 2000 took 0.035s
  training loss:		0.029909
  validation loss:		0.406629
  validation accuracy:		92.17 %
Epoch 767 of 2000 took 0.035s
  training loss:		0.030111
  validation loss:		0.399308
  validation accuracy:		92.07 %
Epoch 768 of 2000 took 0.035s
  training loss:		0.029599
  validation loss:		0.400459
  validation accuracy:		92.39 %
Epoch 769 of 2000 took 0.035s
  training loss:		0.029840
  validation loss:		0.400264
  validation accuracy:		92.17 %
Epoch 770 of 2000 took 0.035s
  training loss:		0.029369
  validation loss:		0.395198
  validation accuracy:		92.61 %
Epoch 771 of 2000 took 0.035s
  training loss:		0.029390
  validation loss:		0.397555
  validation accuracy:		92.39 %
Epoch 772 of 2000 took 0.035s
  training loss:		0.029402
  validation loss:		0.401977
  validation accuracy:		92.28 %
Epoch 773 of 2000 took 0.035s
  training loss:		0.029704
  validation loss:		0.391674
  validation accuracy:		92.39 %
Epoch 774 of 2000 took 0.035s
  training loss:		0.029779
  validation loss:		0.403056
  validation accuracy:		92.28 %
Epoch 775 of 2000 took 0.035s
  training loss:		0.028539
  validation loss:		0.391179
  validation accuracy:		92.50 %
Epoch 776 of 2000 took 0.035s
  training loss:		0.029243
  validation loss:		0.394479
  validation accuracy:		92.17 %
Epoch 777 of 2000 took 0.035s
  training loss:		0.028453
  validation loss:		0.408470
  validation accuracy:		92.17 %
Epoch 778 of 2000 took 0.035s
  training loss:		0.029201
  validation loss:		0.402771
  validation accuracy:		92.28 %
Epoch 779 of 2000 took 0.035s
  training loss:		0.030156
  validation loss:		0.403572
  validation accuracy:		92.39 %
Epoch 780 of 2000 took 0.035s
  training loss:		0.028783
  validation loss:		0.395324
  validation accuracy:		92.72 %
Epoch 781 of 2000 took 0.035s
  training loss:		0.028855
  validation loss:		0.401890
  validation accuracy:		92.17 %
Epoch 782 of 2000 took 0.035s
  training loss:		0.030404
  validation loss:		0.413537
  validation accuracy:		92.28 %
Epoch 783 of 2000 took 0.035s
  training loss:		0.027575
  validation loss:		0.393400
  validation accuracy:		92.39 %
Epoch 784 of 2000 took 0.035s
  training loss:		0.028752
  validation loss:		0.403658
  validation accuracy:		92.39 %
Epoch 785 of 2000 took 0.035s
  training loss:		0.028429
  validation loss:		0.398257
  validation accuracy:		92.39 %
Epoch 786 of 2000 took 0.035s
  training loss:		0.028751
  validation loss:		0.415501
  validation accuracy:		92.17 %
Epoch 787 of 2000 took 0.035s
  training loss:		0.028024
  validation loss:		0.415818
  validation accuracy:		92.17 %
Epoch 788 of 2000 took 0.035s
  training loss:		0.028813
  validation loss:		0.395873
  validation accuracy:		92.17 %
Epoch 789 of 2000 took 0.035s
  training loss:		0.027470
  validation loss:		0.412967
  validation accuracy:		92.07 %
Epoch 790 of 2000 took 0.035s
  training loss:		0.028558
  validation loss:		0.406335
  validation accuracy:		92.17 %
Epoch 791 of 2000 took 0.035s
  training loss:		0.027845
  validation loss:		0.403987
  validation accuracy:		92.17 %
Epoch 792 of 2000 took 0.035s
  training loss:		0.026594
  validation loss:		0.395769
  validation accuracy:		92.50 %
Epoch 793 of 2000 took 0.035s
  training loss:		0.028135
  validation loss:		0.414565
  validation accuracy:		92.07 %
Epoch 794 of 2000 took 0.035s
  training loss:		0.028522
  validation loss:		0.411984
  validation accuracy:		92.07 %
Epoch 795 of 2000 took 0.035s
  training loss:		0.027037
  validation loss:		0.412288
  validation accuracy:		92.28 %
Epoch 796 of 2000 took 0.035s
  training loss:		0.026648
  validation loss:		0.416070
  validation accuracy:		91.96 %
Epoch 797 of 2000 took 0.035s
  training loss:		0.028575
  validation loss:		0.404745
  validation accuracy:		92.28 %
Epoch 798 of 2000 took 0.035s
  training loss:		0.028040
  validation loss:		0.406726
  validation accuracy:		92.39 %
Epoch 799 of 2000 took 0.035s
  training loss:		0.027995
  validation loss:		0.410186
  validation accuracy:		92.17 %
Epoch 800 of 2000 took 0.035s
  training loss:		0.026971
  validation loss:		0.411025
  validation accuracy:		92.28 %
Epoch 801 of 2000 took 0.035s
  training loss:		0.026750
  validation loss:		0.417376
  validation accuracy:		92.07 %
Epoch 802 of 2000 took 0.035s
  training loss:		0.027129
  validation loss:		0.407114
  validation accuracy:		92.28 %
Epoch 803 of 2000 took 0.035s
  training loss:		0.026751
  validation loss:		0.407956
  validation accuracy:		92.17 %
Epoch 804 of 2000 took 0.035s
  training loss:		0.027186
  validation loss:		0.405047
  validation accuracy:		92.28 %
Epoch 805 of 2000 took 0.035s
  training loss:		0.026482
  validation loss:		0.403584
  validation accuracy:		92.28 %
Epoch 806 of 2000 took 0.035s
  training loss:		0.026837
  validation loss:		0.410004
  validation accuracy:		92.39 %
Epoch 807 of 2000 took 0.035s
  training loss:		0.026981
  validation loss:		0.405660
  validation accuracy:		92.39 %
Epoch 808 of 2000 took 0.035s
  training loss:		0.026710
  validation loss:		0.404158
  validation accuracy:		92.28 %
Epoch 809 of 2000 took 0.035s
  training loss:		0.027126
  validation loss:		0.408858
  validation accuracy:		92.39 %
Epoch 810 of 2000 took 0.035s
  training loss:		0.027415
  validation loss:		0.408939
  validation accuracy:		92.39 %
Epoch 811 of 2000 took 0.035s
  training loss:		0.026769
  validation loss:		0.423764
  validation accuracy:		92.28 %
Epoch 812 of 2000 took 0.035s
  training loss:		0.026647
  validation loss:		0.413921
  validation accuracy:		92.07 %
Epoch 813 of 2000 took 0.035s
  training loss:		0.024748
  validation loss:		0.429132
  validation accuracy:		92.07 %
Epoch 814 of 2000 took 0.035s
  training loss:		0.027443
  validation loss:		0.409288
  validation accuracy:		92.17 %
Epoch 815 of 2000 took 0.035s
  training loss:		0.025597
  validation loss:		0.409108
  validation accuracy:		92.39 %
Epoch 816 of 2000 took 0.035s
  training loss:		0.025405
  validation loss:		0.413623
  validation accuracy:		91.85 %
Epoch 817 of 2000 took 0.036s
  training loss:		0.026273
  validation loss:		0.409385
  validation accuracy:		92.50 %
Epoch 818 of 2000 took 0.035s
  training loss:		0.026729
  validation loss:		0.403222
  validation accuracy:		92.61 %
Epoch 819 of 2000 took 0.035s
  training loss:		0.026662
  validation loss:		0.402424
  validation accuracy:		92.50 %
Epoch 820 of 2000 took 0.035s
  training loss:		0.026133
  validation loss:		0.414483
  validation accuracy:		92.39 %
Epoch 821 of 2000 took 0.035s
  training loss:		0.025109
  validation loss:		0.416776
  validation accuracy:		92.07 %
Epoch 822 of 2000 took 0.035s
  training loss:		0.025250
  validation loss:		0.416692
  validation accuracy:		92.17 %
Epoch 823 of 2000 took 0.035s
  training loss:		0.024067
  validation loss:		0.408711
  validation accuracy:		92.28 %
Epoch 824 of 2000 took 0.035s
  training loss:		0.024029
  validation loss:		0.421040
  validation accuracy:		92.17 %
Epoch 825 of 2000 took 0.035s
  training loss:		0.024208
  validation loss:		0.408852
  validation accuracy:		91.96 %
Epoch 826 of 2000 took 0.035s
  training loss:		0.025184
  validation loss:		0.415729
  validation accuracy:		92.39 %
Epoch 827 of 2000 took 0.035s
  training loss:		0.025107
  validation loss:		0.416636
  validation accuracy:		92.39 %
Epoch 828 of 2000 took 0.035s
  training loss:		0.025694
  validation loss:		0.420619
  validation accuracy:		92.17 %
Epoch 829 of 2000 took 0.035s
  training loss:		0.024197
  validation loss:		0.424273
  validation accuracy:		92.07 %
Epoch 830 of 2000 took 0.035s
  training loss:		0.025033
  validation loss:		0.421543
  validation accuracy:		92.17 %
Epoch 831 of 2000 took 0.035s
  training loss:		0.025087
  validation loss:		0.423763
  validation accuracy:		92.07 %
Epoch 832 of 2000 took 0.035s
  training loss:		0.024562
  validation loss:		0.424778
  validation accuracy:		92.07 %
Epoch 833 of 2000 took 0.035s
  training loss:		0.022372
  validation loss:		0.405442
  validation accuracy:		92.28 %
Epoch 834 of 2000 took 0.035s
  training loss:		0.025579
  validation loss:		0.433503
  validation accuracy:		92.07 %
Epoch 835 of 2000 took 0.035s
  training loss:		0.024770
  validation loss:		0.431819
  validation accuracy:		92.07 %
Epoch 836 of 2000 took 0.035s
  training loss:		0.024798
  validation loss:		0.432147
  validation accuracy:		92.17 %
Epoch 837 of 2000 took 0.035s
  training loss:		0.024078
  validation loss:		0.416686
  validation accuracy:		92.28 %
Epoch 838 of 2000 took 0.035s
  training loss:		0.024404
  validation loss:		0.413745
  validation accuracy:		92.39 %
Epoch 839 of 2000 took 0.035s
  training loss:		0.024684
  validation loss:		0.411791
  validation accuracy:		92.39 %
Epoch 840 of 2000 took 0.035s
  training loss:		0.025704
  validation loss:		0.420058
  validation accuracy:		92.39 %
Epoch 841 of 2000 took 0.035s
  training loss:		0.023558
  validation loss:		0.432340
  validation accuracy:		92.17 %
Epoch 842 of 2000 took 0.035s
  training loss:		0.025376
  validation loss:		0.420567
  validation accuracy:		92.28 %
Epoch 843 of 2000 took 0.035s
  training loss:		0.024759
  validation loss:		0.417848
  validation accuracy:		92.17 %
Epoch 844 of 2000 took 0.035s
  training loss:		0.024670
  validation loss:		0.423213
  validation accuracy:		92.17 %
Epoch 845 of 2000 took 0.035s
  training loss:		0.024416
  validation loss:		0.411617
  validation accuracy:		92.39 %
Epoch 846 of 2000 took 0.035s
  training loss:		0.024321
  validation loss:		0.433934
  validation accuracy:		92.50 %
Epoch 847 of 2000 took 0.035s
  training loss:		0.023883
  validation loss:		0.416848
  validation accuracy:		92.17 %
Epoch 848 of 2000 took 0.035s
  training loss:		0.023918
  validation loss:		0.435623
  validation accuracy:		91.96 %
Epoch 849 of 2000 took 0.035s
  training loss:		0.024296
  validation loss:		0.423055
  validation accuracy:		92.17 %
Epoch 850 of 2000 took 0.035s
  training loss:		0.022433
  validation loss:		0.431067
  validation accuracy:		92.39 %
Epoch 851 of 2000 took 0.035s
  training loss:		0.024470
  validation loss:		0.424871
  validation accuracy:		92.17 %
Epoch 852 of 2000 took 0.035s
  training loss:		0.024647
  validation loss:		0.435995
  validation accuracy:		91.85 %
Epoch 853 of 2000 took 0.035s
  training loss:		0.023180
  validation loss:		0.421958
  validation accuracy:		92.39 %
Epoch 854 of 2000 took 0.035s
  training loss:		0.023659
  validation loss:		0.421021
  validation accuracy:		92.07 %
Epoch 855 of 2000 took 0.035s
  training loss:		0.024140
  validation loss:		0.429927
  validation accuracy:		92.50 %
Epoch 856 of 2000 took 0.035s
  training loss:		0.023829
  validation loss:		0.423744
  validation accuracy:		92.50 %
Epoch 857 of 2000 took 0.035s
  training loss:		0.024205
  validation loss:		0.427662
  validation accuracy:		92.07 %
Epoch 858 of 2000 took 0.035s
  training loss:		0.022765
  validation loss:		0.424541
  validation accuracy:		92.28 %
Epoch 859 of 2000 took 0.035s
  training loss:		0.022619
  validation loss:		0.441433
  validation accuracy:		92.07 %
Epoch 860 of 2000 took 0.035s
  training loss:		0.022910
  validation loss:		0.433711
  validation accuracy:		92.07 %
Epoch 861 of 2000 took 0.035s
  training loss:		0.023041
  validation loss:		0.432882
  validation accuracy:		92.07 %
Epoch 862 of 2000 took 0.035s
  training loss:		0.022719
  validation loss:		0.428720
  validation accuracy:		92.28 %
Epoch 863 of 2000 took 0.035s
  training loss:		0.023200
  validation loss:		0.425801
  validation accuracy:		92.28 %
Epoch 864 of 2000 took 0.035s
  training loss:		0.023390
  validation loss:		0.421087
  validation accuracy:		92.39 %
Epoch 865 of 2000 took 0.035s
  training loss:		0.022367
  validation loss:		0.427146
  validation accuracy:		92.07 %
Epoch 866 of 2000 took 0.035s
  training loss:		0.022623
  validation loss:		0.420182
  validation accuracy:		92.50 %
Epoch 867 of 2000 took 0.035s
  training loss:		0.020897
  validation loss:		0.446470
  validation accuracy:		92.28 %
Epoch 868 of 2000 took 0.035s
  training loss:		0.022739
  validation loss:		0.424507
  validation accuracy:		92.07 %
Epoch 869 of 2000 took 0.035s
  training loss:		0.023002
  validation loss:		0.438206
  validation accuracy:		92.07 %
Epoch 870 of 2000 took 0.035s
  training loss:		0.022769
  validation loss:		0.427172
  validation accuracy:		92.50 %
Epoch 871 of 2000 took 0.035s
  training loss:		0.021386
  validation loss:		0.435582
  validation accuracy:		92.07 %
Epoch 872 of 2000 took 0.035s
  training loss:		0.021596
  validation loss:		0.425136
  validation accuracy:		92.28 %
Epoch 873 of 2000 took 0.035s
  training loss:		0.022457
  validation loss:		0.428298
  validation accuracy:		92.28 %
Epoch 874 of 2000 took 0.036s
  training loss:		0.022495
  validation loss:		0.417151
  validation accuracy:		92.28 %
Epoch 875 of 2000 took 0.035s
  training loss:		0.022760
  validation loss:		0.417945
  validation accuracy:		92.61 %
Epoch 876 of 2000 took 0.035s
  training loss:		0.021892
  validation loss:		0.443314
  validation accuracy:		92.50 %
Epoch 877 of 2000 took 0.035s
  training loss:		0.021584
  validation loss:		0.422597
  validation accuracy:		92.28 %
Epoch 878 of 2000 took 0.035s
  training loss:		0.021854
  validation loss:		0.437058
  validation accuracy:		92.07 %
Epoch 879 of 2000 took 0.035s
  training loss:		0.022110
  validation loss:		0.437636
  validation accuracy:		92.07 %
Epoch 880 of 2000 took 0.035s
  training loss:		0.020804
  validation loss:		0.441059
  validation accuracy:		92.07 %
Epoch 881 of 2000 took 0.035s
  training loss:		0.022218
  validation loss:		0.439523
  validation accuracy:		92.07 %
Epoch 882 of 2000 took 0.035s
  training loss:		0.021377
  validation loss:		0.424690
  validation accuracy:		92.61 %
Epoch 883 of 2000 took 0.035s
  training loss:		0.022604
  validation loss:		0.431883
  validation accuracy:		92.39 %
Epoch 884 of 2000 took 0.035s
  training loss:		0.021399
  validation loss:		0.431984
  validation accuracy:		92.28 %
Epoch 885 of 2000 took 0.035s
  training loss:		0.021197
  validation loss:		0.435237
  validation accuracy:		92.17 %
Epoch 886 of 2000 took 0.035s
  training loss:		0.021297
  validation loss:		0.426468
  validation accuracy:		92.28 %
Epoch 887 of 2000 took 0.035s
  training loss:		0.021435
  validation loss:		0.436688
  validation accuracy:		92.28 %
Epoch 888 of 2000 took 0.035s
  training loss:		0.021184
  validation loss:		0.449531
  validation accuracy:		91.96 %
Epoch 889 of 2000 took 0.035s
  training loss:		0.021338
  validation loss:		0.450656
  validation accuracy:		91.85 %
Epoch 890 of 2000 took 0.035s
  training loss:		0.019976
  validation loss:		0.431754
  validation accuracy:		92.17 %
Epoch 891 of 2000 took 0.035s
  training loss:		0.021289
  validation loss:		0.441894
  validation accuracy:		92.07 %
Epoch 892 of 2000 took 0.035s
  training loss:		0.020523
  validation loss:		0.437142
  validation accuracy:		92.39 %
Epoch 893 of 2000 took 0.035s
  training loss:		0.020038
  validation loss:		0.437255
  validation accuracy:		92.28 %
Epoch 894 of 2000 took 0.035s
  training loss:		0.020779
  validation loss:		0.436662
  validation accuracy:		92.39 %
Epoch 895 of 2000 took 0.035s
  training loss:		0.020077
  validation loss:		0.437166
  validation accuracy:		92.07 %
Epoch 896 of 2000 took 0.035s
  training loss:		0.020748
  validation loss:		0.446416
  validation accuracy:		92.07 %
Epoch 897 of 2000 took 0.035s
  training loss:		0.021002
  validation loss:		0.446015
  validation accuracy:		92.07 %
Epoch 898 of 2000 took 0.035s
  training loss:		0.020453
  validation loss:		0.441424
  validation accuracy:		92.07 %
Epoch 899 of 2000 took 0.035s
  training loss:		0.020790
  validation loss:		0.439292
  validation accuracy:		92.28 %
Epoch 900 of 2000 took 0.035s
  training loss:		0.019820
  validation loss:		0.430894
  validation accuracy:		92.61 %
Epoch 901 of 2000 took 0.035s
  training loss:		0.020454
  validation loss:		0.446169
  validation accuracy:		92.28 %
Epoch 902 of 2000 took 0.035s
  training loss:		0.020865
  validation loss:		0.431030
  validation accuracy:		92.50 %
Epoch 903 of 2000 took 0.035s
  training loss:		0.020557
  validation loss:		0.440588
  validation accuracy:		92.17 %
Epoch 904 of 2000 took 0.035s
  training loss:		0.020639
  validation loss:		0.437749
  validation accuracy:		92.07 %
Epoch 905 of 2000 took 0.035s
  training loss:		0.019830
  validation loss:		0.450495
  validation accuracy:		91.96 %
Epoch 906 of 2000 took 0.035s
  training loss:		0.020784
  validation loss:		0.449690
  validation accuracy:		91.96 %
Epoch 907 of 2000 took 0.035s
  training loss:		0.020617
  validation loss:		0.453219
  validation accuracy:		91.85 %
Epoch 908 of 2000 took 0.035s
  training loss:		0.020344
  validation loss:		0.446720
  validation accuracy:		91.85 %
Epoch 909 of 2000 took 0.035s
  training loss:		0.020522
  validation loss:		0.452794
  validation accuracy:		91.96 %
Epoch 910 of 2000 took 0.035s
  training loss:		0.020487
  validation loss:		0.448309
  validation accuracy:		92.07 %
Epoch 911 of 2000 took 0.035s
  training loss:		0.019658
  validation loss:		0.449487
  validation accuracy:		91.96 %
Epoch 912 of 2000 took 0.035s
  training loss:		0.020006
  validation loss:		0.464038
  validation accuracy:		91.85 %
Epoch 913 of 2000 took 0.035s
  training loss:		0.020365
  validation loss:		0.451404
  validation accuracy:		92.07 %
Epoch 914 of 2000 took 0.035s
  training loss:		0.019322
  validation loss:		0.437535
  validation accuracy:		92.17 %
Epoch 915 of 2000 took 0.035s
  training loss:		0.019017
  validation loss:		0.443399
  validation accuracy:		92.17 %
Epoch 916 of 2000 took 0.035s
  training loss:		0.019493
  validation loss:		0.448485
  validation accuracy:		92.17 %
Epoch 917 of 2000 took 0.035s
  training loss:		0.020406
  validation loss:		0.442982
  validation accuracy:		92.28 %
Epoch 918 of 2000 took 0.035s
  training loss:		0.020236
  validation loss:		0.449418
  validation accuracy:		92.07 %
Epoch 919 of 2000 took 0.035s
  training loss:		0.019566
  validation loss:		0.465697
  validation accuracy:		91.96 %
Epoch 920 of 2000 took 0.035s
  training loss:		0.019324
  validation loss:		0.446390
  validation accuracy:		92.07 %
Epoch 921 of 2000 took 0.035s
  training loss:		0.019766
  validation loss:		0.458016
  validation accuracy:		91.96 %
Epoch 922 of 2000 took 0.035s
  training loss:		0.019808
  validation loss:		0.451544
  validation accuracy:		92.17 %
Epoch 923 of 2000 took 0.035s
  training loss:		0.019275
  validation loss:		0.440985
  validation accuracy:		92.50 %
Epoch 924 of 2000 took 0.035s
  training loss:		0.020213
  validation loss:		0.451138
  validation accuracy:		92.07 %
Epoch 925 of 2000 took 0.035s
  training loss:		0.019847
  validation loss:		0.463830
  validation accuracy:		91.96 %
Epoch 926 of 2000 took 0.035s
  training loss:		0.019490
  validation loss:		0.465384
  validation accuracy:		91.85 %
Epoch 927 of 2000 took 0.035s
  training loss:		0.019454
  validation loss:		0.453015
  validation accuracy:		91.96 %
Epoch 928 of 2000 took 0.035s
  training loss:		0.019445
  validation loss:		0.447093
  validation accuracy:		92.17 %
Epoch 929 of 2000 took 0.035s
  training loss:		0.018283
  validation loss:		0.441859
  validation accuracy:		92.17 %
Epoch 930 of 2000 took 0.035s
  training loss:		0.019734
  validation loss:		0.447423
  validation accuracy:		92.50 %
Epoch 931 of 2000 took 0.035s
  training loss:		0.019646
  validation loss:		0.449965
  validation accuracy:		91.96 %
Epoch 932 of 2000 took 0.035s
  training loss:		0.018887
  validation loss:		0.451895
  validation accuracy:		92.07 %
Epoch 933 of 2000 took 0.035s
  training loss:		0.017250
  validation loss:		0.454079
  validation accuracy:		92.07 %
Epoch 934 of 2000 took 0.035s
  training loss:		0.019150
  validation loss:		0.455937
  validation accuracy:		91.85 %
Epoch 935 of 2000 took 0.035s
  training loss:		0.018337
  validation loss:		0.464325
  validation accuracy:		91.74 %
Epoch 936 of 2000 took 0.035s
  training loss:		0.019400
  validation loss:		0.460830
  validation accuracy:		91.96 %
Epoch 937 of 2000 took 0.035s
  training loss:		0.019095
  validation loss:		0.453343
  validation accuracy:		92.17 %
Epoch 938 of 2000 took 0.035s
  training loss:		0.018355
  validation loss:		0.453302
  validation accuracy:		92.28 %
Epoch 939 of 2000 took 0.035s
  training loss:		0.017865
  validation loss:		0.451456
  validation accuracy:		91.85 %
Epoch 940 of 2000 took 0.035s
  training loss:		0.018887
  validation loss:		0.464780
  validation accuracy:		91.96 %
Epoch 941 of 2000 took 0.035s
  training loss:		0.018095
  validation loss:		0.470064
  validation accuracy:		91.96 %
Epoch 942 of 2000 took 0.035s
  training loss:		0.019119
  validation loss:		0.453936
  validation accuracy:		92.17 %
Epoch 943 of 2000 took 0.035s
  training loss:		0.018805
  validation loss:		0.451672
  validation accuracy:		92.17 %
Epoch 944 of 2000 took 0.035s
  training loss:		0.018205
  validation loss:		0.456847
  validation accuracy:		92.28 %
Epoch 945 of 2000 took 0.035s
  training loss:		0.018476
  validation loss:		0.461301
  validation accuracy:		92.17 %
Epoch 946 of 2000 took 0.035s
  training loss:		0.017958
  validation loss:		0.456588
  validation accuracy:		92.17 %
Epoch 947 of 2000 took 0.035s
  training loss:		0.018711
  validation loss:		0.452157
  validation accuracy:		92.39 %
Epoch 948 of 2000 took 0.035s
  training loss:		0.018285
  validation loss:		0.460287
  validation accuracy:		92.17 %
Epoch 949 of 2000 took 0.035s
  training loss:		0.018798
  validation loss:		0.457763
  validation accuracy:		91.85 %
Epoch 950 of 2000 took 0.035s
  training loss:		0.017860
  validation loss:		0.459863
  validation accuracy:		92.17 %
Epoch 951 of 2000 took 0.035s
  training loss:		0.017490
  validation loss:		0.475836
  validation accuracy:		91.63 %
Epoch 952 of 2000 took 0.037s
  training loss:		0.017541
  validation loss:		0.456858
  validation accuracy:		92.17 %
Epoch 953 of 2000 took 0.035s
  training loss:		0.017911
  validation loss:		0.477363
  validation accuracy:		91.63 %
Epoch 954 of 2000 took 0.035s
  training loss:		0.017507
  validation loss:		0.455621
  validation accuracy:		92.39 %
Epoch 955 of 2000 took 0.035s
  training loss:		0.018003
  validation loss:		0.451631
  validation accuracy:		92.17 %
Epoch 956 of 2000 took 0.035s
  training loss:		0.018030
  validation loss:		0.463093
  validation accuracy:		91.74 %
Epoch 957 of 2000 took 0.035s
  training loss:		0.017961
  validation loss:		0.461358
  validation accuracy:		92.17 %
Epoch 958 of 2000 took 0.035s
  training loss:		0.017482
  validation loss:		0.468786
  validation accuracy:		91.85 %
Epoch 959 of 2000 took 0.035s
  training loss:		0.017687
  validation loss:		0.452083
  validation accuracy:		92.39 %
Epoch 960 of 2000 took 0.035s
  training loss:		0.018005
  validation loss:		0.454071
  validation accuracy:		92.07 %
Epoch 961 of 2000 took 0.035s
  training loss:		0.016949
  validation loss:		0.475576
  validation accuracy:		91.74 %
Epoch 962 of 2000 took 0.035s
  training loss:		0.017768
  validation loss:		0.456862
  validation accuracy:		92.07 %
Epoch 963 of 2000 took 0.035s
  training loss:		0.017016
  validation loss:		0.460024
  validation accuracy:		92.17 %
Epoch 964 of 2000 took 0.035s
  training loss:		0.017655
  validation loss:		0.464494
  validation accuracy:		92.17 %
Epoch 965 of 2000 took 0.035s
  training loss:		0.017877
  validation loss:		0.473804
  validation accuracy:		91.74 %
Epoch 966 of 2000 took 0.035s
  training loss:		0.017341
  validation loss:		0.461313
  validation accuracy:		92.28 %
Epoch 967 of 2000 took 0.035s
  training loss:		0.017382
  validation loss:		0.464499
  validation accuracy:		91.74 %
Epoch 968 of 2000 took 0.035s
  training loss:		0.016871
  validation loss:		0.489197
  validation accuracy:		91.63 %
Epoch 969 of 2000 took 0.035s
  training loss:		0.016961
  validation loss:		0.459014
  validation accuracy:		92.28 %
Epoch 970 of 2000 took 0.035s
  training loss:		0.017273
  validation loss:		0.463770
  validation accuracy:		92.07 %
Epoch 971 of 2000 took 0.035s
  training loss:		0.017156
  validation loss:		0.455849
  validation accuracy:		92.17 %
Epoch 972 of 2000 took 0.035s
  training loss:		0.016954
  validation loss:		0.468680
  validation accuracy:		91.74 %
Epoch 973 of 2000 took 0.035s
  training loss:		0.017717
  validation loss:		0.471680
  validation accuracy:		92.07 %
Epoch 974 of 2000 took 0.035s
  training loss:		0.017285
  validation loss:		0.471384
  validation accuracy:		91.74 %
Epoch 975 of 2000 took 0.035s
  training loss:		0.016573
  validation loss:		0.472171
  validation accuracy:		91.96 %
Epoch 976 of 2000 took 0.035s
  training loss:		0.015956
  validation loss:		0.476451
  validation accuracy:		91.74 %
Epoch 977 of 2000 took 0.035s
  training loss:		0.016990
  validation loss:		0.471341
  validation accuracy:		91.63 %
Epoch 978 of 2000 took 0.035s
  training loss:		0.016927
  validation loss:		0.475222
  validation accuracy:		91.74 %
Epoch 979 of 2000 took 0.035s
  training loss:		0.017105
  validation loss:		0.478613
  validation accuracy:		91.85 %
Epoch 980 of 2000 took 0.035s
  training loss:		0.016402
  validation loss:		0.466143
  validation accuracy:		92.17 %
Epoch 981 of 2000 took 0.035s
  training loss:		0.015865
  validation loss:		0.468792
  validation accuracy:		91.85 %
Epoch 982 of 2000 took 0.035s
  training loss:		0.016544
  validation loss:		0.470058
  validation accuracy:		91.96 %
Epoch 983 of 2000 took 0.035s
  training loss:		0.016849
  validation loss:		0.474585
  validation accuracy:		91.74 %
Epoch 984 of 2000 took 0.035s
  training loss:		0.015795
  validation loss:		0.470707
  validation accuracy:		92.07 %
Epoch 985 of 2000 took 0.035s
  training loss:		0.016562
  validation loss:		0.472266
  validation accuracy:		91.63 %
Epoch 986 of 2000 took 0.035s
  training loss:		0.016456
  validation loss:		0.480648
  validation accuracy:		91.96 %
Epoch 987 of 2000 took 0.035s
  training loss:		0.016569
  validation loss:		0.477226
  validation accuracy:		91.96 %
Epoch 988 of 2000 took 0.035s
  training loss:		0.016246
  validation loss:		0.470411
  validation accuracy:		91.85 %
Epoch 989 of 2000 took 0.035s
  training loss:		0.016152
  validation loss:		0.490375
  validation accuracy:		91.96 %
Epoch 990 of 2000 took 0.035s
  training loss:		0.015135
  validation loss:		0.465617
  validation accuracy:		91.85 %
Epoch 991 of 2000 took 0.035s
  training loss:		0.015528
  validation loss:		0.472600
  validation accuracy:		91.85 %
Epoch 992 of 2000 took 0.035s
  training loss:		0.016280
  validation loss:		0.476826
  validation accuracy:		91.85 %
Epoch 993 of 2000 took 0.035s
  training loss:		0.016546
  validation loss:		0.463605
  validation accuracy:		92.50 %
Epoch 994 of 2000 took 0.035s
  training loss:		0.016349
  validation loss:		0.472108
  validation accuracy:		91.96 %
Epoch 995 of 2000 took 0.035s
  training loss:		0.015494
  validation loss:		0.476135
  validation accuracy:		91.85 %
Epoch 996 of 2000 took 0.035s
  training loss:		0.015607
  validation loss:		0.470870
  validation accuracy:		92.17 %
Epoch 997 of 2000 took 0.035s
  training loss:		0.015904
  validation loss:		0.464476
  validation accuracy:		92.17 %
Epoch 998 of 2000 took 0.035s
  training loss:		0.015960
  validation loss:		0.478540
  validation accuracy:		91.74 %
Epoch 999 of 2000 took 0.035s
  training loss:		0.016220
  validation loss:		0.465708
  validation accuracy:		92.50 %
Epoch 1000 of 2000 took 0.035s
  training loss:		0.016102
  validation loss:		0.471647
  validation accuracy:		92.07 %
Epoch 1001 of 2000 took 0.035s
  training loss:		0.015272
  validation loss:		0.485854
  validation accuracy:		91.63 %
Epoch 1002 of 2000 took 0.035s
  training loss:		0.014993
  validation loss:		0.491306
  validation accuracy:		91.96 %
Epoch 1003 of 2000 took 0.035s
  training loss:		0.015619
  validation loss:		0.469769
  validation accuracy:		92.28 %
Epoch 1004 of 2000 took 0.035s
  training loss:		0.014312
  validation loss:		0.466690
  validation accuracy:		92.28 %
Epoch 1005 of 2000 took 0.035s
  training loss:		0.015659
  validation loss:		0.479595
  validation accuracy:		91.74 %
Epoch 1006 of 2000 took 0.035s
  training loss:		0.015811
  validation loss:		0.488222
  validation accuracy:		91.85 %
Epoch 1007 of 2000 took 0.035s
  training loss:		0.015082
  validation loss:		0.470873
  validation accuracy:		91.52 %
Epoch 1008 of 2000 took 0.035s
  training loss:		0.015344
  validation loss:		0.472960
  validation accuracy:		91.96 %
Epoch 1009 of 2000 took 0.035s
  training loss:		0.015247
  validation loss:		0.475222
  validation accuracy:		92.28 %
Epoch 1010 of 2000 took 0.035s
  training loss:		0.015506
  validation loss:		0.472496
  validation accuracy:		91.85 %
Epoch 1011 of 2000 took 0.035s
  training loss:		0.014017
  validation loss:		0.480993
  validation accuracy:		91.96 %
Epoch 1012 of 2000 took 0.035s
  training loss:		0.014936
  validation loss:		0.482201
  validation accuracy:		91.74 %
Epoch 1013 of 2000 took 0.035s
  training loss:		0.015408
  validation loss:		0.477331
  validation accuracy:		91.63 %
Epoch 1014 of 2000 took 0.035s
  training loss:		0.015330
  validation loss:		0.478637
  validation accuracy:		91.74 %
Epoch 1015 of 2000 took 0.035s
  training loss:		0.015522
  validation loss:		0.483499
  validation accuracy:		91.96 %
Epoch 1016 of 2000 took 0.036s
  training loss:		0.015072
  validation loss:		0.468570
  validation accuracy:		92.50 %
Epoch 1017 of 2000 took 0.035s
  training loss:		0.014709
  validation loss:		0.485656
  validation accuracy:		91.85 %
Epoch 1018 of 2000 took 0.035s
  training loss:		0.015207
  validation loss:		0.490511
  validation accuracy:		91.74 %
Epoch 1019 of 2000 took 0.035s
  training loss:		0.014976
  validation loss:		0.484567
  validation accuracy:		91.85 %
Epoch 1020 of 2000 took 0.035s
  training loss:		0.014627
  validation loss:		0.484297
  validation accuracy:		91.85 %
Epoch 1021 of 2000 took 0.035s
  training loss:		0.015043
  validation loss:		0.479207
  validation accuracy:		92.17 %
Epoch 1022 of 2000 took 0.035s
  training loss:		0.014723
  validation loss:		0.495984
  validation accuracy:		91.74 %
Epoch 1023 of 2000 took 0.035s
  training loss:		0.014827
  validation loss:		0.483166
  validation accuracy:		91.63 %
Epoch 1024 of 2000 took 0.035s
  training loss:		0.014496
  validation loss:		0.477681
  validation accuracy:		91.96 %
Epoch 1025 of 2000 took 0.035s
  training loss:		0.014667
  validation loss:		0.494195
  validation accuracy:		91.74 %
Epoch 1026 of 2000 took 0.035s
  training loss:		0.014812
  validation loss:		0.485705
  validation accuracy:		91.52 %
Epoch 1027 of 2000 took 0.035s
  training loss:		0.014614
  validation loss:		0.477830
  validation accuracy:		92.07 %
Epoch 1028 of 2000 took 0.035s
  training loss:		0.014719
  validation loss:		0.490375
  validation accuracy:		91.74 %
Epoch 1029 of 2000 took 0.035s
  training loss:		0.015133
  validation loss:		0.473723
  validation accuracy:		92.28 %
Epoch 1030 of 2000 took 0.035s
  training loss:		0.013472
  validation loss:		0.483116
  validation accuracy:		91.85 %
Epoch 1031 of 2000 took 0.035s
  training loss:		0.014554
  validation loss:		0.481042
  validation accuracy:		91.74 %
Epoch 1032 of 2000 took 0.035s
  training loss:		0.013831
  validation loss:		0.499933
  validation accuracy:		91.74 %
Epoch 1033 of 2000 took 0.035s
  training loss:		0.015050
  validation loss:		0.486694
  validation accuracy:		91.85 %
Epoch 1034 of 2000 took 0.035s
  training loss:		0.014684
  validation loss:		0.491071
  validation accuracy:		91.74 %
Epoch 1035 of 2000 took 0.035s
  training loss:		0.014481
  validation loss:		0.494050
  validation accuracy:		91.85 %
Epoch 1036 of 2000 took 0.035s
  training loss:		0.014641
  validation loss:		0.484299
  validation accuracy:		91.63 %
Epoch 1037 of 2000 took 0.035s
  training loss:		0.013853
  validation loss:		0.487162
  validation accuracy:		91.85 %
Epoch 1038 of 2000 took 0.035s
  training loss:		0.013226
  validation loss:		0.496394
  validation accuracy:		91.63 %
Epoch 1039 of 2000 took 0.035s
  training loss:		0.014420
  validation loss:		0.497442
  validation accuracy:		91.74 %
Epoch 1040 of 2000 took 0.035s
  training loss:		0.014336
  validation loss:		0.488968
  validation accuracy:		91.74 %
Epoch 1041 of 2000 took 0.035s
  training loss:		0.013370
  validation loss:		0.480770
  validation accuracy:		91.74 %
Epoch 1042 of 2000 took 0.035s
  training loss:		0.014377
  validation loss:		0.499343
  validation accuracy:		91.74 %
Epoch 1043 of 2000 took 0.035s
  training loss:		0.014582
  validation loss:		0.487823
  validation accuracy:		91.85 %
Epoch 1044 of 2000 took 0.036s
  training loss:		0.014002
  validation loss:		0.485339
  validation accuracy:		92.07 %
Epoch 1045 of 2000 took 0.035s
  training loss:		0.014465
  validation loss:		0.487423
  validation accuracy:		91.74 %
Epoch 1046 of 2000 took 0.035s
  training loss:		0.013668
  validation loss:		0.503611
  validation accuracy:		91.74 %
Epoch 1047 of 2000 took 0.035s
  training loss:		0.013833
  validation loss:		0.492672
  validation accuracy:		91.96 %
Epoch 1048 of 2000 took 0.035s
  training loss:		0.013731
  validation loss:		0.498324
  validation accuracy:		91.63 %
Epoch 1049 of 2000 took 0.035s
  training loss:		0.013791
  validation loss:		0.496846
  validation accuracy:		91.74 %
Epoch 1050 of 2000 took 0.035s
  training loss:		0.013900
  validation loss:		0.476380
  validation accuracy:		92.50 %
Epoch 1051 of 2000 took 0.035s
  training loss:		0.013827
  validation loss:		0.493918
  validation accuracy:		91.74 %
Epoch 1052 of 2000 took 0.035s
  training loss:		0.013707
  validation loss:		0.491941
  validation accuracy:		91.63 %
Epoch 1053 of 2000 took 0.035s
  training loss:		0.013826
  validation loss:		0.500332
  validation accuracy:		91.63 %
Epoch 1054 of 2000 took 0.035s
  training loss:		0.013440
  validation loss:		0.490129
  validation accuracy:		92.07 %
Epoch 1055 of 2000 took 0.035s
  training loss:		0.013354
  validation loss:		0.499537
  validation accuracy:		91.63 %
Epoch 1056 of 2000 took 0.035s
  training loss:		0.013690
  validation loss:		0.492518
  validation accuracy:		91.85 %
Epoch 1057 of 2000 took 0.035s
  training loss:		0.013672
  validation loss:		0.500368
  validation accuracy:		91.74 %
Epoch 1058 of 2000 took 0.035s
  training loss:		0.012336
  validation loss:		0.489903
  validation accuracy:		91.85 %
Epoch 1059 of 2000 took 0.035s
  training loss:		0.012857
  validation loss:		0.502563
  validation accuracy:		91.85 %
Epoch 1060 of 2000 took 0.035s
  training loss:		0.013836
  validation loss:		0.483550
  validation accuracy:		91.74 %
Epoch 1061 of 2000 took 0.035s
  training loss:		0.013740
  validation loss:		0.507137
  validation accuracy:		91.63 %
Epoch 1062 of 2000 took 0.035s
  training loss:		0.013625
  validation loss:		0.500722
  validation accuracy:		91.52 %
Epoch 1063 of 2000 took 0.035s
  training loss:		0.013126
  validation loss:		0.495170
  validation accuracy:		91.63 %
Epoch 1064 of 2000 took 0.035s
  training loss:		0.013191
  validation loss:		0.505916
  validation accuracy:		91.63 %
Epoch 1065 of 2000 took 0.035s
  training loss:		0.013018
  validation loss:		0.503365
  validation accuracy:		91.74 %
Epoch 1066 of 2000 took 0.035s
  training loss:		0.013063
  validation loss:		0.506372
  validation accuracy:		91.63 %
Epoch 1067 of 2000 took 0.035s
  training loss:		0.013365
  validation loss:		0.503280
  validation accuracy:		91.74 %
Epoch 1068 of 2000 took 0.035s
  training loss:		0.013279
  validation loss:		0.496355
  validation accuracy:		91.52 %
Epoch 1069 of 2000 took 0.035s
  training loss:		0.013217
  validation loss:		0.492542
  validation accuracy:		91.74 %
Epoch 1070 of 2000 took 0.035s
  training loss:		0.012798
  validation loss:		0.507103
  validation accuracy:		91.74 %
Epoch 1071 of 2000 took 0.035s
  training loss:		0.013314
  validation loss:		0.490190
  validation accuracy:		91.74 %
Epoch 1072 of 2000 took 0.035s
  training loss:		0.011801
  validation loss:		0.498654
  validation accuracy:		91.63 %
Epoch 1073 of 2000 took 0.035s
  training loss:		0.012087
  validation loss:		0.499983
  validation accuracy:		91.63 %
Epoch 1074 of 2000 took 0.035s
  training loss:		0.012861
  validation loss:		0.495725
  validation accuracy:		92.17 %
Epoch 1075 of 2000 took 0.035s
  training loss:		0.012958
  validation loss:		0.504070
  validation accuracy:		91.74 %
Epoch 1076 of 2000 took 0.035s
  training loss:		0.012612
  validation loss:		0.503393
  validation accuracy:		91.96 %
Epoch 1077 of 2000 took 0.035s
  training loss:		0.012937
  validation loss:		0.513333
  validation accuracy:		91.85 %
Epoch 1078 of 2000 took 0.035s
  training loss:		0.012986
  validation loss:		0.502004
  validation accuracy:		91.74 %
Epoch 1079 of 2000 took 0.035s
  training loss:		0.012719
  validation loss:		0.498700
  validation accuracy:		91.85 %
Epoch 1080 of 2000 took 0.035s
  training loss:		0.012916
  validation loss:		0.501798
  validation accuracy:		91.63 %
Epoch 1081 of 2000 took 0.035s
  training loss:		0.013068
  validation loss:		0.506862
  validation accuracy:		91.85 %
Epoch 1082 of 2000 took 0.035s
  training loss:		0.012552
  validation loss:		0.505814
  validation accuracy:		91.52 %
Epoch 1083 of 2000 took 0.035s
  training loss:		0.012909
  validation loss:		0.499411
  validation accuracy:		91.85 %
Epoch 1084 of 2000 took 0.035s
  training loss:		0.012570
  validation loss:		0.501020
  validation accuracy:		91.74 %
Epoch 1085 of 2000 took 0.035s
  training loss:		0.012772
  validation loss:		0.523065
  validation accuracy:		91.63 %
Epoch 1086 of 2000 took 0.035s
  training loss:		0.012777
  validation loss:		0.502053
  validation accuracy:		91.85 %
Epoch 1087 of 2000 took 0.035s
  training loss:		0.012856
  validation loss:		0.488952
  validation accuracy:		91.85 %
Epoch 1088 of 2000 took 0.035s
  training loss:		0.012756
  validation loss:		0.506043
  validation accuracy:		91.85 %
Epoch 1089 of 2000 took 0.035s
  training loss:		0.012398
  validation loss:		0.502102
  validation accuracy:		91.74 %
Epoch 1090 of 2000 took 0.035s
  training loss:		0.012311
  validation loss:		0.494843
  validation accuracy:		91.74 %
Epoch 1091 of 2000 took 0.035s
  training loss:		0.012754
  validation loss:		0.507611
  validation accuracy:		91.63 %
Epoch 1092 of 2000 took 0.035s
  training loss:		0.012785
  validation loss:		0.506391
  validation accuracy:		91.85 %
Epoch 1093 of 2000 took 0.035s
  training loss:		0.012176
  validation loss:		0.505816
  validation accuracy:		91.52 %
Epoch 1094 of 2000 took 0.035s
  training loss:		0.012103
  validation loss:		0.504821
  validation accuracy:		91.96 %
Epoch 1095 of 2000 took 0.035s
  training loss:		0.011387
  validation loss:		0.508881
  validation accuracy:		91.41 %
Epoch 1096 of 2000 took 0.035s
  training loss:		0.012259
  validation loss:		0.507668
  validation accuracy:		91.74 %
Epoch 1097 of 2000 took 0.035s
  training loss:		0.011967
  validation loss:		0.498787
  validation accuracy:		91.63 %
Epoch 1098 of 2000 took 0.035s
  training loss:		0.012583
  validation loss:		0.500522
  validation accuracy:		91.63 %
Epoch 1099 of 2000 took 0.035s
  training loss:		0.012355
  validation loss:		0.516003
  validation accuracy:		91.52 %
Epoch 1100 of 2000 took 0.035s
  training loss:		0.011873
  validation loss:		0.503154
  validation accuracy:		91.85 %
Epoch 1101 of 2000 took 0.036s
  training loss:		0.011992
  validation loss:		0.506428
  validation accuracy:		91.74 %
Epoch 1102 of 2000 took 0.035s
  training loss:		0.011959
  validation loss:		0.519203
  validation accuracy:		91.41 %
Epoch 1103 of 2000 took 0.035s
  training loss:		0.011760
  validation loss:		0.515623
  validation accuracy:		91.41 %
Epoch 1104 of 2000 took 0.035s
  training loss:		0.011403
  validation loss:		0.504796
  validation accuracy:		91.85 %
Epoch 1105 of 2000 took 0.035s
  training loss:		0.011740
  validation loss:		0.515380
  validation accuracy:		91.74 %
Epoch 1106 of 2000 took 0.035s
  training loss:		0.011124
  validation loss:		0.503357
  validation accuracy:		91.52 %
Epoch 1107 of 2000 took 0.035s
  training loss:		0.011968
  validation loss:		0.516406
  validation accuracy:		91.74 %
Epoch 1108 of 2000 took 0.035s
  training loss:		0.011787
  validation loss:		0.510395
  validation accuracy:		91.63 %
Epoch 1109 of 2000 took 0.035s
  training loss:		0.012129
  validation loss:		0.513459
  validation accuracy:		91.74 %
Epoch 1110 of 2000 took 0.035s
  training loss:		0.011682
  validation loss:		0.505821
  validation accuracy:		91.52 %
Epoch 1111 of 2000 took 0.035s
  training loss:		0.011827
  validation loss:		0.510937
  validation accuracy:		91.63 %
Epoch 1112 of 2000 took 0.035s
  training loss:		0.011589
  validation loss:		0.505518
  validation accuracy:		92.07 %
Epoch 1113 of 2000 took 0.035s
  training loss:		0.011952
  validation loss:		0.509681
  validation accuracy:		91.41 %
Epoch 1114 of 2000 took 0.035s
  training loss:		0.011591
  validation loss:		0.523530
  validation accuracy:		91.52 %
Epoch 1115 of 2000 took 0.035s
  training loss:		0.011412
  validation loss:		0.511783
  validation accuracy:		91.74 %
Epoch 1116 of 2000 took 0.035s
  training loss:		0.011454
  validation loss:		0.501790
  validation accuracy:		91.74 %
Epoch 1117 of 2000 took 0.035s
  training loss:		0.011606
  validation loss:		0.516733
  validation accuracy:		91.63 %
Epoch 1118 of 2000 took 0.035s
  training loss:		0.010723
  validation loss:		0.506492
  validation accuracy:		91.96 %
Epoch 1119 of 2000 took 0.035s
  training loss:		0.011748
  validation loss:		0.518051
  validation accuracy:		91.85 %
Epoch 1120 of 2000 took 0.035s
  training loss:		0.011603
  validation loss:		0.508328
  validation accuracy:		91.63 %
Epoch 1121 of 2000 took 0.035s
  training loss:		0.011303
  validation loss:		0.501250
  validation accuracy:		91.74 %
Epoch 1122 of 2000 took 0.035s
  training loss:		0.011290
  validation loss:		0.522726
  validation accuracy:		91.74 %
Epoch 1123 of 2000 took 0.035s
  training loss:		0.010889
  validation loss:		0.524708
  validation accuracy:		91.63 %
Epoch 1124 of 2000 took 0.035s
  training loss:		0.011300
  validation loss:		0.502186
  validation accuracy:		91.74 %
Epoch 1125 of 2000 took 0.035s
  training loss:		0.011007
  validation loss:		0.522083
  validation accuracy:		91.63 %
Epoch 1126 of 2000 took 0.035s
  training loss:		0.011632
  validation loss:		0.511475
  validation accuracy:		91.63 %
Epoch 1127 of 2000 took 0.035s
  training loss:		0.011089
  validation loss:		0.511247
  validation accuracy:		92.07 %
Epoch 1128 of 2000 took 0.035s
  training loss:		0.011320
  validation loss:		0.519248
  validation accuracy:		91.74 %
Epoch 1129 of 2000 took 0.035s
  training loss:		0.010967
  validation loss:		0.506191
  validation accuracy:		91.74 %
Epoch 1130 of 2000 took 0.035s
  training loss:		0.010279
  validation loss:		0.509578
  validation accuracy:		91.96 %
Epoch 1131 of 2000 took 0.035s
  training loss:		0.010900
  validation loss:		0.523005
  validation accuracy:		91.41 %
Epoch 1132 of 2000 took 0.035s
  training loss:		0.011130
  validation loss:		0.505899
  validation accuracy:		91.96 %
Epoch 1133 of 2000 took 0.035s
  training loss:		0.011163
  validation loss:		0.513437
  validation accuracy:		91.63 %
Epoch 1134 of 2000 took 0.035s
  training loss:		0.010926
  validation loss:		0.509608
  validation accuracy:		91.85 %
Epoch 1135 of 2000 took 0.035s
  training loss:		0.010953
  validation loss:		0.527493
  validation accuracy:		91.63 %
Epoch 1136 of 2000 took 0.035s
  training loss:		0.011544
  validation loss:		0.512937
  validation accuracy:		91.41 %
Epoch 1137 of 2000 took 0.035s
  training loss:		0.010880
  validation loss:		0.535372
  validation accuracy:		91.74 %
Epoch 1138 of 2000 took 0.035s
  training loss:		0.011160
  validation loss:		0.525567
  validation accuracy:		91.52 %
Epoch 1139 of 2000 took 0.035s
  training loss:		0.011939
  validation loss:		0.528228
  validation accuracy:		91.41 %
Epoch 1140 of 2000 took 0.035s
  training loss:		0.011761
  validation loss:		0.525239
  validation accuracy:		91.63 %
Epoch 1141 of 2000 took 0.035s
  training loss:		0.010544
  validation loss:		0.510701
  validation accuracy:		91.96 %
Epoch 1142 of 2000 took 0.035s
  training loss:		0.010748
  validation loss:		0.514771
  validation accuracy:		91.52 %
Epoch 1143 of 2000 took 0.035s
  training loss:		0.011063
  validation loss:		0.508127
  validation accuracy:		91.96 %
Epoch 1144 of 2000 took 0.035s
  training loss:		0.010333
  validation loss:		0.521281
  validation accuracy:		91.52 %
Epoch 1145 of 2000 took 0.035s
  training loss:		0.009889
  validation loss:		0.520462
  validation accuracy:		91.52 %
Epoch 1146 of 2000 took 0.035s
  training loss:		0.010821
  validation loss:		0.515685
  validation accuracy:		91.41 %
Epoch 1147 of 2000 took 0.036s
  training loss:		0.010681
  validation loss:		0.522133
  validation accuracy:		91.52 %
Epoch 1148 of 2000 took 0.035s
  training loss:		0.010288
  validation loss:		0.517978
  validation accuracy:		91.74 %
Epoch 1149 of 2000 took 0.035s
  training loss:		0.010546
  validation loss:		0.509482
  validation accuracy:		91.74 %
Epoch 1150 of 2000 took 0.035s
  training loss:		0.010811
  validation loss:		0.524937
  validation accuracy:		91.74 %
Epoch 1151 of 2000 took 0.035s
  training loss:		0.010152
  validation loss:		0.530534
  validation accuracy:		91.74 %
Epoch 1152 of 2000 took 0.035s
  training loss:		0.010738
  validation loss:		0.512147
  validation accuracy:		91.74 %
Epoch 1153 of 2000 took 0.035s
  training loss:		0.010492
  validation loss:		0.516163
  validation accuracy:		91.74 %
Epoch 1154 of 2000 took 0.035s
  training loss:		0.010882
  validation loss:		0.528009
  validation accuracy:		91.52 %
Epoch 1155 of 2000 took 0.035s
  training loss:		0.010767
  validation loss:		0.539797
  validation accuracy:		91.41 %
Epoch 1156 of 2000 took 0.035s
  training loss:		0.010223
  validation loss:		0.524054
  validation accuracy:		91.74 %
Epoch 1157 of 2000 took 0.035s
  training loss:		0.010552
  validation loss:		0.522500
  validation accuracy:		91.85 %
Epoch 1158 of 2000 took 0.036s
  training loss:		0.010286
  validation loss:		0.522899
  validation accuracy:		91.63 %
Epoch 1159 of 2000 took 0.035s
  training loss:		0.010455
  validation loss:		0.528134
  validation accuracy:		91.85 %
Epoch 1160 of 2000 took 0.035s
  training loss:		0.009918
  validation loss:		0.518459
  validation accuracy:		91.74 %
Epoch 1161 of 2000 took 0.035s
  training loss:		0.010320
  validation loss:		0.522995
  validation accuracy:		91.74 %
Epoch 1162 of 2000 took 0.035s
  training loss:		0.010145
  validation loss:		0.512992
  validation accuracy:		92.07 %
Epoch 1163 of 2000 took 0.035s
  training loss:		0.010772
  validation loss:		0.516939
  validation accuracy:		91.74 %
Epoch 1164 of 2000 took 0.035s
  training loss:		0.010137
  validation loss:		0.527274
  validation accuracy:		91.74 %
Epoch 1165 of 2000 took 0.035s
  training loss:		0.010645
  validation loss:		0.529950
  validation accuracy:		91.85 %
Epoch 1166 of 2000 took 0.035s
  training loss:		0.010141
  validation loss:		0.532048
  validation accuracy:		91.52 %
Epoch 1167 of 2000 took 0.035s
  training loss:		0.010164
  validation loss:		0.534150
  validation accuracy:		91.52 %
Epoch 1168 of 2000 took 0.035s
  training loss:		0.010562
  validation loss:		0.537306
  validation accuracy:		91.96 %
Epoch 1169 of 2000 took 0.035s
  training loss:		0.010051
  validation loss:		0.536982
  validation accuracy:		91.63 %
Epoch 1170 of 2000 took 0.035s
  training loss:		0.009958
  validation loss:		0.523078
  validation accuracy:		91.63 %
Epoch 1171 of 2000 took 0.035s
  training loss:		0.009868
  validation loss:		0.545524
  validation accuracy:		91.52 %
Epoch 1172 of 2000 took 0.035s
  training loss:		0.010161
  validation loss:		0.525914
  validation accuracy:		91.52 %
Epoch 1173 of 2000 took 0.035s
  training loss:		0.009920
  validation loss:		0.528999
  validation accuracy:		91.63 %
Epoch 1174 of 2000 took 0.035s
  training loss:		0.009955
  validation loss:		0.521366
  validation accuracy:		92.17 %
Epoch 1175 of 2000 took 0.035s
  training loss:		0.010246
  validation loss:		0.527093
  validation accuracy:		91.74 %
Epoch 1176 of 2000 took 0.035s
  training loss:		0.009997
  validation loss:		0.536079
  validation accuracy:		91.30 %
Epoch 1177 of 2000 took 0.035s
  training loss:		0.009658
  validation loss:		0.528722
  validation accuracy:		91.52 %
Epoch 1178 of 2000 took 0.035s
  training loss:		0.010800
  validation loss:		0.526621
  validation accuracy:		91.63 %
Epoch 1179 of 2000 took 0.035s
  training loss:		0.010147
  validation loss:		0.536250
  validation accuracy:		91.63 %
Epoch 1180 of 2000 took 0.035s
  training loss:		0.009498
  validation loss:		0.527028
  validation accuracy:		91.30 %
Epoch 1181 of 2000 took 0.035s
  training loss:		0.010139
  validation loss:		0.535010
  validation accuracy:		91.52 %
Epoch 1182 of 2000 took 0.035s
  training loss:		0.009547
  validation loss:		0.527800
  validation accuracy:		91.63 %
Epoch 1183 of 2000 took 0.035s
  training loss:		0.009307
  validation loss:		0.536869
  validation accuracy:		91.20 %
Epoch 1184 of 2000 took 0.035s
  training loss:		0.009575
  validation loss:		0.526746
  validation accuracy:		91.63 %
Epoch 1185 of 2000 took 0.035s
  training loss:		0.009759
  validation loss:		0.520455
  validation accuracy:		91.74 %
Epoch 1186 of 2000 took 0.035s
  training loss:		0.009541
  validation loss:		0.535930
  validation accuracy:		91.63 %
Epoch 1187 of 2000 took 0.035s
  training loss:		0.009581
  validation loss:		0.540704
  validation accuracy:		91.30 %
Epoch 1188 of 2000 took 0.035s
  training loss:		0.009606
  validation loss:		0.534544
  validation accuracy:		91.52 %
Epoch 1189 of 2000 took 0.035s
  training loss:		0.009092
  validation loss:		0.528763
  validation accuracy:		91.52 %
Epoch 1190 of 2000 took 0.035s
  training loss:		0.009243
  validation loss:		0.543737
  validation accuracy:		91.30 %
Epoch 1191 of 2000 took 0.035s
  training loss:		0.009543
  validation loss:		0.536475
  validation accuracy:		91.52 %
Epoch 1192 of 2000 took 0.035s
  training loss:		0.009405
  validation loss:		0.523191
  validation accuracy:		91.74 %
Epoch 1193 of 2000 took 0.035s
  training loss:		0.009541
  validation loss:		0.532556
  validation accuracy:		91.52 %
Epoch 1194 of 2000 took 0.035s
  training loss:		0.009624
  validation loss:		0.532344
  validation accuracy:		91.41 %
Epoch 1195 of 2000 took 0.035s
  training loss:		0.009502
  validation loss:		0.534025
  validation accuracy:		91.63 %
Epoch 1196 of 2000 took 0.035s
  training loss:		0.009753
  validation loss:		0.528196
  validation accuracy:		91.52 %
Epoch 1197 of 2000 took 0.035s
  training loss:		0.009410
  validation loss:		0.538352
  validation accuracy:		91.74 %
Epoch 1198 of 2000 took 0.035s
  training loss:		0.009463
  validation loss:		0.534564
  validation accuracy:		91.63 %
Epoch 1199 of 2000 took 0.035s
  training loss:		0.009081
  validation loss:		0.532270
  validation accuracy:		91.41 %
Epoch 1200 of 2000 took 0.035s
  training loss:		0.009440
  validation loss:		0.538652
  validation accuracy:		91.09 %
Epoch 1201 of 2000 took 0.035s
  training loss:		0.009215
  validation loss:		0.532610
  validation accuracy:		91.63 %
Epoch 1202 of 2000 took 0.035s
  training loss:		0.009059
  validation loss:		0.553833
  validation accuracy:		91.20 %
Epoch 1203 of 2000 took 0.035s
  training loss:		0.009529
  validation loss:		0.539961
  validation accuracy:		91.52 %
Epoch 1204 of 2000 took 0.035s
  training loss:		0.009061
  validation loss:		0.525022
  validation accuracy:		91.85 %
Epoch 1205 of 2000 took 0.035s
  training loss:		0.009176
  validation loss:		0.532371
  validation accuracy:		91.85 %
Epoch 1206 of 2000 took 0.035s
  training loss:		0.009369
  validation loss:		0.536651
  validation accuracy:		91.74 %
Epoch 1207 of 2000 took 0.035s
  training loss:		0.008789
  validation loss:		0.525052
  validation accuracy:		91.74 %
Epoch 1208 of 2000 took 0.035s
  training loss:		0.009193
  validation loss:		0.552742
  validation accuracy:		91.63 %
Epoch 1209 of 2000 took 0.035s
  training loss:		0.009079
  validation loss:		0.534478
  validation accuracy:		91.41 %
Epoch 1210 of 2000 took 0.035s
  training loss:		0.009552
  validation loss:		0.547582
  validation accuracy:		91.41 %
Epoch 1211 of 2000 took 0.035s
  training loss:		0.009385
  validation loss:		0.541902
  validation accuracy:		91.74 %
Epoch 1212 of 2000 took 0.035s
  training loss:		0.009108
  validation loss:		0.536173
  validation accuracy:		91.41 %
Epoch 1213 of 2000 took 0.035s
  training loss:		0.009034
  validation loss:		0.528474
  validation accuracy:		91.74 %
Epoch 1214 of 2000 took 0.035s
  training loss:		0.008985
  validation loss:		0.544926
  validation accuracy:		91.52 %
Epoch 1215 of 2000 took 0.035s
  training loss:		0.009082
  validation loss:		0.544801
  validation accuracy:		91.20 %
Epoch 1216 of 2000 took 0.035s
  training loss:		0.008779
  validation loss:		0.532612
  validation accuracy:		91.41 %
Epoch 1217 of 2000 took 0.035s
  training loss:		0.008827
  validation loss:		0.546719
  validation accuracy:		91.41 %
Epoch 1218 of 2000 took 0.035s
  training loss:		0.008982
  validation loss:		0.540699
  validation accuracy:		91.74 %
Epoch 1219 of 2000 took 0.035s
  training loss:		0.008733
  validation loss:		0.537234
  validation accuracy:		91.20 %
Epoch 1220 of 2000 took 0.035s
  training loss:		0.008834
  validation loss:		0.543887
  validation accuracy:		91.52 %
Epoch 1221 of 2000 took 0.035s
  training loss:		0.008905
  validation loss:		0.544575
  validation accuracy:		91.85 %
Epoch 1222 of 2000 took 0.035s
  training loss:		0.008998
  validation loss:		0.547382
  validation accuracy:		91.41 %
Epoch 1223 of 2000 took 0.035s
  training loss:		0.008987
  validation loss:		0.538017
  validation accuracy:		91.52 %
Epoch 1224 of 2000 took 0.035s
  training loss:		0.008693
  validation loss:		0.546450
  validation accuracy:		91.41 %
Epoch 1225 of 2000 took 0.035s
  training loss:		0.008857
  validation loss:		0.543355
  validation accuracy:		91.63 %
Epoch 1226 of 2000 took 0.035s
  training loss:		0.008762
  validation loss:		0.553958
  validation accuracy:		91.30 %
Epoch 1227 of 2000 took 0.035s
  training loss:		0.008572
  validation loss:		0.539566
  validation accuracy:		91.85 %
Epoch 1228 of 2000 took 0.035s
  training loss:		0.009047
  validation loss:		0.531756
  validation accuracy:		91.41 %
Epoch 1229 of 2000 took 0.035s
  training loss:		0.008942
  validation loss:		0.536897
  validation accuracy:		91.41 %
Epoch 1230 of 2000 took 0.035s
  training loss:		0.008611
  validation loss:		0.544898
  validation accuracy:		91.63 %
Epoch 1231 of 2000 took 0.035s
  training loss:		0.008649
  validation loss:		0.540219
  validation accuracy:		91.41 %
Epoch 1232 of 2000 took 0.035s
  training loss:		0.008610
  validation loss:		0.544335
  validation accuracy:		91.41 %
Epoch 1233 of 2000 took 0.035s
  training loss:		0.008531
  validation loss:		0.540949
  validation accuracy:		91.52 %
Epoch 1234 of 2000 took 0.035s
  training loss:		0.008605
  validation loss:		0.546091
  validation accuracy:		91.52 %
Epoch 1235 of 2000 took 0.035s
  training loss:		0.008448
  validation loss:		0.533451
  validation accuracy:		91.63 %
Epoch 1236 of 2000 took 0.035s
  training loss:		0.008582
  validation loss:		0.549152
  validation accuracy:		91.30 %
Epoch 1237 of 2000 took 0.035s
  training loss:		0.008272
  validation loss:		0.543681
  validation accuracy:		91.20 %
Epoch 1238 of 2000 took 0.035s
  training loss:		0.008541
  validation loss:		0.550274
  validation accuracy:		91.41 %
Epoch 1239 of 2000 took 0.035s
  training loss:		0.008395
  validation loss:		0.546835
  validation accuracy:		91.30 %
Epoch 1240 of 2000 took 0.035s
  training loss:		0.008588
  validation loss:		0.546412
  validation accuracy:		91.74 %
Epoch 1241 of 2000 took 0.035s
  training loss:		0.008394
  validation loss:		0.548921
  validation accuracy:		91.41 %
Epoch 1242 of 2000 took 0.035s
  training loss:		0.008489
  validation loss:		0.543129
  validation accuracy:		91.52 %
Epoch 1243 of 2000 took 0.035s
  training loss:		0.008594
  validation loss:		0.536632
  validation accuracy:		91.74 %
Epoch 1244 of 2000 took 0.035s
  training loss:		0.008448
  validation loss:		0.551522
  validation accuracy:		91.63 %
Epoch 1245 of 2000 took 0.035s
  training loss:		0.008545
  validation loss:		0.551207
  validation accuracy:		91.63 %
Epoch 1246 of 2000 took 0.035s
  training loss:		0.008414
  validation loss:		0.544199
  validation accuracy:		91.52 %
Epoch 1247 of 2000 took 0.035s
  training loss:		0.008322
  validation loss:		0.545279
  validation accuracy:		91.52 %
Epoch 1248 of 2000 took 0.035s
  training loss:		0.008548
  validation loss:		0.543984
  validation accuracy:		91.30 %
Epoch 1249 of 2000 took 0.035s
  training loss:		0.008262
  validation loss:		0.542965
  validation accuracy:		91.52 %
Epoch 1250 of 2000 took 0.035s
  training loss:		0.008460
  validation loss:		0.549941
  validation accuracy:		91.41 %
Epoch 1251 of 2000 took 0.035s
  training loss:		0.008231
  validation loss:		0.548487
  validation accuracy:		91.74 %
Epoch 1252 of 2000 took 0.035s
  training loss:		0.008140
  validation loss:		0.559314
  validation accuracy:		91.30 %
Epoch 1253 of 2000 took 0.035s
  training loss:		0.008148
  validation loss:		0.544680
  validation accuracy:		91.63 %
Epoch 1254 of 2000 took 0.035s
  training loss:		0.008320
  validation loss:		0.546587
  validation accuracy:		91.63 %
Epoch 1255 of 2000 took 0.035s
  training loss:		0.007915
  validation loss:		0.553240
  validation accuracy:		91.74 %
Epoch 1256 of 2000 took 0.035s
  training loss:		0.007992
  validation loss:		0.561915
  validation accuracy:		91.41 %
Epoch 1257 of 2000 took 0.035s
  training loss:		0.008273
  validation loss:		0.548842
  validation accuracy:		91.30 %
Epoch 1258 of 2000 took 0.035s
  training loss:		0.007980
  validation loss:		0.552956
  validation accuracy:		91.41 %
Epoch 1259 of 2000 took 0.035s
  training loss:		0.008290
  validation loss:		0.553221
  validation accuracy:		91.30 %
Epoch 1260 of 2000 took 0.035s
  training loss:		0.008256
  validation loss:		0.551239
  validation accuracy:		91.85 %
Epoch 1261 of 2000 took 0.035s
  training loss:		0.008148
  validation loss:		0.551041
  validation accuracy:		91.20 %
Epoch 1262 of 2000 took 0.035s
  training loss:		0.008055
  validation loss:		0.557669
  validation accuracy:		91.20 %
Epoch 1263 of 2000 took 0.035s
  training loss:		0.007710
  validation loss:		0.542159
  validation accuracy:		91.63 %
Epoch 1264 of 2000 took 0.035s
  training loss:		0.008110
  validation loss:		0.563416
  validation accuracy:		91.20 %
Epoch 1265 of 2000 took 0.035s
  training loss:		0.008059
  validation loss:		0.548217
  validation accuracy:		91.52 %
Epoch 1266 of 2000 took 0.035s
  training loss:		0.008235
  validation loss:		0.550268
  validation accuracy:		91.30 %
Epoch 1267 of 2000 took 0.035s
  training loss:		0.007744
  validation loss:		0.548520
  validation accuracy:		91.41 %
Epoch 1268 of 2000 took 0.035s
  training loss:		0.007726
  validation loss:		0.562161
  validation accuracy:		91.30 %
Epoch 1269 of 2000 took 0.035s
  training loss:		0.007829
  validation loss:		0.566395
  validation accuracy:		91.30 %
Epoch 1270 of 2000 took 0.035s
  training loss:		0.008205
  validation loss:		0.553874
  validation accuracy:		91.41 %
Epoch 1271 of 2000 took 0.035s
  training loss:		0.007980
  validation loss:		0.551759
  validation accuracy:		91.41 %
Epoch 1272 of 2000 took 0.035s
  training loss:		0.007780
  validation loss:		0.557112
  validation accuracy:		91.41 %
Epoch 1273 of 2000 took 0.035s
  training loss:		0.007764
  validation loss:		0.554981
  validation accuracy:		91.41 %
Epoch 1274 of 2000 took 0.035s
  training loss:		0.007876
  validation loss:		0.546253
  validation accuracy:		91.63 %
Epoch 1275 of 2000 took 0.035s
  training loss:		0.007510
  validation loss:		0.565443
  validation accuracy:		91.30 %
Epoch 1276 of 2000 took 0.035s
  training loss:		0.007961
  validation loss:		0.572911
  validation accuracy:		91.41 %
Epoch 1277 of 2000 took 0.035s
  training loss:		0.007578
  validation loss:		0.553074
  validation accuracy:		91.52 %
Epoch 1278 of 2000 took 0.035s
  training loss:		0.007686
  validation loss:		0.567798
  validation accuracy:		91.09 %
Epoch 1279 of 2000 took 0.035s
  training loss:		0.007759
  validation loss:		0.555309
  validation accuracy:		91.30 %
Epoch 1280 of 2000 took 0.035s
  training loss:		0.007848
  validation loss:		0.557495
  validation accuracy:		91.41 %
Epoch 1281 of 2000 took 0.035s
  training loss:		0.007732
  validation loss:		0.553954
  validation accuracy:		91.52 %
Epoch 1282 of 2000 took 0.035s
  training loss:		0.007861
  validation loss:		0.546955
  validation accuracy:		91.52 %
Epoch 1283 of 2000 took 0.035s
  training loss:		0.007642
  validation loss:		0.556194
  validation accuracy:		91.41 %
Epoch 1284 of 2000 took 0.035s
  training loss:		0.007638
  validation loss:		0.566372
  validation accuracy:		91.20 %
Epoch 1285 of 2000 took 0.035s
  training loss:		0.008051
  validation loss:		0.555273
  validation accuracy:		91.52 %
Epoch 1286 of 2000 took 0.035s
  training loss:		0.007762
  validation loss:		0.557513
  validation accuracy:		91.63 %
Epoch 1287 of 2000 took 0.035s
  training loss:		0.007440
  validation loss:		0.563689
  validation accuracy:		91.52 %
Epoch 1288 of 2000 took 0.035s
  training loss:		0.007614
  validation loss:		0.556743
  validation accuracy:		91.52 %
Epoch 1289 of 2000 took 0.035s
  training loss:		0.007618
  validation loss:		0.557801
  validation accuracy:		91.41 %
Epoch 1290 of 2000 took 0.035s
  training loss:		0.007268
  validation loss:		0.553576
  validation accuracy:		91.41 %
Epoch 1291 of 2000 took 0.035s
  training loss:		0.007515
  validation loss:		0.556852
  validation accuracy:		91.09 %
Epoch 1292 of 2000 took 0.035s
  training loss:		0.007633
  validation loss:		0.554625
  validation accuracy:		91.52 %
Epoch 1293 of 2000 took 0.035s
  training loss:		0.007579
  validation loss:		0.563163
  validation accuracy:		91.63 %
Epoch 1294 of 2000 took 0.035s
  training loss:		0.007308
  validation loss:		0.557038
  validation accuracy:		91.20 %
Epoch 1295 of 2000 took 0.035s
  training loss:		0.007438
  validation loss:		0.553158
  validation accuracy:		91.52 %
Epoch 1296 of 2000 took 0.035s
  training loss:		0.007745
  validation loss:		0.566081
  validation accuracy:		90.98 %
Epoch 1297 of 2000 took 0.035s
  training loss:		0.007626
  validation loss:		0.560592
  validation accuracy:		91.20 %
Epoch 1298 of 2000 took 0.035s
  training loss:		0.007626
  validation loss:		0.567891
  validation accuracy:		91.09 %
Epoch 1299 of 2000 took 0.035s
  training loss:		0.007378
  validation loss:		0.554625
  validation accuracy:		91.09 %
Epoch 1300 of 2000 took 0.036s
  training loss:		0.007573
  validation loss:		0.574349
  validation accuracy:		91.41 %
Epoch 1301 of 2000 took 0.035s
  training loss:		0.007686
  validation loss:		0.565649
  validation accuracy:		91.30 %
Epoch 1302 of 2000 took 0.035s
  training loss:		0.007230
  validation loss:		0.554699
  validation accuracy:		91.41 %
Epoch 1303 of 2000 took 0.035s
  training loss:		0.007161
  validation loss:		0.559564
  validation accuracy:		91.52 %
Epoch 1304 of 2000 took 0.035s
  training loss:		0.007290
  validation loss:		0.554294
  validation accuracy:		91.30 %
Epoch 1305 of 2000 took 0.035s
  training loss:		0.007408
  validation loss:		0.565195
  validation accuracy:		91.30 %
Epoch 1306 of 2000 took 0.035s
  training loss:		0.007383
  validation loss:		0.560715
  validation accuracy:		91.41 %
Epoch 1307 of 2000 took 0.035s
  training loss:		0.007362
  validation loss:		0.565914
  validation accuracy:		91.41 %
Epoch 1308 of 2000 took 0.035s
  training loss:		0.007418
  validation loss:		0.577818
  validation accuracy:		91.41 %
Epoch 1309 of 2000 took 0.035s
  training loss:		0.007481
  validation loss:		0.563310
  validation accuracy:		91.30 %
Epoch 1310 of 2000 took 0.035s
  training loss:		0.007181
  validation loss:		0.566483
  validation accuracy:		91.52 %
Epoch 1311 of 2000 took 0.035s
  training loss:		0.007496
  validation loss:		0.576047
  validation accuracy:		90.98 %
Epoch 1312 of 2000 took 0.035s
  training loss:		0.007238
  validation loss:		0.566273
  validation accuracy:		91.41 %
Epoch 1313 of 2000 took 0.035s
  training loss:		0.006949
  validation loss:		0.561682
  validation accuracy:		91.30 %
Epoch 1314 of 2000 took 0.035s
  training loss:		0.007163
  validation loss:		0.574798
  validation accuracy:		90.98 %
Epoch 1315 of 2000 took 0.035s
  training loss:		0.007225
  validation loss:		0.567905
  validation accuracy:		91.41 %
Epoch 1316 of 2000 took 0.035s
  training loss:		0.006700
  validation loss:		0.569165
  validation accuracy:		91.20 %
Epoch 1317 of 2000 took 0.035s
  training loss:		0.007345
  validation loss:		0.577366
  validation accuracy:		91.20 %
Epoch 1318 of 2000 took 0.035s
  training loss:		0.006917
  validation loss:		0.567529
  validation accuracy:		91.52 %
Epoch 1319 of 2000 took 0.035s
  training loss:		0.006796
  validation loss:		0.563811
  validation accuracy:		91.52 %
Epoch 1320 of 2000 took 0.035s
  training loss:		0.006914
  validation loss:		0.573587
  validation accuracy:		91.09 %
Epoch 1321 of 2000 took 0.035s
  training loss:		0.006865
  validation loss:		0.568821
  validation accuracy:		91.30 %
Epoch 1322 of 2000 took 0.035s
  training loss:		0.007286
  validation loss:		0.567953
  validation accuracy:		91.41 %
Epoch 1323 of 2000 took 0.035s
  training loss:		0.007000
  validation loss:		0.565480
  validation accuracy:		91.30 %
Epoch 1324 of 2000 took 0.035s
  training loss:		0.006882
  validation loss:		0.563413
  validation accuracy:		91.09 %
Epoch 1325 of 2000 took 0.035s
  training loss:		0.006959
  validation loss:		0.570864
  validation accuracy:		91.41 %
Epoch 1326 of 2000 took 0.035s
  training loss:		0.006929
  validation loss:		0.576079
  validation accuracy:		91.20 %
Epoch 1327 of 2000 took 0.035s
  training loss:		0.006870
  validation loss:		0.563438
  validation accuracy:		91.20 %
Epoch 1328 of 2000 took 0.036s
  training loss:		0.006660
  validation loss:		0.565700
  validation accuracy:		91.20 %
Epoch 1329 of 2000 took 0.035s
  training loss:		0.007034
  validation loss:		0.579039
  validation accuracy:		91.20 %
Epoch 1330 of 2000 took 0.035s
  training loss:		0.006927
  validation loss:		0.573697
  validation accuracy:		91.30 %
Epoch 1331 of 2000 took 0.035s
  training loss:		0.007001
  validation loss:		0.563044
  validation accuracy:		91.41 %
Epoch 1332 of 2000 took 0.035s
  training loss:		0.007000
  validation loss:		0.558950
  validation accuracy:		91.52 %
Epoch 1333 of 2000 took 0.035s
  training loss:		0.006663
  validation loss:		0.573122
  validation accuracy:		91.20 %
Epoch 1334 of 2000 took 0.035s
  training loss:		0.007081
  validation loss:		0.581613
  validation accuracy:		91.41 %
Epoch 1335 of 2000 took 0.035s
  training loss:		0.006685
  validation loss:		0.560825
  validation accuracy:		91.30 %
Epoch 1336 of 2000 took 0.035s
  training loss:		0.006902
  validation loss:		0.564096
  validation accuracy:		91.52 %
Epoch 1337 of 2000 took 0.035s
  training loss:		0.007034
  validation loss:		0.567713
  validation accuracy:		91.20 %
Epoch 1338 of 2000 took 0.035s
  training loss:		0.006856
  validation loss:		0.567643
  validation accuracy:		91.41 %
Epoch 1339 of 2000 took 0.035s
  training loss:		0.006684
  validation loss:		0.572971
  validation accuracy:		91.41 %
Epoch 1340 of 2000 took 0.035s
  training loss:		0.006869
  validation loss:		0.572812
  validation accuracy:		91.20 %
Epoch 1341 of 2000 took 0.035s
  training loss:		0.006794
  validation loss:		0.569710
  validation accuracy:		91.20 %
Epoch 1342 of 2000 took 0.035s
  training loss:		0.006655
  validation loss:		0.578337
  validation accuracy:		91.09 %
Epoch 1343 of 2000 took 0.035s
  training loss:		0.006562
  validation loss:		0.564379
  validation accuracy:		91.30 %
Epoch 1344 of 2000 took 0.035s
  training loss:		0.006679
  validation loss:		0.576124
  validation accuracy:		91.30 %
Epoch 1345 of 2000 took 0.035s
  training loss:		0.006748
  validation loss:		0.572534
  validation accuracy:		91.41 %
Epoch 1346 of 2000 took 0.035s
  training loss:		0.006506
  validation loss:		0.572787
  validation accuracy:		91.52 %
Epoch 1347 of 2000 took 0.035s
  training loss:		0.006952
  validation loss:		0.558959
  validation accuracy:		91.74 %
Epoch 1348 of 2000 took 0.035s
  training loss:		0.006788
  validation loss:		0.571178
  validation accuracy:		91.30 %
Epoch 1349 of 2000 took 0.035s
  training loss:		0.006755
  validation loss:		0.572536
  validation accuracy:		91.09 %
Epoch 1350 of 2000 took 0.035s
  training loss:		0.006660
  validation loss:		0.573433
  validation accuracy:		91.09 %
Epoch 1351 of 2000 took 0.035s
  training loss:		0.006658
  validation loss:		0.572246
  validation accuracy:		91.20 %
Epoch 1352 of 2000 took 0.035s
  training loss:		0.006566
  validation loss:		0.562611
  validation accuracy:		91.52 %
Epoch 1353 of 2000 took 0.035s
  training loss:		0.006795
  validation loss:		0.580379
  validation accuracy:		91.20 %
Epoch 1354 of 2000 took 0.035s
  training loss:		0.006604
  validation loss:		0.583950
  validation accuracy:		90.98 %
Epoch 1355 of 2000 took 0.035s
  training loss:		0.006530
  validation loss:		0.571140
  validation accuracy:		91.30 %
Epoch 1356 of 2000 took 0.035s
  training loss:		0.006368
  validation loss:		0.570037
  validation accuracy:		91.09 %
Epoch 1357 of 2000 took 0.035s
  training loss:		0.006346
  validation loss:		0.581772
  validation accuracy:		91.30 %
Epoch 1358 of 2000 took 0.035s
  training loss:		0.006436
  validation loss:		0.571924
  validation accuracy:		91.30 %
Epoch 1359 of 2000 took 0.035s
  training loss:		0.006532
  validation loss:		0.583022
  validation accuracy:		90.87 %
Epoch 1360 of 2000 took 0.035s
  training loss:		0.006417
  validation loss:		0.581194
  validation accuracy:		91.09 %
Epoch 1361 of 2000 took 0.035s
  training loss:		0.006578
  validation loss:		0.567048
  validation accuracy:		91.41 %
Epoch 1362 of 2000 took 0.035s
  training loss:		0.006429
  validation loss:		0.583966
  validation accuracy:		91.30 %
Epoch 1363 of 2000 took 0.035s
  training loss:		0.006428
  validation loss:		0.588089
  validation accuracy:		90.98 %
Epoch 1364 of 2000 took 0.035s
  training loss:		0.006438
  validation loss:		0.580023
  validation accuracy:		91.41 %
Epoch 1365 of 2000 took 0.035s
  training loss:		0.006420
  validation loss:		0.583635
  validation accuracy:		91.30 %
Epoch 1366 of 2000 took 0.035s
  training loss:		0.006511
  validation loss:		0.583080
  validation accuracy:		91.09 %
Epoch 1367 of 2000 took 0.035s
  training loss:		0.006380
  validation loss:		0.572831
  validation accuracy:		91.30 %
Epoch 1368 of 2000 took 0.035s
  training loss:		0.006514
  validation loss:		0.572677
  validation accuracy:		91.30 %
Epoch 1369 of 2000 took 0.035s
  training loss:		0.006560
  validation loss:		0.578855
  validation accuracy:		91.30 %
Epoch 1370 of 2000 took 0.035s
  training loss:		0.006354
  validation loss:		0.581955
  validation accuracy:		91.09 %
Epoch 1371 of 2000 took 0.035s
  training loss:		0.006363
  validation loss:		0.580772
  validation accuracy:		91.41 %
Epoch 1372 of 2000 took 0.035s
  training loss:		0.006324
  validation loss:		0.573817
  validation accuracy:		91.20 %
Epoch 1373 of 2000 took 0.035s
  training loss:		0.006237
  validation loss:		0.584735
  validation accuracy:		91.20 %
Epoch 1374 of 2000 took 0.035s
  training loss:		0.006186
  validation loss:		0.574421
  validation accuracy:		91.09 %
Epoch 1375 of 2000 took 0.035s
  training loss:		0.006156
  validation loss:		0.583781
  validation accuracy:		91.20 %
Epoch 1376 of 2000 took 0.035s
  training loss:		0.006186
  validation loss:		0.578987
  validation accuracy:		91.41 %
Epoch 1377 of 2000 took 0.035s
  training loss:		0.006310
  validation loss:		0.579098
  validation accuracy:		91.09 %
Epoch 1378 of 2000 took 0.035s
  training loss:		0.006087
  validation loss:		0.576431
  validation accuracy:		91.20 %
Epoch 1379 of 2000 took 0.035s
  training loss:		0.006247
  validation loss:		0.576744
  validation accuracy:		91.52 %
Epoch 1380 of 2000 took 0.035s
  training loss:		0.006349
  validation loss:		0.574933
  validation accuracy:		91.52 %
Epoch 1381 of 2000 took 0.035s
  training loss:		0.006070
  validation loss:		0.585682
  validation accuracy:		91.20 %
Epoch 1382 of 2000 took 0.035s
  training loss:		0.006227
  validation loss:		0.579432
  validation accuracy:		91.52 %
Epoch 1383 of 2000 took 0.035s
  training loss:		0.006191
  validation loss:		0.584600
  validation accuracy:		91.30 %
Epoch 1384 of 2000 took 0.035s
  training loss:		0.006097
  validation loss:		0.584400
  validation accuracy:		91.41 %
Epoch 1385 of 2000 took 0.036s
  training loss:		0.006228
  validation loss:		0.590483
  validation accuracy:		91.20 %
Epoch 1386 of 2000 took 0.035s
  training loss:		0.006023
  validation loss:		0.579014
  validation accuracy:		90.98 %
Epoch 1387 of 2000 took 0.035s
  training loss:		0.006101
  validation loss:		0.578514
  validation accuracy:		91.52 %
Epoch 1388 of 2000 took 0.035s
  training loss:		0.006125
  validation loss:		0.576097
  validation accuracy:		91.20 %
Epoch 1389 of 2000 took 0.035s
  training loss:		0.006033
  validation loss:		0.587964
  validation accuracy:		91.20 %
Epoch 1390 of 2000 took 0.035s
  training loss:		0.006159
  validation loss:		0.575896
  validation accuracy:		91.30 %
Epoch 1391 of 2000 took 0.035s
  training loss:		0.006157
  validation loss:		0.582444
  validation accuracy:		91.20 %
Epoch 1392 of 2000 took 0.035s
  training loss:		0.006060
  validation loss:		0.588845
  validation accuracy:		91.30 %
Epoch 1393 of 2000 took 0.035s
  training loss:		0.005841
  validation loss:		0.577441
  validation accuracy:		91.30 %
Epoch 1394 of 2000 took 0.035s
  training loss:		0.006083
  validation loss:		0.588457
  validation accuracy:		90.98 %
Epoch 1395 of 2000 took 0.035s
  training loss:		0.005897
  validation loss:		0.574149
  validation accuracy:		91.41 %
Epoch 1396 of 2000 took 0.035s
  training loss:		0.006101
  validation loss:		0.596410
  validation accuracy:		91.20 %
Epoch 1397 of 2000 took 0.035s
  training loss:		0.006108
  validation loss:		0.578989
  validation accuracy:		91.09 %
Epoch 1398 of 2000 took 0.035s
  training loss:		0.005930
  validation loss:		0.580920
  validation accuracy:		91.41 %
Epoch 1399 of 2000 took 0.035s
  training loss:		0.005840
  validation loss:		0.584872
  validation accuracy:		91.20 %
Epoch 1400 of 2000 took 0.035s
  training loss:		0.005880
  validation loss:		0.586406
  validation accuracy:		91.30 %
Epoch 1401 of 2000 took 0.035s
  training loss:		0.005696
  validation loss:		0.592553
  validation accuracy:		91.41 %
Epoch 1402 of 2000 took 0.035s
  training loss:		0.006111
  validation loss:		0.589516
  validation accuracy:		91.09 %
Epoch 1403 of 2000 took 0.035s
  training loss:		0.005974
  validation loss:		0.583035
  validation accuracy:		91.09 %
Epoch 1404 of 2000 took 0.035s
  training loss:		0.005900
  validation loss:		0.582079
  validation accuracy:		91.20 %
Epoch 1405 of 2000 took 0.035s
  training loss:		0.005873
  validation loss:		0.580731
  validation accuracy:		91.09 %
Epoch 1406 of 2000 took 0.035s
  training loss:		0.006069
  validation loss:		0.590317
  validation accuracy:		91.20 %
Epoch 1407 of 2000 took 0.035s
  training loss:		0.006036
  validation loss:		0.587394
  validation accuracy:		91.20 %
Epoch 1408 of 2000 took 0.035s
  training loss:		0.005883
  validation loss:		0.593731
  validation accuracy:		91.20 %
Epoch 1409 of 2000 took 0.035s
  training loss:		0.005982
  validation loss:		0.587871
  validation accuracy:		91.30 %
Epoch 1410 of 2000 took 0.035s
  training loss:		0.005727
  validation loss:		0.598905
  validation accuracy:		90.87 %
Epoch 1411 of 2000 took 0.035s
  training loss:		0.006029
  validation loss:		0.592689
  validation accuracy:		91.20 %
Epoch 1412 of 2000 took 0.035s
  training loss:		0.005862
  validation loss:		0.591400
  validation accuracy:		91.09 %
Epoch 1413 of 2000 took 0.035s
  training loss:		0.005717
  validation loss:		0.582781
  validation accuracy:		91.41 %
Epoch 1414 of 2000 took 0.035s
  training loss:		0.005933
  validation loss:		0.597482
  validation accuracy:		91.09 %
Epoch 1415 of 2000 took 0.035s
  training loss:		0.005789
  validation loss:		0.588445
  validation accuracy:		91.30 %
Epoch 1416 of 2000 took 0.035s
  training loss:		0.005964
  validation loss:		0.592678
  validation accuracy:		91.09 %
Epoch 1417 of 2000 took 0.035s
  training loss:		0.005972
  validation loss:		0.593779
  validation accuracy:		90.98 %
Epoch 1418 of 2000 took 0.035s
  training loss:		0.005917
  validation loss:		0.584234
  validation accuracy:		91.09 %
Epoch 1419 of 2000 took 0.035s
  training loss:		0.005815
  validation loss:		0.591893
  validation accuracy:		91.20 %
Epoch 1420 of 2000 took 0.035s
  training loss:		0.005467
  validation loss:		0.600187
  validation accuracy:		90.98 %
Epoch 1421 of 2000 took 0.035s
  training loss:		0.005694
  validation loss:		0.584202
  validation accuracy:		91.20 %
Epoch 1422 of 2000 took 0.035s
  training loss:		0.005622
  validation loss:		0.589872
  validation accuracy:		91.30 %
Epoch 1423 of 2000 took 0.035s
  training loss:		0.005788
  validation loss:		0.601258
  validation accuracy:		91.20 %
Epoch 1424 of 2000 took 0.035s
  training loss:		0.005863
  validation loss:		0.587925
  validation accuracy:		91.20 %
Epoch 1425 of 2000 took 0.035s
  training loss:		0.005775
  validation loss:		0.598857
  validation accuracy:		91.09 %
Epoch 1426 of 2000 took 0.035s
  training loss:		0.005592
  validation loss:		0.583577
  validation accuracy:		91.30 %
Epoch 1427 of 2000 took 0.035s
  training loss:		0.005652
  validation loss:		0.591266
  validation accuracy:		91.20 %
Epoch 1428 of 2000 took 0.035s
  training loss:		0.005742
  validation loss:		0.592652
  validation accuracy:		91.30 %
Epoch 1429 of 2000 took 0.035s
  training loss:		0.005719
  validation loss:		0.590324
  validation accuracy:		91.20 %
Epoch 1430 of 2000 took 0.035s
  training loss:		0.005712
  validation loss:		0.596334
  validation accuracy:		91.20 %
Epoch 1431 of 2000 took 0.035s
  training loss:		0.005637
  validation loss:		0.582661
  validation accuracy:		91.41 %
Epoch 1432 of 2000 took 0.035s
  training loss:		0.005563
  validation loss:		0.593977
  validation accuracy:		91.20 %
Epoch 1433 of 2000 took 0.035s
  training loss:		0.005693
  validation loss:		0.594233
  validation accuracy:		91.09 %
Epoch 1434 of 2000 took 0.035s
  training loss:		0.005739
  validation loss:		0.589680
  validation accuracy:		91.30 %
Epoch 1435 of 2000 took 0.035s
  training loss:		0.005671
  validation loss:		0.595494
  validation accuracy:		91.20 %
Epoch 1436 of 2000 took 0.035s
  training loss:		0.005550
  validation loss:		0.593461
  validation accuracy:		91.20 %
Epoch 1437 of 2000 took 0.035s
  training loss:		0.005549
  validation loss:		0.599501
  validation accuracy:		91.09 %
Epoch 1438 of 2000 took 0.035s
  training loss:		0.005372
  validation loss:		0.594972
  validation accuracy:		91.09 %
Epoch 1439 of 2000 took 0.035s
  training loss:		0.005468
  validation loss:		0.592350
  validation accuracy:		91.20 %
Epoch 1440 of 2000 took 0.035s
  training loss:		0.005526
  validation loss:		0.598187
  validation accuracy:		91.09 %
Epoch 1441 of 2000 took 0.035s
  training loss:		0.005554
  validation loss:		0.592942
  validation accuracy:		91.09 %
Epoch 1442 of 2000 took 0.035s
  training loss:		0.005620
  validation loss:		0.579247
  validation accuracy:		91.30 %
Epoch 1443 of 2000 took 0.035s
  training loss:		0.005554
  validation loss:		0.600829
  validation accuracy:		91.20 %
Epoch 1444 of 2000 took 0.035s
  training loss:		0.005608
  validation loss:		0.603417
  validation accuracy:		91.20 %
Epoch 1445 of 2000 took 0.035s
  training loss:		0.005723
  validation loss:		0.606581
  validation accuracy:		91.20 %
Epoch 1446 of 2000 took 0.035s
  training loss:		0.005432
  validation loss:		0.595336
  validation accuracy:		91.09 %
Epoch 1447 of 2000 took 0.035s
  training loss:		0.005488
  validation loss:		0.595803
  validation accuracy:		91.09 %
Epoch 1448 of 2000 took 0.035s
  training loss:		0.005407
  validation loss:		0.587854
  validation accuracy:		91.20 %
Epoch 1449 of 2000 took 0.035s
  training loss:		0.005482
  validation loss:		0.600492
  validation accuracy:		91.20 %
Epoch 1450 of 2000 took 0.035s
  training loss:		0.005490
  validation loss:		0.594330
  validation accuracy:		91.20 %
Epoch 1451 of 2000 took 0.035s
  training loss:		0.005451
  validation loss:		0.592844
  validation accuracy:		91.20 %
Epoch 1452 of 2000 took 0.035s
  training loss:		0.005354
  validation loss:		0.600245
  validation accuracy:		91.30 %
Epoch 1453 of 2000 took 0.035s
  training loss:		0.005332
  validation loss:		0.604677
  validation accuracy:		91.09 %
Epoch 1454 of 2000 took 0.035s
  training loss:		0.005383
  validation loss:		0.591733
  validation accuracy:		91.09 %
Epoch 1455 of 2000 took 0.035s
  training loss:		0.005337
  validation loss:		0.605283
  validation accuracy:		91.20 %
Epoch 1456 of 2000 took 0.035s
  training loss:		0.005372
  validation loss:		0.600081
  validation accuracy:		91.20 %
Epoch 1457 of 2000 took 0.035s
  training loss:		0.005268
  validation loss:		0.598475
  validation accuracy:		91.30 %
Epoch 1458 of 2000 took 0.035s
  training loss:		0.005359
  validation loss:		0.600718
  validation accuracy:		91.20 %
Epoch 1459 of 2000 took 0.035s
  training loss:		0.005347
  validation loss:		0.616484
  validation accuracy:		91.09 %
Epoch 1460 of 2000 took 0.035s
  training loss:		0.005500
  validation loss:		0.594831
  validation accuracy:		91.20 %
Epoch 1461 of 2000 took 0.035s
  training loss:		0.005347
  validation loss:		0.603435
  validation accuracy:		91.20 %
Epoch 1462 of 2000 took 0.035s
  training loss:		0.005327
  validation loss:		0.599520
  validation accuracy:		91.20 %
Epoch 1463 of 2000 took 0.035s
  training loss:		0.005257
  validation loss:		0.596634
  validation accuracy:		91.20 %
Epoch 1464 of 2000 took 0.035s
  training loss:		0.005124
  validation loss:		0.591907
  validation accuracy:		91.30 %
Epoch 1465 of 2000 took 0.035s
  training loss:		0.005359
  validation loss:		0.603530
  validation accuracy:		91.09 %
Epoch 1466 of 2000 took 0.035s
  training loss:		0.005421
  validation loss:		0.597150
  validation accuracy:		91.52 %
Epoch 1467 of 2000 took 0.035s
  training loss:		0.005340
  validation loss:		0.597670
  validation accuracy:		91.30 %
Epoch 1468 of 2000 took 0.035s
  training loss:		0.005409
  validation loss:		0.596567
  validation accuracy:		91.20 %
Epoch 1469 of 2000 took 0.035s
  training loss:		0.005256
  validation loss:		0.605589
  validation accuracy:		91.20 %
Epoch 1470 of 2000 took 0.035s
  training loss:		0.005136
  validation loss:		0.604140
  validation accuracy:		91.30 %
Epoch 1471 of 2000 took 0.035s
  training loss:		0.005248
  validation loss:		0.589602
  validation accuracy:		91.30 %
Epoch 1472 of 2000 took 0.035s
  training loss:		0.005394
  validation loss:		0.618431
  validation accuracy:		91.09 %
Epoch 1473 of 2000 took 0.035s
  training loss:		0.005293
  validation loss:		0.596816
  validation accuracy:		91.09 %
Epoch 1474 of 2000 took 0.035s
  training loss:		0.005276
  validation loss:		0.607435
  validation accuracy:		91.20 %
Epoch 1475 of 2000 took 0.035s
  training loss:		0.005187
  validation loss:		0.611418
  validation accuracy:		91.20 %
Epoch 1476 of 2000 took 0.035s
  training loss:		0.005080
  validation loss:		0.598047
  validation accuracy:		91.30 %
Epoch 1477 of 2000 took 0.035s
  training loss:		0.005296
  validation loss:		0.603907
  validation accuracy:		91.09 %
Epoch 1478 of 2000 took 0.035s
  training loss:		0.005163
  validation loss:		0.608644
  validation accuracy:		91.20 %
Epoch 1479 of 2000 took 0.035s
  training loss:		0.005106
  validation loss:		0.605420
  validation accuracy:		91.30 %
Epoch 1480 of 2000 took 0.035s
  training loss:		0.005242
  validation loss:		0.606163
  validation accuracy:		91.20 %
Epoch 1481 of 2000 took 0.035s
  training loss:		0.005114
  validation loss:		0.597935
  validation accuracy:		91.09 %
Epoch 1482 of 2000 took 0.035s
  training loss:		0.005262
  validation loss:		0.606108
  validation accuracy:		91.09 %
Epoch 1483 of 2000 took 0.035s
  training loss:		0.005099
  validation loss:		0.601776
  validation accuracy:		91.20 %
Epoch 1484 of 2000 took 0.035s
  training loss:		0.004987
  validation loss:		0.605002
  validation accuracy:		91.09 %
Epoch 1485 of 2000 took 0.035s
  training loss:		0.004967
  validation loss:		0.604465
  validation accuracy:		90.98 %
Epoch 1486 of 2000 took 0.035s
  training loss:		0.005144
  validation loss:		0.608408
  validation accuracy:		91.20 %
Epoch 1487 of 2000 took 0.035s
  training loss:		0.005124
  validation loss:		0.606031
  validation accuracy:		91.20 %
Epoch 1488 of 2000 took 0.035s
  training loss:		0.005064
  validation loss:		0.611740
  validation accuracy:		91.20 %
Epoch 1489 of 2000 took 0.035s
  training loss:		0.005081
  validation loss:		0.607592
  validation accuracy:		91.20 %
Epoch 1490 of 2000 took 0.035s
  training loss:		0.005086
  validation loss:		0.601343
  validation accuracy:		91.41 %
Epoch 1491 of 2000 took 0.035s
  training loss:		0.005146
  validation loss:		0.607387
  validation accuracy:		91.30 %
Epoch 1492 of 2000 took 0.035s
  training loss:		0.005058
  validation loss:		0.604980
  validation accuracy:		91.20 %
Epoch 1493 of 2000 took 0.035s
  training loss:		0.004758
  validation loss:		0.611351
  validation accuracy:		91.20 %
Epoch 1494 of 2000 took 0.035s
  training loss:		0.004985
  validation loss:		0.613635
  validation accuracy:		91.20 %
Epoch 1495 of 2000 took 0.035s
  training loss:		0.005086
  validation loss:		0.607569
  validation accuracy:		91.20 %
Epoch 1496 of 2000 took 0.035s
  training loss:		0.005053
  validation loss:		0.600958
  validation accuracy:		91.20 %
Epoch 1497 of 2000 took 0.035s
  training loss:		0.004979
  validation loss:		0.602865
  validation accuracy:		91.30 %
Epoch 1498 of 2000 took 0.035s
  training loss:		0.005034
  validation loss:		0.602968
  validation accuracy:		91.20 %
Epoch 1499 of 2000 took 0.035s
  training loss:		0.004851
  validation loss:		0.602663
  validation accuracy:		91.09 %
Epoch 1500 of 2000 took 0.035s
  training loss:		0.004990
  validation loss:		0.610001
  validation accuracy:		91.09 %
Epoch 1501 of 2000 took 0.035s
  training loss:		0.005029
  validation loss:		0.607305
  validation accuracy:		91.09 %
Epoch 1502 of 2000 took 0.035s
  training loss:		0.004965
  validation loss:		0.607114
  validation accuracy:		91.20 %
Epoch 1503 of 2000 took 0.035s
  training loss:		0.005038
  validation loss:		0.604127
  validation accuracy:		91.20 %
Epoch 1504 of 2000 took 0.035s
  training loss:		0.004979
  validation loss:		0.608140
  validation accuracy:		91.20 %
Epoch 1505 of 2000 took 0.035s
  training loss:		0.004805
  validation loss:		0.607864
  validation accuracy:		91.30 %
Epoch 1506 of 2000 took 0.035s
  training loss:		0.004864
  validation loss:		0.604747
  validation accuracy:		91.20 %
Epoch 1507 of 2000 took 0.035s
  training loss:		0.004942
  validation loss:		0.606568
  validation accuracy:		91.09 %
Epoch 1508 of 2000 took 0.035s
  training loss:		0.005155
  validation loss:		0.615369
  validation accuracy:		91.09 %
Epoch 1509 of 2000 took 0.035s
  training loss:		0.004928
  validation loss:		0.611049
  validation accuracy:		91.20 %
Epoch 1510 of 2000 took 0.035s
  training loss:		0.004904
  validation loss:		0.608504
  validation accuracy:		91.30 %
Epoch 1511 of 2000 took 0.035s
  training loss:		0.005069
  validation loss:		0.607082
  validation accuracy:		91.09 %
Epoch 1512 of 2000 took 0.035s
  training loss:		0.004793
  validation loss:		0.617967
  validation accuracy:		91.20 %
Epoch 1513 of 2000 took 0.035s
  training loss:		0.004815
  validation loss:		0.610855
  validation accuracy:		91.20 %
Epoch 1514 of 2000 took 0.035s
  training loss:		0.004803
  validation loss:		0.608205
  validation accuracy:		91.30 %
Epoch 1515 of 2000 took 0.035s
  training loss:		0.004812
  validation loss:		0.610005
  validation accuracy:		91.20 %
Epoch 1516 of 2000 took 0.035s
  training loss:		0.004831
  validation loss:		0.610097
  validation accuracy:		91.09 %
Epoch 1517 of 2000 took 0.035s
  training loss:		0.004926
  validation loss:		0.605491
  validation accuracy:		91.20 %
Epoch 1518 of 2000 took 0.035s
  training loss:		0.004777
  validation loss:		0.621250
  validation accuracy:		91.09 %
Epoch 1519 of 2000 took 0.035s
  training loss:		0.004733
  validation loss:		0.616468
  validation accuracy:		91.20 %
Epoch 1520 of 2000 took 0.035s
  training loss:		0.004908
  validation loss:		0.613839
  validation accuracy:		91.20 %
Epoch 1521 of 2000 took 0.035s
  training loss:		0.004769
  validation loss:		0.619252
  validation accuracy:		91.09 %
Epoch 1522 of 2000 took 0.035s
  training loss:		0.004788
  validation loss:		0.612223
  validation accuracy:		91.20 %
Epoch 1523 of 2000 took 0.035s
  training loss:		0.004771
  validation loss:		0.622486
  validation accuracy:		91.09 %
Epoch 1524 of 2000 took 0.035s
  training loss:		0.004769
  validation loss:		0.605714
  validation accuracy:		91.09 %
Epoch 1525 of 2000 took 0.035s
  training loss:		0.004819
  validation loss:		0.613294
  validation accuracy:		91.30 %
Epoch 1526 of 2000 took 0.035s
  training loss:		0.004825
  validation loss:		0.619780
  validation accuracy:		91.20 %
Epoch 1527 of 2000 took 0.035s
  training loss:		0.004830
  validation loss:		0.611408
  validation accuracy:		91.20 %
Epoch 1528 of 2000 took 0.035s
  training loss:		0.004437
  validation loss:		0.614244
  validation accuracy:		91.20 %
Epoch 1529 of 2000 took 0.035s
  training loss:		0.004695
  validation loss:		0.614535
  validation accuracy:		91.20 %
Epoch 1530 of 2000 took 0.035s
  training loss:		0.004679
  validation loss:		0.610772
  validation accuracy:		91.20 %
Epoch 1531 of 2000 took 0.035s
  training loss:		0.004658
  validation loss:		0.620994
  validation accuracy:		91.09 %
Epoch 1532 of 2000 took 0.035s
  training loss:		0.004673
  validation loss:		0.603253
  validation accuracy:		91.30 %
Epoch 1533 of 2000 took 0.035s
  training loss:		0.004923
  validation loss:		0.612252
  validation accuracy:		91.09 %
Epoch 1534 of 2000 took 0.035s
  training loss:		0.004559
  validation loss:		0.615359
  validation accuracy:		91.20 %
Epoch 1535 of 2000 took 0.035s
  training loss:		0.004540
  validation loss:		0.612166
  validation accuracy:		91.30 %
Epoch 1536 of 2000 took 0.035s
  training loss:		0.004543
  validation loss:		0.614515
  validation accuracy:		91.30 %
Epoch 1537 of 2000 took 0.035s
  training loss:		0.004663
  validation loss:		0.618127
  validation accuracy:		91.20 %
Epoch 1538 of 2000 took 0.035s
  training loss:		0.004606
  validation loss:		0.613221
  validation accuracy:		91.20 %
Epoch 1539 of 2000 took 0.035s
  training loss:		0.004597
  validation loss:		0.616308
  validation accuracy:		91.20 %
Epoch 1540 of 2000 took 0.035s
  training loss:		0.004654
  validation loss:		0.608441
  validation accuracy:		91.09 %
Epoch 1541 of 2000 took 0.035s
  training loss:		0.004594
  validation loss:		0.607204
  validation accuracy:		91.30 %
Epoch 1542 of 2000 took 0.035s
  training loss:		0.004788
  validation loss:		0.610793
  validation accuracy:		91.20 %
Epoch 1543 of 2000 took 0.035s
  training loss:		0.004712
  validation loss:		0.621315
  validation accuracy:		91.20 %
Epoch 1544 of 2000 took 0.035s
  training loss:		0.004740
  validation loss:		0.617276
  validation accuracy:		91.09 %
Epoch 1545 of 2000 took 0.035s
  training loss:		0.004625
  validation loss:		0.619560
  validation accuracy:		91.20 %
Epoch 1546 of 2000 took 0.035s
  training loss:		0.004725
  validation loss:		0.613704
  validation accuracy:		91.20 %
Epoch 1547 of 2000 took 0.035s
  training loss:		0.004480
  validation loss:		0.616449
  validation accuracy:		91.20 %
Epoch 1548 of 2000 took 0.035s
  training loss:		0.004569
  validation loss:		0.617124
  validation accuracy:		91.20 %
Epoch 1549 of 2000 took 0.035s
  training loss:		0.004513
  validation loss:		0.616904
  validation accuracy:		91.30 %
Epoch 1550 of 2000 took 0.035s
  training loss:		0.004520
  validation loss:		0.614522
  validation accuracy:		91.09 %
Epoch 1551 of 2000 took 0.035s
  training loss:		0.004550
  validation loss:		0.622141
  validation accuracy:		91.20 %
Epoch 1552 of 2000 took 0.035s
  training loss:		0.004380
  validation loss:		0.619188
  validation accuracy:		91.20 %
Epoch 1553 of 2000 took 0.035s
  training loss:		0.004706
  validation loss:		0.610957
  validation accuracy:		91.20 %
Epoch 1554 of 2000 took 0.035s
  training loss:		0.004593
  validation loss:		0.610418
  validation accuracy:		91.09 %
Epoch 1555 of 2000 took 0.035s
  training loss:		0.004601
  validation loss:		0.606886
  validation accuracy:		91.30 %
Epoch 1556 of 2000 took 0.035s
  training loss:		0.004469
  validation loss:		0.620343
  validation accuracy:		91.20 %
Epoch 1557 of 2000 took 0.035s
  training loss:		0.004437
  validation loss:		0.619931
  validation accuracy:		91.20 %
Epoch 1558 of 2000 took 0.035s
  training loss:		0.004399
  validation loss:		0.618465
  validation accuracy:		91.20 %
Epoch 1559 of 2000 took 0.035s
  training loss:		0.004645
  validation loss:		0.619013
  validation accuracy:		91.20 %
Epoch 1560 of 2000 took 0.035s
  training loss:		0.004458
  validation loss:		0.624490
  validation accuracy:		91.20 %
Epoch 1561 of 2000 took 0.035s
  training loss:		0.004584
  validation loss:		0.615849
  validation accuracy:		91.30 %
Epoch 1562 of 2000 took 0.035s
  training loss:		0.004565
  validation loss:		0.614689
  validation accuracy:		91.20 %
Epoch 1563 of 2000 took 0.035s
  training loss:		0.004527
  validation loss:		0.622777
  validation accuracy:		91.20 %
Epoch 1564 of 2000 took 0.035s
  training loss:		0.004530
  validation loss:		0.622810
  validation accuracy:		91.20 %
Epoch 1565 of 2000 took 0.035s
  training loss:		0.004482
  validation loss:		0.623884
  validation accuracy:		91.09 %
Epoch 1566 of 2000 took 0.035s
  training loss:		0.004437
  validation loss:		0.610905
  validation accuracy:		91.30 %
Epoch 1567 of 2000 took 0.035s
  training loss:		0.004514
  validation loss:		0.621772
  validation accuracy:		91.09 %
Epoch 1568 of 2000 took 0.035s
  training loss:		0.004442
  validation loss:		0.615401
  validation accuracy:		91.20 %
Epoch 1569 of 2000 took 0.035s
  training loss:		0.004416
  validation loss:		0.626750
  validation accuracy:		91.20 %
Epoch 1570 of 2000 took 0.035s
  training loss:		0.004395
  validation loss:		0.614542
  validation accuracy:		91.20 %
Epoch 1571 of 2000 took 0.035s
  training loss:		0.004369
  validation loss:		0.620920
  validation accuracy:		91.20 %
Epoch 1572 of 2000 took 0.035s
  training loss:		0.004351
  validation loss:		0.616380
  validation accuracy:		91.20 %
Epoch 1573 of 2000 took 0.036s
  training loss:		0.004497
  validation loss:		0.615840
  validation accuracy:		91.20 %
Epoch 1574 of 2000 took 0.035s
  training loss:		0.004349
  validation loss:		0.615580
  validation accuracy:		91.20 %
Epoch 1575 of 2000 took 0.035s
  training loss:		0.004161
  validation loss:		0.621919
  validation accuracy:		91.20 %
Epoch 1576 of 2000 took 0.035s
  training loss:		0.004330
  validation loss:		0.628652
  validation accuracy:		91.20 %
Epoch 1577 of 2000 took 0.035s
  training loss:		0.004234
  validation loss:		0.613162
  validation accuracy:		91.41 %
Epoch 1578 of 2000 took 0.035s
  training loss:		0.004376
  validation loss:		0.626307
  validation accuracy:		91.30 %
Epoch 1579 of 2000 took 0.035s
  training loss:		0.004374
  validation loss:		0.618582
  validation accuracy:		91.20 %
Epoch 1580 of 2000 took 0.035s
  training loss:		0.004531
  validation loss:		0.623870
  validation accuracy:		91.20 %
Epoch 1581 of 2000 took 0.035s
  training loss:		0.004410
  validation loss:		0.620602
  validation accuracy:		91.20 %
Epoch 1582 of 2000 took 0.035s
  training loss:		0.004302
  validation loss:		0.622547
  validation accuracy:		91.30 %
Epoch 1583 of 2000 took 0.035s
  training loss:		0.004339
  validation loss:		0.623388
  validation accuracy:		91.30 %
Epoch 1584 of 2000 took 0.036s
  training loss:		0.004322
  validation loss:		0.625158
  validation accuracy:		91.20 %
Epoch 1585 of 2000 took 0.035s
  training loss:		0.004389
  validation loss:		0.625000
  validation accuracy:		91.20 %
Epoch 1586 of 2000 took 0.035s
  training loss:		0.004206
  validation loss:		0.626285
  validation accuracy:		91.20 %
Epoch 1587 of 2000 took 0.035s
  training loss:		0.004192
  validation loss:		0.619341
  validation accuracy:		91.20 %
Epoch 1588 of 2000 took 0.035s
  training loss:		0.004335
  validation loss:		0.631160
  validation accuracy:		91.20 %
Epoch 1589 of 2000 took 0.035s
  training loss:		0.004281
  validation loss:		0.623260
  validation accuracy:		91.30 %
Epoch 1590 of 2000 took 0.035s
  training loss:		0.004296
  validation loss:		0.625387
  validation accuracy:		91.20 %
Epoch 1591 of 2000 took 0.035s
  training loss:		0.004263
  validation loss:		0.623750
  validation accuracy:		91.20 %
Epoch 1592 of 2000 took 0.035s
  training loss:		0.004203
  validation loss:		0.630469
  validation accuracy:		91.09 %
Epoch 1593 of 2000 took 0.035s
  training loss:		0.004198
  validation loss:		0.625690
  validation accuracy:		91.20 %
Epoch 1594 of 2000 took 0.035s
  training loss:		0.004139
  validation loss:		0.625579
  validation accuracy:		91.20 %
Epoch 1595 of 2000 took 0.035s
  training loss:		0.004341
  validation loss:		0.630173
  validation accuracy:		91.30 %
Epoch 1596 of 2000 took 0.035s
  training loss:		0.004278
  validation loss:		0.629432
  validation accuracy:		91.20 %
Epoch 1597 of 2000 took 0.035s
  training loss:		0.004216
  validation loss:		0.630932
  validation accuracy:		91.20 %
Epoch 1598 of 2000 took 0.035s
  training loss:		0.004278
  validation loss:		0.621822
  validation accuracy:		91.20 %
Epoch 1599 of 2000 took 0.035s
  training loss:		0.004281
  validation loss:		0.632365
  validation accuracy:		91.20 %
Epoch 1600 of 2000 took 0.035s
  training loss:		0.004246
  validation loss:		0.622135
  validation accuracy:		91.20 %
Epoch 1601 of 2000 took 0.035s
  training loss:		0.004187
  validation loss:		0.621213
  validation accuracy:		91.09 %
Epoch 1602 of 2000 took 0.035s
  training loss:		0.004151
  validation loss:		0.622325
  validation accuracy:		91.30 %
Epoch 1603 of 2000 took 0.035s
  training loss:		0.004276
  validation loss:		0.626158
  validation accuracy:		91.20 %
Epoch 1604 of 2000 took 0.037s
  training loss:		0.004188
  validation loss:		0.627390
  validation accuracy:		91.20 %
Epoch 1605 of 2000 took 0.035s
  training loss:		0.004139
  validation loss:		0.621813
  validation accuracy:		91.20 %
Epoch 1606 of 2000 took 0.035s
  training loss:		0.004243
  validation loss:		0.627721
  validation accuracy:		91.20 %
Epoch 1607 of 2000 took 0.035s
  training loss:		0.004202
  validation loss:		0.623562
  validation accuracy:		91.20 %
Epoch 1608 of 2000 took 0.035s
  training loss:		0.004090
  validation loss:		0.636818
  validation accuracy:		91.20 %
Epoch 1609 of 2000 took 0.035s
  training loss:		0.004148
  validation loss:		0.634062
  validation accuracy:		91.20 %
Epoch 1610 of 2000 took 0.035s
  training loss:		0.004070
  validation loss:		0.623592
  validation accuracy:		91.30 %
Epoch 1611 of 2000 took 0.035s
  training loss:		0.004165
  validation loss:		0.632716
  validation accuracy:		91.30 %
Epoch 1612 of 2000 took 0.036s
  training loss:		0.004148
  validation loss:		0.631695
  validation accuracy:		91.20 %
Epoch 1613 of 2000 took 0.035s
  training loss:		0.004041
  validation loss:		0.632620
  validation accuracy:		91.20 %
Epoch 1614 of 2000 took 0.035s
  training loss:		0.004057
  validation loss:		0.627511
  validation accuracy:		91.20 %
Epoch 1615 of 2000 took 0.035s
  training loss:		0.004017
  validation loss:		0.622129
  validation accuracy:		91.20 %
Epoch 1616 of 2000 took 0.035s
  training loss:		0.004199
  validation loss:		0.633618
  validation accuracy:		91.20 %
Epoch 1617 of 2000 took 0.035s
  training loss:		0.003939
  validation loss:		0.633690
  validation accuracy:		91.20 %
Epoch 1618 of 2000 took 0.035s
  training loss:		0.004117
  validation loss:		0.628016
  validation accuracy:		91.20 %
Epoch 1619 of 2000 took 0.035s
  training loss:		0.004000
  validation loss:		0.627817
  validation accuracy:		91.30 %
Epoch 1620 of 2000 took 0.035s
  training loss:		0.004094
  validation loss:		0.635447
  validation accuracy:		91.20 %
Epoch 1621 of 2000 took 0.035s
  training loss:		0.003884
  validation loss:		0.624552
  validation accuracy:		91.20 %
Epoch 1622 of 2000 took 0.035s
  training loss:		0.004169
  validation loss:		0.632911
  validation accuracy:		91.30 %
Epoch 1623 of 2000 took 0.035s
  training loss:		0.003966
  validation loss:		0.625030
  validation accuracy:		91.41 %
Epoch 1624 of 2000 took 0.035s
  training loss:		0.004074
  validation loss:		0.641762
  validation accuracy:		91.20 %
Epoch 1625 of 2000 took 0.035s
  training loss:		0.004068
  validation loss:		0.634572
  validation accuracy:		91.20 %
Epoch 1626 of 2000 took 0.035s
  training loss:		0.003957
  validation loss:		0.636327
  validation accuracy:		91.30 %
Epoch 1627 of 2000 took 0.035s
  training loss:		0.003989
  validation loss:		0.630500
  validation accuracy:		91.20 %
Epoch 1628 of 2000 took 0.035s
  training loss:		0.004128
  validation loss:		0.628384
  validation accuracy:		91.20 %
Epoch 1629 of 2000 took 0.035s
  training loss:		0.004084
  validation loss:		0.632581
  validation accuracy:		91.20 %
Epoch 1630 of 2000 took 0.035s
  training loss:		0.004006
  validation loss:		0.628668
  validation accuracy:		91.20 %
Epoch 1631 of 2000 took 0.035s
  training loss:		0.003904
  validation loss:		0.643295
  validation accuracy:		91.09 %
Epoch 1632 of 2000 took 0.035s
  training loss:		0.003978
  validation loss:		0.630915
  validation accuracy:		91.20 %
Epoch 1633 of 2000 took 0.035s
  training loss:		0.003871
  validation loss:		0.636949
  validation accuracy:		91.20 %
Epoch 1634 of 2000 took 0.035s
  training loss:		0.003937
  validation loss:		0.630185
  validation accuracy:		91.20 %
Epoch 1635 of 2000 took 0.035s
  training loss:		0.003953
  validation loss:		0.629514
  validation accuracy:		91.20 %
Epoch 1636 of 2000 took 0.035s
  training loss:		0.003821
  validation loss:		0.633884
  validation accuracy:		91.20 %
Epoch 1637 of 2000 took 0.035s
  training loss:		0.003970
  validation loss:		0.628572
  validation accuracy:		91.20 %
Epoch 1638 of 2000 took 0.035s
  training loss:		0.004038
  validation loss:		0.626249
  validation accuracy:		91.30 %
Epoch 1639 of 2000 took 0.035s
  training loss:		0.004041
  validation loss:		0.641337
  validation accuracy:		91.20 %
Epoch 1640 of 2000 took 0.035s
  training loss:		0.004035
  validation loss:		0.634064
  validation accuracy:		91.20 %
Epoch 1641 of 2000 took 0.035s
  training loss:		0.003766
  validation loss:		0.632897
  validation accuracy:		91.20 %
Epoch 1642 of 2000 took 0.035s
  training loss:		0.004008
  validation loss:		0.629163
  validation accuracy:		91.30 %
Epoch 1643 of 2000 took 0.035s
  training loss:		0.003930
  validation loss:		0.635440
  validation accuracy:		91.20 %
Epoch 1644 of 2000 took 0.035s
  training loss:		0.003929
  validation loss:		0.631593
  validation accuracy:		91.20 %
Epoch 1645 of 2000 took 0.035s
  training loss:		0.003941
  validation loss:		0.636961
  validation accuracy:		91.20 %
Epoch 1646 of 2000 took 0.035s
  training loss:		0.003926
  validation loss:		0.627005
  validation accuracy:		91.20 %
Epoch 1647 of 2000 took 0.035s
  training loss:		0.003902
  validation loss:		0.629543
  validation accuracy:		91.20 %
Epoch 1648 of 2000 took 0.035s
  training loss:		0.004040
  validation loss:		0.643240
  validation accuracy:		91.20 %
Epoch 1649 of 2000 took 0.035s
  training loss:		0.003895
  validation loss:		0.627780
  validation accuracy:		91.30 %
Epoch 1650 of 2000 took 0.035s
  training loss:		0.003920
  validation loss:		0.632097
  validation accuracy:		91.20 %
Epoch 1651 of 2000 took 0.035s
  training loss:		0.003954
  validation loss:		0.632657
  validation accuracy:		91.20 %
Epoch 1652 of 2000 took 0.035s
  training loss:		0.003796
  validation loss:		0.641562
  validation accuracy:		91.20 %
Epoch 1653 of 2000 took 0.035s
  training loss:		0.003879
  validation loss:		0.632993
  validation accuracy:		91.20 %
Epoch 1654 of 2000 took 0.035s
  training loss:		0.003885
  validation loss:		0.636930
  validation accuracy:		91.20 %
Epoch 1655 of 2000 took 0.035s
  training loss:		0.003836
  validation loss:		0.638470
  validation accuracy:		91.20 %
Epoch 1656 of 2000 took 0.035s
  training loss:		0.003930
  validation loss:		0.636870
  validation accuracy:		91.30 %
Epoch 1657 of 2000 took 0.035s
  training loss:		0.003834
  validation loss:		0.637666
  validation accuracy:		91.20 %
Epoch 1658 of 2000 took 0.035s
  training loss:		0.003777
  validation loss:		0.635125
  validation accuracy:		91.30 %
Epoch 1659 of 2000 took 0.035s
  training loss:		0.003926
  validation loss:		0.631653
  validation accuracy:		91.20 %
Epoch 1660 of 2000 took 0.035s
  training loss:		0.003808
  validation loss:		0.632409
  validation accuracy:		91.30 %
Epoch 1661 of 2000 took 0.035s
  training loss:		0.003809
  validation loss:		0.631440
  validation accuracy:		91.41 %
Epoch 1662 of 2000 took 0.035s
  training loss:		0.003929
  validation loss:		0.639977
  validation accuracy:		91.20 %
Epoch 1663 of 2000 took 0.035s
  training loss:		0.003799
  validation loss:		0.631671
  validation accuracy:		91.20 %
Epoch 1664 of 2000 took 0.035s
  training loss:		0.003863
  validation loss:		0.634420
  validation accuracy:		91.30 %
Epoch 1665 of 2000 took 0.035s
  training loss:		0.003754
  validation loss:		0.638953
  validation accuracy:		91.20 %
Epoch 1666 of 2000 took 0.035s
  training loss:		0.003785
  validation loss:		0.644707
  validation accuracy:		91.30 %
Epoch 1667 of 2000 took 0.035s
  training loss:		0.003834
  validation loss:		0.644922
  validation accuracy:		91.20 %
Epoch 1668 of 2000 took 0.035s
  training loss:		0.003901
  validation loss:		0.632540
  validation accuracy:		91.30 %
Epoch 1669 of 2000 took 0.036s
  training loss:		0.003750
  validation loss:		0.645983
  validation accuracy:		91.20 %
Epoch 1670 of 2000 took 0.035s
  training loss:		0.003814
  validation loss:		0.637683
  validation accuracy:		91.20 %
Epoch 1671 of 2000 took 0.035s
  training loss:		0.003810
  validation loss:		0.634225
  validation accuracy:		91.20 %
Epoch 1672 of 2000 took 0.035s
  training loss:		0.003743
  validation loss:		0.645673
  validation accuracy:		91.20 %
Epoch 1673 of 2000 took 0.035s
  training loss:		0.003827
  validation loss:		0.636457
  validation accuracy:		91.30 %
Epoch 1674 of 2000 took 0.035s
  training loss:		0.003850
  validation loss:		0.641625
  validation accuracy:		91.20 %
Epoch 1675 of 2000 took 0.035s
  training loss:		0.003747
  validation loss:		0.634307
  validation accuracy:		91.30 %
Epoch 1676 of 2000 took 0.035s
  training loss:		0.003803
  validation loss:		0.637217
  validation accuracy:		91.20 %
Epoch 1677 of 2000 took 0.035s
  training loss:		0.003823
  validation loss:		0.647483
  validation accuracy:		91.30 %
Epoch 1678 of 2000 took 0.035s
  training loss:		0.003792
  validation loss:		0.637166
  validation accuracy:		91.30 %
Epoch 1679 of 2000 took 0.035s
  training loss:		0.003672
  validation loss:		0.633577
  validation accuracy:		91.20 %
Epoch 1680 of 2000 took 0.035s
  training loss:		0.003857
  validation loss:		0.639249
  validation accuracy:		91.20 %
Epoch 1681 of 2000 took 0.035s
  training loss:		0.003759
  validation loss:		0.639454
  validation accuracy:		91.20 %
Epoch 1682 of 2000 took 0.035s
  training loss:		0.003644
  validation loss:		0.642561
  validation accuracy:		91.20 %
Epoch 1683 of 2000 took 0.035s
  training loss:		0.003715
  validation loss:		0.640902
  validation accuracy:		91.09 %
Epoch 1684 of 2000 took 0.035s
  training loss:		0.003786
  validation loss:		0.641437
  validation accuracy:		91.30 %
Epoch 1685 of 2000 took 0.035s
  training loss:		0.003549
  validation loss:		0.638982
  validation accuracy:		91.30 %
Epoch 1686 of 2000 took 0.035s
  training loss:		0.003752
  validation loss:		0.649293
  validation accuracy:		91.20 %
Epoch 1687 of 2000 took 0.035s
  training loss:		0.003786
  validation loss:		0.638295
  validation accuracy:		91.30 %
Epoch 1688 of 2000 took 0.035s
  training loss:		0.003758
  validation loss:		0.641866
  validation accuracy:		91.09 %
Epoch 1689 of 2000 took 0.035s
  training loss:		0.003709
  validation loss:		0.647872
  validation accuracy:		91.20 %
Epoch 1690 of 2000 took 0.035s
  training loss:		0.003680
  validation loss:		0.643348
  validation accuracy:		91.20 %
Epoch 1691 of 2000 took 0.035s
  training loss:		0.003617
  validation loss:		0.649210
  validation accuracy:		91.20 %
Epoch 1692 of 2000 took 0.035s
  training loss:		0.003764
  validation loss:		0.637942
  validation accuracy:		91.20 %
Epoch 1693 of 2000 took 0.035s
  training loss:		0.003724
  validation loss:		0.643694
  validation accuracy:		91.20 %
Epoch 1694 of 2000 took 0.035s
  training loss:		0.003580
  validation loss:		0.652510
  validation accuracy:		91.20 %
Epoch 1695 of 2000 took 0.036s
  training loss:		0.003685
  validation loss:		0.642189
  validation accuracy:		91.30 %
Epoch 1696 of 2000 took 0.036s
  training loss:		0.003567
  validation loss:		0.642127
  validation accuracy:		91.30 %
Epoch 1697 of 2000 took 0.035s
  training loss:		0.003662
  validation loss:		0.640803
  validation accuracy:		91.20 %
Epoch 1698 of 2000 took 0.035s
  training loss:		0.003605
  validation loss:		0.644012
  validation accuracy:		91.20 %
Epoch 1699 of 2000 took 0.035s
  training loss:		0.003574
  validation loss:		0.641313
  validation accuracy:		91.30 %
Epoch 1700 of 2000 took 0.035s
  training loss:		0.003525
  validation loss:		0.652049
  validation accuracy:		91.20 %
Epoch 1701 of 2000 took 0.035s
  training loss:		0.003654
  validation loss:		0.645229
  validation accuracy:		91.20 %
Epoch 1702 of 2000 took 0.035s
  training loss:		0.003613
  validation loss:		0.638837
  validation accuracy:		91.20 %
Epoch 1703 of 2000 took 0.035s
  training loss:		0.003617
  validation loss:		0.640565
  validation accuracy:		91.20 %
Epoch 1704 of 2000 took 0.035s
  training loss:		0.003615
  validation loss:		0.646722
  validation accuracy:		91.20 %
Epoch 1705 of 2000 took 0.035s
  training loss:		0.003623
  validation loss:		0.645524
  validation accuracy:		91.20 %
Epoch 1706 of 2000 took 0.035s
  training loss:		0.003449
  validation loss:		0.645920
  validation accuracy:		91.30 %
Epoch 1707 of 2000 took 0.035s
  training loss:		0.003574
  validation loss:		0.644632
  validation accuracy:		91.20 %
Epoch 1708 of 2000 took 0.035s
  training loss:		0.003506
  validation loss:		0.651314
  validation accuracy:		91.20 %
Epoch 1709 of 2000 took 0.035s
  training loss:		0.003674
  validation loss:		0.645684
  validation accuracy:		91.20 %
Epoch 1710 of 2000 took 0.035s
  training loss:		0.003515
  validation loss:		0.648133
  validation accuracy:		91.20 %
Epoch 1711 of 2000 took 0.035s
  training loss:		0.003665
  validation loss:		0.652228
  validation accuracy:		91.30 %
Epoch 1712 of 2000 took 0.035s
  training loss:		0.003400
  validation loss:		0.644378
  validation accuracy:		91.30 %
Epoch 1713 of 2000 took 0.035s
  training loss:		0.003555
  validation loss:		0.649677
  validation accuracy:		91.20 %
Epoch 1714 of 2000 took 0.035s
  training loss:		0.003502
  validation loss:		0.646189
  validation accuracy:		91.20 %
Epoch 1715 of 2000 took 0.035s
  training loss:		0.003510
  validation loss:		0.648077
  validation accuracy:		91.20 %
Epoch 1716 of 2000 took 0.035s
  training loss:		0.003539
  validation loss:		0.636259
  validation accuracy:		91.30 %
Epoch 1717 of 2000 took 0.035s
  training loss:		0.003452
  validation loss:		0.650182
  validation accuracy:		91.30 %
Epoch 1718 of 2000 took 0.035s
  training loss:		0.003407
  validation loss:		0.642104
  validation accuracy:		91.30 %
Epoch 1719 of 2000 took 0.035s
  training loss:		0.003455
  validation loss:		0.642865
  validation accuracy:		91.41 %
Epoch 1720 of 2000 took 0.035s
  training loss:		0.003549
  validation loss:		0.648031
  validation accuracy:		91.30 %
Epoch 1721 of 2000 took 0.035s
  training loss:		0.003426
  validation loss:		0.651227
  validation accuracy:		91.30 %
Epoch 1722 of 2000 took 0.035s
  training loss:		0.003486
  validation loss:		0.647202
  validation accuracy:		91.20 %
Epoch 1723 of 2000 took 0.035s
  training loss:		0.003601
  validation loss:		0.651023
  validation accuracy:		91.30 %
Epoch 1724 of 2000 took 0.035s
  training loss:		0.003512
  validation loss:		0.647935
  validation accuracy:		91.20 %
Epoch 1725 of 2000 took 0.035s
  training loss:		0.003483
  validation loss:		0.646606
  validation accuracy:		91.30 %
Epoch 1726 of 2000 took 0.035s
  training loss:		0.003442
  validation loss:		0.648573
  validation accuracy:		91.20 %
Epoch 1727 of 2000 took 0.035s
  training loss:		0.003405
  validation loss:		0.646572
  validation accuracy:		91.30 %
Epoch 1728 of 2000 took 0.035s
  training loss:		0.003466
  validation loss:		0.652346
  validation accuracy:		91.20 %
Epoch 1729 of 2000 took 0.035s
  training loss:		0.003571
  validation loss:		0.648230
  validation accuracy:		91.30 %
Epoch 1730 of 2000 took 0.035s
  training loss:		0.003455
  validation loss:		0.646929
  validation accuracy:		91.20 %
Epoch 1731 of 2000 took 0.035s
  training loss:		0.003330
  validation loss:		0.647009
  validation accuracy:		91.20 %
Epoch 1732 of 2000 took 0.035s
  training loss:		0.003489
  validation loss:		0.653426
  validation accuracy:		91.30 %
Epoch 1733 of 2000 took 0.035s
  training loss:		0.003441
  validation loss:		0.647676
  validation accuracy:		91.20 %
Epoch 1734 of 2000 took 0.035s
  training loss:		0.003451
  validation loss:		0.650770
  validation accuracy:		91.30 %
Epoch 1735 of 2000 took 0.035s
  training loss:		0.003451
  validation loss:		0.648861
  validation accuracy:		91.30 %
Epoch 1736 of 2000 took 0.035s
  training loss:		0.003265
  validation loss:		0.649510
  validation accuracy:		91.20 %
Epoch 1737 of 2000 took 0.035s
  training loss:		0.003508
  validation loss:		0.647364
  validation accuracy:		91.41 %
Epoch 1738 of 2000 took 0.035s
  training loss:		0.003443
  validation loss:		0.651173
  validation accuracy:		91.30 %
Epoch 1739 of 2000 took 0.035s
  training loss:		0.003358
  validation loss:		0.650919
  validation accuracy:		91.20 %
Epoch 1740 of 2000 took 0.035s
  training loss:		0.003398
  validation loss:		0.649858
  validation accuracy:		91.20 %
Epoch 1741 of 2000 took 0.035s
  training loss:		0.003413
  validation loss:		0.651517
  validation accuracy:		91.20 %
Epoch 1742 of 2000 took 0.035s
  training loss:		0.003407
  validation loss:		0.647021
  validation accuracy:		91.30 %
Epoch 1743 of 2000 took 0.035s
  training loss:		0.003373
  validation loss:		0.651598
  validation accuracy:		91.30 %
Epoch 1744 of 2000 took 0.035s
  training loss:		0.003304
  validation loss:		0.650465
  validation accuracy:		91.30 %
Epoch 1745 of 2000 took 0.037s
  training loss:		0.003374
  validation loss:		0.645451
  validation accuracy:		91.30 %
Epoch 1746 of 2000 took 0.037s
  training loss:		0.003333
  validation loss:		0.648105
  validation accuracy:		91.20 %
Epoch 1747 of 2000 took 0.036s
  training loss:		0.003375
  validation loss:		0.649918
  validation accuracy:		91.20 %
Epoch 1748 of 2000 took 0.036s
  training loss:		0.003373
  validation loss:		0.661403
  validation accuracy:		91.20 %
Epoch 1749 of 2000 took 0.036s
  training loss:		0.003468
  validation loss:		0.644652
  validation accuracy:		91.41 %
Epoch 1750 of 2000 took 0.036s
  training loss:		0.003374
  validation loss:		0.647237
  validation accuracy:		91.30 %
Epoch 1751 of 2000 took 0.036s
  training loss:		0.003343
  validation loss:		0.654676
  validation accuracy:		91.30 %
Epoch 1752 of 2000 took 0.036s
  training loss:		0.003373
  validation loss:		0.660436
  validation accuracy:		91.20 %
Epoch 1753 of 2000 took 0.036s
  training loss:		0.003382
  validation loss:		0.653163
  validation accuracy:		91.20 %
Epoch 1754 of 2000 took 0.036s
  training loss:		0.003356
  validation loss:		0.652749
  validation accuracy:		91.30 %
Epoch 1755 of 2000 took 0.036s
  training loss:		0.003358
  validation loss:		0.657554
  validation accuracy:		91.30 %
Epoch 1756 of 2000 took 0.036s
  training loss:		0.003314
  validation loss:		0.654899
  validation accuracy:		91.20 %
Epoch 1757 of 2000 took 0.036s
  training loss:		0.003454
  validation loss:		0.654181
  validation accuracy:		91.30 %
Epoch 1758 of 2000 took 0.036s
  training loss:		0.003365
  validation loss:		0.647551
  validation accuracy:		91.30 %
Epoch 1759 of 2000 took 0.036s
  training loss:		0.003331
  validation loss:		0.646845
  validation accuracy:		91.41 %
Epoch 1760 of 2000 took 0.036s
  training loss:		0.003351
  validation loss:		0.654521
  validation accuracy:		91.30 %
Epoch 1761 of 2000 took 0.036s
  training loss:		0.003340
  validation loss:		0.647261
  validation accuracy:		91.30 %
Epoch 1762 of 2000 took 0.036s
  training loss:		0.003338
  validation loss:		0.646944
  validation accuracy:		91.41 %
Epoch 1763 of 2000 took 0.036s
  training loss:		0.003315
  validation loss:		0.663994
  validation accuracy:		91.20 %
Epoch 1764 of 2000 took 0.036s
  training loss:		0.003402
  validation loss:		0.642528
  validation accuracy:		91.30 %
Epoch 1765 of 2000 took 0.036s
  training loss:		0.003373
  validation loss:		0.652985
  validation accuracy:		91.20 %
Epoch 1766 of 2000 took 0.036s
  training loss:		0.003354
  validation loss:		0.651753
  validation accuracy:		91.30 %
Epoch 1767 of 2000 took 0.036s
  training loss:		0.003230
  validation loss:		0.651518
  validation accuracy:		91.20 %
Epoch 1768 of 2000 took 0.036s
  training loss:		0.003371
  validation loss:		0.653643
  validation accuracy:		91.30 %
Epoch 1769 of 2000 took 0.036s
  training loss:		0.003293
  validation loss:		0.662087
  validation accuracy:		91.20 %
Epoch 1770 of 2000 took 0.036s
  training loss:		0.003120
  validation loss:		0.647517
  validation accuracy:		91.30 %
Epoch 1771 of 2000 took 0.036s
  training loss:		0.003197
  validation loss:		0.658170
  validation accuracy:		91.20 %
Epoch 1772 of 2000 took 0.036s
  training loss:		0.003292
  validation loss:		0.654997
  validation accuracy:		91.20 %
Epoch 1773 of 2000 took 0.036s
  training loss:		0.003294
  validation loss:		0.665321
  validation accuracy:		91.20 %
Epoch 1774 of 2000 took 0.036s
  training loss:		0.003306
  validation loss:		0.653241
  validation accuracy:		91.20 %
Epoch 1775 of 2000 took 0.036s
  training loss:		0.003348
  validation loss:		0.658821
  validation accuracy:		91.30 %
Epoch 1776 of 2000 took 0.036s
  training loss:		0.003126
  validation loss:		0.666137
  validation accuracy:		91.09 %
Epoch 1777 of 2000 took 0.036s
  training loss:		0.003226
  validation loss:		0.652690
  validation accuracy:		91.30 %
Epoch 1778 of 2000 took 0.036s
  training loss:		0.003260
  validation loss:		0.658444
  validation accuracy:		91.30 %
Epoch 1779 of 2000 took 0.036s
  training loss:		0.003173
  validation loss:		0.656557
  validation accuracy:		91.30 %
Epoch 1780 of 2000 took 0.036s
  training loss:		0.003125
  validation loss:		0.656713
  validation accuracy:		91.30 %
Epoch 1781 of 2000 took 0.036s
  training loss:		0.003244
  validation loss:		0.656358
  validation accuracy:		91.30 %
Epoch 1782 of 2000 took 0.035s
  training loss:		0.003188
  validation loss:		0.656399
  validation accuracy:		91.30 %
Epoch 1783 of 2000 took 0.035s
  training loss:		0.003191
  validation loss:		0.665226
  validation accuracy:		91.20 %
Epoch 1784 of 2000 took 0.035s
  training loss:		0.003161
  validation loss:		0.653141
  validation accuracy:		91.41 %
Epoch 1785 of 2000 took 0.035s
  training loss:		0.003219
  validation loss:		0.669281
  validation accuracy:		91.20 %
Epoch 1786 of 2000 took 0.035s
  training loss:		0.003144
  validation loss:		0.658973
  validation accuracy:		91.30 %
Epoch 1787 of 2000 took 0.035s
  training loss:		0.003228
  validation loss:		0.661041
  validation accuracy:		91.30 %
Epoch 1788 of 2000 took 0.035s
  training loss:		0.003184
  validation loss:		0.663265
  validation accuracy:		91.30 %
Epoch 1789 of 2000 took 0.035s
  training loss:		0.003230
  validation loss:		0.654723
  validation accuracy:		91.41 %
Epoch 1790 of 2000 took 0.035s
  training loss:		0.003160
  validation loss:		0.655880
  validation accuracy:		91.30 %
Epoch 1791 of 2000 took 0.035s
  training loss:		0.003162
  validation loss:		0.659127
  validation accuracy:		91.30 %
Epoch 1792 of 2000 took 0.035s
  training loss:		0.003189
  validation loss:		0.655803
  validation accuracy:		91.30 %
Epoch 1793 of 2000 took 0.035s
  training loss:		0.003114
  validation loss:		0.658393
  validation accuracy:		91.30 %
Epoch 1794 of 2000 took 0.035s
  training loss:		0.003166
  validation loss:		0.657085
  validation accuracy:		91.30 %
Epoch 1795 of 2000 took 0.035s
  training loss:		0.003117
  validation loss:		0.657914
  validation accuracy:		91.41 %
Epoch 1796 of 2000 took 0.035s
  training loss:		0.003207
  validation loss:		0.664913
  validation accuracy:		91.30 %
Epoch 1797 of 2000 took 0.035s
  training loss:		0.003203
  validation loss:		0.652764
  validation accuracy:		91.30 %
Epoch 1798 of 2000 took 0.035s
  training loss:		0.003212
  validation loss:		0.663392
  validation accuracy:		91.30 %
Epoch 1799 of 2000 took 0.035s
  training loss:		0.003058
  validation loss:		0.662277
  validation accuracy:		91.30 %
Epoch 1800 of 2000 took 0.035s
  training loss:		0.003073
  validation loss:		0.662249
  validation accuracy:		91.30 %
Epoch 1801 of 2000 took 0.035s
  training loss:		0.003126
  validation loss:		0.662860
  validation accuracy:		91.30 %
Epoch 1802 of 2000 took 0.035s
  training loss:		0.003178
  validation loss:		0.656940
  validation accuracy:		91.30 %
Epoch 1803 of 2000 took 0.035s
  training loss:		0.003111
  validation loss:		0.661929
  validation accuracy:		91.30 %
Epoch 1804 of 2000 took 0.035s
  training loss:		0.003195
  validation loss:		0.654646
  validation accuracy:		91.41 %
Epoch 1805 of 2000 took 0.035s
  training loss:		0.003138
  validation loss:		0.657478
  validation accuracy:		91.30 %
Epoch 1806 of 2000 took 0.035s
  training loss:		0.003045
  validation loss:		0.657982
  validation accuracy:		91.30 %
Epoch 1807 of 2000 took 0.035s
  training loss:		0.003160
  validation loss:		0.664678
  validation accuracy:		91.30 %
Epoch 1808 of 2000 took 0.035s
  training loss:		0.003214
  validation loss:		0.661760
  validation accuracy:		91.20 %
Epoch 1809 of 2000 took 0.035s
  training loss:		0.003068
  validation loss:		0.663833
  validation accuracy:		91.09 %
Epoch 1810 of 2000 took 0.035s
  training loss:		0.003078
  validation loss:		0.654617
  validation accuracy:		91.30 %
Epoch 1811 of 2000 took 0.035s
  training loss:		0.003108
  validation loss:		0.661629
  validation accuracy:		91.20 %
Epoch 1812 of 2000 took 0.035s
  training loss:		0.003081
  validation loss:		0.663329
  validation accuracy:		91.41 %
Epoch 1813 of 2000 took 0.035s
  training loss:		0.003042
  validation loss:		0.657400
  validation accuracy:		91.41 %
Epoch 1814 of 2000 took 0.035s
  training loss:		0.003044
  validation loss:		0.657766
  validation accuracy:		91.30 %
Epoch 1815 of 2000 took 0.035s
  training loss:		0.003114
  validation loss:		0.655543
  validation accuracy:		91.52 %
Epoch 1816 of 2000 took 0.035s
  training loss:		0.003069
  validation loss:		0.664091
  validation accuracy:		91.20 %
Epoch 1817 of 2000 took 0.035s
  training loss:		0.003075
  validation loss:		0.663588
  validation accuracy:		91.30 %
Epoch 1818 of 2000 took 0.035s
  training loss:		0.003034
  validation loss:		0.663149
  validation accuracy:		91.30 %
Epoch 1819 of 2000 took 0.035s
  training loss:		0.003115
  validation loss:		0.667142
  validation accuracy:		91.30 %
Epoch 1820 of 2000 took 0.035s
  training loss:		0.003104
  validation loss:		0.662128
  validation accuracy:		91.41 %
Epoch 1821 of 2000 took 0.035s
  training loss:		0.003021
  validation loss:		0.659019
  validation accuracy:		91.41 %
Epoch 1822 of 2000 took 0.035s
  training loss:		0.003160
  validation loss:		0.660499
  validation accuracy:		91.30 %
Epoch 1823 of 2000 took 0.035s
  training loss:		0.003137
  validation loss:		0.665656
  validation accuracy:		91.30 %
Epoch 1824 of 2000 took 0.035s
  training loss:		0.003092
  validation loss:		0.657844
  validation accuracy:		91.41 %
Epoch 1825 of 2000 took 0.035s
  training loss:		0.003055
  validation loss:		0.669463
  validation accuracy:		91.20 %
Epoch 1826 of 2000 took 0.035s
  training loss:		0.003058
  validation loss:		0.665566
  validation accuracy:		91.30 %
Epoch 1827 of 2000 took 0.035s
  training loss:		0.003099
  validation loss:		0.663973
  validation accuracy:		91.41 %
Epoch 1828 of 2000 took 0.035s
  training loss:		0.003028
  validation loss:		0.669823
  validation accuracy:		91.30 %
Epoch 1829 of 2000 took 0.035s
  training loss:		0.003130
  validation loss:		0.672503
  validation accuracy:		91.30 %
Epoch 1830 of 2000 took 0.035s
  training loss:		0.003044
  validation loss:		0.656045
  validation accuracy:		91.30 %
Epoch 1831 of 2000 took 0.035s
  training loss:		0.003097
  validation loss:		0.666775
  validation accuracy:		91.30 %
Epoch 1832 of 2000 took 0.035s
  training loss:		0.002978
  validation loss:		0.661766
  validation accuracy:		91.41 %
Epoch 1833 of 2000 took 0.035s
  training loss:		0.003086
  validation loss:		0.660730
  validation accuracy:		91.30 %
Epoch 1834 of 2000 took 0.035s
  training loss:		0.003121
  validation loss:		0.667166
  validation accuracy:		91.41 %
Epoch 1835 of 2000 took 0.035s
  training loss:		0.002990
  validation loss:		0.670104
  validation accuracy:		91.20 %
Epoch 1836 of 2000 took 0.035s
  training loss:		0.002953
  validation loss:		0.658577
  validation accuracy:		91.63 %
Epoch 1837 of 2000 took 0.035s
  training loss:		0.002990
  validation loss:		0.669627
  validation accuracy:		91.30 %
Epoch 1838 of 2000 took 0.035s
  training loss:		0.003054
  validation loss:		0.670774
  validation accuracy:		91.20 %
Epoch 1839 of 2000 took 0.035s
  training loss:		0.002923
  validation loss:		0.663012
  validation accuracy:		91.41 %
Epoch 1840 of 2000 took 0.035s
  training loss:		0.003016
  validation loss:		0.670233
  validation accuracy:		91.20 %
Epoch 1841 of 2000 took 0.035s
  training loss:		0.002989
  validation loss:		0.662076
  validation accuracy:		91.41 %
Epoch 1842 of 2000 took 0.035s
  training loss:		0.002960
  validation loss:		0.662822
  validation accuracy:		91.30 %
Epoch 1843 of 2000 took 0.035s
  training loss:		0.002934
  validation loss:		0.663908
  validation accuracy:		91.41 %
Epoch 1844 of 2000 took 0.035s
  training loss:		0.002985
  validation loss:		0.669819
  validation accuracy:		91.20 %
Epoch 1845 of 2000 took 0.035s
  training loss:		0.002961
  validation loss:		0.666445
  validation accuracy:		91.41 %
Epoch 1846 of 2000 took 0.035s
  training loss:		0.003072
  validation loss:		0.665386
  validation accuracy:		91.41 %
Epoch 1847 of 2000 took 0.035s
  training loss:		0.003005
  validation loss:		0.670146
  validation accuracy:		91.30 %
Epoch 1848 of 2000 took 0.035s
  training loss:		0.002919
  validation loss:		0.665556
  validation accuracy:		91.41 %
Epoch 1849 of 2000 took 0.035s
  training loss:		0.002902
  validation loss:		0.668346
  validation accuracy:		91.30 %
Epoch 1850 of 2000 took 0.035s
  training loss:		0.002921
  validation loss:		0.665406
  validation accuracy:		91.30 %
Epoch 1851 of 2000 took 0.035s
  training loss:		0.002889
  validation loss:		0.672324
  validation accuracy:		91.30 %
Epoch 1852 of 2000 took 0.035s
  training loss:		0.002931
  validation loss:		0.666636
  validation accuracy:		91.41 %
Epoch 1853 of 2000 took 0.035s
  training loss:		0.002914
  validation loss:		0.663686
  validation accuracy:		91.30 %
Epoch 1854 of 2000 took 0.035s
  training loss:		0.002884
  validation loss:		0.671351
  validation accuracy:		91.30 %
Epoch 1855 of 2000 took 0.035s
  training loss:		0.002867
  validation loss:		0.669760
  validation accuracy:		91.30 %
Epoch 1856 of 2000 took 0.035s
  training loss:		0.002953
  validation loss:		0.666364
  validation accuracy:		91.30 %
Epoch 1857 of 2000 took 0.035s
  training loss:		0.002914
  validation loss:		0.666906
  validation accuracy:		91.41 %
Epoch 1858 of 2000 took 0.035s
  training loss:		0.002935
  validation loss:		0.668000
  validation accuracy:		91.30 %
Epoch 1859 of 2000 took 0.035s
  training loss:		0.002997
  validation loss:		0.672674
  validation accuracy:		91.41 %
Epoch 1860 of 2000 took 0.035s
  training loss:		0.002952
  validation loss:		0.668856
  validation accuracy:		91.30 %
Epoch 1861 of 2000 took 0.035s
  training loss:		0.002959
  validation loss:		0.673284
  validation accuracy:		91.41 %
Epoch 1862 of 2000 took 0.035s
  training loss:		0.002884
  validation loss:		0.669853
  validation accuracy:		91.41 %
Epoch 1863 of 2000 took 0.035s
  training loss:		0.002780
  validation loss:		0.668243
  validation accuracy:		91.52 %
Epoch 1864 of 2000 took 0.035s
  training loss:		0.002940
  validation loss:		0.664853
  validation accuracy:		91.41 %
Epoch 1865 of 2000 took 0.035s
  training loss:		0.002852
  validation loss:		0.674861
  validation accuracy:		91.30 %
Epoch 1866 of 2000 took 0.035s
  training loss:		0.002871
  validation loss:		0.670597
  validation accuracy:		91.30 %
Epoch 1867 of 2000 took 0.036s
  training loss:		0.002796
  validation loss:		0.671563
  validation accuracy:		91.30 %
Epoch 1868 of 2000 took 0.036s
  training loss:		0.002938
  validation loss:		0.669533
  validation accuracy:		91.52 %
Epoch 1869 of 2000 took 0.035s
  training loss:		0.002865
  validation loss:		0.672063
  validation accuracy:		91.41 %
Epoch 1870 of 2000 took 0.035s
  training loss:		0.002726
  validation loss:		0.668939
  validation accuracy:		91.41 %
Epoch 1871 of 2000 took 0.035s
  training loss:		0.002912
  validation loss:		0.669854
  validation accuracy:		91.52 %
Epoch 1872 of 2000 took 0.035s
  training loss:		0.002861
  validation loss:		0.668009
  validation accuracy:		91.41 %
Epoch 1873 of 2000 took 0.035s
  training loss:		0.002829
  validation loss:		0.673023
  validation accuracy:		91.30 %
Epoch 1874 of 2000 took 0.035s
  training loss:		0.002821
  validation loss:		0.670645
  validation accuracy:		91.41 %
Epoch 1875 of 2000 took 0.035s
  training loss:		0.002782
  validation loss:		0.676602
  validation accuracy:		91.41 %
Epoch 1876 of 2000 took 0.035s
  training loss:		0.002820
  validation loss:		0.667018
  validation accuracy:		91.41 %
Epoch 1877 of 2000 took 0.035s
  training loss:		0.002745
  validation loss:		0.670119
  validation accuracy:		91.41 %
Epoch 1878 of 2000 took 0.035s
  training loss:		0.002777
  validation loss:		0.670432
  validation accuracy:		91.30 %
Epoch 1879 of 2000 took 0.035s
  training loss:		0.002774
  validation loss:		0.671573
  validation accuracy:		91.30 %
Epoch 1880 of 2000 took 0.035s
  training loss:		0.002869
  validation loss:		0.671871
  validation accuracy:		91.30 %
Epoch 1881 of 2000 took 0.035s
  training loss:		0.002844
  validation loss:		0.678966
  validation accuracy:		91.30 %
Epoch 1882 of 2000 took 0.035s
  training loss:		0.002856
  validation loss:		0.666011
  validation accuracy:		91.41 %
Epoch 1883 of 2000 took 0.035s
  training loss:		0.002916
  validation loss:		0.668653
  validation accuracy:		91.41 %
Epoch 1884 of 2000 took 0.035s
  training loss:		0.002901
  validation loss:		0.677046
  validation accuracy:		91.41 %
Epoch 1885 of 2000 took 0.035s
  training loss:		0.002822
  validation loss:		0.670021
  validation accuracy:		91.30 %
Epoch 1886 of 2000 took 0.035s
  training loss:		0.002735
  validation loss:		0.677020
  validation accuracy:		91.41 %
Epoch 1887 of 2000 took 0.035s
  training loss:		0.002871
  validation loss:		0.674588
  validation accuracy:		91.41 %
Epoch 1888 of 2000 took 0.035s
  training loss:		0.002740
  validation loss:		0.678452
  validation accuracy:		91.41 %
Epoch 1889 of 2000 took 0.035s
  training loss:		0.002797
  validation loss:		0.667438
  validation accuracy:		91.52 %
Epoch 1890 of 2000 took 0.035s
  training loss:		0.002739
  validation loss:		0.672527
  validation accuracy:		91.30 %
Epoch 1891 of 2000 took 0.035s
  training loss:		0.002814
  validation loss:		0.676359
  validation accuracy:		91.41 %
Epoch 1892 of 2000 took 0.035s
  training loss:		0.002704
  validation loss:		0.671956
  validation accuracy:		91.41 %
Epoch 1893 of 2000 took 0.035s
  training loss:		0.002798
  validation loss:		0.676158
  validation accuracy:		91.20 %
Epoch 1894 of 2000 took 0.035s
  training loss:		0.002839
  validation loss:		0.673456
  validation accuracy:		91.52 %
Epoch 1895 of 2000 took 0.036s
  training loss:		0.002810
  validation loss:		0.679278
  validation accuracy:		91.30 %
Epoch 1896 of 2000 took 0.035s
  training loss:		0.002820
  validation loss:		0.669428
  validation accuracy:		91.41 %
Epoch 1897 of 2000 took 0.035s
  training loss:		0.002807
  validation loss:		0.677460
  validation accuracy:		91.41 %
Epoch 1898 of 2000 took 0.035s
  training loss:		0.002861
  validation loss:		0.670595
  validation accuracy:		91.52 %
Epoch 1899 of 2000 took 0.035s
  training loss:		0.002816
  validation loss:		0.679138
  validation accuracy:		91.30 %
Epoch 1900 of 2000 took 0.035s
  training loss:		0.002683
  validation loss:		0.668569
  validation accuracy:		91.52 %
Epoch 1901 of 2000 took 0.035s
  training loss:		0.002791
  validation loss:		0.674515
  validation accuracy:		91.20 %
Epoch 1902 of 2000 took 0.035s
  training loss:		0.002756
  validation loss:		0.677529
  validation accuracy:		91.41 %
Epoch 1903 of 2000 took 0.035s
  training loss:		0.002819
  validation loss:		0.672675
  validation accuracy:		91.41 %
Epoch 1904 of 2000 took 0.035s
  training loss:		0.002695
  validation loss:		0.678163
  validation accuracy:		91.20 %
Epoch 1905 of 2000 took 0.035s
  training loss:		0.002820
  validation loss:		0.677950
  validation accuracy:		91.30 %
Epoch 1906 of 2000 took 0.035s
  training loss:		0.002742
  validation loss:		0.672790
  validation accuracy:		91.41 %
Epoch 1907 of 2000 took 0.035s
  training loss:		0.002795
  validation loss:		0.675221
  validation accuracy:		91.41 %
Epoch 1908 of 2000 took 0.035s
  training loss:		0.002727
  validation loss:		0.677554
  validation accuracy:		91.41 %
Epoch 1909 of 2000 took 0.035s
  training loss:		0.002779
  validation loss:		0.674942
  validation accuracy:		91.52 %
Epoch 1910 of 2000 took 0.035s
  training loss:		0.002744
  validation loss:		0.677124
  validation accuracy:		91.52 %
Epoch 1911 of 2000 took 0.035s
  training loss:		0.002736
  validation loss:		0.676383
  validation accuracy:		91.41 %
Epoch 1912 of 2000 took 0.035s
  training loss:		0.002583
  validation loss:		0.680730
  validation accuracy:		91.30 %
Epoch 1913 of 2000 took 0.035s
  training loss:		0.002664
  validation loss:		0.674660
  validation accuracy:		91.52 %
Epoch 1914 of 2000 took 0.035s
  training loss:		0.002698
  validation loss:		0.679705
  validation accuracy:		91.20 %
Epoch 1915 of 2000 took 0.035s
  training loss:		0.002661
  validation loss:		0.681636
  validation accuracy:		91.41 %
Epoch 1916 of 2000 took 0.035s
  training loss:		0.002661
  validation loss:		0.673105
  validation accuracy:		91.41 %
Epoch 1917 of 2000 took 0.035s
  training loss:		0.002740
  validation loss:		0.678957
  validation accuracy:		91.30 %
Epoch 1918 of 2000 took 0.035s
  training loss:		0.002718
  validation loss:		0.680413
  validation accuracy:		91.20 %
Epoch 1919 of 2000 took 0.035s
  training loss:		0.002648
  validation loss:		0.676403
  validation accuracy:		91.52 %
Epoch 1920 of 2000 took 0.035s
  training loss:		0.002671
  validation loss:		0.673130
  validation accuracy:		91.52 %
Epoch 1921 of 2000 took 0.035s
  training loss:		0.002693
  validation loss:		0.686952
  validation accuracy:		91.20 %
Epoch 1922 of 2000 took 0.035s
  training loss:		0.002698
  validation loss:		0.668001
  validation accuracy:		91.52 %
Epoch 1923 of 2000 took 0.035s
  training loss:		0.002698
  validation loss:		0.678951
  validation accuracy:		91.41 %
Epoch 1924 of 2000 took 0.035s
  training loss:		0.002664
  validation loss:		0.678482
  validation accuracy:		91.30 %
Epoch 1925 of 2000 took 0.035s
  training loss:		0.002740
  validation loss:		0.678745
  validation accuracy:		91.41 %
Epoch 1926 of 2000 took 0.035s
  training loss:		0.002614
  validation loss:		0.676430
  validation accuracy:		91.52 %
Epoch 1927 of 2000 took 0.035s
  training loss:		0.002765
  validation loss:		0.680437
  validation accuracy:		91.41 %
Epoch 1928 of 2000 took 0.035s
  training loss:		0.002584
  validation loss:		0.670947
  validation accuracy:		91.63 %
Epoch 1929 of 2000 took 0.035s
  training loss:		0.002663
  validation loss:		0.678936
  validation accuracy:		91.52 %
Epoch 1930 of 2000 took 0.035s
  training loss:		0.002679
  validation loss:		0.677782
  validation accuracy:		91.52 %
Epoch 1931 of 2000 took 0.035s
  training loss:		0.002556
  validation loss:		0.678133
  validation accuracy:		91.52 %
Epoch 1932 of 2000 took 0.035s
  training loss:		0.002725
  validation loss:		0.674983
  validation accuracy:		91.41 %
Epoch 1933 of 2000 took 0.035s
  training loss:		0.002682
  validation loss:		0.680950
  validation accuracy:		91.41 %
Epoch 1934 of 2000 took 0.035s
  training loss:		0.002654
  validation loss:		0.682934
  validation accuracy:		91.52 %
Epoch 1935 of 2000 took 0.035s
  training loss:		0.002681
  validation loss:		0.679905
  validation accuracy:		91.41 %
Epoch 1936 of 2000 took 0.035s
  training loss:		0.002572
  validation loss:		0.677355
  validation accuracy:		91.52 %
Epoch 1937 of 2000 took 0.035s
  training loss:		0.002578
  validation loss:		0.678075
  validation accuracy:		91.41 %
Epoch 1938 of 2000 took 0.035s
  training loss:		0.002707
  validation loss:		0.682884
  validation accuracy:		91.30 %
Epoch 1939 of 2000 took 0.035s
  training loss:		0.002667
  validation loss:		0.673259
  validation accuracy:		91.41 %
Epoch 1940 of 2000 took 0.035s
  training loss:		0.002662
  validation loss:		0.686644
  validation accuracy:		91.30 %
Epoch 1941 of 2000 took 0.035s
  training loss:		0.002682
  validation loss:		0.684421
  validation accuracy:		91.41 %
Epoch 1942 of 2000 took 0.035s
  training loss:		0.002660
  validation loss:		0.684480
  validation accuracy:		91.41 %
Epoch 1943 of 2000 took 0.035s
  training loss:		0.002623
  validation loss:		0.675741
  validation accuracy:		91.52 %
Epoch 1944 of 2000 took 0.035s
  training loss:		0.002702
  validation loss:		0.677015
  validation accuracy:		91.41 %
Epoch 1945 of 2000 took 0.035s
  training loss:		0.002689
  validation loss:		0.679798
  validation accuracy:		91.41 %
Epoch 1946 of 2000 took 0.035s
  training loss:		0.002661
  validation loss:		0.685007
  validation accuracy:		91.52 %
Epoch 1947 of 2000 took 0.035s
  training loss:		0.002544
  validation loss:		0.679904
  validation accuracy:		91.41 %
Epoch 1948 of 2000 took 0.035s
  training loss:		0.002577
  validation loss:		0.683615
  validation accuracy:		91.41 %
Epoch 1949 of 2000 took 0.035s
  training loss:		0.002579
  validation loss:		0.688949
  validation accuracy:		91.30 %
Epoch 1950 of 2000 took 0.036s
  training loss:		0.002660
  validation loss:		0.681939
  validation accuracy:		91.52 %
Epoch 1951 of 2000 took 0.035s
  training loss:		0.002631
  validation loss:		0.675930
  validation accuracy:		91.52 %
Epoch 1952 of 2000 took 0.036s
  training loss:		0.002489
  validation loss:		0.692471
  validation accuracy:		91.41 %
Epoch 1953 of 2000 took 0.035s
  training loss:		0.002665
  validation loss:		0.677246
  validation accuracy:		91.41 %
Epoch 1954 of 2000 took 0.035s
  training loss:		0.002619
  validation loss:		0.685061
  validation accuracy:		91.30 %
Epoch 1955 of 2000 took 0.035s
  training loss:		0.002617
  validation loss:		0.683463
  validation accuracy:		91.52 %
Epoch 1956 of 2000 took 0.035s
  training loss:		0.002687
  validation loss:		0.682867
  validation accuracy:		91.52 %
Epoch 1957 of 2000 took 0.035s
  training loss:		0.002631
  validation loss:		0.681568
  validation accuracy:		91.52 %
Epoch 1958 of 2000 took 0.035s
  training loss:		0.002539
  validation loss:		0.690920
  validation accuracy:		91.52 %
Epoch 1959 of 2000 took 0.035s
  training loss:		0.002637
  validation loss:		0.684617
  validation accuracy:		91.52 %
Epoch 1960 of 2000 took 0.035s
  training loss:		0.002590
  validation loss:		0.681906
  validation accuracy:		91.41 %
Epoch 1961 of 2000 took 0.035s
  training loss:		0.002511
  validation loss:		0.683032
  validation accuracy:		91.41 %
Epoch 1962 of 2000 took 0.035s
  training loss:		0.002559
  validation loss:		0.685136
  validation accuracy:		91.52 %
Epoch 1963 of 2000 took 0.035s
  training loss:		0.002608
  validation loss:		0.677229
  validation accuracy:		91.52 %
Epoch 1964 of 2000 took 0.035s
  training loss:		0.002563
  validation loss:		0.678425
  validation accuracy:		91.52 %
Epoch 1965 of 2000 took 0.035s
  training loss:		0.002506
  validation loss:		0.682888
  validation accuracy:		91.52 %
Epoch 1966 of 2000 took 0.035s
  training loss:		0.002548
  validation loss:		0.686602
  validation accuracy:		91.52 %
Epoch 1967 of 2000 took 0.035s
  training loss:		0.002441
  validation loss:		0.680682
  validation accuracy:		91.52 %
Epoch 1968 of 2000 took 0.035s
  training loss:		0.002600
  validation loss:		0.684284
  validation accuracy:		91.52 %
Epoch 1969 of 2000 took 0.035s
  training loss:		0.002537
  validation loss:		0.685710
  validation accuracy:		91.52 %
Epoch 1970 of 2000 took 0.035s
  training loss:		0.002589
  validation loss:		0.683693
  validation accuracy:		91.52 %
Epoch 1971 of 2000 took 0.035s
  training loss:		0.002510
  validation loss:		0.689015
  validation accuracy:		91.41 %
Epoch 1972 of 2000 took 0.035s
  training loss:		0.002537
  validation loss:		0.683977
  validation accuracy:		91.52 %
Epoch 1973 of 2000 took 0.035s
  training loss:		0.002570
  validation loss:		0.687021
  validation accuracy:		91.52 %
Epoch 1974 of 2000 took 0.035s
  training loss:		0.002596
  validation loss:		0.681808
  validation accuracy:		91.52 %
Epoch 1975 of 2000 took 0.035s
  training loss:		0.002490
  validation loss:		0.681342
  validation accuracy:		91.41 %
Epoch 1976 of 2000 took 0.035s
  training loss:		0.002499
  validation loss:		0.687762
  validation accuracy:		91.52 %
Epoch 1977 of 2000 took 0.035s
  training loss:		0.002509
  validation loss:		0.688465
  validation accuracy:		91.52 %
Epoch 1978 of 2000 took 0.035s
  training loss:		0.002574
  validation loss:		0.680918
  validation accuracy:		91.52 %
Epoch 1979 of 2000 took 0.035s
  training loss:		0.002525
  validation loss:		0.685200
  validation accuracy:		91.41 %
Epoch 1980 of 2000 took 0.035s
  training loss:		0.002507
  validation loss:		0.686754
  validation accuracy:		91.52 %
Epoch 1981 of 2000 took 0.035s
  training loss:		0.002492
  validation loss:		0.685287
  validation accuracy:		91.52 %
Epoch 1982 of 2000 took 0.035s
  training loss:		0.002502
  validation loss:		0.686701
  validation accuracy:		91.52 %
Epoch 1983 of 2000 took 0.035s
  training loss:		0.002433
  validation loss:		0.683809
  validation accuracy:		91.52 %
Epoch 1984 of 2000 took 0.035s
  training loss:		0.002493
  validation loss:		0.689904
  validation accuracy:		91.41 %
Epoch 1985 of 2000 took 0.035s
  training loss:		0.002431
  validation loss:		0.683205
  validation accuracy:		91.52 %
Epoch 1986 of 2000 took 0.035s
  training loss:		0.002537
  validation loss:		0.690926
  validation accuracy:		91.41 %
Epoch 1987 of 2000 took 0.035s
  training loss:		0.002462
  validation loss:		0.688224
  validation accuracy:		91.41 %
Epoch 1988 of 2000 took 0.035s
  training loss:		0.002555
  validation loss:		0.692298
  validation accuracy:		91.52 %
Epoch 1989 of 2000 took 0.035s
  training loss:		0.002428
  validation loss:		0.685367
  validation accuracy:		91.52 %
Epoch 1990 of 2000 took 0.035s
  training loss:		0.002407
  validation loss:		0.690253
  validation accuracy:		91.41 %
Epoch 1991 of 2000 took 0.035s
  training loss:		0.002527
  validation loss:		0.684390
  validation accuracy:		91.52 %
Epoch 1992 of 2000 took 0.035s
  training loss:		0.002420
  validation loss:		0.687482
  validation accuracy:		91.52 %
Epoch 1993 of 2000 took 0.035s
  training loss:		0.002463
  validation loss:		0.683527
  validation accuracy:		91.52 %
Epoch 1994 of 2000 took 0.035s
  training loss:		0.002398
  validation loss:		0.686540
  validation accuracy:		91.52 %
Epoch 1995 of 2000 took 0.035s
  training loss:		0.002491
  validation loss:		0.685538
  validation accuracy:		91.52 %
Epoch 1996 of 2000 took 0.035s
  training loss:		0.002455
  validation loss:		0.690396
  validation accuracy:		91.41 %
Epoch 1997 of 2000 took 0.035s
  training loss:		0.002484
  validation loss:		0.685204
  validation accuracy:		91.52 %
Epoch 1998 of 2000 took 0.035s
  training loss:		0.002458
  validation loss:		0.684623
  validation accuracy:		91.52 %
Epoch 1999 of 2000 took 0.035s
  training loss:		0.002504
  validation loss:		0.684466
  validation accuracy:		91.52 %
Epoch 2000 of 2000 took 0.035s
  training loss:		0.002479
  validation loss:		0.688804
  validation accuracy:		91.52 %
Final results:
  test loss:			1.543105
  test accuracy:		83.66 %
