Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 200),b=(200,)
decomposing tensor W of shape (1, 200, 200)...
decomposing tensor B of shape (1, 200)...
Starting training...
Epoch 1 of 2000 took 0.052s
  training loss:		2.955507
  validation loss:		2.869518
  validation accuracy:		10.11 %
Epoch 2 of 2000 took 0.043s
  training loss:		2.790378
  validation loss:		2.663128
  validation accuracy:		18.80 %
Epoch 3 of 2000 took 0.040s
  training loss:		2.596222
  validation loss:		2.452131
  validation accuracy:		20.22 %
Epoch 4 of 2000 took 0.038s
  training loss:		2.423122
  validation loss:		2.283259
  validation accuracy:		31.85 %
Epoch 5 of 2000 took 0.039s
  training loss:		2.302432
  validation loss:		2.186059
  validation accuracy:		49.57 %
Epoch 6 of 2000 took 0.038s
  training loss:		2.232740
  validation loss:		2.139599
  validation accuracy:		56.85 %
Epoch 7 of 2000 took 0.039s
  training loss:		2.188748
  validation loss:		2.107443
  validation accuracy:		57.07 %
Epoch 8 of 2000 took 0.061s
  training loss:		2.153515
  validation loss:		2.069570
  validation accuracy:		61.52 %
Epoch 9 of 2000 took 0.054s
  training loss:		2.118253
  validation loss:		2.028494
  validation accuracy:		60.22 %
Epoch 10 of 2000 took 0.045s
  training loss:		2.082460
  validation loss:		1.986579
  validation accuracy:		65.76 %
Epoch 11 of 2000 took 0.042s
  training loss:		2.044434
  validation loss:		1.949911
  validation accuracy:		66.30 %
Epoch 12 of 2000 took 0.039s
  training loss:		2.004999
  validation loss:		1.904115
  validation accuracy:		67.50 %
Epoch 13 of 2000 took 0.038s
  training loss:		1.959288
  validation loss:		1.854314
  validation accuracy:		67.50 %
Epoch 14 of 2000 took 0.038s
  training loss:		1.915129
  validation loss:		1.798926
  validation accuracy:		70.54 %
Epoch 15 of 2000 took 0.038s
  training loss:		1.859356
  validation loss:		1.739146
  validation accuracy:		71.20 %
Epoch 16 of 2000 took 0.038s
  training loss:		1.804695
  validation loss:		1.681038
  validation accuracy:		74.02 %
Epoch 17 of 2000 took 0.038s
  training loss:		1.746393
  validation loss:		1.613655
  validation accuracy:		74.89 %
Epoch 18 of 2000 took 0.039s
  training loss:		1.681455
  validation loss:		1.554415
  validation accuracy:		76.63 %
Epoch 19 of 2000 took 0.039s
  training loss:		1.619248
  validation loss:		1.476871
  validation accuracy:		76.85 %
Epoch 20 of 2000 took 0.038s
  training loss:		1.550549
  validation loss:		1.410608
  validation accuracy:		75.22 %
Epoch 21 of 2000 took 0.038s
  training loss:		1.492096
  validation loss:		1.356355
  validation accuracy:		78.48 %
Epoch 22 of 2000 took 0.039s
  training loss:		1.422314
  validation loss:		1.284389
  validation accuracy:		78.80 %
Epoch 23 of 2000 took 0.037s
  training loss:		1.364719
  validation loss:		1.229833
  validation accuracy:		79.57 %
Epoch 24 of 2000 took 0.035s
  training loss:		1.309464
  validation loss:		1.171196
  validation accuracy:		80.54 %
Epoch 25 of 2000 took 0.035s
  training loss:		1.251926
  validation loss:		1.120863
  validation accuracy:		81.74 %
Epoch 26 of 2000 took 0.035s
  training loss:		1.199547
  validation loss:		1.069456
  validation accuracy:		81.20 %
Epoch 27 of 2000 took 0.035s
  training loss:		1.147363
  validation loss:		1.020400
  validation accuracy:		81.41 %
Epoch 28 of 2000 took 0.035s
  training loss:		1.101302
  validation loss:		0.977167
  validation accuracy:		81.96 %
Epoch 29 of 2000 took 0.035s
  training loss:		1.054704
  validation loss:		0.937609
  validation accuracy:		83.04 %
Epoch 30 of 2000 took 0.035s
  training loss:		1.011442
  validation loss:		0.897127
  validation accuracy:		83.37 %
Epoch 31 of 2000 took 0.035s
  training loss:		0.966172
  validation loss:		0.858051
  validation accuracy:		84.35 %
Epoch 32 of 2000 took 0.035s
  training loss:		0.932493
  validation loss:		0.823715
  validation accuracy:		84.35 %
Epoch 33 of 2000 took 0.035s
  training loss:		0.894734
  validation loss:		0.799326
  validation accuracy:		84.57 %
Epoch 34 of 2000 took 0.035s
  training loss:		0.858742
  validation loss:		0.761243
  validation accuracy:		85.33 %
Epoch 35 of 2000 took 0.035s
  training loss:		0.834707
  validation loss:		0.737672
  validation accuracy:		84.78 %
Epoch 36 of 2000 took 0.035s
  training loss:		0.799600
  validation loss:		0.703489
  validation accuracy:		85.98 %
Epoch 37 of 2000 took 0.035s
  training loss:		0.773573
  validation loss:		0.679875
  validation accuracy:		85.76 %
Epoch 38 of 2000 took 0.035s
  training loss:		0.743271
  validation loss:		0.655795
  validation accuracy:		86.20 %
Epoch 39 of 2000 took 0.035s
  training loss:		0.718407
  validation loss:		0.648068
  validation accuracy:		85.98 %
Epoch 40 of 2000 took 0.035s
  training loss:		0.697775
  validation loss:		0.614991
  validation accuracy:		86.63 %
Epoch 41 of 2000 took 0.035s
  training loss:		0.673637
  validation loss:		0.599053
  validation accuracy:		86.63 %
Epoch 42 of 2000 took 0.035s
  training loss:		0.653580
  validation loss:		0.579604
  validation accuracy:		87.17 %
Epoch 43 of 2000 took 0.035s
  training loss:		0.629131
  validation loss:		0.565617
  validation accuracy:		87.07 %
Epoch 44 of 2000 took 0.035s
  training loss:		0.615813
  validation loss:		0.547998
  validation accuracy:		87.50 %
Epoch 45 of 2000 took 0.035s
  training loss:		0.593879
  validation loss:		0.535564
  validation accuracy:		87.61 %
Epoch 46 of 2000 took 0.036s
  training loss:		0.573534
  validation loss:		0.510761
  validation accuracy:		88.26 %
Epoch 47 of 2000 took 0.035s
  training loss:		0.554435
  validation loss:		0.495702
  validation accuracy:		88.80 %
Epoch 48 of 2000 took 0.035s
  training loss:		0.541175
  validation loss:		0.490376
  validation accuracy:		88.70 %
Epoch 49 of 2000 took 0.035s
  training loss:		0.526763
  validation loss:		0.470653
  validation accuracy:		88.91 %
Epoch 50 of 2000 took 0.035s
  training loss:		0.515356
  validation loss:		0.464509
  validation accuracy:		89.02 %
Epoch 51 of 2000 took 0.035s
  training loss:		0.506735
  validation loss:		0.455810
  validation accuracy:		89.13 %
Epoch 52 of 2000 took 0.035s
  training loss:		0.490959
  validation loss:		0.438900
  validation accuracy:		89.35 %
Epoch 53 of 2000 took 0.035s
  training loss:		0.483353
  validation loss:		0.428613
  validation accuracy:		89.78 %
Epoch 54 of 2000 took 0.035s
  training loss:		0.471879
  validation loss:		0.418939
  validation accuracy:		89.78 %
Epoch 55 of 2000 took 0.035s
  training loss:		0.456156
  validation loss:		0.413245
  validation accuracy:		89.35 %
Epoch 56 of 2000 took 0.035s
  training loss:		0.447655
  validation loss:		0.393957
  validation accuracy:		90.00 %
Epoch 57 of 2000 took 0.035s
  training loss:		0.435274
  validation loss:		0.399493
  validation accuracy:		90.22 %
Epoch 58 of 2000 took 0.035s
  training loss:		0.428781
  validation loss:		0.402223
  validation accuracy:		89.35 %
Epoch 59 of 2000 took 0.035s
  training loss:		0.414946
  validation loss:		0.393139
  validation accuracy:		90.22 %
Epoch 60 of 2000 took 0.035s
  training loss:		0.415117
  validation loss:		0.372234
  validation accuracy:		90.98 %
Epoch 61 of 2000 took 0.035s
  training loss:		0.404994
  validation loss:		0.379058
  validation accuracy:		90.00 %
Epoch 62 of 2000 took 0.035s
  training loss:		0.401422
  validation loss:		0.370750
  validation accuracy:		90.43 %
Epoch 63 of 2000 took 0.035s
  training loss:		0.390833
  validation loss:		0.358295
  validation accuracy:		90.76 %
Epoch 64 of 2000 took 0.035s
  training loss:		0.383930
  validation loss:		0.365534
  validation accuracy:		90.22 %
Epoch 65 of 2000 took 0.035s
  training loss:		0.376982
  validation loss:		0.359627
  validation accuracy:		90.22 %
Epoch 66 of 2000 took 0.035s
  training loss:		0.374407
  validation loss:		0.345651
  validation accuracy:		91.20 %
Epoch 67 of 2000 took 0.035s
  training loss:		0.365695
  validation loss:		0.347081
  validation accuracy:		90.98 %
Epoch 68 of 2000 took 0.035s
  training loss:		0.367281
  validation loss:		0.345628
  validation accuracy:		90.43 %
Epoch 69 of 2000 took 0.035s
  training loss:		0.358750
  validation loss:		0.333930
  validation accuracy:		91.09 %
Epoch 70 of 2000 took 0.035s
  training loss:		0.352816
  validation loss:		0.337741
  validation accuracy:		91.09 %
Epoch 71 of 2000 took 0.038s
  training loss:		0.338572
  validation loss:		0.322855
  validation accuracy:		91.41 %
Epoch 72 of 2000 took 0.035s
  training loss:		0.347305
  validation loss:		0.324424
  validation accuracy:		91.09 %
Epoch 73 of 2000 took 0.035s
  training loss:		0.341353
  validation loss:		0.325243
  validation accuracy:		91.09 %
Epoch 74 of 2000 took 0.036s
  training loss:		0.332110
  validation loss:		0.310081
  validation accuracy:		91.09 %
Epoch 75 of 2000 took 0.035s
  training loss:		0.325240
  validation loss:		0.315931
  validation accuracy:		90.98 %
Epoch 76 of 2000 took 0.035s
  training loss:		0.322805
  validation loss:		0.310472
  validation accuracy:		91.63 %
Epoch 77 of 2000 took 0.035s
  training loss:		0.320341
  validation loss:		0.302670
  validation accuracy:		91.74 %
Epoch 78 of 2000 took 0.035s
  training loss:		0.318341
  validation loss:		0.299302
  validation accuracy:		91.85 %
Epoch 79 of 2000 took 0.035s
  training loss:		0.316788
  validation loss:		0.299549
  validation accuracy:		91.52 %
Epoch 80 of 2000 took 0.035s
  training loss:		0.310869
  validation loss:		0.304134
  validation accuracy:		91.30 %
Epoch 81 of 2000 took 0.035s
  training loss:		0.304792
  validation loss:		0.301403
  validation accuracy:		91.09 %
Epoch 82 of 2000 took 0.035s
  training loss:		0.299059
  validation loss:		0.296784
  validation accuracy:		90.87 %
Epoch 83 of 2000 took 0.035s
  training loss:		0.298053
  validation loss:		0.297645
  validation accuracy:		91.52 %
Epoch 84 of 2000 took 0.035s
  training loss:		0.296786
  validation loss:		0.289477
  validation accuracy:		91.41 %
Epoch 85 of 2000 took 0.035s
  training loss:		0.294791
  validation loss:		0.284700
  validation accuracy:		91.96 %
Epoch 86 of 2000 took 0.035s
  training loss:		0.291502
  validation loss:		0.280802
  validation accuracy:		91.85 %
Epoch 87 of 2000 took 0.035s
  training loss:		0.288466
  validation loss:		0.287886
  validation accuracy:		91.74 %
Epoch 88 of 2000 took 0.035s
  training loss:		0.283158
  validation loss:		0.293557
  validation accuracy:		90.76 %
Epoch 89 of 2000 took 0.035s
  training loss:		0.283118
  validation loss:		0.272564
  validation accuracy:		92.28 %
Epoch 90 of 2000 took 0.035s
  training loss:		0.272938
  validation loss:		0.277528
  validation accuracy:		91.85 %
Epoch 91 of 2000 took 0.035s
  training loss:		0.278055
  validation loss:		0.275080
  validation accuracy:		91.96 %
Epoch 92 of 2000 took 0.035s
  training loss:		0.273472
  validation loss:		0.268879
  validation accuracy:		91.63 %
Epoch 93 of 2000 took 0.035s
  training loss:		0.272192
  validation loss:		0.274014
  validation accuracy:		92.07 %
Epoch 94 of 2000 took 0.035s
  training loss:		0.268775
  validation loss:		0.268906
  validation accuracy:		91.85 %
Epoch 95 of 2000 took 0.035s
  training loss:		0.265234
  validation loss:		0.264047
  validation accuracy:		92.28 %
Epoch 96 of 2000 took 0.035s
  training loss:		0.264364
  validation loss:		0.260178
  validation accuracy:		92.28 %
Epoch 97 of 2000 took 0.035s
  training loss:		0.260473
  validation loss:		0.266374
  validation accuracy:		91.96 %
Epoch 98 of 2000 took 0.035s
  training loss:		0.262795
  validation loss:		0.275472
  validation accuracy:		91.09 %
Epoch 99 of 2000 took 0.035s
  training loss:		0.256147
  validation loss:		0.266667
  validation accuracy:		91.96 %
Epoch 100 of 2000 took 0.035s
  training loss:		0.252047
  validation loss:		0.257716
  validation accuracy:		91.63 %
Epoch 101 of 2000 took 0.035s
  training loss:		0.253665
  validation loss:		0.264469
  validation accuracy:		92.07 %
Epoch 102 of 2000 took 0.035s
  training loss:		0.250407
  validation loss:		0.262523
  validation accuracy:		91.74 %
Epoch 103 of 2000 took 0.036s
  training loss:		0.247232
  validation loss:		0.257341
  validation accuracy:		91.41 %
Epoch 104 of 2000 took 0.035s
  training loss:		0.246427
  validation loss:		0.259389
  validation accuracy:		91.96 %
Epoch 105 of 2000 took 0.035s
  training loss:		0.242897
  validation loss:		0.250447
  validation accuracy:		92.72 %
Epoch 106 of 2000 took 0.035s
  training loss:		0.237631
  validation loss:		0.255140
  validation accuracy:		92.07 %
Epoch 107 of 2000 took 0.035s
  training loss:		0.238272
  validation loss:		0.247064
  validation accuracy:		92.28 %
Epoch 108 of 2000 took 0.035s
  training loss:		0.238235
  validation loss:		0.252216
  validation accuracy:		91.96 %
Epoch 109 of 2000 took 0.035s
  training loss:		0.237657
  validation loss:		0.250184
  validation accuracy:		92.39 %
Epoch 110 of 2000 took 0.035s
  training loss:		0.237930
  validation loss:		0.247178
  validation accuracy:		92.17 %
Epoch 111 of 2000 took 0.035s
  training loss:		0.233582
  validation loss:		0.256905
  validation accuracy:		92.07 %
Epoch 112 of 2000 took 0.035s
  training loss:		0.228901
  validation loss:		0.238643
  validation accuracy:		92.50 %
Epoch 113 of 2000 took 0.035s
  training loss:		0.230038
  validation loss:		0.243198
  validation accuracy:		92.61 %
Epoch 114 of 2000 took 0.035s
  training loss:		0.227838
  validation loss:		0.241571
  validation accuracy:		92.39 %
Epoch 115 of 2000 took 0.036s
  training loss:		0.223330
  validation loss:		0.238083
  validation accuracy:		92.61 %
Epoch 116 of 2000 took 0.035s
  training loss:		0.225818
  validation loss:		0.256974
  validation accuracy:		91.96 %
Epoch 117 of 2000 took 0.035s
  training loss:		0.223619
  validation loss:		0.244093
  validation accuracy:		92.07 %
Epoch 118 of 2000 took 0.035s
  training loss:		0.220757
  validation loss:		0.235600
  validation accuracy:		92.39 %
Epoch 119 of 2000 took 0.035s
  training loss:		0.222789
  validation loss:		0.237322
  validation accuracy:		92.72 %
Epoch 120 of 2000 took 0.035s
  training loss:		0.217914
  validation loss:		0.233826
  validation accuracy:		92.61 %
Epoch 121 of 2000 took 0.035s
  training loss:		0.220346
  validation loss:		0.239317
  validation accuracy:		92.50 %
Epoch 122 of 2000 took 0.035s
  training loss:		0.217001
  validation loss:		0.253649
  validation accuracy:		91.96 %
Epoch 123 of 2000 took 0.035s
  training loss:		0.220223
  validation loss:		0.230158
  validation accuracy:		92.61 %
Epoch 124 of 2000 took 0.035s
  training loss:		0.211212
  validation loss:		0.230895
  validation accuracy:		92.72 %
Epoch 125 of 2000 took 0.035s
  training loss:		0.215176
  validation loss:		0.232724
  validation accuracy:		92.61 %
Epoch 126 of 2000 took 0.035s
  training loss:		0.211161
  validation loss:		0.237957
  validation accuracy:		92.28 %
Epoch 127 of 2000 took 0.035s
  training loss:		0.209810
  validation loss:		0.228374
  validation accuracy:		92.93 %
Epoch 128 of 2000 took 0.035s
  training loss:		0.208406
  validation loss:		0.222963
  validation accuracy:		93.04 %
Epoch 129 of 2000 took 0.035s
  training loss:		0.208602
  validation loss:		0.230227
  validation accuracy:		92.61 %
Epoch 130 of 2000 took 0.035s
  training loss:		0.202509
  validation loss:		0.229623
  validation accuracy:		92.83 %
Epoch 131 of 2000 took 0.035s
  training loss:		0.205845
  validation loss:		0.224920
  validation accuracy:		92.93 %
Epoch 132 of 2000 took 0.035s
  training loss:		0.204764
  validation loss:		0.221286
  validation accuracy:		92.83 %
Epoch 133 of 2000 took 0.035s
  training loss:		0.202500
  validation loss:		0.233777
  validation accuracy:		92.50 %
Epoch 134 of 2000 took 0.035s
  training loss:		0.205567
  validation loss:		0.223445
  validation accuracy:		93.15 %
Epoch 135 of 2000 took 0.035s
  training loss:		0.200469
  validation loss:		0.229505
  validation accuracy:		92.83 %
Epoch 136 of 2000 took 0.035s
  training loss:		0.199970
  validation loss:		0.231530
  validation accuracy:		92.61 %
Epoch 137 of 2000 took 0.035s
  training loss:		0.195821
  validation loss:		0.219395
  validation accuracy:		93.26 %
Epoch 138 of 2000 took 0.035s
  training loss:		0.195510
  validation loss:		0.226403
  validation accuracy:		92.50 %
Epoch 139 of 2000 took 0.035s
  training loss:		0.192493
  validation loss:		0.222724
  validation accuracy:		93.04 %
Epoch 140 of 2000 took 0.035s
  training loss:		0.188022
  validation loss:		0.220010
  validation accuracy:		92.93 %
Epoch 141 of 2000 took 0.035s
  training loss:		0.192768
  validation loss:		0.220620
  validation accuracy:		92.61 %
Epoch 142 of 2000 took 0.035s
  training loss:		0.190603
  validation loss:		0.219573
  validation accuracy:		93.15 %
Epoch 143 of 2000 took 0.035s
  training loss:		0.192805
  validation loss:		0.222929
  validation accuracy:		92.93 %
Epoch 144 of 2000 took 0.035s
  training loss:		0.191520
  validation loss:		0.213905
  validation accuracy:		92.93 %
Epoch 145 of 2000 took 0.035s
  training loss:		0.190494
  validation loss:		0.217672
  validation accuracy:		92.93 %
Epoch 146 of 2000 took 0.035s
  training loss:		0.189480
  validation loss:		0.221256
  validation accuracy:		93.04 %
Epoch 147 of 2000 took 0.035s
  training loss:		0.182185
  validation loss:		0.213544
  validation accuracy:		93.15 %
Epoch 148 of 2000 took 0.035s
  training loss:		0.187591
  validation loss:		0.222936
  validation accuracy:		92.83 %
Epoch 149 of 2000 took 0.035s
  training loss:		0.191613
  validation loss:		0.217594
  validation accuracy:		93.04 %
Epoch 150 of 2000 took 0.035s
  training loss:		0.187350
  validation loss:		0.220033
  validation accuracy:		92.72 %
Epoch 151 of 2000 took 0.035s
  training loss:		0.181227
  validation loss:		0.226433
  validation accuracy:		92.61 %
Epoch 152 of 2000 took 0.035s
  training loss:		0.183207
  validation loss:		0.213541
  validation accuracy:		92.83 %
Epoch 153 of 2000 took 0.035s
  training loss:		0.182294
  validation loss:		0.211755
  validation accuracy:		93.37 %
Epoch 154 of 2000 took 0.035s
  training loss:		0.181429
  validation loss:		0.218514
  validation accuracy:		93.04 %
Epoch 155 of 2000 took 0.035s
  training loss:		0.176719
  validation loss:		0.209174
  validation accuracy:		93.26 %
Epoch 156 of 2000 took 0.035s
  training loss:		0.176353
  validation loss:		0.214242
  validation accuracy:		93.04 %
Epoch 157 of 2000 took 0.035s
  training loss:		0.180247
  validation loss:		0.218475
  validation accuracy:		92.50 %
Epoch 158 of 2000 took 0.035s
  training loss:		0.174603
  validation loss:		0.214377
  validation accuracy:		93.15 %
Epoch 159 of 2000 took 0.035s
  training loss:		0.179187
  validation loss:		0.213533
  validation accuracy:		93.04 %
Epoch 160 of 2000 took 0.035s
  training loss:		0.172471
  validation loss:		0.204873
  validation accuracy:		93.15 %
Epoch 161 of 2000 took 0.035s
  training loss:		0.176229
  validation loss:		0.205388
  validation accuracy:		93.37 %
Epoch 162 of 2000 took 0.035s
  training loss:		0.176877
  validation loss:		0.211434
  validation accuracy:		93.15 %
Epoch 163 of 2000 took 0.035s
  training loss:		0.174256
  validation loss:		0.211638
  validation accuracy:		92.83 %
Epoch 164 of 2000 took 0.035s
  training loss:		0.172981
  validation loss:		0.205688
  validation accuracy:		93.04 %
Epoch 165 of 2000 took 0.035s
  training loss:		0.171040
  validation loss:		0.209862
  validation accuracy:		92.50 %
Epoch 166 of 2000 took 0.035s
  training loss:		0.169747
  validation loss:		0.221643
  validation accuracy:		92.83 %
Epoch 167 of 2000 took 0.035s
  training loss:		0.168713
  validation loss:		0.209056
  validation accuracy:		93.48 %
Epoch 168 of 2000 took 0.035s
  training loss:		0.169083
  validation loss:		0.210548
  validation accuracy:		93.26 %
Epoch 169 of 2000 took 0.035s
  training loss:		0.166269
  validation loss:		0.210049
  validation accuracy:		93.26 %
Epoch 170 of 2000 took 0.035s
  training loss:		0.168053
  validation loss:		0.209870
  validation accuracy:		93.37 %
Epoch 171 of 2000 took 0.035s
  training loss:		0.164113
  validation loss:		0.202633
  validation accuracy:		93.80 %
Epoch 172 of 2000 took 0.035s
  training loss:		0.162792
  validation loss:		0.207188
  validation accuracy:		92.93 %
Epoch 173 of 2000 took 0.035s
  training loss:		0.162504
  validation loss:		0.205225
  validation accuracy:		93.26 %
Epoch 174 of 2000 took 0.035s
  training loss:		0.166806
  validation loss:		0.210864
  validation accuracy:		93.15 %
Epoch 175 of 2000 took 0.035s
  training loss:		0.166025
  validation loss:		0.207002
  validation accuracy:		93.37 %
Epoch 176 of 2000 took 0.035s
  training loss:		0.163429
  validation loss:		0.214523
  validation accuracy:		92.93 %
Epoch 177 of 2000 took 0.037s
  training loss:		0.161106
  validation loss:		0.202044
  validation accuracy:		93.59 %
Epoch 178 of 2000 took 0.035s
  training loss:		0.163032
  validation loss:		0.204196
  validation accuracy:		93.48 %
Epoch 179 of 2000 took 0.035s
  training loss:		0.158520
  validation loss:		0.205827
  validation accuracy:		93.26 %
Epoch 180 of 2000 took 0.035s
  training loss:		0.162271
  validation loss:		0.202340
  validation accuracy:		93.59 %
Epoch 181 of 2000 took 0.035s
  training loss:		0.154167
  validation loss:		0.208902
  validation accuracy:		93.26 %
Epoch 182 of 2000 took 0.035s
  training loss:		0.156768
  validation loss:		0.204325
  validation accuracy:		93.26 %
Epoch 183 of 2000 took 0.035s
  training loss:		0.155780
  validation loss:		0.199484
  validation accuracy:		93.48 %
Epoch 184 of 2000 took 0.035s
  training loss:		0.159545
  validation loss:		0.207622
  validation accuracy:		93.15 %
Epoch 185 of 2000 took 0.035s
  training loss:		0.157084
  validation loss:		0.203197
  validation accuracy:		93.26 %
Epoch 186 of 2000 took 0.035s
  training loss:		0.158709
  validation loss:		0.200669
  validation accuracy:		93.48 %
Epoch 187 of 2000 took 0.035s
  training loss:		0.156125
  validation loss:		0.199454
  validation accuracy:		93.59 %
Epoch 188 of 2000 took 0.035s
  training loss:		0.158614
  validation loss:		0.202129
  validation accuracy:		93.59 %
Epoch 189 of 2000 took 0.035s
  training loss:		0.157468
  validation loss:		0.202114
  validation accuracy:		93.26 %
Epoch 190 of 2000 took 0.035s
  training loss:		0.153105
  validation loss:		0.207336
  validation accuracy:		93.59 %
Epoch 191 of 2000 took 0.035s
  training loss:		0.153833
  validation loss:		0.206020
  validation accuracy:		93.26 %
Epoch 192 of 2000 took 0.035s
  training loss:		0.151661
  validation loss:		0.208104
  validation accuracy:		93.26 %
Epoch 193 of 2000 took 0.035s
  training loss:		0.151606
  validation loss:		0.207556
  validation accuracy:		92.93 %
Epoch 194 of 2000 took 0.035s
  training loss:		0.149945
  validation loss:		0.203153
  validation accuracy:		93.48 %
Epoch 195 of 2000 took 0.035s
  training loss:		0.151444
  validation loss:		0.207688
  validation accuracy:		93.70 %
Epoch 196 of 2000 took 0.035s
  training loss:		0.149331
  validation loss:		0.204126
  validation accuracy:		93.15 %
Epoch 197 of 2000 took 0.035s
  training loss:		0.144698
  validation loss:		0.197491
  validation accuracy:		92.93 %
Epoch 198 of 2000 took 0.035s
  training loss:		0.148710
  validation loss:		0.206573
  validation accuracy:		93.15 %
Epoch 199 of 2000 took 0.035s
  training loss:		0.146879
  validation loss:		0.197879
  validation accuracy:		93.80 %
Epoch 200 of 2000 took 0.035s
  training loss:		0.149551
  validation loss:		0.211328
  validation accuracy:		93.04 %
Epoch 201 of 2000 took 0.035s
  training loss:		0.145854
  validation loss:		0.202760
  validation accuracy:		93.26 %
Epoch 202 of 2000 took 0.035s
  training loss:		0.146514
  validation loss:		0.208272
  validation accuracy:		93.04 %
Epoch 203 of 2000 took 0.035s
  training loss:		0.147469
  validation loss:		0.197613
  validation accuracy:		93.48 %
Epoch 204 of 2000 took 0.035s
  training loss:		0.141645
  validation loss:		0.209211
  validation accuracy:		92.93 %
Epoch 205 of 2000 took 0.035s
  training loss:		0.145164
  validation loss:		0.206603
  validation accuracy:		92.93 %
Epoch 206 of 2000 took 0.035s
  training loss:		0.143522
  validation loss:		0.204439
  validation accuracy:		93.15 %
Epoch 207 of 2000 took 0.035s
  training loss:		0.144326
  validation loss:		0.202571
  validation accuracy:		93.59 %
Epoch 208 of 2000 took 0.035s
  training loss:		0.141589
  validation loss:		0.198837
  validation accuracy:		93.48 %
Epoch 209 of 2000 took 0.035s
  training loss:		0.139545
  validation loss:		0.202263
  validation accuracy:		93.48 %
Epoch 210 of 2000 took 0.035s
  training loss:		0.143009
  validation loss:		0.198992
  validation accuracy:		93.37 %
Epoch 211 of 2000 took 0.035s
  training loss:		0.137202
  validation loss:		0.191840
  validation accuracy:		93.70 %
Epoch 212 of 2000 took 0.035s
  training loss:		0.139740
  validation loss:		0.198242
  validation accuracy:		93.48 %
Epoch 213 of 2000 took 0.035s
  training loss:		0.140513
  validation loss:		0.197946
  validation accuracy:		93.70 %
Epoch 214 of 2000 took 0.035s
  training loss:		0.136460
  validation loss:		0.199331
  validation accuracy:		93.26 %
Epoch 215 of 2000 took 0.035s
  training loss:		0.139940
  validation loss:		0.199349
  validation accuracy:		93.59 %
Epoch 216 of 2000 took 0.035s
  training loss:		0.138333
  validation loss:		0.190625
  validation accuracy:		93.91 %
Epoch 217 of 2000 took 0.035s
  training loss:		0.137575
  validation loss:		0.205188
  validation accuracy:		93.15 %
Epoch 218 of 2000 took 0.035s
  training loss:		0.137757
  validation loss:		0.202887
  validation accuracy:		93.37 %
Epoch 219 of 2000 took 0.035s
  training loss:		0.136018
  validation loss:		0.201754
  validation accuracy:		92.93 %
Epoch 220 of 2000 took 0.035s
  training loss:		0.136930
  validation loss:		0.192332
  validation accuracy:		93.26 %
Epoch 221 of 2000 took 0.035s
  training loss:		0.135275
  validation loss:		0.191640
  validation accuracy:		93.48 %
Epoch 222 of 2000 took 0.035s
  training loss:		0.136279
  validation loss:		0.198892
  validation accuracy:		93.37 %
Epoch 223 of 2000 took 0.035s
  training loss:		0.136483
  validation loss:		0.193557
  validation accuracy:		93.59 %
Epoch 224 of 2000 took 0.035s
  training loss:		0.134405
  validation loss:		0.198515
  validation accuracy:		93.26 %
Epoch 225 of 2000 took 0.035s
  training loss:		0.132345
  validation loss:		0.195811
  validation accuracy:		93.59 %
Epoch 226 of 2000 took 0.035s
  training loss:		0.133726
  validation loss:		0.201580
  validation accuracy:		93.15 %
Epoch 227 of 2000 took 0.035s
  training loss:		0.129495
  validation loss:		0.196972
  validation accuracy:		93.04 %
Epoch 228 of 2000 took 0.035s
  training loss:		0.133765
  validation loss:		0.194143
  validation accuracy:		93.48 %
Epoch 229 of 2000 took 0.035s
  training loss:		0.130905
  validation loss:		0.200300
  validation accuracy:		93.48 %
Epoch 230 of 2000 took 0.035s
  training loss:		0.131076
  validation loss:		0.193402
  validation accuracy:		93.59 %
Epoch 231 of 2000 took 0.035s
  training loss:		0.129777
  validation loss:		0.194711
  validation accuracy:		93.37 %
Epoch 232 of 2000 took 0.035s
  training loss:		0.131469
  validation loss:		0.193962
  validation accuracy:		93.59 %
Epoch 233 of 2000 took 0.035s
  training loss:		0.130841
  validation loss:		0.197872
  validation accuracy:		93.48 %
Epoch 234 of 2000 took 0.035s
  training loss:		0.125653
  validation loss:		0.195936
  validation accuracy:		93.48 %
Epoch 235 of 2000 took 0.035s
  training loss:		0.127164
  validation loss:		0.194416
  validation accuracy:		93.70 %
Epoch 236 of 2000 took 0.035s
  training loss:		0.129113
  validation loss:		0.194309
  validation accuracy:		93.59 %
Epoch 237 of 2000 took 0.035s
  training loss:		0.127405
  validation loss:		0.199822
  validation accuracy:		92.93 %
Epoch 238 of 2000 took 0.035s
  training loss:		0.130483
  validation loss:		0.201288
  validation accuracy:		93.59 %
Epoch 239 of 2000 took 0.035s
  training loss:		0.124245
  validation loss:		0.193046
  validation accuracy:		93.59 %
Epoch 240 of 2000 took 0.035s
  training loss:		0.124810
  validation loss:		0.200362
  validation accuracy:		93.48 %
Epoch 241 of 2000 took 0.035s
  training loss:		0.126923
  validation loss:		0.201006
  validation accuracy:		93.26 %
Epoch 242 of 2000 took 0.035s
  training loss:		0.128528
  validation loss:		0.204819
  validation accuracy:		93.48 %
Epoch 243 of 2000 took 0.035s
  training loss:		0.125554
  validation loss:		0.206623
  validation accuracy:		93.37 %
Epoch 244 of 2000 took 0.035s
  training loss:		0.124764
  validation loss:		0.199270
  validation accuracy:		93.59 %
Epoch 245 of 2000 took 0.035s
  training loss:		0.127360
  validation loss:		0.198613
  validation accuracy:		93.80 %
Epoch 246 of 2000 took 0.035s
  training loss:		0.125639
  validation loss:		0.189609
  validation accuracy:		93.80 %
Epoch 247 of 2000 took 0.035s
  training loss:		0.120697
  validation loss:		0.201296
  validation accuracy:		93.48 %
Epoch 248 of 2000 took 0.035s
  training loss:		0.123432
  validation loss:		0.201521
  validation accuracy:		93.59 %
Epoch 249 of 2000 took 0.036s
  training loss:		0.121048
  validation loss:		0.204367
  validation accuracy:		93.26 %
Epoch 250 of 2000 took 0.035s
  training loss:		0.122623
  validation loss:		0.195523
  validation accuracy:		93.37 %
Epoch 251 of 2000 took 0.035s
  training loss:		0.122266
  validation loss:		0.204419
  validation accuracy:		93.26 %
Epoch 252 of 2000 took 0.035s
  training loss:		0.121051
  validation loss:		0.198181
  validation accuracy:		93.37 %
Epoch 253 of 2000 took 0.035s
  training loss:		0.123059
  validation loss:		0.195320
  validation accuracy:		93.70 %
Epoch 254 of 2000 took 0.035s
  training loss:		0.121369
  validation loss:		0.194138
  validation accuracy:		93.91 %
Epoch 255 of 2000 took 0.035s
  training loss:		0.119750
  validation loss:		0.195717
  validation accuracy:		93.70 %
Epoch 256 of 2000 took 0.035s
  training loss:		0.119591
  validation loss:		0.195194
  validation accuracy:		93.70 %
Epoch 257 of 2000 took 0.035s
  training loss:		0.120609
  validation loss:		0.203495
  validation accuracy:		93.48 %
Epoch 258 of 2000 took 0.035s
  training loss:		0.117625
  validation loss:		0.200632
  validation accuracy:		93.37 %
Epoch 259 of 2000 took 0.035s
  training loss:		0.120489
  validation loss:		0.196518
  validation accuracy:		93.37 %
Epoch 260 of 2000 took 0.035s
  training loss:		0.116562
  validation loss:		0.198478
  validation accuracy:		93.48 %
Epoch 261 of 2000 took 0.035s
  training loss:		0.117059
  validation loss:		0.193347
  validation accuracy:		93.59 %
Epoch 262 of 2000 took 0.035s
  training loss:		0.119510
  validation loss:		0.199462
  validation accuracy:		93.59 %
Epoch 263 of 2000 took 0.035s
  training loss:		0.116102
  validation loss:		0.196170
  validation accuracy:		93.26 %
Epoch 264 of 2000 took 0.035s
  training loss:		0.114820
  validation loss:		0.204843
  validation accuracy:		93.48 %
Epoch 265 of 2000 took 0.035s
  training loss:		0.116103
  validation loss:		0.197295
  validation accuracy:		93.26 %
Epoch 266 of 2000 took 0.035s
  training loss:		0.112158
  validation loss:		0.199859
  validation accuracy:		93.15 %
Epoch 267 of 2000 took 0.035s
  training loss:		0.111674
  validation loss:		0.196483
  validation accuracy:		93.37 %
Epoch 268 of 2000 took 0.035s
  training loss:		0.115219
  validation loss:		0.197429
  validation accuracy:		93.48 %
Epoch 269 of 2000 took 0.035s
  training loss:		0.114195
  validation loss:		0.198548
  validation accuracy:		93.48 %
Epoch 270 of 2000 took 0.035s
  training loss:		0.114040
  validation loss:		0.204315
  validation accuracy:		93.15 %
Epoch 271 of 2000 took 0.035s
  training loss:		0.114019
  validation loss:		0.190260
  validation accuracy:		93.70 %
Epoch 272 of 2000 took 0.035s
  training loss:		0.113310
  validation loss:		0.190168
  validation accuracy:		93.59 %
Epoch 273 of 2000 took 0.035s
  training loss:		0.112425
  validation loss:		0.192637
  validation accuracy:		93.70 %
Epoch 274 of 2000 took 0.035s
  training loss:		0.115079
  validation loss:		0.198308
  validation accuracy:		93.37 %
Epoch 275 of 2000 took 0.035s
  training loss:		0.115370
  validation loss:		0.200620
  validation accuracy:		93.37 %
Epoch 276 of 2000 took 0.035s
  training loss:		0.111728
  validation loss:		0.201712
  validation accuracy:		93.37 %
Epoch 277 of 2000 took 0.035s
  training loss:		0.110384
  validation loss:		0.198312
  validation accuracy:		93.48 %
Epoch 278 of 2000 took 0.035s
  training loss:		0.109890
  validation loss:		0.202039
  validation accuracy:		93.48 %
Epoch 279 of 2000 took 0.035s
  training loss:		0.109610
  validation loss:		0.193400
  validation accuracy:		93.26 %
Epoch 280 of 2000 took 0.035s
  training loss:		0.108499
  validation loss:		0.198949
  validation accuracy:		93.26 %
Epoch 281 of 2000 took 0.035s
  training loss:		0.108810
  validation loss:		0.195899
  validation accuracy:		93.59 %
Epoch 282 of 2000 took 0.035s
  training loss:		0.107998
  validation loss:		0.201948
  validation accuracy:		93.48 %
Epoch 283 of 2000 took 0.035s
  training loss:		0.109196
  validation loss:		0.200342
  validation accuracy:		93.26 %
Epoch 284 of 2000 took 0.035s
  training loss:		0.110920
  validation loss:		0.195698
  validation accuracy:		93.26 %
Epoch 285 of 2000 took 0.035s
  training loss:		0.108382
  validation loss:		0.193105
  validation accuracy:		93.80 %
Epoch 286 of 2000 took 0.035s
  training loss:		0.109366
  validation loss:		0.202573
  validation accuracy:		93.80 %
Epoch 287 of 2000 took 0.035s
  training loss:		0.107930
  validation loss:		0.198882
  validation accuracy:		93.37 %
Epoch 288 of 2000 took 0.035s
  training loss:		0.108958
  validation loss:		0.200523
  validation accuracy:		93.48 %
Epoch 289 of 2000 took 0.035s
  training loss:		0.109726
  validation loss:		0.199529
  validation accuracy:		93.59 %
Epoch 290 of 2000 took 0.035s
  training loss:		0.108091
  validation loss:		0.192930
  validation accuracy:		93.70 %
Epoch 291 of 2000 took 0.035s
  training loss:		0.104838
  validation loss:		0.205717
  validation accuracy:		93.59 %
Epoch 292 of 2000 took 0.035s
  training loss:		0.107372
  validation loss:		0.195562
  validation accuracy:		93.59 %
Epoch 293 of 2000 took 0.035s
  training loss:		0.106195
  validation loss:		0.193695
  validation accuracy:		93.48 %
Epoch 294 of 2000 took 0.035s
  training loss:		0.104621
  validation loss:		0.201148
  validation accuracy:		93.48 %
Epoch 295 of 2000 took 0.035s
  training loss:		0.106971
  validation loss:		0.192888
  validation accuracy:		93.70 %
Epoch 296 of 2000 took 0.035s
  training loss:		0.102196
  validation loss:		0.199675
  validation accuracy:		93.37 %
Epoch 297 of 2000 took 0.035s
  training loss:		0.104449
  validation loss:		0.194224
  validation accuracy:		94.13 %
Epoch 298 of 2000 took 0.035s
  training loss:		0.106607
  validation loss:		0.195221
  validation accuracy:		93.59 %
Epoch 299 of 2000 took 0.035s
  training loss:		0.105681
  validation loss:		0.198975
  validation accuracy:		93.37 %
Epoch 300 of 2000 took 0.035s
  training loss:		0.103668
  validation loss:		0.200431
  validation accuracy:		93.48 %
Epoch 301 of 2000 took 0.035s
  training loss:		0.106221
  validation loss:		0.201923
  validation accuracy:		93.48 %
Epoch 302 of 2000 took 0.035s
  training loss:		0.103606
  validation loss:		0.204833
  validation accuracy:		93.59 %
Epoch 303 of 2000 took 0.035s
  training loss:		0.102526
  validation loss:		0.199353
  validation accuracy:		93.59 %
Epoch 304 of 2000 took 0.035s
  training loss:		0.103508
  validation loss:		0.194301
  validation accuracy:		93.70 %
Epoch 305 of 2000 took 0.035s
  training loss:		0.103451
  validation loss:		0.202288
  validation accuracy:		93.48 %
Epoch 306 of 2000 took 0.035s
  training loss:		0.104430
  validation loss:		0.210433
  validation accuracy:		93.80 %
Epoch 307 of 2000 took 0.035s
  training loss:		0.102968
  validation loss:		0.199146
  validation accuracy:		93.59 %
Epoch 308 of 2000 took 0.035s
  training loss:		0.099346
  validation loss:		0.200384
  validation accuracy:		93.59 %
Epoch 309 of 2000 took 0.035s
  training loss:		0.101355
  validation loss:		0.198312
  validation accuracy:		93.70 %
Epoch 310 of 2000 took 0.035s
  training loss:		0.101083
  validation loss:		0.194218
  validation accuracy:		93.80 %
Epoch 311 of 2000 took 0.035s
  training loss:		0.101805
  validation loss:		0.205272
  validation accuracy:		93.48 %
Epoch 312 of 2000 took 0.035s
  training loss:		0.100274
  validation loss:		0.199834
  validation accuracy:		93.70 %
Epoch 313 of 2000 took 0.035s
  training loss:		0.099880
  validation loss:		0.198178
  validation accuracy:		93.59 %
Epoch 314 of 2000 took 0.035s
  training loss:		0.100104
  validation loss:		0.198919
  validation accuracy:		93.70 %
Epoch 315 of 2000 took 0.035s
  training loss:		0.099277
  validation loss:		0.203584
  validation accuracy:		93.48 %
Epoch 316 of 2000 took 0.035s
  training loss:		0.098827
  validation loss:		0.204245
  validation accuracy:		93.26 %
Epoch 317 of 2000 took 0.035s
  training loss:		0.099069
  validation loss:		0.194583
  validation accuracy:		93.80 %
Epoch 318 of 2000 took 0.035s
  training loss:		0.101984
  validation loss:		0.197131
  validation accuracy:		93.59 %
Epoch 319 of 2000 took 0.035s
  training loss:		0.099312
  validation loss:		0.197403
  validation accuracy:		93.48 %
Epoch 320 of 2000 took 0.035s
  training loss:		0.098742
  validation loss:		0.208673
  validation accuracy:		93.59 %
Epoch 321 of 2000 took 0.035s
  training loss:		0.098594
  validation loss:		0.198183
  validation accuracy:		93.59 %
Epoch 322 of 2000 took 0.035s
  training loss:		0.098566
  validation loss:		0.199611
  validation accuracy:		93.70 %
Epoch 323 of 2000 took 0.035s
  training loss:		0.099029
  validation loss:		0.193078
  validation accuracy:		93.80 %
Epoch 324 of 2000 took 0.035s
  training loss:		0.096304
  validation loss:		0.203644
  validation accuracy:		93.48 %
Epoch 325 of 2000 took 0.035s
  training loss:		0.098772
  validation loss:		0.207887
  validation accuracy:		93.70 %
Epoch 326 of 2000 took 0.035s
  training loss:		0.094933
  validation loss:		0.197120
  validation accuracy:		93.59 %
Epoch 327 of 2000 took 0.035s
  training loss:		0.096527
  validation loss:		0.200976
  validation accuracy:		93.59 %
Epoch 328 of 2000 took 0.035s
  training loss:		0.097606
  validation loss:		0.201126
  validation accuracy:		93.48 %
Epoch 329 of 2000 took 0.035s
  training loss:		0.093233
  validation loss:		0.203118
  validation accuracy:		93.48 %
Epoch 330 of 2000 took 0.035s
  training loss:		0.095349
  validation loss:		0.204276
  validation accuracy:		93.59 %
Epoch 331 of 2000 took 0.035s
  training loss:		0.094092
  validation loss:		0.203444
  validation accuracy:		93.59 %
Epoch 332 of 2000 took 0.035s
  training loss:		0.096466
  validation loss:		0.203969
  validation accuracy:		93.70 %
Epoch 333 of 2000 took 0.035s
  training loss:		0.093116
  validation loss:		0.206507
  validation accuracy:		93.37 %
Epoch 334 of 2000 took 0.035s
  training loss:		0.095062
  validation loss:		0.201772
  validation accuracy:		93.37 %
Epoch 335 of 2000 took 0.035s
  training loss:		0.095336
  validation loss:		0.209823
  validation accuracy:		93.59 %
Epoch 336 of 2000 took 0.037s
  training loss:		0.095937
  validation loss:		0.203072
  validation accuracy:		93.59 %
Epoch 337 of 2000 took 0.035s
  training loss:		0.092568
  validation loss:		0.203708
  validation accuracy:		93.59 %
Epoch 338 of 2000 took 0.035s
  training loss:		0.094292
  validation loss:		0.202455
  validation accuracy:		93.91 %
Epoch 339 of 2000 took 0.035s
  training loss:		0.092037
  validation loss:		0.205042
  validation accuracy:		93.37 %
Epoch 340 of 2000 took 0.035s
  training loss:		0.092833
  validation loss:		0.208079
  validation accuracy:		93.70 %
Epoch 341 of 2000 took 0.035s
  training loss:		0.092137
  validation loss:		0.206032
  validation accuracy:		93.80 %
Epoch 342 of 2000 took 0.035s
  training loss:		0.094503
  validation loss:		0.204222
  validation accuracy:		93.80 %
Epoch 343 of 2000 took 0.035s
  training loss:		0.090959
  validation loss:		0.198025
  validation accuracy:		94.02 %
Epoch 344 of 2000 took 0.035s
  training loss:		0.092935
  validation loss:		0.204611
  validation accuracy:		93.48 %
Epoch 345 of 2000 took 0.035s
  training loss:		0.088984
  validation loss:		0.202954
  validation accuracy:		93.80 %
Epoch 346 of 2000 took 0.035s
  training loss:		0.091453
  validation loss:		0.200077
  validation accuracy:		93.80 %
Epoch 347 of 2000 took 0.035s
  training loss:		0.092047
  validation loss:		0.205609
  validation accuracy:		93.80 %
Epoch 348 of 2000 took 0.035s
  training loss:		0.089541
  validation loss:		0.210875
  validation accuracy:		93.37 %
Epoch 349 of 2000 took 0.035s
  training loss:		0.091040
  validation loss:		0.206921
  validation accuracy:		93.70 %
Epoch 350 of 2000 took 0.035s
  training loss:		0.090845
  validation loss:		0.205226
  validation accuracy:		93.70 %
Epoch 351 of 2000 took 0.035s
  training loss:		0.089647
  validation loss:		0.205356
  validation accuracy:		93.70 %
Epoch 352 of 2000 took 0.035s
  training loss:		0.088925
  validation loss:		0.201894
  validation accuracy:		93.59 %
Epoch 353 of 2000 took 0.035s
  training loss:		0.087924
  validation loss:		0.207129
  validation accuracy:		93.70 %
Epoch 354 of 2000 took 0.035s
  training loss:		0.088868
  validation loss:		0.202264
  validation accuracy:		93.91 %
Epoch 355 of 2000 took 0.035s
  training loss:		0.090041
  validation loss:		0.205086
  validation accuracy:		93.70 %
Epoch 356 of 2000 took 0.035s
  training loss:		0.089209
  validation loss:		0.202355
  validation accuracy:		93.80 %
Epoch 357 of 2000 took 0.035s
  training loss:		0.088266
  validation loss:		0.195755
  validation accuracy:		93.37 %
Epoch 358 of 2000 took 0.035s
  training loss:		0.089487
  validation loss:		0.203404
  validation accuracy:		93.91 %
Epoch 359 of 2000 took 0.035s
  training loss:		0.088825
  validation loss:		0.199312
  validation accuracy:		94.02 %
Epoch 360 of 2000 took 0.035s
  training loss:		0.089119
  validation loss:		0.206695
  validation accuracy:		93.59 %
Epoch 361 of 2000 took 0.035s
  training loss:		0.083963
  validation loss:		0.208596
  validation accuracy:		93.70 %
Epoch 362 of 2000 took 0.035s
  training loss:		0.084280
  validation loss:		0.198693
  validation accuracy:		93.91 %
Epoch 363 of 2000 took 0.035s
  training loss:		0.087969
  validation loss:		0.204963
  validation accuracy:		93.80 %
Epoch 364 of 2000 took 0.035s
  training loss:		0.086575
  validation loss:		0.203750
  validation accuracy:		93.70 %
Epoch 365 of 2000 took 0.035s
  training loss:		0.087004
  validation loss:		0.207486
  validation accuracy:		93.37 %
Epoch 366 of 2000 took 0.035s
  training loss:		0.083543
  validation loss:		0.210773
  validation accuracy:		93.37 %
Epoch 367 of 2000 took 0.035s
  training loss:		0.086243
  validation loss:		0.214148
  validation accuracy:		93.59 %
Epoch 368 of 2000 took 0.035s
  training loss:		0.083363
  validation loss:		0.201168
  validation accuracy:		93.91 %
Epoch 369 of 2000 took 0.035s
  training loss:		0.086613
  validation loss:		0.200313
  validation accuracy:		93.91 %
Epoch 370 of 2000 took 0.035s
  training loss:		0.081925
  validation loss:		0.204371
  validation accuracy:		93.70 %
Epoch 371 of 2000 took 0.035s
  training loss:		0.084390
  validation loss:		0.202881
  validation accuracy:		93.80 %
Epoch 372 of 2000 took 0.035s
  training loss:		0.085291
  validation loss:		0.212141
  validation accuracy:		93.48 %
Epoch 373 of 2000 took 0.035s
  training loss:		0.084839
  validation loss:		0.208894
  validation accuracy:		93.26 %
Epoch 374 of 2000 took 0.035s
  training loss:		0.084104
  validation loss:		0.204664
  validation accuracy:		94.13 %
Epoch 375 of 2000 took 0.035s
  training loss:		0.083603
  validation loss:		0.203867
  validation accuracy:		94.02 %
Epoch 376 of 2000 took 0.035s
  training loss:		0.082933
  validation loss:		0.208121
  validation accuracy:		93.48 %
Epoch 377 of 2000 took 0.035s
  training loss:		0.083708
  validation loss:		0.215725
  validation accuracy:		93.15 %
Epoch 378 of 2000 took 0.035s
  training loss:		0.083245
  validation loss:		0.203851
  validation accuracy:		94.02 %
Epoch 379 of 2000 took 0.035s
  training loss:		0.082090
  validation loss:		0.201798
  validation accuracy:		93.80 %
Epoch 380 of 2000 took 0.035s
  training loss:		0.084100
  validation loss:		0.203499
  validation accuracy:		94.13 %
Epoch 381 of 2000 took 0.035s
  training loss:		0.083028
  validation loss:		0.205898
  validation accuracy:		93.91 %
Epoch 382 of 2000 took 0.035s
  training loss:		0.081274
  validation loss:		0.201086
  validation accuracy:		93.80 %
Epoch 383 of 2000 took 0.035s
  training loss:		0.080396
  validation loss:		0.205710
  validation accuracy:		93.59 %
Epoch 384 of 2000 took 0.035s
  training loss:		0.082134
  validation loss:		0.205819
  validation accuracy:		93.91 %
Epoch 385 of 2000 took 0.035s
  training loss:		0.082693
  validation loss:		0.209506
  validation accuracy:		93.91 %
Epoch 386 of 2000 took 0.036s
  training loss:		0.079696
  validation loss:		0.205046
  validation accuracy:		93.91 %
Epoch 387 of 2000 took 0.035s
  training loss:		0.081712
  validation loss:		0.204356
  validation accuracy:		93.91 %
Epoch 388 of 2000 took 0.035s
  training loss:		0.080814
  validation loss:		0.209118
  validation accuracy:		93.91 %
Epoch 389 of 2000 took 0.035s
  training loss:		0.081307
  validation loss:		0.208335
  validation accuracy:		93.80 %
Epoch 390 of 2000 took 0.035s
  training loss:		0.077640
  validation loss:		0.201368
  validation accuracy:		94.02 %
Epoch 391 of 2000 took 0.035s
  training loss:		0.080467
  validation loss:		0.204753
  validation accuracy:		93.80 %
Epoch 392 of 2000 took 0.035s
  training loss:		0.081299
  validation loss:		0.206638
  validation accuracy:		94.02 %
Epoch 393 of 2000 took 0.035s
  training loss:		0.081937
  validation loss:		0.208019
  validation accuracy:		94.02 %
Epoch 394 of 2000 took 0.035s
  training loss:		0.080610
  validation loss:		0.209487
  validation accuracy:		93.37 %
Epoch 395 of 2000 took 0.035s
  training loss:		0.078352
  validation loss:		0.202520
  validation accuracy:		94.13 %
Epoch 396 of 2000 took 0.035s
  training loss:		0.078791
  validation loss:		0.212362
  validation accuracy:		93.70 %
Epoch 397 of 2000 took 0.035s
  training loss:		0.080884
  validation loss:		0.209257
  validation accuracy:		93.59 %
Epoch 398 of 2000 took 0.035s
  training loss:		0.078620
  validation loss:		0.208831
  validation accuracy:		93.91 %
Epoch 399 of 2000 took 0.035s
  training loss:		0.078843
  validation loss:		0.206572
  validation accuracy:		94.13 %
Epoch 400 of 2000 took 0.035s
  training loss:		0.077706
  validation loss:		0.210879
  validation accuracy:		94.02 %
Epoch 401 of 2000 took 0.035s
  training loss:		0.080076
  validation loss:		0.213158
  validation accuracy:		93.70 %
Epoch 402 of 2000 took 0.035s
  training loss:		0.076887
  validation loss:		0.210170
  validation accuracy:		93.80 %
Epoch 403 of 2000 took 0.035s
  training loss:		0.077778
  validation loss:		0.207775
  validation accuracy:		94.02 %
Epoch 404 of 2000 took 0.035s
  training loss:		0.078269
  validation loss:		0.208182
  validation accuracy:		94.02 %
Epoch 405 of 2000 took 0.035s
  training loss:		0.075976
  validation loss:		0.206615
  validation accuracy:		93.80 %
Epoch 406 of 2000 took 0.035s
  training loss:		0.075462
  validation loss:		0.207133
  validation accuracy:		94.02 %
Epoch 407 of 2000 took 0.035s
  training loss:		0.076179
  validation loss:		0.214122
  validation accuracy:		94.02 %
Epoch 408 of 2000 took 0.035s
  training loss:		0.077222
  validation loss:		0.208242
  validation accuracy:		94.13 %
Epoch 409 of 2000 took 0.035s
  training loss:		0.077965
  validation loss:		0.205595
  validation accuracy:		94.13 %
Epoch 410 of 2000 took 0.035s
  training loss:		0.073938
  validation loss:		0.210879
  validation accuracy:		93.80 %
Epoch 411 of 2000 took 0.035s
  training loss:		0.076892
  validation loss:		0.219076
  validation accuracy:		93.59 %
Epoch 412 of 2000 took 0.035s
  training loss:		0.077370
  validation loss:		0.214891
  validation accuracy:		93.91 %
Epoch 413 of 2000 took 0.035s
  training loss:		0.074860
  validation loss:		0.206146
  validation accuracy:		93.59 %
Epoch 414 of 2000 took 0.035s
  training loss:		0.077053
  validation loss:		0.205751
  validation accuracy:		93.80 %
Epoch 415 of 2000 took 0.035s
  training loss:		0.073764
  validation loss:		0.226102
  validation accuracy:		92.93 %
Epoch 416 of 2000 took 0.035s
  training loss:		0.076540
  validation loss:		0.210698
  validation accuracy:		93.91 %
Epoch 417 of 2000 took 0.035s
  training loss:		0.073636
  validation loss:		0.217945
  validation accuracy:		94.02 %
Epoch 418 of 2000 took 0.035s
  training loss:		0.075941
  validation loss:		0.211210
  validation accuracy:		93.80 %
Epoch 419 of 2000 took 0.035s
  training loss:		0.074644
  validation loss:		0.214357
  validation accuracy:		94.13 %
Epoch 420 of 2000 took 0.035s
  training loss:		0.072426
  validation loss:		0.221075
  validation accuracy:		93.59 %
Epoch 421 of 2000 took 0.035s
  training loss:		0.076300
  validation loss:		0.216222
  validation accuracy:		93.80 %
Epoch 422 of 2000 took 0.035s
  training loss:		0.072509
  validation loss:		0.206825
  validation accuracy:		94.13 %
Epoch 423 of 2000 took 0.035s
  training loss:		0.074354
  validation loss:		0.209903
  validation accuracy:		93.80 %
Epoch 424 of 2000 took 0.035s
  training loss:		0.073757
  validation loss:		0.215795
  validation accuracy:		94.13 %
Epoch 425 of 2000 took 0.035s
  training loss:		0.073075
  validation loss:		0.218040
  validation accuracy:		93.37 %
Epoch 426 of 2000 took 0.035s
  training loss:		0.071403
  validation loss:		0.221223
  validation accuracy:		93.37 %
Epoch 427 of 2000 took 0.035s
  training loss:		0.073049
  validation loss:		0.208422
  validation accuracy:		93.59 %
Epoch 428 of 2000 took 0.035s
  training loss:		0.073555
  validation loss:		0.215219
  validation accuracy:		93.91 %
Epoch 429 of 2000 took 0.035s
  training loss:		0.072563
  validation loss:		0.212903
  validation accuracy:		93.80 %
Epoch 430 of 2000 took 0.035s
  training loss:		0.071316
  validation loss:		0.218694
  validation accuracy:		93.80 %
Epoch 431 of 2000 took 0.035s
  training loss:		0.073156
  validation loss:		0.212488
  validation accuracy:		94.13 %
Epoch 432 of 2000 took 0.035s
  training loss:		0.069351
  validation loss:		0.216055
  validation accuracy:		93.91 %
Epoch 433 of 2000 took 0.035s
  training loss:		0.070029
  validation loss:		0.216784
  validation accuracy:		93.80 %
Epoch 434 of 2000 took 0.035s
  training loss:		0.069753
  validation loss:		0.219539
  validation accuracy:		93.59 %
Epoch 435 of 2000 took 0.035s
  training loss:		0.071668
  validation loss:		0.210879
  validation accuracy:		94.02 %
Epoch 436 of 2000 took 0.035s
  training loss:		0.068619
  validation loss:		0.210686
  validation accuracy:		94.13 %
Epoch 437 of 2000 took 0.035s
  training loss:		0.071739
  validation loss:		0.218036
  validation accuracy:		93.70 %
Epoch 438 of 2000 took 0.035s
  training loss:		0.071963
  validation loss:		0.212858
  validation accuracy:		93.59 %
Epoch 439 of 2000 took 0.035s
  training loss:		0.071033
  validation loss:		0.210815
  validation accuracy:		93.91 %
Epoch 440 of 2000 took 0.035s
  training loss:		0.071316
  validation loss:		0.220896
  validation accuracy:		93.26 %
Epoch 441 of 2000 took 0.035s
  training loss:		0.069382
  validation loss:		0.215159
  validation accuracy:		94.24 %
Epoch 442 of 2000 took 0.035s
  training loss:		0.069187
  validation loss:		0.221595
  validation accuracy:		93.37 %
Epoch 443 of 2000 took 0.036s
  training loss:		0.069455
  validation loss:		0.216380
  validation accuracy:		93.26 %
Epoch 444 of 2000 took 0.035s
  training loss:		0.070721
  validation loss:		0.216108
  validation accuracy:		93.91 %
Epoch 445 of 2000 took 0.035s
  training loss:		0.066832
  validation loss:		0.220421
  validation accuracy:		93.91 %
Epoch 446 of 2000 took 0.035s
  training loss:		0.069480
  validation loss:		0.216924
  validation accuracy:		93.91 %
Epoch 447 of 2000 took 0.035s
  training loss:		0.068572
  validation loss:		0.209339
  validation accuracy:		93.91 %
Epoch 448 of 2000 took 0.035s
  training loss:		0.067320
  validation loss:		0.225186
  validation accuracy:		93.59 %
Epoch 449 of 2000 took 0.035s
  training loss:		0.068048
  validation loss:		0.223332
  validation accuracy:		93.37 %
Epoch 450 of 2000 took 0.035s
  training loss:		0.070065
  validation loss:		0.219546
  validation accuracy:		93.59 %
Epoch 451 of 2000 took 0.035s
  training loss:		0.066228
  validation loss:		0.215124
  validation accuracy:		93.91 %
Epoch 452 of 2000 took 0.035s
  training loss:		0.068600
  validation loss:		0.219473
  validation accuracy:		93.91 %
Epoch 453 of 2000 took 0.035s
  training loss:		0.067153
  validation loss:		0.215481
  validation accuracy:		93.48 %
Epoch 454 of 2000 took 0.035s
  training loss:		0.068110
  validation loss:		0.225689
  validation accuracy:		94.02 %
Epoch 455 of 2000 took 0.035s
  training loss:		0.069773
  validation loss:		0.221611
  validation accuracy:		93.48 %
Epoch 456 of 2000 took 0.035s
  training loss:		0.065732
  validation loss:		0.219108
  validation accuracy:		93.80 %
Epoch 457 of 2000 took 0.035s
  training loss:		0.066116
  validation loss:		0.215794
  validation accuracy:		93.70 %
Epoch 458 of 2000 took 0.035s
  training loss:		0.066931
  validation loss:		0.223209
  validation accuracy:		94.02 %
Epoch 459 of 2000 took 0.035s
  training loss:		0.065604
  validation loss:		0.217807
  validation accuracy:		93.70 %
Epoch 460 of 2000 took 0.035s
  training loss:		0.066913
  validation loss:		0.218084
  validation accuracy:		94.02 %
Epoch 461 of 2000 took 0.035s
  training loss:		0.064571
  validation loss:		0.215152
  validation accuracy:		93.80 %
Epoch 462 of 2000 took 0.035s
  training loss:		0.066052
  validation loss:		0.225963
  validation accuracy:		93.70 %
Epoch 463 of 2000 took 0.035s
  training loss:		0.067491
  validation loss:		0.214810
  validation accuracy:		93.91 %
Epoch 464 of 2000 took 0.035s
  training loss:		0.064885
  validation loss:		0.216724
  validation accuracy:		93.80 %
Epoch 465 of 2000 took 0.035s
  training loss:		0.064371
  validation loss:		0.220993
  validation accuracy:		94.02 %
Epoch 466 of 2000 took 0.035s
  training loss:		0.066373
  validation loss:		0.215616
  validation accuracy:		94.02 %
Epoch 467 of 2000 took 0.035s
  training loss:		0.064449
  validation loss:		0.221322
  validation accuracy:		93.48 %
Epoch 468 of 2000 took 0.035s
  training loss:		0.066534
  validation loss:		0.216503
  validation accuracy:		93.70 %
Epoch 469 of 2000 took 0.035s
  training loss:		0.064903
  validation loss:		0.219152
  validation accuracy:		93.91 %
Epoch 470 of 2000 took 0.035s
  training loss:		0.063004
  validation loss:		0.221360
  validation accuracy:		93.80 %
Epoch 471 of 2000 took 0.035s
  training loss:		0.063603
  validation loss:		0.212728
  validation accuracy:		94.02 %
Epoch 472 of 2000 took 0.035s
  training loss:		0.066177
  validation loss:		0.232092
  validation accuracy:		93.26 %
Epoch 473 of 2000 took 0.035s
  training loss:		0.066081
  validation loss:		0.232894
  validation accuracy:		93.04 %
Epoch 474 of 2000 took 0.035s
  training loss:		0.062724
  validation loss:		0.227876
  validation accuracy:		93.70 %
Epoch 475 of 2000 took 0.035s
  training loss:		0.064108
  validation loss:		0.217935
  validation accuracy:		93.70 %
Epoch 476 of 2000 took 0.035s
  training loss:		0.061787
  validation loss:		0.223493
  validation accuracy:		94.02 %
Epoch 477 of 2000 took 0.035s
  training loss:		0.063720
  validation loss:		0.216750
  validation accuracy:		93.91 %
Epoch 478 of 2000 took 0.035s
  training loss:		0.064282
  validation loss:		0.215681
  validation accuracy:		94.02 %
Epoch 479 of 2000 took 0.035s
  training loss:		0.061637
  validation loss:		0.226484
  validation accuracy:		93.48 %
Epoch 480 of 2000 took 0.035s
  training loss:		0.061831
  validation loss:		0.221293
  validation accuracy:		93.91 %
Epoch 481 of 2000 took 0.035s
  training loss:		0.062066
  validation loss:		0.225051
  validation accuracy:		93.48 %
Epoch 482 of 2000 took 0.035s
  training loss:		0.063509
  validation loss:		0.223555
  validation accuracy:		94.02 %
Epoch 483 of 2000 took 0.035s
  training loss:		0.061243
  validation loss:		0.221050
  validation accuracy:		93.70 %
Epoch 484 of 2000 took 0.035s
  training loss:		0.062307
  validation loss:		0.228689
  validation accuracy:		93.91 %
Epoch 485 of 2000 took 0.035s
  training loss:		0.061733
  validation loss:		0.221292
  validation accuracy:		93.70 %
Epoch 486 of 2000 took 0.035s
  training loss:		0.062329
  validation loss:		0.226159
  validation accuracy:		93.70 %
Epoch 487 of 2000 took 0.035s
  training loss:		0.061821
  validation loss:		0.234377
  validation accuracy:		93.59 %
Epoch 488 of 2000 took 0.035s
  training loss:		0.062905
  validation loss:		0.221205
  validation accuracy:		93.91 %
Epoch 489 of 2000 took 0.035s
  training loss:		0.061202
  validation loss:		0.223565
  validation accuracy:		93.80 %
Epoch 490 of 2000 took 0.035s
  training loss:		0.059876
  validation loss:		0.222988
  validation accuracy:		93.80 %
Epoch 491 of 2000 took 0.035s
  training loss:		0.062240
  validation loss:		0.226521
  validation accuracy:		93.59 %
Epoch 492 of 2000 took 0.035s
  training loss:		0.058774
  validation loss:		0.220614
  validation accuracy:		93.80 %
Epoch 493 of 2000 took 0.035s
  training loss:		0.060157
  validation loss:		0.226840
  validation accuracy:		93.70 %
Epoch 494 of 2000 took 0.035s
  training loss:		0.062006
  validation loss:		0.219071
  validation accuracy:		93.59 %
Epoch 495 of 2000 took 0.035s
  training loss:		0.060220
  validation loss:		0.225160
  validation accuracy:		93.91 %
Epoch 496 of 2000 took 0.035s
  training loss:		0.060975
  validation loss:		0.229084
  validation accuracy:		93.59 %
Epoch 497 of 2000 took 0.035s
  training loss:		0.058758
  validation loss:		0.225347
  validation accuracy:		93.80 %
Epoch 498 of 2000 took 0.035s
  training loss:		0.060091
  validation loss:		0.228294
  validation accuracy:		93.37 %
Epoch 499 of 2000 took 0.036s
  training loss:		0.058704
  validation loss:		0.228531
  validation accuracy:		93.70 %
Epoch 500 of 2000 took 0.035s
  training loss:		0.060776
  validation loss:		0.223374
  validation accuracy:		93.48 %
Epoch 501 of 2000 took 0.035s
  training loss:		0.057993
  validation loss:		0.223274
  validation accuracy:		93.91 %
Epoch 502 of 2000 took 0.035s
  training loss:		0.059084
  validation loss:		0.224343
  validation accuracy:		93.70 %
Epoch 503 of 2000 took 0.035s
  training loss:		0.058543
  validation loss:		0.231003
  validation accuracy:		93.59 %
Epoch 504 of 2000 took 0.035s
  training loss:		0.059348
  validation loss:		0.224188
  validation accuracy:		93.80 %
Epoch 505 of 2000 took 0.035s
  training loss:		0.059514
  validation loss:		0.224172
  validation accuracy:		93.91 %
Epoch 506 of 2000 took 0.035s
  training loss:		0.057040
  validation loss:		0.224363
  validation accuracy:		93.80 %
Epoch 507 of 2000 took 0.035s
  training loss:		0.058306
  validation loss:		0.225630
  validation accuracy:		94.02 %
Epoch 508 of 2000 took 0.035s
  training loss:		0.058608
  validation loss:		0.220235
  validation accuracy:		93.91 %
Epoch 509 of 2000 took 0.035s
  training loss:		0.057402
  validation loss:		0.226564
  validation accuracy:		93.70 %
Epoch 510 of 2000 took 0.035s
  training loss:		0.057467
  validation loss:		0.222390
  validation accuracy:		94.24 %
Epoch 511 of 2000 took 0.035s
  training loss:		0.056637
  validation loss:		0.235273
  validation accuracy:		93.04 %
Epoch 512 of 2000 took 0.035s
  training loss:		0.060257
  validation loss:		0.233355
  validation accuracy:		93.91 %
Epoch 513 of 2000 took 0.035s
  training loss:		0.058135
  validation loss:		0.235197
  validation accuracy:		94.13 %
Epoch 514 of 2000 took 0.035s
  training loss:		0.057681
  validation loss:		0.234690
  validation accuracy:		93.70 %
Epoch 515 of 2000 took 0.035s
  training loss:		0.058772
  validation loss:		0.227135
  validation accuracy:		94.02 %
Epoch 516 of 2000 took 0.035s
  training loss:		0.055922
  validation loss:		0.219691
  validation accuracy:		93.91 %
Epoch 517 of 2000 took 0.035s
  training loss:		0.054906
  validation loss:		0.226630
  validation accuracy:		93.48 %
Epoch 518 of 2000 took 0.035s
  training loss:		0.056264
  validation loss:		0.229455
  validation accuracy:		93.59 %
Epoch 519 of 2000 took 0.035s
  training loss:		0.055188
  validation loss:		0.225832
  validation accuracy:		93.80 %
Epoch 520 of 2000 took 0.035s
  training loss:		0.056720
  validation loss:		0.230445
  validation accuracy:		93.80 %
Epoch 521 of 2000 took 0.035s
  training loss:		0.056701
  validation loss:		0.227027
  validation accuracy:		93.48 %
Epoch 522 of 2000 took 0.035s
  training loss:		0.056241
  validation loss:		0.225900
  validation accuracy:		94.13 %
Epoch 523 of 2000 took 0.035s
  training loss:		0.054785
  validation loss:		0.232877
  validation accuracy:		93.91 %
Epoch 524 of 2000 took 0.035s
  training loss:		0.054665
  validation loss:		0.232093
  validation accuracy:		93.48 %
Epoch 525 of 2000 took 0.035s
  training loss:		0.055271
  validation loss:		0.227569
  validation accuracy:		93.91 %
Epoch 526 of 2000 took 0.035s
  training loss:		0.054804
  validation loss:		0.230806
  validation accuracy:		93.91 %
Epoch 527 of 2000 took 0.035s
  training loss:		0.055260
  validation loss:		0.228133
  validation accuracy:		93.80 %
Epoch 528 of 2000 took 0.035s
  training loss:		0.055313
  validation loss:		0.233389
  validation accuracy:		93.48 %
Epoch 529 of 2000 took 0.035s
  training loss:		0.053937
  validation loss:		0.230958
  validation accuracy:		93.80 %
Epoch 530 of 2000 took 0.035s
  training loss:		0.054893
  validation loss:		0.236774
  validation accuracy:		93.15 %
Epoch 531 of 2000 took 0.035s
  training loss:		0.053601
  validation loss:		0.234184
  validation accuracy:		93.80 %
Epoch 532 of 2000 took 0.035s
  training loss:		0.053991
  validation loss:		0.234861
  validation accuracy:		93.70 %
Epoch 533 of 2000 took 0.035s
  training loss:		0.054461
  validation loss:		0.229120
  validation accuracy:		93.91 %
Epoch 534 of 2000 took 0.035s
  training loss:		0.052809
  validation loss:		0.231608
  validation accuracy:		93.48 %
Epoch 535 of 2000 took 0.035s
  training loss:		0.054396
  validation loss:		0.234475
  validation accuracy:		94.02 %
Epoch 536 of 2000 took 0.035s
  training loss:		0.054719
  validation loss:		0.230769
  validation accuracy:		93.48 %
Epoch 537 of 2000 took 0.035s
  training loss:		0.054952
  validation loss:		0.236910
  validation accuracy:		93.80 %
Epoch 538 of 2000 took 0.035s
  training loss:		0.051344
  validation loss:		0.233982
  validation accuracy:		93.37 %
Epoch 539 of 2000 took 0.035s
  training loss:		0.056070
  validation loss:		0.232740
  validation accuracy:		93.91 %
Epoch 540 of 2000 took 0.035s
  training loss:		0.051628
  validation loss:		0.241742
  validation accuracy:		93.26 %
Epoch 541 of 2000 took 0.035s
  training loss:		0.051823
  validation loss:		0.232665
  validation accuracy:		93.80 %
Epoch 542 of 2000 took 0.035s
  training loss:		0.052736
  validation loss:		0.229533
  validation accuracy:		93.80 %
Epoch 543 of 2000 took 0.035s
  training loss:		0.052482
  validation loss:		0.235846
  validation accuracy:		93.91 %
Epoch 544 of 2000 took 0.035s
  training loss:		0.051618
  validation loss:		0.230542
  validation accuracy:		93.80 %
Epoch 545 of 2000 took 0.035s
  training loss:		0.052161
  validation loss:		0.239316
  validation accuracy:		93.70 %
Epoch 546 of 2000 took 0.035s
  training loss:		0.052218
  validation loss:		0.233802
  validation accuracy:		93.48 %
Epoch 547 of 2000 took 0.035s
  training loss:		0.053567
  validation loss:		0.227687
  validation accuracy:		93.80 %
Epoch 548 of 2000 took 0.035s
  training loss:		0.053154
  validation loss:		0.229489
  validation accuracy:		93.70 %
Epoch 549 of 2000 took 0.035s
  training loss:		0.053642
  validation loss:		0.234757
  validation accuracy:		93.80 %
Epoch 550 of 2000 took 0.035s
  training loss:		0.053390
  validation loss:		0.230343
  validation accuracy:		93.80 %
Epoch 551 of 2000 took 0.035s
  training loss:		0.052507
  validation loss:		0.240763
  validation accuracy:		93.59 %
Epoch 552 of 2000 took 0.035s
  training loss:		0.050311
  validation loss:		0.243095
  validation accuracy:		93.80 %
Epoch 553 of 2000 took 0.035s
  training loss:		0.052170
  validation loss:		0.234025
  validation accuracy:		93.59 %
Epoch 554 of 2000 took 0.035s
  training loss:		0.050726
  validation loss:		0.228430
  validation accuracy:		94.02 %
Epoch 555 of 2000 took 0.035s
  training loss:		0.053135
  validation loss:		0.235365
  validation accuracy:		93.48 %
Epoch 556 of 2000 took 0.035s
  training loss:		0.049629
  validation loss:		0.238396
  validation accuracy:		94.02 %
Epoch 557 of 2000 took 0.035s
  training loss:		0.049539
  validation loss:		0.243407
  validation accuracy:		93.70 %
Epoch 558 of 2000 took 0.035s
  training loss:		0.052026
  validation loss:		0.238774
  validation accuracy:		93.59 %
Epoch 559 of 2000 took 0.035s
  training loss:		0.054129
  validation loss:		0.234294
  validation accuracy:		93.70 %
Epoch 560 of 2000 took 0.035s
  training loss:		0.053496
  validation loss:		0.232646
  validation accuracy:		93.80 %
Epoch 561 of 2000 took 0.035s
  training loss:		0.048815
  validation loss:		0.237370
  validation accuracy:		93.70 %
Epoch 562 of 2000 took 0.035s
  training loss:		0.050297
  validation loss:		0.234944
  validation accuracy:		94.13 %
Epoch 563 of 2000 took 0.035s
  training loss:		0.048157
  validation loss:		0.238779
  validation accuracy:		93.37 %
Epoch 564 of 2000 took 0.035s
  training loss:		0.050545
  validation loss:		0.235005
  validation accuracy:		93.91 %
Epoch 565 of 2000 took 0.035s
  training loss:		0.050329
  validation loss:		0.237982
  validation accuracy:		93.59 %
Epoch 566 of 2000 took 0.035s
  training loss:		0.050313
  validation loss:		0.241632
  validation accuracy:		93.70 %
Epoch 567 of 2000 took 0.035s
  training loss:		0.050050
  validation loss:		0.244701
  validation accuracy:		93.37 %
Epoch 568 of 2000 took 0.035s
  training loss:		0.049407
  validation loss:		0.231517
  validation accuracy:		94.02 %
Epoch 569 of 2000 took 0.035s
  training loss:		0.050686
  validation loss:		0.238035
  validation accuracy:		93.91 %
Epoch 570 of 2000 took 0.035s
  training loss:		0.049154
  validation loss:		0.229705
  validation accuracy:		93.80 %
Epoch 571 of 2000 took 0.035s
  training loss:		0.049270
  validation loss:		0.247365
  validation accuracy:		93.59 %
Epoch 572 of 2000 took 0.035s
  training loss:		0.048824
  validation loss:		0.239791
  validation accuracy:		93.59 %
Epoch 573 of 2000 took 0.035s
  training loss:		0.047156
  validation loss:		0.238546
  validation accuracy:		93.59 %
Epoch 574 of 2000 took 0.035s
  training loss:		0.047857
  validation loss:		0.246511
  validation accuracy:		93.80 %
Epoch 575 of 2000 took 0.035s
  training loss:		0.049581
  validation loss:		0.238510
  validation accuracy:		93.59 %
Epoch 576 of 2000 took 0.035s
  training loss:		0.049118
  validation loss:		0.240684
  validation accuracy:		94.02 %
Epoch 577 of 2000 took 0.035s
  training loss:		0.048928
  validation loss:		0.242986
  validation accuracy:		93.59 %
Epoch 578 of 2000 took 0.035s
  training loss:		0.047396
  validation loss:		0.240439
  validation accuracy:		93.70 %
Epoch 579 of 2000 took 0.035s
  training loss:		0.046229
  validation loss:		0.250705
  validation accuracy:		93.48 %
Epoch 580 of 2000 took 0.035s
  training loss:		0.047105
  validation loss:		0.238852
  validation accuracy:		93.48 %
Epoch 581 of 2000 took 0.035s
  training loss:		0.048245
  validation loss:		0.248305
  validation accuracy:		93.70 %
Epoch 582 of 2000 took 0.035s
  training loss:		0.048606
  validation loss:		0.243249
  validation accuracy:		93.70 %
Epoch 583 of 2000 took 0.035s
  training loss:		0.048367
  validation loss:		0.239987
  validation accuracy:		93.70 %
Epoch 584 of 2000 took 0.035s
  training loss:		0.048073
  validation loss:		0.235452
  validation accuracy:		93.70 %
Epoch 585 of 2000 took 0.035s
  training loss:		0.048002
  validation loss:		0.241556
  validation accuracy:		93.80 %
Epoch 586 of 2000 took 0.035s
  training loss:		0.048879
  validation loss:		0.249249
  validation accuracy:		93.70 %
Epoch 587 of 2000 took 0.035s
  training loss:		0.045787
  validation loss:		0.243628
  validation accuracy:		93.70 %
Epoch 588 of 2000 took 0.035s
  training loss:		0.045292
  validation loss:		0.238652
  validation accuracy:		93.37 %
Epoch 589 of 2000 took 0.035s
  training loss:		0.046488
  validation loss:		0.238895
  validation accuracy:		93.59 %
Epoch 590 of 2000 took 0.037s
  training loss:		0.046239
  validation loss:		0.243878
  validation accuracy:		94.02 %
Epoch 591 of 2000 took 0.036s
  training loss:		0.047532
  validation loss:		0.243375
  validation accuracy:		93.59 %
Epoch 592 of 2000 took 0.035s
  training loss:		0.048709
  validation loss:		0.244892
  validation accuracy:		94.02 %
Epoch 593 of 2000 took 0.035s
  training loss:		0.046822
  validation loss:		0.241724
  validation accuracy:		93.59 %
Epoch 594 of 2000 took 0.035s
  training loss:		0.046705
  validation loss:		0.253238
  validation accuracy:		93.37 %
Epoch 595 of 2000 took 0.035s
  training loss:		0.045341
  validation loss:		0.243518
  validation accuracy:		93.70 %
Epoch 596 of 2000 took 0.035s
  training loss:		0.046421
  validation loss:		0.242751
  validation accuracy:		93.59 %
Epoch 597 of 2000 took 0.035s
  training loss:		0.045817
  validation loss:		0.251130
  validation accuracy:		93.48 %
Epoch 598 of 2000 took 0.035s
  training loss:		0.044956
  validation loss:		0.243073
  validation accuracy:		93.70 %
Epoch 599 of 2000 took 0.035s
  training loss:		0.045668
  validation loss:		0.243452
  validation accuracy:		93.91 %
Epoch 600 of 2000 took 0.035s
  training loss:		0.045965
  validation loss:		0.237568
  validation accuracy:		94.13 %
Epoch 601 of 2000 took 0.035s
  training loss:		0.044860
  validation loss:		0.243756
  validation accuracy:		93.70 %
Epoch 602 of 2000 took 0.035s
  training loss:		0.045331
  validation loss:		0.236120
  validation accuracy:		93.70 %
Epoch 603 of 2000 took 0.035s
  training loss:		0.046765
  validation loss:		0.236813
  validation accuracy:		93.70 %
Epoch 604 of 2000 took 0.035s
  training loss:		0.044298
  validation loss:		0.244719
  validation accuracy:		93.70 %
Epoch 605 of 2000 took 0.035s
  training loss:		0.043942
  validation loss:		0.248192
  validation accuracy:		93.48 %
Epoch 606 of 2000 took 0.035s
  training loss:		0.045344
  validation loss:		0.248969
  validation accuracy:		93.70 %
Epoch 607 of 2000 took 0.035s
  training loss:		0.044964
  validation loss:		0.248615
  validation accuracy:		93.59 %
Epoch 608 of 2000 took 0.035s
  training loss:		0.044020
  validation loss:		0.245693
  validation accuracy:		93.91 %
Epoch 609 of 2000 took 0.035s
  training loss:		0.044395
  validation loss:		0.238982
  validation accuracy:		93.70 %
Epoch 610 of 2000 took 0.035s
  training loss:		0.045102
  validation loss:		0.247006
  validation accuracy:		93.70 %
Epoch 611 of 2000 took 0.035s
  training loss:		0.043074
  validation loss:		0.251412
  validation accuracy:		93.80 %
Epoch 612 of 2000 took 0.035s
  training loss:		0.044197
  validation loss:		0.250051
  validation accuracy:		93.37 %
Epoch 613 of 2000 took 0.035s
  training loss:		0.042059
  validation loss:		0.243798
  validation accuracy:		93.70 %
Epoch 614 of 2000 took 0.035s
  training loss:		0.043912
  validation loss:		0.262989
  validation accuracy:		93.37 %
Epoch 615 of 2000 took 0.035s
  training loss:		0.043658
  validation loss:		0.250230
  validation accuracy:		94.02 %
Epoch 616 of 2000 took 0.035s
  training loss:		0.044529
  validation loss:		0.252251
  validation accuracy:		93.59 %
Epoch 617 of 2000 took 0.035s
  training loss:		0.043823
  validation loss:		0.253804
  validation accuracy:		93.48 %
Epoch 618 of 2000 took 0.035s
  training loss:		0.042443
  validation loss:		0.243864
  validation accuracy:		93.59 %
Epoch 619 of 2000 took 0.035s
  training loss:		0.042277
  validation loss:		0.244343
  validation accuracy:		93.70 %
Epoch 620 of 2000 took 0.035s
  training loss:		0.044812
  validation loss:		0.250388
  validation accuracy:		93.70 %
Epoch 621 of 2000 took 0.035s
  training loss:		0.041671
  validation loss:		0.245645
  validation accuracy:		93.59 %
Epoch 622 of 2000 took 0.035s
  training loss:		0.042647
  validation loss:		0.252577
  validation accuracy:		93.91 %
Epoch 623 of 2000 took 0.035s
  training loss:		0.042573
  validation loss:		0.245833
  validation accuracy:		93.80 %
Epoch 624 of 2000 took 0.035s
  training loss:		0.041564
  validation loss:		0.250365
  validation accuracy:		93.80 %
Epoch 625 of 2000 took 0.035s
  training loss:		0.041897
  validation loss:		0.264280
  validation accuracy:		93.26 %
Epoch 626 of 2000 took 0.035s
  training loss:		0.042777
  validation loss:		0.246983
  validation accuracy:		93.59 %
Epoch 627 of 2000 took 0.035s
  training loss:		0.042126
  validation loss:		0.249048
  validation accuracy:		93.59 %
Epoch 628 of 2000 took 0.035s
  training loss:		0.040575
  validation loss:		0.256008
  validation accuracy:		93.59 %
Epoch 629 of 2000 took 0.035s
  training loss:		0.040961
  validation loss:		0.248309
  validation accuracy:		93.59 %
Epoch 630 of 2000 took 0.035s
  training loss:		0.041888
  validation loss:		0.254679
  validation accuracy:		93.91 %
Epoch 631 of 2000 took 0.035s
  training loss:		0.040974
  validation loss:		0.248743
  validation accuracy:		93.48 %
Epoch 632 of 2000 took 0.035s
  training loss:		0.042041
  validation loss:		0.253403
  validation accuracy:		93.59 %
Epoch 633 of 2000 took 0.035s
  training loss:		0.041099
  validation loss:		0.251248
  validation accuracy:		93.48 %
Epoch 634 of 2000 took 0.035s
  training loss:		0.040218
  validation loss:		0.243765
  validation accuracy:		93.70 %
Epoch 635 of 2000 took 0.035s
  training loss:		0.041989
  validation loss:		0.253403
  validation accuracy:		93.59 %
Epoch 636 of 2000 took 0.035s
  training loss:		0.041133
  validation loss:		0.252396
  validation accuracy:		93.15 %
Epoch 637 of 2000 took 0.035s
  training loss:		0.040384
  validation loss:		0.249075
  validation accuracy:		93.80 %
Epoch 638 of 2000 took 0.035s
  training loss:		0.041182
  validation loss:		0.251516
  validation accuracy:		93.80 %
Epoch 639 of 2000 took 0.035s
  training loss:		0.042033
  validation loss:		0.264526
  validation accuracy:		92.93 %
Epoch 640 of 2000 took 0.035s
  training loss:		0.040037
  validation loss:		0.252508
  validation accuracy:		93.59 %
Epoch 641 of 2000 took 0.035s
  training loss:		0.040907
  validation loss:		0.257486
  validation accuracy:		93.37 %
Epoch 642 of 2000 took 0.035s
  training loss:		0.041044
  validation loss:		0.250082
  validation accuracy:		93.70 %
Epoch 643 of 2000 took 0.035s
  training loss:		0.040043
  validation loss:		0.258579
  validation accuracy:		93.48 %
Epoch 644 of 2000 took 0.035s
  training loss:		0.039302
  validation loss:		0.251892
  validation accuracy:		93.59 %
Epoch 645 of 2000 took 0.035s
  training loss:		0.040086
  validation loss:		0.257409
  validation accuracy:		93.70 %
Epoch 646 of 2000 took 0.035s
  training loss:		0.040513
  validation loss:		0.254162
  validation accuracy:		93.48 %
Epoch 647 of 2000 took 0.035s
  training loss:		0.040837
  validation loss:		0.252451
  validation accuracy:		93.80 %
Epoch 648 of 2000 took 0.035s
  training loss:		0.040458
  validation loss:		0.255735
  validation accuracy:		93.59 %
Epoch 649 of 2000 took 0.035s
  training loss:		0.040206
  validation loss:		0.253919
  validation accuracy:		93.59 %
Epoch 650 of 2000 took 0.035s
  training loss:		0.039623
  validation loss:		0.262722
  validation accuracy:		93.15 %
Epoch 651 of 2000 took 0.035s
  training loss:		0.039476
  validation loss:		0.254216
  validation accuracy:		93.59 %
Epoch 652 of 2000 took 0.035s
  training loss:		0.038567
  validation loss:		0.262000
  validation accuracy:		93.37 %
Epoch 653 of 2000 took 0.035s
  training loss:		0.038603
  validation loss:		0.259815
  validation accuracy:		93.59 %
Epoch 654 of 2000 took 0.035s
  training loss:		0.039590
  validation loss:		0.252654
  validation accuracy:		93.70 %
Epoch 655 of 2000 took 0.035s
  training loss:		0.039959
  validation loss:		0.252068
  validation accuracy:		93.48 %
Epoch 656 of 2000 took 0.035s
  training loss:		0.038488
  validation loss:		0.261259
  validation accuracy:		93.59 %
Epoch 657 of 2000 took 0.035s
  training loss:		0.037073
  validation loss:		0.254396
  validation accuracy:		93.48 %
Epoch 658 of 2000 took 0.035s
  training loss:		0.039139
  validation loss:		0.257285
  validation accuracy:		93.80 %
Epoch 659 of 2000 took 0.035s
  training loss:		0.038911
  validation loss:		0.260915
  validation accuracy:		93.26 %
Epoch 660 of 2000 took 0.035s
  training loss:		0.038832
  validation loss:		0.256973
  validation accuracy:		93.70 %
Epoch 661 of 2000 took 0.035s
  training loss:		0.038527
  validation loss:		0.258386
  validation accuracy:		93.37 %
Epoch 662 of 2000 took 0.035s
  training loss:		0.037271
  validation loss:		0.259023
  validation accuracy:		93.59 %
Epoch 663 of 2000 took 0.035s
  training loss:		0.038236
  validation loss:		0.254664
  validation accuracy:		93.59 %
Epoch 664 of 2000 took 0.035s
  training loss:		0.036985
  validation loss:		0.263464
  validation accuracy:		93.37 %
Epoch 665 of 2000 took 0.035s
  training loss:		0.038581
  validation loss:		0.258719
  validation accuracy:		93.48 %
Epoch 666 of 2000 took 0.035s
  training loss:		0.038561
  validation loss:		0.260596
  validation accuracy:		93.70 %
Epoch 667 of 2000 took 0.035s
  training loss:		0.038166
  validation loss:		0.251736
  validation accuracy:		93.59 %
Epoch 668 of 2000 took 0.036s
  training loss:		0.037855
  validation loss:		0.256655
  validation accuracy:		93.80 %
Epoch 669 of 2000 took 0.036s
  training loss:		0.038747
  validation loss:		0.263323
  validation accuracy:		93.59 %
Epoch 670 of 2000 took 0.035s
  training loss:		0.037249
  validation loss:		0.263208
  validation accuracy:		93.26 %
Epoch 671 of 2000 took 0.035s
  training loss:		0.036057
  validation loss:		0.258319
  validation accuracy:		93.48 %
Epoch 672 of 2000 took 0.035s
  training loss:		0.036992
  validation loss:		0.260531
  validation accuracy:		93.59 %
Epoch 673 of 2000 took 0.035s
  training loss:		0.036378
  validation loss:		0.262434
  validation accuracy:		93.26 %
Epoch 674 of 2000 took 0.035s
  training loss:		0.037967
  validation loss:		0.259357
  validation accuracy:		93.48 %
Epoch 675 of 2000 took 0.035s
  training loss:		0.037129
  validation loss:		0.263363
  validation accuracy:		93.59 %
Epoch 676 of 2000 took 0.035s
  training loss:		0.037100
  validation loss:		0.266434
  validation accuracy:		93.15 %
Epoch 677 of 2000 took 0.035s
  training loss:		0.038147
  validation loss:		0.258835
  validation accuracy:		93.59 %
Epoch 678 of 2000 took 0.035s
  training loss:		0.037454
  validation loss:		0.262989
  validation accuracy:		93.37 %
Epoch 679 of 2000 took 0.035s
  training loss:		0.034763
  validation loss:		0.264170
  validation accuracy:		93.59 %
Epoch 680 of 2000 took 0.035s
  training loss:		0.036351
  validation loss:		0.264517
  validation accuracy:		93.15 %
Epoch 681 of 2000 took 0.035s
  training loss:		0.037225
  validation loss:		0.262248
  validation accuracy:		93.59 %
Epoch 682 of 2000 took 0.035s
  training loss:		0.035676
  validation loss:		0.262406
  validation accuracy:		93.70 %
Epoch 683 of 2000 took 0.035s
  training loss:		0.036744
  validation loss:		0.263900
  validation accuracy:		93.48 %
Epoch 684 of 2000 took 0.035s
  training loss:		0.036367
  validation loss:		0.264094
  validation accuracy:		93.48 %
Epoch 685 of 2000 took 0.035s
  training loss:		0.035350
  validation loss:		0.272709
  validation accuracy:		93.04 %
Epoch 686 of 2000 took 0.035s
  training loss:		0.035400
  validation loss:		0.261946
  validation accuracy:		93.80 %
Epoch 687 of 2000 took 0.035s
  training loss:		0.036070
  validation loss:		0.272047
  validation accuracy:		93.15 %
Epoch 688 of 2000 took 0.035s
  training loss:		0.036861
  validation loss:		0.263962
  validation accuracy:		93.59 %
Epoch 689 of 2000 took 0.035s
  training loss:		0.035375
  validation loss:		0.259863
  validation accuracy:		93.48 %
Epoch 690 of 2000 took 0.035s
  training loss:		0.035824
  validation loss:		0.265831
  validation accuracy:		93.48 %
Epoch 691 of 2000 took 0.035s
  training loss:		0.035944
  validation loss:		0.263223
  validation accuracy:		93.70 %
Epoch 692 of 2000 took 0.035s
  training loss:		0.035098
  validation loss:		0.268063
  validation accuracy:		93.37 %
Epoch 693 of 2000 took 0.035s
  training loss:		0.035462
  validation loss:		0.265014
  validation accuracy:		93.80 %
Epoch 694 of 2000 took 0.035s
  training loss:		0.036832
  validation loss:		0.260652
  validation accuracy:		93.48 %
Epoch 695 of 2000 took 0.035s
  training loss:		0.034589
  validation loss:		0.262127
  validation accuracy:		93.37 %
Epoch 696 of 2000 took 0.035s
  training loss:		0.035017
  validation loss:		0.268314
  validation accuracy:		93.48 %
Epoch 697 of 2000 took 0.035s
  training loss:		0.035068
  validation loss:		0.267869
  validation accuracy:		93.59 %
Epoch 698 of 2000 took 0.035s
  training loss:		0.033975
  validation loss:		0.264020
  validation accuracy:		93.37 %
Epoch 699 of 2000 took 0.035s
  training loss:		0.034980
  validation loss:		0.267526
  validation accuracy:		93.37 %
Epoch 700 of 2000 took 0.035s
  training loss:		0.035826
  validation loss:		0.261398
  validation accuracy:		93.59 %
Epoch 701 of 2000 took 0.035s
  training loss:		0.034710
  validation loss:		0.271106
  validation accuracy:		93.48 %
Epoch 702 of 2000 took 0.035s
  training loss:		0.035362
  validation loss:		0.269768
  validation accuracy:		93.59 %
Epoch 703 of 2000 took 0.035s
  training loss:		0.034319
  validation loss:		0.269917
  validation accuracy:		93.04 %
Epoch 704 of 2000 took 0.035s
  training loss:		0.033487
  validation loss:		0.274826
  validation accuracy:		93.26 %
Epoch 705 of 2000 took 0.035s
  training loss:		0.033947
  validation loss:		0.271622
  validation accuracy:		93.15 %
Epoch 706 of 2000 took 0.035s
  training loss:		0.034295
  validation loss:		0.269847
  validation accuracy:		93.59 %
Epoch 707 of 2000 took 0.035s
  training loss:		0.033456
  validation loss:		0.279660
  validation accuracy:		93.37 %
Epoch 708 of 2000 took 0.035s
  training loss:		0.033507
  validation loss:		0.267168
  validation accuracy:		93.59 %
Epoch 709 of 2000 took 0.035s
  training loss:		0.031758
  validation loss:		0.266369
  validation accuracy:		93.59 %
Epoch 710 of 2000 took 0.035s
  training loss:		0.035122
  validation loss:		0.262673
  validation accuracy:		93.80 %
Epoch 711 of 2000 took 0.035s
  training loss:		0.033661
  validation loss:		0.267084
  validation accuracy:		93.37 %
Epoch 712 of 2000 took 0.035s
  training loss:		0.032921
  validation loss:		0.262899
  validation accuracy:		93.48 %
Epoch 713 of 2000 took 0.035s
  training loss:		0.032437
  validation loss:		0.268179
  validation accuracy:		93.37 %
Epoch 714 of 2000 took 0.036s
  training loss:		0.034289
  validation loss:		0.266140
  validation accuracy:		93.48 %
Epoch 715 of 2000 took 0.035s
  training loss:		0.032931
  validation loss:		0.276708
  validation accuracy:		93.59 %
Epoch 716 of 2000 took 0.035s
  training loss:		0.033785
  validation loss:		0.275075
  validation accuracy:		93.37 %
Epoch 717 of 2000 took 0.035s
  training loss:		0.033334
  validation loss:		0.270604
  validation accuracy:		93.59 %
Epoch 718 of 2000 took 0.035s
  training loss:		0.032583
  validation loss:		0.276827
  validation accuracy:		93.37 %
Epoch 719 of 2000 took 0.035s
  training loss:		0.032755
  validation loss:		0.279296
  validation accuracy:		93.48 %
Epoch 720 of 2000 took 0.035s
  training loss:		0.032060
  validation loss:		0.267301
  validation accuracy:		93.37 %
Epoch 721 of 2000 took 0.035s
  training loss:		0.033874
  validation loss:		0.272532
  validation accuracy:		93.26 %
Epoch 722 of 2000 took 0.035s
  training loss:		0.032721
  validation loss:		0.263565
  validation accuracy:		93.80 %
Epoch 723 of 2000 took 0.035s
  training loss:		0.033539
  validation loss:		0.264214
  validation accuracy:		93.70 %
Epoch 724 of 2000 took 0.035s
  training loss:		0.032016
  validation loss:		0.280774
  validation accuracy:		93.15 %
Epoch 725 of 2000 took 0.035s
  training loss:		0.031348
  validation loss:		0.267351
  validation accuracy:		93.59 %
Epoch 726 of 2000 took 0.035s
  training loss:		0.032237
  validation loss:		0.275084
  validation accuracy:		93.37 %
Epoch 727 of 2000 took 0.035s
  training loss:		0.032484
  validation loss:		0.282675
  validation accuracy:		93.26 %
Epoch 728 of 2000 took 0.035s
  training loss:		0.031858
  validation loss:		0.275571
  validation accuracy:		93.48 %
Epoch 729 of 2000 took 0.035s
  training loss:		0.031322
  validation loss:		0.264144
  validation accuracy:		93.59 %
Epoch 730 of 2000 took 0.035s
  training loss:		0.033509
  validation loss:		0.276479
  validation accuracy:		93.15 %
Epoch 731 of 2000 took 0.035s
  training loss:		0.032938
  validation loss:		0.277941
  validation accuracy:		93.48 %
Epoch 732 of 2000 took 0.035s
  training loss:		0.032380
  validation loss:		0.281211
  validation accuracy:		93.48 %
Epoch 733 of 2000 took 0.035s
  training loss:		0.031763
  validation loss:		0.278219
  validation accuracy:		93.26 %
Epoch 734 of 2000 took 0.035s
  training loss:		0.031324
  validation loss:		0.273734
  validation accuracy:		93.26 %
Epoch 735 of 2000 took 0.035s
  training loss:		0.031591
  validation loss:		0.275475
  validation accuracy:		93.26 %
Epoch 736 of 2000 took 0.035s
  training loss:		0.031248
  validation loss:		0.269510
  validation accuracy:		93.48 %
Epoch 737 of 2000 took 0.035s
  training loss:		0.031276
  validation loss:		0.276981
  validation accuracy:		93.37 %
Epoch 738 of 2000 took 0.035s
  training loss:		0.030027
  validation loss:		0.271917
  validation accuracy:		93.59 %
Epoch 739 of 2000 took 0.035s
  training loss:		0.031468
  validation loss:		0.269913
  validation accuracy:		93.59 %
Epoch 740 of 2000 took 0.035s
  training loss:		0.030414
  validation loss:		0.278476
  validation accuracy:		93.26 %
Epoch 741 of 2000 took 0.035s
  training loss:		0.030062
  validation loss:		0.279314
  validation accuracy:		93.26 %
Epoch 742 of 2000 took 0.035s
  training loss:		0.031963
  validation loss:		0.278999
  validation accuracy:		93.26 %
Epoch 743 of 2000 took 0.035s
  training loss:		0.031283
  validation loss:		0.279494
  validation accuracy:		93.70 %
Epoch 744 of 2000 took 0.035s
  training loss:		0.031523
  validation loss:		0.268513
  validation accuracy:		93.59 %
Epoch 745 of 2000 took 0.035s
  training loss:		0.030957
  validation loss:		0.282263
  validation accuracy:		93.37 %
Epoch 746 of 2000 took 0.035s
  training loss:		0.030704
  validation loss:		0.275056
  validation accuracy:		93.37 %
Epoch 747 of 2000 took 0.035s
  training loss:		0.030671
  validation loss:		0.276256
  validation accuracy:		93.48 %
Epoch 748 of 2000 took 0.035s
  training loss:		0.030924
  validation loss:		0.286252
  validation accuracy:		93.48 %
Epoch 749 of 2000 took 0.035s
  training loss:		0.030602
  validation loss:		0.276880
  validation accuracy:		93.48 %
Epoch 750 of 2000 took 0.035s
  training loss:		0.029915
  validation loss:		0.276281
  validation accuracy:		93.37 %
Epoch 751 of 2000 took 0.035s
  training loss:		0.029924
  validation loss:		0.279753
  validation accuracy:		93.26 %
Epoch 752 of 2000 took 0.035s
  training loss:		0.030304
  validation loss:		0.277535
  validation accuracy:		93.26 %
Epoch 753 of 2000 took 0.035s
  training loss:		0.029768
  validation loss:		0.282451
  validation accuracy:		93.37 %
Epoch 754 of 2000 took 0.035s
  training loss:		0.030769
  validation loss:		0.277050
  validation accuracy:		93.48 %
Epoch 755 of 2000 took 0.035s
  training loss:		0.030683
  validation loss:		0.280826
  validation accuracy:		93.59 %
Epoch 756 of 2000 took 0.035s
  training loss:		0.029968
  validation loss:		0.273557
  validation accuracy:		93.70 %
Epoch 757 of 2000 took 0.035s
  training loss:		0.030060
  validation loss:		0.284210
  validation accuracy:		93.26 %
Epoch 758 of 2000 took 0.035s
  training loss:		0.029524
  validation loss:		0.275191
  validation accuracy:		93.48 %
Epoch 759 of 2000 took 0.035s
  training loss:		0.029511
  validation loss:		0.273815
  validation accuracy:		93.59 %
Epoch 760 of 2000 took 0.035s
  training loss:		0.029458
  validation loss:		0.281386
  validation accuracy:		93.37 %
Epoch 761 of 2000 took 0.035s
  training loss:		0.029177
  validation loss:		0.273575
  validation accuracy:		93.70 %
Epoch 762 of 2000 took 0.035s
  training loss:		0.028059
  validation loss:		0.287065
  validation accuracy:		93.37 %
Epoch 763 of 2000 took 0.035s
  training loss:		0.029240
  validation loss:		0.290083
  validation accuracy:		93.26 %
Epoch 764 of 2000 took 0.035s
  training loss:		0.029096
  validation loss:		0.275979
  validation accuracy:		93.59 %
Epoch 765 of 2000 took 0.035s
  training loss:		0.028751
  validation loss:		0.284918
  validation accuracy:		93.37 %
Epoch 766 of 2000 took 0.035s
  training loss:		0.029394
  validation loss:		0.276845
  validation accuracy:		93.48 %
Epoch 767 of 2000 took 0.035s
  training loss:		0.029374
  validation loss:		0.280244
  validation accuracy:		93.48 %
Epoch 768 of 2000 took 0.035s
  training loss:		0.028727
  validation loss:		0.281219
  validation accuracy:		93.26 %
Epoch 769 of 2000 took 0.035s
  training loss:		0.028425
  validation loss:		0.279584
  validation accuracy:		93.37 %
Epoch 770 of 2000 took 0.035s
  training loss:		0.028881
  validation loss:		0.288275
  validation accuracy:		93.59 %
Epoch 771 of 2000 took 0.035s
  training loss:		0.028185
  validation loss:		0.282261
  validation accuracy:		93.37 %
Epoch 772 of 2000 took 0.035s
  training loss:		0.029389
  validation loss:		0.281971
  validation accuracy:		93.37 %
Epoch 773 of 2000 took 0.035s
  training loss:		0.029070
  validation loss:		0.278917
  validation accuracy:		93.59 %
Epoch 774 of 2000 took 0.035s
  training loss:		0.029031
  validation loss:		0.288216
  validation accuracy:		93.37 %
Epoch 775 of 2000 took 0.035s
  training loss:		0.028066
  validation loss:		0.288039
  validation accuracy:		93.48 %
Epoch 776 of 2000 took 0.035s
  training loss:		0.028080
  validation loss:		0.284833
  validation accuracy:		93.37 %
Epoch 777 of 2000 took 0.035s
  training loss:		0.028379
  validation loss:		0.284349
  validation accuracy:		93.26 %
Epoch 778 of 2000 took 0.035s
  training loss:		0.028335
  validation loss:		0.285957
  validation accuracy:		93.48 %
Epoch 779 of 2000 took 0.035s
  training loss:		0.029203
  validation loss:		0.291515
  validation accuracy:		93.48 %
Epoch 780 of 2000 took 0.035s
  training loss:		0.028253
  validation loss:		0.291966
  validation accuracy:		93.04 %
Epoch 781 of 2000 took 0.035s
  training loss:		0.027809
  validation loss:		0.285100
  validation accuracy:		93.37 %
Epoch 782 of 2000 took 0.035s
  training loss:		0.026912
  validation loss:		0.289657
  validation accuracy:		93.26 %
Epoch 783 of 2000 took 0.035s
  training loss:		0.028738
  validation loss:		0.285908
  validation accuracy:		93.37 %
Epoch 784 of 2000 took 0.035s
  training loss:		0.027669
  validation loss:		0.292455
  validation accuracy:		93.26 %
Epoch 785 of 2000 took 0.035s
  training loss:		0.026871
  validation loss:		0.291343
  validation accuracy:		93.26 %
Epoch 786 of 2000 took 0.035s
  training loss:		0.027346
  validation loss:		0.288864
  validation accuracy:		93.37 %
Epoch 787 of 2000 took 0.035s
  training loss:		0.026722
  validation loss:		0.282831
  validation accuracy:		93.48 %
Epoch 788 of 2000 took 0.035s
  training loss:		0.026864
  validation loss:		0.285003
  validation accuracy:		93.48 %
Epoch 789 of 2000 took 0.035s
  training loss:		0.026823
  validation loss:		0.284169
  validation accuracy:		93.59 %
Epoch 790 of 2000 took 0.035s
  training loss:		0.028127
  validation loss:		0.283613
  validation accuracy:		93.48 %
Epoch 791 of 2000 took 0.035s
  training loss:		0.027808
  validation loss:		0.280288
  validation accuracy:		93.70 %
Epoch 792 of 2000 took 0.035s
  training loss:		0.027134
  validation loss:		0.285915
  validation accuracy:		93.70 %
Epoch 793 of 2000 took 0.035s
  training loss:		0.026463
  validation loss:		0.281757
  validation accuracy:		93.37 %
Epoch 794 of 2000 took 0.035s
  training loss:		0.026466
  validation loss:		0.291454
  validation accuracy:		93.48 %
Epoch 795 of 2000 took 0.035s
  training loss:		0.027023
  validation loss:		0.283659
  validation accuracy:		93.37 %
Epoch 796 of 2000 took 0.035s
  training loss:		0.026372
  validation loss:		0.281444
  validation accuracy:		93.70 %
Epoch 797 of 2000 took 0.035s
  training loss:		0.026718
  validation loss:		0.287982
  validation accuracy:		93.37 %
Epoch 798 of 2000 took 0.035s
  training loss:		0.026049
  validation loss:		0.294915
  validation accuracy:		93.37 %
Epoch 799 of 2000 took 0.035s
  training loss:		0.026725
  validation loss:		0.289629
  validation accuracy:		93.37 %
Epoch 800 of 2000 took 0.035s
  training loss:		0.027250
  validation loss:		0.285569
  validation accuracy:		93.48 %
Epoch 801 of 2000 took 0.035s
  training loss:		0.027078
  validation loss:		0.290906
  validation accuracy:		93.26 %
Epoch 802 of 2000 took 0.035s
  training loss:		0.026492
  validation loss:		0.290236
  validation accuracy:		93.37 %
Epoch 803 of 2000 took 0.035s
  training loss:		0.026867
  validation loss:		0.296207
  validation accuracy:		93.48 %
Epoch 804 of 2000 took 0.035s
  training loss:		0.026588
  validation loss:		0.287655
  validation accuracy:		93.37 %
Epoch 805 of 2000 took 0.035s
  training loss:		0.026433
  validation loss:		0.293045
  validation accuracy:		93.37 %
Epoch 806 of 2000 took 0.035s
  training loss:		0.026432
  validation loss:		0.288461
  validation accuracy:		93.59 %
Epoch 807 of 2000 took 0.035s
  training loss:		0.026455
  validation loss:		0.291143
  validation accuracy:		93.48 %
Epoch 808 of 2000 took 0.035s
  training loss:		0.025987
  validation loss:		0.286736
  validation accuracy:		93.59 %
Epoch 809 of 2000 took 0.035s
  training loss:		0.026975
  validation loss:		0.292576
  validation accuracy:		93.37 %
Epoch 810 of 2000 took 0.035s
  training loss:		0.026462
  validation loss:		0.295814
  validation accuracy:		93.37 %
Epoch 811 of 2000 took 0.035s
  training loss:		0.025083
  validation loss:		0.289404
  validation accuracy:		93.59 %
Epoch 812 of 2000 took 0.035s
  training loss:		0.025603
  validation loss:		0.291609
  validation accuracy:		93.37 %
Epoch 813 of 2000 took 0.035s
  training loss:		0.025799
  validation loss:		0.290989
  validation accuracy:		93.26 %
Epoch 814 of 2000 took 0.035s
  training loss:		0.025455
  validation loss:		0.289073
  validation accuracy:		93.59 %
Epoch 815 of 2000 took 0.035s
  training loss:		0.026876
  validation loss:		0.287348
  validation accuracy:		93.48 %
Epoch 816 of 2000 took 0.036s
  training loss:		0.025330
  validation loss:		0.294080
  validation accuracy:		93.59 %
Epoch 817 of 2000 took 0.035s
  training loss:		0.025028
  validation loss:		0.298924
  validation accuracy:		93.15 %
Epoch 818 of 2000 took 0.035s
  training loss:		0.025921
  validation loss:		0.293334
  validation accuracy:		93.37 %
Epoch 819 of 2000 took 0.035s
  training loss:		0.024963
  validation loss:		0.293656
  validation accuracy:		93.15 %
Epoch 820 of 2000 took 0.035s
  training loss:		0.025528
  validation loss:		0.302939
  validation accuracy:		93.37 %
Epoch 821 of 2000 took 0.035s
  training loss:		0.024172
  validation loss:		0.295029
  validation accuracy:		93.37 %
Epoch 822 of 2000 took 0.035s
  training loss:		0.025584
  validation loss:		0.307844
  validation accuracy:		93.04 %
Epoch 823 of 2000 took 0.035s
  training loss:		0.024990
  validation loss:		0.297918
  validation accuracy:		93.48 %
Epoch 824 of 2000 took 0.035s
  training loss:		0.025876
  validation loss:		0.296075
  validation accuracy:		93.37 %
Epoch 825 of 2000 took 0.035s
  training loss:		0.025518
  validation loss:		0.298254
  validation accuracy:		93.37 %
Epoch 826 of 2000 took 0.035s
  training loss:		0.025450
  validation loss:		0.297213
  validation accuracy:		93.26 %
Epoch 827 of 2000 took 0.035s
  training loss:		0.024077
  validation loss:		0.297366
  validation accuracy:		93.26 %
Epoch 828 of 2000 took 0.035s
  training loss:		0.024255
  validation loss:		0.303297
  validation accuracy:		93.48 %
Epoch 829 of 2000 took 0.035s
  training loss:		0.025420
  validation loss:		0.296031
  validation accuracy:		93.59 %
Epoch 830 of 2000 took 0.035s
  training loss:		0.024850
  validation loss:		0.295005
  validation accuracy:		93.37 %
Epoch 831 of 2000 took 0.035s
  training loss:		0.023893
  validation loss:		0.298729
  validation accuracy:		93.37 %
Epoch 832 of 2000 took 0.035s
  training loss:		0.024326
  validation loss:		0.301038
  validation accuracy:		93.37 %
Epoch 833 of 2000 took 0.035s
  training loss:		0.024755
  validation loss:		0.294953
  validation accuracy:		93.37 %
Epoch 834 of 2000 took 0.035s
  training loss:		0.025129
  validation loss:		0.298482
  validation accuracy:		93.37 %
Epoch 835 of 2000 took 0.035s
  training loss:		0.024567
  validation loss:		0.294076
  validation accuracy:		93.48 %
Epoch 836 of 2000 took 0.035s
  training loss:		0.024360
  validation loss:		0.295618
  validation accuracy:		93.26 %
Epoch 837 of 2000 took 0.035s
  training loss:		0.023856
  validation loss:		0.302239
  validation accuracy:		93.26 %
Epoch 838 of 2000 took 0.035s
  training loss:		0.023931
  validation loss:		0.300195
  validation accuracy:		93.37 %
Epoch 839 of 2000 took 0.036s
  training loss:		0.024543
  validation loss:		0.295361
  validation accuracy:		93.70 %
Epoch 840 of 2000 took 0.035s
  training loss:		0.024192
  validation loss:		0.291078
  validation accuracy:		93.26 %
Epoch 841 of 2000 took 0.035s
  training loss:		0.022563
  validation loss:		0.305545
  validation accuracy:		93.48 %
Epoch 842 of 2000 took 0.035s
  training loss:		0.024435
  validation loss:		0.300656
  validation accuracy:		93.26 %
Epoch 843 of 2000 took 0.035s
  training loss:		0.023289
  validation loss:		0.300413
  validation accuracy:		93.48 %
Epoch 844 of 2000 took 0.035s
  training loss:		0.023674
  validation loss:		0.296559
  validation accuracy:		93.48 %
Epoch 845 of 2000 took 0.035s
  training loss:		0.023551
  validation loss:		0.298775
  validation accuracy:		93.26 %
Epoch 846 of 2000 took 0.035s
  training loss:		0.023697
  validation loss:		0.304959
  validation accuracy:		93.37 %
Epoch 847 of 2000 took 0.035s
  training loss:		0.023823
  validation loss:		0.301280
  validation accuracy:		93.48 %
Epoch 848 of 2000 took 0.035s
  training loss:		0.023929
  validation loss:		0.298931
  validation accuracy:		93.48 %
Epoch 849 of 2000 took 0.035s
  training loss:		0.023026
  validation loss:		0.293615
  validation accuracy:		93.48 %
Epoch 850 of 2000 took 0.035s
  training loss:		0.023803
  validation loss:		0.301737
  validation accuracy:		93.37 %
Epoch 851 of 2000 took 0.035s
  training loss:		0.022844
  validation loss:		0.297578
  validation accuracy:		93.37 %
Epoch 852 of 2000 took 0.035s
  training loss:		0.022847
  validation loss:		0.308325
  validation accuracy:		93.26 %
Epoch 853 of 2000 took 0.035s
  training loss:		0.022911
  validation loss:		0.299580
  validation accuracy:		93.48 %
Epoch 854 of 2000 took 0.035s
  training loss:		0.024110
  validation loss:		0.300555
  validation accuracy:		93.37 %
Epoch 855 of 2000 took 0.035s
  training loss:		0.022875
  validation loss:		0.314062
  validation accuracy:		93.15 %
Epoch 856 of 2000 took 0.035s
  training loss:		0.023514
  validation loss:		0.302195
  validation accuracy:		93.26 %
Epoch 857 of 2000 took 0.035s
  training loss:		0.023172
  validation loss:		0.305099
  validation accuracy:		93.59 %
Epoch 858 of 2000 took 0.035s
  training loss:		0.022113
  validation loss:		0.300609
  validation accuracy:		93.37 %
Epoch 859 of 2000 took 0.035s
  training loss:		0.023188
  validation loss:		0.303337
  validation accuracy:		93.15 %
Epoch 860 of 2000 took 0.035s
  training loss:		0.022575
  validation loss:		0.303300
  validation accuracy:		93.15 %
Epoch 861 of 2000 took 0.035s
  training loss:		0.022506
  validation loss:		0.301547
  validation accuracy:		93.37 %
Epoch 862 of 2000 took 0.035s
  training loss:		0.023131
  validation loss:		0.303005
  validation accuracy:		93.37 %
Epoch 863 of 2000 took 0.035s
  training loss:		0.021679
  validation loss:		0.302964
  validation accuracy:		93.48 %
Epoch 864 of 2000 took 0.035s
  training loss:		0.022717
  validation loss:		0.310115
  validation accuracy:		93.37 %
Epoch 865 of 2000 took 0.035s
  training loss:		0.022462
  validation loss:		0.304639
  validation accuracy:		93.37 %
Epoch 866 of 2000 took 0.035s
  training loss:		0.022238
  validation loss:		0.315188
  validation accuracy:		93.04 %
Epoch 867 of 2000 took 0.035s
  training loss:		0.023086
  validation loss:		0.302565
  validation accuracy:		93.37 %
Epoch 868 of 2000 took 0.035s
  training loss:		0.022689
  validation loss:		0.306626
  validation accuracy:		93.15 %
Epoch 869 of 2000 took 0.035s
  training loss:		0.022518
  validation loss:		0.314246
  validation accuracy:		93.37 %
Epoch 870 of 2000 took 0.035s
  training loss:		0.020839
  validation loss:		0.309457
  validation accuracy:		93.04 %
Epoch 871 of 2000 took 0.035s
  training loss:		0.022160
  validation loss:		0.306965
  validation accuracy:		93.15 %
Epoch 872 of 2000 took 0.035s
  training loss:		0.022500
  validation loss:		0.311132
  validation accuracy:		93.37 %
Epoch 873 of 2000 took 0.035s
  training loss:		0.021473
  validation loss:		0.301222
  validation accuracy:		93.70 %
Epoch 874 of 2000 took 0.035s
  training loss:		0.022142
  validation loss:		0.302687
  validation accuracy:		93.48 %
Epoch 875 of 2000 took 0.035s
  training loss:		0.021945
  validation loss:		0.307310
  validation accuracy:		93.15 %
Epoch 876 of 2000 took 0.035s
  training loss:		0.021440
  validation loss:		0.301588
  validation accuracy:		93.26 %
Epoch 877 of 2000 took 0.035s
  training loss:		0.021634
  validation loss:		0.315081
  validation accuracy:		93.37 %
Epoch 878 of 2000 took 0.035s
  training loss:		0.021524
  validation loss:		0.299024
  validation accuracy:		93.48 %
Epoch 879 of 2000 took 0.035s
  training loss:		0.021893
  validation loss:		0.314476
  validation accuracy:		93.26 %
Epoch 880 of 2000 took 0.035s
  training loss:		0.022191
  validation loss:		0.307067
  validation accuracy:		93.26 %
Epoch 881 of 2000 took 0.035s
  training loss:		0.020642
  validation loss:		0.307064
  validation accuracy:		93.15 %
Epoch 882 of 2000 took 0.035s
  training loss:		0.021720
  validation loss:		0.303613
  validation accuracy:		93.26 %
Epoch 883 of 2000 took 0.035s
  training loss:		0.021189
  validation loss:		0.310687
  validation accuracy:		93.26 %
Epoch 884 of 2000 took 0.035s
  training loss:		0.021258
  validation loss:		0.302431
  validation accuracy:		93.26 %
Epoch 885 of 2000 took 0.035s
  training loss:		0.021027
  validation loss:		0.322699
  validation accuracy:		92.93 %
Epoch 886 of 2000 took 0.035s
  training loss:		0.021141
  validation loss:		0.302573
  validation accuracy:		93.37 %
Epoch 887 of 2000 took 0.035s
  training loss:		0.021664
  validation loss:		0.312234
  validation accuracy:		93.15 %
Epoch 888 of 2000 took 0.035s
  training loss:		0.021866
  validation loss:		0.307929
  validation accuracy:		93.26 %
Epoch 889 of 2000 took 0.035s
  training loss:		0.020621
  validation loss:		0.313124
  validation accuracy:		93.26 %
Epoch 890 of 2000 took 0.035s
  training loss:		0.021206
  validation loss:		0.303370
  validation accuracy:		93.26 %
Epoch 891 of 2000 took 0.035s
  training loss:		0.021104
  validation loss:		0.305513
  validation accuracy:		93.48 %
Epoch 892 of 2000 took 0.035s
  training loss:		0.021123
  validation loss:		0.311670
  validation accuracy:		93.15 %
Epoch 893 of 2000 took 0.035s
  training loss:		0.020051
  validation loss:		0.306537
  validation accuracy:		93.26 %
Epoch 894 of 2000 took 0.035s
  training loss:		0.020753
  validation loss:		0.317592
  validation accuracy:		93.48 %
Epoch 895 of 2000 took 0.035s
  training loss:		0.020823
  validation loss:		0.313226
  validation accuracy:		93.26 %
Epoch 896 of 2000 took 0.035s
  training loss:		0.020026
  validation loss:		0.316222
  validation accuracy:		93.48 %
Epoch 897 of 2000 took 0.035s
  training loss:		0.021480
  validation loss:		0.311729
  validation accuracy:		93.37 %
Epoch 898 of 2000 took 0.035s
  training loss:		0.021178
  validation loss:		0.316853
  validation accuracy:		93.04 %
Epoch 899 of 2000 took 0.035s
  training loss:		0.020679
  validation loss:		0.311154
  validation accuracy:		93.26 %
Epoch 900 of 2000 took 0.035s
  training loss:		0.020174
  validation loss:		0.314220
  validation accuracy:		93.15 %
Epoch 901 of 2000 took 0.036s
  training loss:		0.020714
  validation loss:		0.313812
  validation accuracy:		93.15 %
Epoch 902 of 2000 took 0.035s
  training loss:		0.019732
  validation loss:		0.315392
  validation accuracy:		93.26 %
Epoch 903 of 2000 took 0.035s
  training loss:		0.020524
  validation loss:		0.317170
  validation accuracy:		93.26 %
Epoch 904 of 2000 took 0.035s
  training loss:		0.020473
  validation loss:		0.301041
  validation accuracy:		93.70 %
Epoch 905 of 2000 took 0.035s
  training loss:		0.020532
  validation loss:		0.312195
  validation accuracy:		93.37 %
Epoch 906 of 2000 took 0.035s
  training loss:		0.020407
  validation loss:		0.310265
  validation accuracy:		93.48 %
Epoch 907 of 2000 took 0.035s
  training loss:		0.020473
  validation loss:		0.310031
  validation accuracy:		93.26 %
Epoch 908 of 2000 took 0.035s
  training loss:		0.020453
  validation loss:		0.313679
  validation accuracy:		93.37 %
Epoch 909 of 2000 took 0.035s
  training loss:		0.020462
  validation loss:		0.313940
  validation accuracy:		93.26 %
Epoch 910 of 2000 took 0.035s
  training loss:		0.019793
  validation loss:		0.310431
  validation accuracy:		93.37 %
Epoch 911 of 2000 took 0.035s
  training loss:		0.019542
  validation loss:		0.318639
  validation accuracy:		93.26 %
Epoch 912 of 2000 took 0.035s
  training loss:		0.019860
  validation loss:		0.312136
  validation accuracy:		93.48 %
Epoch 913 of 2000 took 0.035s
  training loss:		0.020006
  validation loss:		0.312364
  validation accuracy:		93.26 %
Epoch 914 of 2000 took 0.035s
  training loss:		0.020287
  validation loss:		0.313281
  validation accuracy:		93.26 %
Epoch 915 of 2000 took 0.035s
  training loss:		0.019343
  validation loss:		0.316645
  validation accuracy:		93.26 %
Epoch 916 of 2000 took 0.035s
  training loss:		0.019840
  validation loss:		0.313082
  validation accuracy:		93.37 %
Epoch 917 of 2000 took 0.035s
  training loss:		0.019915
  validation loss:		0.307747
  validation accuracy:		93.26 %
Epoch 918 of 2000 took 0.035s
  training loss:		0.019892
  validation loss:		0.320442
  validation accuracy:		93.15 %
Epoch 919 of 2000 took 0.035s
  training loss:		0.018607
  validation loss:		0.310411
  validation accuracy:		93.70 %
Epoch 920 of 2000 took 0.035s
  training loss:		0.019445
  validation loss:		0.319552
  validation accuracy:		93.37 %
Epoch 921 of 2000 took 0.035s
  training loss:		0.019259
  validation loss:		0.320768
  validation accuracy:		93.26 %
Epoch 922 of 2000 took 0.035s
  training loss:		0.019232
  validation loss:		0.320249
  validation accuracy:		93.15 %
Epoch 923 of 2000 took 0.035s
  training loss:		0.019536
  validation loss:		0.311901
  validation accuracy:		93.26 %
Epoch 924 of 2000 took 0.035s
  training loss:		0.019320
  validation loss:		0.322298
  validation accuracy:		93.26 %
Epoch 925 of 2000 took 0.035s
  training loss:		0.019654
  validation loss:		0.317774
  validation accuracy:		93.37 %
Epoch 926 of 2000 took 0.035s
  training loss:		0.019039
  validation loss:		0.315754
  validation accuracy:		93.37 %
Epoch 927 of 2000 took 0.035s
  training loss:		0.018789
  validation loss:		0.316220
  validation accuracy:		93.26 %
Epoch 928 of 2000 took 0.035s
  training loss:		0.018966
  validation loss:		0.326563
  validation accuracy:		93.04 %
Epoch 929 of 2000 took 0.035s
  training loss:		0.019381
  validation loss:		0.318836
  validation accuracy:		93.48 %
Epoch 930 of 2000 took 0.035s
  training loss:		0.019192
  validation loss:		0.315837
  validation accuracy:		93.26 %
Epoch 931 of 2000 took 0.035s
  training loss:		0.019212
  validation loss:		0.314778
  validation accuracy:		93.26 %
Epoch 932 of 2000 took 0.035s
  training loss:		0.019257
  validation loss:		0.316410
  validation accuracy:		93.26 %
Epoch 933 of 2000 took 0.035s
  training loss:		0.018853
  validation loss:		0.322778
  validation accuracy:		93.37 %
Epoch 934 of 2000 took 0.035s
  training loss:		0.020843
  validation loss:		0.314389
  validation accuracy:		93.48 %
Epoch 935 of 2000 took 0.035s
  training loss:		0.019130
  validation loss:		0.320461
  validation accuracy:		93.26 %
Epoch 936 of 2000 took 0.035s
  training loss:		0.019123
  validation loss:		0.320782
  validation accuracy:		93.26 %
Epoch 937 of 2000 took 0.035s
  training loss:		0.018995
  validation loss:		0.325169
  validation accuracy:		93.15 %
Epoch 938 of 2000 took 0.035s
  training loss:		0.019121
  validation loss:		0.321832
  validation accuracy:		93.26 %
Epoch 939 of 2000 took 0.035s
  training loss:		0.017793
  validation loss:		0.325422
  validation accuracy:		93.37 %
Epoch 940 of 2000 took 0.035s
  training loss:		0.018859
  validation loss:		0.318770
  validation accuracy:		93.26 %
Epoch 941 of 2000 took 0.035s
  training loss:		0.018692
  validation loss:		0.320304
  validation accuracy:		93.48 %
Epoch 942 of 2000 took 0.035s
  training loss:		0.018612
  validation loss:		0.327419
  validation accuracy:		93.04 %
Epoch 943 of 2000 took 0.035s
  training loss:		0.018864
  validation loss:		0.328844
  validation accuracy:		93.37 %
Epoch 944 of 2000 took 0.035s
  training loss:		0.019194
  validation loss:		0.325610
  validation accuracy:		93.48 %
Epoch 945 of 2000 took 0.035s
  training loss:		0.018339
  validation loss:		0.323953
  validation accuracy:		93.37 %
Epoch 946 of 2000 took 0.035s
  training loss:		0.018248
  validation loss:		0.319900
  validation accuracy:		93.26 %
Epoch 947 of 2000 took 0.035s
  training loss:		0.018723
  validation loss:		0.322858
  validation accuracy:		93.48 %
Epoch 948 of 2000 took 0.035s
  training loss:		0.018614
  validation loss:		0.323587
  validation accuracy:		93.26 %
Epoch 949 of 2000 took 0.035s
  training loss:		0.018269
  validation loss:		0.322696
  validation accuracy:		93.59 %
Epoch 950 of 2000 took 0.035s
  training loss:		0.018321
  validation loss:		0.322328
  validation accuracy:		93.37 %
Epoch 951 of 2000 took 0.035s
  training loss:		0.017934
  validation loss:		0.334325
  validation accuracy:		92.83 %
Epoch 952 of 2000 took 0.035s
  training loss:		0.018550
  validation loss:		0.323433
  validation accuracy:		93.26 %
Epoch 953 of 2000 took 0.036s
  training loss:		0.017873
  validation loss:		0.327159
  validation accuracy:		93.37 %
Epoch 954 of 2000 took 0.035s
  training loss:		0.017928
  validation loss:		0.325248
  validation accuracy:		93.26 %
Epoch 955 of 2000 took 0.035s
  training loss:		0.017218
  validation loss:		0.319719
  validation accuracy:		93.59 %
Epoch 956 of 2000 took 0.035s
  training loss:		0.018065
  validation loss:		0.316176
  validation accuracy:		93.37 %
Epoch 957 of 2000 took 0.035s
  training loss:		0.017361
  validation loss:		0.325814
  validation accuracy:		93.48 %
Epoch 958 of 2000 took 0.035s
  training loss:		0.016891
  validation loss:		0.318263
  validation accuracy:		93.26 %
Epoch 959 of 2000 took 0.035s
  training loss:		0.016577
  validation loss:		0.323054
  validation accuracy:		93.26 %
Epoch 960 of 2000 took 0.035s
  training loss:		0.017255
  validation loss:		0.324221
  validation accuracy:		93.26 %
Epoch 961 of 2000 took 0.035s
  training loss:		0.017945
  validation loss:		0.332914
  validation accuracy:		93.37 %
Epoch 962 of 2000 took 0.035s
  training loss:		0.018227
  validation loss:		0.326775
  validation accuracy:		93.26 %
Epoch 963 of 2000 took 0.035s
  training loss:		0.017284
  validation loss:		0.330345
  validation accuracy:		93.26 %
Epoch 964 of 2000 took 0.035s
  training loss:		0.017140
  validation loss:		0.328208
  validation accuracy:		93.26 %
Epoch 965 of 2000 took 0.035s
  training loss:		0.017226
  validation loss:		0.320211
  validation accuracy:		93.37 %
Epoch 966 of 2000 took 0.035s
  training loss:		0.017738
  validation loss:		0.334231
  validation accuracy:		93.15 %
Epoch 967 of 2000 took 0.035s
  training loss:		0.017207
  validation loss:		0.325701
  validation accuracy:		93.26 %
Epoch 968 of 2000 took 0.035s
  training loss:		0.017420
  validation loss:		0.328681
  validation accuracy:		93.48 %
Epoch 969 of 2000 took 0.035s
  training loss:		0.017305
  validation loss:		0.326215
  validation accuracy:		93.37 %
Epoch 970 of 2000 took 0.035s
  training loss:		0.016849
  validation loss:		0.333357
  validation accuracy:		93.15 %
Epoch 971 of 2000 took 0.035s
  training loss:		0.017515
  validation loss:		0.325694
  validation accuracy:		93.37 %
Epoch 972 of 2000 took 0.035s
  training loss:		0.016928
  validation loss:		0.334335
  validation accuracy:		93.15 %
Epoch 973 of 2000 took 0.035s
  training loss:		0.018040
  validation loss:		0.321660
  validation accuracy:		93.26 %
Epoch 974 of 2000 took 0.035s
  training loss:		0.017323
  validation loss:		0.330583
  validation accuracy:		93.26 %
Epoch 975 of 2000 took 0.035s
  training loss:		0.017442
  validation loss:		0.327951
  validation accuracy:		93.37 %
Epoch 976 of 2000 took 0.035s
  training loss:		0.017040
  validation loss:		0.330474
  validation accuracy:		93.37 %
Epoch 977 of 2000 took 0.035s
  training loss:		0.016976
  validation loss:		0.333951
  validation accuracy:		93.04 %
Epoch 978 of 2000 took 0.035s
  training loss:		0.016748
  validation loss:		0.330789
  validation accuracy:		93.37 %
Epoch 979 of 2000 took 0.035s
  training loss:		0.017118
  validation loss:		0.332491
  validation accuracy:		93.26 %
Epoch 980 of 2000 took 0.035s
  training loss:		0.016703
  validation loss:		0.333939
  validation accuracy:		93.37 %
Epoch 981 of 2000 took 0.035s
  training loss:		0.017334
  validation loss:		0.330185
  validation accuracy:		93.37 %
Epoch 982 of 2000 took 0.035s
  training loss:		0.016190
  validation loss:		0.328317
  validation accuracy:		93.48 %
Epoch 983 of 2000 took 0.035s
  training loss:		0.016049
  validation loss:		0.336754
  validation accuracy:		93.04 %
Epoch 984 of 2000 took 0.035s
  training loss:		0.017262
  validation loss:		0.340964
  validation accuracy:		93.04 %
Epoch 985 of 2000 took 0.035s
  training loss:		0.016519
  validation loss:		0.327044
  validation accuracy:		93.37 %
Epoch 986 of 2000 took 0.035s
  training loss:		0.016919
  validation loss:		0.329208
  validation accuracy:		93.37 %
Epoch 987 of 2000 took 0.035s
  training loss:		0.016750
  validation loss:		0.334505
  validation accuracy:		93.26 %
Epoch 988 of 2000 took 0.035s
  training loss:		0.016600
  validation loss:		0.331537
  validation accuracy:		93.26 %
Epoch 989 of 2000 took 0.035s
  training loss:		0.016369
  validation loss:		0.340038
  validation accuracy:		93.04 %
Epoch 990 of 2000 took 0.035s
  training loss:		0.016873
  validation loss:		0.333399
  validation accuracy:		93.26 %
Epoch 991 of 2000 took 0.035s
  training loss:		0.016579
  validation loss:		0.325152
  validation accuracy:		93.26 %
Epoch 992 of 2000 took 0.035s
  training loss:		0.016319
  validation loss:		0.330366
  validation accuracy:		93.26 %
Epoch 993 of 2000 took 0.035s
  training loss:		0.016389
  validation loss:		0.339733
  validation accuracy:		93.48 %
Epoch 994 of 2000 took 0.035s
  training loss:		0.016784
  validation loss:		0.330429
  validation accuracy:		93.48 %
Epoch 995 of 2000 took 0.035s
  training loss:		0.016101
  validation loss:		0.329821
  validation accuracy:		93.37 %
Epoch 996 of 2000 took 0.035s
  training loss:		0.015869
  validation loss:		0.341920
  validation accuracy:		93.48 %
Epoch 997 of 2000 took 0.037s
  training loss:		0.016485
  validation loss:		0.329130
  validation accuracy:		93.37 %
Epoch 998 of 2000 took 0.035s
  training loss:		0.016036
  validation loss:		0.342110
  validation accuracy:		93.04 %
Epoch 999 of 2000 took 0.035s
  training loss:		0.016734
  validation loss:		0.340215
  validation accuracy:		93.37 %
Epoch 1000 of 2000 took 0.035s
  training loss:		0.016027
  validation loss:		0.333783
  validation accuracy:		93.15 %
Epoch 1001 of 2000 took 0.035s
  training loss:		0.016233
  validation loss:		0.331396
  validation accuracy:		93.48 %
Epoch 1002 of 2000 took 0.035s
  training loss:		0.015528
  validation loss:		0.343302
  validation accuracy:		93.04 %
Epoch 1003 of 2000 took 0.035s
  training loss:		0.015754
  validation loss:		0.330741
  validation accuracy:		93.26 %
Epoch 1004 of 2000 took 0.035s
  training loss:		0.015168
  validation loss:		0.337961
  validation accuracy:		93.26 %
Epoch 1005 of 2000 took 0.035s
  training loss:		0.015879
  validation loss:		0.334133
  validation accuracy:		93.59 %
Epoch 1006 of 2000 took 0.035s
  training loss:		0.016325
  validation loss:		0.343794
  validation accuracy:		93.26 %
Epoch 1007 of 2000 took 0.035s
  training loss:		0.015689
  validation loss:		0.332020
  validation accuracy:		93.26 %
Epoch 1008 of 2000 took 0.035s
  training loss:		0.016196
  validation loss:		0.338822
  validation accuracy:		93.26 %
Epoch 1009 of 2000 took 0.036s
  training loss:		0.015975
  validation loss:		0.338017
  validation accuracy:		93.59 %
Epoch 1010 of 2000 took 0.035s
  training loss:		0.015806
  validation loss:		0.341806
  validation accuracy:		93.15 %
Epoch 1011 of 2000 took 0.035s
  training loss:		0.015927
  validation loss:		0.346364
  validation accuracy:		93.15 %
Epoch 1012 of 2000 took 0.035s
  training loss:		0.015896
  validation loss:		0.339702
  validation accuracy:		93.48 %
Epoch 1013 of 2000 took 0.035s
  training loss:		0.016455
  validation loss:		0.339760
  validation accuracy:		93.37 %
Epoch 1014 of 2000 took 0.035s
  training loss:		0.015940
  validation loss:		0.336561
  validation accuracy:		93.26 %
Epoch 1015 of 2000 took 0.035s
  training loss:		0.015287
  validation loss:		0.337708
  validation accuracy:		93.37 %
Epoch 1016 of 2000 took 0.035s
  training loss:		0.015527
  validation loss:		0.338432
  validation accuracy:		93.48 %
Epoch 1017 of 2000 took 0.035s
  training loss:		0.015508
  validation loss:		0.338266
  validation accuracy:		93.26 %
Epoch 1018 of 2000 took 0.035s
  training loss:		0.015480
  validation loss:		0.344736
  validation accuracy:		93.04 %
Epoch 1019 of 2000 took 0.035s
  training loss:		0.015350
  validation loss:		0.346685
  validation accuracy:		93.04 %
Epoch 1020 of 2000 took 0.035s
  training loss:		0.015872
  validation loss:		0.335186
  validation accuracy:		93.59 %
Epoch 1021 of 2000 took 0.035s
  training loss:		0.015937
  validation loss:		0.341715
  validation accuracy:		93.26 %
Epoch 1022 of 2000 took 0.035s
  training loss:		0.015691
  validation loss:		0.344928
  validation accuracy:		93.26 %
Epoch 1023 of 2000 took 0.035s
  training loss:		0.015318
  validation loss:		0.343246
  validation accuracy:		93.37 %
Epoch 1024 of 2000 took 0.035s
  training loss:		0.015410
  validation loss:		0.340329
  validation accuracy:		93.59 %
Epoch 1025 of 2000 took 0.035s
  training loss:		0.014520
  validation loss:		0.344113
  validation accuracy:		93.26 %
Epoch 1026 of 2000 took 0.035s
  training loss:		0.015402
  validation loss:		0.344307
  validation accuracy:		93.37 %
Epoch 1027 of 2000 took 0.035s
  training loss:		0.015536
  validation loss:		0.341445
  validation accuracy:		93.26 %
Epoch 1028 of 2000 took 0.035s
  training loss:		0.014994
  validation loss:		0.351931
  validation accuracy:		93.15 %
Epoch 1029 of 2000 took 0.035s
  training loss:		0.015057
  validation loss:		0.342261
  validation accuracy:		93.37 %
Epoch 1030 of 2000 took 0.035s
  training loss:		0.014457
  validation loss:		0.339440
  validation accuracy:		93.26 %
Epoch 1031 of 2000 took 0.035s
  training loss:		0.015465
  validation loss:		0.349781
  validation accuracy:		93.15 %
Epoch 1032 of 2000 took 0.035s
  training loss:		0.015309
  validation loss:		0.340547
  validation accuracy:		93.48 %
Epoch 1033 of 2000 took 0.035s
  training loss:		0.014940
  validation loss:		0.341709
  validation accuracy:		93.37 %
Epoch 1034 of 2000 took 0.035s
  training loss:		0.015161
  validation loss:		0.342665
  validation accuracy:		93.37 %
Epoch 1035 of 2000 took 0.035s
  training loss:		0.014927
  validation loss:		0.347608
  validation accuracy:		93.26 %
Epoch 1036 of 2000 took 0.035s
  training loss:		0.014612
  validation loss:		0.351203
  validation accuracy:		93.04 %
Epoch 1037 of 2000 took 0.035s
  training loss:		0.015162
  validation loss:		0.344931
  validation accuracy:		93.37 %
Epoch 1038 of 2000 took 0.035s
  training loss:		0.014994
  validation loss:		0.342166
  validation accuracy:		93.37 %
Epoch 1039 of 2000 took 0.035s
  training loss:		0.014486
  validation loss:		0.346212
  validation accuracy:		93.37 %
Epoch 1040 of 2000 took 0.035s
  training loss:		0.015104
  validation loss:		0.339609
  validation accuracy:		93.37 %
Epoch 1041 of 2000 took 0.035s
  training loss:		0.015119
  validation loss:		0.348672
  validation accuracy:		93.15 %
Epoch 1042 of 2000 took 0.035s
  training loss:		0.014886
  validation loss:		0.341840
  validation accuracy:		93.26 %
Epoch 1043 of 2000 took 0.035s
  training loss:		0.014996
  validation loss:		0.340287
  validation accuracy:		93.37 %
Epoch 1044 of 2000 took 0.035s
  training loss:		0.014957
  validation loss:		0.349205
  validation accuracy:		93.37 %
Epoch 1045 of 2000 took 0.035s
  training loss:		0.014693
  validation loss:		0.348751
  validation accuracy:		93.37 %
Epoch 1046 of 2000 took 0.035s
  training loss:		0.014238
  validation loss:		0.349523
  validation accuracy:		93.37 %
Epoch 1047 of 2000 took 0.035s
  training loss:		0.014576
  validation loss:		0.346818
  validation accuracy:		93.26 %
Epoch 1048 of 2000 took 0.035s
  training loss:		0.014531
  validation loss:		0.344258
  validation accuracy:		93.48 %
Epoch 1049 of 2000 took 0.035s
  training loss:		0.014285
  validation loss:		0.352769
  validation accuracy:		93.37 %
Epoch 1050 of 2000 took 0.035s
  training loss:		0.014683
  validation loss:		0.340131
  validation accuracy:		93.26 %
Epoch 1051 of 2000 took 0.035s
  training loss:		0.013986
  validation loss:		0.343807
  validation accuracy:		93.37 %
Epoch 1052 of 2000 took 0.035s
  training loss:		0.014656
  validation loss:		0.346024
  validation accuracy:		93.37 %
Epoch 1053 of 2000 took 0.035s
  training loss:		0.014513
  validation loss:		0.341670
  validation accuracy:		93.48 %
Epoch 1054 of 2000 took 0.035s
  training loss:		0.014092
  validation loss:		0.347408
  validation accuracy:		93.37 %
Epoch 1055 of 2000 took 0.035s
  training loss:		0.014346
  validation loss:		0.350986
  validation accuracy:		93.48 %
Epoch 1056 of 2000 took 0.035s
  training loss:		0.014271
  validation loss:		0.350773
  validation accuracy:		93.26 %
Epoch 1057 of 2000 took 0.035s
  training loss:		0.013717
  validation loss:		0.351853
  validation accuracy:		93.37 %
Epoch 1058 of 2000 took 0.035s
  training loss:		0.014355
  validation loss:		0.360533
  validation accuracy:		93.15 %
Epoch 1059 of 2000 took 0.035s
  training loss:		0.014652
  validation loss:		0.352744
  validation accuracy:		93.37 %
Epoch 1060 of 2000 took 0.035s
  training loss:		0.014100
  validation loss:		0.352692
  validation accuracy:		93.37 %
Epoch 1061 of 2000 took 0.035s
  training loss:		0.014180
  validation loss:		0.345110
  validation accuracy:		93.48 %
Epoch 1062 of 2000 took 0.035s
  training loss:		0.014217
  validation loss:		0.354890
  validation accuracy:		93.04 %
Epoch 1063 of 2000 took 0.035s
  training loss:		0.013657
  validation loss:		0.346160
  validation accuracy:		93.59 %
Epoch 1064 of 2000 took 0.035s
  training loss:		0.014043
  validation loss:		0.345412
  validation accuracy:		93.37 %
Epoch 1065 of 2000 took 0.035s
  training loss:		0.014576
  validation loss:		0.342272
  validation accuracy:		93.37 %
Epoch 1066 of 2000 took 0.035s
  training loss:		0.014132
  validation loss:		0.345387
  validation accuracy:		93.37 %
Epoch 1067 of 2000 took 0.035s
  training loss:		0.013823
  validation loss:		0.347807
  validation accuracy:		93.37 %
Epoch 1068 of 2000 took 0.035s
  training loss:		0.013717
  validation loss:		0.348123
  validation accuracy:		93.26 %
Epoch 1069 of 2000 took 0.035s
  training loss:		0.013999
  validation loss:		0.352066
  validation accuracy:		93.37 %
Epoch 1070 of 2000 took 0.035s
  training loss:		0.013660
  validation loss:		0.361953
  validation accuracy:		93.15 %
Epoch 1071 of 2000 took 0.035s
  training loss:		0.013722
  validation loss:		0.349651
  validation accuracy:		93.26 %
Epoch 1072 of 2000 took 0.035s
  training loss:		0.013478
  validation loss:		0.354310
  validation accuracy:		93.37 %
Epoch 1073 of 2000 took 0.035s
  training loss:		0.013546
  validation loss:		0.352724
  validation accuracy:		93.48 %
Epoch 1074 of 2000 took 0.035s
  training loss:		0.013612
  validation loss:		0.354603
  validation accuracy:		93.48 %
Epoch 1075 of 2000 took 0.035s
  training loss:		0.013488
  validation loss:		0.350580
  validation accuracy:		93.48 %
Epoch 1076 of 2000 took 0.035s
  training loss:		0.013509
  validation loss:		0.356809
  validation accuracy:		93.37 %
Epoch 1077 of 2000 took 0.035s
  training loss:		0.013144
  validation loss:		0.354412
  validation accuracy:		93.37 %
Epoch 1078 of 2000 took 0.035s
  training loss:		0.013424
  validation loss:		0.349745
  validation accuracy:		93.37 %
Epoch 1079 of 2000 took 0.035s
  training loss:		0.013772
  validation loss:		0.351846
  validation accuracy:		93.37 %
Epoch 1080 of 2000 took 0.035s
  training loss:		0.013264
  validation loss:		0.349983
  validation accuracy:		93.26 %
Epoch 1081 of 2000 took 0.035s
  training loss:		0.013253
  validation loss:		0.344232
  validation accuracy:		93.37 %
Epoch 1082 of 2000 took 0.035s
  training loss:		0.013172
  validation loss:		0.359481
  validation accuracy:		93.26 %
Epoch 1083 of 2000 took 0.035s
  training loss:		0.013115
  validation loss:		0.359261
  validation accuracy:		93.37 %
Epoch 1084 of 2000 took 0.035s
  training loss:		0.013362
  validation loss:		0.351880
  validation accuracy:		93.37 %
Epoch 1085 of 2000 took 0.035s
  training loss:		0.012989
  validation loss:		0.354730
  validation accuracy:		93.26 %
Epoch 1086 of 2000 took 0.035s
  training loss:		0.013911
  validation loss:		0.348158
  validation accuracy:		93.59 %
Epoch 1087 of 2000 took 0.035s
  training loss:		0.013133
  validation loss:		0.355347
  validation accuracy:		93.26 %
Epoch 1088 of 2000 took 0.035s
  training loss:		0.013275
  validation loss:		0.362452
  validation accuracy:		93.26 %
Epoch 1089 of 2000 took 0.035s
  training loss:		0.013330
  validation loss:		0.352472
  validation accuracy:		93.37 %
Epoch 1090 of 2000 took 0.035s
  training loss:		0.013053
  validation loss:		0.350554
  validation accuracy:		93.37 %
Epoch 1091 of 2000 took 0.035s
  training loss:		0.012948
  validation loss:		0.358307
  validation accuracy:		93.26 %
Epoch 1092 of 2000 took 0.035s
  training loss:		0.013036
  validation loss:		0.354865
  validation accuracy:		93.37 %
Epoch 1093 of 2000 took 0.035s
  training loss:		0.013274
  validation loss:		0.348527
  validation accuracy:		93.37 %
Epoch 1094 of 2000 took 0.035s
  training loss:		0.013151
  validation loss:		0.350145
  validation accuracy:		93.48 %
Epoch 1095 of 2000 took 0.035s
  training loss:		0.013126
  validation loss:		0.358686
  validation accuracy:		93.37 %
Epoch 1096 of 2000 took 0.035s
  training loss:		0.012958
  validation loss:		0.355673
  validation accuracy:		93.37 %
Epoch 1097 of 2000 took 0.035s
  training loss:		0.012879
  validation loss:		0.352305
  validation accuracy:		93.37 %
Epoch 1098 of 2000 took 0.035s
  training loss:		0.012755
  validation loss:		0.357760
  validation accuracy:		93.26 %
Epoch 1099 of 2000 took 0.035s
  training loss:		0.012491
  validation loss:		0.362951
  validation accuracy:		93.15 %
Epoch 1100 of 2000 took 0.035s
  training loss:		0.013035
  validation loss:		0.357817
  validation accuracy:		93.37 %
Epoch 1101 of 2000 took 0.035s
  training loss:		0.012077
  validation loss:		0.350973
  validation accuracy:		93.37 %
Epoch 1102 of 2000 took 0.035s
  training loss:		0.013038
  validation loss:		0.352265
  validation accuracy:		93.37 %
Epoch 1103 of 2000 took 0.035s
  training loss:		0.013067
  validation loss:		0.355923
  validation accuracy:		93.48 %
Epoch 1104 of 2000 took 0.035s
  training loss:		0.012666
  validation loss:		0.359962
  validation accuracy:		93.26 %
Epoch 1105 of 2000 took 0.035s
  training loss:		0.012600
  validation loss:		0.362092
  validation accuracy:		93.37 %
Epoch 1106 of 2000 took 0.035s
  training loss:		0.012836
  validation loss:		0.360232
  validation accuracy:		93.37 %
Epoch 1107 of 2000 took 0.035s
  training loss:		0.012693
  validation loss:		0.352986
  validation accuracy:		93.37 %
Epoch 1108 of 2000 took 0.035s
  training loss:		0.012656
  validation loss:		0.365997
  validation accuracy:		93.37 %
Epoch 1109 of 2000 took 0.035s
  training loss:		0.012445
  validation loss:		0.361891
  validation accuracy:		93.37 %
Epoch 1110 of 2000 took 0.035s
  training loss:		0.012466
  validation loss:		0.357154
  validation accuracy:		93.37 %
Epoch 1111 of 2000 took 0.035s
  training loss:		0.012170
  validation loss:		0.362706
  validation accuracy:		93.26 %
Epoch 1112 of 2000 took 0.035s
  training loss:		0.012387
  validation loss:		0.356920
  validation accuracy:		93.48 %
Epoch 1113 of 2000 took 0.035s
  training loss:		0.012434
  validation loss:		0.356631
  validation accuracy:		93.26 %
Epoch 1114 of 2000 took 0.035s
  training loss:		0.012354
  validation loss:		0.360300
  validation accuracy:		93.48 %
Epoch 1115 of 2000 took 0.035s
  training loss:		0.012352
  validation loss:		0.357773
  validation accuracy:		93.37 %
Epoch 1116 of 2000 took 0.035s
  training loss:		0.012098
  validation loss:		0.365105
  validation accuracy:		93.26 %
Epoch 1117 of 2000 took 0.035s
  training loss:		0.012462
  validation loss:		0.365402
  validation accuracy:		93.37 %
Epoch 1118 of 2000 took 0.035s
  training loss:		0.012581
  validation loss:		0.358286
  validation accuracy:		93.37 %
Epoch 1119 of 2000 took 0.035s
  training loss:		0.011994
  validation loss:		0.364237
  validation accuracy:		93.37 %
Epoch 1120 of 2000 took 0.035s
  training loss:		0.012435
  validation loss:		0.362283
  validation accuracy:		93.48 %
Epoch 1121 of 2000 took 0.035s
  training loss:		0.011945
  validation loss:		0.365434
  validation accuracy:		93.26 %
Epoch 1122 of 2000 took 0.035s
  training loss:		0.012531
  validation loss:		0.361152
  validation accuracy:		93.37 %
Epoch 1123 of 2000 took 0.035s
  training loss:		0.012685
  validation loss:		0.358757
  validation accuracy:		93.37 %
Epoch 1124 of 2000 took 0.035s
  training loss:		0.012273
  validation loss:		0.360452
  validation accuracy:		93.59 %
Epoch 1125 of 2000 took 0.035s
  training loss:		0.011994
  validation loss:		0.364518
  validation accuracy:		93.48 %
Epoch 1126 of 2000 took 0.035s
  training loss:		0.012030
  validation loss:		0.358484
  validation accuracy:		93.37 %
Epoch 1127 of 2000 took 0.035s
  training loss:		0.011646
  validation loss:		0.365546
  validation accuracy:		93.37 %
Epoch 1128 of 2000 took 0.035s
  training loss:		0.011763
  validation loss:		0.363186
  validation accuracy:		93.37 %
Epoch 1129 of 2000 took 0.035s
  training loss:		0.012167
  validation loss:		0.365071
  validation accuracy:		93.15 %
Epoch 1130 of 2000 took 0.035s
  training loss:		0.012010
  validation loss:		0.359420
  validation accuracy:		93.37 %
Epoch 1131 of 2000 took 0.035s
  training loss:		0.011886
  validation loss:		0.364100
  validation accuracy:		93.37 %
Epoch 1132 of 2000 took 0.035s
  training loss:		0.011949
  validation loss:		0.363105
  validation accuracy:		93.37 %
Epoch 1133 of 2000 took 0.035s
  training loss:		0.011966
  validation loss:		0.361797
  validation accuracy:		93.26 %
Epoch 1134 of 2000 took 0.035s
  training loss:		0.011870
  validation loss:		0.364220
  validation accuracy:		93.37 %
Epoch 1135 of 2000 took 0.035s
  training loss:		0.011644
  validation loss:		0.360209
  validation accuracy:		93.37 %
Epoch 1136 of 2000 took 0.035s
  training loss:		0.011751
  validation loss:		0.366999
  validation accuracy:		93.37 %
Epoch 1137 of 2000 took 0.035s
  training loss:		0.011782
  validation loss:		0.366599
  validation accuracy:		93.37 %
Epoch 1138 of 2000 took 0.035s
  training loss:		0.012151
  validation loss:		0.363402
  validation accuracy:		93.48 %
Epoch 1139 of 2000 took 0.035s
  training loss:		0.011674
  validation loss:		0.364361
  validation accuracy:		93.26 %
Epoch 1140 of 2000 took 0.035s
  training loss:		0.011632
  validation loss:		0.365496
  validation accuracy:		93.37 %
Epoch 1141 of 2000 took 0.035s
  training loss:		0.011812
  validation loss:		0.362987
  validation accuracy:		93.37 %
Epoch 1142 of 2000 took 0.035s
  training loss:		0.011412
  validation loss:		0.369390
  validation accuracy:		93.15 %
Epoch 1143 of 2000 took 0.035s
  training loss:		0.012082
  validation loss:		0.373509
  validation accuracy:		93.37 %
Epoch 1144 of 2000 took 0.035s
  training loss:		0.011670
  validation loss:		0.368930
  validation accuracy:		93.37 %
Epoch 1145 of 2000 took 0.035s
  training loss:		0.011924
  validation loss:		0.365422
  validation accuracy:		93.37 %
Epoch 1146 of 2000 took 0.035s
  training loss:		0.011119
  validation loss:		0.359299
  validation accuracy:		93.37 %
Epoch 1147 of 2000 took 0.035s
  training loss:		0.011415
  validation loss:		0.367155
  validation accuracy:		93.48 %
Epoch 1148 of 2000 took 0.035s
  training loss:		0.011189
  validation loss:		0.371276
  validation accuracy:		93.37 %
Epoch 1149 of 2000 took 0.035s
  training loss:		0.011365
  validation loss:		0.370480
  validation accuracy:		93.37 %
Epoch 1150 of 2000 took 0.035s
  training loss:		0.011240
  validation loss:		0.368920
  validation accuracy:		93.48 %
Epoch 1151 of 2000 took 0.035s
  training loss:		0.011271
  validation loss:		0.373665
  validation accuracy:		93.15 %
Epoch 1152 of 2000 took 0.035s
  training loss:		0.011082
  validation loss:		0.370768
  validation accuracy:		93.37 %
Epoch 1153 of 2000 took 0.035s
  training loss:		0.011348
  validation loss:		0.366358
  validation accuracy:		93.26 %
Epoch 1154 of 2000 took 0.035s
  training loss:		0.011034
  validation loss:		0.370139
  validation accuracy:		93.48 %
Epoch 1155 of 2000 took 0.035s
  training loss:		0.011323
  validation loss:		0.365996
  validation accuracy:		93.37 %
Epoch 1156 of 2000 took 0.035s
  training loss:		0.011471
  validation loss:		0.371396
  validation accuracy:		93.26 %
Epoch 1157 of 2000 took 0.035s
  training loss:		0.011663
  validation loss:		0.370114
  validation accuracy:		93.59 %
Epoch 1158 of 2000 took 0.035s
  training loss:		0.011543
  validation loss:		0.370980
  validation accuracy:		93.37 %
Epoch 1159 of 2000 took 0.035s
  training loss:		0.011143
  validation loss:		0.370086
  validation accuracy:		93.59 %
Epoch 1160 of 2000 took 0.035s
  training loss:		0.011086
  validation loss:		0.367202
  validation accuracy:		93.48 %
Epoch 1161 of 2000 took 0.035s
  training loss:		0.011330
  validation loss:		0.371617
  validation accuracy:		93.37 %
Epoch 1162 of 2000 took 0.035s
  training loss:		0.010909
  validation loss:		0.368808
  validation accuracy:		93.37 %
Epoch 1163 of 2000 took 0.035s
  training loss:		0.011265
  validation loss:		0.372714
  validation accuracy:		93.37 %
Epoch 1164 of 2000 took 0.035s
  training loss:		0.010872
  validation loss:		0.373024
  validation accuracy:		93.48 %
Epoch 1165 of 2000 took 0.035s
  training loss:		0.011002
  validation loss:		0.378611
  validation accuracy:		93.37 %
Epoch 1166 of 2000 took 0.035s
  training loss:		0.010693
  validation loss:		0.366495
  validation accuracy:		93.37 %
Epoch 1167 of 2000 took 0.035s
  training loss:		0.010671
  validation loss:		0.367465
  validation accuracy:		93.48 %
Epoch 1168 of 2000 took 0.035s
  training loss:		0.011051
  validation loss:		0.373269
  validation accuracy:		93.26 %
Epoch 1169 of 2000 took 0.035s
  training loss:		0.010867
  validation loss:		0.365824
  validation accuracy:		93.48 %
Epoch 1170 of 2000 took 0.035s
  training loss:		0.010951
  validation loss:		0.372046
  validation accuracy:		93.59 %
Epoch 1171 of 2000 took 0.035s
  training loss:		0.010996
  validation loss:		0.373039
  validation accuracy:		93.48 %
Epoch 1172 of 2000 took 0.035s
  training loss:		0.011260
  validation loss:		0.375934
  validation accuracy:		93.48 %
Epoch 1173 of 2000 took 0.035s
  training loss:		0.010848
  validation loss:		0.372147
  validation accuracy:		93.48 %
Epoch 1174 of 2000 took 0.035s
  training loss:		0.010413
  validation loss:		0.367728
  validation accuracy:		93.37 %
Epoch 1175 of 2000 took 0.035s
  training loss:		0.010935
  validation loss:		0.377470
  validation accuracy:		93.37 %
Epoch 1176 of 2000 took 0.035s
  training loss:		0.011389
  validation loss:		0.374239
  validation accuracy:		93.37 %
Epoch 1177 of 2000 took 0.035s
  training loss:		0.010735
  validation loss:		0.370476
  validation accuracy:		93.48 %
Epoch 1178 of 2000 took 0.035s
  training loss:		0.010855
  validation loss:		0.372525
  validation accuracy:		93.37 %
Epoch 1179 of 2000 took 0.035s
  training loss:		0.010476
  validation loss:		0.376267
  validation accuracy:		93.37 %
Epoch 1180 of 2000 took 0.035s
  training loss:		0.010726
  validation loss:		0.367220
  validation accuracy:		93.37 %
Epoch 1181 of 2000 took 0.035s
  training loss:		0.010711
  validation loss:		0.368832
  validation accuracy:		93.26 %
Epoch 1182 of 2000 took 0.035s
  training loss:		0.010223
  validation loss:		0.371918
  validation accuracy:		93.37 %
Epoch 1183 of 2000 took 0.035s
  training loss:		0.010931
  validation loss:		0.376378
  validation accuracy:		93.37 %
Epoch 1184 of 2000 took 0.035s
  training loss:		0.010377
  validation loss:		0.374077
  validation accuracy:		93.37 %
Epoch 1185 of 2000 took 0.035s
  training loss:		0.010320
  validation loss:		0.372434
  validation accuracy:		93.48 %
Epoch 1186 of 2000 took 0.035s
  training loss:		0.010402
  validation loss:		0.381018
  validation accuracy:		93.15 %
Epoch 1187 of 2000 took 0.035s
  training loss:		0.010525
  validation loss:		0.378259
  validation accuracy:		93.37 %
Epoch 1188 of 2000 took 0.035s
  training loss:		0.010351
  validation loss:		0.377888
  validation accuracy:		93.37 %
Epoch 1189 of 2000 took 0.035s
  training loss:		0.010955
  validation loss:		0.371054
  validation accuracy:		93.37 %
Epoch 1190 of 2000 took 0.035s
  training loss:		0.010698
  validation loss:		0.371512
  validation accuracy:		93.48 %
Epoch 1191 of 2000 took 0.035s
  training loss:		0.010527
  validation loss:		0.379940
  validation accuracy:		93.48 %
Epoch 1192 of 2000 took 0.035s
  training loss:		0.010408
  validation loss:		0.372354
  validation accuracy:		93.37 %
Epoch 1193 of 2000 took 0.035s
  training loss:		0.010327
  validation loss:		0.377651
  validation accuracy:		93.48 %
Epoch 1194 of 2000 took 0.035s
  training loss:		0.010794
  validation loss:		0.373930
  validation accuracy:		93.59 %
Epoch 1195 of 2000 took 0.035s
  training loss:		0.010252
  validation loss:		0.372454
  validation accuracy:		93.26 %
Epoch 1196 of 2000 took 0.035s
  training loss:		0.010623
  validation loss:		0.378026
  validation accuracy:		93.26 %
Epoch 1197 of 2000 took 0.035s
  training loss:		0.010912
  validation loss:		0.380239
  validation accuracy:		93.26 %
Epoch 1198 of 2000 took 0.035s
  training loss:		0.010802
  validation loss:		0.385425
  validation accuracy:		93.15 %
Epoch 1199 of 2000 took 0.035s
  training loss:		0.010557
  validation loss:		0.374702
  validation accuracy:		93.37 %
Epoch 1200 of 2000 took 0.035s
  training loss:		0.010422
  validation loss:		0.378795
  validation accuracy:		93.26 %
Epoch 1201 of 2000 took 0.035s
  training loss:		0.010142
  validation loss:		0.385953
  validation accuracy:		93.37 %
Epoch 1202 of 2000 took 0.035s
  training loss:		0.010443
  validation loss:		0.377509
  validation accuracy:		93.59 %
Epoch 1203 of 2000 took 0.035s
  training loss:		0.009951
  validation loss:		0.374112
  validation accuracy:		93.37 %
Epoch 1204 of 2000 took 0.035s
  training loss:		0.009908
  validation loss:		0.382326
  validation accuracy:		93.48 %
Epoch 1205 of 2000 took 0.035s
  training loss:		0.010264
  validation loss:		0.383456
  validation accuracy:		93.26 %
Epoch 1206 of 2000 took 0.035s
  training loss:		0.010138
  validation loss:		0.383407
  validation accuracy:		93.15 %
Epoch 1207 of 2000 took 0.035s
  training loss:		0.010158
  validation loss:		0.385323
  validation accuracy:		93.26 %
Epoch 1208 of 2000 took 0.035s
  training loss:		0.010146
  validation loss:		0.376761
  validation accuracy:		93.37 %
Epoch 1209 of 2000 took 0.035s
  training loss:		0.010242
  validation loss:		0.381723
  validation accuracy:		93.48 %
Epoch 1210 of 2000 took 0.035s
  training loss:		0.009973
  validation loss:		0.379283
  validation accuracy:		93.37 %
Epoch 1211 of 2000 took 0.035s
  training loss:		0.010219
  validation loss:		0.376486
  validation accuracy:		93.59 %
Epoch 1212 of 2000 took 0.035s
  training loss:		0.009804
  validation loss:		0.390116
  validation accuracy:		93.15 %
Epoch 1213 of 2000 took 0.035s
  training loss:		0.009999
  validation loss:		0.377587
  validation accuracy:		93.48 %
Epoch 1214 of 2000 took 0.035s
  training loss:		0.009875
  validation loss:		0.383487
  validation accuracy:		93.37 %
Epoch 1215 of 2000 took 0.035s
  training loss:		0.009674
  validation loss:		0.387590
  validation accuracy:		93.26 %
Epoch 1216 of 2000 took 0.035s
  training loss:		0.010065
  validation loss:		0.380269
  validation accuracy:		93.37 %
Epoch 1217 of 2000 took 0.035s
  training loss:		0.009393
  validation loss:		0.384252
  validation accuracy:		93.37 %
Epoch 1218 of 2000 took 0.035s
  training loss:		0.010062
  validation loss:		0.383149
  validation accuracy:		93.48 %
Epoch 1219 of 2000 took 0.035s
  training loss:		0.009853
  validation loss:		0.380115
  validation accuracy:		93.48 %
Epoch 1220 of 2000 took 0.035s
  training loss:		0.009810
  validation loss:		0.389803
  validation accuracy:		93.15 %
Epoch 1221 of 2000 took 0.035s
  training loss:		0.009737
  validation loss:		0.391929
  validation accuracy:		93.04 %
Epoch 1222 of 2000 took 0.035s
  training loss:		0.010202
  validation loss:		0.377939
  validation accuracy:		93.48 %
Epoch 1223 of 2000 took 0.035s
  training loss:		0.010097
  validation loss:		0.381022
  validation accuracy:		93.59 %
Epoch 1224 of 2000 took 0.035s
  training loss:		0.009829
  validation loss:		0.383203
  validation accuracy:		93.37 %
Epoch 1225 of 2000 took 0.035s
  training loss:		0.009971
  validation loss:		0.386695
  validation accuracy:		93.37 %
Epoch 1226 of 2000 took 0.035s
  training loss:		0.009878
  validation loss:		0.380091
  validation accuracy:		93.59 %
Epoch 1227 of 2000 took 0.035s
  training loss:		0.010005
  validation loss:		0.386762
  validation accuracy:		93.26 %
Epoch 1228 of 2000 took 0.035s
  training loss:		0.009848
  validation loss:		0.379249
  validation accuracy:		93.48 %
Epoch 1229 of 2000 took 0.035s
  training loss:		0.009352
  validation loss:		0.386515
  validation accuracy:		93.37 %
Epoch 1230 of 2000 took 0.035s
  training loss:		0.009685
  validation loss:		0.390123
  validation accuracy:		93.26 %
Epoch 1231 of 2000 took 0.035s
  training loss:		0.009671
  validation loss:		0.382681
  validation accuracy:		93.37 %
Epoch 1232 of 2000 took 0.035s
  training loss:		0.009494
  validation loss:		0.386854
  validation accuracy:		93.59 %
Epoch 1233 of 2000 took 0.035s
  training loss:		0.009567
  validation loss:		0.386520
  validation accuracy:		93.59 %
Epoch 1234 of 2000 took 0.035s
  training loss:		0.009543
  validation loss:		0.378897
  validation accuracy:		93.48 %
Epoch 1235 of 2000 took 0.035s
  training loss:		0.009728
  validation loss:		0.383437
  validation accuracy:		93.37 %
Epoch 1236 of 2000 took 0.035s
  training loss:		0.009705
  validation loss:		0.395128
  validation accuracy:		93.37 %
Epoch 1237 of 2000 took 0.035s
  training loss:		0.009694
  validation loss:		0.383285
  validation accuracy:		93.48 %
Epoch 1238 of 2000 took 0.035s
  training loss:		0.009564
  validation loss:		0.386751
  validation accuracy:		93.37 %
Epoch 1239 of 2000 took 0.035s
  training loss:		0.009320
  validation loss:		0.384290
  validation accuracy:		93.37 %
Epoch 1240 of 2000 took 0.035s
  training loss:		0.009715
  validation loss:		0.387756
  validation accuracy:		93.37 %
Epoch 1241 of 2000 took 0.035s
  training loss:		0.009172
  validation loss:		0.377921
  validation accuracy:		93.48 %
Epoch 1242 of 2000 took 0.035s
  training loss:		0.009683
  validation loss:		0.379366
  validation accuracy:		93.48 %
Epoch 1243 of 2000 took 0.035s
  training loss:		0.009651
  validation loss:		0.383174
  validation accuracy:		93.37 %
Epoch 1244 of 2000 took 0.035s
  training loss:		0.009467
  validation loss:		0.386654
  validation accuracy:		93.70 %
Epoch 1245 of 2000 took 0.035s
  training loss:		0.009356
  validation loss:		0.386624
  validation accuracy:		93.48 %
Epoch 1246 of 2000 took 0.035s
  training loss:		0.009407
  validation loss:		0.386258
  validation accuracy:		93.26 %
Epoch 1247 of 2000 took 0.035s
  training loss:		0.009807
  validation loss:		0.384784
  validation accuracy:		93.48 %
Epoch 1248 of 2000 took 0.035s
  training loss:		0.009294
  validation loss:		0.386365
  validation accuracy:		93.70 %
Epoch 1249 of 2000 took 0.035s
  training loss:		0.009410
  validation loss:		0.395497
  validation accuracy:		93.15 %
Epoch 1250 of 2000 took 0.035s
  training loss:		0.009204
  validation loss:		0.386159
  validation accuracy:		93.37 %
Epoch 1251 of 2000 took 0.035s
  training loss:		0.009187
  validation loss:		0.392414
  validation accuracy:		93.37 %
Epoch 1252 of 2000 took 0.035s
  training loss:		0.009432
  validation loss:		0.386578
  validation accuracy:		93.37 %
Epoch 1253 of 2000 took 0.035s
  training loss:		0.009119
  validation loss:		0.390077
  validation accuracy:		93.48 %
Epoch 1254 of 2000 took 0.035s
  training loss:		0.009266
  validation loss:		0.386593
  validation accuracy:		93.26 %
Epoch 1255 of 2000 took 0.035s
  training loss:		0.009346
  validation loss:		0.391054
  validation accuracy:		93.37 %
Epoch 1256 of 2000 took 0.035s
  training loss:		0.008984
  validation loss:		0.394464
  validation accuracy:		93.26 %
Epoch 1257 of 2000 took 0.035s
  training loss:		0.009106
  validation loss:		0.389792
  validation accuracy:		93.37 %
Epoch 1258 of 2000 took 0.035s
  training loss:		0.009288
  validation loss:		0.391897
  validation accuracy:		93.59 %
Epoch 1259 of 2000 took 0.035s
  training loss:		0.009175
  validation loss:		0.388578
  validation accuracy:		93.37 %
Epoch 1260 of 2000 took 0.035s
  training loss:		0.009035
  validation loss:		0.397498
  validation accuracy:		93.37 %
Epoch 1261 of 2000 took 0.035s
  training loss:		0.009378
  validation loss:		0.392004
  validation accuracy:		93.48 %
Epoch 1262 of 2000 took 0.035s
  training loss:		0.009244
  validation loss:		0.389413
  validation accuracy:		93.48 %
Epoch 1263 of 2000 took 0.035s
  training loss:		0.008888
  validation loss:		0.394399
  validation accuracy:		93.37 %
Epoch 1264 of 2000 took 0.035s
  training loss:		0.008850
  validation loss:		0.384025
  validation accuracy:		93.48 %
Epoch 1265 of 2000 took 0.035s
  training loss:		0.008997
  validation loss:		0.392035
  validation accuracy:		93.48 %
Epoch 1266 of 2000 took 0.035s
  training loss:		0.009298
  validation loss:		0.393772
  validation accuracy:		93.37 %
Epoch 1267 of 2000 took 0.035s
  training loss:		0.009179
  validation loss:		0.397169
  validation accuracy:		93.37 %
Epoch 1268 of 2000 took 0.035s
  training loss:		0.008928
  validation loss:		0.384430
  validation accuracy:		93.48 %
Epoch 1269 of 2000 took 0.035s
  training loss:		0.009127
  validation loss:		0.395422
  validation accuracy:		93.59 %
Epoch 1270 of 2000 took 0.035s
  training loss:		0.009002
  validation loss:		0.387863
  validation accuracy:		93.48 %
Epoch 1271 of 2000 took 0.035s
  training loss:		0.008777
  validation loss:		0.396241
  validation accuracy:		93.59 %
Epoch 1272 of 2000 took 0.035s
  training loss:		0.008535
  validation loss:		0.386502
  validation accuracy:		93.37 %
Epoch 1273 of 2000 took 0.035s
  training loss:		0.008816
  validation loss:		0.398041
  validation accuracy:		93.37 %
Epoch 1274 of 2000 took 0.035s
  training loss:		0.008539
  validation loss:		0.389619
  validation accuracy:		93.37 %
Epoch 1275 of 2000 took 0.035s
  training loss:		0.008682
  validation loss:		0.389650
  validation accuracy:		93.48 %
Epoch 1276 of 2000 took 0.035s
  training loss:		0.008826
  validation loss:		0.391468
  validation accuracy:		93.48 %
Epoch 1277 of 2000 took 0.035s
  training loss:		0.009092
  validation loss:		0.393796
  validation accuracy:		93.48 %
Epoch 1278 of 2000 took 0.035s
  training loss:		0.008854
  validation loss:		0.395148
  validation accuracy:		93.48 %
Epoch 1279 of 2000 took 0.035s
  training loss:		0.008478
  validation loss:		0.393358
  validation accuracy:		93.59 %
Epoch 1280 of 2000 took 0.035s
  training loss:		0.008832
  validation loss:		0.393036
  validation accuracy:		93.37 %
Epoch 1281 of 2000 took 0.035s
  training loss:		0.009003
  validation loss:		0.399950
  validation accuracy:		93.37 %
Epoch 1282 of 2000 took 0.035s
  training loss:		0.008733
  validation loss:		0.398640
  validation accuracy:		93.59 %
Epoch 1283 of 2000 took 0.035s
  training loss:		0.009017
  validation loss:		0.391567
  validation accuracy:		93.37 %
Epoch 1284 of 2000 took 0.035s
  training loss:		0.008534
  validation loss:		0.398140
  validation accuracy:		93.37 %
Epoch 1285 of 2000 took 0.035s
  training loss:		0.008712
  validation loss:		0.396912
  validation accuracy:		93.37 %
Epoch 1286 of 2000 took 0.035s
  training loss:		0.008874
  validation loss:		0.397339
  validation accuracy:		93.48 %
Epoch 1287 of 2000 took 0.035s
  training loss:		0.008331
  validation loss:		0.393842
  validation accuracy:		93.48 %
Epoch 1288 of 2000 took 0.035s
  training loss:		0.008416
  validation loss:		0.397312
  validation accuracy:		93.59 %
Epoch 1289 of 2000 took 0.035s
  training loss:		0.008305
  validation loss:		0.396187
  validation accuracy:		93.48 %
Epoch 1290 of 2000 took 0.035s
  training loss:		0.008350
  validation loss:		0.391024
  validation accuracy:		93.48 %
Epoch 1291 of 2000 took 0.035s
  training loss:		0.008364
  validation loss:		0.397944
  validation accuracy:		93.37 %
Epoch 1292 of 2000 took 0.035s
  training loss:		0.008179
  validation loss:		0.399534
  validation accuracy:		93.48 %
Epoch 1293 of 2000 took 0.035s
  training loss:		0.008274
  validation loss:		0.397042
  validation accuracy:		93.59 %
Epoch 1294 of 2000 took 0.035s
  training loss:		0.008517
  validation loss:		0.398652
  validation accuracy:		93.26 %
Epoch 1295 of 2000 took 0.035s
  training loss:		0.008823
  validation loss:		0.397889
  validation accuracy:		93.37 %
Epoch 1296 of 2000 took 0.035s
  training loss:		0.008796
  validation loss:		0.395563
  validation accuracy:		93.48 %
Epoch 1297 of 2000 took 0.035s
  training loss:		0.008440
  validation loss:		0.402321
  validation accuracy:		93.48 %
Epoch 1298 of 2000 took 0.035s
  training loss:		0.008493
  validation loss:		0.401674
  validation accuracy:		93.70 %
Epoch 1299 of 2000 took 0.035s
  training loss:		0.008412
  validation loss:		0.391844
  validation accuracy:		93.37 %
Epoch 1300 of 2000 took 0.035s
  training loss:		0.008603
  validation loss:		0.405664
  validation accuracy:		93.37 %
Epoch 1301 of 2000 took 0.035s
  training loss:		0.008426
  validation loss:		0.392525
  validation accuracy:		93.48 %
Epoch 1302 of 2000 took 0.035s
  training loss:		0.008289
  validation loss:		0.401834
  validation accuracy:		93.48 %
Epoch 1303 of 2000 took 0.035s
  training loss:		0.008350
  validation loss:		0.405124
  validation accuracy:		93.37 %
Epoch 1304 of 2000 took 0.035s
  training loss:		0.008454
  validation loss:		0.397704
  validation accuracy:		93.37 %
Epoch 1305 of 2000 took 0.035s
  training loss:		0.008151
  validation loss:		0.397067
  validation accuracy:		93.48 %
Epoch 1306 of 2000 took 0.035s
  training loss:		0.008233
  validation loss:		0.399328
  validation accuracy:		93.48 %
Epoch 1307 of 2000 took 0.035s
  training loss:		0.008221
  validation loss:		0.399382
  validation accuracy:		93.48 %
Epoch 1308 of 2000 took 0.035s
  training loss:		0.008330
  validation loss:		0.397968
  validation accuracy:		93.48 %
Epoch 1309 of 2000 took 0.035s
  training loss:		0.008360
  validation loss:		0.402890
  validation accuracy:		93.48 %
Epoch 1310 of 2000 took 0.035s
  training loss:		0.007851
  validation loss:		0.400203
  validation accuracy:		93.37 %
Epoch 1311 of 2000 took 0.035s
  training loss:		0.008085
  validation loss:		0.406061
  validation accuracy:		93.37 %
Epoch 1312 of 2000 took 0.035s
  training loss:		0.008059
  validation loss:		0.398194
  validation accuracy:		93.48 %
Epoch 1313 of 2000 took 0.035s
  training loss:		0.008607
  validation loss:		0.406262
  validation accuracy:		93.37 %
Epoch 1314 of 2000 took 0.035s
  training loss:		0.008234
  validation loss:		0.401468
  validation accuracy:		93.37 %
Epoch 1315 of 2000 took 0.035s
  training loss:		0.008236
  validation loss:		0.403808
  validation accuracy:		93.48 %
Epoch 1316 of 2000 took 0.035s
  training loss:		0.008238
  validation loss:		0.400968
  validation accuracy:		93.37 %
Epoch 1317 of 2000 took 0.035s
  training loss:		0.008124
  validation loss:		0.404115
  validation accuracy:		93.59 %
Epoch 1318 of 2000 took 0.035s
  training loss:		0.008190
  validation loss:		0.405097
  validation accuracy:		93.26 %
Epoch 1319 of 2000 took 0.035s
  training loss:		0.007914
  validation loss:		0.402537
  validation accuracy:		93.37 %
Epoch 1320 of 2000 took 0.035s
  training loss:		0.007968
  validation loss:		0.404925
  validation accuracy:		93.37 %
Epoch 1321 of 2000 took 0.035s
  training loss:		0.008235
  validation loss:		0.402118
  validation accuracy:		93.59 %
Epoch 1322 of 2000 took 0.035s
  training loss:		0.008080
  validation loss:		0.402314
  validation accuracy:		93.48 %
Epoch 1323 of 2000 took 0.035s
  training loss:		0.008177
  validation loss:		0.406590
  validation accuracy:		93.37 %
Epoch 1324 of 2000 took 0.035s
  training loss:		0.008113
  validation loss:		0.405874
  validation accuracy:		93.48 %
Epoch 1325 of 2000 took 0.035s
  training loss:		0.008119
  validation loss:		0.401211
  validation accuracy:		93.70 %
Epoch 1326 of 2000 took 0.035s
  training loss:		0.008121
  validation loss:		0.404111
  validation accuracy:		93.70 %
Epoch 1327 of 2000 took 0.035s
  training loss:		0.007787
  validation loss:		0.405154
  validation accuracy:		93.59 %
Epoch 1328 of 2000 took 0.035s
  training loss:		0.008024
  validation loss:		0.405163
  validation accuracy:		93.48 %
Epoch 1329 of 2000 took 0.035s
  training loss:		0.007720
  validation loss:		0.396612
  validation accuracy:		93.59 %
Epoch 1330 of 2000 took 0.035s
  training loss:		0.008122
  validation loss:		0.398683
  validation accuracy:		93.59 %
Epoch 1331 of 2000 took 0.035s
  training loss:		0.008122
  validation loss:		0.402265
  validation accuracy:		93.59 %
Epoch 1332 of 2000 took 0.035s
  training loss:		0.008305
  validation loss:		0.403565
  validation accuracy:		93.59 %
Epoch 1333 of 2000 took 0.035s
  training loss:		0.007755
  validation loss:		0.407861
  validation accuracy:		93.59 %
Epoch 1334 of 2000 took 0.035s
  training loss:		0.007848
  validation loss:		0.403994
  validation accuracy:		93.37 %
Epoch 1335 of 2000 took 0.035s
  training loss:		0.007481
  validation loss:		0.405794
  validation accuracy:		93.70 %
Epoch 1336 of 2000 took 0.035s
  training loss:		0.007961
  validation loss:		0.404939
  validation accuracy:		93.37 %
Epoch 1337 of 2000 took 0.035s
  training loss:		0.007894
  validation loss:		0.396657
  validation accuracy:		93.48 %
Epoch 1338 of 2000 took 0.035s
  training loss:		0.007786
  validation loss:		0.405557
  validation accuracy:		93.70 %
Epoch 1339 of 2000 took 0.035s
  training loss:		0.007691
  validation loss:		0.403664
  validation accuracy:		93.37 %
Epoch 1340 of 2000 took 0.035s
  training loss:		0.007755
  validation loss:		0.405628
  validation accuracy:		93.37 %
Epoch 1341 of 2000 took 0.035s
  training loss:		0.007730
  validation loss:		0.407490
  validation accuracy:		93.59 %
Epoch 1342 of 2000 took 0.035s
  training loss:		0.007720
  validation loss:		0.405614
  validation accuracy:		93.59 %
Epoch 1343 of 2000 took 0.035s
  training loss:		0.007786
  validation loss:		0.404480
  validation accuracy:		93.70 %
Epoch 1344 of 2000 took 0.035s
  training loss:		0.007669
  validation loss:		0.406868
  validation accuracy:		93.48 %
Epoch 1345 of 2000 took 0.035s
  training loss:		0.007648
  validation loss:		0.406005
  validation accuracy:		93.59 %
Epoch 1346 of 2000 took 0.035s
  training loss:		0.007855
  validation loss:		0.409978
  validation accuracy:		93.37 %
Epoch 1347 of 2000 took 0.035s
  training loss:		0.007755
  validation loss:		0.407201
  validation accuracy:		93.59 %
Epoch 1348 of 2000 took 0.035s
  training loss:		0.007495
  validation loss:		0.405275
  validation accuracy:		93.59 %
Epoch 1349 of 2000 took 0.035s
  training loss:		0.007668
  validation loss:		0.406159
  validation accuracy:		93.70 %
Epoch 1350 of 2000 took 0.035s
  training loss:		0.007857
  validation loss:		0.408627
  validation accuracy:		93.59 %
Epoch 1351 of 2000 took 0.035s
  training loss:		0.007693
  validation loss:		0.407723
  validation accuracy:		93.48 %
Epoch 1352 of 2000 took 0.035s
  training loss:		0.007625
  validation loss:		0.406397
  validation accuracy:		93.48 %
Epoch 1353 of 2000 took 0.035s
  training loss:		0.007394
  validation loss:		0.403571
  validation accuracy:		93.70 %
Epoch 1354 of 2000 took 0.035s
  training loss:		0.007921
  validation loss:		0.408919
  validation accuracy:		93.26 %
Epoch 1355 of 2000 took 0.035s
  training loss:		0.007560
  validation loss:		0.409913
  validation accuracy:		93.59 %
Epoch 1356 of 2000 took 0.035s
  training loss:		0.007389
  validation loss:		0.409671
  validation accuracy:		93.48 %
Epoch 1357 of 2000 took 0.035s
  training loss:		0.007585
  validation loss:		0.410322
  validation accuracy:		93.59 %
Epoch 1358 of 2000 took 0.035s
  training loss:		0.007646
  validation loss:		0.407264
  validation accuracy:		93.59 %
Epoch 1359 of 2000 took 0.035s
  training loss:		0.007492
  validation loss:		0.412489
  validation accuracy:		93.59 %
Epoch 1360 of 2000 took 0.035s
  training loss:		0.007340
  validation loss:		0.407273
  validation accuracy:		93.48 %
Epoch 1361 of 2000 took 0.035s
  training loss:		0.007468
  validation loss:		0.407624
  validation accuracy:		93.48 %
Epoch 1362 of 2000 took 0.035s
  training loss:		0.007564
  validation loss:		0.407435
  validation accuracy:		93.59 %
Epoch 1363 of 2000 took 0.035s
  training loss:		0.007343
  validation loss:		0.414524
  validation accuracy:		93.15 %
Epoch 1364 of 2000 took 0.035s
  training loss:		0.007609
  validation loss:		0.402388
  validation accuracy:		93.59 %
Epoch 1365 of 2000 took 0.035s
  training loss:		0.007810
  validation loss:		0.404532
  validation accuracy:		93.59 %
Epoch 1366 of 2000 took 0.035s
  training loss:		0.007565
  validation loss:		0.408375
  validation accuracy:		93.48 %
Epoch 1367 of 2000 took 0.035s
  training loss:		0.007198
  validation loss:		0.403376
  validation accuracy:		93.70 %
Epoch 1368 of 2000 took 0.035s
  training loss:		0.007355
  validation loss:		0.419175
  validation accuracy:		93.15 %
Epoch 1369 of 2000 took 0.035s
  training loss:		0.007563
  validation loss:		0.407919
  validation accuracy:		93.70 %
Epoch 1370 of 2000 took 0.035s
  training loss:		0.007372
  validation loss:		0.408082
  validation accuracy:		93.48 %
Epoch 1371 of 2000 took 0.035s
  training loss:		0.007315
  validation loss:		0.413348
  validation accuracy:		93.70 %
Epoch 1372 of 2000 took 0.035s
  training loss:		0.007240
  validation loss:		0.408029
  validation accuracy:		93.59 %
Epoch 1373 of 2000 took 0.035s
  training loss:		0.007482
  validation loss:		0.412898
  validation accuracy:		93.59 %
Epoch 1374 of 2000 took 0.035s
  training loss:		0.007254
  validation loss:		0.408289
  validation accuracy:		93.59 %
Epoch 1375 of 2000 took 0.035s
  training loss:		0.007360
  validation loss:		0.411888
  validation accuracy:		93.48 %
Epoch 1376 of 2000 took 0.035s
  training loss:		0.007351
  validation loss:		0.416887
  validation accuracy:		93.26 %
Epoch 1377 of 2000 took 0.035s
  training loss:		0.007177
  validation loss:		0.410184
  validation accuracy:		93.48 %
Epoch 1378 of 2000 took 0.035s
  training loss:		0.007362
  validation loss:		0.417569
  validation accuracy:		93.37 %
Epoch 1379 of 2000 took 0.035s
  training loss:		0.007485
  validation loss:		0.417339
  validation accuracy:		93.48 %
Epoch 1380 of 2000 took 0.035s
  training loss:		0.007018
  validation loss:		0.410717
  validation accuracy:		93.59 %
Epoch 1381 of 2000 took 0.035s
  training loss:		0.007205
  validation loss:		0.412357
  validation accuracy:		93.59 %
Epoch 1382 of 2000 took 0.035s
  training loss:		0.007260
  validation loss:		0.412886
  validation accuracy:		93.48 %
Epoch 1383 of 2000 took 0.035s
  training loss:		0.007134
  validation loss:		0.407808
  validation accuracy:		93.48 %
Epoch 1384 of 2000 took 0.035s
  training loss:		0.007296
  validation loss:		0.407970
  validation accuracy:		93.59 %
Epoch 1385 of 2000 took 0.035s
  training loss:		0.007289
  validation loss:		0.417000
  validation accuracy:		93.37 %
Epoch 1386 of 2000 took 0.035s
  training loss:		0.007167
  validation loss:		0.410461
  validation accuracy:		93.59 %
Epoch 1387 of 2000 took 0.035s
  training loss:		0.007102
  validation loss:		0.409924
  validation accuracy:		93.48 %
Epoch 1388 of 2000 took 0.035s
  training loss:		0.006936
  validation loss:		0.416767
  validation accuracy:		93.59 %
Epoch 1389 of 2000 took 0.035s
  training loss:		0.007118
  validation loss:		0.413383
  validation accuracy:		93.70 %
Epoch 1390 of 2000 took 0.035s
  training loss:		0.007216
  validation loss:		0.415518
  validation accuracy:		93.37 %
Epoch 1391 of 2000 took 0.035s
  training loss:		0.007050
  validation loss:		0.415447
  validation accuracy:		93.59 %
Epoch 1392 of 2000 took 0.035s
  training loss:		0.007012
  validation loss:		0.414961
  validation accuracy:		93.59 %
Epoch 1393 of 2000 took 0.035s
  training loss:		0.007152
  validation loss:		0.416127
  validation accuracy:		93.48 %
Epoch 1394 of 2000 took 0.035s
  training loss:		0.006882
  validation loss:		0.413432
  validation accuracy:		93.59 %
Epoch 1395 of 2000 took 0.035s
  training loss:		0.006889
  validation loss:		0.413751
  validation accuracy:		93.59 %
Epoch 1396 of 2000 took 0.035s
  training loss:		0.006851
  validation loss:		0.418219
  validation accuracy:		93.59 %
Epoch 1397 of 2000 took 0.035s
  training loss:		0.007361
  validation loss:		0.413215
  validation accuracy:		93.48 %
Epoch 1398 of 2000 took 0.035s
  training loss:		0.007164
  validation loss:		0.413145
  validation accuracy:		93.59 %
Epoch 1399 of 2000 took 0.035s
  training loss:		0.006684
  validation loss:		0.419054
  validation accuracy:		93.59 %
Epoch 1400 of 2000 took 0.035s
  training loss:		0.007046
  validation loss:		0.419961
  validation accuracy:		93.37 %
Epoch 1401 of 2000 took 0.035s
  training loss:		0.006858
  validation loss:		0.416352
  validation accuracy:		93.59 %
Epoch 1402 of 2000 took 0.035s
  training loss:		0.007000
  validation loss:		0.414282
  validation accuracy:		93.59 %
Epoch 1403 of 2000 took 0.035s
  training loss:		0.007059
  validation loss:		0.415535
  validation accuracy:		93.59 %
Epoch 1404 of 2000 took 0.035s
  training loss:		0.006883
  validation loss:		0.413394
  validation accuracy:		93.59 %
Epoch 1405 of 2000 took 0.035s
  training loss:		0.007111
  validation loss:		0.417131
  validation accuracy:		93.48 %
Epoch 1406 of 2000 took 0.035s
  training loss:		0.006931
  validation loss:		0.414863
  validation accuracy:		93.48 %
Epoch 1407 of 2000 took 0.035s
  training loss:		0.006855
  validation loss:		0.421310
  validation accuracy:		93.48 %
Epoch 1408 of 2000 took 0.035s
  training loss:		0.006812
  validation loss:		0.412239
  validation accuracy:		93.70 %
Epoch 1409 of 2000 took 0.035s
  training loss:		0.006846
  validation loss:		0.411679
  validation accuracy:		93.70 %
Epoch 1410 of 2000 took 0.035s
  training loss:		0.006924
  validation loss:		0.418066
  validation accuracy:		93.48 %
Epoch 1411 of 2000 took 0.035s
  training loss:		0.006766
  validation loss:		0.422052
  validation accuracy:		93.37 %
Epoch 1412 of 2000 took 0.035s
  training loss:		0.006738
  validation loss:		0.417257
  validation accuracy:		93.59 %
Epoch 1413 of 2000 took 0.035s
  training loss:		0.006611
  validation loss:		0.418546
  validation accuracy:		93.48 %
Epoch 1414 of 2000 took 0.035s
  training loss:		0.006757
  validation loss:		0.425019
  validation accuracy:		93.48 %
Epoch 1415 of 2000 took 0.035s
  training loss:		0.006741
  validation loss:		0.413427
  validation accuracy:		93.59 %
Epoch 1416 of 2000 took 0.035s
  training loss:		0.006840
  validation loss:		0.418409
  validation accuracy:		93.70 %
Epoch 1417 of 2000 took 0.035s
  training loss:		0.006576
  validation loss:		0.417595
  validation accuracy:		93.70 %
Epoch 1418 of 2000 took 0.035s
  training loss:		0.006614
  validation loss:		0.413962
  validation accuracy:		93.48 %
Epoch 1419 of 2000 took 0.035s
  training loss:		0.006667
  validation loss:		0.421946
  validation accuracy:		93.37 %
Epoch 1420 of 2000 took 0.035s
  training loss:		0.006744
  validation loss:		0.417137
  validation accuracy:		93.70 %
Epoch 1421 of 2000 took 0.035s
  training loss:		0.006659
  validation loss:		0.422174
  validation accuracy:		93.59 %
Epoch 1422 of 2000 took 0.035s
  training loss:		0.006354
  validation loss:		0.419044
  validation accuracy:		93.48 %
Epoch 1423 of 2000 took 0.035s
  training loss:		0.006588
  validation loss:		0.419215
  validation accuracy:		93.59 %
Epoch 1424 of 2000 took 0.035s
  training loss:		0.006551
  validation loss:		0.418795
  validation accuracy:		93.59 %
Epoch 1425 of 2000 took 0.035s
  training loss:		0.006630
  validation loss:		0.429423
  validation accuracy:		93.26 %
Epoch 1426 of 2000 took 0.035s
  training loss:		0.006925
  validation loss:		0.418629
  validation accuracy:		93.48 %
Epoch 1427 of 2000 took 0.035s
  training loss:		0.006618
  validation loss:		0.420874
  validation accuracy:		93.59 %
Epoch 1428 of 2000 took 0.035s
  training loss:		0.006548
  validation loss:		0.422448
  validation accuracy:		93.59 %
Epoch 1429 of 2000 took 0.035s
  training loss:		0.006827
  validation loss:		0.419380
  validation accuracy:		93.48 %
Epoch 1430 of 2000 took 0.035s
  training loss:		0.006771
  validation loss:		0.421355
  validation accuracy:		93.59 %
Epoch 1431 of 2000 took 0.035s
  training loss:		0.006327
  validation loss:		0.421048
  validation accuracy:		93.70 %
Epoch 1432 of 2000 took 0.035s
  training loss:		0.006466
  validation loss:		0.420858
  validation accuracy:		93.70 %
Epoch 1433 of 2000 took 0.035s
  training loss:		0.006541
  validation loss:		0.418421
  validation accuracy:		93.70 %
Epoch 1434 of 2000 took 0.035s
  training loss:		0.006465
  validation loss:		0.427532
  validation accuracy:		93.37 %
Epoch 1435 of 2000 took 0.035s
  training loss:		0.006830
  validation loss:		0.422117
  validation accuracy:		93.59 %
Epoch 1436 of 2000 took 0.035s
  training loss:		0.006522
  validation loss:		0.422385
  validation accuracy:		93.59 %
Epoch 1437 of 2000 took 0.035s
  training loss:		0.006658
  validation loss:		0.423200
  validation accuracy:		93.48 %
Epoch 1438 of 2000 took 0.035s
  training loss:		0.006450
  validation loss:		0.419717
  validation accuracy:		93.37 %
Epoch 1439 of 2000 took 0.035s
  training loss:		0.006471
  validation loss:		0.419264
  validation accuracy:		93.70 %
Epoch 1440 of 2000 took 0.035s
  training loss:		0.006312
  validation loss:		0.421231
  validation accuracy:		93.70 %
Epoch 1441 of 2000 took 0.035s
  training loss:		0.006527
  validation loss:		0.425490
  validation accuracy:		93.59 %
Epoch 1442 of 2000 took 0.035s
  training loss:		0.006165
  validation loss:		0.429559
  validation accuracy:		93.37 %
Epoch 1443 of 2000 took 0.035s
  training loss:		0.006408
  validation loss:		0.418058
  validation accuracy:		93.59 %
Epoch 1444 of 2000 took 0.035s
  training loss:		0.006531
  validation loss:		0.428139
  validation accuracy:		93.48 %
Epoch 1445 of 2000 took 0.035s
  training loss:		0.006440
  validation loss:		0.423359
  validation accuracy:		93.59 %
Epoch 1446 of 2000 took 0.035s
  training loss:		0.006371
  validation loss:		0.424253
  validation accuracy:		93.59 %
Epoch 1447 of 2000 took 0.035s
  training loss:		0.006469
  validation loss:		0.422313
  validation accuracy:		93.70 %
Epoch 1448 of 2000 took 0.035s
  training loss:		0.006345
  validation loss:		0.425454
  validation accuracy:		93.59 %
Epoch 1449 of 2000 took 0.035s
  training loss:		0.006274
  validation loss:		0.425589
  validation accuracy:		93.48 %
Epoch 1450 of 2000 took 0.035s
  training loss:		0.006480
  validation loss:		0.422446
  validation accuracy:		93.59 %
Epoch 1451 of 2000 took 0.035s
  training loss:		0.006522
  validation loss:		0.425853
  validation accuracy:		93.59 %
Epoch 1452 of 2000 took 0.035s
  training loss:		0.006511
  validation loss:		0.423838
  validation accuracy:		93.70 %
Epoch 1453 of 2000 took 0.035s
  training loss:		0.006467
  validation loss:		0.429254
  validation accuracy:		93.37 %
Epoch 1454 of 2000 took 0.035s
  training loss:		0.006194
  validation loss:		0.424074
  validation accuracy:		93.48 %
Epoch 1455 of 2000 took 0.035s
  training loss:		0.006237
  validation loss:		0.426442
  validation accuracy:		93.59 %
Epoch 1456 of 2000 took 0.035s
  training loss:		0.006454
  validation loss:		0.432463
  validation accuracy:		93.26 %
Epoch 1457 of 2000 took 0.035s
  training loss:		0.006254
  validation loss:		0.430261
  validation accuracy:		93.48 %
Epoch 1458 of 2000 took 0.035s
  training loss:		0.006424
  validation loss:		0.424207
  validation accuracy:		93.70 %
Epoch 1459 of 2000 took 0.035s
  training loss:		0.006375
  validation loss:		0.425892
  validation accuracy:		93.59 %
Epoch 1460 of 2000 took 0.035s
  training loss:		0.006093
  validation loss:		0.426371
  validation accuracy:		93.48 %
Epoch 1461 of 2000 took 0.035s
  training loss:		0.006306
  validation loss:		0.429065
  validation accuracy:		93.59 %
Epoch 1462 of 2000 took 0.035s
  training loss:		0.006396
  validation loss:		0.420707
  validation accuracy:		93.70 %
Epoch 1463 of 2000 took 0.038s
  training loss:		0.006263
  validation loss:		0.425515
  validation accuracy:		93.48 %
Epoch 1464 of 2000 took 0.037s
  training loss:		0.006182
  validation loss:		0.424230
  validation accuracy:		93.48 %
Epoch 1465 of 2000 took 0.036s
  training loss:		0.006026
  validation loss:		0.424552
  validation accuracy:		93.48 %
Epoch 1466 of 2000 took 0.036s
  training loss:		0.006235
  validation loss:		0.426577
  validation accuracy:		93.59 %
Epoch 1467 of 2000 took 0.037s
  training loss:		0.006302
  validation loss:		0.426318
  validation accuracy:		93.48 %
Epoch 1468 of 2000 took 0.037s
  training loss:		0.006387
  validation loss:		0.422917
  validation accuracy:		93.70 %
Epoch 1469 of 2000 took 0.036s
  training loss:		0.005912
  validation loss:		0.424733
  validation accuracy:		93.59 %
Epoch 1470 of 2000 took 0.036s
  training loss:		0.006048
  validation loss:		0.422809
  validation accuracy:		93.59 %
Epoch 1471 of 2000 took 0.036s
  training loss:		0.006237
  validation loss:		0.430096
  validation accuracy:		93.48 %
Epoch 1472 of 2000 took 0.036s
  training loss:		0.006191
  validation loss:		0.421130
  validation accuracy:		93.70 %
Epoch 1473 of 2000 took 0.036s
  training loss:		0.006188
  validation loss:		0.428905
  validation accuracy:		93.37 %
Epoch 1474 of 2000 took 0.036s
  training loss:		0.006315
  validation loss:		0.434133
  validation accuracy:		93.37 %
Epoch 1475 of 2000 took 0.036s
  training loss:		0.006105
  validation loss:		0.426488
  validation accuracy:		93.26 %
Epoch 1476 of 2000 took 0.036s
  training loss:		0.006125
  validation loss:		0.425815
  validation accuracy:		93.59 %
Epoch 1477 of 2000 took 0.036s
  training loss:		0.006273
  validation loss:		0.433698
  validation accuracy:		93.37 %
Epoch 1478 of 2000 took 0.036s
  training loss:		0.006047
  validation loss:		0.426428
  validation accuracy:		93.70 %
Epoch 1479 of 2000 took 0.036s
  training loss:		0.005898
  validation loss:		0.425776
  validation accuracy:		93.59 %
Epoch 1480 of 2000 took 0.036s
  training loss:		0.006074
  validation loss:		0.427121
  validation accuracy:		93.59 %
Epoch 1481 of 2000 took 0.036s
  training loss:		0.005967
  validation loss:		0.428312
  validation accuracy:		93.59 %
Epoch 1482 of 2000 took 0.036s
  training loss:		0.006356
  validation loss:		0.428962
  validation accuracy:		93.37 %
Epoch 1483 of 2000 took 0.036s
  training loss:		0.005941
  validation loss:		0.431438
  validation accuracy:		93.48 %
Epoch 1484 of 2000 took 0.035s
  training loss:		0.006022
  validation loss:		0.435227
  validation accuracy:		93.37 %
Epoch 1485 of 2000 took 0.035s
  training loss:		0.005908
  validation loss:		0.425897
  validation accuracy:		93.59 %
Epoch 1486 of 2000 took 0.035s
  training loss:		0.005988
  validation loss:		0.427826
  validation accuracy:		93.70 %
Epoch 1487 of 2000 took 0.035s
  training loss:		0.006062
  validation loss:		0.433760
  validation accuracy:		93.59 %
Epoch 1488 of 2000 took 0.035s
  training loss:		0.005909
  validation loss:		0.427404
  validation accuracy:		93.59 %
Epoch 1489 of 2000 took 0.035s
  training loss:		0.006208
  validation loss:		0.430724
  validation accuracy:		93.59 %
Epoch 1490 of 2000 took 0.035s
  training loss:		0.005904
  validation loss:		0.428982
  validation accuracy:		93.59 %
Epoch 1491 of 2000 took 0.035s
  training loss:		0.006003
  validation loss:		0.429014
  validation accuracy:		93.48 %
Epoch 1492 of 2000 took 0.035s
  training loss:		0.005873
  validation loss:		0.428868
  validation accuracy:		93.37 %
Epoch 1493 of 2000 took 0.035s
  training loss:		0.006082
  validation loss:		0.434122
  validation accuracy:		93.59 %
Epoch 1494 of 2000 took 0.035s
  training loss:		0.005830
  validation loss:		0.431564
  validation accuracy:		93.59 %
Epoch 1495 of 2000 took 0.035s
  training loss:		0.005868
  validation loss:		0.429853
  validation accuracy:		93.48 %
Epoch 1496 of 2000 took 0.035s
  training loss:		0.005909
  validation loss:		0.428985
  validation accuracy:		93.70 %
Epoch 1497 of 2000 took 0.035s
  training loss:		0.005902
  validation loss:		0.428273
  validation accuracy:		93.70 %
Epoch 1498 of 2000 took 0.035s
  training loss:		0.005901
  validation loss:		0.440692
  validation accuracy:		93.26 %
Epoch 1499 of 2000 took 0.035s
  training loss:		0.005873
  validation loss:		0.427541
  validation accuracy:		93.70 %
Epoch 1500 of 2000 took 0.035s
  training loss:		0.006057
  validation loss:		0.440339
  validation accuracy:		93.26 %
Epoch 1501 of 2000 took 0.035s
  training loss:		0.005789
  validation loss:		0.430368
  validation accuracy:		93.59 %
Epoch 1502 of 2000 took 0.035s
  training loss:		0.006062
  validation loss:		0.430171
  validation accuracy:		93.59 %
Epoch 1503 of 2000 took 0.035s
  training loss:		0.005801
  validation loss:		0.432118
  validation accuracy:		93.48 %
Epoch 1504 of 2000 took 0.035s
  training loss:		0.006084
  validation loss:		0.434227
  validation accuracy:		93.48 %
Epoch 1505 of 2000 took 0.035s
  training loss:		0.005861
  validation loss:		0.430533
  validation accuracy:		93.37 %
Epoch 1506 of 2000 took 0.035s
  training loss:		0.005898
  validation loss:		0.432430
  validation accuracy:		93.48 %
Epoch 1507 of 2000 took 0.035s
  training loss:		0.005805
  validation loss:		0.430778
  validation accuracy:		93.70 %
Epoch 1508 of 2000 took 0.035s
  training loss:		0.005682
  validation loss:		0.431676
  validation accuracy:		93.70 %
Epoch 1509 of 2000 took 0.035s
  training loss:		0.005644
  validation loss:		0.440485
  validation accuracy:		93.26 %
Epoch 1510 of 2000 took 0.035s
  training loss:		0.006141
  validation loss:		0.444048
  validation accuracy:		93.15 %
Epoch 1511 of 2000 took 0.035s
  training loss:		0.005816
  validation loss:		0.430958
  validation accuracy:		93.70 %
Epoch 1512 of 2000 took 0.035s
  training loss:		0.005681
  validation loss:		0.434126
  validation accuracy:		93.59 %
Epoch 1513 of 2000 took 0.035s
  training loss:		0.005596
  validation loss:		0.438789
  validation accuracy:		93.48 %
Epoch 1514 of 2000 took 0.035s
  training loss:		0.005770
  validation loss:		0.433780
  validation accuracy:		93.70 %
Epoch 1515 of 2000 took 0.035s
  training loss:		0.005718
  validation loss:		0.439362
  validation accuracy:		93.48 %
Epoch 1516 of 2000 took 0.035s
  training loss:		0.005579
  validation loss:		0.428752
  validation accuracy:		93.48 %
Epoch 1517 of 2000 took 0.035s
  training loss:		0.005801
  validation loss:		0.438175
  validation accuracy:		93.48 %
Epoch 1518 of 2000 took 0.036s
  training loss:		0.005665
  validation loss:		0.436480
  validation accuracy:		93.48 %
Epoch 1519 of 2000 took 0.035s
  training loss:		0.005808
  validation loss:		0.433862
  validation accuracy:		93.37 %
Epoch 1520 of 2000 took 0.035s
  training loss:		0.005782
  validation loss:		0.436496
  validation accuracy:		93.59 %
Epoch 1521 of 2000 took 0.035s
  training loss:		0.005760
  validation loss:		0.434805
  validation accuracy:		93.48 %
Epoch 1522 of 2000 took 0.035s
  training loss:		0.005678
  validation loss:		0.433319
  validation accuracy:		93.37 %
Epoch 1523 of 2000 took 0.035s
  training loss:		0.005787
  validation loss:		0.438294
  validation accuracy:		93.48 %
Epoch 1524 of 2000 took 0.035s
  training loss:		0.005796
  validation loss:		0.434608
  validation accuracy:		93.48 %
Epoch 1525 of 2000 took 0.035s
  training loss:		0.005623
  validation loss:		0.437063
  validation accuracy:		93.70 %
Epoch 1526 of 2000 took 0.035s
  training loss:		0.005725
  validation loss:		0.434451
  validation accuracy:		93.59 %
Epoch 1527 of 2000 took 0.035s
  training loss:		0.005546
  validation loss:		0.437836
  validation accuracy:		93.37 %
Epoch 1528 of 2000 took 0.035s
  training loss:		0.005633
  validation loss:		0.435407
  validation accuracy:		93.48 %
Epoch 1529 of 2000 took 0.036s
  training loss:		0.005494
  validation loss:		0.433868
  validation accuracy:		93.59 %
Epoch 1530 of 2000 took 0.035s
  training loss:		0.005645
  validation loss:		0.437684
  validation accuracy:		93.70 %
Epoch 1531 of 2000 took 0.035s
  training loss:		0.005614
  validation loss:		0.434800
  validation accuracy:		93.59 %
Epoch 1532 of 2000 took 0.035s
  training loss:		0.005847
  validation loss:		0.433126
  validation accuracy:		93.59 %
Epoch 1533 of 2000 took 0.035s
  training loss:		0.005655
  validation loss:		0.437344
  validation accuracy:		93.48 %
Epoch 1534 of 2000 took 0.035s
  training loss:		0.005456
  validation loss:		0.435720
  validation accuracy:		93.70 %
Epoch 1535 of 2000 took 0.035s
  training loss:		0.005617
  validation loss:		0.438384
  validation accuracy:		93.59 %
Epoch 1536 of 2000 took 0.035s
  training loss:		0.005528
  validation loss:		0.442663
  validation accuracy:		93.26 %
Epoch 1537 of 2000 took 0.035s
  training loss:		0.005664
  validation loss:		0.438373
  validation accuracy:		93.59 %
Epoch 1538 of 2000 took 0.035s
  training loss:		0.005654
  validation loss:		0.439729
  validation accuracy:		93.59 %
Epoch 1539 of 2000 took 0.035s
  training loss:		0.005524
  validation loss:		0.435350
  validation accuracy:		93.59 %
Epoch 1540 of 2000 took 0.035s
  training loss:		0.005417
  validation loss:		0.438542
  validation accuracy:		93.48 %
Epoch 1541 of 2000 took 0.035s
  training loss:		0.005511
  validation loss:		0.438636
  validation accuracy:		93.48 %
Epoch 1542 of 2000 took 0.035s
  training loss:		0.005572
  validation loss:		0.442776
  validation accuracy:		93.37 %
Epoch 1543 of 2000 took 0.035s
  training loss:		0.005323
  validation loss:		0.432621
  validation accuracy:		93.59 %
Epoch 1544 of 2000 took 0.035s
  training loss:		0.005601
  validation loss:		0.437190
  validation accuracy:		93.70 %
Epoch 1545 of 2000 took 0.035s
  training loss:		0.005299
  validation loss:		0.442537
  validation accuracy:		93.59 %
Epoch 1546 of 2000 took 0.035s
  training loss:		0.005509
  validation loss:		0.437497
  validation accuracy:		93.70 %
Epoch 1547 of 2000 took 0.035s
  training loss:		0.005403
  validation loss:		0.440017
  validation accuracy:		93.48 %
Epoch 1548 of 2000 took 0.035s
  training loss:		0.005594
  validation loss:		0.438161
  validation accuracy:		93.37 %
Epoch 1549 of 2000 took 0.035s
  training loss:		0.005596
  validation loss:		0.440483
  validation accuracy:		93.48 %
Epoch 1550 of 2000 took 0.035s
  training loss:		0.005428
  validation loss:		0.447434
  validation accuracy:		93.26 %
Epoch 1551 of 2000 took 0.035s
  training loss:		0.005379
  validation loss:		0.433061
  validation accuracy:		93.48 %
Epoch 1552 of 2000 took 0.035s
  training loss:		0.005497
  validation loss:		0.444767
  validation accuracy:		93.48 %
Epoch 1553 of 2000 took 0.035s
  training loss:		0.005275
  validation loss:		0.440964
  validation accuracy:		93.48 %
Epoch 1554 of 2000 took 0.035s
  training loss:		0.005431
  validation loss:		0.437929
  validation accuracy:		93.59 %
Epoch 1555 of 2000 took 0.035s
  training loss:		0.005441
  validation loss:		0.439561
  validation accuracy:		93.59 %
Epoch 1556 of 2000 took 0.035s
  training loss:		0.005375
  validation loss:		0.441465
  validation accuracy:		93.48 %
Epoch 1557 of 2000 took 0.035s
  training loss:		0.005244
  validation loss:		0.435452
  validation accuracy:		93.59 %
Epoch 1558 of 2000 took 0.035s
  training loss:		0.005371
  validation loss:		0.442239
  validation accuracy:		93.59 %
Epoch 1559 of 2000 took 0.035s
  training loss:		0.005389
  validation loss:		0.443008
  validation accuracy:		93.59 %
Epoch 1560 of 2000 took 0.035s
  training loss:		0.005437
  validation loss:		0.441361
  validation accuracy:		93.48 %
Epoch 1561 of 2000 took 0.035s
  training loss:		0.005256
  validation loss:		0.443003
  validation accuracy:		93.48 %
Epoch 1562 of 2000 took 0.035s
  training loss:		0.005324
  validation loss:		0.438953
  validation accuracy:		93.70 %
Epoch 1563 of 2000 took 0.035s
  training loss:		0.005266
  validation loss:		0.440227
  validation accuracy:		93.48 %
Epoch 1564 of 2000 took 0.035s
  training loss:		0.005340
  validation loss:		0.445085
  validation accuracy:		93.48 %
Epoch 1565 of 2000 took 0.035s
  training loss:		0.005195
  validation loss:		0.442231
  validation accuracy:		93.37 %
Epoch 1566 of 2000 took 0.035s
  training loss:		0.005100
  validation loss:		0.440963
  validation accuracy:		93.59 %
Epoch 1567 of 2000 took 0.035s
  training loss:		0.005163
  validation loss:		0.439617
  validation accuracy:		93.70 %
Epoch 1568 of 2000 took 0.035s
  training loss:		0.005178
  validation loss:		0.445126
  validation accuracy:		93.37 %
Epoch 1569 of 2000 took 0.035s
  training loss:		0.005342
  validation loss:		0.444106
  validation accuracy:		93.48 %
Epoch 1570 of 2000 took 0.035s
  training loss:		0.005193
  validation loss:		0.439579
  validation accuracy:		93.26 %
Epoch 1571 of 2000 took 0.035s
  training loss:		0.005487
  validation loss:		0.443041
  validation accuracy:		93.59 %
Epoch 1572 of 2000 took 0.035s
  training loss:		0.005253
  validation loss:		0.443086
  validation accuracy:		93.48 %
Epoch 1573 of 2000 took 0.035s
  training loss:		0.005197
  validation loss:		0.443189
  validation accuracy:		93.59 %
Epoch 1574 of 2000 took 0.035s
  training loss:		0.005256
  validation loss:		0.440804
  validation accuracy:		93.26 %
Epoch 1575 of 2000 took 0.036s
  training loss:		0.005213
  validation loss:		0.446355
  validation accuracy:		93.59 %
Epoch 1576 of 2000 took 0.035s
  training loss:		0.005108
  validation loss:		0.446407
  validation accuracy:		93.48 %
Epoch 1577 of 2000 took 0.035s
  training loss:		0.005273
  validation loss:		0.442820
  validation accuracy:		93.59 %
Epoch 1578 of 2000 took 0.035s
  training loss:		0.005258
  validation loss:		0.444233
  validation accuracy:		93.59 %
Epoch 1579 of 2000 took 0.035s
  training loss:		0.005252
  validation loss:		0.441118
  validation accuracy:		93.59 %
Epoch 1580 of 2000 took 0.035s
  training loss:		0.005140
  validation loss:		0.446765
  validation accuracy:		93.59 %
Epoch 1581 of 2000 took 0.035s
  training loss:		0.005203
  validation loss:		0.445283
  validation accuracy:		93.59 %
Epoch 1582 of 2000 took 0.035s
  training loss:		0.005219
  validation loss:		0.448438
  validation accuracy:		93.48 %
Epoch 1583 of 2000 took 0.035s
  training loss:		0.005201
  validation loss:		0.446982
  validation accuracy:		93.48 %
Epoch 1584 of 2000 took 0.035s
  training loss:		0.005209
  validation loss:		0.446862
  validation accuracy:		93.59 %
Epoch 1585 of 2000 took 0.035s
  training loss:		0.005339
  validation loss:		0.447231
  validation accuracy:		93.48 %
Epoch 1586 of 2000 took 0.035s
  training loss:		0.005070
  validation loss:		0.444116
  validation accuracy:		93.70 %
Epoch 1587 of 2000 took 0.035s
  training loss:		0.005185
  validation loss:		0.448523
  validation accuracy:		93.48 %
Epoch 1588 of 2000 took 0.035s
  training loss:		0.005183
  validation loss:		0.447136
  validation accuracy:		93.48 %
Epoch 1589 of 2000 took 0.035s
  training loss:		0.005226
  validation loss:		0.446790
  validation accuracy:		93.48 %
Epoch 1590 of 2000 took 0.035s
  training loss:		0.005042
  validation loss:		0.445963
  validation accuracy:		93.59 %
Epoch 1591 of 2000 took 0.035s
  training loss:		0.005240
  validation loss:		0.445879
  validation accuracy:		93.59 %
Epoch 1592 of 2000 took 0.035s
  training loss:		0.005171
  validation loss:		0.450046
  validation accuracy:		93.48 %
Epoch 1593 of 2000 took 0.035s
  training loss:		0.005001
  validation loss:		0.446502
  validation accuracy:		93.48 %
Epoch 1594 of 2000 took 0.035s
  training loss:		0.004968
  validation loss:		0.445696
  validation accuracy:		93.59 %
Epoch 1595 of 2000 took 0.035s
  training loss:		0.005112
  validation loss:		0.447355
  validation accuracy:		93.48 %
Epoch 1596 of 2000 took 0.035s
  training loss:		0.005148
  validation loss:		0.444376
  validation accuracy:		93.59 %
Epoch 1597 of 2000 took 0.035s
  training loss:		0.005075
  validation loss:		0.445015
  validation accuracy:		93.59 %
Epoch 1598 of 2000 took 0.035s
  training loss:		0.005031
  validation loss:		0.445302
  validation accuracy:		93.48 %
Epoch 1599 of 2000 took 0.035s
  training loss:		0.004959
  validation loss:		0.450607
  validation accuracy:		93.59 %
Epoch 1600 of 2000 took 0.035s
  training loss:		0.004934
  validation loss:		0.445607
  validation accuracy:		93.59 %
Epoch 1601 of 2000 took 0.035s
  training loss:		0.005079
  validation loss:		0.445973
  validation accuracy:		93.48 %
Epoch 1602 of 2000 took 0.035s
  training loss:		0.005054
  validation loss:		0.450630
  validation accuracy:		93.48 %
Epoch 1603 of 2000 took 0.035s
  training loss:		0.005050
  validation loss:		0.445592
  validation accuracy:		93.37 %
Epoch 1604 of 2000 took 0.035s
  training loss:		0.005126
  validation loss:		0.447294
  validation accuracy:		93.48 %
Epoch 1605 of 2000 took 0.035s
  training loss:		0.005284
  validation loss:		0.449137
  validation accuracy:		93.48 %
Epoch 1606 of 2000 took 0.035s
  training loss:		0.004945
  validation loss:		0.453841
  validation accuracy:		93.48 %
Epoch 1607 of 2000 took 0.035s
  training loss:		0.005025
  validation loss:		0.448912
  validation accuracy:		93.37 %
Epoch 1608 of 2000 took 0.035s
  training loss:		0.004979
  validation loss:		0.452203
  validation accuracy:		93.48 %
Epoch 1609 of 2000 took 0.035s
  training loss:		0.005132
  validation loss:		0.449183
  validation accuracy:		93.48 %
Epoch 1610 of 2000 took 0.035s
  training loss:		0.004840
  validation loss:		0.447389
  validation accuracy:		93.48 %
Epoch 1611 of 2000 took 0.035s
  training loss:		0.004978
  validation loss:		0.451627
  validation accuracy:		93.48 %
Epoch 1612 of 2000 took 0.035s
  training loss:		0.005035
  validation loss:		0.454234
  validation accuracy:		93.48 %
Epoch 1613 of 2000 took 0.035s
  training loss:		0.005075
  validation loss:		0.446704
  validation accuracy:		93.48 %
Epoch 1614 of 2000 took 0.035s
  training loss:		0.004957
  validation loss:		0.450493
  validation accuracy:		93.48 %
Epoch 1615 of 2000 took 0.035s
  training loss:		0.004974
  validation loss:		0.450286
  validation accuracy:		93.37 %
Epoch 1616 of 2000 took 0.035s
  training loss:		0.004988
  validation loss:		0.449870
  validation accuracy:		93.48 %
Epoch 1617 of 2000 took 0.035s
  training loss:		0.004928
  validation loss:		0.453304
  validation accuracy:		93.37 %
Epoch 1618 of 2000 took 0.035s
  training loss:		0.005055
  validation loss:		0.454408
  validation accuracy:		93.48 %
Epoch 1619 of 2000 took 0.035s
  training loss:		0.005111
  validation loss:		0.454887
  validation accuracy:		93.48 %
Epoch 1620 of 2000 took 0.035s
  training loss:		0.004889
  validation loss:		0.452158
  validation accuracy:		93.48 %
Epoch 1621 of 2000 took 0.035s
  training loss:		0.004984
  validation loss:		0.451635
  validation accuracy:		93.48 %
Epoch 1622 of 2000 took 0.035s
  training loss:		0.004748
  validation loss:		0.453680
  validation accuracy:		93.48 %
Epoch 1623 of 2000 took 0.035s
  training loss:		0.004889
  validation loss:		0.448463
  validation accuracy:		93.59 %
Epoch 1624 of 2000 took 0.035s
  training loss:		0.004964
  validation loss:		0.450179
  validation accuracy:		93.48 %
Epoch 1625 of 2000 took 0.035s
  training loss:		0.004962
  validation loss:		0.452381
  validation accuracy:		93.48 %
Epoch 1626 of 2000 took 0.035s
  training loss:		0.004762
  validation loss:		0.454038
  validation accuracy:		93.59 %
Epoch 1627 of 2000 took 0.035s
  training loss:		0.004860
  validation loss:		0.455856
  validation accuracy:		93.26 %
Epoch 1628 of 2000 took 0.035s
  training loss:		0.005054
  validation loss:		0.454525
  validation accuracy:		93.26 %
Epoch 1629 of 2000 took 0.035s
  training loss:		0.004814
  validation loss:		0.451419
  validation accuracy:		93.59 %
Epoch 1630 of 2000 took 0.035s
  training loss:		0.004934
  validation loss:		0.452152
  validation accuracy:		93.59 %
Epoch 1631 of 2000 took 0.035s
  training loss:		0.004807
  validation loss:		0.455297
  validation accuracy:		93.48 %
Epoch 1632 of 2000 took 0.035s
  training loss:		0.004833
  validation loss:		0.445654
  validation accuracy:		93.37 %
Epoch 1633 of 2000 took 0.035s
  training loss:		0.004958
  validation loss:		0.456556
  validation accuracy:		93.37 %
Epoch 1634 of 2000 took 0.035s
  training loss:		0.004824
  validation loss:		0.451091
  validation accuracy:		93.59 %
Epoch 1635 of 2000 took 0.035s
  training loss:		0.004818
  validation loss:		0.453792
  validation accuracy:		93.59 %
Epoch 1636 of 2000 took 0.035s
  training loss:		0.004858
  validation loss:		0.449835
  validation accuracy:		93.48 %
Epoch 1637 of 2000 took 0.035s
  training loss:		0.004818
  validation loss:		0.451941
  validation accuracy:		93.80 %
Epoch 1638 of 2000 took 0.035s
  training loss:		0.004605
  validation loss:		0.455622
  validation accuracy:		93.48 %
Epoch 1639 of 2000 took 0.035s
  training loss:		0.004770
  validation loss:		0.452147
  validation accuracy:		93.48 %
Epoch 1640 of 2000 took 0.035s
  training loss:		0.004762
  validation loss:		0.452385
  validation accuracy:		93.48 %
Epoch 1641 of 2000 took 0.035s
  training loss:		0.004568
  validation loss:		0.455702
  validation accuracy:		93.48 %
Epoch 1642 of 2000 took 0.035s
  training loss:		0.004905
  validation loss:		0.455170
  validation accuracy:		93.59 %
Epoch 1643 of 2000 took 0.035s
  training loss:		0.004775
  validation loss:		0.455987
  validation accuracy:		93.59 %
Epoch 1644 of 2000 took 0.035s
  training loss:		0.004857
  validation loss:		0.454078
  validation accuracy:		93.26 %
Epoch 1645 of 2000 took 0.035s
  training loss:		0.004689
  validation loss:		0.454527
  validation accuracy:		93.59 %
Epoch 1646 of 2000 took 0.035s
  training loss:		0.004683
  validation loss:		0.453440
  validation accuracy:		93.48 %
Epoch 1647 of 2000 took 0.035s
  training loss:		0.004677
  validation loss:		0.455364
  validation accuracy:		93.48 %
Epoch 1648 of 2000 took 0.037s
  training loss:		0.004783
  validation loss:		0.454797
  validation accuracy:		93.59 %
Epoch 1649 of 2000 took 0.035s
  training loss:		0.004623
  validation loss:		0.455169
  validation accuracy:		93.48 %
Epoch 1650 of 2000 took 0.035s
  training loss:		0.004669
  validation loss:		0.455154
  validation accuracy:		93.48 %
Epoch 1651 of 2000 took 0.035s
  training loss:		0.004556
  validation loss:		0.459499
  validation accuracy:		93.37 %
Epoch 1652 of 2000 took 0.035s
  training loss:		0.004715
  validation loss:		0.453900
  validation accuracy:		93.48 %
Epoch 1653 of 2000 took 0.035s
  training loss:		0.004626
  validation loss:		0.455154
  validation accuracy:		93.48 %
Epoch 1654 of 2000 took 0.035s
  training loss:		0.004555
  validation loss:		0.451977
  validation accuracy:		93.59 %
Epoch 1655 of 2000 took 0.035s
  training loss:		0.004530
  validation loss:		0.458973
  validation accuracy:		93.48 %
Epoch 1656 of 2000 took 0.035s
  training loss:		0.004451
  validation loss:		0.453387
  validation accuracy:		93.70 %
Epoch 1657 of 2000 took 0.035s
  training loss:		0.004697
  validation loss:		0.458266
  validation accuracy:		93.37 %
Epoch 1658 of 2000 took 0.035s
  training loss:		0.004654
  validation loss:		0.455059
  validation accuracy:		93.37 %
Epoch 1659 of 2000 took 0.035s
  training loss:		0.004578
  validation loss:		0.458764
  validation accuracy:		93.59 %
Epoch 1660 of 2000 took 0.035s
  training loss:		0.004550
  validation loss:		0.456159
  validation accuracy:		93.48 %
Epoch 1661 of 2000 took 0.035s
  training loss:		0.004597
  validation loss:		0.454646
  validation accuracy:		93.48 %
Epoch 1662 of 2000 took 0.035s
  training loss:		0.004527
  validation loss:		0.457454
  validation accuracy:		93.59 %
Epoch 1663 of 2000 took 0.035s
  training loss:		0.004546
  validation loss:		0.462457
  validation accuracy:		93.48 %
Epoch 1664 of 2000 took 0.035s
  training loss:		0.004638
  validation loss:		0.454917
  validation accuracy:		93.59 %
Epoch 1665 of 2000 took 0.035s
  training loss:		0.004508
  validation loss:		0.459489
  validation accuracy:		93.37 %
Epoch 1666 of 2000 took 0.035s
  training loss:		0.004575
  validation loss:		0.454727
  validation accuracy:		93.48 %
Epoch 1667 of 2000 took 0.035s
  training loss:		0.004652
  validation loss:		0.451151
  validation accuracy:		93.48 %
Epoch 1668 of 2000 took 0.035s
  training loss:		0.004475
  validation loss:		0.457988
  validation accuracy:		93.37 %
Epoch 1669 of 2000 took 0.035s
  training loss:		0.004537
  validation loss:		0.455486
  validation accuracy:		93.59 %
Epoch 1670 of 2000 took 0.035s
  training loss:		0.004513
  validation loss:		0.456213
  validation accuracy:		93.48 %
Epoch 1671 of 2000 took 0.035s
  training loss:		0.004511
  validation loss:		0.456807
  validation accuracy:		93.59 %
Epoch 1672 of 2000 took 0.035s
  training loss:		0.004390
  validation loss:		0.457432
  validation accuracy:		93.37 %
Epoch 1673 of 2000 took 0.035s
  training loss:		0.004568
  validation loss:		0.456613
  validation accuracy:		93.48 %
Epoch 1674 of 2000 took 0.035s
  training loss:		0.004560
  validation loss:		0.459157
  validation accuracy:		93.70 %
Epoch 1675 of 2000 took 0.035s
  training loss:		0.004598
  validation loss:		0.465087
  validation accuracy:		93.37 %
Epoch 1676 of 2000 took 0.035s
  training loss:		0.004722
  validation loss:		0.458213
  validation accuracy:		93.59 %
Epoch 1677 of 2000 took 0.035s
  training loss:		0.004653
  validation loss:		0.458951
  validation accuracy:		93.48 %
Epoch 1678 of 2000 took 0.035s
  training loss:		0.004605
  validation loss:		0.456251
  validation accuracy:		93.26 %
Epoch 1679 of 2000 took 0.035s
  training loss:		0.004635
  validation loss:		0.470813
  validation accuracy:		93.26 %
Epoch 1680 of 2000 took 0.035s
  training loss:		0.004682
  validation loss:		0.455152
  validation accuracy:		93.26 %
Epoch 1681 of 2000 took 0.035s
  training loss:		0.004478
  validation loss:		0.463041
  validation accuracy:		93.37 %
Epoch 1682 of 2000 took 0.035s
  training loss:		0.004525
  validation loss:		0.455124
  validation accuracy:		93.70 %
Epoch 1683 of 2000 took 0.035s
  training loss:		0.004549
  validation loss:		0.457647
  validation accuracy:		93.26 %
Epoch 1684 of 2000 took 0.035s
  training loss:		0.004359
  validation loss:		0.458181
  validation accuracy:		93.48 %
Epoch 1685 of 2000 took 0.035s
  training loss:		0.004530
  validation loss:		0.458819
  validation accuracy:		93.48 %
Epoch 1686 of 2000 took 0.035s
  training loss:		0.004580
  validation loss:		0.461590
  validation accuracy:		93.48 %
Epoch 1687 of 2000 took 0.036s
  training loss:		0.004419
  validation loss:		0.457173
  validation accuracy:		93.26 %
Epoch 1688 of 2000 took 0.036s
  training loss:		0.004427
  validation loss:		0.462497
  validation accuracy:		93.48 %
Epoch 1689 of 2000 took 0.035s
  training loss:		0.004422
  validation loss:		0.462680
  validation accuracy:		93.37 %
Epoch 1690 of 2000 took 0.035s
  training loss:		0.004498
  validation loss:		0.461402
  validation accuracy:		93.37 %
Epoch 1691 of 2000 took 0.035s
  training loss:		0.004391
  validation loss:		0.458405
  validation accuracy:		93.48 %
Epoch 1692 of 2000 took 0.035s
  training loss:		0.004560
  validation loss:		0.462108
  validation accuracy:		93.37 %
Epoch 1693 of 2000 took 0.035s
  training loss:		0.004489
  validation loss:		0.457902
  validation accuracy:		93.48 %
Epoch 1694 of 2000 took 0.035s
  training loss:		0.004311
  validation loss:		0.462579
  validation accuracy:		93.37 %
Epoch 1695 of 2000 took 0.035s
  training loss:		0.004375
  validation loss:		0.462637
  validation accuracy:		93.48 %
Epoch 1696 of 2000 took 0.035s
  training loss:		0.004348
  validation loss:		0.460490
  validation accuracy:		93.48 %
Epoch 1697 of 2000 took 0.035s
  training loss:		0.004338
  validation loss:		0.461438
  validation accuracy:		93.59 %
Epoch 1698 of 2000 took 0.035s
  training loss:		0.004381
  validation loss:		0.464262
  validation accuracy:		93.48 %
Epoch 1699 of 2000 took 0.035s
  training loss:		0.004401
  validation loss:		0.461734
  validation accuracy:		93.48 %
Epoch 1700 of 2000 took 0.035s
  training loss:		0.004397
  validation loss:		0.463403
  validation accuracy:		93.48 %
Epoch 1701 of 2000 took 0.035s
  training loss:		0.004545
  validation loss:		0.458833
  validation accuracy:		93.37 %
Epoch 1702 of 2000 took 0.035s
  training loss:		0.004561
  validation loss:		0.456751
  validation accuracy:		93.48 %
Epoch 1703 of 2000 took 0.035s
  training loss:		0.004381
  validation loss:		0.467256
  validation accuracy:		93.37 %
Epoch 1704 of 2000 took 0.035s
  training loss:		0.004335
  validation loss:		0.467516
  validation accuracy:		93.26 %
Epoch 1705 of 2000 took 0.035s
  training loss:		0.004400
  validation loss:		0.463400
  validation accuracy:		93.37 %
Epoch 1706 of 2000 took 0.035s
  training loss:		0.004162
  validation loss:		0.456609
  validation accuracy:		93.37 %
Epoch 1707 of 2000 took 0.035s
  training loss:		0.004443
  validation loss:		0.463436
  validation accuracy:		93.59 %
Epoch 1708 of 2000 took 0.035s
  training loss:		0.004395
  validation loss:		0.460151
  validation accuracy:		93.59 %
Epoch 1709 of 2000 took 0.035s
  training loss:		0.004234
  validation loss:		0.466622
  validation accuracy:		93.48 %
Epoch 1710 of 2000 took 0.035s
  training loss:		0.004381
  validation loss:		0.461688
  validation accuracy:		93.48 %
Epoch 1711 of 2000 took 0.035s
  training loss:		0.004211
  validation loss:		0.458009
  validation accuracy:		93.26 %
Epoch 1712 of 2000 took 0.035s
  training loss:		0.004248
  validation loss:		0.460108
  validation accuracy:		93.70 %
Epoch 1713 of 2000 took 0.035s
  training loss:		0.004411
  validation loss:		0.465198
  validation accuracy:		93.48 %
Epoch 1714 of 2000 took 0.035s
  training loss:		0.004303
  validation loss:		0.468754
  validation accuracy:		93.48 %
Epoch 1715 of 2000 took 0.035s
  training loss:		0.004352
  validation loss:		0.462467
  validation accuracy:		93.48 %
Epoch 1716 of 2000 took 0.035s
  training loss:		0.004305
  validation loss:		0.462695
  validation accuracy:		93.48 %
Epoch 1717 of 2000 took 0.035s
  training loss:		0.004385
  validation loss:		0.465174
  validation accuracy:		93.37 %
Epoch 1718 of 2000 took 0.035s
  training loss:		0.004324
  validation loss:		0.465647
  validation accuracy:		93.48 %
Epoch 1719 of 2000 took 0.035s
  training loss:		0.004284
  validation loss:		0.461629
  validation accuracy:		93.37 %
Epoch 1720 of 2000 took 0.035s
  training loss:		0.004326
  validation loss:		0.466201
  validation accuracy:		93.59 %
Epoch 1721 of 2000 took 0.035s
  training loss:		0.004223
  validation loss:		0.463701
  validation accuracy:		93.48 %
Epoch 1722 of 2000 took 0.035s
  training loss:		0.004196
  validation loss:		0.468456
  validation accuracy:		93.26 %
Epoch 1723 of 2000 took 0.035s
  training loss:		0.004168
  validation loss:		0.466422
  validation accuracy:		93.48 %
Epoch 1724 of 2000 took 0.035s
  training loss:		0.004187
  validation loss:		0.465621
  validation accuracy:		93.37 %
Epoch 1725 of 2000 took 0.035s
  training loss:		0.004343
  validation loss:		0.465909
  validation accuracy:		93.37 %
Epoch 1726 of 2000 took 0.035s
  training loss:		0.003942
  validation loss:		0.461599
  validation accuracy:		93.48 %
Epoch 1727 of 2000 took 0.035s
  training loss:		0.004212
  validation loss:		0.465486
  validation accuracy:		93.59 %
Epoch 1728 of 2000 took 0.035s
  training loss:		0.004165
  validation loss:		0.469904
  validation accuracy:		93.37 %
Epoch 1729 of 2000 took 0.035s
  training loss:		0.004211
  validation loss:		0.466710
  validation accuracy:		93.48 %
Epoch 1730 of 2000 took 0.035s
  training loss:		0.004215
  validation loss:		0.462555
  validation accuracy:		93.37 %
Epoch 1731 of 2000 took 0.035s
  training loss:		0.004026
  validation loss:		0.466026
  validation accuracy:		93.37 %
Epoch 1732 of 2000 took 0.035s
  training loss:		0.004172
  validation loss:		0.462786
  validation accuracy:		93.59 %
Epoch 1733 of 2000 took 0.035s
  training loss:		0.004201
  validation loss:		0.465774
  validation accuracy:		93.48 %
Epoch 1734 of 2000 took 0.035s
  training loss:		0.004172
  validation loss:		0.465324
  validation accuracy:		93.37 %
Epoch 1735 of 2000 took 0.035s
  training loss:		0.004197
  validation loss:		0.465005
  validation accuracy:		93.48 %
Epoch 1736 of 2000 took 0.035s
  training loss:		0.004266
  validation loss:		0.466986
  validation accuracy:		93.37 %
Epoch 1737 of 2000 took 0.035s
  training loss:		0.004106
  validation loss:		0.470412
  validation accuracy:		93.37 %
Epoch 1738 of 2000 took 0.035s
  training loss:		0.004050
  validation loss:		0.469042
  validation accuracy:		93.48 %
Epoch 1739 of 2000 took 0.035s
  training loss:		0.004302
  validation loss:		0.465724
  validation accuracy:		93.37 %
Epoch 1740 of 2000 took 0.035s
  training loss:		0.004101
  validation loss:		0.472760
  validation accuracy:		93.37 %
Epoch 1741 of 2000 took 0.035s
  training loss:		0.004149
  validation loss:		0.466785
  validation accuracy:		93.48 %
Epoch 1742 of 2000 took 0.035s
  training loss:		0.004060
  validation loss:		0.467602
  validation accuracy:		93.48 %
Epoch 1743 of 2000 took 0.035s
  training loss:		0.004219
  validation loss:		0.465770
  validation accuracy:		93.48 %
Epoch 1744 of 2000 took 0.035s
  training loss:		0.004112
  validation loss:		0.467032
  validation accuracy:		93.70 %
Epoch 1745 of 2000 took 0.036s
  training loss:		0.004153
  validation loss:		0.472648
  validation accuracy:		93.37 %
Epoch 1746 of 2000 took 0.035s
  training loss:		0.004279
  validation loss:		0.474428
  validation accuracy:		93.26 %
Epoch 1747 of 2000 took 0.035s
  training loss:		0.004199
  validation loss:		0.468153
  validation accuracy:		93.59 %
Epoch 1748 of 2000 took 0.035s
  training loss:		0.004053
  validation loss:		0.469626
  validation accuracy:		93.48 %
Epoch 1749 of 2000 took 0.035s
  training loss:		0.004022
  validation loss:		0.469749
  validation accuracy:		93.37 %
Epoch 1750 of 2000 took 0.035s
  training loss:		0.004145
  validation loss:		0.472865
  validation accuracy:		93.37 %
Epoch 1751 of 2000 took 0.035s
  training loss:		0.003842
  validation loss:		0.467827
  validation accuracy:		93.48 %
Epoch 1752 of 2000 took 0.035s
  training loss:		0.003912
  validation loss:		0.473096
  validation accuracy:		93.48 %
Epoch 1753 of 2000 took 0.035s
  training loss:		0.004144
  validation loss:		0.468520
  validation accuracy:		93.37 %
Epoch 1754 of 2000 took 0.035s
  training loss:		0.004091
  validation loss:		0.471161
  validation accuracy:		93.48 %
Epoch 1755 of 2000 took 0.035s
  training loss:		0.004021
  validation loss:		0.470568
  validation accuracy:		93.37 %
Epoch 1756 of 2000 took 0.035s
  training loss:		0.004111
  validation loss:		0.469721
  validation accuracy:		93.59 %
Epoch 1757 of 2000 took 0.035s
  training loss:		0.004212
  validation loss:		0.468978
  validation accuracy:		93.48 %
Epoch 1758 of 2000 took 0.035s
  training loss:		0.004095
  validation loss:		0.475671
  validation accuracy:		93.37 %
Epoch 1759 of 2000 took 0.035s
  training loss:		0.004092
  validation loss:		0.467872
  validation accuracy:		93.37 %
Epoch 1760 of 2000 took 0.035s
  training loss:		0.003952
  validation loss:		0.474191
  validation accuracy:		93.48 %
Epoch 1761 of 2000 took 0.036s
  training loss:		0.004084
  validation loss:		0.471349
  validation accuracy:		93.48 %
Epoch 1762 of 2000 took 0.035s
  training loss:		0.004056
  validation loss:		0.471134
  validation accuracy:		93.59 %
Epoch 1763 of 2000 took 0.035s
  training loss:		0.003858
  validation loss:		0.467541
  validation accuracy:		93.37 %
Epoch 1764 of 2000 took 0.035s
  training loss:		0.003990
  validation loss:		0.468233
  validation accuracy:		93.48 %
Epoch 1765 of 2000 took 0.035s
  training loss:		0.003982
  validation loss:		0.467923
  validation accuracy:		93.70 %
Epoch 1766 of 2000 took 0.035s
  training loss:		0.003997
  validation loss:		0.466850
  validation accuracy:		93.37 %
Epoch 1767 of 2000 took 0.035s
  training loss:		0.003981
  validation loss:		0.474236
  validation accuracy:		93.48 %
Epoch 1768 of 2000 took 0.035s
  training loss:		0.003977
  validation loss:		0.471842
  validation accuracy:		93.37 %
Epoch 1769 of 2000 took 0.035s
  training loss:		0.004037
  validation loss:		0.474456
  validation accuracy:		93.48 %
Epoch 1770 of 2000 took 0.035s
  training loss:		0.003860
  validation loss:		0.469989
  validation accuracy:		93.37 %
Epoch 1771 of 2000 took 0.035s
  training loss:		0.003957
  validation loss:		0.472987
  validation accuracy:		93.48 %
Epoch 1772 of 2000 took 0.036s
  training loss:		0.003898
  validation loss:		0.469823
  validation accuracy:		93.48 %
Epoch 1773 of 2000 took 0.035s
  training loss:		0.003991
  validation loss:		0.473099
  validation accuracy:		93.37 %
Epoch 1774 of 2000 took 0.035s
  training loss:		0.003912
  validation loss:		0.465790
  validation accuracy:		93.70 %
Epoch 1775 of 2000 took 0.035s
  training loss:		0.003892
  validation loss:		0.476044
  validation accuracy:		93.37 %
Epoch 1776 of 2000 took 0.035s
  training loss:		0.003921
  validation loss:		0.469833
  validation accuracy:		93.59 %
Epoch 1777 of 2000 took 0.035s
  training loss:		0.004013
  validation loss:		0.473540
  validation accuracy:		93.48 %
Epoch 1778 of 2000 took 0.035s
  training loss:		0.003970
  validation loss:		0.474274
  validation accuracy:		93.37 %
Epoch 1779 of 2000 took 0.035s
  training loss:		0.003966
  validation loss:		0.472776
  validation accuracy:		93.37 %
Epoch 1780 of 2000 took 0.035s
  training loss:		0.003907
  validation loss:		0.474376
  validation accuracy:		93.48 %
Epoch 1781 of 2000 took 0.035s
  training loss:		0.003853
  validation loss:		0.473918
  validation accuracy:		93.48 %
Epoch 1782 of 2000 took 0.035s
  training loss:		0.004031
  validation loss:		0.474616
  validation accuracy:		93.59 %
Epoch 1783 of 2000 took 0.035s
  training loss:		0.003941
  validation loss:		0.474961
  validation accuracy:		93.48 %
Epoch 1784 of 2000 took 0.035s
  training loss:		0.003950
  validation loss:		0.473821
  validation accuracy:		93.48 %
Epoch 1785 of 2000 took 0.035s
  training loss:		0.003900
  validation loss:		0.473910
  validation accuracy:		93.48 %
Epoch 1786 of 2000 took 0.035s
  training loss:		0.004065
  validation loss:		0.472127
  validation accuracy:		93.48 %
Epoch 1787 of 2000 took 0.035s
  training loss:		0.003897
  validation loss:		0.473724
  validation accuracy:		93.26 %
Epoch 1788 of 2000 took 0.035s
  training loss:		0.003904
  validation loss:		0.475728
  validation accuracy:		93.48 %
Epoch 1789 of 2000 took 0.035s
  training loss:		0.003821
  validation loss:		0.470451
  validation accuracy:		93.70 %
Epoch 1790 of 2000 took 0.035s
  training loss:		0.003875
  validation loss:		0.475681
  validation accuracy:		93.26 %
Epoch 1791 of 2000 took 0.035s
  training loss:		0.003875
  validation loss:		0.472131
  validation accuracy:		93.59 %
Epoch 1792 of 2000 took 0.035s
  training loss:		0.003895
  validation loss:		0.472816
  validation accuracy:		93.26 %
Epoch 1793 of 2000 took 0.035s
  training loss:		0.003936
  validation loss:		0.474851
  validation accuracy:		93.48 %
Epoch 1794 of 2000 took 0.035s
  training loss:		0.003852
  validation loss:		0.474114
  validation accuracy:		93.26 %
Epoch 1795 of 2000 took 0.035s
  training loss:		0.003886
  validation loss:		0.474638
  validation accuracy:		93.37 %
Epoch 1796 of 2000 took 0.035s
  training loss:		0.003947
  validation loss:		0.477761
  validation accuracy:		93.48 %
Epoch 1797 of 2000 took 0.035s
  training loss:		0.003949
  validation loss:		0.479781
  validation accuracy:		93.37 %
Epoch 1798 of 2000 took 0.035s
  training loss:		0.003928
  validation loss:		0.473329
  validation accuracy:		93.37 %
Epoch 1799 of 2000 took 0.035s
  training loss:		0.003777
  validation loss:		0.473080
  validation accuracy:		93.70 %
Epoch 1800 of 2000 took 0.035s
  training loss:		0.003917
  validation loss:		0.481713
  validation accuracy:		93.26 %
Epoch 1801 of 2000 took 0.035s
  training loss:		0.003856
  validation loss:		0.473017
  validation accuracy:		93.26 %
Epoch 1802 of 2000 took 0.036s
  training loss:		0.003832
  validation loss:		0.475744
  validation accuracy:		93.48 %
Epoch 1803 of 2000 took 0.035s
  training loss:		0.003796
  validation loss:		0.475441
  validation accuracy:		93.59 %
Epoch 1804 of 2000 took 0.035s
  training loss:		0.003725
  validation loss:		0.474253
  validation accuracy:		93.48 %
Epoch 1805 of 2000 took 0.035s
  training loss:		0.003759
  validation loss:		0.474765
  validation accuracy:		93.37 %
Epoch 1806 of 2000 took 0.035s
  training loss:		0.003850
  validation loss:		0.475668
  validation accuracy:		93.59 %
Epoch 1807 of 2000 took 0.035s
  training loss:		0.003843
  validation loss:		0.478654
  validation accuracy:		93.26 %
Epoch 1808 of 2000 took 0.035s
  training loss:		0.003762
  validation loss:		0.477477
  validation accuracy:		93.48 %
Epoch 1809 of 2000 took 0.035s
  training loss:		0.003799
  validation loss:		0.475644
  validation accuracy:		93.48 %
Epoch 1810 of 2000 took 0.035s
  training loss:		0.003660
  validation loss:		0.475523
  validation accuracy:		93.48 %
Epoch 1811 of 2000 took 0.035s
  training loss:		0.003794
  validation loss:		0.477545
  validation accuracy:		93.59 %
Epoch 1812 of 2000 took 0.035s
  training loss:		0.003679
  validation loss:		0.475843
  validation accuracy:		93.37 %
Epoch 1813 of 2000 took 0.035s
  training loss:		0.003837
  validation loss:		0.475187
  validation accuracy:		93.37 %
Epoch 1814 of 2000 took 0.035s
  training loss:		0.003779
  validation loss:		0.475594
  validation accuracy:		93.26 %
Epoch 1815 of 2000 took 0.035s
  training loss:		0.003805
  validation loss:		0.473964
  validation accuracy:		93.48 %
Epoch 1816 of 2000 took 0.035s
  training loss:		0.003800
  validation loss:		0.475941
  validation accuracy:		93.48 %
Epoch 1817 of 2000 took 0.035s
  training loss:		0.003737
  validation loss:		0.477542
  validation accuracy:		93.48 %
Epoch 1818 of 2000 took 0.035s
  training loss:		0.003735
  validation loss:		0.480841
  validation accuracy:		93.37 %
Epoch 1819 of 2000 took 0.035s
  training loss:		0.003794
  validation loss:		0.479038
  validation accuracy:		93.70 %
Epoch 1820 of 2000 took 0.035s
  training loss:		0.003734
  validation loss:		0.476226
  validation accuracy:		93.26 %
Epoch 1821 of 2000 took 0.035s
  training loss:		0.003632
  validation loss:		0.477777
  validation accuracy:		93.48 %
Epoch 1822 of 2000 took 0.035s
  training loss:		0.003766
  validation loss:		0.477791
  validation accuracy:		93.26 %
Epoch 1823 of 2000 took 0.035s
  training loss:		0.003816
  validation loss:		0.480406
  validation accuracy:		93.59 %
Epoch 1824 of 2000 took 0.035s
  training loss:		0.003628
  validation loss:		0.477286
  validation accuracy:		93.26 %
Epoch 1825 of 2000 took 0.035s
  training loss:		0.003712
  validation loss:		0.474456
  validation accuracy:		93.48 %
Epoch 1826 of 2000 took 0.035s
  training loss:		0.003758
  validation loss:		0.477703
  validation accuracy:		93.37 %
Epoch 1827 of 2000 took 0.035s
  training loss:		0.003731
  validation loss:		0.480970
  validation accuracy:		93.59 %
Epoch 1828 of 2000 took 0.035s
  training loss:		0.003717
  validation loss:		0.482099
  validation accuracy:		93.26 %
Epoch 1829 of 2000 took 0.035s
  training loss:		0.003770
  validation loss:		0.478200
  validation accuracy:		93.37 %
Epoch 1830 of 2000 took 0.035s
  training loss:		0.003659
  validation loss:		0.483221
  validation accuracy:		93.26 %
Epoch 1831 of 2000 took 0.035s
  training loss:		0.003650
  validation loss:		0.477927
  validation accuracy:		93.48 %
Epoch 1832 of 2000 took 0.035s
  training loss:		0.003703
  validation loss:		0.477521
  validation accuracy:		93.37 %
Epoch 1833 of 2000 took 0.035s
  training loss:		0.003580
  validation loss:		0.478107
  validation accuracy:		93.59 %
Epoch 1834 of 2000 took 0.035s
  training loss:		0.003808
  validation loss:		0.480790
  validation accuracy:		93.59 %
Epoch 1835 of 2000 took 0.035s
  training loss:		0.003652
  validation loss:		0.475702
  validation accuracy:		93.37 %
Epoch 1836 of 2000 took 0.035s
  training loss:		0.003683
  validation loss:		0.484656
  validation accuracy:		93.37 %
Epoch 1837 of 2000 took 0.035s
  training loss:		0.003662
  validation loss:		0.478146
  validation accuracy:		93.26 %
Epoch 1838 of 2000 took 0.035s
  training loss:		0.003668
  validation loss:		0.481518
  validation accuracy:		93.59 %
Epoch 1839 of 2000 took 0.035s
  training loss:		0.003745
  validation loss:		0.481407
  validation accuracy:		93.70 %
Epoch 1840 of 2000 took 0.035s
  training loss:		0.003751
  validation loss:		0.480235
  validation accuracy:		93.26 %
Epoch 1841 of 2000 took 0.035s
  training loss:		0.003478
  validation loss:		0.480839
  validation accuracy:		93.48 %
Epoch 1842 of 2000 took 0.035s
  training loss:		0.003631
  validation loss:		0.480168
  validation accuracy:		93.48 %
Epoch 1843 of 2000 took 0.035s
  training loss:		0.003650
  validation loss:		0.481658
  validation accuracy:		93.37 %
Epoch 1844 of 2000 took 0.035s
  training loss:		0.003653
  validation loss:		0.484129
  validation accuracy:		93.48 %
Epoch 1845 of 2000 took 0.035s
  training loss:		0.003717
  validation loss:		0.481601
  validation accuracy:		93.37 %
Epoch 1846 of 2000 took 0.036s
  training loss:		0.003490
  validation loss:		0.478715
  validation accuracy:		93.70 %
Epoch 1847 of 2000 took 0.035s
  training loss:		0.003576
  validation loss:		0.482290
  validation accuracy:		93.48 %
Epoch 1848 of 2000 took 0.035s
  training loss:		0.003594
  validation loss:		0.477923
  validation accuracy:		93.37 %
Epoch 1849 of 2000 took 0.035s
  training loss:		0.003692
  validation loss:		0.481754
  validation accuracy:		93.48 %
Epoch 1850 of 2000 took 0.035s
  training loss:		0.003602
  validation loss:		0.478725
  validation accuracy:		93.80 %
Epoch 1851 of 2000 took 0.035s
  training loss:		0.003684
  validation loss:		0.483402
  validation accuracy:		93.26 %
Epoch 1852 of 2000 took 0.035s
  training loss:		0.003482
  validation loss:		0.479099
  validation accuracy:		93.70 %
Epoch 1853 of 2000 took 0.035s
  training loss:		0.003572
  validation loss:		0.484718
  validation accuracy:		93.37 %
Epoch 1854 of 2000 took 0.035s
  training loss:		0.003520
  validation loss:		0.484259
  validation accuracy:		93.59 %
Epoch 1855 of 2000 took 0.035s
  training loss:		0.003533
  validation loss:		0.479853
  validation accuracy:		93.37 %
Epoch 1856 of 2000 took 0.035s
  training loss:		0.003566
  validation loss:		0.485525
  validation accuracy:		93.37 %
Epoch 1857 of 2000 took 0.035s
  training loss:		0.003619
  validation loss:		0.483011
  validation accuracy:		93.37 %
Epoch 1858 of 2000 took 0.036s
  training loss:		0.003663
  validation loss:		0.482092
  validation accuracy:		93.48 %
Epoch 1859 of 2000 took 0.035s
  training loss:		0.003650
  validation loss:		0.481814
  validation accuracy:		93.48 %
Epoch 1860 of 2000 took 0.035s
  training loss:		0.003562
  validation loss:		0.485921
  validation accuracy:		93.48 %
Epoch 1861 of 2000 took 0.035s
  training loss:		0.003519
  validation loss:		0.484278
  validation accuracy:		93.37 %
Epoch 1862 of 2000 took 0.035s
  training loss:		0.003628
  validation loss:		0.477475
  validation accuracy:		93.59 %
Epoch 1863 of 2000 took 0.035s
  training loss:		0.003629
  validation loss:		0.487282
  validation accuracy:		93.37 %
Epoch 1864 of 2000 took 0.035s
  training loss:		0.003564
  validation loss:		0.481171
  validation accuracy:		93.37 %
Epoch 1865 of 2000 took 0.035s
  training loss:		0.003526
  validation loss:		0.487601
  validation accuracy:		93.37 %
Epoch 1866 of 2000 took 0.035s
  training loss:		0.003503
  validation loss:		0.485596
  validation accuracy:		93.37 %
Epoch 1867 of 2000 took 0.035s
  training loss:		0.003550
  validation loss:		0.480003
  validation accuracy:		93.59 %
Epoch 1868 of 2000 took 0.035s
  training loss:		0.003410
  validation loss:		0.481991
  validation accuracy:		93.48 %
Epoch 1869 of 2000 took 0.035s
  training loss:		0.003534
  validation loss:		0.483799
  validation accuracy:		93.26 %
Epoch 1870 of 2000 took 0.035s
  training loss:		0.003569
  validation loss:		0.486417
  validation accuracy:		93.70 %
Epoch 1871 of 2000 took 0.035s
  training loss:		0.003605
  validation loss:		0.480091
  validation accuracy:		93.59 %
Epoch 1872 of 2000 took 0.035s
  training loss:		0.003546
  validation loss:		0.486603
  validation accuracy:		93.37 %
Epoch 1873 of 2000 took 0.035s
  training loss:		0.003620
  validation loss:		0.481747
  validation accuracy:		93.70 %
Epoch 1874 of 2000 took 0.035s
  training loss:		0.003588
  validation loss:		0.486760
  validation accuracy:		93.26 %
Epoch 1875 of 2000 took 0.035s
  training loss:		0.003475
  validation loss:		0.482252
  validation accuracy:		93.70 %
Epoch 1876 of 2000 took 0.035s
  training loss:		0.003481
  validation loss:		0.483817
  validation accuracy:		93.37 %
Epoch 1877 of 2000 took 0.035s
  training loss:		0.003595
  validation loss:		0.484928
  validation accuracy:		93.26 %
Epoch 1878 of 2000 took 0.035s
  training loss:		0.003420
  validation loss:		0.488347
  validation accuracy:		93.37 %
Epoch 1879 of 2000 took 0.035s
  training loss:		0.003552
  validation loss:		0.482916
  validation accuracy:		93.59 %
Epoch 1880 of 2000 took 0.035s
  training loss:		0.003523
  validation loss:		0.483039
  validation accuracy:		93.48 %
Epoch 1881 of 2000 took 0.035s
  training loss:		0.003364
  validation loss:		0.486556
  validation accuracy:		93.37 %
Epoch 1882 of 2000 took 0.035s
  training loss:		0.003368
  validation loss:		0.484804
  validation accuracy:		93.26 %
Epoch 1883 of 2000 took 0.035s
  training loss:		0.003532
  validation loss:		0.489198
  validation accuracy:		93.48 %
Epoch 1884 of 2000 took 0.035s
  training loss:		0.003395
  validation loss:		0.483862
  validation accuracy:		93.48 %
Epoch 1885 of 2000 took 0.035s
  training loss:		0.003389
  validation loss:		0.489905
  validation accuracy:		93.26 %
Epoch 1886 of 2000 took 0.035s
  training loss:		0.003482
  validation loss:		0.486027
  validation accuracy:		93.59 %
Epoch 1887 of 2000 took 0.035s
  training loss:		0.003438
  validation loss:		0.494345
  validation accuracy:		93.26 %
Epoch 1888 of 2000 took 0.035s
  training loss:		0.003547
  validation loss:		0.482875
  validation accuracy:		93.59 %
Epoch 1889 of 2000 took 0.035s
  training loss:		0.003524
  validation loss:		0.485847
  validation accuracy:		93.37 %
Epoch 1890 of 2000 took 0.035s
  training loss:		0.003384
  validation loss:		0.487393
  validation accuracy:		93.26 %
Epoch 1891 of 2000 took 0.035s
  training loss:		0.003383
  validation loss:		0.481956
  validation accuracy:		93.26 %
Epoch 1892 of 2000 took 0.035s
  training loss:		0.003391
  validation loss:		0.490877
  validation accuracy:		93.37 %
Epoch 1893 of 2000 took 0.035s
  training loss:		0.003452
  validation loss:		0.488760
  validation accuracy:		93.59 %
Epoch 1894 of 2000 took 0.035s
  training loss:		0.003399
  validation loss:		0.484224
  validation accuracy:		93.48 %
Epoch 1895 of 2000 took 0.035s
  training loss:		0.003387
  validation loss:		0.487521
  validation accuracy:		93.37 %
Epoch 1896 of 2000 took 0.035s
  training loss:		0.003455
  validation loss:		0.487105
  validation accuracy:		93.70 %
Epoch 1897 of 2000 took 0.035s
  training loss:		0.003453
  validation loss:		0.486310
  validation accuracy:		93.26 %
Epoch 1898 of 2000 took 0.035s
  training loss:		0.003464
  validation loss:		0.485646
  validation accuracy:		93.59 %
Epoch 1899 of 2000 took 0.035s
  training loss:		0.003370
  validation loss:		0.490102
  validation accuracy:		93.37 %
Epoch 1900 of 2000 took 0.035s
  training loss:		0.003396
  validation loss:		0.489146
  validation accuracy:		93.59 %
Epoch 1901 of 2000 took 0.035s
  training loss:		0.003396
  validation loss:		0.490621
  validation accuracy:		93.26 %
Epoch 1902 of 2000 took 0.035s
  training loss:		0.003444
  validation loss:		0.484851
  validation accuracy:		93.59 %
Epoch 1903 of 2000 took 0.035s
  training loss:		0.003431
  validation loss:		0.489582
  validation accuracy:		93.26 %
Epoch 1904 of 2000 took 0.035s
  training loss:		0.003369
  validation loss:		0.490968
  validation accuracy:		93.37 %
Epoch 1905 of 2000 took 0.035s
  training loss:		0.003313
  validation loss:		0.489862
  validation accuracy:		93.37 %
Epoch 1906 of 2000 took 0.035s
  training loss:		0.003374
  validation loss:		0.488424
  validation accuracy:		93.48 %
Epoch 1907 of 2000 took 0.035s
  training loss:		0.003389
  validation loss:		0.489740
  validation accuracy:		93.48 %
Epoch 1908 of 2000 took 0.035s
  training loss:		0.003449
  validation loss:		0.489808
  validation accuracy:		93.26 %
Epoch 1909 of 2000 took 0.035s
  training loss:		0.003421
  validation loss:		0.484204
  validation accuracy:		93.59 %
Epoch 1910 of 2000 took 0.035s
  training loss:		0.003291
  validation loss:		0.493939
  validation accuracy:		93.48 %
Epoch 1911 of 2000 took 0.035s
  training loss:		0.003338
  validation loss:		0.489200
  validation accuracy:		93.26 %
Epoch 1912 of 2000 took 0.035s
  training loss:		0.003368
  validation loss:		0.489141
  validation accuracy:		93.26 %
Epoch 1913 of 2000 took 0.035s
  training loss:		0.003348
  validation loss:		0.489043
  validation accuracy:		93.48 %
Epoch 1914 of 2000 took 0.035s
  training loss:		0.003301
  validation loss:		0.488930
  validation accuracy:		93.37 %
Epoch 1915 of 2000 took 0.035s
  training loss:		0.003391
  validation loss:		0.492536
  validation accuracy:		93.37 %
Epoch 1916 of 2000 took 0.035s
  training loss:		0.003344
  validation loss:		0.484125
  validation accuracy:		93.48 %
Epoch 1917 of 2000 took 0.035s
  training loss:		0.003408
  validation loss:		0.489528
  validation accuracy:		93.26 %
Epoch 1918 of 2000 took 0.035s
  training loss:		0.003425
  validation loss:		0.496804
  validation accuracy:		93.26 %
Epoch 1919 of 2000 took 0.035s
  training loss:		0.003290
  validation loss:		0.488686
  validation accuracy:		93.26 %
Epoch 1920 of 2000 took 0.035s
  training loss:		0.003311
  validation loss:		0.491275
  validation accuracy:		93.59 %
Epoch 1921 of 2000 took 0.035s
  training loss:		0.003318
  validation loss:		0.497637
  validation accuracy:		93.37 %
Epoch 1922 of 2000 took 0.035s
  training loss:		0.003308
  validation loss:		0.485896
  validation accuracy:		93.48 %
Epoch 1923 of 2000 took 0.035s
  training loss:		0.003310
  validation loss:		0.491204
  validation accuracy:		93.26 %
Epoch 1924 of 2000 took 0.035s
  training loss:		0.003314
  validation loss:		0.490455
  validation accuracy:		93.26 %
Epoch 1925 of 2000 took 0.035s
  training loss:		0.003315
  validation loss:		0.493076
  validation accuracy:		93.59 %
Epoch 1926 of 2000 took 0.035s
  training loss:		0.003293
  validation loss:		0.491046
  validation accuracy:		93.48 %
Epoch 1927 of 2000 took 0.035s
  training loss:		0.003328
  validation loss:		0.494870
  validation accuracy:		93.26 %
Epoch 1928 of 2000 took 0.035s
  training loss:		0.003172
  validation loss:		0.488377
  validation accuracy:		93.37 %
Epoch 1929 of 2000 took 0.035s
  training loss:		0.003259
  validation loss:		0.488558
  validation accuracy:		93.59 %
Epoch 1930 of 2000 took 0.035s
  training loss:		0.003209
  validation loss:		0.494656
  validation accuracy:		93.37 %
Epoch 1931 of 2000 took 0.036s
  training loss:		0.003247
  validation loss:		0.490213
  validation accuracy:		93.48 %
Epoch 1932 of 2000 took 0.035s
  training loss:		0.003305
  validation loss:		0.491860
  validation accuracy:		93.26 %
Epoch 1933 of 2000 took 0.035s
  training loss:		0.003248
  validation loss:		0.492055
  validation accuracy:		93.59 %
Epoch 1934 of 2000 took 0.035s
  training loss:		0.003211
  validation loss:		0.492969
  validation accuracy:		93.37 %
Epoch 1935 of 2000 took 0.035s
  training loss:		0.003328
  validation loss:		0.490805
  validation accuracy:		93.26 %
Epoch 1936 of 2000 took 0.035s
  training loss:		0.003231
  validation loss:		0.491000
  validation accuracy:		93.59 %
Epoch 1937 of 2000 took 0.035s
  training loss:		0.003164
  validation loss:		0.492485
  validation accuracy:		93.59 %
Epoch 1938 of 2000 took 0.035s
  training loss:		0.003233
  validation loss:		0.494393
  validation accuracy:		93.26 %
Epoch 1939 of 2000 took 0.035s
  training loss:		0.003198
  validation loss:		0.490646
  validation accuracy:		93.59 %
Epoch 1940 of 2000 took 0.035s
  training loss:		0.003249
  validation loss:		0.493252
  validation accuracy:		93.48 %
Epoch 1941 of 2000 took 0.035s
  training loss:		0.003255
  validation loss:		0.495655
  validation accuracy:		93.48 %
Epoch 1942 of 2000 took 0.035s
  training loss:		0.003265
  validation loss:		0.489930
  validation accuracy:		93.48 %
Epoch 1943 of 2000 took 0.035s
  training loss:		0.003229
  validation loss:		0.492719
  validation accuracy:		93.37 %
Epoch 1944 of 2000 took 0.035s
  training loss:		0.003237
  validation loss:		0.493822
  validation accuracy:		93.37 %
Epoch 1945 of 2000 took 0.035s
  training loss:		0.003163
  validation loss:		0.495784
  validation accuracy:		93.59 %
Epoch 1946 of 2000 took 0.035s
  training loss:		0.003260
  validation loss:		0.496298
  validation accuracy:		93.26 %
Epoch 1947 of 2000 took 0.035s
  training loss:		0.003213
  validation loss:		0.491027
  validation accuracy:		93.48 %
Epoch 1948 of 2000 took 0.035s
  training loss:		0.003232
  validation loss:		0.493739
  validation accuracy:		93.37 %
Epoch 1949 of 2000 took 0.035s
  training loss:		0.003151
  validation loss:		0.492224
  validation accuracy:		93.48 %
Epoch 1950 of 2000 took 0.035s
  training loss:		0.003201
  validation loss:		0.496497
  validation accuracy:		93.48 %
Epoch 1951 of 2000 took 0.035s
  training loss:		0.003204
  validation loss:		0.489138
  validation accuracy:		93.59 %
Epoch 1952 of 2000 took 0.035s
  training loss:		0.003118
  validation loss:		0.495171
  validation accuracy:		93.26 %
Epoch 1953 of 2000 took 0.035s
  training loss:		0.003131
  validation loss:		0.495596
  validation accuracy:		93.26 %
Epoch 1954 of 2000 took 0.035s
  training loss:		0.003183
  validation loss:		0.490962
  validation accuracy:		93.48 %
Epoch 1955 of 2000 took 0.035s
  training loss:		0.003196
  validation loss:		0.493326
  validation accuracy:		93.59 %
Epoch 1956 of 2000 took 0.035s
  training loss:		0.003204
  validation loss:		0.497301
  validation accuracy:		93.37 %
Epoch 1957 of 2000 took 0.035s
  training loss:		0.003177
  validation loss:		0.498265
  validation accuracy:		93.37 %
Epoch 1958 of 2000 took 0.035s
  training loss:		0.003182
  validation loss:		0.495080
  validation accuracy:		93.59 %
Epoch 1959 of 2000 took 0.035s
  training loss:		0.003183
  validation loss:		0.496215
  validation accuracy:		93.26 %
Epoch 1960 of 2000 took 0.035s
  training loss:		0.003236
  validation loss:		0.491092
  validation accuracy:		93.59 %
Epoch 1961 of 2000 took 0.035s
  training loss:		0.003110
  validation loss:		0.497324
  validation accuracy:		93.48 %
Epoch 1962 of 2000 took 0.035s
  training loss:		0.003169
  validation loss:		0.496724
  validation accuracy:		93.37 %
Epoch 1963 of 2000 took 0.035s
  training loss:		0.003095
  validation loss:		0.494765
  validation accuracy:		93.48 %
Epoch 1964 of 2000 took 0.035s
  training loss:		0.003157
  validation loss:		0.495515
  validation accuracy:		93.48 %
Epoch 1965 of 2000 took 0.035s
  training loss:		0.003093
  validation loss:		0.495500
  validation accuracy:		93.37 %
Epoch 1966 of 2000 took 0.035s
  training loss:		0.003249
  validation loss:		0.496759
  validation accuracy:		93.48 %
Epoch 1967 of 2000 took 0.035s
  training loss:		0.003026
  validation loss:		0.492518
  validation accuracy:		93.48 %
Epoch 1968 of 2000 took 0.035s
  training loss:		0.003049
  validation loss:		0.494462
  validation accuracy:		93.48 %
Epoch 1969 of 2000 took 0.035s
  training loss:		0.003192
  validation loss:		0.496446
  validation accuracy:		93.26 %
Epoch 1970 of 2000 took 0.035s
  training loss:		0.003182
  validation loss:		0.495675
  validation accuracy:		93.59 %
Epoch 1971 of 2000 took 0.036s
  training loss:		0.003031
  validation loss:		0.494775
  validation accuracy:		93.48 %
Epoch 1972 of 2000 took 0.035s
  training loss:		0.003166
  validation loss:		0.495539
  validation accuracy:		93.48 %
Epoch 1973 of 2000 took 0.035s
  training loss:		0.003143
  validation loss:		0.498229
  validation accuracy:		93.37 %
Epoch 1974 of 2000 took 0.035s
  training loss:		0.003152
  validation loss:		0.499928
  validation accuracy:		93.48 %
Epoch 1975 of 2000 took 0.035s
  training loss:		0.003171
  validation loss:		0.495172
  validation accuracy:		93.37 %
Epoch 1976 of 2000 took 0.035s
  training loss:		0.003131
  validation loss:		0.496436
  validation accuracy:		93.48 %
Epoch 1977 of 2000 took 0.035s
  training loss:		0.003050
  validation loss:		0.496737
  validation accuracy:		93.59 %
Epoch 1978 of 2000 took 0.035s
  training loss:		0.003170
  validation loss:		0.498801
  validation accuracy:		93.48 %
Epoch 1979 of 2000 took 0.035s
  training loss:		0.003117
  validation loss:		0.495752
  validation accuracy:		93.59 %
Epoch 1980 of 2000 took 0.035s
  training loss:		0.003080
  validation loss:		0.493724
  validation accuracy:		93.48 %
Epoch 1981 of 2000 took 0.035s
  training loss:		0.003067
  validation loss:		0.498293
  validation accuracy:		93.37 %
Epoch 1982 of 2000 took 0.035s
  training loss:		0.003152
  validation loss:		0.499684
  validation accuracy:		93.37 %
Epoch 1983 of 2000 took 0.035s
  training loss:		0.003105
  validation loss:		0.497084
  validation accuracy:		93.48 %
Epoch 1984 of 2000 took 0.035s
  training loss:		0.003082
  validation loss:		0.497053
  validation accuracy:		93.26 %
Epoch 1985 of 2000 took 0.035s
  training loss:		0.003222
  validation loss:		0.498067
  validation accuracy:		93.48 %
Epoch 1986 of 2000 took 0.035s
  training loss:		0.003085
  validation loss:		0.497771
  validation accuracy:		93.37 %
Epoch 1987 of 2000 took 0.035s
  training loss:		0.003100
  validation loss:		0.493443
  validation accuracy:		93.59 %
Epoch 1988 of 2000 took 0.035s
  training loss:		0.003054
  validation loss:		0.500091
  validation accuracy:		93.37 %
Epoch 1989 of 2000 took 0.035s
  training loss:		0.003096
  validation loss:		0.496183
  validation accuracy:		93.37 %
Epoch 1990 of 2000 took 0.035s
  training loss:		0.002976
  validation loss:		0.496041
  validation accuracy:		93.59 %
Epoch 1991 of 2000 took 0.035s
  training loss:		0.002963
  validation loss:		0.498967
  validation accuracy:		93.48 %
Epoch 1992 of 2000 took 0.035s
  training loss:		0.002995
  validation loss:		0.500960
  validation accuracy:		93.48 %
Epoch 1993 of 2000 took 0.035s
  training loss:		0.003099
  validation loss:		0.494082
  validation accuracy:		93.48 %
Epoch 1994 of 2000 took 0.035s
  training loss:		0.003012
  validation loss:		0.498955
  validation accuracy:		93.37 %
Epoch 1995 of 2000 took 0.035s
  training loss:		0.003032
  validation loss:		0.500251
  validation accuracy:		93.48 %
Epoch 1996 of 2000 took 0.035s
  training loss:		0.003060
  validation loss:		0.496802
  validation accuracy:		93.37 %
Epoch 1997 of 2000 took 0.035s
  training loss:		0.003022
  validation loss:		0.502569
  validation accuracy:		93.48 %
Epoch 1998 of 2000 took 0.035s
  training loss:		0.003049
  validation loss:		0.497705
  validation accuracy:		93.37 %
Epoch 1999 of 2000 took 0.035s
  training loss:		0.003095
  validation loss:		0.500108
  validation accuracy:		93.59 %
Epoch 2000 of 2000 took 0.035s
  training loss:		0.002996
  validation loss:		0.497630
  validation accuracy:		93.48 %
Final results:
  test loss:			1.234308
  test accuracy:		84.13 %
