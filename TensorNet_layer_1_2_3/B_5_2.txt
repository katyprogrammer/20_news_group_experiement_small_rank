Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 150),b=(150,)
w=(150, 100),b=(100,)
w=(100, 50),b=(50,)
decomposing tensor W of shape (3, 200, 150)...
decomposing tensor B of shape (3, 150)...
Starting training...
Epoch 1 of 2000 took 0.110s
  training loss:		2.986245
  validation loss:		2.970480
  validation accuracy:		13.04 %
Epoch 2 of 2000 took 0.104s
  training loss:		2.958539
  validation loss:		2.935550
  validation accuracy:		12.83 %
Epoch 3 of 2000 took 0.104s
  training loss:		2.922226
  validation loss:		2.896992
  validation accuracy:		11.96 %
Epoch 4 of 2000 took 0.104s
  training loss:		2.884556
  validation loss:		2.856542
  validation accuracy:		11.85 %
Epoch 5 of 2000 took 0.104s
  training loss:		2.844999
  validation loss:		2.814258
  validation accuracy:		11.85 %
Epoch 6 of 2000 took 0.104s
  training loss:		2.803156
  validation loss:		2.768931
  validation accuracy:		11.85 %
Epoch 7 of 2000 took 0.104s
  training loss:		2.758108
  validation loss:		2.719533
  validation accuracy:		11.85 %
Epoch 8 of 2000 took 0.104s
  training loss:		2.711607
  validation loss:		2.666108
  validation accuracy:		11.85 %
Epoch 9 of 2000 took 0.104s
  training loss:		2.662164
  validation loss:		2.609313
  validation accuracy:		11.85 %
Epoch 10 of 2000 took 0.104s
  training loss:		2.607797
  validation loss:		2.550048
  validation accuracy:		11.85 %
Epoch 11 of 2000 took 0.104s
  training loss:		2.556758
  validation loss:		2.490904
  validation accuracy:		11.85 %
Epoch 12 of 2000 took 0.104s
  training loss:		2.505824
  validation loss:		2.434261
  validation accuracy:		11.85 %
Epoch 13 of 2000 took 0.104s
  training loss:		2.457765
  validation loss:		2.383517
  validation accuracy:		11.85 %
Epoch 14 of 2000 took 0.110s
  training loss:		2.417184
  validation loss:		2.340173
  validation accuracy:		12.93 %
Epoch 15 of 2000 took 0.105s
  training loss:		2.384197
  validation loss:		2.306587
  validation accuracy:		12.93 %
Epoch 16 of 2000 took 0.104s
  training loss:		2.361329
  validation loss:		2.285693
  validation accuracy:		12.93 %
Epoch 17 of 2000 took 0.104s
  training loss:		2.344699
  validation loss:		2.271815
  validation accuracy:		13.37 %
Epoch 18 of 2000 took 0.104s
  training loss:		2.334491
  validation loss:		2.265468
  validation accuracy:		18.04 %
Epoch 19 of 2000 took 0.104s
  training loss:		2.323919
  validation loss:		2.261263
  validation accuracy:		15.87 %
Epoch 20 of 2000 took 0.104s
  training loss:		2.318392
  validation loss:		2.260843
  validation accuracy:		16.52 %
Epoch 21 of 2000 took 0.104s
  training loss:		2.313277
  validation loss:		2.260848
  validation accuracy:		23.04 %
Epoch 22 of 2000 took 0.104s
  training loss:		2.309330
  validation loss:		2.256289
  validation accuracy:		20.76 %
Epoch 23 of 2000 took 0.104s
  training loss:		2.307421
  validation loss:		2.252093
  validation accuracy:		19.35 %
Epoch 24 of 2000 took 0.104s
  training loss:		2.304674
  validation loss:		2.253288
  validation accuracy:		21.41 %
Epoch 25 of 2000 took 0.104s
  training loss:		2.303651
  validation loss:		2.248909
  validation accuracy:		13.91 %
Epoch 26 of 2000 took 0.105s
  training loss:		2.301364
  validation loss:		2.246636
  validation accuracy:		13.91 %
Epoch 27 of 2000 took 0.107s
  training loss:		2.300098
  validation loss:		2.247839
  validation accuracy:		19.89 %
Epoch 28 of 2000 took 0.105s
  training loss:		2.300490
  validation loss:		2.247334
  validation accuracy:		19.67 %
Epoch 29 of 2000 took 0.105s
  training loss:		2.298589
  validation loss:		2.246625
  validation accuracy:		13.48 %
Epoch 30 of 2000 took 0.105s
  training loss:		2.297708
  validation loss:		2.245084
  validation accuracy:		20.98 %
Epoch 31 of 2000 took 0.105s
  training loss:		2.297152
  validation loss:		2.243536
  validation accuracy:		25.33 %
Epoch 32 of 2000 took 0.105s
  training loss:		2.296807
  validation loss:		2.245405
  validation accuracy:		19.35 %
Epoch 33 of 2000 took 0.105s
  training loss:		2.296187
  validation loss:		2.241717
  validation accuracy:		13.59 %
Epoch 34 of 2000 took 0.105s
  training loss:		2.295083
  validation loss:		2.241940
  validation accuracy:		22.50 %
Epoch 35 of 2000 took 0.105s
  training loss:		2.295358
  validation loss:		2.241367
  validation accuracy:		13.15 %
Epoch 36 of 2000 took 0.105s
  training loss:		2.294749
  validation loss:		2.244055
  validation accuracy:		21.85 %
Epoch 37 of 2000 took 0.111s
  training loss:		2.293483
  validation loss:		2.241332
  validation accuracy:		19.89 %
Epoch 38 of 2000 took 0.105s
  training loss:		2.293748
  validation loss:		2.239975
  validation accuracy:		17.72 %
Epoch 39 of 2000 took 0.105s
  training loss:		2.292973
  validation loss:		2.241610
  validation accuracy:		17.83 %
Epoch 40 of 2000 took 0.105s
  training loss:		2.294130
  validation loss:		2.238199
  validation accuracy:		17.07 %
Epoch 41 of 2000 took 0.105s
  training loss:		2.293414
  validation loss:		2.242446
  validation accuracy:		17.50 %
Epoch 42 of 2000 took 0.105s
  training loss:		2.293075
  validation loss:		2.245542
  validation accuracy:		25.11 %
Epoch 43 of 2000 took 0.105s
  training loss:		2.291527
  validation loss:		2.239176
  validation accuracy:		14.57 %
Epoch 44 of 2000 took 0.105s
  training loss:		2.292788
  validation loss:		2.236239
  validation accuracy:		13.70 %
Epoch 45 of 2000 took 0.105s
  training loss:		2.293086
  validation loss:		2.241496
  validation accuracy:		13.91 %
Epoch 46 of 2000 took 0.112s
  training loss:		2.291879
  validation loss:		2.242194
  validation accuracy:		21.74 %
Epoch 47 of 2000 took 0.111s
  training loss:		2.290838
  validation loss:		2.238960
  validation accuracy:		23.04 %
Epoch 48 of 2000 took 0.108s
  training loss:		2.291586
  validation loss:		2.233993
  validation accuracy:		22.61 %
Epoch 49 of 2000 took 0.108s
  training loss:		2.290152
  validation loss:		2.240802
  validation accuracy:		25.22 %
Epoch 50 of 2000 took 0.108s
  training loss:		2.290794
  validation loss:		2.238078
  validation accuracy:		16.41 %
Epoch 51 of 2000 took 0.108s
  training loss:		2.289057
  validation loss:		2.236919
  validation accuracy:		21.41 %
Epoch 52 of 2000 took 0.106s
  training loss:		2.290129
  validation loss:		2.236004
  validation accuracy:		13.48 %
Epoch 53 of 2000 took 0.104s
  training loss:		2.288246
  validation loss:		2.236050
  validation accuracy:		22.07 %
Epoch 54 of 2000 took 0.114s
  training loss:		2.289491
  validation loss:		2.232803
  validation accuracy:		23.59 %
Epoch 55 of 2000 took 0.142s
  training loss:		2.289104
  validation loss:		2.236610
  validation accuracy:		15.33 %
Epoch 56 of 2000 took 0.109s
  training loss:		2.288494
  validation loss:		2.234577
  validation accuracy:		20.11 %
Epoch 57 of 2000 took 0.102s
  training loss:		2.288436
  validation loss:		2.236434
  validation accuracy:		22.72 %
Epoch 58 of 2000 took 0.104s
  training loss:		2.288141
  validation loss:		2.239466
  validation accuracy:		23.48 %
Epoch 59 of 2000 took 0.106s
  training loss:		2.288204
  validation loss:		2.234754
  validation accuracy:		21.74 %
Epoch 60 of 2000 took 0.103s
  training loss:		2.288026
  validation loss:		2.237293
  validation accuracy:		19.67 %
Epoch 61 of 2000 took 0.116s
  training loss:		2.287370
  validation loss:		2.235890
  validation accuracy:		19.35 %
Epoch 62 of 2000 took 0.101s
  training loss:		2.286675
  validation loss:		2.234317
  validation accuracy:		23.91 %
Epoch 63 of 2000 took 0.101s
  training loss:		2.286496
  validation loss:		2.233610
  validation accuracy:		19.89 %
Epoch 64 of 2000 took 0.101s
  training loss:		2.285799
  validation loss:		2.232337
  validation accuracy:		23.37 %
Epoch 65 of 2000 took 0.100s
  training loss:		2.285175
  validation loss:		2.231949
  validation accuracy:		25.54 %
Epoch 66 of 2000 took 0.101s
  training loss:		2.285165
  validation loss:		2.233675
  validation accuracy:		22.28 %
Epoch 67 of 2000 took 0.100s
  training loss:		2.284105
  validation loss:		2.230049
  validation accuracy:		26.63 %
Epoch 68 of 2000 took 0.100s
  training loss:		2.283722
  validation loss:		2.231643
  validation accuracy:		24.78 %
Epoch 69 of 2000 took 0.100s
  training loss:		2.283954
  validation loss:		2.228061
  validation accuracy:		21.30 %
Epoch 70 of 2000 took 0.100s
  training loss:		2.282946
  validation loss:		2.230875
  validation accuracy:		26.63 %
Epoch 71 of 2000 took 0.101s
  training loss:		2.282387
  validation loss:		2.230845
  validation accuracy:		24.02 %
Epoch 72 of 2000 took 0.100s
  training loss:		2.280585
  validation loss:		2.227253
  validation accuracy:		25.43 %
Epoch 73 of 2000 took 0.100s
  training loss:		2.281368
  validation loss:		2.229303
  validation accuracy:		22.07 %
Epoch 74 of 2000 took 0.100s
  training loss:		2.281987
  validation loss:		2.223175
  validation accuracy:		23.70 %
Epoch 75 of 2000 took 0.101s
  training loss:		2.281198
  validation loss:		2.229518
  validation accuracy:		22.39 %
Epoch 76 of 2000 took 0.101s
  training loss:		2.279504
  validation loss:		2.228051
  validation accuracy:		24.89 %
Epoch 77 of 2000 took 0.100s
  training loss:		2.279254
  validation loss:		2.224886
  validation accuracy:		23.15 %
Epoch 78 of 2000 took 0.100s
  training loss:		2.277847
  validation loss:		2.224725
  validation accuracy:		24.13 %
Epoch 79 of 2000 took 0.103s
  training loss:		2.276425
  validation loss:		2.222206
  validation accuracy:		27.93 %
Epoch 80 of 2000 took 0.101s
  training loss:		2.277069
  validation loss:		2.219604
  validation accuracy:		24.46 %
Epoch 81 of 2000 took 0.102s
  training loss:		2.275334
  validation loss:		2.221302
  validation accuracy:		24.02 %
Epoch 82 of 2000 took 0.101s
  training loss:		2.274576
  validation loss:		2.218727
  validation accuracy:		24.67 %
Epoch 83 of 2000 took 0.100s
  training loss:		2.273919
  validation loss:		2.220406
  validation accuracy:		22.17 %
Epoch 84 of 2000 took 0.100s
  training loss:		2.272918
  validation loss:		2.216031
  validation accuracy:		24.35 %
Epoch 85 of 2000 took 0.102s
  training loss:		2.270895
  validation loss:		2.217971
  validation accuracy:		26.96 %
Epoch 86 of 2000 took 0.100s
  training loss:		2.269472
  validation loss:		2.211273
  validation accuracy:		24.57 %
Epoch 87 of 2000 took 0.100s
  training loss:		2.268833
  validation loss:		2.208690
  validation accuracy:		25.11 %
Epoch 88 of 2000 took 0.101s
  training loss:		2.268024
  validation loss:		2.216764
  validation accuracy:		25.22 %
Epoch 89 of 2000 took 0.100s
  training loss:		2.266411
  validation loss:		2.209576
  validation accuracy:		24.35 %
Epoch 90 of 2000 took 0.100s
  training loss:		2.264637
  validation loss:		2.206139
  validation accuracy:		27.50 %
Epoch 91 of 2000 took 0.102s
  training loss:		2.262651
  validation loss:		2.205071
  validation accuracy:		24.02 %
Epoch 92 of 2000 took 0.102s
  training loss:		2.261349
  validation loss:		2.206866
  validation accuracy:		23.91 %
Epoch 93 of 2000 took 0.101s
  training loss:		2.258934
  validation loss:		2.203868
  validation accuracy:		25.00 %
Epoch 94 of 2000 took 0.102s
  training loss:		2.255434
  validation loss:		2.198067
  validation accuracy:		23.48 %
Epoch 95 of 2000 took 0.131s
  training loss:		2.254724
  validation loss:		2.196220
  validation accuracy:		23.80 %
Epoch 96 of 2000 took 0.165s
  training loss:		2.251628
  validation loss:		2.192414
  validation accuracy:		24.13 %
Epoch 97 of 2000 took 0.165s
  training loss:		2.248721
  validation loss:		2.194840
  validation accuracy:		23.70 %
Epoch 98 of 2000 took 0.165s
  training loss:		2.245970
  validation loss:		2.188106
  validation accuracy:		27.50 %
Epoch 99 of 2000 took 0.169s
  training loss:		2.241067
  validation loss:		2.177110
  validation accuracy:		23.48 %
Epoch 100 of 2000 took 0.165s
  training loss:		2.237396
  validation loss:		2.179537
  validation accuracy:		24.35 %
Epoch 101 of 2000 took 0.165s
  training loss:		2.233277
  validation loss:		2.173871
  validation accuracy:		26.30 %
Epoch 102 of 2000 took 0.165s
  training loss:		2.229602
  validation loss:		2.165548
  validation accuracy:		25.43 %
Epoch 103 of 2000 took 0.165s
  training loss:		2.224556
  validation loss:		2.159633
  validation accuracy:		24.13 %
Epoch 104 of 2000 took 0.165s
  training loss:		2.218512
  validation loss:		2.156220
  validation accuracy:		25.00 %
Epoch 105 of 2000 took 0.165s
  training loss:		2.212091
  validation loss:		2.151743
  validation accuracy:		25.43 %
Epoch 106 of 2000 took 0.164s
  training loss:		2.204335
  validation loss:		2.136611
  validation accuracy:		27.72 %
Epoch 107 of 2000 took 0.102s
  training loss:		2.196074
  validation loss:		2.121896
  validation accuracy:		24.13 %
Epoch 108 of 2000 took 0.100s
  training loss:		2.187437
  validation loss:		2.114990
  validation accuracy:		25.43 %
Epoch 109 of 2000 took 0.102s
  training loss:		2.179415
  validation loss:		2.111488
  validation accuracy:		25.98 %
Epoch 110 of 2000 took 0.106s
  training loss:		2.166670
  validation loss:		2.096504
  validation accuracy:		26.63 %
Epoch 111 of 2000 took 0.110s
  training loss:		2.153775
  validation loss:		2.075807
  validation accuracy:		26.74 %
Epoch 112 of 2000 took 0.101s
  training loss:		2.144257
  validation loss:		2.064303
  validation accuracy:		27.93 %
Epoch 113 of 2000 took 0.100s
  training loss:		2.127412
  validation loss:		2.051494
  validation accuracy:		28.04 %
Epoch 114 of 2000 took 0.100s
  training loss:		2.111423
  validation loss:		2.031922
  validation accuracy:		28.70 %
Epoch 115 of 2000 took 0.100s
  training loss:		2.093848
  validation loss:		2.013702
  validation accuracy:		29.13 %
Epoch 116 of 2000 took 0.100s
  training loss:		2.077091
  validation loss:		1.990034
  validation accuracy:		30.43 %
Epoch 117 of 2000 took 0.100s
  training loss:		2.056454
  validation loss:		1.967046
  validation accuracy:		28.80 %
Epoch 118 of 2000 took 0.100s
  training loss:		2.032921
  validation loss:		1.942724
  validation accuracy:		31.63 %
Epoch 119 of 2000 took 0.100s
  training loss:		2.013124
  validation loss:		1.916920
  validation accuracy:		31.74 %
Epoch 120 of 2000 took 0.103s
  training loss:		1.990809
  validation loss:		1.897395
  validation accuracy:		31.63 %
Epoch 121 of 2000 took 0.100s
  training loss:		1.971369
  validation loss:		1.876185
  validation accuracy:		32.17 %
Epoch 122 of 2000 took 0.103s
  training loss:		1.945865
  validation loss:		1.844980
  validation accuracy:		31.96 %
Epoch 123 of 2000 took 0.103s
  training loss:		1.925434
  validation loss:		1.831968
  validation accuracy:		33.59 %
Epoch 124 of 2000 took 0.100s
  training loss:		1.906855
  validation loss:		1.802366
  validation accuracy:		32.39 %
Epoch 125 of 2000 took 0.102s
  training loss:		1.883003
  validation loss:		1.780407
  validation accuracy:		34.24 %
Epoch 126 of 2000 took 0.103s
  training loss:		1.863287
  validation loss:		1.762632
  validation accuracy:		32.72 %
Epoch 127 of 2000 took 0.103s
  training loss:		1.844208
  validation loss:		1.743609
  validation accuracy:		34.67 %
Epoch 128 of 2000 took 0.103s
  training loss:		1.822023
  validation loss:		1.722319
  validation accuracy:		34.24 %
Epoch 129 of 2000 took 0.103s
  training loss:		1.804452
  validation loss:		1.704442
  validation accuracy:		33.37 %
Epoch 130 of 2000 took 0.103s
  training loss:		1.788677
  validation loss:		1.688783
  validation accuracy:		35.11 %
Epoch 131 of 2000 took 0.103s
  training loss:		1.773670
  validation loss:		1.676917
  validation accuracy:		36.96 %
Epoch 132 of 2000 took 0.103s
  training loss:		1.760892
  validation loss:		1.651441
  validation accuracy:		35.65 %
Epoch 133 of 2000 took 0.104s
  training loss:		1.747235
  validation loss:		1.637584
  validation accuracy:		36.63 %
Epoch 134 of 2000 took 0.104s
  training loss:		1.726903
  validation loss:		1.627459
  validation accuracy:		37.07 %
Epoch 135 of 2000 took 0.103s
  training loss:		1.710861
  validation loss:		1.610938
  validation accuracy:		36.96 %
Epoch 136 of 2000 took 0.103s
  training loss:		1.697604
  validation loss:		1.594049
  validation accuracy:		38.80 %
Epoch 137 of 2000 took 0.107s
  training loss:		1.678010
  validation loss:		1.582322
  validation accuracy:		38.80 %
Epoch 138 of 2000 took 0.103s
  training loss:		1.670811
  validation loss:		1.569166
  validation accuracy:		39.57 %
Epoch 139 of 2000 took 0.103s
  training loss:		1.654065
  validation loss:		1.554136
  validation accuracy:		38.80 %
Epoch 140 of 2000 took 0.103s
  training loss:		1.641172
  validation loss:		1.536351
  validation accuracy:		40.87 %
Epoch 141 of 2000 took 0.103s
  training loss:		1.629624
  validation loss:		1.525267
  validation accuracy:		39.57 %
Epoch 142 of 2000 took 0.103s
  training loss:		1.622124
  validation loss:		1.519604
  validation accuracy:		40.22 %
Epoch 143 of 2000 took 0.103s
  training loss:		1.608596
  validation loss:		1.506238
  validation accuracy:		41.20 %
Epoch 144 of 2000 took 0.103s
  training loss:		1.601882
  validation loss:		1.511434
  validation accuracy:		43.91 %
Epoch 145 of 2000 took 0.103s
  training loss:		1.582036
  validation loss:		1.483636
  validation accuracy:		41.63 %
Epoch 146 of 2000 took 0.103s
  training loss:		1.576420
  validation loss:		1.480217
  validation accuracy:		44.24 %
Epoch 147 of 2000 took 0.104s
  training loss:		1.563653
  validation loss:		1.465643
  validation accuracy:		43.91 %
Epoch 148 of 2000 took 0.103s
  training loss:		1.552997
  validation loss:		1.461569
  validation accuracy:		44.13 %
Epoch 149 of 2000 took 0.103s
  training loss:		1.546416
  validation loss:		1.446391
  validation accuracy:		44.35 %
Epoch 150 of 2000 took 0.103s
  training loss:		1.540598
  validation loss:		1.433149
  validation accuracy:		45.11 %
Epoch 151 of 2000 took 0.102s
  training loss:		1.528448
  validation loss:		1.427440
  validation accuracy:		46.30 %
Epoch 152 of 2000 took 0.103s
  training loss:		1.518914
  validation loss:		1.421116
  validation accuracy:		46.30 %
Epoch 153 of 2000 took 0.102s
  training loss:		1.516429
  validation loss:		1.418208
  validation accuracy:		47.28 %
Epoch 154 of 2000 took 0.103s
  training loss:		1.513188
  validation loss:		1.408300
  validation accuracy:		46.41 %
Epoch 155 of 2000 took 0.102s
  training loss:		1.502269
  validation loss:		1.404144
  validation accuracy:		47.07 %
Epoch 156 of 2000 took 0.103s
  training loss:		1.489717
  validation loss:		1.393213
  validation accuracy:		47.61 %
Epoch 157 of 2000 took 0.105s
  training loss:		1.492149
  validation loss:		1.392739
  validation accuracy:		47.28 %
Epoch 158 of 2000 took 0.103s
  training loss:		1.481582
  validation loss:		1.380895
  validation accuracy:		48.59 %
Epoch 159 of 2000 took 0.103s
  training loss:		1.477645
  validation loss:		1.378282
  validation accuracy:		47.72 %
Epoch 160 of 2000 took 0.103s
  training loss:		1.474550
  validation loss:		1.370117
  validation accuracy:		48.15 %
Epoch 161 of 2000 took 0.103s
  training loss:		1.466495
  validation loss:		1.370871
  validation accuracy:		48.26 %
Epoch 162 of 2000 took 0.103s
  training loss:		1.456826
  validation loss:		1.371235
  validation accuracy:		49.02 %
Epoch 163 of 2000 took 0.103s
  training loss:		1.457928
  validation loss:		1.354918
  validation accuracy:		49.13 %
Epoch 164 of 2000 took 0.103s
  training loss:		1.459307
  validation loss:		1.358191
  validation accuracy:		50.00 %
Epoch 165 of 2000 took 0.103s
  training loss:		1.455714
  validation loss:		1.352293
  validation accuracy:		51.09 %
Epoch 166 of 2000 took 0.103s
  training loss:		1.442033
  validation loss:		1.354265
  validation accuracy:		50.76 %
Epoch 167 of 2000 took 0.103s
  training loss:		1.441012
  validation loss:		1.341384
  validation accuracy:		50.43 %
Epoch 168 of 2000 took 0.102s
  training loss:		1.438276
  validation loss:		1.336150
  validation accuracy:		50.98 %
Epoch 169 of 2000 took 0.102s
  training loss:		1.436374
  validation loss:		1.342515
  validation accuracy:		50.54 %
Epoch 170 of 2000 took 0.102s
  training loss:		1.434264
  validation loss:		1.326639
  validation accuracy:		51.96 %
Epoch 171 of 2000 took 0.103s
  training loss:		1.429749
  validation loss:		1.324694
  validation accuracy:		50.87 %
Epoch 172 of 2000 took 0.103s
  training loss:		1.428278
  validation loss:		1.334019
  validation accuracy:		51.41 %
Epoch 173 of 2000 took 0.103s
  training loss:		1.421896
  validation loss:		1.315195
  validation accuracy:		52.50 %
Epoch 174 of 2000 took 0.103s
  training loss:		1.425116
  validation loss:		1.324493
  validation accuracy:		51.96 %
Epoch 175 of 2000 took 0.103s
  training loss:		1.428362
  validation loss:		1.313093
  validation accuracy:		52.28 %
Epoch 176 of 2000 took 0.103s
  training loss:		1.425329
  validation loss:		1.334517
  validation accuracy:		52.17 %
Epoch 177 of 2000 took 0.103s
  training loss:		1.415045
  validation loss:		1.340994
  validation accuracy:		51.63 %
Epoch 178 of 2000 took 0.103s
  training loss:		1.413547
  validation loss:		1.310938
  validation accuracy:		52.39 %
Epoch 179 of 2000 took 0.103s
  training loss:		1.418859
  validation loss:		1.338511
  validation accuracy:		51.63 %
Epoch 180 of 2000 took 0.102s
  training loss:		1.423310
  validation loss:		1.309490
  validation accuracy:		52.61 %
Epoch 181 of 2000 took 0.105s
  training loss:		1.404054
  validation loss:		1.296999
  validation accuracy:		53.04 %
Epoch 182 of 2000 took 0.103s
  training loss:		1.408024
  validation loss:		1.301695
  validation accuracy:		52.93 %
Epoch 183 of 2000 took 0.103s
  training loss:		1.400075
  validation loss:		1.307751
  validation accuracy:		52.61 %
Epoch 184 of 2000 took 0.103s
  training loss:		1.405265
  validation loss:		1.290690
  validation accuracy:		52.93 %
Epoch 185 of 2000 took 0.103s
  training loss:		1.411862
  validation loss:		1.292680
  validation accuracy:		52.93 %
Epoch 186 of 2000 took 0.103s
  training loss:		1.407848
  validation loss:		1.295479
  validation accuracy:		52.50 %
Epoch 187 of 2000 took 0.103s
  training loss:		1.411172
  validation loss:		1.309248
  validation accuracy:		53.91 %
Epoch 188 of 2000 took 0.102s
  training loss:		1.387707
  validation loss:		1.290328
  validation accuracy:		53.37 %
Epoch 189 of 2000 took 0.103s
  training loss:		1.395442
  validation loss:		1.288540
  validation accuracy:		52.61 %
Epoch 190 of 2000 took 0.102s
  training loss:		1.392776
  validation loss:		1.339248
  validation accuracy:		51.85 %
Epoch 191 of 2000 took 0.102s
  training loss:		1.415311
  validation loss:		1.300190
  validation accuracy:		54.13 %
Epoch 192 of 2000 took 0.103s
  training loss:		1.393062
  validation loss:		1.286308
  validation accuracy:		54.24 %
Epoch 193 of 2000 took 0.103s
  training loss:		1.383066
  validation loss:		1.283040
  validation accuracy:		54.02 %
Epoch 194 of 2000 took 0.103s
  training loss:		1.387476
  validation loss:		1.317995
  validation accuracy:		53.80 %
Epoch 195 of 2000 took 0.105s
  training loss:		1.398860
  validation loss:		1.341809
  validation accuracy:		52.39 %
Epoch 196 of 2000 took 0.106s
  training loss:		1.387766
  validation loss:		1.304503
  validation accuracy:		54.02 %
Epoch 197 of 2000 took 0.106s
  training loss:		1.390371
  validation loss:		1.303961
  validation accuracy:		54.13 %
Epoch 198 of 2000 took 0.106s
  training loss:		1.382174
  validation loss:		1.283180
  validation accuracy:		54.46 %
Epoch 199 of 2000 took 0.106s
  training loss:		1.383044
  validation loss:		1.294376
  validation accuracy:		54.35 %
Epoch 200 of 2000 took 0.106s
  training loss:		1.387564
  validation loss:		1.289216
  validation accuracy:		53.70 %
Epoch 201 of 2000 took 0.106s
  training loss:		1.403206
  validation loss:		1.280718
  validation accuracy:		54.24 %
Epoch 202 of 2000 took 0.106s
  training loss:		1.398610
  validation loss:		1.293608
  validation accuracy:		53.48 %
Epoch 203 of 2000 took 0.106s
  training loss:		1.378805
  validation loss:		1.268275
  validation accuracy:		54.46 %
Epoch 204 of 2000 took 0.106s
  training loss:		1.391313
  validation loss:		1.272651
  validation accuracy:		53.80 %
Epoch 205 of 2000 took 0.106s
  training loss:		1.373708
  validation loss:		1.271042
  validation accuracy:		54.89 %
Epoch 206 of 2000 took 0.106s
  training loss:		1.384556
  validation loss:		1.345790
  validation accuracy:		51.52 %
Epoch 207 of 2000 took 0.106s
  training loss:		1.390351
  validation loss:		1.266441
  validation accuracy:		54.57 %
Epoch 208 of 2000 took 0.106s
  training loss:		1.411657
  validation loss:		1.273850
  validation accuracy:		55.11 %
Epoch 209 of 2000 took 0.106s
  training loss:		1.381135
  validation loss:		1.263787
  validation accuracy:		55.33 %
Epoch 210 of 2000 took 0.109s
  training loss:		1.377960
  validation loss:		1.256978
  validation accuracy:		54.46 %
Epoch 211 of 2000 took 0.106s
  training loss:		1.383572
  validation loss:		1.282381
  validation accuracy:		55.22 %
Epoch 212 of 2000 took 0.106s
  training loss:		1.404265
  validation loss:		1.267230
  validation accuracy:		55.00 %
Epoch 213 of 2000 took 0.106s
  training loss:		1.385770
  validation loss:		1.293651
  validation accuracy:		55.22 %
Epoch 214 of 2000 took 0.103s
  training loss:		1.371161
  validation loss:		1.282886
  validation accuracy:		55.33 %
Epoch 215 of 2000 took 0.103s
  training loss:		1.384781
  validation loss:		1.292758
  validation accuracy:		53.37 %
Epoch 216 of 2000 took 0.102s
  training loss:		1.396175
  validation loss:		1.279208
  validation accuracy:		55.00 %
Epoch 217 of 2000 took 0.103s
  training loss:		1.369523
  validation loss:		1.274819
  validation accuracy:		55.76 %
Epoch 218 of 2000 took 0.102s
  training loss:		1.369346
  validation loss:		1.279237
  validation accuracy:		54.89 %
Epoch 219 of 2000 took 0.102s
  training loss:		1.374941
  validation loss:		1.269732
  validation accuracy:		55.33 %
Epoch 220 of 2000 took 0.102s
  training loss:		1.387946
  validation loss:		1.329989
  validation accuracy:		51.96 %
Epoch 221 of 2000 took 0.103s
  training loss:		1.375917
  validation loss:		1.265146
  validation accuracy:		55.54 %
Epoch 222 of 2000 took 0.103s
  training loss:		1.376363
  validation loss:		1.275221
  validation accuracy:		55.54 %
Epoch 223 of 2000 took 0.103s
  training loss:		1.374365
  validation loss:		1.292000
  validation accuracy:		54.24 %
Epoch 224 of 2000 took 0.103s
  training loss:		1.377502
  validation loss:		1.292477
  validation accuracy:		52.83 %
Epoch 225 of 2000 took 0.103s
  training loss:		1.428128
  validation loss:		1.329833
  validation accuracy:		52.28 %
Epoch 226 of 2000 took 0.103s
  training loss:		1.369400
  validation loss:		1.282754
  validation accuracy:		55.54 %
Epoch 227 of 2000 took 0.103s
  training loss:		1.376634
  validation loss:		1.266886
  validation accuracy:		54.13 %
Epoch 228 of 2000 took 0.103s
  training loss:		1.362326
  validation loss:		1.258419
  validation accuracy:		55.65 %
Epoch 229 of 2000 took 0.103s
  training loss:		1.369788
  validation loss:		1.257169
  validation accuracy:		56.09 %
Epoch 230 of 2000 took 0.103s
  training loss:		1.382010
  validation loss:		1.258273
  validation accuracy:		54.46 %
Epoch 231 of 2000 took 0.103s
  training loss:		1.383480
  validation loss:		1.259479
  validation accuracy:		55.33 %
Epoch 232 of 2000 took 0.102s
  training loss:		1.386336
  validation loss:		1.257480
  validation accuracy:		56.52 %
Epoch 233 of 2000 took 0.103s
  training loss:		1.360870
  validation loss:		1.256309
  validation accuracy:		56.41 %
Epoch 234 of 2000 took 0.102s
  training loss:		1.372873
  validation loss:		1.264924
  validation accuracy:		56.41 %
Epoch 235 of 2000 took 0.103s
  training loss:		1.389970
  validation loss:		1.253416
  validation accuracy:		56.30 %
Epoch 236 of 2000 took 0.103s
  training loss:		1.354277
  validation loss:		1.254882
  validation accuracy:		56.09 %
Epoch 237 of 2000 took 0.103s
  training loss:		1.369766
  validation loss:		1.268537
  validation accuracy:		55.54 %
Epoch 238 of 2000 took 0.103s
  training loss:		1.362890
  validation loss:		1.252720
  validation accuracy:		55.22 %
Epoch 239 of 2000 took 0.103s
  training loss:		1.373392
  validation loss:		1.270879
  validation accuracy:		56.30 %
Epoch 240 of 2000 took 0.103s
  training loss:		1.355528
  validation loss:		1.256662
  validation accuracy:		56.30 %
Epoch 241 of 2000 took 0.103s
  training loss:		1.371291
  validation loss:		1.293746
  validation accuracy:		52.39 %
Epoch 242 of 2000 took 0.103s
  training loss:		1.381118
  validation loss:		1.250065
  validation accuracy:		56.85 %
Epoch 243 of 2000 took 0.103s
  training loss:		1.358068
  validation loss:		1.269573
  validation accuracy:		56.30 %
Epoch 244 of 2000 took 0.103s
  training loss:		1.354892
  validation loss:		1.247461
  validation accuracy:		56.41 %
Epoch 245 of 2000 took 0.106s
  training loss:		1.356713
  validation loss:		1.256443
  validation accuracy:		56.52 %
Epoch 246 of 2000 took 0.103s
  training loss:		1.357786
  validation loss:		1.257529
  validation accuracy:		56.20 %
Epoch 247 of 2000 took 0.103s
  training loss:		1.370581
  validation loss:		1.262392
  validation accuracy:		54.46 %
Epoch 248 of 2000 took 0.103s
  training loss:		1.421759
  validation loss:		1.255011
  validation accuracy:		57.07 %
Epoch 249 of 2000 took 0.103s
  training loss:		1.359797
  validation loss:		1.292270
  validation accuracy:		54.46 %
Epoch 250 of 2000 took 0.103s
  training loss:		1.370701
  validation loss:		1.257604
  validation accuracy:		56.30 %
Epoch 251 of 2000 took 0.103s
  training loss:		1.354862
  validation loss:		1.251521
  validation accuracy:		56.41 %
Epoch 252 of 2000 took 0.103s
  training loss:		1.361475
  validation loss:		1.254709
  validation accuracy:		57.07 %
Epoch 253 of 2000 took 0.104s
  training loss:		1.370404
  validation loss:		1.272402
  validation accuracy:		52.72 %
Epoch 254 of 2000 took 0.103s
  training loss:		1.359753
  validation loss:		1.301703
  validation accuracy:		53.37 %
Epoch 255 of 2000 took 0.103s
  training loss:		1.385921
  validation loss:		1.264943
  validation accuracy:		54.78 %
Epoch 256 of 2000 took 0.103s
  training loss:		1.358674
  validation loss:		1.263115
  validation accuracy:		56.41 %
Epoch 257 of 2000 took 0.102s
  training loss:		1.358943
  validation loss:		1.238131
  validation accuracy:		56.85 %
Epoch 258 of 2000 took 0.103s
  training loss:		1.354005
  validation loss:		1.272158
  validation accuracy:		54.89 %
Epoch 259 of 2000 took 0.103s
  training loss:		1.355490
  validation loss:		1.251993
  validation accuracy:		55.65 %
Epoch 260 of 2000 took 0.103s
  training loss:		1.353379
  validation loss:		1.248546
  validation accuracy:		57.28 %
Epoch 261 of 2000 took 0.103s
  training loss:		1.366398
  validation loss:		1.264916
  validation accuracy:		53.91 %
Epoch 262 of 2000 took 0.103s
  training loss:		1.372211
  validation loss:		1.246498
  validation accuracy:		54.89 %
Epoch 263 of 2000 took 0.103s
  training loss:		1.365843
  validation loss:		1.269009
  validation accuracy:		54.78 %
Epoch 264 of 2000 took 0.103s
  training loss:		1.404614
  validation loss:		1.263544
  validation accuracy:		54.57 %
Epoch 265 of 2000 took 0.103s
  training loss:		1.351611
  validation loss:		1.237917
  validation accuracy:		56.20 %
Epoch 266 of 2000 took 0.103s
  training loss:		1.367217
  validation loss:		1.247840
  validation accuracy:		56.20 %
Epoch 267 of 2000 took 0.102s
  training loss:		1.366861
  validation loss:		1.253579
  validation accuracy:		55.33 %
Epoch 268 of 2000 took 0.103s
  training loss:		1.370237
  validation loss:		1.259501
  validation accuracy:		56.09 %
Epoch 269 of 2000 took 0.103s
  training loss:		1.428581
  validation loss:		1.260130
  validation accuracy:		56.74 %
Epoch 270 of 2000 took 0.103s
  training loss:		1.356136
  validation loss:		1.251854
  validation accuracy:		54.35 %
Epoch 271 of 2000 took 0.103s
  training loss:		1.366534
  validation loss:		1.253324
  validation accuracy:		55.65 %
Epoch 272 of 2000 took 0.103s
  training loss:		1.378239
  validation loss:		1.259392
  validation accuracy:		56.20 %
Epoch 273 of 2000 took 0.103s
  training loss:		1.408367
  validation loss:		1.279170
  validation accuracy:		52.17 %
Epoch 274 of 2000 took 0.103s
  training loss:		1.363504
  validation loss:		1.277410
  validation accuracy:		53.91 %
Epoch 275 of 2000 took 0.102s
  training loss:		1.371489
  validation loss:		1.242358
  validation accuracy:		56.74 %
Epoch 276 of 2000 took 0.103s
  training loss:		1.346680
  validation loss:		1.256679
  validation accuracy:		56.96 %
Epoch 277 of 2000 took 0.102s
  training loss:		1.360555
  validation loss:		1.282248
  validation accuracy:		55.87 %
Epoch 278 of 2000 took 0.103s
  training loss:		1.349775
  validation loss:		1.255539
  validation accuracy:		54.89 %
Epoch 279 of 2000 took 0.102s
  training loss:		1.361007
  validation loss:		1.240932
  validation accuracy:		56.20 %
Epoch 280 of 2000 took 0.103s
  training loss:		1.358533
  validation loss:		1.250653
  validation accuracy:		57.61 %
Epoch 281 of 2000 took 0.103s
  training loss:		1.356485
  validation loss:		1.288087
  validation accuracy:		55.00 %
Epoch 282 of 2000 took 0.103s
  training loss:		1.383307
  validation loss:		1.237951
  validation accuracy:		56.52 %
Epoch 283 of 2000 took 0.103s
  training loss:		1.363418
  validation loss:		1.262873
  validation accuracy:		55.33 %
Epoch 284 of 2000 took 0.103s
  training loss:		1.371090
  validation loss:		1.258295
  validation accuracy:		56.63 %
Epoch 285 of 2000 took 0.102s
  training loss:		1.355218
  validation loss:		1.262697
  validation accuracy:		56.85 %
Epoch 286 of 2000 took 0.104s
  training loss:		1.357129
  validation loss:		1.241928
  validation accuracy:		57.17 %
Epoch 287 of 2000 took 0.105s
  training loss:		1.360090
  validation loss:		1.243535
  validation accuracy:		57.28 %
Epoch 288 of 2000 took 0.103s
  training loss:		1.352441
  validation loss:		1.249542
  validation accuracy:		57.28 %
Epoch 289 of 2000 took 0.103s
  training loss:		1.371287
  validation loss:		1.243962
  validation accuracy:		57.50 %
Epoch 290 of 2000 took 0.103s
  training loss:		1.359038
  validation loss:		1.248166
  validation accuracy:		55.33 %
Epoch 291 of 2000 took 0.103s
  training loss:		1.358091
  validation loss:		1.306222
  validation accuracy:		54.57 %
Epoch 292 of 2000 took 0.103s
  training loss:		1.365649
  validation loss:		1.245476
  validation accuracy:		55.87 %
Epoch 293 of 2000 took 0.103s
  training loss:		1.353105
  validation loss:		1.240939
  validation accuracy:		57.50 %
Epoch 294 of 2000 took 0.103s
  training loss:		1.374054
  validation loss:		1.254949
  validation accuracy:		57.28 %
Epoch 295 of 2000 took 0.103s
  training loss:		1.366897
  validation loss:		1.241390
  validation accuracy:		55.98 %
Epoch 296 of 2000 took 0.103s
  training loss:		1.352800
  validation loss:		1.239435
  validation accuracy:		57.17 %
Epoch 297 of 2000 took 0.103s
  training loss:		1.350316
  validation loss:		1.244512
  validation accuracy:		58.26 %
Epoch 298 of 2000 took 0.103s
  training loss:		1.349391
  validation loss:		1.248837
  validation accuracy:		57.61 %
Epoch 299 of 2000 took 0.103s
  training loss:		1.363946
  validation loss:		1.237535
  validation accuracy:		56.52 %
Epoch 300 of 2000 took 0.103s
  training loss:		1.359532
  validation loss:		1.270867
  validation accuracy:		55.43 %
Epoch 301 of 2000 took 0.103s
  training loss:		1.356996
  validation loss:		1.243574
  validation accuracy:		58.26 %
Epoch 302 of 2000 took 0.103s
  training loss:		1.396119
  validation loss:		1.269406
  validation accuracy:		53.91 %
Epoch 303 of 2000 took 0.103s
  training loss:		1.345025
  validation loss:		1.253571
  validation accuracy:		57.17 %
Epoch 304 of 2000 took 0.103s
  training loss:		1.340465
  validation loss:		1.243719
  validation accuracy:		57.50 %
Epoch 305 of 2000 took 0.103s
  training loss:		1.348173
  validation loss:		1.233180
  validation accuracy:		58.37 %
Epoch 306 of 2000 took 0.103s
  training loss:		1.343602
  validation loss:		1.246536
  validation accuracy:		57.39 %
Epoch 307 of 2000 took 0.103s
  training loss:		1.352353
  validation loss:		1.249062
  validation accuracy:		57.83 %
Epoch 308 of 2000 took 0.103s
  training loss:		1.364483
  validation loss:		1.230024
  validation accuracy:		58.37 %
Epoch 309 of 2000 took 0.103s
  training loss:		1.352152
  validation loss:		1.246041
  validation accuracy:		56.09 %
Epoch 310 of 2000 took 0.103s
  training loss:		1.372915
  validation loss:		1.307153
  validation accuracy:		53.91 %
Epoch 311 of 2000 took 0.103s
  training loss:		1.352903
  validation loss:		1.236277
  validation accuracy:		57.93 %
Epoch 312 of 2000 took 0.103s
  training loss:		1.348434
  validation loss:		1.252865
  validation accuracy:		57.61 %
Epoch 313 of 2000 took 0.103s
  training loss:		1.354676
  validation loss:		1.238123
  validation accuracy:		57.83 %
Epoch 314 of 2000 took 0.103s
  training loss:		1.366596
  validation loss:		1.325675
  validation accuracy:		53.59 %
Epoch 315 of 2000 took 0.102s
  training loss:		1.387379
  validation loss:		1.245452
  validation accuracy:		57.07 %
Epoch 316 of 2000 took 0.102s
  training loss:		1.347341
  validation loss:		1.248196
  validation accuracy:		58.04 %
Epoch 317 of 2000 took 0.103s
  training loss:		1.363963
  validation loss:		1.235149
  validation accuracy:		57.93 %
Epoch 318 of 2000 took 0.102s
  training loss:		1.344952
  validation loss:		1.240856
  validation accuracy:		58.15 %
Epoch 319 of 2000 took 0.103s
  training loss:		1.352902
  validation loss:		1.240194
  validation accuracy:		58.37 %
Epoch 320 of 2000 took 0.102s
  training loss:		1.349517
  validation loss:		1.256189
  validation accuracy:		55.43 %
Epoch 321 of 2000 took 0.103s
  training loss:		1.384802
  validation loss:		1.339235
  validation accuracy:		52.39 %
Epoch 322 of 2000 took 0.103s
  training loss:		1.403818
  validation loss:		1.261090
  validation accuracy:		58.04 %
Epoch 323 of 2000 took 0.103s
  training loss:		1.361697
  validation loss:		1.239710
  validation accuracy:		58.04 %
Epoch 324 of 2000 took 0.103s
  training loss:		1.354844
  validation loss:		1.237777
  validation accuracy:		58.26 %
Epoch 325 of 2000 took 0.103s
  training loss:		1.384850
  validation loss:		1.237949
  validation accuracy:		57.83 %
Epoch 326 of 2000 took 0.103s
  training loss:		1.339282
  validation loss:		1.246496
  validation accuracy:		57.83 %
Epoch 327 of 2000 took 0.103s
  training loss:		1.373659
  validation loss:		1.250646
  validation accuracy:		55.65 %
Epoch 328 of 2000 took 0.103s
  training loss:		1.351092
  validation loss:		1.272142
  validation accuracy:		56.09 %
Epoch 329 of 2000 took 0.103s
  training loss:		1.369118
  validation loss:		1.248081
  validation accuracy:		58.80 %
Epoch 330 of 2000 took 0.103s
  training loss:		1.337011
  validation loss:		1.239790
  validation accuracy:		57.72 %
Epoch 331 of 2000 took 0.103s
  training loss:		1.356816
  validation loss:		1.237436
  validation accuracy:		57.72 %
Epoch 332 of 2000 took 0.103s
  training loss:		1.378786
  validation loss:		1.237512
  validation accuracy:		57.72 %
Epoch 333 of 2000 took 0.103s
  training loss:		1.351302
  validation loss:		1.245572
  validation accuracy:		58.48 %
Epoch 334 of 2000 took 0.103s
  training loss:		1.345036
  validation loss:		1.237759
  validation accuracy:		57.93 %
Epoch 335 of 2000 took 0.102s
  training loss:		1.349115
  validation loss:		1.235776
  validation accuracy:		58.59 %
Epoch 336 of 2000 took 0.103s
  training loss:		1.355837
  validation loss:		1.233091
  validation accuracy:		58.15 %
Epoch 337 of 2000 took 0.106s
  training loss:		1.350149
  validation loss:		1.231426
  validation accuracy:		58.80 %
Epoch 338 of 2000 took 0.103s
  training loss:		1.351847
  validation loss:		1.238648
  validation accuracy:		58.70 %
Epoch 339 of 2000 took 0.103s
  training loss:		1.354325
  validation loss:		1.232409
  validation accuracy:		58.26 %
Epoch 340 of 2000 took 0.103s
  training loss:		1.376912
  validation loss:		1.293218
  validation accuracy:		54.89 %
Epoch 341 of 2000 took 0.104s
  training loss:		1.354558
  validation loss:		1.241886
  validation accuracy:		56.41 %
Epoch 342 of 2000 took 0.103s
  training loss:		1.346723
  validation loss:		1.235366
  validation accuracy:		55.98 %
Epoch 343 of 2000 took 0.103s
  training loss:		1.352587
  validation loss:		1.240269
  validation accuracy:		58.48 %
Epoch 344 of 2000 took 0.103s
  training loss:		1.350041
  validation loss:		1.229819
  validation accuracy:		58.48 %
Epoch 345 of 2000 took 0.103s
  training loss:		1.361771
  validation loss:		1.331669
  validation accuracy:		53.48 %
Epoch 346 of 2000 took 0.103s
  training loss:		1.364894
  validation loss:		1.234024
  validation accuracy:		57.83 %
Epoch 347 of 2000 took 0.103s
  training loss:		1.364774
  validation loss:		1.278773
  validation accuracy:		56.96 %
Epoch 348 of 2000 took 0.103s
  training loss:		1.354220
  validation loss:		1.241459
  validation accuracy:		56.63 %
Epoch 349 of 2000 took 0.102s
  training loss:		1.359586
  validation loss:		1.238563
  validation accuracy:		59.02 %
Epoch 350 of 2000 took 0.103s
  training loss:		1.348573
  validation loss:		1.259281
  validation accuracy:		56.96 %
Epoch 351 of 2000 took 0.103s
  training loss:		1.370426
  validation loss:		1.236291
  validation accuracy:		59.13 %
Epoch 352 of 2000 took 0.103s
  training loss:		1.359452
  validation loss:		1.234377
  validation accuracy:		58.04 %
Epoch 353 of 2000 took 0.103s
  training loss:		1.363396
  validation loss:		1.241380
  validation accuracy:		56.20 %
Epoch 354 of 2000 took 0.103s
  training loss:		1.357321
  validation loss:		1.238844
  validation accuracy:		58.70 %
Epoch 355 of 2000 took 0.102s
  training loss:		1.347333
  validation loss:		1.243548
  validation accuracy:		56.63 %
Epoch 356 of 2000 took 0.103s
  training loss:		1.391886
  validation loss:		1.236254
  validation accuracy:		58.26 %
Epoch 357 of 2000 took 0.103s
  training loss:		1.347267
  validation loss:		1.237648
  validation accuracy:		58.15 %
Epoch 358 of 2000 took 0.103s
  training loss:		1.377949
  validation loss:		1.242896
  validation accuracy:		58.04 %
Epoch 359 of 2000 took 0.103s
  training loss:		1.353299
  validation loss:		1.239026
  validation accuracy:		56.63 %
Epoch 360 of 2000 took 0.103s
  training loss:		1.359031
  validation loss:		1.242486
  validation accuracy:		57.50 %
Epoch 361 of 2000 took 0.103s
  training loss:		1.343652
  validation loss:		1.232727
  validation accuracy:		58.70 %
Epoch 362 of 2000 took 0.103s
  training loss:		1.347191
  validation loss:		1.234663
  validation accuracy:		57.93 %
Epoch 363 of 2000 took 0.102s
  training loss:		1.339945
  validation loss:		1.236407
  validation accuracy:		58.15 %
Epoch 364 of 2000 took 0.103s
  training loss:		1.349260
  validation loss:		1.230084
  validation accuracy:		57.50 %
Epoch 365 of 2000 took 0.103s
  training loss:		1.346097
  validation loss:		1.240727
  validation accuracy:		58.91 %
Epoch 366 of 2000 took 0.103s
  training loss:		1.340573
  validation loss:		1.257498
  validation accuracy:		56.41 %
Epoch 367 of 2000 took 0.103s
  training loss:		1.343199
  validation loss:		1.242709
  validation accuracy:		57.61 %
Epoch 368 of 2000 took 0.103s
  training loss:		1.357598
  validation loss:		1.248413
  validation accuracy:		57.17 %
Epoch 369 of 2000 took 0.103s
  training loss:		1.349170
  validation loss:		1.233239
  validation accuracy:		58.59 %
Epoch 370 of 2000 took 0.104s
  training loss:		1.341370
  validation loss:		1.257272
  validation accuracy:		57.28 %
Epoch 371 of 2000 took 0.103s
  training loss:		1.352515
  validation loss:		1.230056
  validation accuracy:		59.24 %
Epoch 372 of 2000 took 0.103s
  training loss:		1.399411
  validation loss:		1.262220
  validation accuracy:		58.04 %
Epoch 373 of 2000 took 0.103s
  training loss:		1.337656
  validation loss:		1.234824
  validation accuracy:		58.04 %
Epoch 374 of 2000 took 0.103s
  training loss:		1.346154
  validation loss:		1.222901
  validation accuracy:		58.48 %
Epoch 375 of 2000 took 0.103s
  training loss:		1.345674
  validation loss:		1.256727
  validation accuracy:		58.15 %
Epoch 376 of 2000 took 0.103s
  training loss:		1.347663
  validation loss:		1.283811
  validation accuracy:		55.43 %
Epoch 377 of 2000 took 0.103s
  training loss:		1.344400
  validation loss:		1.269415
  validation accuracy:		56.20 %
Epoch 378 of 2000 took 0.102s
  training loss:		1.342080
  validation loss:		1.226020
  validation accuracy:		58.26 %
Epoch 379 of 2000 took 0.103s
  training loss:		1.345383
  validation loss:		1.259718
  validation accuracy:		57.39 %
Epoch 380 of 2000 took 0.103s
  training loss:		1.346037
  validation loss:		1.229334
  validation accuracy:		58.15 %
Epoch 381 of 2000 took 0.103s
  training loss:		1.386601
  validation loss:		1.298165
  validation accuracy:		57.07 %
Epoch 382 of 2000 took 0.103s
  training loss:		1.367949
  validation loss:		1.233314
  validation accuracy:		58.15 %
Epoch 383 of 2000 took 0.103s
  training loss:		1.345266
  validation loss:		1.239031
  validation accuracy:		58.48 %
Epoch 384 of 2000 took 0.103s
  training loss:		1.353790
  validation loss:		1.246798
  validation accuracy:		58.15 %
Epoch 385 of 2000 took 0.103s
  training loss:		1.344270
  validation loss:		1.238181
  validation accuracy:		59.02 %
Epoch 386 of 2000 took 0.102s
  training loss:		1.342685
  validation loss:		1.229892
  validation accuracy:		58.80 %
Epoch 387 of 2000 took 0.103s
  training loss:		1.363767
  validation loss:		1.237724
  validation accuracy:		58.37 %
Epoch 388 of 2000 took 0.102s
  training loss:		1.334849
  validation loss:		1.230893
  validation accuracy:		58.91 %
Epoch 389 of 2000 took 0.103s
  training loss:		1.395921
  validation loss:		1.299648
  validation accuracy:		55.43 %
Epoch 390 of 2000 took 0.102s
  training loss:		1.346304
  validation loss:		1.238568
  validation accuracy:		58.37 %
Epoch 391 of 2000 took 0.103s
  training loss:		1.346398
  validation loss:		1.252140
  validation accuracy:		57.39 %
Epoch 392 of 2000 took 0.103s
  training loss:		1.341029
  validation loss:		1.236108
  validation accuracy:		58.15 %
Epoch 393 of 2000 took 0.103s
  training loss:		1.356862
  validation loss:		1.266841
  validation accuracy:		57.72 %
Epoch 394 of 2000 took 0.103s
  training loss:		1.347406
  validation loss:		1.232453
  validation accuracy:		58.48 %
Epoch 395 of 2000 took 0.103s
  training loss:		1.359592
  validation loss:		1.301539
  validation accuracy:		54.67 %
Epoch 396 of 2000 took 0.102s
  training loss:		1.365271
  validation loss:		1.235435
  validation accuracy:		58.80 %
Epoch 397 of 2000 took 0.105s
  training loss:		1.349183
  validation loss:		1.268542
  validation accuracy:		57.50 %
Epoch 398 of 2000 took 0.103s
  training loss:		1.359618
  validation loss:		1.230041
  validation accuracy:		58.48 %
Epoch 399 of 2000 took 0.103s
  training loss:		1.355641
  validation loss:		1.240699
  validation accuracy:		56.52 %
Epoch 400 of 2000 took 0.103s
  training loss:		1.348437
  validation loss:		1.234984
  validation accuracy:		58.48 %
Epoch 401 of 2000 took 0.102s
  training loss:		1.347172
  validation loss:		1.240525
  validation accuracy:		56.63 %
Epoch 402 of 2000 took 0.103s
  training loss:		1.363116
  validation loss:		1.264664
  validation accuracy:		57.39 %
Epoch 403 of 2000 took 0.102s
  training loss:		1.347869
  validation loss:		1.244982
  validation accuracy:		58.15 %
Epoch 404 of 2000 took 0.103s
  training loss:		1.344332
  validation loss:		1.230054
  validation accuracy:		58.80 %
Epoch 405 of 2000 took 0.102s
  training loss:		1.366984
  validation loss:		1.268841
  validation accuracy:		57.39 %
Epoch 406 of 2000 took 0.103s
  training loss:		1.344177
  validation loss:		1.230173
  validation accuracy:		59.02 %
Epoch 407 of 2000 took 0.103s
  training loss:		1.351796
  validation loss:		1.244121
  validation accuracy:		57.72 %
Epoch 408 of 2000 took 0.103s
  training loss:		1.351814
  validation loss:		1.251460
  validation accuracy:		55.00 %
Epoch 409 of 2000 took 0.102s
  training loss:		1.351254
  validation loss:		1.229570
  validation accuracy:		57.93 %
Epoch 410 of 2000 took 0.103s
  training loss:		1.345300
  validation loss:		1.233781
  validation accuracy:		58.80 %
Epoch 411 of 2000 took 0.102s
  training loss:		1.345604
  validation loss:		1.249243
  validation accuracy:		56.96 %
Epoch 412 of 2000 took 0.102s
  training loss:		1.345779
  validation loss:		1.230271
  validation accuracy:		58.15 %
Epoch 413 of 2000 took 0.103s
  training loss:		1.349802
  validation loss:		1.238112
  validation accuracy:		58.15 %
Epoch 414 of 2000 took 0.103s
  training loss:		1.354356
  validation loss:		1.250679
  validation accuracy:		58.37 %
Epoch 415 of 2000 took 0.102s
  training loss:		1.344914
  validation loss:		1.229277
  validation accuracy:		57.93 %
Epoch 416 of 2000 took 0.103s
  training loss:		1.347283
  validation loss:		1.224752
  validation accuracy:		59.02 %
Epoch 417 of 2000 took 0.103s
  training loss:		1.339532
  validation loss:		1.253602
  validation accuracy:		57.17 %
Epoch 418 of 2000 took 0.103s
  training loss:		1.348337
  validation loss:		1.237163
  validation accuracy:		57.93 %
Epoch 419 of 2000 took 0.103s
  training loss:		1.343856
  validation loss:		1.232380
  validation accuracy:		58.59 %
Epoch 420 of 2000 took 0.103s
  training loss:		1.344759
  validation loss:		1.228813
  validation accuracy:		58.04 %
Epoch 421 of 2000 took 0.103s
  training loss:		1.341119
  validation loss:		1.256162
  validation accuracy:		53.80 %
Epoch 422 of 2000 took 0.103s
  training loss:		1.345072
  validation loss:		1.246877
  validation accuracy:		55.87 %
Epoch 423 of 2000 took 0.102s
  training loss:		1.365823
  validation loss:		1.227380
  validation accuracy:		58.59 %
Epoch 424 of 2000 took 0.103s
  training loss:		1.339656
  validation loss:		1.232577
  validation accuracy:		58.70 %
Epoch 425 of 2000 took 0.103s
  training loss:		1.341504
  validation loss:		1.233139
  validation accuracy:		59.13 %
Epoch 426 of 2000 took 0.103s
  training loss:		1.334394
  validation loss:		1.235905
  validation accuracy:		58.04 %
Epoch 427 of 2000 took 0.102s
  training loss:		1.343410
  validation loss:		1.246903
  validation accuracy:		56.63 %
Epoch 428 of 2000 took 0.103s
  training loss:		1.359971
  validation loss:		1.257922
  validation accuracy:		57.17 %
Epoch 429 of 2000 took 0.104s
  training loss:		1.344195
  validation loss:		1.233416
  validation accuracy:		58.26 %
Epoch 430 of 2000 took 0.103s
  training loss:		1.355510
  validation loss:		1.234345
  validation accuracy:		58.80 %
Epoch 431 of 2000 took 0.102s
  training loss:		1.345252
  validation loss:		1.223478
  validation accuracy:		58.26 %
Epoch 432 of 2000 took 0.103s
  training loss:		1.364148
  validation loss:		1.233223
  validation accuracy:		58.15 %
Epoch 433 of 2000 took 0.103s
  training loss:		1.349482
  validation loss:		1.260979
  validation accuracy:		56.74 %
Epoch 434 of 2000 took 0.103s
  training loss:		1.350961
  validation loss:		1.270430
  validation accuracy:		56.85 %
Epoch 435 of 2000 took 0.103s
  training loss:		1.351920
  validation loss:		1.239662
  validation accuracy:		59.46 %
Epoch 436 of 2000 took 0.103s
  training loss:		1.347495
  validation loss:		1.224644
  validation accuracy:		58.04 %
Epoch 437 of 2000 took 0.103s
  training loss:		1.370509
  validation loss:		1.261837
  validation accuracy:		57.28 %
Epoch 438 of 2000 took 0.103s
  training loss:		1.350001
  validation loss:		1.240769
  validation accuracy:		57.93 %
Epoch 439 of 2000 took 0.103s
  training loss:		1.343790
  validation loss:		1.250760
  validation accuracy:		58.15 %
Epoch 440 of 2000 took 0.103s
  training loss:		1.339412
  validation loss:		1.232804
  validation accuracy:		58.48 %
Epoch 441 of 2000 took 0.103s
  training loss:		1.350386
  validation loss:		1.235604
  validation accuracy:		58.48 %
Epoch 442 of 2000 took 0.102s
  training loss:		1.350340
  validation loss:		1.286806
  validation accuracy:		54.35 %
Epoch 443 of 2000 took 0.103s
  training loss:		1.341815
  validation loss:		1.239342
  validation accuracy:		58.37 %
Epoch 444 of 2000 took 0.103s
  training loss:		1.348137
  validation loss:		1.258436
  validation accuracy:		57.28 %
Epoch 445 of 2000 took 0.103s
  training loss:		1.354816
  validation loss:		1.222304
  validation accuracy:		58.59 %
Epoch 446 of 2000 took 0.103s
  training loss:		1.351309
  validation loss:		1.286682
  validation accuracy:		54.46 %
Epoch 447 of 2000 took 0.103s
  training loss:		1.354380
  validation loss:		1.246382
  validation accuracy:		58.48 %
Epoch 448 of 2000 took 0.103s
  training loss:		1.345883
  validation loss:		1.220234
  validation accuracy:		57.72 %
Epoch 449 of 2000 took 0.102s
  training loss:		1.354779
  validation loss:		1.236624
  validation accuracy:		58.59 %
Epoch 450 of 2000 took 0.103s
  training loss:		1.330931
  validation loss:		1.236832
  validation accuracy:		58.15 %
Epoch 451 of 2000 took 0.103s
  training loss:		1.357028
  validation loss:		1.285198
  validation accuracy:		55.54 %
Epoch 452 of 2000 took 0.102s
  training loss:		1.365637
  validation loss:		1.229649
  validation accuracy:		58.37 %
Epoch 453 of 2000 took 0.102s
  training loss:		1.345117
  validation loss:		1.238297
  validation accuracy:		58.70 %
Epoch 454 of 2000 took 0.103s
  training loss:		1.349242
  validation loss:		1.232360
  validation accuracy:		58.80 %
Epoch 455 of 2000 took 0.103s
  training loss:		1.359082
  validation loss:		1.232122
  validation accuracy:		59.13 %
Epoch 456 of 2000 took 0.102s
  training loss:		1.345162
  validation loss:		1.227956
  validation accuracy:		58.70 %
Epoch 457 of 2000 took 0.103s
  training loss:		1.348775
  validation loss:		1.236458
  validation accuracy:		58.48 %
Epoch 458 of 2000 took 0.104s
  training loss:		1.341057
  validation loss:		1.233421
  validation accuracy:		57.93 %
Epoch 459 of 2000 took 0.103s
  training loss:		1.346507
  validation loss:		1.228484
  validation accuracy:		58.80 %
Epoch 460 of 2000 took 0.102s
  training loss:		1.343807
  validation loss:		1.234093
  validation accuracy:		58.59 %
Epoch 461 of 2000 took 0.102s
  training loss:		1.338872
  validation loss:		1.230148
  validation accuracy:		58.70 %
Epoch 462 of 2000 took 0.102s
  training loss:		1.341230
  validation loss:		1.227454
  validation accuracy:		58.59 %
Epoch 463 of 2000 took 0.103s
  training loss:		1.350737
  validation loss:		1.236994
  validation accuracy:		58.70 %
Epoch 464 of 2000 took 0.103s
  training loss:		1.338805
  validation loss:		1.241179
  validation accuracy:		57.72 %
Epoch 465 of 2000 took 0.103s
  training loss:		1.352263
  validation loss:		1.258477
  validation accuracy:		57.28 %
Epoch 466 of 2000 took 0.103s
  training loss:		1.340801
  validation loss:		1.242744
  validation accuracy:		58.15 %
Epoch 467 of 2000 took 0.103s
  training loss:		1.356327
  validation loss:		1.232256
  validation accuracy:		57.83 %
Epoch 468 of 2000 took 0.103s
  training loss:		1.354287
  validation loss:		1.261359
  validation accuracy:		56.52 %
Epoch 469 of 2000 took 0.103s
  training loss:		1.338510
  validation loss:		1.239590
  validation accuracy:		59.13 %
Epoch 470 of 2000 took 0.106s
  training loss:		1.344254
  validation loss:		1.236526
  validation accuracy:		58.91 %
Epoch 471 of 2000 took 0.103s
  training loss:		1.346543
  validation loss:		1.232739
  validation accuracy:		58.59 %
Epoch 472 of 2000 took 0.102s
  training loss:		1.354145
  validation loss:		1.226766
  validation accuracy:		58.37 %
Epoch 473 of 2000 took 0.103s
  training loss:		1.358692
  validation loss:		1.256087
  validation accuracy:		54.24 %
Epoch 474 of 2000 took 0.103s
  training loss:		1.361111
  validation loss:		1.315757
  validation accuracy:		53.37 %
Epoch 475 of 2000 took 0.103s
  training loss:		1.353787
  validation loss:		1.229435
  validation accuracy:		58.48 %
Epoch 476 of 2000 took 0.102s
  training loss:		1.344351
  validation loss:		1.237603
  validation accuracy:		58.70 %
Epoch 477 of 2000 took 0.103s
  training loss:		1.335266
  validation loss:		1.228904
  validation accuracy:		58.48 %
Epoch 478 of 2000 took 0.103s
  training loss:		1.340378
  validation loss:		1.227372
  validation accuracy:		58.59 %
Epoch 479 of 2000 took 0.103s
  training loss:		1.351293
  validation loss:		1.223461
  validation accuracy:		58.70 %
Epoch 480 of 2000 took 0.102s
  training loss:		1.351077
  validation loss:		1.300599
  validation accuracy:		54.46 %
Epoch 481 of 2000 took 0.102s
  training loss:		1.358133
  validation loss:		1.235646
  validation accuracy:		59.13 %
Epoch 482 of 2000 took 0.101s
  training loss:		1.334575
  validation loss:		1.239766
  validation accuracy:		58.04 %
Epoch 483 of 2000 took 0.103s
  training loss:		1.362750
  validation loss:		1.243308
  validation accuracy:		59.13 %
Epoch 484 of 2000 took 0.105s
  training loss:		1.353728
  validation loss:		1.262029
  validation accuracy:		56.52 %
Epoch 485 of 2000 took 0.100s
  training loss:		1.353228
  validation loss:		1.238277
  validation accuracy:		57.72 %
Epoch 486 of 2000 took 0.102s
  training loss:		1.353257
  validation loss:		1.229674
  validation accuracy:		58.91 %
Epoch 487 of 2000 took 0.104s
  training loss:		1.354094
  validation loss:		1.233873
  validation accuracy:		58.91 %
Epoch 488 of 2000 took 0.106s
  training loss:		1.347465
  validation loss:		1.233720
  validation accuracy:		58.48 %
Epoch 489 of 2000 took 0.106s
  training loss:		1.343259
  validation loss:		1.239316
  validation accuracy:		58.26 %
Epoch 490 of 2000 took 0.106s
  training loss:		1.343605
  validation loss:		1.228697
  validation accuracy:		57.93 %
Epoch 491 of 2000 took 0.106s
  training loss:		1.354261
  validation loss:		1.280228
  validation accuracy:		55.87 %
Epoch 492 of 2000 took 0.106s
  training loss:		1.350775
  validation loss:		1.235983
  validation accuracy:		58.26 %
Epoch 493 of 2000 took 0.106s
  training loss:		1.346627
  validation loss:		1.229055
  validation accuracy:		58.48 %
Epoch 494 of 2000 took 0.110s
  training loss:		1.349595
  validation loss:		1.227866
  validation accuracy:		58.91 %
Epoch 495 of 2000 took 0.104s
  training loss:		1.344216
  validation loss:		1.278707
  validation accuracy:		55.43 %
Epoch 496 of 2000 took 0.106s
  training loss:		1.339758
  validation loss:		1.265365
  validation accuracy:		56.09 %
Epoch 497 of 2000 took 0.103s
  training loss:		1.344856
  validation loss:		1.238438
  validation accuracy:		58.26 %
Epoch 498 of 2000 took 0.106s
  training loss:		1.341619
  validation loss:		1.244575
  validation accuracy:		57.83 %
Epoch 499 of 2000 took 0.108s
  training loss:		1.340210
  validation loss:		1.235069
  validation accuracy:		58.59 %
Epoch 500 of 2000 took 0.104s
  training loss:		1.354209
  validation loss:		1.280259
  validation accuracy:		56.20 %
Epoch 501 of 2000 took 0.105s
  training loss:		1.347996
  validation loss:		1.299913
  validation accuracy:		55.33 %
Epoch 502 of 2000 took 0.110s
  training loss:		1.346059
  validation loss:		1.237921
  validation accuracy:		58.59 %
Epoch 503 of 2000 took 0.104s
  training loss:		1.346839
  validation loss:		1.266074
  validation accuracy:		57.07 %
Epoch 504 of 2000 took 0.106s
  training loss:		1.351047
  validation loss:		1.232247
  validation accuracy:		58.80 %
Epoch 505 of 2000 took 0.104s
  training loss:		1.335777
  validation loss:		1.225100
  validation accuracy:		58.80 %
Epoch 506 of 2000 took 0.106s
  training loss:		1.343352
  validation loss:		1.241884
  validation accuracy:		58.91 %
Epoch 507 of 2000 took 0.108s
  training loss:		1.342771
  validation loss:		1.235611
  validation accuracy:		58.91 %
Epoch 508 of 2000 took 0.104s
  training loss:		1.335634
  validation loss:		1.253415
  validation accuracy:		57.17 %
Epoch 509 of 2000 took 0.105s
  training loss:		1.346899
  validation loss:		1.229739
  validation accuracy:		58.59 %
Epoch 510 of 2000 took 0.110s
  training loss:		1.358644
  validation loss:		1.229235
  validation accuracy:		58.15 %
Epoch 511 of 2000 took 0.104s
  training loss:		1.348231
  validation loss:		1.230849
  validation accuracy:		58.70 %
Epoch 512 of 2000 took 0.105s
  training loss:		1.352819
  validation loss:		1.236788
  validation accuracy:		58.26 %
Epoch 513 of 2000 took 0.103s
  training loss:		1.338750
  validation loss:		1.221607
  validation accuracy:		58.15 %
Epoch 514 of 2000 took 0.105s
  training loss:		1.345336
  validation loss:		1.238372
  validation accuracy:		58.91 %
Epoch 515 of 2000 took 0.108s
  training loss:		1.344481
  validation loss:		1.263289
  validation accuracy:		56.74 %
Epoch 516 of 2000 took 0.105s
  training loss:		1.361410
  validation loss:		1.307132
  validation accuracy:		54.67 %
Epoch 517 of 2000 took 0.105s
  training loss:		1.352073
  validation loss:		1.236421
  validation accuracy:		58.48 %
Epoch 518 of 2000 took 0.110s
  training loss:		1.340393
  validation loss:		1.245232
  validation accuracy:		58.59 %
Epoch 519 of 2000 took 0.104s
  training loss:		1.344722
  validation loss:		1.233250
  validation accuracy:		58.91 %
Epoch 520 of 2000 took 0.106s
  training loss:		1.343317
  validation loss:		1.227870
  validation accuracy:		58.91 %
Epoch 521 of 2000 took 0.104s
  training loss:		1.344560
  validation loss:		1.255197
  validation accuracy:		57.39 %
Epoch 522 of 2000 took 0.105s
  training loss:		1.354582
  validation loss:		1.228663
  validation accuracy:		58.26 %
Epoch 523 of 2000 took 0.108s
  training loss:		1.354557
  validation loss:		1.242099
  validation accuracy:		56.20 %
Epoch 524 of 2000 took 0.102s
  training loss:		1.353386
  validation loss:		1.225139
  validation accuracy:		58.91 %
Epoch 525 of 2000 took 0.101s
  training loss:		1.344548
  validation loss:		1.229732
  validation accuracy:		58.48 %
Epoch 526 of 2000 took 0.106s
  training loss:		1.330610
  validation loss:		1.241692
  validation accuracy:		58.59 %
Epoch 527 of 2000 took 0.101s
  training loss:		1.341810
  validation loss:		1.252200
  validation accuracy:		57.50 %
Epoch 528 of 2000 took 0.102s
  training loss:		1.345872
  validation loss:		1.231419
  validation accuracy:		58.80 %
Epoch 529 of 2000 took 0.102s
  training loss:		1.344071
  validation loss:		1.270386
  validation accuracy:		57.72 %
Epoch 530 of 2000 took 0.103s
  training loss:		1.353226
  validation loss:		1.230311
  validation accuracy:		58.37 %
Epoch 531 of 2000 took 0.102s
  training loss:		1.339623
  validation loss:		1.225843
  validation accuracy:		58.91 %
Epoch 532 of 2000 took 0.103s
  training loss:		1.331366
  validation loss:		1.231884
  validation accuracy:		58.59 %
Epoch 533 of 2000 took 0.102s
  training loss:		1.349479
  validation loss:		1.245116
  validation accuracy:		57.39 %
Epoch 534 of 2000 took 0.103s
  training loss:		1.342720
  validation loss:		1.311331
  validation accuracy:		53.59 %
Epoch 535 of 2000 took 0.102s
  training loss:		1.381994
  validation loss:		1.240314
  validation accuracy:		58.91 %
Epoch 536 of 2000 took 0.103s
  training loss:		1.361280
  validation loss:		1.283160
  validation accuracy:		56.30 %
Epoch 537 of 2000 took 0.102s
  training loss:		1.349664
  validation loss:		1.237756
  validation accuracy:		58.26 %
Epoch 538 of 2000 took 0.103s
  training loss:		1.347395
  validation loss:		1.255130
  validation accuracy:		56.85 %
Epoch 539 of 2000 took 0.102s
  training loss:		1.356304
  validation loss:		1.239999
  validation accuracy:		58.48 %
Epoch 540 of 2000 took 0.102s
  training loss:		1.337147
  validation loss:		1.235849
  validation accuracy:		58.80 %
Epoch 541 of 2000 took 0.102s
  training loss:		1.346784
  validation loss:		1.232512
  validation accuracy:		58.04 %
Epoch 542 of 2000 took 0.103s
  training loss:		1.346321
  validation loss:		1.233724
  validation accuracy:		59.24 %
Epoch 543 of 2000 took 0.102s
  training loss:		1.341546
  validation loss:		1.230849
  validation accuracy:		58.48 %
Epoch 544 of 2000 took 0.103s
  training loss:		1.342930
  validation loss:		1.238755
  validation accuracy:		56.85 %
Epoch 545 of 2000 took 0.103s
  training loss:		1.334411
  validation loss:		1.236495
  validation accuracy:		57.83 %
Epoch 546 of 2000 took 0.102s
  training loss:		1.348277
  validation loss:		1.237166
  validation accuracy:		59.02 %
Epoch 547 of 2000 took 0.102s
  training loss:		1.346374
  validation loss:		1.231336
  validation accuracy:		58.70 %
Epoch 548 of 2000 took 0.103s
  training loss:		1.343396
  validation loss:		1.228029
  validation accuracy:		58.59 %
Epoch 549 of 2000 took 0.103s
  training loss:		1.345084
  validation loss:		1.232622
  validation accuracy:		58.26 %
Epoch 550 of 2000 took 0.102s
  training loss:		1.342908
  validation loss:		1.247993
  validation accuracy:		57.72 %
Epoch 551 of 2000 took 0.102s
  training loss:		1.345833
  validation loss:		1.239086
  validation accuracy:		57.50 %
Epoch 552 of 2000 took 0.105s
  training loss:		1.337822
  validation loss:		1.237052
  validation accuracy:		57.72 %
Epoch 553 of 2000 took 0.103s
  training loss:		1.368960
  validation loss:		1.274848
  validation accuracy:		57.17 %
Epoch 554 of 2000 took 0.100s
  training loss:		1.357093
  validation loss:		1.236756
  validation accuracy:		58.91 %
Epoch 555 of 2000 took 0.107s
  training loss:		1.342355
  validation loss:		1.241100
  validation accuracy:		55.00 %
Epoch 556 of 2000 took 0.105s
  training loss:		1.341487
  validation loss:		1.230011
  validation accuracy:		57.72 %
Epoch 557 of 2000 took 0.101s
  training loss:		1.346388
  validation loss:		1.264460
  validation accuracy:		57.61 %
Epoch 558 of 2000 took 0.103s
  training loss:		1.355641
  validation loss:		1.227629
  validation accuracy:		59.24 %
Epoch 559 of 2000 took 0.103s
  training loss:		1.338319
  validation loss:		1.241105
  validation accuracy:		56.63 %
Epoch 560 of 2000 took 0.103s
  training loss:		1.335988
  validation loss:		1.239149
  validation accuracy:		58.48 %
Epoch 561 of 2000 took 0.103s
  training loss:		1.336496
  validation loss:		1.223698
  validation accuracy:		57.83 %
Epoch 562 of 2000 took 0.103s
  training loss:		1.343273
  validation loss:		1.247975
  validation accuracy:		56.85 %
Epoch 563 of 2000 took 0.103s
  training loss:		1.330796
  validation loss:		1.245825
  validation accuracy:		56.96 %
Epoch 564 of 2000 took 0.102s
  training loss:		1.358847
  validation loss:		1.224781
  validation accuracy:		59.13 %
Epoch 565 of 2000 took 0.103s
  training loss:		1.336117
  validation loss:		1.230879
  validation accuracy:		58.59 %
Epoch 566 of 2000 took 0.102s
  training loss:		1.345640
  validation loss:		1.243342
  validation accuracy:		57.72 %
Epoch 567 of 2000 took 0.102s
  training loss:		1.345352
  validation loss:		1.237268
  validation accuracy:		58.26 %
Epoch 568 of 2000 took 0.103s
  training loss:		1.347677
  validation loss:		1.235815
  validation accuracy:		58.59 %
Epoch 569 of 2000 took 0.103s
  training loss:		1.351788
  validation loss:		1.279443
  validation accuracy:		55.87 %
Epoch 570 of 2000 took 0.102s
  training loss:		1.345318
  validation loss:		1.261642
  validation accuracy:		56.52 %
Epoch 571 of 2000 took 0.103s
  training loss:		1.341303
  validation loss:		1.243813
  validation accuracy:		58.80 %
Epoch 572 of 2000 took 0.103s
  training loss:		1.348682
  validation loss:		1.273590
  validation accuracy:		56.41 %
Epoch 573 of 2000 took 0.103s
  training loss:		1.355085
  validation loss:		1.231980
  validation accuracy:		59.78 %
Epoch 574 of 2000 took 0.102s
  training loss:		1.347892
  validation loss:		1.228289
  validation accuracy:		57.50 %
Epoch 575 of 2000 took 0.103s
  training loss:		1.344448
  validation loss:		1.237579
  validation accuracy:		58.37 %
Epoch 576 of 2000 took 0.102s
  training loss:		1.346158
  validation loss:		1.234644
  validation accuracy:		57.93 %
Epoch 577 of 2000 took 0.102s
  training loss:		1.344891
  validation loss:		1.233112
  validation accuracy:		58.37 %
Epoch 578 of 2000 took 0.102s
  training loss:		1.339752
  validation loss:		1.225514
  validation accuracy:		58.59 %
Epoch 579 of 2000 took 0.103s
  training loss:		1.350610
  validation loss:		1.235352
  validation accuracy:		57.93 %
Epoch 580 of 2000 took 0.102s
  training loss:		1.349723
  validation loss:		1.247604
  validation accuracy:		57.72 %
Epoch 581 of 2000 took 0.102s
  training loss:		1.341385
  validation loss:		1.237971
  validation accuracy:		58.59 %
Epoch 582 of 2000 took 0.102s
  training loss:		1.341984
  validation loss:		1.242681
  validation accuracy:		57.39 %
Epoch 583 of 2000 took 0.103s
  training loss:		1.330152
  validation loss:		1.236064
  validation accuracy:		58.70 %
Epoch 584 of 2000 took 0.103s
  training loss:		1.340967
  validation loss:		1.281571
  validation accuracy:		56.30 %
Epoch 585 of 2000 took 0.103s
  training loss:		1.342909
  validation loss:		1.231742
  validation accuracy:		58.91 %
Epoch 586 of 2000 took 0.102s
  training loss:		1.353722
  validation loss:		1.260068
  validation accuracy:		57.72 %
Epoch 587 of 2000 took 0.102s
  training loss:		1.352689
  validation loss:		1.232970
  validation accuracy:		54.46 %
Epoch 588 of 2000 took 0.102s
  training loss:		1.350501
  validation loss:		1.233639
  validation accuracy:		58.37 %
Epoch 589 of 2000 took 0.103s
  training loss:		1.343813
  validation loss:		1.223120
  validation accuracy:		58.80 %
Epoch 590 of 2000 took 0.103s
  training loss:		1.365789
  validation loss:		1.260548
  validation accuracy:		57.93 %
Epoch 591 of 2000 took 0.102s
  training loss:		1.350167
  validation loss:		1.239957
  validation accuracy:		59.57 %
Epoch 592 of 2000 took 0.102s
  training loss:		1.352903
  validation loss:		1.228030
  validation accuracy:		58.04 %
Epoch 593 of 2000 took 0.101s
  training loss:		1.344712
  validation loss:		1.228442
  validation accuracy:		58.37 %
Epoch 594 of 2000 took 0.102s
  training loss:		1.342653
  validation loss:		1.232883
  validation accuracy:		58.15 %
Epoch 595 of 2000 took 0.100s
  training loss:		1.347961
  validation loss:		1.267541
  validation accuracy:		57.07 %
Epoch 596 of 2000 took 0.105s
  training loss:		1.344398
  validation loss:		1.230890
  validation accuracy:		58.59 %
Epoch 597 of 2000 took 0.103s
  training loss:		1.331007
  validation loss:		1.235966
  validation accuracy:		58.70 %
Epoch 598 of 2000 took 0.100s
  training loss:		1.336281
  validation loss:		1.222006
  validation accuracy:		58.26 %
Epoch 599 of 2000 took 0.102s
  training loss:		1.349512
  validation loss:		1.226775
  validation accuracy:		58.37 %
Epoch 600 of 2000 took 0.103s
  training loss:		1.338348
  validation loss:		1.237768
  validation accuracy:		59.13 %
Epoch 601 of 2000 took 0.103s
  training loss:		1.332881
  validation loss:		1.249034
  validation accuracy:		56.85 %
Epoch 602 of 2000 took 0.101s
  training loss:		1.353840
  validation loss:		1.236397
  validation accuracy:		58.70 %
Epoch 603 of 2000 took 0.102s
  training loss:		1.339001
  validation loss:		1.232134
  validation accuracy:		58.04 %
Epoch 604 of 2000 took 0.106s
  training loss:		1.345766
  validation loss:		1.286734
  validation accuracy:		56.52 %
Epoch 605 of 2000 took 0.102s
  training loss:		1.343120
  validation loss:		1.230437
  validation accuracy:		58.91 %
Epoch 606 of 2000 took 0.101s
  training loss:		1.337562
  validation loss:		1.226900
  validation accuracy:		59.02 %
Epoch 607 of 2000 took 0.106s
  training loss:		1.343192
  validation loss:		1.220268
  validation accuracy:		58.91 %
Epoch 608 of 2000 took 0.102s
  training loss:		1.350451
  validation loss:		1.252608
  validation accuracy:		57.93 %
Epoch 609 of 2000 took 0.101s
  training loss:		1.338409
  validation loss:		1.227835
  validation accuracy:		58.04 %
Epoch 610 of 2000 took 0.103s
  training loss:		1.363967
  validation loss:		1.236379
  validation accuracy:		59.35 %
Epoch 611 of 2000 took 0.103s
  training loss:		1.342177
  validation loss:		1.323496
  validation accuracy:		54.13 %
Epoch 612 of 2000 took 0.105s
  training loss:		1.355521
  validation loss:		1.227972
  validation accuracy:		58.37 %
Epoch 613 of 2000 took 0.101s
  training loss:		1.339142
  validation loss:		1.246695
  validation accuracy:		58.37 %
Epoch 614 of 2000 took 0.102s
  training loss:		1.346260
  validation loss:		1.237698
  validation accuracy:		58.70 %
Epoch 615 of 2000 took 0.107s
  training loss:		1.336042
  validation loss:		1.240509
  validation accuracy:		57.93 %
Epoch 616 of 2000 took 0.101s
  training loss:		1.347700
  validation loss:		1.234360
  validation accuracy:		56.74 %
Epoch 617 of 2000 took 0.102s
  training loss:		1.346309
  validation loss:		1.226321
  validation accuracy:		58.59 %
Epoch 618 of 2000 took 0.100s
  training loss:		1.340118
  validation loss:		1.234238
  validation accuracy:		57.17 %
Epoch 619 of 2000 took 0.101s
  training loss:		1.359149
  validation loss:		1.245863
  validation accuracy:		57.83 %
Epoch 620 of 2000 took 0.103s
  training loss:		1.339060
  validation loss:		1.228972
  validation accuracy:		58.37 %
Epoch 621 of 2000 took 0.102s
  training loss:		1.341221
  validation loss:		1.227398
  validation accuracy:		58.48 %
Epoch 622 of 2000 took 0.106s
  training loss:		1.336402
  validation loss:		1.222554
  validation accuracy:		58.59 %
Epoch 623 of 2000 took 0.112s
  training loss:		1.345493
  validation loss:		1.238595
  validation accuracy:		56.85 %
Epoch 624 of 2000 took 0.104s
  training loss:		1.347226
  validation loss:		1.232333
  validation accuracy:		58.04 %
Epoch 625 of 2000 took 0.106s
  training loss:		1.346076
  validation loss:		1.243337
  validation accuracy:		57.39 %
Epoch 626 of 2000 took 0.103s
  training loss:		1.346253
  validation loss:		1.225368
  validation accuracy:		58.91 %
Epoch 627 of 2000 took 0.106s
  training loss:		1.336858
  validation loss:		1.233146
  validation accuracy:		59.57 %
Epoch 628 of 2000 took 0.108s
  training loss:		1.343218
  validation loss:		1.226763
  validation accuracy:		58.59 %
Epoch 629 of 2000 took 0.106s
  training loss:		1.336869
  validation loss:		1.232990
  validation accuracy:		58.80 %
Epoch 630 of 2000 took 0.103s
  training loss:		1.346925
  validation loss:		1.231689
  validation accuracy:		59.57 %
Epoch 631 of 2000 took 0.105s
  training loss:		1.342434
  validation loss:		1.267761
  validation accuracy:		57.17 %
Epoch 632 of 2000 took 0.101s
  training loss:		1.341836
  validation loss:		1.231704
  validation accuracy:		58.26 %
Epoch 633 of 2000 took 0.103s
  training loss:		1.342289
  validation loss:		1.234416
  validation accuracy:		59.35 %
Epoch 634 of 2000 took 0.100s
  training loss:		1.344188
  validation loss:		1.228394
  validation accuracy:		57.93 %
Epoch 635 of 2000 took 0.104s
  training loss:		1.345059
  validation loss:		1.242521
  validation accuracy:		58.37 %
Epoch 636 of 2000 took 0.104s
  training loss:		1.332323
  validation loss:		1.221453
  validation accuracy:		57.61 %
Epoch 637 of 2000 took 0.100s
  training loss:		1.336578
  validation loss:		1.233915
  validation accuracy:		58.48 %
Epoch 638 of 2000 took 0.103s
  training loss:		1.342264
  validation loss:		1.232913
  validation accuracy:		58.70 %
Epoch 639 of 2000 took 0.103s
  training loss:		1.334961
  validation loss:		1.223465
  validation accuracy:		57.61 %
Epoch 640 of 2000 took 0.103s
  training loss:		1.343807
  validation loss:		1.248876
  validation accuracy:		58.37 %
Epoch 641 of 2000 took 0.102s
  training loss:		1.340504
  validation loss:		1.237603
  validation accuracy:		58.37 %
Epoch 642 of 2000 took 0.100s
  training loss:		1.327248
  validation loss:		1.224542
  validation accuracy:		58.15 %
Epoch 643 of 2000 took 0.105s
  training loss:		1.346238
  validation loss:		1.245147
  validation accuracy:		57.50 %
Epoch 644 of 2000 took 0.103s
  training loss:		1.347843
  validation loss:		1.222144
  validation accuracy:		58.15 %
Epoch 645 of 2000 took 0.100s
  training loss:		1.344349
  validation loss:		1.234999
  validation accuracy:		58.91 %
Epoch 646 of 2000 took 0.104s
  training loss:		1.333529
  validation loss:		1.231201
  validation accuracy:		58.91 %
Epoch 647 of 2000 took 0.105s
  training loss:		1.344473
  validation loss:		1.236771
  validation accuracy:		57.39 %
Epoch 648 of 2000 took 0.100s
  training loss:		1.339649
  validation loss:		1.228234
  validation accuracy:		58.80 %
Epoch 649 of 2000 took 0.102s
  training loss:		1.348323
  validation loss:		1.229412
  validation accuracy:		58.15 %
Epoch 650 of 2000 took 0.102s
  training loss:		1.350970
  validation loss:		1.244393
  validation accuracy:		58.59 %
Epoch 651 of 2000 took 0.106s
  training loss:		1.341505
  validation loss:		1.250602
  validation accuracy:		57.50 %
Epoch 652 of 2000 took 0.103s
  training loss:		1.351312
  validation loss:		1.239456
  validation accuracy:		58.26 %
Epoch 653 of 2000 took 0.100s
  training loss:		1.345140
  validation loss:		1.247674
  validation accuracy:		58.80 %
Epoch 654 of 2000 took 0.104s
  training loss:		1.347341
  validation loss:		1.219591
  validation accuracy:		58.37 %
Epoch 655 of 2000 took 0.105s
  training loss:		1.339761
  validation loss:		1.242988
  validation accuracy:		58.26 %
Epoch 656 of 2000 took 0.100s
  training loss:		1.344464
  validation loss:		1.223338
  validation accuracy:		58.26 %
Epoch 657 of 2000 took 0.103s
  training loss:		1.349604
  validation loss:		1.222935
  validation accuracy:		59.13 %
Epoch 658 of 2000 took 0.100s
  training loss:		1.334747
  validation loss:		1.229866
  validation accuracy:		58.91 %
Epoch 659 of 2000 took 0.104s
  training loss:		1.343471
  validation loss:		1.243918
  validation accuracy:		57.93 %
Epoch 660 of 2000 took 0.106s
  training loss:		1.348104
  validation loss:		1.232771
  validation accuracy:		58.15 %
Epoch 661 of 2000 took 0.100s
  training loss:		1.348877
  validation loss:		1.234278
  validation accuracy:		57.72 %
Epoch 662 of 2000 took 0.104s
  training loss:		1.337168
  validation loss:		1.228182
  validation accuracy:		58.15 %
Epoch 663 of 2000 took 0.105s
  training loss:		1.342542
  validation loss:		1.235422
  validation accuracy:		58.80 %
Epoch 664 of 2000 took 0.100s
  training loss:		1.340685
  validation loss:		1.261873
  validation accuracy:		56.85 %
Epoch 665 of 2000 took 0.102s
  training loss:		1.328915
  validation loss:		1.231543
  validation accuracy:		58.80 %
Epoch 666 of 2000 took 0.100s
  training loss:		1.340088
  validation loss:		1.252455
  validation accuracy:		57.83 %
Epoch 667 of 2000 took 0.104s
  training loss:		1.342590
  validation loss:		1.225775
  validation accuracy:		58.15 %
Epoch 668 of 2000 took 0.105s
  training loss:		1.344637
  validation loss:		1.231600
  validation accuracy:		58.48 %
Epoch 669 of 2000 took 0.100s
  training loss:		1.344355
  validation loss:		1.240897
  validation accuracy:		59.02 %
Epoch 670 of 2000 took 0.102s
  training loss:		1.345034
  validation loss:		1.227823
  validation accuracy:		58.15 %
Epoch 671 of 2000 took 0.102s
  training loss:		1.343402
  validation loss:		1.223147
  validation accuracy:		58.48 %
Epoch 672 of 2000 took 0.103s
  training loss:		1.339454
  validation loss:		1.263256
  validation accuracy:		56.63 %
Epoch 673 of 2000 took 0.103s
  training loss:		1.346612
  validation loss:		1.234871
  validation accuracy:		59.35 %
Epoch 674 of 2000 took 0.102s
  training loss:		1.343578
  validation loss:		1.238129
  validation accuracy:		58.70 %
Epoch 675 of 2000 took 0.102s
  training loss:		1.337160
  validation loss:		1.226142
  validation accuracy:		58.48 %
Epoch 676 of 2000 took 0.103s
  training loss:		1.347137
  validation loss:		1.234077
  validation accuracy:		57.83 %
Epoch 677 of 2000 took 0.102s
  training loss:		1.338574
  validation loss:		1.236414
  validation accuracy:		58.59 %
Epoch 678 of 2000 took 0.103s
  training loss:		1.352630
  validation loss:		1.230385
  validation accuracy:		58.37 %
Epoch 679 of 2000 took 0.102s
  training loss:		1.353652
  validation loss:		1.229560
  validation accuracy:		58.37 %
Epoch 680 of 2000 took 0.103s
  training loss:		1.339209
  validation loss:		1.222869
  validation accuracy:		58.59 %
Epoch 681 of 2000 took 0.102s
  training loss:		1.341967
  validation loss:		1.241969
  validation accuracy:		59.67 %
Epoch 682 of 2000 took 0.103s
  training loss:		1.334910
  validation loss:		1.227236
  validation accuracy:		56.30 %
Epoch 683 of 2000 took 0.102s
  training loss:		1.342515
  validation loss:		1.226576
  validation accuracy:		58.59 %
Epoch 684 of 2000 took 0.102s
  training loss:		1.347898
  validation loss:		1.232642
  validation accuracy:		58.48 %
Epoch 685 of 2000 took 0.103s
  training loss:		1.335679
  validation loss:		1.241856
  validation accuracy:		58.37 %
Epoch 686 of 2000 took 0.103s
  training loss:		1.342914
  validation loss:		1.284665
  validation accuracy:		56.52 %
Epoch 687 of 2000 took 0.102s
  training loss:		1.360104
  validation loss:		1.229450
  validation accuracy:		58.04 %
Epoch 688 of 2000 took 0.102s
  training loss:		1.341011
  validation loss:		1.255430
  validation accuracy:		58.04 %
Epoch 689 of 2000 took 0.104s
  training loss:		1.342384
  validation loss:		1.231680
  validation accuracy:		57.61 %
Epoch 690 of 2000 took 0.105s
  training loss:		1.348603
  validation loss:		1.230598
  validation accuracy:		59.02 %
Epoch 691 of 2000 took 0.103s
  training loss:		1.340243
  validation loss:		1.220917
  validation accuracy:		58.26 %
Epoch 692 of 2000 took 0.103s
  training loss:		1.341725
  validation loss:		1.242969
  validation accuracy:		59.13 %
Epoch 693 of 2000 took 0.102s
  training loss:		1.340482
  validation loss:		1.276182
  validation accuracy:		56.85 %
Epoch 694 of 2000 took 0.102s
  training loss:		1.350018
  validation loss:		1.225821
  validation accuracy:		58.48 %
Epoch 695 of 2000 took 0.103s
  training loss:		1.337230
  validation loss:		1.233919
  validation accuracy:		58.80 %
Epoch 696 of 2000 took 0.102s
  training loss:		1.335229
  validation loss:		1.230398
  validation accuracy:		57.83 %
Epoch 697 of 2000 took 0.102s
  training loss:		1.350494
  validation loss:		1.247086
  validation accuracy:		54.46 %
Epoch 698 of 2000 took 0.102s
  training loss:		1.349437
  validation loss:		1.242115
  validation accuracy:		58.04 %
Epoch 699 of 2000 took 0.101s
  training loss:		1.340042
  validation loss:		1.236098
  validation accuracy:		59.24 %
Epoch 700 of 2000 took 0.102s
  training loss:		1.346364
  validation loss:		1.216866
  validation accuracy:		58.59 %
Epoch 701 of 2000 took 0.102s
  training loss:		1.338028
  validation loss:		1.231254
  validation accuracy:		58.70 %
Epoch 702 of 2000 took 0.102s
  training loss:		1.340778
  validation loss:		1.230157
  validation accuracy:		59.02 %
Epoch 703 of 2000 took 0.102s
  training loss:		1.341525
  validation loss:		1.227406
  validation accuracy:		58.91 %
Epoch 704 of 2000 took 0.102s
  training loss:		1.346239
  validation loss:		1.232009
  validation accuracy:		57.72 %
Epoch 705 of 2000 took 0.102s
  training loss:		1.344541
  validation loss:		1.231342
  validation accuracy:		58.48 %
Epoch 706 of 2000 took 0.102s
  training loss:		1.351121
  validation loss:		1.223235
  validation accuracy:		58.59 %
Epoch 707 of 2000 took 0.102s
  training loss:		1.342256
  validation loss:		1.236665
  validation accuracy:		56.85 %
Epoch 708 of 2000 took 0.102s
  training loss:		1.374580
  validation loss:		1.225592
  validation accuracy:		58.59 %
Epoch 709 of 2000 took 0.102s
  training loss:		1.341091
  validation loss:		1.233403
  validation accuracy:		58.59 %
Epoch 710 of 2000 took 0.101s
  training loss:		1.344523
  validation loss:		1.233270
  validation accuracy:		58.70 %
Epoch 711 of 2000 took 0.103s
  training loss:		1.336716
  validation loss:		1.241954
  validation accuracy:		57.50 %
Epoch 712 of 2000 took 0.103s
  training loss:		1.343349
  validation loss:		1.219933
  validation accuracy:		58.91 %
Epoch 713 of 2000 took 0.103s
  training loss:		1.334567
  validation loss:		1.253574
  validation accuracy:		58.26 %
Epoch 714 of 2000 took 0.102s
  training loss:		1.338437
  validation loss:		1.233366
  validation accuracy:		59.13 %
Epoch 715 of 2000 took 0.103s
  training loss:		1.347540
  validation loss:		1.229553
  validation accuracy:		58.48 %
Epoch 716 of 2000 took 0.103s
  training loss:		1.346372
  validation loss:		1.229375
  validation accuracy:		58.04 %
Epoch 717 of 2000 took 0.103s
  training loss:		1.345724
  validation loss:		1.217362
  validation accuracy:		59.02 %
Epoch 718 of 2000 took 0.103s
  training loss:		1.339935
  validation loss:		1.231015
  validation accuracy:		58.37 %
Epoch 719 of 2000 took 0.100s
  training loss:		1.345187
  validation loss:		1.231566
  validation accuracy:		58.70 %
Epoch 720 of 2000 took 0.102s
  training loss:		1.349421
  validation loss:		1.248767
  validation accuracy:		57.72 %
Epoch 721 of 2000 took 0.103s
  training loss:		1.342503
  validation loss:		1.233624
  validation accuracy:		58.91 %
Epoch 722 of 2000 took 0.102s
  training loss:		1.344910
  validation loss:		1.236718
  validation accuracy:		58.70 %
Epoch 723 of 2000 took 0.103s
  training loss:		1.349861
  validation loss:		1.242864
  validation accuracy:		59.78 %
Epoch 724 of 2000 took 0.102s
  training loss:		1.351980
  validation loss:		1.230598
  validation accuracy:		58.70 %
Epoch 725 of 2000 took 0.103s
  training loss:		1.342332
  validation loss:		1.223500
  validation accuracy:		58.59 %
Epoch 726 of 2000 took 0.102s
  training loss:		1.341422
  validation loss:		1.226178
  validation accuracy:		58.70 %
Epoch 727 of 2000 took 0.102s
  training loss:		1.341424
  validation loss:		1.236672
  validation accuracy:		55.54 %
Epoch 728 of 2000 took 0.103s
  training loss:		1.335247
  validation loss:		1.267847
  validation accuracy:		57.50 %
Epoch 729 of 2000 took 0.101s
  training loss:		1.348323
  validation loss:		1.268559
  validation accuracy:		56.74 %
Epoch 730 of 2000 took 0.102s
  training loss:		1.343679
  validation loss:		1.231641
  validation accuracy:		59.13 %
Epoch 731 of 2000 took 0.103s
  training loss:		1.339965
  validation loss:		1.226863
  validation accuracy:		58.91 %
Epoch 732 of 2000 took 0.103s
  training loss:		1.352818
  validation loss:		1.242033
  validation accuracy:		57.83 %
Epoch 733 of 2000 took 0.102s
  training loss:		1.347503
  validation loss:		1.246336
  validation accuracy:		58.26 %
Epoch 734 of 2000 took 0.102s
  training loss:		1.343640
  validation loss:		1.234839
  validation accuracy:		58.80 %
Epoch 735 of 2000 took 0.103s
  training loss:		1.344455
  validation loss:		1.228743
  validation accuracy:		57.07 %
Epoch 736 of 2000 took 0.103s
  training loss:		1.360242
  validation loss:		1.241406
  validation accuracy:		54.78 %
Epoch 737 of 2000 took 0.102s
  training loss:		1.344405
  validation loss:		1.227933
  validation accuracy:		58.48 %
Epoch 738 of 2000 took 0.105s
  training loss:		1.341047
  validation loss:		1.244009
  validation accuracy:		58.37 %
Epoch 739 of 2000 took 0.100s
  training loss:		1.345462
  validation loss:		1.236552
  validation accuracy:		58.37 %
Epoch 740 of 2000 took 0.102s
  training loss:		1.340833
  validation loss:		1.231044
  validation accuracy:		57.39 %
Epoch 741 of 2000 took 0.102s
  training loss:		1.343919
  validation loss:		1.224608
  validation accuracy:		58.37 %
Epoch 742 of 2000 took 0.102s
  training loss:		1.350167
  validation loss:		1.274533
  validation accuracy:		56.63 %
Epoch 743 of 2000 took 0.102s
  training loss:		1.356224
  validation loss:		1.242232
  validation accuracy:		58.80 %
Epoch 744 of 2000 took 0.102s
  training loss:		1.337780
  validation loss:		1.246560
  validation accuracy:		57.83 %
Epoch 745 of 2000 took 0.102s
  training loss:		1.346989
  validation loss:		1.230830
  validation accuracy:		58.80 %
Epoch 746 of 2000 took 0.103s
  training loss:		1.339714
  validation loss:		1.232175
  validation accuracy:		59.35 %
Epoch 747 of 2000 took 0.103s
  training loss:		1.340956
  validation loss:		1.252338
  validation accuracy:		57.61 %
Epoch 748 of 2000 took 0.101s
  training loss:		1.344558
  validation loss:		1.302248
  validation accuracy:		54.89 %
Epoch 749 of 2000 took 0.102s
  training loss:		1.345000
  validation loss:		1.235699
  validation accuracy:		58.91 %
Epoch 750 of 2000 took 0.103s
  training loss:		1.337801
  validation loss:		1.236542
  validation accuracy:		59.02 %
Epoch 751 of 2000 took 0.103s
  training loss:		1.349891
  validation loss:		1.238352
  validation accuracy:		58.91 %
Epoch 752 of 2000 took 0.102s
  training loss:		1.331218
  validation loss:		1.234763
  validation accuracy:		59.13 %
Epoch 753 of 2000 took 0.102s
  training loss:		1.344107
  validation loss:		1.225128
  validation accuracy:		56.63 %
Epoch 754 of 2000 took 0.103s
  training loss:		1.347677
  validation loss:		1.233810
  validation accuracy:		59.02 %
Epoch 755 of 2000 took 0.103s
  training loss:		1.344174
  validation loss:		1.263905
  validation accuracy:		56.52 %
Epoch 756 of 2000 took 0.103s
  training loss:		1.341033
  validation loss:		1.226164
  validation accuracy:		58.26 %
Epoch 757 of 2000 took 0.103s
  training loss:		1.335428
  validation loss:		1.230707
  validation accuracy:		59.35 %
Epoch 758 of 2000 took 0.102s
  training loss:		1.349035
  validation loss:		1.231961
  validation accuracy:		58.80 %
Epoch 759 of 2000 took 0.101s
  training loss:		1.353107
  validation loss:		1.266776
  validation accuracy:		57.17 %
Epoch 760 of 2000 took 0.103s
  training loss:		1.342838
  validation loss:		1.229390
  validation accuracy:		58.37 %
Epoch 761 of 2000 took 0.102s
  training loss:		1.340478
  validation loss:		1.223534
  validation accuracy:		58.80 %
Epoch 762 of 2000 took 0.102s
  training loss:		1.355519
  validation loss:		1.266619
  validation accuracy:		57.28 %
Epoch 763 of 2000 took 0.102s
  training loss:		1.348816
  validation loss:		1.238484
  validation accuracy:		58.04 %
Epoch 764 of 2000 took 0.103s
  training loss:		1.342751
  validation loss:		1.228224
  validation accuracy:		56.96 %
Epoch 765 of 2000 took 0.103s
  training loss:		1.342081
  validation loss:		1.230565
  validation accuracy:		59.02 %
Epoch 766 of 2000 took 0.102s
  training loss:		1.339758
  validation loss:		1.244495
  validation accuracy:		58.04 %
Epoch 767 of 2000 took 0.104s
  training loss:		1.344546
  validation loss:		1.222743
  validation accuracy:		58.15 %
Epoch 768 of 2000 took 0.102s
  training loss:		1.339229
  validation loss:		1.239879
  validation accuracy:		58.59 %
Epoch 769 of 2000 took 0.101s
  training loss:		1.341256
  validation loss:		1.262669
  validation accuracy:		58.04 %
Epoch 770 of 2000 took 0.101s
  training loss:		1.343305
  validation loss:		1.221736
  validation accuracy:		57.28 %
Epoch 771 of 2000 took 0.101s
  training loss:		1.336532
  validation loss:		1.227566
  validation accuracy:		58.70 %
Epoch 772 of 2000 took 0.102s
  training loss:		1.347821
  validation loss:		1.230866
  validation accuracy:		57.28 %
Epoch 773 of 2000 took 0.102s
  training loss:		1.339886
  validation loss:		1.234002
  validation accuracy:		58.37 %
Epoch 774 of 2000 took 0.102s
  training loss:		1.344931
  validation loss:		1.224733
  validation accuracy:		57.93 %
Epoch 775 of 2000 took 0.102s
  training loss:		1.344489
  validation loss:		1.229185
  validation accuracy:		59.13 %
Epoch 776 of 2000 took 0.102s
  training loss:		1.338628
  validation loss:		1.234424
  validation accuracy:		58.48 %
Epoch 777 of 2000 took 0.102s
  training loss:		1.340704
  validation loss:		1.218427
  validation accuracy:		59.02 %
Epoch 778 of 2000 took 0.100s
  training loss:		1.340374
  validation loss:		1.242660
  validation accuracy:		59.67 %
Epoch 779 of 2000 took 0.105s
  training loss:		1.344111
  validation loss:		1.230240
  validation accuracy:		56.96 %
Epoch 780 of 2000 took 0.104s
  training loss:		1.337905
  validation loss:		1.225487
  validation accuracy:		59.13 %
Epoch 781 of 2000 took 0.101s
  training loss:		1.348994
  validation loss:		1.228694
  validation accuracy:		59.46 %
Epoch 782 of 2000 took 0.102s
  training loss:		1.337540
  validation loss:		1.225437
  validation accuracy:		58.15 %
Epoch 783 of 2000 took 0.102s
  training loss:		1.338200
  validation loss:		1.235073
  validation accuracy:		59.35 %
Epoch 784 of 2000 took 0.102s
  training loss:		1.335483
  validation loss:		1.246022
  validation accuracy:		59.24 %
Epoch 785 of 2000 took 0.105s
  training loss:		1.341937
  validation loss:		1.239379
  validation accuracy:		57.61 %
Epoch 786 of 2000 took 0.103s
  training loss:		1.348292
  validation loss:		1.219957
  validation accuracy:		58.70 %
Epoch 787 of 2000 took 0.103s
  training loss:		1.338668
  validation loss:		1.233653
  validation accuracy:		59.02 %
Epoch 788 of 2000 took 0.101s
  training loss:		1.335768
  validation loss:		1.238718
  validation accuracy:		59.46 %
Epoch 789 of 2000 took 0.102s
  training loss:		1.350835
  validation loss:		1.220334
  validation accuracy:		57.50 %
Epoch 790 of 2000 took 0.106s
  training loss:		1.343303
  validation loss:		1.239387
  validation accuracy:		59.35 %
Epoch 791 of 2000 took 0.101s
  training loss:		1.346918
  validation loss:		1.227039
  validation accuracy:		58.80 %
Epoch 792 of 2000 took 0.102s
  training loss:		1.337671
  validation loss:		1.225296
  validation accuracy:		58.59 %
Epoch 793 of 2000 took 0.103s
  training loss:		1.339295
  validation loss:		1.240500
  validation accuracy:		58.91 %
Epoch 794 of 2000 took 0.102s
  training loss:		1.344613
  validation loss:		1.232717
  validation accuracy:		59.13 %
Epoch 795 of 2000 took 0.103s
  training loss:		1.347131
  validation loss:		1.238333
  validation accuracy:		58.37 %
Epoch 796 of 2000 took 0.103s
  training loss:		1.338556
  validation loss:		1.226474
  validation accuracy:		59.78 %
Epoch 797 of 2000 took 0.104s
  training loss:		1.334738
  validation loss:		1.231425
  validation accuracy:		57.61 %
Epoch 798 of 2000 took 0.104s
  training loss:		1.356087
  validation loss:		1.232834
  validation accuracy:		56.52 %
Epoch 799 of 2000 took 0.101s
  training loss:		1.343963
  validation loss:		1.225691
  validation accuracy:		59.35 %
Epoch 800 of 2000 took 0.102s
  training loss:		1.352898
  validation loss:		1.256738
  validation accuracy:		57.39 %
Epoch 801 of 2000 took 0.100s
  training loss:		1.347976
  validation loss:		1.232422
  validation accuracy:		58.91 %
Epoch 802 of 2000 took 0.102s
  training loss:		1.341708
  validation loss:		1.241191
  validation accuracy:		58.70 %
Epoch 803 of 2000 took 0.103s
  training loss:		1.339989
  validation loss:		1.234750
  validation accuracy:		58.37 %
Epoch 804 of 2000 took 0.102s
  training loss:		1.343854
  validation loss:		1.225968
  validation accuracy:		57.50 %
Epoch 805 of 2000 took 0.102s
  training loss:		1.345664
  validation loss:		1.255551
  validation accuracy:		56.85 %
Epoch 806 of 2000 took 0.102s
  training loss:		1.344958
  validation loss:		1.243334
  validation accuracy:		57.93 %
Epoch 807 of 2000 took 0.102s
  training loss:		1.342074
  validation loss:		1.267743
  validation accuracy:		57.50 %
Epoch 808 of 2000 took 0.100s
  training loss:		1.336799
  validation loss:		1.219704
  validation accuracy:		58.04 %
Epoch 809 of 2000 took 0.102s
  training loss:		1.340064
  validation loss:		1.240880
  validation accuracy:		58.91 %
Epoch 810 of 2000 took 0.106s
  training loss:		1.339002
  validation loss:		1.220863
  validation accuracy:		59.35 %
Epoch 811 of 2000 took 0.101s
  training loss:		1.344016
  validation loss:		1.235111
  validation accuracy:		58.59 %
Epoch 812 of 2000 took 0.101s
  training loss:		1.340586
  validation loss:		1.228716
  validation accuracy:		58.15 %
Epoch 813 of 2000 took 0.102s
  training loss:		1.339524
  validation loss:		1.247880
  validation accuracy:		58.26 %
Epoch 814 of 2000 took 0.102s
  training loss:		1.342569
  validation loss:		1.230226
  validation accuracy:		58.91 %
Epoch 815 of 2000 took 0.102s
  training loss:		1.340110
  validation loss:		1.224281
  validation accuracy:		57.61 %
Epoch 816 of 2000 took 0.102s
  training loss:		1.344676
  validation loss:		1.226992
  validation accuracy:		59.13 %
Epoch 817 of 2000 took 0.105s
  training loss:		1.339136
  validation loss:		1.241121
  validation accuracy:		58.80 %
Epoch 818 of 2000 took 0.104s
  training loss:		1.348406
  validation loss:		1.322063
  validation accuracy:		53.59 %
Epoch 819 of 2000 took 0.100s
  training loss:		1.347836
  validation loss:		1.227938
  validation accuracy:		59.13 %
Epoch 820 of 2000 took 0.103s
  training loss:		1.352013
  validation loss:		1.246540
  validation accuracy:		58.26 %
Epoch 821 of 2000 took 0.102s
  training loss:		1.337764
  validation loss:		1.230681
  validation accuracy:		59.46 %
Epoch 822 of 2000 took 0.101s
  training loss:		1.341225
  validation loss:		1.249140
  validation accuracy:		58.91 %
Epoch 823 of 2000 took 0.103s
  training loss:		1.335407
  validation loss:		1.221094
  validation accuracy:		58.80 %
Epoch 824 of 2000 took 0.102s
  training loss:		1.339628
  validation loss:		1.225775
  validation accuracy:		59.02 %
Epoch 825 of 2000 took 0.102s
  training loss:		1.353870
  validation loss:		1.274777
  validation accuracy:		56.74 %
Epoch 826 of 2000 took 0.102s
  training loss:		1.346804
  validation loss:		1.229561
  validation accuracy:		59.46 %
Epoch 827 of 2000 took 0.103s
  training loss:		1.340839
  validation loss:		1.223473
  validation accuracy:		58.15 %
Epoch 828 of 2000 took 0.102s
  training loss:		1.344617
  validation loss:		1.236730
  validation accuracy:		56.30 %
Epoch 829 of 2000 took 0.101s
  training loss:		1.342368
  validation loss:		1.225696
  validation accuracy:		58.91 %
Epoch 830 of 2000 took 0.104s
  training loss:		1.337862
  validation loss:		1.265691
  validation accuracy:		57.50 %
Epoch 831 of 2000 took 0.100s
  training loss:		1.349240
  validation loss:		1.234243
  validation accuracy:		59.35 %
Epoch 832 of 2000 took 0.103s
  training loss:		1.338774
  validation loss:		1.234860
  validation accuracy:		58.48 %
Epoch 833 of 2000 took 0.102s
  training loss:		1.346036
  validation loss:		1.228105
  validation accuracy:		58.91 %
Epoch 834 of 2000 took 0.101s
  training loss:		1.342470
  validation loss:		1.227451
  validation accuracy:		58.80 %
Epoch 835 of 2000 took 0.103s
  training loss:		1.335743
  validation loss:		1.230097
  validation accuracy:		58.91 %
Epoch 836 of 2000 took 0.101s
  training loss:		1.346167
  validation loss:		1.250282
  validation accuracy:		58.26 %
Epoch 837 of 2000 took 0.104s
  training loss:		1.353493
  validation loss:		1.231155
  validation accuracy:		56.30 %
Epoch 838 of 2000 took 0.101s
  training loss:		1.350315
  validation loss:		1.261799
  validation accuracy:		57.07 %
Epoch 839 of 2000 took 0.103s
  training loss:		1.340236
  validation loss:		1.225765
  validation accuracy:		57.83 %
Epoch 840 of 2000 took 0.104s
  training loss:		1.336754
  validation loss:		1.229603
  validation accuracy:		59.35 %
Epoch 841 of 2000 took 0.100s
  training loss:		1.332094
  validation loss:		1.241568
  validation accuracy:		58.15 %
Epoch 842 of 2000 took 0.105s
  training loss:		1.340581
  validation loss:		1.222029
  validation accuracy:		59.13 %
Epoch 843 of 2000 took 0.101s
  training loss:		1.348669
  validation loss:		1.225551
  validation accuracy:		58.15 %
Epoch 844 of 2000 took 0.102s
  training loss:		1.344425
  validation loss:		1.233925
  validation accuracy:		59.35 %
Epoch 845 of 2000 took 0.102s
  training loss:		1.339188
  validation loss:		1.225446
  validation accuracy:		57.61 %
Epoch 846 of 2000 took 0.102s
  training loss:		1.345642
  validation loss:		1.250633
  validation accuracy:		58.48 %
Epoch 847 of 2000 took 0.106s
  training loss:		1.342058
  validation loss:		1.236396
  validation accuracy:		59.02 %
Epoch 848 of 2000 took 0.102s
  training loss:		1.355842
  validation loss:		1.242674
  validation accuracy:		59.24 %
Epoch 849 of 2000 took 0.101s
  training loss:		1.349525
  validation loss:		1.218464
  validation accuracy:		59.35 %
Epoch 850 of 2000 took 0.101s
  training loss:		1.336803
  validation loss:		1.230267
  validation accuracy:		59.67 %
Epoch 851 of 2000 took 0.101s
  training loss:		1.348523
  validation loss:		1.247865
  validation accuracy:		58.04 %
Epoch 852 of 2000 took 0.105s
  training loss:		1.352000
  validation loss:		1.227090
  validation accuracy:		59.13 %
Epoch 853 of 2000 took 0.102s
  training loss:		1.347055
  validation loss:		1.244511
  validation accuracy:		58.48 %
Epoch 854 of 2000 took 0.101s
  training loss:		1.342838
  validation loss:		1.249800
  validation accuracy:		58.70 %
Epoch 855 of 2000 took 0.103s
  training loss:		1.345180
  validation loss:		1.224122
  validation accuracy:		58.80 %
Epoch 856 of 2000 took 0.101s
  training loss:		1.345589
  validation loss:		1.237599
  validation accuracy:		58.48 %
Epoch 857 of 2000 took 0.102s
  training loss:		1.347050
  validation loss:		1.252732
  validation accuracy:		58.70 %
Epoch 858 of 2000 took 0.100s
  training loss:		1.340591
  validation loss:		1.227174
  validation accuracy:		59.13 %
Epoch 859 of 2000 took 0.102s
  training loss:		1.338040
  validation loss:		1.225904
  validation accuracy:		59.24 %
Epoch 860 of 2000 took 0.105s
  training loss:		1.348638
  validation loss:		1.237461
  validation accuracy:		58.80 %
Epoch 861 of 2000 took 0.102s
  training loss:		1.342140
  validation loss:		1.246267
  validation accuracy:		58.59 %
Epoch 862 of 2000 took 0.101s
  training loss:		1.333916
  validation loss:		1.225835
  validation accuracy:		59.78 %
Epoch 863 of 2000 took 0.106s
  training loss:		1.334361
  validation loss:		1.223818
  validation accuracy:		58.70 %
Epoch 864 of 2000 took 0.102s
  training loss:		1.339596
  validation loss:		1.244323
  validation accuracy:		58.80 %
Epoch 865 of 2000 took 0.103s
  training loss:		1.341547
  validation loss:		1.227629
  validation accuracy:		59.46 %
Epoch 866 of 2000 took 0.101s
  training loss:		1.343560
  validation loss:		1.232589
  validation accuracy:		58.59 %
Epoch 867 of 2000 took 0.102s
  training loss:		1.332597
  validation loss:		1.222896
  validation accuracy:		59.46 %
Epoch 868 of 2000 took 0.106s
  training loss:		1.332630
  validation loss:		1.226487
  validation accuracy:		58.91 %
Epoch 869 of 2000 took 0.102s
  training loss:		1.347180
  validation loss:		1.236659
  validation accuracy:		59.35 %
Epoch 870 of 2000 took 0.101s
  training loss:		1.350189
  validation loss:		1.268832
  validation accuracy:		57.61 %
Epoch 871 of 2000 took 0.106s
  training loss:		1.342310
  validation loss:		1.223873
  validation accuracy:		58.59 %
Epoch 872 of 2000 took 0.101s
  training loss:		1.333203
  validation loss:		1.222552
  validation accuracy:		58.37 %
Epoch 873 of 2000 took 0.102s
  training loss:		1.346408
  validation loss:		1.230587
  validation accuracy:		58.37 %
Epoch 874 of 2000 took 0.101s
  training loss:		1.328294
  validation loss:		1.222922
  validation accuracy:		58.80 %
Epoch 875 of 2000 took 0.102s
  training loss:		1.345578
  validation loss:		1.221949
  validation accuracy:		57.93 %
Epoch 876 of 2000 took 0.105s
  training loss:		1.343959
  validation loss:		1.233209
  validation accuracy:		59.35 %
Epoch 877 of 2000 took 0.102s
  training loss:		1.338335
  validation loss:		1.236058
  validation accuracy:		58.59 %
Epoch 878 of 2000 took 0.101s
  training loss:		1.343641
  validation loss:		1.240113
  validation accuracy:		58.91 %
Epoch 879 of 2000 took 0.106s
  training loss:		1.340369
  validation loss:		1.230520
  validation accuracy:		59.02 %
Epoch 880 of 2000 took 0.102s
  training loss:		1.337940
  validation loss:		1.238110
  validation accuracy:		59.35 %
Epoch 881 of 2000 took 0.101s
  training loss:		1.337633
  validation loss:		1.225897
  validation accuracy:		58.70 %
Epoch 882 of 2000 took 0.101s
  training loss:		1.336738
  validation loss:		1.235038
  validation accuracy:		59.24 %
Epoch 883 of 2000 took 0.101s
  training loss:		1.343445
  validation loss:		1.219042
  validation accuracy:		59.35 %
Epoch 884 of 2000 took 0.105s
  training loss:		1.330419
  validation loss:		1.225445
  validation accuracy:		59.67 %
Epoch 885 of 2000 took 0.102s
  training loss:		1.341957
  validation loss:		1.243343
  validation accuracy:		58.80 %
Epoch 886 of 2000 took 0.100s
  training loss:		1.331358
  validation loss:		1.226978
  validation accuracy:		57.72 %
Epoch 887 of 2000 took 0.105s
  training loss:		1.353084
  validation loss:		1.225303
  validation accuracy:		57.93 %
Epoch 888 of 2000 took 0.103s
  training loss:		1.330370
  validation loss:		1.235188
  validation accuracy:		60.22 %
Epoch 889 of 2000 took 0.101s
  training loss:		1.351396
  validation loss:		1.225037
  validation accuracy:		57.17 %
Epoch 890 of 2000 took 0.101s
  training loss:		1.337966
  validation loss:		1.242299
  validation accuracy:		59.13 %
Epoch 891 of 2000 took 0.100s
  training loss:		1.339883
  validation loss:		1.219858
  validation accuracy:		59.35 %
Epoch 892 of 2000 took 0.106s
  training loss:		1.343247
  validation loss:		1.239678
  validation accuracy:		59.24 %
Epoch 893 of 2000 took 0.102s
  training loss:		1.333267
  validation loss:		1.242492
  validation accuracy:		58.70 %
Epoch 894 of 2000 took 0.100s
  training loss:		1.341897
  validation loss:		1.233409
  validation accuracy:		60.00 %
Epoch 895 of 2000 took 0.103s
  training loss:		1.334627
  validation loss:		1.230828
  validation accuracy:		59.24 %
Epoch 896 of 2000 took 0.103s
  training loss:		1.343270
  validation loss:		1.232062
  validation accuracy:		59.57 %
Epoch 897 of 2000 took 0.103s
  training loss:		1.337173
  validation loss:		1.226475
  validation accuracy:		59.35 %
Epoch 898 of 2000 took 0.103s
  training loss:		1.340470
  validation loss:		1.246774
  validation accuracy:		58.59 %
Epoch 899 of 2000 took 0.102s
  training loss:		1.337266
  validation loss:		1.220810
  validation accuracy:		59.24 %
Epoch 900 of 2000 took 0.102s
  training loss:		1.337542
  validation loss:		1.230660
  validation accuracy:		59.78 %
Epoch 901 of 2000 took 0.102s
  training loss:		1.334976
  validation loss:		1.231603
  validation accuracy:		59.89 %
Epoch 902 of 2000 took 0.102s
  training loss:		1.338332
  validation loss:		1.224994
  validation accuracy:		59.13 %
Epoch 903 of 2000 took 0.102s
  training loss:		1.340135
  validation loss:		1.243489
  validation accuracy:		59.02 %
Epoch 904 of 2000 took 0.103s
  training loss:		1.342281
  validation loss:		1.240332
  validation accuracy:		60.11 %
Epoch 905 of 2000 took 0.102s
  training loss:		1.337528
  validation loss:		1.230007
  validation accuracy:		59.02 %
Epoch 906 of 2000 took 0.103s
  training loss:		1.338922
  validation loss:		1.231529
  validation accuracy:		60.00 %
Epoch 907 of 2000 took 0.103s
  training loss:		1.341654
  validation loss:		1.238175
  validation accuracy:		59.57 %
Epoch 908 of 2000 took 0.103s
  training loss:		1.341119
  validation loss:		1.241420
  validation accuracy:		59.67 %
Epoch 909 of 2000 took 0.103s
  training loss:		1.343945
  validation loss:		1.225397
  validation accuracy:		58.48 %
Epoch 910 of 2000 took 0.103s
  training loss:		1.342811
  validation loss:		1.231695
  validation accuracy:		59.35 %
Epoch 911 of 2000 took 0.102s
  training loss:		1.340215
  validation loss:		1.224141
  validation accuracy:		59.78 %
Epoch 912 of 2000 took 0.103s
  training loss:		1.337761
  validation loss:		1.237334
  validation accuracy:		58.37 %
Epoch 913 of 2000 took 0.103s
  training loss:		1.342072
  validation loss:		1.242081
  validation accuracy:		59.89 %
Epoch 914 of 2000 took 0.103s
  training loss:		1.343826
  validation loss:		1.234763
  validation accuracy:		59.89 %
Epoch 915 of 2000 took 0.102s
  training loss:		1.332368
  validation loss:		1.227592
  validation accuracy:		60.54 %
Epoch 916 of 2000 took 0.103s
  training loss:		1.344969
  validation loss:		1.225594
  validation accuracy:		57.17 %
Epoch 917 of 2000 took 0.102s
  training loss:		1.337979
  validation loss:		1.217679
  validation accuracy:		58.15 %
Epoch 918 of 2000 took 0.103s
  training loss:		1.334955
  validation loss:		1.234086
  validation accuracy:		59.67 %
Epoch 919 of 2000 took 0.102s
  training loss:		1.346981
  validation loss:		1.221850
  validation accuracy:		59.67 %
Epoch 920 of 2000 took 0.102s
  training loss:		1.343395
  validation loss:		1.227608
  validation accuracy:		59.46 %
Epoch 921 of 2000 took 0.100s
  training loss:		1.333808
  validation loss:		1.225766
  validation accuracy:		59.35 %
Epoch 922 of 2000 took 0.102s
  training loss:		1.336335
  validation loss:		1.224917
  validation accuracy:		59.13 %
Epoch 923 of 2000 took 0.105s
  training loss:		1.335741
  validation loss:		1.227124
  validation accuracy:		59.35 %
Epoch 924 of 2000 took 0.102s
  training loss:		1.331562
  validation loss:		1.220393
  validation accuracy:		58.80 %
Epoch 925 of 2000 took 0.101s
  training loss:		1.344767
  validation loss:		1.232089
  validation accuracy:		60.22 %
Epoch 926 of 2000 took 0.103s
  training loss:		1.333909
  validation loss:		1.219305
  validation accuracy:		59.13 %
Epoch 927 of 2000 took 0.103s
  training loss:		1.332137
  validation loss:		1.215992
  validation accuracy:		59.46 %
Epoch 928 of 2000 took 0.103s
  training loss:		1.339753
  validation loss:		1.222627
  validation accuracy:		58.15 %
Epoch 929 of 2000 took 0.102s
  training loss:		1.333269
  validation loss:		1.249833
  validation accuracy:		58.91 %
Epoch 930 of 2000 took 0.104s
  training loss:		1.334816
  validation loss:		1.235470
  validation accuracy:		59.13 %
Epoch 931 of 2000 took 0.104s
  training loss:		1.339335
  validation loss:		1.217021
  validation accuracy:		57.39 %
Epoch 932 of 2000 took 0.100s
  training loss:		1.333395
  validation loss:		1.224340
  validation accuracy:		58.48 %
Epoch 933 of 2000 took 0.103s
  training loss:		1.339039
  validation loss:		1.227201
  validation accuracy:		60.65 %
Epoch 934 of 2000 took 0.106s
  training loss:		1.340428
  validation loss:		1.237589
  validation accuracy:		59.78 %
Epoch 935 of 2000 took 0.100s
  training loss:		1.341993
  validation loss:		1.220515
  validation accuracy:		58.26 %
Epoch 936 of 2000 took 0.106s
  training loss:		1.337561
  validation loss:		1.233208
  validation accuracy:		60.87 %
Epoch 937 of 2000 took 0.103s
  training loss:		1.336937
  validation loss:		1.219249
  validation accuracy:		60.22 %
Epoch 938 of 2000 took 0.102s
  training loss:		1.336680
  validation loss:		1.220831
  validation accuracy:		60.33 %
Epoch 939 of 2000 took 0.103s
  training loss:		1.336436
  validation loss:		1.222790
  validation accuracy:		60.43 %
Epoch 940 of 2000 took 0.100s
  training loss:		1.334784
  validation loss:		1.230710
  validation accuracy:		60.11 %
Epoch 941 of 2000 took 0.104s
  training loss:		1.330392
  validation loss:		1.224176
  validation accuracy:		60.54 %
Epoch 942 of 2000 took 0.104s
  training loss:		1.339028
  validation loss:		1.245997
  validation accuracy:		59.24 %
Epoch 943 of 2000 took 0.100s
  training loss:		1.341046
  validation loss:		1.224796
  validation accuracy:		60.00 %
Epoch 944 of 2000 took 0.102s
  training loss:		1.342080
  validation loss:		1.217211
  validation accuracy:		59.78 %
Epoch 945 of 2000 took 0.100s
  training loss:		1.341320
  validation loss:		1.240330
  validation accuracy:		60.00 %
Epoch 946 of 2000 took 0.105s
  training loss:		1.329154
  validation loss:		1.228334
  validation accuracy:		59.57 %
Epoch 947 of 2000 took 0.103s
  training loss:		1.329999
  validation loss:		1.216360
  validation accuracy:		57.72 %
Epoch 948 of 2000 took 0.102s
  training loss:		1.332846
  validation loss:		1.221038
  validation accuracy:		59.35 %
Epoch 949 of 2000 took 0.105s
  training loss:		1.340398
  validation loss:		1.228685
  validation accuracy:		60.65 %
Epoch 950 of 2000 took 0.105s
  training loss:		1.334010
  validation loss:		1.227383
  validation accuracy:		61.20 %
Epoch 951 of 2000 took 0.101s
  training loss:		1.337398
  validation loss:		1.219312
  validation accuracy:		59.89 %
Epoch 952 of 2000 took 0.102s
  training loss:		1.340080
  validation loss:		1.227973
  validation accuracy:		61.09 %
Epoch 953 of 2000 took 0.100s
  training loss:		1.333004
  validation loss:		1.228363
  validation accuracy:		59.46 %
Epoch 954 of 2000 took 0.105s
  training loss:		1.329328
  validation loss:		1.250683
  validation accuracy:		59.78 %
Epoch 955 of 2000 took 0.103s
  training loss:		1.339206
  validation loss:		1.249646
  validation accuracy:		59.89 %
Epoch 956 of 2000 took 0.100s
  training loss:		1.329705
  validation loss:		1.225754
  validation accuracy:		59.02 %
Epoch 957 of 2000 took 0.104s
  training loss:		1.335367
  validation loss:		1.215081
  validation accuracy:		59.46 %
Epoch 958 of 2000 took 0.102s
  training loss:		1.327176
  validation loss:		1.220558
  validation accuracy:		59.89 %
Epoch 959 of 2000 took 0.101s
  training loss:		1.339791
  validation loss:		1.214563
  validation accuracy:		60.54 %
Epoch 960 of 2000 took 0.101s
  training loss:		1.333514
  validation loss:		1.221508
  validation accuracy:		60.11 %
Epoch 961 of 2000 took 0.100s
  training loss:		1.340883
  validation loss:		1.226994
  validation accuracy:		57.83 %
Epoch 962 of 2000 took 0.106s
  training loss:		1.336344
  validation loss:		1.232591
  validation accuracy:		60.76 %
Epoch 963 of 2000 took 0.103s
  training loss:		1.334926
  validation loss:		1.227880
  validation accuracy:		59.89 %
Epoch 964 of 2000 took 0.100s
  training loss:		1.335928
  validation loss:		1.221906
  validation accuracy:		60.76 %
Epoch 965 of 2000 took 0.105s
  training loss:		1.337447
  validation loss:		1.222481
  validation accuracy:		61.63 %
Epoch 966 of 2000 took 0.104s
  training loss:		1.338815
  validation loss:		1.211333
  validation accuracy:		59.78 %
Epoch 967 of 2000 took 0.100s
  training loss:		1.327893
  validation loss:		1.218219
  validation accuracy:		59.67 %
Epoch 968 of 2000 took 0.102s
  training loss:		1.338177
  validation loss:		1.211213
  validation accuracy:		60.54 %
Epoch 969 of 2000 took 0.101s
  training loss:		1.340236
  validation loss:		1.235642
  validation accuracy:		61.41 %
Epoch 970 of 2000 took 0.106s
  training loss:		1.330616
  validation loss:		1.208970
  validation accuracy:		61.52 %
Epoch 971 of 2000 took 0.102s
  training loss:		1.342912
  validation loss:		1.227325
  validation accuracy:		61.52 %
Epoch 972 of 2000 took 0.100s
  training loss:		1.331612
  validation loss:		1.221847
  validation accuracy:		59.35 %
Epoch 973 of 2000 took 0.104s
  training loss:		1.334884
  validation loss:		1.274257
  validation accuracy:		57.28 %
Epoch 974 of 2000 took 0.104s
  training loss:		1.334920
  validation loss:		1.216987
  validation accuracy:		61.52 %
Epoch 975 of 2000 took 0.100s
  training loss:		1.336510
  validation loss:		1.218943
  validation accuracy:		61.96 %
Epoch 976 of 2000 took 0.102s
  training loss:		1.331383
  validation loss:		1.213953
  validation accuracy:		61.52 %
Epoch 977 of 2000 took 0.100s
  training loss:		1.328690
  validation loss:		1.213144
  validation accuracy:		61.52 %
Epoch 978 of 2000 took 0.105s
  training loss:		1.330486
  validation loss:		1.230712
  validation accuracy:		62.39 %
Epoch 979 of 2000 took 0.103s
  training loss:		1.325126
  validation loss:		1.227622
  validation accuracy:		60.87 %
Epoch 980 of 2000 took 0.100s
  training loss:		1.334324
  validation loss:		1.237064
  validation accuracy:		61.09 %
Epoch 981 of 2000 took 0.104s
  training loss:		1.331274
  validation loss:		1.212424
  validation accuracy:		62.93 %
Epoch 982 of 2000 took 0.105s
  training loss:		1.334064
  validation loss:		1.221463
  validation accuracy:		62.72 %
Epoch 983 of 2000 took 0.100s
  training loss:		1.326426
  validation loss:		1.209881
  validation accuracy:		60.33 %
Epoch 984 of 2000 took 0.102s
  training loss:		1.332369
  validation loss:		1.219128
  validation accuracy:		61.96 %
Epoch 985 of 2000 took 0.100s
  training loss:		1.321172
  validation loss:		1.216440
  validation accuracy:		62.50 %
Epoch 986 of 2000 took 0.105s
  training loss:		1.325588
  validation loss:		1.204917
  validation accuracy:		62.28 %
Epoch 987 of 2000 took 0.104s
  training loss:		1.322727
  validation loss:		1.212664
  validation accuracy:		59.67 %
Epoch 988 of 2000 took 0.101s
  training loss:		1.339965
  validation loss:		1.224011
  validation accuracy:		61.96 %
Epoch 989 of 2000 took 0.103s
  training loss:		1.330224
  validation loss:		1.206813
  validation accuracy:		60.87 %
Epoch 990 of 2000 took 0.106s
  training loss:		1.319703
  validation loss:		1.243784
  validation accuracy:		61.41 %
Epoch 991 of 2000 took 0.101s
  training loss:		1.335104
  validation loss:		1.217861
  validation accuracy:		62.83 %
Epoch 992 of 2000 took 0.103s
  training loss:		1.317664
  validation loss:		1.205961
  validation accuracy:		62.17 %
Epoch 993 of 2000 took 0.100s
  training loss:		1.330345
  validation loss:		1.217161
  validation accuracy:		61.96 %
Epoch 994 of 2000 took 0.104s
  training loss:		1.323586
  validation loss:		1.214140
  validation accuracy:		62.50 %
Epoch 995 of 2000 took 0.104s
  training loss:		1.320908
  validation loss:		1.239534
  validation accuracy:		62.39 %
Epoch 996 of 2000 took 0.100s
  training loss:		1.339483
  validation loss:		1.219845
  validation accuracy:		62.17 %
Epoch 997 of 2000 took 0.102s
  training loss:		1.331547
  validation loss:		1.247317
  validation accuracy:		62.28 %
Epoch 998 of 2000 took 0.103s
  training loss:		1.325549
  validation loss:		1.247066
  validation accuracy:		62.17 %
Epoch 999 of 2000 took 0.102s
  training loss:		1.320986
  validation loss:		1.223361
  validation accuracy:		62.17 %
Epoch 1000 of 2000 took 0.103s
  training loss:		1.317457
  validation loss:		1.218355
  validation accuracy:		63.37 %
Epoch 1001 of 2000 took 0.103s
  training loss:		1.315266
  validation loss:		1.205688
  validation accuracy:		62.28 %
Epoch 1002 of 2000 took 0.103s
  training loss:		1.321258
  validation loss:		1.228221
  validation accuracy:		62.17 %
Epoch 1003 of 2000 took 0.102s
  training loss:		1.335301
  validation loss:		1.237824
  validation accuracy:		63.15 %
Epoch 1004 of 2000 took 0.103s
  training loss:		1.323646
  validation loss:		1.209716
  validation accuracy:		63.70 %
Epoch 1005 of 2000 took 0.103s
  training loss:		1.311334
  validation loss:		1.208882
  validation accuracy:		63.15 %
Epoch 1006 of 2000 took 0.103s
  training loss:		1.323364
  validation loss:		1.220065
  validation accuracy:		63.59 %
Epoch 1007 of 2000 took 0.103s
  training loss:		1.318599
  validation loss:		1.213211
  validation accuracy:		60.22 %
Epoch 1008 of 2000 took 0.103s
  training loss:		1.316124
  validation loss:		1.204854
  validation accuracy:		63.37 %
Epoch 1009 of 2000 took 0.102s
  training loss:		1.312408
  validation loss:		1.205643
  validation accuracy:		64.02 %
Epoch 1010 of 2000 took 0.102s
  training loss:		1.320984
  validation loss:		1.203486
  validation accuracy:		63.59 %
Epoch 1011 of 2000 took 0.103s
  training loss:		1.310854
  validation loss:		1.200949
  validation accuracy:		63.48 %
Epoch 1012 of 2000 took 0.103s
  training loss:		1.308600
  validation loss:		1.211112
  validation accuracy:		63.59 %
Epoch 1013 of 2000 took 0.102s
  training loss:		1.320825
  validation loss:		1.201343
  validation accuracy:		62.61 %
Epoch 1014 of 2000 took 0.103s
  training loss:		1.318508
  validation loss:		1.202126
  validation accuracy:		63.70 %
Epoch 1015 of 2000 took 0.103s
  training loss:		1.299344
  validation loss:		1.201285
  validation accuracy:		63.48 %
Epoch 1016 of 2000 took 0.102s
  training loss:		1.310567
  validation loss:		1.221197
  validation accuracy:		64.13 %
Epoch 1017 of 2000 took 0.104s
  training loss:		1.314921
  validation loss:		1.229744
  validation accuracy:		63.70 %
Epoch 1018 of 2000 took 0.102s
  training loss:		1.307307
  validation loss:		1.203860
  validation accuracy:		65.22 %
Epoch 1019 of 2000 took 0.103s
  training loss:		1.311536
  validation loss:		1.194055
  validation accuracy:		64.89 %
Epoch 1020 of 2000 took 0.102s
  training loss:		1.301214
  validation loss:		1.182060
  validation accuracy:		65.00 %
Epoch 1021 of 2000 took 0.103s
  training loss:		1.302003
  validation loss:		1.196290
  validation accuracy:		64.67 %
Epoch 1022 of 2000 took 0.103s
  training loss:		1.294598
  validation loss:		1.194669
  validation accuracy:		64.89 %
Epoch 1023 of 2000 took 0.103s
  training loss:		1.301768
  validation loss:		1.180882
  validation accuracy:		62.28 %
Epoch 1024 of 2000 took 0.103s
  training loss:		1.299379
  validation loss:		1.191143
  validation accuracy:		65.54 %
Epoch 1025 of 2000 took 0.102s
  training loss:		1.294658
  validation loss:		1.213300
  validation accuracy:		65.22 %
Epoch 1026 of 2000 took 0.103s
  training loss:		1.300271
  validation loss:		1.207722
  validation accuracy:		64.57 %
Epoch 1027 of 2000 took 0.101s
  training loss:		1.295061
  validation loss:		1.229825
  validation accuracy:		63.26 %
Epoch 1028 of 2000 took 0.102s
  training loss:		1.292204
  validation loss:		1.175359
  validation accuracy:		65.33 %
Epoch 1029 of 2000 took 0.103s
  training loss:		1.291062
  validation loss:		1.165704
  validation accuracy:		64.89 %
Epoch 1030 of 2000 took 0.103s
  training loss:		1.275900
  validation loss:		1.173378
  validation accuracy:		66.30 %
Epoch 1031 of 2000 took 0.103s
  training loss:		1.282375
  validation loss:		1.172053
  validation accuracy:		64.57 %
Epoch 1032 of 2000 took 0.102s
  training loss:		1.271529
  validation loss:		1.173622
  validation accuracy:		67.07 %
Epoch 1033 of 2000 took 0.103s
  training loss:		1.276349
  validation loss:		1.160354
  validation accuracy:		61.85 %
Epoch 1034 of 2000 took 0.103s
  training loss:		1.272977
  validation loss:		1.152327
  validation accuracy:		65.22 %
Epoch 1035 of 2000 took 0.103s
  training loss:		1.266782
  validation loss:		1.148343
  validation accuracy:		66.52 %
Epoch 1036 of 2000 took 0.102s
  training loss:		1.267203
  validation loss:		1.150794
  validation accuracy:		67.28 %
Epoch 1037 of 2000 took 0.100s
  training loss:		1.257042
  validation loss:		1.141845
  validation accuracy:		68.70 %
Epoch 1038 of 2000 took 0.102s
  training loss:		1.248223
  validation loss:		1.146562
  validation accuracy:		67.17 %
Epoch 1039 of 2000 took 0.102s
  training loss:		1.249911
  validation loss:		1.162918
  validation accuracy:		67.07 %
Epoch 1040 of 2000 took 0.102s
  training loss:		1.250263
  validation loss:		1.123830
  validation accuracy:		67.07 %
Epoch 1041 of 2000 took 0.103s
  training loss:		1.232407
  validation loss:		1.127416
  validation accuracy:		69.13 %
Epoch 1042 of 2000 took 0.102s
  training loss:		1.232026
  validation loss:		1.114353
  validation accuracy:		68.91 %
Epoch 1043 of 2000 took 0.103s
  training loss:		1.226909
  validation loss:		1.107625
  validation accuracy:		68.15 %
Epoch 1044 of 2000 took 0.102s
  training loss:		1.225311
  validation loss:		1.091367
  validation accuracy:		69.24 %
Epoch 1045 of 2000 took 0.103s
  training loss:		1.201723
  validation loss:		1.084183
  validation accuracy:		66.96 %
Epoch 1046 of 2000 took 0.102s
  training loss:		1.198851
  validation loss:		1.065669
  validation accuracy:		68.04 %
Epoch 1047 of 2000 took 0.101s
  training loss:		1.191091
  validation loss:		1.089439
  validation accuracy:		68.48 %
Epoch 1048 of 2000 took 0.102s
  training loss:		1.178555
  validation loss:		1.052613
  validation accuracy:		68.59 %
Epoch 1049 of 2000 took 0.102s
  training loss:		1.167575
  validation loss:		1.044082
  validation accuracy:		70.00 %
Epoch 1050 of 2000 took 0.103s
  training loss:		1.154154
  validation loss:		1.046068
  validation accuracy:		69.02 %
Epoch 1051 of 2000 took 0.103s
  training loss:		1.137923
  validation loss:		1.020493
  validation accuracy:		69.02 %
Epoch 1052 of 2000 took 0.102s
  training loss:		1.128467
  validation loss:		1.016307
  validation accuracy:		70.22 %
Epoch 1053 of 2000 took 0.103s
  training loss:		1.123600
  validation loss:		1.010522
  validation accuracy:		69.57 %
Epoch 1054 of 2000 took 0.103s
  training loss:		1.117704
  validation loss:		0.990328
  validation accuracy:		68.70 %
Epoch 1055 of 2000 took 0.103s
  training loss:		1.104674
  validation loss:		0.978894
  validation accuracy:		69.57 %
Epoch 1056 of 2000 took 0.103s
  training loss:		1.087023
  validation loss:		0.999420
  validation accuracy:		69.46 %
Epoch 1057 of 2000 took 0.101s
  training loss:		1.081229
  validation loss:		0.969782
  validation accuracy:		70.54 %
Epoch 1058 of 2000 took 0.101s
  training loss:		1.080360
  validation loss:		0.949619
  validation accuracy:		69.46 %
Epoch 1059 of 2000 took 0.103s
  training loss:		1.057112
  validation loss:		0.967524
  validation accuracy:		70.00 %
Epoch 1060 of 2000 took 0.103s
  training loss:		1.051053
  validation loss:		0.921286
  validation accuracy:		69.46 %
Epoch 1061 of 2000 took 0.103s
  training loss:		1.040465
  validation loss:		0.915111
  validation accuracy:		68.91 %
Epoch 1062 of 2000 took 0.102s
  training loss:		1.030590
  validation loss:		0.920722
  validation accuracy:		71.41 %
Epoch 1063 of 2000 took 0.102s
  training loss:		1.023067
  validation loss:		0.917223
  validation accuracy:		71.20 %
Epoch 1064 of 2000 took 0.103s
  training loss:		1.011413
  validation loss:		0.900793
  validation accuracy:		71.63 %
Epoch 1065 of 2000 took 0.103s
  training loss:		1.002899
  validation loss:		0.884231
  validation accuracy:		71.96 %
Epoch 1066 of 2000 took 0.104s
  training loss:		0.991496
  validation loss:		0.859136
  validation accuracy:		72.07 %
Epoch 1067 of 2000 took 0.104s
  training loss:		0.980520
  validation loss:		0.859634
  validation accuracy:		72.39 %
Epoch 1068 of 2000 took 0.101s
  training loss:		0.971559
  validation loss:		0.849615
  validation accuracy:		72.61 %
Epoch 1069 of 2000 took 0.106s
  training loss:		0.962850
  validation loss:		0.870752
  validation accuracy:		73.26 %
Epoch 1070 of 2000 took 0.106s
  training loss:		0.950189
  validation loss:		0.855264
  validation accuracy:		72.39 %
Epoch 1071 of 2000 took 0.103s
  training loss:		0.944217
  validation loss:		0.849355
  validation accuracy:		73.91 %
Epoch 1072 of 2000 took 0.103s
  training loss:		0.932167
  validation loss:		0.844360
  validation accuracy:		73.91 %
Epoch 1073 of 2000 took 0.103s
  training loss:		0.925156
  validation loss:		0.812329
  validation accuracy:		73.48 %
Epoch 1074 of 2000 took 0.103s
  training loss:		0.917964
  validation loss:		0.797702
  validation accuracy:		73.59 %
Epoch 1075 of 2000 took 0.103s
  training loss:		0.912043
  validation loss:		0.789628
  validation accuracy:		74.24 %
Epoch 1076 of 2000 took 0.101s
  training loss:		0.907950
  validation loss:		0.783236
  validation accuracy:		74.24 %
Epoch 1077 of 2000 took 0.102s
  training loss:		0.889581
  validation loss:		0.776313
  validation accuracy:		74.35 %
Epoch 1078 of 2000 took 0.100s
  training loss:		0.887423
  validation loss:		0.769878
  validation accuracy:		75.11 %
Epoch 1079 of 2000 took 0.102s
  training loss:		0.884246
  validation loss:		0.765618
  validation accuracy:		75.00 %
Epoch 1080 of 2000 took 0.103s
  training loss:		0.867040
  validation loss:		0.768481
  validation accuracy:		74.67 %
Epoch 1081 of 2000 took 0.103s
  training loss:		0.873445
  validation loss:		0.761324
  validation accuracy:		74.35 %
Epoch 1082 of 2000 took 0.103s
  training loss:		0.866966
  validation loss:		0.754791
  validation accuracy:		75.76 %
Epoch 1083 of 2000 took 0.103s
  training loss:		0.847334
  validation loss:		0.745075
  validation accuracy:		75.33 %
Epoch 1084 of 2000 took 0.103s
  training loss:		0.835602
  validation loss:		0.742024
  validation accuracy:		75.22 %
Epoch 1085 of 2000 took 0.103s
  training loss:		0.832704
  validation loss:		0.734362
  validation accuracy:		75.00 %
Epoch 1086 of 2000 took 0.103s
  training loss:		0.829375
  validation loss:		0.731809
  validation accuracy:		76.20 %
Epoch 1087 of 2000 took 0.100s
  training loss:		0.832350
  validation loss:		0.729706
  validation accuracy:		75.98 %
Epoch 1088 of 2000 took 0.104s
  training loss:		0.817794
  validation loss:		0.737196
  validation accuracy:		75.33 %
Epoch 1089 of 2000 took 0.103s
  training loss:		0.812479
  validation loss:		0.730356
  validation accuracy:		76.20 %
Epoch 1090 of 2000 took 0.103s
  training loss:		0.798481
  validation loss:		0.725848
  validation accuracy:		75.54 %
Epoch 1091 of 2000 took 0.103s
  training loss:		0.804165
  validation loss:		0.707490
  validation accuracy:		76.52 %
Epoch 1092 of 2000 took 0.103s
  training loss:		0.799656
  validation loss:		0.720622
  validation accuracy:		75.00 %
Epoch 1093 of 2000 took 0.103s
  training loss:		0.797057
  validation loss:		0.704885
  validation accuracy:		75.54 %
Epoch 1094 of 2000 took 0.103s
  training loss:		0.785907
  validation loss:		0.708606
  validation accuracy:		76.52 %
Epoch 1095 of 2000 took 0.102s
  training loss:		0.779055
  validation loss:		0.702682
  validation accuracy:		75.54 %
Epoch 1096 of 2000 took 0.100s
  training loss:		0.784640
  validation loss:		0.688656
  validation accuracy:		76.85 %
Epoch 1097 of 2000 took 0.104s
  training loss:		0.773267
  validation loss:		0.700526
  validation accuracy:		76.41 %
Epoch 1098 of 2000 took 0.105s
  training loss:		0.771041
  validation loss:		0.676608
  validation accuracy:		76.96 %
Epoch 1099 of 2000 took 0.103s
  training loss:		0.766721
  validation loss:		0.684085
  validation accuracy:		76.74 %
Epoch 1100 of 2000 took 0.103s
  training loss:		0.760836
  validation loss:		0.686747
  validation accuracy:		76.63 %
Epoch 1101 of 2000 took 0.103s
  training loss:		0.754697
  validation loss:		0.682461
  validation accuracy:		77.39 %
Epoch 1102 of 2000 took 0.103s
  training loss:		0.754408
  validation loss:		0.685920
  validation accuracy:		77.07 %
Epoch 1103 of 2000 took 0.104s
  training loss:		0.759607
  validation loss:		0.675001
  validation accuracy:		77.17 %
Epoch 1104 of 2000 took 0.103s
  training loss:		0.734962
  validation loss:		0.684906
  validation accuracy:		76.63 %
Epoch 1105 of 2000 took 0.102s
  training loss:		0.728466
  validation loss:		0.678037
  validation accuracy:		77.39 %
Epoch 1106 of 2000 took 0.104s
  training loss:		0.738400
  validation loss:		0.667002
  validation accuracy:		77.61 %
Epoch 1107 of 2000 took 0.105s
  training loss:		0.742419
  validation loss:		0.681230
  validation accuracy:		76.74 %
Epoch 1108 of 2000 took 0.101s
  training loss:		0.731801
  validation loss:		0.665446
  validation accuracy:		77.72 %
Epoch 1109 of 2000 took 0.102s
  training loss:		0.715760
  validation loss:		0.651564
  validation accuracy:		78.04 %
Epoch 1110 of 2000 took 0.103s
  training loss:		0.731200
  validation loss:		0.669702
  validation accuracy:		77.39 %
Epoch 1111 of 2000 took 0.103s
  training loss:		0.721197
  validation loss:		0.667369
  validation accuracy:		78.04 %
Epoch 1112 of 2000 took 0.103s
  training loss:		0.719545
  validation loss:		0.647402
  validation accuracy:		77.93 %
Epoch 1113 of 2000 took 0.103s
  training loss:		0.727010
  validation loss:		0.645682
  validation accuracy:		78.59 %
Epoch 1114 of 2000 took 0.103s
  training loss:		0.711264
  validation loss:		0.660117
  validation accuracy:		78.04 %
Epoch 1115 of 2000 took 0.106s
  training loss:		0.706249
  validation loss:		0.674428
  validation accuracy:		77.07 %
Epoch 1116 of 2000 took 0.106s
  training loss:		0.708961
  validation loss:		0.647941
  validation accuracy:		78.48 %
Epoch 1117 of 2000 took 0.101s
  training loss:		0.702963
  validation loss:		0.669502
  validation accuracy:		77.83 %
Epoch 1118 of 2000 took 0.104s
  training loss:		0.702304
  validation loss:		0.643683
  validation accuracy:		79.02 %
Epoch 1119 of 2000 took 0.104s
  training loss:		0.691544
  validation loss:		0.644053
  validation accuracy:		78.91 %
Epoch 1120 of 2000 took 0.103s
  training loss:		0.702330
  validation loss:		0.699312
  validation accuracy:		75.43 %
Epoch 1121 of 2000 took 0.103s
  training loss:		0.698575
  validation loss:		0.634332
  validation accuracy:		78.37 %
Epoch 1122 of 2000 took 0.103s
  training loss:		0.694836
  validation loss:		0.641992
  validation accuracy:		78.70 %
Epoch 1123 of 2000 took 0.103s
  training loss:		0.682335
  validation loss:		0.650722
  validation accuracy:		77.93 %
Epoch 1124 of 2000 took 0.103s
  training loss:		0.679402
  validation loss:		0.635996
  validation accuracy:		78.70 %
Epoch 1125 of 2000 took 0.100s
  training loss:		0.695770
  validation loss:		0.651452
  validation accuracy:		78.59 %
Epoch 1126 of 2000 took 0.103s
  training loss:		0.680984
  validation loss:		0.630746
  validation accuracy:		78.59 %
Epoch 1127 of 2000 took 0.107s
  training loss:		0.690516
  validation loss:		0.633061
  validation accuracy:		78.91 %
Epoch 1128 of 2000 took 0.100s
  training loss:		0.680243
  validation loss:		0.650250
  validation accuracy:		78.37 %
Epoch 1129 of 2000 took 0.102s
  training loss:		0.674724
  validation loss:		0.622600
  validation accuracy:		78.59 %
Epoch 1130 of 2000 took 0.103s
  training loss:		0.676491
  validation loss:		0.644707
  validation accuracy:		78.80 %
Epoch 1131 of 2000 took 0.103s
  training loss:		0.674807
  validation loss:		0.638893
  validation accuracy:		78.91 %
Epoch 1132 of 2000 took 0.102s
  training loss:		0.671961
  validation loss:		0.641138
  validation accuracy:		78.91 %
Epoch 1133 of 2000 took 0.103s
  training loss:		0.670794
  validation loss:		0.621307
  validation accuracy:		79.24 %
Epoch 1134 of 2000 took 0.105s
  training loss:		0.662490
  validation loss:		0.646238
  validation accuracy:		78.80 %
Epoch 1135 of 2000 took 0.102s
  training loss:		0.657634
  validation loss:		0.632656
  validation accuracy:		78.59 %
Epoch 1136 of 2000 took 0.101s
  training loss:		0.676085
  validation loss:		0.634314
  validation accuracy:		78.04 %
Epoch 1137 of 2000 took 0.101s
  training loss:		0.670391
  validation loss:		0.630639
  validation accuracy:		79.46 %
Epoch 1138 of 2000 took 0.101s
  training loss:		0.659829
  validation loss:		0.630233
  validation accuracy:		79.13 %
Epoch 1139 of 2000 took 0.103s
  training loss:		0.642180
  validation loss:		0.621613
  validation accuracy:		78.48 %
Epoch 1140 of 2000 took 0.103s
  training loss:		0.656158
  validation loss:		0.641106
  validation accuracy:		79.02 %
Epoch 1141 of 2000 took 0.103s
  training loss:		0.656217
  validation loss:		0.613780
  validation accuracy:		79.24 %
Epoch 1142 of 2000 took 0.103s
  training loss:		0.665823
  validation loss:		0.639952
  validation accuracy:		78.80 %
Epoch 1143 of 2000 took 0.103s
  training loss:		0.652593
  validation loss:		0.628355
  validation accuracy:		79.67 %
Epoch 1144 of 2000 took 0.103s
  training loss:		0.654245
  validation loss:		0.621711
  validation accuracy:		79.67 %
Epoch 1145 of 2000 took 0.100s
  training loss:		0.657996
  validation loss:		0.619170
  validation accuracy:		78.59 %
Epoch 1146 of 2000 took 0.104s
  training loss:		0.645737
  validation loss:		0.631990
  validation accuracy:		79.13 %
Epoch 1147 of 2000 took 0.104s
  training loss:		0.668936
  validation loss:		0.642525
  validation accuracy:		79.24 %
Epoch 1148 of 2000 took 0.100s
  training loss:		0.653004
  validation loss:		0.625668
  validation accuracy:		79.57 %
Epoch 1149 of 2000 took 0.102s
  training loss:		0.652262
  validation loss:		0.641809
  validation accuracy:		79.24 %
Epoch 1150 of 2000 took 0.103s
  training loss:		0.653979
  validation loss:		0.618225
  validation accuracy:		79.57 %
Epoch 1151 of 2000 took 0.102s
  training loss:		0.653725
  validation loss:		0.609193
  validation accuracy:		79.02 %
Epoch 1152 of 2000 took 0.102s
  training loss:		0.652730
  validation loss:		0.614337
  validation accuracy:		79.57 %
Epoch 1153 of 2000 took 0.103s
  training loss:		0.643215
  validation loss:		0.653321
  validation accuracy:		78.91 %
Epoch 1154 of 2000 took 0.105s
  training loss:		0.644785
  validation loss:		0.620011
  validation accuracy:		79.89 %
Epoch 1155 of 2000 took 0.102s
  training loss:		0.641856
  validation loss:		0.632903
  validation accuracy:		79.78 %
Epoch 1156 of 2000 took 0.101s
  training loss:		0.641999
  validation loss:		0.630391
  validation accuracy:		79.57 %
Epoch 1157 of 2000 took 0.106s
  training loss:		0.643646
  validation loss:		0.611349
  validation accuracy:		79.67 %
Epoch 1158 of 2000 took 0.101s
  training loss:		0.643011
  validation loss:		0.618552
  validation accuracy:		79.35 %
Epoch 1159 of 2000 took 0.101s
  training loss:		0.644985
  validation loss:		0.648937
  validation accuracy:		78.91 %
Epoch 1160 of 2000 took 0.103s
  training loss:		0.632177
  validation loss:		0.611838
  validation accuracy:		79.89 %
Epoch 1161 of 2000 took 0.103s
  training loss:		0.637528
  validation loss:		0.613722
  validation accuracy:		80.00 %
Epoch 1162 of 2000 took 0.103s
  training loss:		0.644934
  validation loss:		0.604923
  validation accuracy:		79.89 %
Epoch 1163 of 2000 took 0.103s
  training loss:		0.636603
  validation loss:		0.623401
  validation accuracy:		80.00 %
Epoch 1164 of 2000 took 0.103s
  training loss:		0.633128
  validation loss:		0.625880
  validation accuracy:		79.89 %
Epoch 1165 of 2000 took 0.106s
  training loss:		0.632142
  validation loss:		0.607882
  validation accuracy:		79.89 %
Epoch 1166 of 2000 took 0.100s
  training loss:		0.626663
  validation loss:		0.622368
  validation accuracy:		80.22 %
Epoch 1167 of 2000 took 0.102s
  training loss:		0.630052
  validation loss:		0.611656
  validation accuracy:		79.67 %
Epoch 1168 of 2000 took 0.100s
  training loss:		0.630117
  validation loss:		0.598917
  validation accuracy:		79.35 %
Epoch 1169 of 2000 took 0.102s
  training loss:		0.634527
  validation loss:		0.605889
  validation accuracy:		79.78 %
Epoch 1170 of 2000 took 0.103s
  training loss:		0.627332
  validation loss:		0.605716
  validation accuracy:		80.43 %
Epoch 1171 of 2000 took 0.103s
  training loss:		0.626500
  validation loss:		0.639862
  validation accuracy:		79.35 %
Epoch 1172 of 2000 took 0.103s
  training loss:		0.631602
  validation loss:		0.615085
  validation accuracy:		80.87 %
Epoch 1173 of 2000 took 0.102s
  training loss:		0.620928
  validation loss:		0.620321
  validation accuracy:		80.22 %
Epoch 1174 of 2000 took 0.101s
  training loss:		0.625590
  validation loss:		0.613642
  validation accuracy:		80.11 %
Epoch 1175 of 2000 took 0.101s
  training loss:		0.654022
  validation loss:		0.621223
  validation accuracy:		79.89 %
Epoch 1176 of 2000 took 0.101s
  training loss:		0.636886
  validation loss:		0.614914
  validation accuracy:		80.76 %
Epoch 1177 of 2000 took 0.105s
  training loss:		0.622937
  validation loss:		0.600188
  validation accuracy:		78.91 %
Epoch 1178 of 2000 took 0.102s
  training loss:		0.622069
  validation loss:		0.596376
  validation accuracy:		80.11 %
Epoch 1179 of 2000 took 0.102s
  training loss:		0.626320
  validation loss:		0.630418
  validation accuracy:		79.89 %
Epoch 1180 of 2000 took 0.103s
  training loss:		0.627544
  validation loss:		0.612558
  validation accuracy:		80.54 %
Epoch 1181 of 2000 took 0.103s
  training loss:		0.623627
  validation loss:		0.601029
  validation accuracy:		80.33 %
Epoch 1182 of 2000 took 0.103s
  training loss:		0.627323
  validation loss:		0.614999
  validation accuracy:		79.89 %
Epoch 1183 of 2000 took 0.098s
  training loss:		0.616671
  validation loss:		0.603824
  validation accuracy:		80.98 %
Epoch 1184 of 2000 took 0.097s
  training loss:		0.621229
  validation loss:		0.604670
  validation accuracy:		80.22 %
Epoch 1185 of 2000 took 0.097s
  training loss:		0.631789
  validation loss:		0.644788
  validation accuracy:		79.57 %
Epoch 1186 of 2000 took 0.097s
  training loss:		0.622754
  validation loss:		0.596896
  validation accuracy:		79.67 %
Epoch 1187 of 2000 took 0.097s
  training loss:		0.634077
  validation loss:		0.597630
  validation accuracy:		80.33 %
Epoch 1188 of 2000 took 0.097s
  training loss:		0.617734
  validation loss:		0.599839
  validation accuracy:		80.33 %
Epoch 1189 of 2000 took 0.097s
  training loss:		0.615791
  validation loss:		0.616872
  validation accuracy:		80.43 %
Epoch 1190 of 2000 took 0.097s
  training loss:		0.614941
  validation loss:		0.617125
  validation accuracy:		80.43 %
Epoch 1191 of 2000 took 0.097s
  training loss:		0.615720
  validation loss:		0.605522
  validation accuracy:		80.33 %
Epoch 1192 of 2000 took 0.097s
  training loss:		0.624609
  validation loss:		0.647338
  validation accuracy:		79.57 %
Epoch 1193 of 2000 took 0.097s
  training loss:		0.626280
  validation loss:		0.596872
  validation accuracy:		79.89 %
Epoch 1194 of 2000 took 0.097s
  training loss:		0.620657
  validation loss:		0.609514
  validation accuracy:		80.43 %
Epoch 1195 of 2000 took 0.096s
  training loss:		0.650003
  validation loss:		0.627941
  validation accuracy:		79.67 %
Epoch 1196 of 2000 took 0.097s
  training loss:		0.606431
  validation loss:		0.593939
  validation accuracy:		80.43 %
Epoch 1197 of 2000 took 0.096s
  training loss:		0.601186
  validation loss:		0.618309
  validation accuracy:		79.24 %
Epoch 1198 of 2000 took 0.097s
  training loss:		0.620316
  validation loss:		0.610189
  validation accuracy:		80.33 %
Epoch 1199 of 2000 took 0.096s
  training loss:		0.617551
  validation loss:		0.614253
  validation accuracy:		80.54 %
Epoch 1200 of 2000 took 0.097s
  training loss:		0.624163
  validation loss:		0.611508
  validation accuracy:		81.20 %
Epoch 1201 of 2000 took 0.097s
  training loss:		0.619341
  validation loss:		0.597665
  validation accuracy:		79.89 %
Epoch 1202 of 2000 took 0.097s
  training loss:		0.606785
  validation loss:		0.599390
  validation accuracy:		81.41 %
Epoch 1203 of 2000 took 0.096s
  training loss:		0.621699
  validation loss:		0.614078
  validation accuracy:		79.89 %
Epoch 1204 of 2000 took 0.097s
  training loss:		0.613675
  validation loss:		0.599702
  validation accuracy:		81.30 %
Epoch 1205 of 2000 took 0.096s
  training loss:		0.611780
  validation loss:		0.600281
  validation accuracy:		81.09 %
Epoch 1206 of 2000 took 0.097s
  training loss:		0.610572
  validation loss:		0.623004
  validation accuracy:		80.43 %
Epoch 1207 of 2000 took 0.096s
  training loss:		0.615507
  validation loss:		0.614051
  validation accuracy:		80.87 %
Epoch 1208 of 2000 took 0.097s
  training loss:		0.616784
  validation loss:		0.607295
  validation accuracy:		80.43 %
Epoch 1209 of 2000 took 0.096s
  training loss:		0.596821
  validation loss:		0.602958
  validation accuracy:		80.43 %
Epoch 1210 of 2000 took 0.100s
  training loss:		0.615280
  validation loss:		0.604764
  validation accuracy:		81.52 %
Epoch 1211 of 2000 took 0.103s
  training loss:		0.614488
  validation loss:		0.598341
  validation accuracy:		80.87 %
Epoch 1212 of 2000 took 0.103s
  training loss:		0.609508
  validation loss:		0.639199
  validation accuracy:		79.57 %
Epoch 1213 of 2000 took 0.103s
  training loss:		0.625283
  validation loss:		0.603034
  validation accuracy:		80.87 %
Epoch 1214 of 2000 took 0.103s
  training loss:		0.615912
  validation loss:		0.590670
  validation accuracy:		80.11 %
Epoch 1215 of 2000 took 0.103s
  training loss:		0.608185
  validation loss:		0.590679
  validation accuracy:		80.54 %
Epoch 1216 of 2000 took 0.103s
  training loss:		0.613014
  validation loss:		0.586110
  validation accuracy:		80.11 %
Epoch 1217 of 2000 took 0.103s
  training loss:		0.593844
  validation loss:		0.599324
  validation accuracy:		80.65 %
Epoch 1218 of 2000 took 0.101s
  training loss:		0.605567
  validation loss:		0.593005
  validation accuracy:		80.22 %
Epoch 1219 of 2000 took 0.096s
  training loss:		0.610493
  validation loss:		0.606285
  validation accuracy:		80.65 %
Epoch 1220 of 2000 took 0.097s
  training loss:		0.632794
  validation loss:		0.656499
  validation accuracy:		78.70 %
Epoch 1221 of 2000 took 0.096s
  training loss:		0.630836
  validation loss:		0.624786
  validation accuracy:		80.43 %
Epoch 1222 of 2000 took 0.096s
  training loss:		0.609966
  validation loss:		0.599208
  validation accuracy:		81.09 %
Epoch 1223 of 2000 took 0.097s
  training loss:		0.616917
  validation loss:		0.666734
  validation accuracy:		77.93 %
Epoch 1224 of 2000 took 0.097s
  training loss:		0.602486
  validation loss:		0.596637
  validation accuracy:		80.98 %
Epoch 1225 of 2000 took 0.097s
  training loss:		0.601503
  validation loss:		0.606472
  validation accuracy:		80.65 %
Epoch 1226 of 2000 took 0.097s
  training loss:		0.611127
  validation loss:		0.586134
  validation accuracy:		80.87 %
Epoch 1227 of 2000 took 0.097s
  training loss:		0.607159
  validation loss:		0.608564
  validation accuracy:		80.87 %
Epoch 1228 of 2000 took 0.097s
  training loss:		0.610709
  validation loss:		0.615159
  validation accuracy:		80.11 %
Epoch 1229 of 2000 took 0.097s
  training loss:		0.621841
  validation loss:		0.614400
  validation accuracy:		80.76 %
Epoch 1230 of 2000 took 0.097s
  training loss:		0.633313
  validation loss:		0.660947
  validation accuracy:		77.93 %
Epoch 1231 of 2000 took 0.096s
  training loss:		0.614104
  validation loss:		0.628654
  validation accuracy:		80.43 %
Epoch 1232 of 2000 took 0.097s
  training loss:		0.605691
  validation loss:		0.626991
  validation accuracy:		80.76 %
Epoch 1233 of 2000 took 0.096s
  training loss:		0.608869
  validation loss:		0.626146
  validation accuracy:		80.00 %
Epoch 1234 of 2000 took 0.096s
  training loss:		0.621119
  validation loss:		0.639049
  validation accuracy:		80.43 %
Epoch 1235 of 2000 took 0.097s
  training loss:		0.603184
  validation loss:		0.627542
  validation accuracy:		80.54 %
Epoch 1236 of 2000 took 0.096s
  training loss:		0.604834
  validation loss:		0.608595
  validation accuracy:		80.76 %
Epoch 1237 of 2000 took 0.096s
  training loss:		0.606040
  validation loss:		0.588943
  validation accuracy:		81.20 %
Epoch 1238 of 2000 took 0.097s
  training loss:		0.604149
  validation loss:		0.607653
  validation accuracy:		80.76 %
Epoch 1239 of 2000 took 0.097s
  training loss:		0.603788
  validation loss:		0.607231
  validation accuracy:		80.98 %
Epoch 1240 of 2000 took 0.097s
  training loss:		0.594944
  validation loss:		0.596701
  validation accuracy:		80.65 %
Epoch 1241 of 2000 took 0.097s
  training loss:		0.607951
  validation loss:		0.589684
  validation accuracy:		81.63 %
Epoch 1242 of 2000 took 0.097s
  training loss:		0.618031
  validation loss:		0.610160
  validation accuracy:		80.98 %
Epoch 1243 of 2000 took 0.097s
  training loss:		0.592763
  validation loss:		0.598250
  validation accuracy:		80.65 %
Epoch 1244 of 2000 took 0.096s
  training loss:		0.588830
  validation loss:		0.607992
  validation accuracy:		81.09 %
Epoch 1245 of 2000 took 0.098s
  training loss:		0.608060
  validation loss:		0.583585
  validation accuracy:		80.98 %
Epoch 1246 of 2000 took 0.096s
  training loss:		0.607069
  validation loss:		0.592084
  validation accuracy:		80.98 %
Epoch 1247 of 2000 took 0.097s
  training loss:		0.614344
  validation loss:		0.610546
  validation accuracy:		81.20 %
Epoch 1248 of 2000 took 0.096s
  training loss:		0.612624
  validation loss:		0.661321
  validation accuracy:		78.26 %
Epoch 1249 of 2000 took 0.097s
  training loss:		0.610382
  validation loss:		0.612368
  validation accuracy:		80.87 %
Epoch 1250 of 2000 took 0.097s
  training loss:		0.590302
  validation loss:		0.592429
  validation accuracy:		81.41 %
Epoch 1251 of 2000 took 0.097s
  training loss:		0.615852
  validation loss:		0.680602
  validation accuracy:		77.72 %
Epoch 1252 of 2000 took 0.096s
  training loss:		0.619166
  validation loss:		0.581998
  validation accuracy:		80.98 %
Epoch 1253 of 2000 took 0.096s
  training loss:		0.602107
  validation loss:		0.601342
  validation accuracy:		81.20 %
Epoch 1254 of 2000 took 0.097s
  training loss:		0.595756
  validation loss:		0.607496
  validation accuracy:		81.20 %
Epoch 1255 of 2000 took 0.097s
  training loss:		0.593609
  validation loss:		0.580354
  validation accuracy:		80.33 %
Epoch 1256 of 2000 took 0.097s
  training loss:		0.604753
  validation loss:		0.602777
  validation accuracy:		81.63 %
Epoch 1257 of 2000 took 0.097s
  training loss:		0.590277
  validation loss:		0.608033
  validation accuracy:		81.74 %
Epoch 1258 of 2000 took 0.097s
  training loss:		0.610695
  validation loss:		0.649058
  validation accuracy:		78.37 %
Epoch 1259 of 2000 took 0.097s
  training loss:		0.603122
  validation loss:		0.606823
  validation accuracy:		81.30 %
Epoch 1260 of 2000 took 0.097s
  training loss:		0.599078
  validation loss:		0.630707
  validation accuracy:		80.11 %
Epoch 1261 of 2000 took 0.097s
  training loss:		0.591492
  validation loss:		0.596609
  validation accuracy:		81.52 %
Epoch 1262 of 2000 took 0.097s
  training loss:		0.591913
  validation loss:		0.610141
  validation accuracy:		81.09 %
Epoch 1263 of 2000 took 0.097s
  training loss:		0.593695
  validation loss:		0.630485
  validation accuracy:		80.33 %
Epoch 1264 of 2000 took 0.097s
  training loss:		0.599514
  validation loss:		0.616098
  validation accuracy:		80.76 %
Epoch 1265 of 2000 took 0.097s
  training loss:		0.598516
  validation loss:		0.617334
  validation accuracy:		81.20 %
Epoch 1266 of 2000 took 0.097s
  training loss:		0.594651
  validation loss:		0.603205
  validation accuracy:		81.52 %
Epoch 1267 of 2000 took 0.096s
  training loss:		0.599645
  validation loss:		0.605346
  validation accuracy:		81.30 %
Epoch 1268 of 2000 took 0.097s
  training loss:		0.592750
  validation loss:		0.590773
  validation accuracy:		81.20 %
Epoch 1269 of 2000 took 0.097s
  training loss:		0.599708
  validation loss:		0.597919
  validation accuracy:		81.52 %
Epoch 1270 of 2000 took 0.097s
  training loss:		0.612681
  validation loss:		0.594532
  validation accuracy:		81.85 %
Epoch 1271 of 2000 took 0.096s
  training loss:		0.614241
  validation loss:		0.634680
  validation accuracy:		79.67 %
Epoch 1272 of 2000 took 0.097s
  training loss:		0.598555
  validation loss:		0.588444
  validation accuracy:		80.98 %
Epoch 1273 of 2000 took 0.097s
  training loss:		0.590465
  validation loss:		0.611258
  validation accuracy:		81.41 %
Epoch 1274 of 2000 took 0.097s
  training loss:		0.599571
  validation loss:		0.678125
  validation accuracy:		77.28 %
Epoch 1275 of 2000 took 0.096s
  training loss:		0.613990
  validation loss:		0.602549
  validation accuracy:		81.63 %
Epoch 1276 of 2000 took 0.097s
  training loss:		0.611512
  validation loss:		0.623041
  validation accuracy:		79.89 %
Epoch 1277 of 2000 took 0.099s
  training loss:		0.601282
  validation loss:		0.620134
  validation accuracy:		80.87 %
Epoch 1278 of 2000 took 0.100s
  training loss:		0.622568
  validation loss:		0.589231
  validation accuracy:		81.74 %
Epoch 1279 of 2000 took 0.100s
  training loss:		0.604076
  validation loss:		0.597560
  validation accuracy:		81.52 %
Epoch 1280 of 2000 took 0.099s
  training loss:		0.601447
  validation loss:		0.608646
  validation accuracy:		80.76 %
Epoch 1281 of 2000 took 0.097s
  training loss:		0.593886
  validation loss:		0.591771
  validation accuracy:		81.63 %
Epoch 1282 of 2000 took 0.097s
  training loss:		0.594053
  validation loss:		0.607053
  validation accuracy:		81.09 %
Epoch 1283 of 2000 took 0.096s
  training loss:		0.600713
  validation loss:		0.629149
  validation accuracy:		79.67 %
Epoch 1284 of 2000 took 0.097s
  training loss:		0.603173
  validation loss:		0.597645
  validation accuracy:		81.63 %
Epoch 1285 of 2000 took 0.097s
  training loss:		0.589883
  validation loss:		0.612062
  validation accuracy:		80.98 %
Epoch 1286 of 2000 took 0.097s
  training loss:		0.596261
  validation loss:		0.597503
  validation accuracy:		80.98 %
Epoch 1287 of 2000 took 0.096s
  training loss:		0.605242
  validation loss:		0.619136
  validation accuracy:		80.54 %
Epoch 1288 of 2000 took 0.097s
  training loss:		0.602656
  validation loss:		0.637040
  validation accuracy:		79.13 %
Epoch 1289 of 2000 took 0.096s
  training loss:		0.589196
  validation loss:		0.603061
  validation accuracy:		81.63 %
Epoch 1290 of 2000 took 0.097s
  training loss:		0.585190
  validation loss:		0.605567
  validation accuracy:		81.30 %
Epoch 1291 of 2000 took 0.097s
  training loss:		0.597434
  validation loss:		0.617953
  validation accuracy:		80.98 %
Epoch 1292 of 2000 took 0.097s
  training loss:		0.590915
  validation loss:		0.590470
  validation accuracy:		81.96 %
Epoch 1293 of 2000 took 0.097s
  training loss:		0.608614
  validation loss:		0.619504
  validation accuracy:		80.65 %
Epoch 1294 of 2000 took 0.097s
  training loss:		0.600201
  validation loss:		0.594690
  validation accuracy:		81.96 %
Epoch 1295 of 2000 took 0.096s
  training loss:		0.589494
  validation loss:		0.594458
  validation accuracy:		81.96 %
Epoch 1296 of 2000 took 0.097s
  training loss:		0.595517
  validation loss:		0.610501
  validation accuracy:		81.20 %
Epoch 1297 of 2000 took 0.096s
  training loss:		0.595558
  validation loss:		0.592459
  validation accuracy:		81.85 %
Epoch 1298 of 2000 took 0.096s
  training loss:		0.592493
  validation loss:		0.625332
  validation accuracy:		80.22 %
Epoch 1299 of 2000 took 0.097s
  training loss:		0.596669
  validation loss:		0.597995
  validation accuracy:		81.63 %
Epoch 1300 of 2000 took 0.096s
  training loss:		0.592181
  validation loss:		0.640880
  validation accuracy:		79.02 %
Epoch 1301 of 2000 took 0.097s
  training loss:		0.601846
  validation loss:		0.591124
  validation accuracy:		81.74 %
Epoch 1302 of 2000 took 0.096s
  training loss:		0.596055
  validation loss:		0.598943
  validation accuracy:		82.07 %
Epoch 1303 of 2000 took 0.097s
  training loss:		0.592352
  validation loss:		0.596444
  validation accuracy:		82.17 %
Epoch 1304 of 2000 took 0.097s
  training loss:		0.593588
  validation loss:		0.608059
  validation accuracy:		81.41 %
Epoch 1305 of 2000 took 0.097s
  training loss:		0.584989
  validation loss:		0.595276
  validation accuracy:		81.96 %
Epoch 1306 of 2000 took 0.097s
  training loss:		0.592276
  validation loss:		0.607335
  validation accuracy:		81.96 %
Epoch 1307 of 2000 took 0.097s
  training loss:		0.604805
  validation loss:		0.605469
  validation accuracy:		81.74 %
Epoch 1308 of 2000 took 0.097s
  training loss:		0.597541
  validation loss:		0.591250
  validation accuracy:		81.96 %
Epoch 1309 of 2000 took 0.097s
  training loss:		0.590973
  validation loss:		0.584361
  validation accuracy:		81.74 %
Epoch 1310 of 2000 took 0.097s
  training loss:		0.601526
  validation loss:		0.593892
  validation accuracy:		81.96 %
Epoch 1311 of 2000 took 0.097s
  training loss:		0.604731
  validation loss:		0.613267
  validation accuracy:		81.52 %
Epoch 1312 of 2000 took 0.097s
  training loss:		0.585772
  validation loss:		0.599120
  validation accuracy:		82.07 %
Epoch 1313 of 2000 took 0.097s
  training loss:		0.594043
  validation loss:		0.589445
  validation accuracy:		82.17 %
Epoch 1314 of 2000 took 0.097s
  training loss:		0.590422
  validation loss:		0.588910
  validation accuracy:		82.07 %
Epoch 1315 of 2000 took 0.097s
  training loss:		0.590523
  validation loss:		0.697791
  validation accuracy:		77.61 %
Epoch 1316 of 2000 took 0.097s
  training loss:		0.593670
  validation loss:		0.610294
  validation accuracy:		81.85 %
Epoch 1317 of 2000 took 0.097s
  training loss:		0.579578
  validation loss:		0.599092
  validation accuracy:		81.63 %
Epoch 1318 of 2000 took 0.096s
  training loss:		0.587403
  validation loss:		0.593186
  validation accuracy:		81.41 %
Epoch 1319 of 2000 took 0.097s
  training loss:		0.585339
  validation loss:		0.597804
  validation accuracy:		81.52 %
Epoch 1320 of 2000 took 0.097s
  training loss:		0.594729
  validation loss:		0.606097
  validation accuracy:		81.63 %
Epoch 1321 of 2000 took 0.097s
  training loss:		0.595022
  validation loss:		0.600767
  validation accuracy:		82.07 %
Epoch 1322 of 2000 took 0.097s
  training loss:		0.584288
  validation loss:		0.592701
  validation accuracy:		82.50 %
Epoch 1323 of 2000 took 0.097s
  training loss:		0.593980
  validation loss:		0.595472
  validation accuracy:		80.98 %
Epoch 1324 of 2000 took 0.097s
  training loss:		0.592685
  validation loss:		0.612736
  validation accuracy:		80.43 %
Epoch 1325 of 2000 took 0.097s
  training loss:		0.591335
  validation loss:		0.612142
  validation accuracy:		81.20 %
Epoch 1326 of 2000 took 0.096s
  training loss:		0.587615
  validation loss:		0.585388
  validation accuracy:		81.96 %
Epoch 1327 of 2000 took 0.097s
  training loss:		0.594554
  validation loss:		0.613512
  validation accuracy:		80.54 %
Epoch 1328 of 2000 took 0.097s
  training loss:		0.592664
  validation loss:		0.583772
  validation accuracy:		81.96 %
Epoch 1329 of 2000 took 0.096s
  training loss:		0.618778
  validation loss:		0.643498
  validation accuracy:		79.02 %
Epoch 1330 of 2000 took 0.097s
  training loss:		0.590423
  validation loss:		0.591477
  validation accuracy:		82.07 %
Epoch 1331 of 2000 took 0.097s
  training loss:		0.590403
  validation loss:		0.598310
  validation accuracy:		82.07 %
Epoch 1332 of 2000 took 0.097s
  training loss:		0.579233
  validation loss:		0.621607
  validation accuracy:		80.87 %
Epoch 1333 of 2000 took 0.096s
  training loss:		0.590059
  validation loss:		0.588238
  validation accuracy:		81.96 %
Epoch 1334 of 2000 took 0.097s
  training loss:		0.586770
  validation loss:		0.600044
  validation accuracy:		81.74 %
Epoch 1335 of 2000 took 0.096s
  training loss:		0.588903
  validation loss:		0.596164
  validation accuracy:		81.96 %
Epoch 1336 of 2000 took 0.097s
  training loss:		0.592870
  validation loss:		0.613332
  validation accuracy:		81.52 %
Epoch 1337 of 2000 took 0.096s
  training loss:		0.577649
  validation loss:		0.603648
  validation accuracy:		82.07 %
Epoch 1338 of 2000 took 0.097s
  training loss:		0.584685
  validation loss:		0.604742
  validation accuracy:		81.20 %
Epoch 1339 of 2000 took 0.096s
  training loss:		0.582771
  validation loss:		0.588036
  validation accuracy:		81.63 %
Epoch 1340 of 2000 took 0.097s
  training loss:		0.601627
  validation loss:		0.596288
  validation accuracy:		80.98 %
Epoch 1341 of 2000 took 0.099s
  training loss:		0.588286
  validation loss:		0.587694
  validation accuracy:		81.52 %
Epoch 1342 of 2000 took 0.097s
  training loss:		0.589573
  validation loss:		0.596633
  validation accuracy:		82.28 %
Epoch 1343 of 2000 took 0.097s
  training loss:		0.585586
  validation loss:		0.605928
  validation accuracy:		81.74 %
Epoch 1344 of 2000 took 0.097s
  training loss:		0.588315
  validation loss:		0.577864
  validation accuracy:		81.52 %
Epoch 1345 of 2000 took 0.096s
  training loss:		0.589702
  validation loss:		0.632591
  validation accuracy:		79.46 %
Epoch 1346 of 2000 took 0.097s
  training loss:		0.591259
  validation loss:		0.599952
  validation accuracy:		81.96 %
Epoch 1347 of 2000 took 0.097s
  training loss:		0.594562
  validation loss:		0.621800
  validation accuracy:		80.76 %
Epoch 1348 of 2000 took 0.097s
  training loss:		0.594675
  validation loss:		0.602085
  validation accuracy:		81.85 %
Epoch 1349 of 2000 took 0.097s
  training loss:		0.589721
  validation loss:		0.583549
  validation accuracy:		81.74 %
Epoch 1350 of 2000 took 0.097s
  training loss:		0.591360
  validation loss:		0.621908
  validation accuracy:		80.65 %
Epoch 1351 of 2000 took 0.098s
  training loss:		0.592044
  validation loss:		0.629002
  validation accuracy:		80.11 %
Epoch 1352 of 2000 took 0.100s
  training loss:		0.583559
  validation loss:		0.587514
  validation accuracy:		81.74 %
Epoch 1353 of 2000 took 0.100s
  training loss:		0.581591
  validation loss:		0.620558
  validation accuracy:		80.11 %
Epoch 1354 of 2000 took 0.100s
  training loss:		0.599752
  validation loss:		0.625043
  validation accuracy:		80.76 %
Epoch 1355 of 2000 took 0.100s
  training loss:		0.580119
  validation loss:		0.607855
  validation accuracy:		81.63 %
Epoch 1356 of 2000 took 0.100s
  training loss:		0.581727
  validation loss:		0.585983
  validation accuracy:		82.07 %
Epoch 1357 of 2000 took 0.100s
  training loss:		0.583817
  validation loss:		0.621062
  validation accuracy:		80.00 %
Epoch 1358 of 2000 took 0.100s
  training loss:		0.597888
  validation loss:		0.604526
  validation accuracy:		81.74 %
Epoch 1359 of 2000 took 0.100s
  training loss:		0.580440
  validation loss:		0.602490
  validation accuracy:		81.96 %
Epoch 1360 of 2000 took 0.100s
  training loss:		0.594339
  validation loss:		0.612358
  validation accuracy:		80.76 %
Epoch 1361 of 2000 took 0.099s
  training loss:		0.597331
  validation loss:		0.590874
  validation accuracy:		82.07 %
Epoch 1362 of 2000 took 0.100s
  training loss:		0.589181
  validation loss:		0.617144
  validation accuracy:		81.63 %
Epoch 1363 of 2000 took 0.100s
  training loss:		0.577869
  validation loss:		0.626551
  validation accuracy:		81.20 %
Epoch 1364 of 2000 took 0.100s
  training loss:		0.589767
  validation loss:		0.612454
  validation accuracy:		81.20 %
Epoch 1365 of 2000 took 0.100s
  training loss:		0.596096
  validation loss:		0.627400
  validation accuracy:		80.54 %
Epoch 1366 of 2000 took 0.100s
  training loss:		0.600902
  validation loss:		0.586185
  validation accuracy:		82.50 %
Epoch 1367 of 2000 took 0.100s
  training loss:		0.584263
  validation loss:		0.612830
  validation accuracy:		81.20 %
Epoch 1368 of 2000 took 0.100s
  training loss:		0.598818
  validation loss:		0.630774
  validation accuracy:		79.67 %
Epoch 1369 of 2000 took 0.100s
  training loss:		0.579996
  validation loss:		0.579303
  validation accuracy:		81.30 %
Epoch 1370 of 2000 took 0.100s
  training loss:		0.586404
  validation loss:		0.613910
  validation accuracy:		80.98 %
Epoch 1371 of 2000 took 0.099s
  training loss:		0.592952
  validation loss:		0.596289
  validation accuracy:		82.50 %
Epoch 1372 of 2000 took 0.100s
  training loss:		0.610814
  validation loss:		0.622583
  validation accuracy:		80.11 %
Epoch 1373 of 2000 took 0.100s
  training loss:		0.583871
  validation loss:		0.603090
  validation accuracy:		81.85 %
Epoch 1374 of 2000 took 0.100s
  training loss:		0.583776
  validation loss:		0.601963
  validation accuracy:		81.63 %
Epoch 1375 of 2000 took 0.100s
  training loss:		0.587709
  validation loss:		0.610152
  validation accuracy:		81.74 %
Epoch 1376 of 2000 took 0.100s
  training loss:		0.587850
  validation loss:		0.580003
  validation accuracy:		82.39 %
Epoch 1377 of 2000 took 0.100s
  training loss:		0.613990
  validation loss:		0.605153
  validation accuracy:		81.63 %
Epoch 1378 of 2000 took 0.100s
  training loss:		0.586393
  validation loss:		0.587297
  validation accuracy:		81.74 %
Epoch 1379 of 2000 took 0.100s
  training loss:		0.585365
  validation loss:		0.609956
  validation accuracy:		81.09 %
Epoch 1380 of 2000 took 0.100s
  training loss:		0.590859
  validation loss:		0.655117
  validation accuracy:		79.24 %
Epoch 1381 of 2000 took 0.100s
  training loss:		0.582613
  validation loss:		0.594763
  validation accuracy:		82.39 %
Epoch 1382 of 2000 took 0.100s
  training loss:		0.576463
  validation loss:		0.585157
  validation accuracy:		81.52 %
Epoch 1383 of 2000 took 0.100s
  training loss:		0.581585
  validation loss:		0.655876
  validation accuracy:		79.24 %
Epoch 1384 of 2000 took 0.100s
  training loss:		0.584553
  validation loss:		0.604742
  validation accuracy:		81.96 %
Epoch 1385 of 2000 took 0.100s
  training loss:		0.581736
  validation loss:		0.644663
  validation accuracy:		79.78 %
Epoch 1386 of 2000 took 0.100s
  training loss:		0.588508
  validation loss:		0.596867
  validation accuracy:		82.17 %
Epoch 1387 of 2000 took 0.100s
  training loss:		0.589606
  validation loss:		0.580035
  validation accuracy:		81.52 %
Epoch 1388 of 2000 took 0.100s
  training loss:		0.599155
  validation loss:		0.598691
  validation accuracy:		82.28 %
Epoch 1389 of 2000 took 0.100s
  training loss:		0.586303
  validation loss:		0.650088
  validation accuracy:		79.78 %
Epoch 1390 of 2000 took 0.100s
  training loss:		0.585253
  validation loss:		0.589278
  validation accuracy:		81.85 %
Epoch 1391 of 2000 took 0.100s
  training loss:		0.572759
  validation loss:		0.606223
  validation accuracy:		81.96 %
Epoch 1392 of 2000 took 0.100s
  training loss:		0.577039
  validation loss:		0.616890
  validation accuracy:		81.74 %
Epoch 1393 of 2000 took 0.100s
  training loss:		0.580452
  validation loss:		0.580036
  validation accuracy:		81.74 %
Epoch 1394 of 2000 took 0.100s
  training loss:		0.583643
  validation loss:		0.598129
  validation accuracy:		82.17 %
Epoch 1395 of 2000 took 0.100s
  training loss:		0.585566
  validation loss:		0.617823
  validation accuracy:		81.20 %
Epoch 1396 of 2000 took 0.100s
  training loss:		0.579270
  validation loss:		0.600642
  validation accuracy:		82.07 %
Epoch 1397 of 2000 took 0.100s
  training loss:		0.586658
  validation loss:		0.588552
  validation accuracy:		82.28 %
Epoch 1398 of 2000 took 0.100s
  training loss:		0.620265
  validation loss:		0.604436
  validation accuracy:		82.28 %
Epoch 1399 of 2000 took 0.100s
  training loss:		0.588642
  validation loss:		0.585340
  validation accuracy:		81.74 %
Epoch 1400 of 2000 took 0.100s
  training loss:		0.582837
  validation loss:		0.631683
  validation accuracy:		80.00 %
Epoch 1401 of 2000 took 0.100s
  training loss:		0.581195
  validation loss:		0.589871
  validation accuracy:		81.85 %
Epoch 1402 of 2000 took 0.100s
  training loss:		0.581372
  validation loss:		0.608424
  validation accuracy:		81.63 %
Epoch 1403 of 2000 took 0.100s
  training loss:		0.584833
  validation loss:		0.611015
  validation accuracy:		80.76 %
Epoch 1404 of 2000 took 0.100s
  training loss:		0.582042
  validation loss:		0.581059
  validation accuracy:		81.09 %
Epoch 1405 of 2000 took 0.100s
  training loss:		0.592182
  validation loss:		0.608003
  validation accuracy:		80.87 %
Epoch 1406 of 2000 took 0.100s
  training loss:		0.586134
  validation loss:		0.597664
  validation accuracy:		82.07 %
Epoch 1407 of 2000 took 0.100s
  training loss:		0.603717
  validation loss:		0.651739
  validation accuracy:		79.24 %
Epoch 1408 of 2000 took 0.100s
  training loss:		0.580444
  validation loss:		0.593158
  validation accuracy:		82.39 %
Epoch 1409 of 2000 took 0.100s
  training loss:		0.574821
  validation loss:		0.585909
  validation accuracy:		81.96 %
Epoch 1410 of 2000 took 0.100s
  training loss:		0.581417
  validation loss:		0.593915
  validation accuracy:		82.07 %
Epoch 1411 of 2000 took 0.100s
  training loss:		0.611871
  validation loss:		0.669040
  validation accuracy:		79.13 %
Epoch 1412 of 2000 took 0.100s
  training loss:		0.599732
  validation loss:		0.613167
  validation accuracy:		81.20 %
Epoch 1413 of 2000 took 0.100s
  training loss:		0.592469
  validation loss:		0.582582
  validation accuracy:		81.30 %
Epoch 1414 of 2000 took 0.100s
  training loss:		0.578025
  validation loss:		0.641416
  validation accuracy:		79.78 %
Epoch 1415 of 2000 took 0.100s
  training loss:		0.589153
  validation loss:		0.607278
  validation accuracy:		81.96 %
Epoch 1416 of 2000 took 0.100s
  training loss:		0.591822
  validation loss:		0.588244
  validation accuracy:		82.07 %
Epoch 1417 of 2000 took 0.100s
  training loss:		0.587065
  validation loss:		0.579246
  validation accuracy:		81.85 %
Epoch 1418 of 2000 took 0.100s
  training loss:		0.587572
  validation loss:		0.659097
  validation accuracy:		79.24 %
Epoch 1419 of 2000 took 0.100s
  training loss:		0.587379
  validation loss:		0.607064
  validation accuracy:		81.96 %
Epoch 1420 of 2000 took 0.100s
  training loss:		0.580235
  validation loss:		0.583345
  validation accuracy:		82.07 %
Epoch 1421 of 2000 took 0.100s
  training loss:		0.594103
  validation loss:		0.580604
  validation accuracy:		82.17 %
Epoch 1422 of 2000 took 0.100s
  training loss:		0.591255
  validation loss:		0.595992
  validation accuracy:		82.61 %
Epoch 1423 of 2000 took 0.100s
  training loss:		0.596591
  validation loss:		0.674897
  validation accuracy:		78.59 %
Epoch 1424 of 2000 took 0.100s
  training loss:		0.590314
  validation loss:		0.601060
  validation accuracy:		81.96 %
Epoch 1425 of 2000 took 0.100s
  training loss:		0.602613
  validation loss:		0.656819
  validation accuracy:		79.46 %
Epoch 1426 of 2000 took 0.100s
  training loss:		0.591695
  validation loss:		0.601173
  validation accuracy:		81.63 %
Epoch 1427 of 2000 took 0.100s
  training loss:		0.576868
  validation loss:		0.591590
  validation accuracy:		82.50 %
Epoch 1428 of 2000 took 0.100s
  training loss:		0.584059
  validation loss:		0.628711
  validation accuracy:		79.78 %
Epoch 1429 of 2000 took 0.100s
  training loss:		0.585194
  validation loss:		0.599771
  validation accuracy:		82.17 %
Epoch 1430 of 2000 took 0.100s
  training loss:		0.585752
  validation loss:		0.606065
  validation accuracy:		81.85 %
Epoch 1431 of 2000 took 0.103s
  training loss:		0.578642
  validation loss:		0.613598
  validation accuracy:		82.07 %
Epoch 1432 of 2000 took 0.103s
  training loss:		0.576373
  validation loss:		0.600567
  validation accuracy:		82.07 %
Epoch 1433 of 2000 took 0.103s
  training loss:		0.579424
  validation loss:		0.583290
  validation accuracy:		82.07 %
Epoch 1434 of 2000 took 0.103s
  training loss:		0.600206
  validation loss:		0.581452
  validation accuracy:		81.52 %
Epoch 1435 of 2000 took 0.103s
  training loss:		0.568665
  validation loss:		0.605036
  validation accuracy:		81.96 %
Epoch 1436 of 2000 took 0.103s
  training loss:		0.591553
  validation loss:		0.597651
  validation accuracy:		81.63 %
Epoch 1437 of 2000 took 0.103s
  training loss:		0.585001
  validation loss:		0.589016
  validation accuracy:		82.28 %
Epoch 1438 of 2000 took 0.104s
  training loss:		0.590034
  validation loss:		0.586359
  validation accuracy:		81.96 %
Epoch 1439 of 2000 took 0.103s
  training loss:		0.583725
  validation loss:		0.582991
  validation accuracy:		82.17 %
Epoch 1440 of 2000 took 0.103s
  training loss:		0.588044
  validation loss:		0.611390
  validation accuracy:		81.30 %
Epoch 1441 of 2000 took 0.103s
  training loss:		0.581620
  validation loss:		0.612075
  validation accuracy:		81.52 %
Epoch 1442 of 2000 took 0.103s
  training loss:		0.578290
  validation loss:		0.594013
  validation accuracy:		82.17 %
Epoch 1443 of 2000 took 0.103s
  training loss:		0.591342
  validation loss:		0.599536
  validation accuracy:		82.17 %
Epoch 1444 of 2000 took 0.103s
  training loss:		0.588276
  validation loss:		0.615162
  validation accuracy:		81.74 %
Epoch 1445 of 2000 took 0.103s
  training loss:		0.607601
  validation loss:		0.580600
  validation accuracy:		82.28 %
Epoch 1446 of 2000 took 0.103s
  training loss:		0.577134
  validation loss:		0.599096
  validation accuracy:		82.28 %
Epoch 1447 of 2000 took 0.103s
  training loss:		0.579414
  validation loss:		0.600666
  validation accuracy:		82.28 %
Epoch 1448 of 2000 took 0.103s
  training loss:		0.575265
  validation loss:		0.601645
  validation accuracy:		82.28 %
Epoch 1449 of 2000 took 0.103s
  training loss:		0.586235
  validation loss:		0.625341
  validation accuracy:		80.87 %
Epoch 1450 of 2000 took 0.103s
  training loss:		0.576973
  validation loss:		0.607767
  validation accuracy:		81.63 %
Epoch 1451 of 2000 took 0.103s
  training loss:		0.582455
  validation loss:		0.608896
  validation accuracy:		81.52 %
Epoch 1452 of 2000 took 0.103s
  training loss:		0.596187
  validation loss:		0.641916
  validation accuracy:		79.57 %
Epoch 1453 of 2000 took 0.103s
  training loss:		0.585748
  validation loss:		0.590161
  validation accuracy:		82.17 %
Epoch 1454 of 2000 took 0.103s
  training loss:		0.595916
  validation loss:		0.599938
  validation accuracy:		81.96 %
Epoch 1455 of 2000 took 0.103s
  training loss:		0.575646
  validation loss:		0.601564
  validation accuracy:		82.17 %
Epoch 1456 of 2000 took 0.103s
  training loss:		0.582747
  validation loss:		0.595437
  validation accuracy:		82.28 %
Epoch 1457 of 2000 took 0.103s
  training loss:		0.575613
  validation loss:		0.596282
  validation accuracy:		82.17 %
Epoch 1458 of 2000 took 0.103s
  training loss:		0.570533
  validation loss:		0.603561
  validation accuracy:		82.28 %
Epoch 1459 of 2000 took 0.103s
  training loss:		0.584682
  validation loss:		0.600813
  validation accuracy:		81.96 %
Epoch 1460 of 2000 took 0.103s
  training loss:		0.589098
  validation loss:		0.609041
  validation accuracy:		82.07 %
Epoch 1461 of 2000 took 0.103s
  training loss:		0.581479
  validation loss:		0.592620
  validation accuracy:		82.39 %
Epoch 1462 of 2000 took 0.104s
  training loss:		0.584013
  validation loss:		0.592863
  validation accuracy:		82.17 %
Epoch 1463 of 2000 took 0.107s
  training loss:		0.581204
  validation loss:		0.597918
  validation accuracy:		82.39 %
Epoch 1464 of 2000 took 0.111s
  training loss:		0.584986
  validation loss:		0.603612
  validation accuracy:		82.17 %
Epoch 1465 of 2000 took 0.145s
  training loss:		0.589829
  validation loss:		0.609922
  validation accuracy:		81.52 %
Epoch 1466 of 2000 took 0.104s
  training loss:		0.581832
  validation loss:		0.588524
  validation accuracy:		82.72 %
Epoch 1467 of 2000 took 0.102s
  training loss:		0.588235
  validation loss:		0.611424
  validation accuracy:		81.85 %
Epoch 1468 of 2000 took 0.104s
  training loss:		0.591469
  validation loss:		0.612131
  validation accuracy:		81.96 %
Epoch 1469 of 2000 took 0.106s
  training loss:		0.580230
  validation loss:		0.588054
  validation accuracy:		82.17 %
Epoch 1470 of 2000 took 0.103s
  training loss:		0.583026
  validation loss:		0.603789
  validation accuracy:		82.07 %
Epoch 1471 of 2000 took 0.104s
  training loss:		0.572064
  validation loss:		0.599270
  validation accuracy:		82.50 %
Epoch 1472 of 2000 took 0.100s
  training loss:		0.579922
  validation loss:		0.605661
  validation accuracy:		82.28 %
Epoch 1473 of 2000 took 0.101s
  training loss:		0.576992
  validation loss:		0.598219
  validation accuracy:		81.85 %
Epoch 1474 of 2000 took 0.100s
  training loss:		0.580718
  validation loss:		0.594715
  validation accuracy:		82.17 %
Epoch 1475 of 2000 took 0.100s
  training loss:		0.588418
  validation loss:		0.606958
  validation accuracy:		81.63 %
Epoch 1476 of 2000 took 0.101s
  training loss:		0.582090
  validation loss:		0.608623
  validation accuracy:		81.85 %
Epoch 1477 of 2000 took 0.100s
  training loss:		0.574412
  validation loss:		0.607454
  validation accuracy:		82.07 %
Epoch 1478 of 2000 took 0.101s
  training loss:		0.581107
  validation loss:		0.618866
  validation accuracy:		81.30 %
Epoch 1479 of 2000 took 0.100s
  training loss:		0.583248
  validation loss:		0.625638
  validation accuracy:		80.33 %
Epoch 1480 of 2000 took 0.101s
  training loss:		0.576921
  validation loss:		0.603798
  validation accuracy:		81.63 %
Epoch 1481 of 2000 took 0.101s
  training loss:		0.585519
  validation loss:		0.592483
  validation accuracy:		81.96 %
Epoch 1482 of 2000 took 0.101s
  training loss:		0.587798
  validation loss:		0.634617
  validation accuracy:		79.78 %
Epoch 1483 of 2000 took 0.100s
  training loss:		0.589535
  validation loss:		0.612287
  validation accuracy:		81.74 %
Epoch 1484 of 2000 took 0.100s
  training loss:		0.592279
  validation loss:		0.586106
  validation accuracy:		81.85 %
Epoch 1485 of 2000 took 0.101s
  training loss:		0.584020
  validation loss:		0.589754
  validation accuracy:		82.17 %
Epoch 1486 of 2000 took 0.100s
  training loss:		0.585908
  validation loss:		0.610852
  validation accuracy:		81.96 %
Epoch 1487 of 2000 took 0.100s
  training loss:		0.586003
  validation loss:		0.608580
  validation accuracy:		81.63 %
Epoch 1488 of 2000 took 0.100s
  training loss:		0.584778
  validation loss:		0.582057
  validation accuracy:		82.28 %
Epoch 1489 of 2000 took 0.101s
  training loss:		0.577262
  validation loss:		0.629735
  validation accuracy:		79.78 %
Epoch 1490 of 2000 took 0.100s
  training loss:		0.581985
  validation loss:		0.614785
  validation accuracy:		81.30 %
Epoch 1491 of 2000 took 0.101s
  training loss:		0.579621
  validation loss:		0.618411
  validation accuracy:		81.85 %
Epoch 1492 of 2000 took 0.100s
  training loss:		0.570531
  validation loss:		0.588570
  validation accuracy:		82.50 %
Epoch 1493 of 2000 took 0.100s
  training loss:		0.581732
  validation loss:		0.591835
  validation accuracy:		82.28 %
Epoch 1494 of 2000 took 0.101s
  training loss:		0.583558
  validation loss:		0.597106
  validation accuracy:		82.07 %
Epoch 1495 of 2000 took 0.101s
  training loss:		0.585521
  validation loss:		0.631068
  validation accuracy:		80.22 %
Epoch 1496 of 2000 took 0.102s
  training loss:		0.589825
  validation loss:		0.589760
  validation accuracy:		82.28 %
Epoch 1497 of 2000 took 0.101s
  training loss:		0.575381
  validation loss:		0.590853
  validation accuracy:		82.61 %
Epoch 1498 of 2000 took 0.100s
  training loss:		0.580763
  validation loss:		0.642804
  validation accuracy:		79.78 %
Epoch 1499 of 2000 took 0.101s
  training loss:		0.573071
  validation loss:		0.611223
  validation accuracy:		82.17 %
Epoch 1500 of 2000 took 0.100s
  training loss:		0.607943
  validation loss:		0.636018
  validation accuracy:		80.87 %
Epoch 1501 of 2000 took 0.101s
  training loss:		0.601751
  validation loss:		0.592620
  validation accuracy:		82.50 %
Epoch 1502 of 2000 took 0.101s
  training loss:		0.598109
  validation loss:		0.599597
  validation accuracy:		82.72 %
Epoch 1503 of 2000 took 0.101s
  training loss:		0.573581
  validation loss:		0.585252
  validation accuracy:		82.50 %
Epoch 1504 of 2000 took 0.101s
  training loss:		0.576196
  validation loss:		0.621088
  validation accuracy:		81.20 %
Epoch 1505 of 2000 took 0.102s
  training loss:		0.589097
  validation loss:		0.588235
  validation accuracy:		82.50 %
Epoch 1506 of 2000 took 0.103s
  training loss:		0.585995
  validation loss:		0.608523
  validation accuracy:		81.20 %
Epoch 1507 of 2000 took 0.100s
  training loss:		0.576495
  validation loss:		0.579040
  validation accuracy:		81.52 %
Epoch 1508 of 2000 took 0.100s
  training loss:		0.590217
  validation loss:		0.633141
  validation accuracy:		80.33 %
Epoch 1509 of 2000 took 0.100s
  training loss:		0.586278
  validation loss:		0.588071
  validation accuracy:		82.72 %
Epoch 1510 of 2000 took 0.100s
  training loss:		0.615799
  validation loss:		0.628219
  validation accuracy:		80.98 %
Epoch 1511 of 2000 took 0.100s
  training loss:		0.585433
  validation loss:		0.602462
  validation accuracy:		81.30 %
Epoch 1512 of 2000 took 0.100s
  training loss:		0.594504
  validation loss:		0.636653
  validation accuracy:		80.43 %
Epoch 1513 of 2000 took 0.100s
  training loss:		0.594751
  validation loss:		0.598610
  validation accuracy:		82.17 %
Epoch 1514 of 2000 took 0.100s
  training loss:		0.578685
  validation loss:		0.626332
  validation accuracy:		81.20 %
Epoch 1515 of 2000 took 0.100s
  training loss:		0.581376
  validation loss:		0.606505
  validation accuracy:		81.52 %
Epoch 1516 of 2000 took 0.100s
  training loss:		0.577900
  validation loss:		0.599850
  validation accuracy:		82.17 %
Epoch 1517 of 2000 took 0.100s
  training loss:		0.582856
  validation loss:		0.591340
  validation accuracy:		82.72 %
Epoch 1518 of 2000 took 0.100s
  training loss:		0.576326
  validation loss:		0.612624
  validation accuracy:		81.52 %
Epoch 1519 of 2000 took 0.100s
  training loss:		0.582680
  validation loss:		0.605953
  validation accuracy:		81.09 %
Epoch 1520 of 2000 took 0.100s
  training loss:		0.586262
  validation loss:		0.600492
  validation accuracy:		82.17 %
Epoch 1521 of 2000 took 0.100s
  training loss:		0.582220
  validation loss:		0.601502
  validation accuracy:		81.96 %
Epoch 1522 of 2000 took 0.100s
  training loss:		0.588503
  validation loss:		0.613686
  validation accuracy:		81.52 %
Epoch 1523 of 2000 took 0.100s
  training loss:		0.590861
  validation loss:		0.588611
  validation accuracy:		82.83 %
Epoch 1524 of 2000 took 0.100s
  training loss:		0.580185
  validation loss:		0.580636
  validation accuracy:		82.50 %
Epoch 1525 of 2000 took 0.100s
  training loss:		0.578247
  validation loss:		0.583959
  validation accuracy:		81.96 %
Epoch 1526 of 2000 took 0.101s
  training loss:		0.582885
  validation loss:		0.620322
  validation accuracy:		80.76 %
Epoch 1527 of 2000 took 0.102s
  training loss:		0.575816
  validation loss:		0.590503
  validation accuracy:		82.61 %
Epoch 1528 of 2000 took 0.106s
  training loss:		0.571367
  validation loss:		0.603721
  validation accuracy:		81.96 %
Epoch 1529 of 2000 took 0.107s
  training loss:		0.576692
  validation loss:		0.593352
  validation accuracy:		82.39 %
Epoch 1530 of 2000 took 0.107s
  training loss:		0.578205
  validation loss:		0.612026
  validation accuracy:		82.39 %
Epoch 1531 of 2000 took 0.097s
  training loss:		0.570442
  validation loss:		0.591004
  validation accuracy:		82.61 %
Epoch 1532 of 2000 took 0.097s
  training loss:		0.576793
  validation loss:		0.594832
  validation accuracy:		82.39 %
Epoch 1533 of 2000 took 0.097s
  training loss:		0.575464
  validation loss:		0.583541
  validation accuracy:		81.85 %
Epoch 1534 of 2000 took 0.097s
  training loss:		0.577328
  validation loss:		0.583621
  validation accuracy:		81.63 %
Epoch 1535 of 2000 took 0.096s
  training loss:		0.600295
  validation loss:		0.597523
  validation accuracy:		82.17 %
Epoch 1536 of 2000 took 0.097s
  training loss:		0.592639
  validation loss:		0.646147
  validation accuracy:		80.33 %
Epoch 1537 of 2000 took 0.097s
  training loss:		0.588609
  validation loss:		0.611231
  validation accuracy:		82.07 %
Epoch 1538 of 2000 took 0.096s
  training loss:		0.579443
  validation loss:		0.609685
  validation accuracy:		81.30 %
Epoch 1539 of 2000 took 0.097s
  training loss:		0.579713
  validation loss:		0.606471
  validation accuracy:		81.30 %
Epoch 1540 of 2000 took 0.097s
  training loss:		0.583341
  validation loss:		0.611480
  validation accuracy:		81.09 %
Epoch 1541 of 2000 took 0.097s
  training loss:		0.586862
  validation loss:		0.598142
  validation accuracy:		82.17 %
Epoch 1542 of 2000 took 0.096s
  training loss:		0.571974
  validation loss:		0.607936
  validation accuracy:		81.52 %
Epoch 1543 of 2000 took 0.097s
  training loss:		0.568175
  validation loss:		0.587839
  validation accuracy:		82.07 %
Epoch 1544 of 2000 took 0.096s
  training loss:		0.578568
  validation loss:		0.613260
  validation accuracy:		82.39 %
Epoch 1545 of 2000 took 0.096s
  training loss:		0.588121
  validation loss:		0.600850
  validation accuracy:		81.96 %
Epoch 1546 of 2000 took 0.097s
  training loss:		0.571879
  validation loss:		0.603879
  validation accuracy:		81.63 %
Epoch 1547 of 2000 took 0.097s
  training loss:		0.575619
  validation loss:		0.582934
  validation accuracy:		81.74 %
Epoch 1548 of 2000 took 0.096s
  training loss:		0.572448
  validation loss:		0.590294
  validation accuracy:		82.50 %
Epoch 1549 of 2000 took 0.097s
  training loss:		0.585639
  validation loss:		0.611700
  validation accuracy:		81.63 %
Epoch 1550 of 2000 took 0.097s
  training loss:		0.579933
  validation loss:		0.598797
  validation accuracy:		82.07 %
Epoch 1551 of 2000 took 0.097s
  training loss:		0.579028
  validation loss:		0.613142
  validation accuracy:		82.17 %
Epoch 1552 of 2000 took 0.096s
  training loss:		0.582107
  validation loss:		0.598097
  validation accuracy:		82.39 %
Epoch 1553 of 2000 took 0.097s
  training loss:		0.563526
  validation loss:		0.595926
  validation accuracy:		82.50 %
Epoch 1554 of 2000 took 0.097s
  training loss:		0.577408
  validation loss:		0.588055
  validation accuracy:		81.96 %
Epoch 1555 of 2000 took 0.097s
  training loss:		0.579238
  validation loss:		0.597129
  validation accuracy:		82.17 %
Epoch 1556 of 2000 took 0.097s
  training loss:		0.579359
  validation loss:		0.631982
  validation accuracy:		80.87 %
Epoch 1557 of 2000 took 0.098s
  training loss:		0.582059
  validation loss:		0.620341
  validation accuracy:		80.98 %
Epoch 1558 of 2000 took 0.097s
  training loss:		0.588022
  validation loss:		0.607214
  validation accuracy:		81.52 %
Epoch 1559 of 2000 took 0.097s
  training loss:		0.567075
  validation loss:		0.610533
  validation accuracy:		81.41 %
Epoch 1560 of 2000 took 0.096s
  training loss:		0.580755
  validation loss:		0.612170
  validation accuracy:		82.17 %
Epoch 1561 of 2000 took 0.097s
  training loss:		0.577158
  validation loss:		0.588968
  validation accuracy:		82.28 %
Epoch 1562 of 2000 took 0.097s
  training loss:		0.583817
  validation loss:		0.596784
  validation accuracy:		82.50 %
Epoch 1563 of 2000 took 0.097s
  training loss:		0.577154
  validation loss:		0.611712
  validation accuracy:		82.39 %
Epoch 1564 of 2000 took 0.097s
  training loss:		0.579182
  validation loss:		0.598076
  validation accuracy:		82.39 %
Epoch 1565 of 2000 took 0.097s
  training loss:		0.577630
  validation loss:		0.600302
  validation accuracy:		82.28 %
Epoch 1566 of 2000 took 0.097s
  training loss:		0.583670
  validation loss:		0.628187
  validation accuracy:		80.98 %
Epoch 1567 of 2000 took 0.097s
  training loss:		0.577653
  validation loss:		0.624123
  validation accuracy:		81.20 %
Epoch 1568 of 2000 took 0.097s
  training loss:		0.588928
  validation loss:		0.598521
  validation accuracy:		82.28 %
Epoch 1569 of 2000 took 0.096s
  training loss:		0.577869
  validation loss:		0.612659
  validation accuracy:		82.28 %
Epoch 1570 of 2000 took 0.097s
  training loss:		0.581970
  validation loss:		0.594024
  validation accuracy:		82.07 %
Epoch 1571 of 2000 took 0.097s
  training loss:		0.587374
  validation loss:		0.634609
  validation accuracy:		80.76 %
Epoch 1572 of 2000 took 0.097s
  training loss:		0.580602
  validation loss:		0.600900
  validation accuracy:		82.17 %
Epoch 1573 of 2000 took 0.096s
  training loss:		0.584894
  validation loss:		0.596238
  validation accuracy:		81.52 %
Epoch 1574 of 2000 took 0.097s
  training loss:		0.580992
  validation loss:		0.607013
  validation accuracy:		81.96 %
Epoch 1575 of 2000 took 0.096s
  training loss:		0.585588
  validation loss:		0.598218
  validation accuracy:		82.07 %
Epoch 1576 of 2000 took 0.096s
  training loss:		0.575935
  validation loss:		0.601537
  validation accuracy:		82.28 %
Epoch 1577 of 2000 took 0.096s
  training loss:		0.589790
  validation loss:		0.596115
  validation accuracy:		82.61 %
Epoch 1578 of 2000 took 0.097s
  training loss:		0.572035
  validation loss:		0.592662
  validation accuracy:		82.50 %
Epoch 1579 of 2000 took 0.097s
  training loss:		0.586309
  validation loss:		0.596288
  validation accuracy:		82.17 %
Epoch 1580 of 2000 took 0.096s
  training loss:		0.573911
  validation loss:		0.602566
  validation accuracy:		82.28 %
Epoch 1581 of 2000 took 0.096s
  training loss:		0.576743
  validation loss:		0.614539
  validation accuracy:		81.96 %
Epoch 1582 of 2000 took 0.097s
  training loss:		0.575637
  validation loss:		0.602472
  validation accuracy:		81.74 %
Epoch 1583 of 2000 took 0.096s
  training loss:		0.576533
  validation loss:		0.592454
  validation accuracy:		82.28 %
Epoch 1584 of 2000 took 0.097s
  training loss:		0.576940
  validation loss:		0.602763
  validation accuracy:		81.74 %
Epoch 1585 of 2000 took 0.096s
  training loss:		0.578135
  validation loss:		0.597442
  validation accuracy:		81.74 %
Epoch 1586 of 2000 took 0.096s
  training loss:		0.583991
  validation loss:		0.603461
  validation accuracy:		82.07 %
Epoch 1587 of 2000 took 0.097s
  training loss:		0.577035
  validation loss:		0.673697
  validation accuracy:		78.91 %
Epoch 1588 of 2000 took 0.098s
  training loss:		0.588367
  validation loss:		0.617547
  validation accuracy:		81.85 %
Epoch 1589 of 2000 took 0.097s
  training loss:		0.582912
  validation loss:		0.610342
  validation accuracy:		81.20 %
Epoch 1590 of 2000 took 0.097s
  training loss:		0.589451
  validation loss:		0.590506
  validation accuracy:		82.07 %
Epoch 1591 of 2000 took 0.097s
  training loss:		0.579561
  validation loss:		0.652432
  validation accuracy:		79.46 %
Epoch 1592 of 2000 took 0.097s
  training loss:		0.574533
  validation loss:		0.595576
  validation accuracy:		82.17 %
Epoch 1593 of 2000 took 0.097s
  training loss:		0.575308
  validation loss:		0.630901
  validation accuracy:		81.09 %
Epoch 1594 of 2000 took 0.097s
  training loss:		0.592626
  validation loss:		0.596675
  validation accuracy:		82.07 %
Epoch 1595 of 2000 took 0.097s
  training loss:		0.575674
  validation loss:		0.623052
  validation accuracy:		81.63 %
Epoch 1596 of 2000 took 0.097s
  training loss:		0.571114
  validation loss:		0.657908
  validation accuracy:		80.00 %
Epoch 1597 of 2000 took 0.097s
  training loss:		0.582939
  validation loss:		0.596042
  validation accuracy:		82.28 %
Epoch 1598 of 2000 took 0.096s
  training loss:		0.574917
  validation loss:		0.610966
  validation accuracy:		81.20 %
Epoch 1599 of 2000 took 0.097s
  training loss:		0.568424
  validation loss:		0.619739
  validation accuracy:		81.96 %
Epoch 1600 of 2000 took 0.097s
  training loss:		0.577934
  validation loss:		0.594271
  validation accuracy:		82.39 %
Epoch 1601 of 2000 took 0.097s
  training loss:		0.579673
  validation loss:		0.620425
  validation accuracy:		81.52 %
Epoch 1602 of 2000 took 0.097s
  training loss:		0.573596
  validation loss:		0.610047
  validation accuracy:		81.30 %
Epoch 1603 of 2000 took 0.097s
  training loss:		0.577779
  validation loss:		0.611883
  validation accuracy:		81.63 %
Epoch 1604 of 2000 took 0.096s
  training loss:		0.574983
  validation loss:		0.611629
  validation accuracy:		82.17 %
Epoch 1605 of 2000 took 0.097s
  training loss:		0.580022
  validation loss:		0.592211
  validation accuracy:		82.39 %
Epoch 1606 of 2000 took 0.097s
  training loss:		0.581452
  validation loss:		0.630746
  validation accuracy:		80.11 %
Epoch 1607 of 2000 took 0.097s
  training loss:		0.587399
  validation loss:		0.604434
  validation accuracy:		81.63 %
Epoch 1608 of 2000 took 0.097s
  training loss:		0.581695
  validation loss:		0.586067
  validation accuracy:		82.07 %
Epoch 1609 of 2000 took 0.100s
  training loss:		0.578506
  validation loss:		0.609129
  validation accuracy:		82.07 %
Epoch 1610 of 2000 took 0.097s
  training loss:		0.579071
  validation loss:		0.584915
  validation accuracy:		81.85 %
Epoch 1611 of 2000 took 0.097s
  training loss:		0.578539
  validation loss:		0.613704
  validation accuracy:		81.85 %
Epoch 1612 of 2000 took 0.096s
  training loss:		0.578447
  validation loss:		0.609852
  validation accuracy:		81.63 %
Epoch 1613 of 2000 took 0.097s
  training loss:		0.581869
  validation loss:		0.591346
  validation accuracy:		82.17 %
Epoch 1614 of 2000 took 0.097s
  training loss:		0.587622
  validation loss:		0.593125
  validation accuracy:		82.50 %
Epoch 1615 of 2000 took 0.097s
  training loss:		0.579906
  validation loss:		0.619932
  validation accuracy:		81.85 %
Epoch 1616 of 2000 took 0.096s
  training loss:		0.579382
  validation loss:		0.591010
  validation accuracy:		82.07 %
Epoch 1617 of 2000 took 0.097s
  training loss:		0.583262
  validation loss:		0.602065
  validation accuracy:		81.41 %
Epoch 1618 of 2000 took 0.096s
  training loss:		0.568227
  validation loss:		0.589170
  validation accuracy:		82.17 %
Epoch 1619 of 2000 took 0.097s
  training loss:		0.593687
  validation loss:		0.597680
  validation accuracy:		82.17 %
Epoch 1620 of 2000 took 0.097s
  training loss:		0.578852
  validation loss:		0.600910
  validation accuracy:		81.96 %
Epoch 1621 of 2000 took 0.097s
  training loss:		0.570877
  validation loss:		0.596250
  validation accuracy:		82.39 %
Epoch 1622 of 2000 took 0.096s
  training loss:		0.574436
  validation loss:		0.607447
  validation accuracy:		82.39 %
Epoch 1623 of 2000 took 0.097s
  training loss:		0.588825
  validation loss:		0.613692
  validation accuracy:		81.74 %
Epoch 1624 of 2000 took 0.097s
  training loss:		0.595387
  validation loss:		0.593387
  validation accuracy:		82.39 %
Epoch 1625 of 2000 took 0.097s
  training loss:		0.571365
  validation loss:		0.615808
  validation accuracy:		81.09 %
Epoch 1626 of 2000 took 0.097s
  training loss:		0.585726
  validation loss:		0.601454
  validation accuracy:		82.07 %
Epoch 1627 of 2000 took 0.097s
  training loss:		0.570618
  validation loss:		0.605274
  validation accuracy:		81.63 %
Epoch 1628 of 2000 took 0.097s
  training loss:		0.587113
  validation loss:		0.603217
  validation accuracy:		82.50 %
Epoch 1629 of 2000 took 0.097s
  training loss:		0.570685
  validation loss:		0.603941
  validation accuracy:		81.52 %
Epoch 1630 of 2000 took 0.097s
  training loss:		0.587334
  validation loss:		0.636689
  validation accuracy:		80.87 %
Epoch 1631 of 2000 took 0.097s
  training loss:		0.589768
  validation loss:		0.593649
  validation accuracy:		82.50 %
Epoch 1632 of 2000 took 0.097s
  training loss:		0.581180
  validation loss:		0.587344
  validation accuracy:		82.61 %
Epoch 1633 of 2000 took 0.097s
  training loss:		0.577054
  validation loss:		0.604452
  validation accuracy:		81.52 %
Epoch 1634 of 2000 took 0.097s
  training loss:		0.563794
  validation loss:		0.606306
  validation accuracy:		82.28 %
Epoch 1635 of 2000 took 0.100s
  training loss:		0.588964
  validation loss:		0.591421
  validation accuracy:		81.96 %
Epoch 1636 of 2000 took 0.105s
  training loss:		0.582261
  validation loss:		0.600750
  validation accuracy:		82.07 %
Epoch 1637 of 2000 took 0.110s
  training loss:		0.573866
  validation loss:		0.594603
  validation accuracy:		82.07 %
Epoch 1638 of 2000 took 0.100s
  training loss:		0.574790
  validation loss:		0.664714
  validation accuracy:		79.35 %
Epoch 1639 of 2000 took 0.100s
  training loss:		0.582404
  validation loss:		0.621378
  validation accuracy:		80.98 %
Epoch 1640 of 2000 took 0.101s
  training loss:		0.569378
  validation loss:		0.590966
  validation accuracy:		82.28 %
Epoch 1641 of 2000 took 0.100s
  training loss:		0.577352
  validation loss:		0.612602
  validation accuracy:		81.09 %
Epoch 1642 of 2000 took 0.100s
  training loss:		0.580597
  validation loss:		0.613177
  validation accuracy:		81.20 %
Epoch 1643 of 2000 took 0.100s
  training loss:		0.593464
  validation loss:		0.613602
  validation accuracy:		82.50 %
Epoch 1644 of 2000 took 0.100s
  training loss:		0.581829
  validation loss:		0.623851
  validation accuracy:		81.20 %
Epoch 1645 of 2000 took 0.100s
  training loss:		0.575563
  validation loss:		0.617465
  validation accuracy:		81.63 %
Epoch 1646 of 2000 took 0.100s
  training loss:		0.584478
  validation loss:		0.620581
  validation accuracy:		80.76 %
Epoch 1647 of 2000 took 0.100s
  training loss:		0.583769
  validation loss:		0.624184
  validation accuracy:		82.07 %
Epoch 1648 of 2000 took 0.106s
  training loss:		0.576807
  validation loss:		0.603120
  validation accuracy:		81.96 %
Epoch 1649 of 2000 took 0.107s
  training loss:		0.568908
  validation loss:		0.616366
  validation accuracy:		82.07 %
Epoch 1650 of 2000 took 0.104s
  training loss:		0.576987
  validation loss:		0.609453
  validation accuracy:		81.74 %
Epoch 1651 of 2000 took 0.105s
  training loss:		0.588377
  validation loss:		0.597749
  validation accuracy:		82.17 %
Epoch 1652 of 2000 took 0.106s
  training loss:		0.572214
  validation loss:		0.601705
  validation accuracy:		82.07 %
Epoch 1653 of 2000 took 0.104s
  training loss:		0.580253
  validation loss:		0.622955
  validation accuracy:		80.65 %
Epoch 1654 of 2000 took 0.103s
  training loss:		0.574729
  validation loss:		0.587661
  validation accuracy:		82.28 %
Epoch 1655 of 2000 took 0.103s
  training loss:		0.566044
  validation loss:		0.602260
  validation accuracy:		81.96 %
Epoch 1656 of 2000 took 0.103s
  training loss:		0.580251
  validation loss:		0.632552
  validation accuracy:		80.65 %
Epoch 1657 of 2000 took 0.103s
  training loss:		0.574106
  validation loss:		0.596207
  validation accuracy:		82.39 %
Epoch 1658 of 2000 took 0.103s
  training loss:		0.573901
  validation loss:		0.628685
  validation accuracy:		81.41 %
Epoch 1659 of 2000 took 0.103s
  training loss:		0.577521
  validation loss:		0.622373
  validation accuracy:		81.20 %
Epoch 1660 of 2000 took 0.103s
  training loss:		0.570048
  validation loss:		0.597812
  validation accuracy:		81.85 %
Epoch 1661 of 2000 took 0.103s
  training loss:		0.570104
  validation loss:		0.603094
  validation accuracy:		81.96 %
Epoch 1662 of 2000 took 0.103s
  training loss:		0.570572
  validation loss:		0.617317
  validation accuracy:		81.41 %
Epoch 1663 of 2000 took 0.103s
  training loss:		0.575254
  validation loss:		0.595549
  validation accuracy:		82.07 %
Epoch 1664 of 2000 took 0.103s
  training loss:		0.595697
  validation loss:		0.651071
  validation accuracy:		79.89 %
Epoch 1665 of 2000 took 0.103s
  training loss:		0.602785
  validation loss:		0.605973
  validation accuracy:		81.74 %
Epoch 1666 of 2000 took 0.103s
  training loss:		0.571769
  validation loss:		0.628307
  validation accuracy:		80.33 %
Epoch 1667 of 2000 took 0.103s
  training loss:		0.572554
  validation loss:		0.587068
  validation accuracy:		81.96 %
Epoch 1668 of 2000 took 0.103s
  training loss:		0.567304
  validation loss:		0.591185
  validation accuracy:		82.39 %
Epoch 1669 of 2000 took 0.103s
  training loss:		0.594135
  validation loss:		0.613361
  validation accuracy:		81.30 %
Epoch 1670 of 2000 took 0.103s
  training loss:		0.581097
  validation loss:		0.631311
  validation accuracy:		81.85 %
Epoch 1671 of 2000 took 0.103s
  training loss:		0.578298
  validation loss:		0.637251
  validation accuracy:		81.20 %
Epoch 1672 of 2000 took 0.103s
  training loss:		0.582306
  validation loss:		0.607478
  validation accuracy:		81.41 %
Epoch 1673 of 2000 took 0.103s
  training loss:		0.571731
  validation loss:		0.604032
  validation accuracy:		81.52 %
Epoch 1674 of 2000 took 0.103s
  training loss:		0.565946
  validation loss:		0.617189
  validation accuracy:		81.85 %
Epoch 1675 of 2000 took 0.103s
  training loss:		0.581509
  validation loss:		0.589587
  validation accuracy:		82.17 %
Epoch 1676 of 2000 took 0.103s
  training loss:		0.586351
  validation loss:		0.651401
  validation accuracy:		79.89 %
Epoch 1677 of 2000 took 0.103s
  training loss:		0.575158
  validation loss:		0.607366
  validation accuracy:		80.87 %
Epoch 1678 of 2000 took 0.103s
  training loss:		0.581602
  validation loss:		0.599539
  validation accuracy:		82.39 %
Epoch 1679 of 2000 took 0.104s
  training loss:		0.583954
  validation loss:		0.620861
  validation accuracy:		80.87 %
Epoch 1680 of 2000 took 0.103s
  training loss:		0.579200
  validation loss:		0.606584
  validation accuracy:		82.39 %
Epoch 1681 of 2000 took 0.103s
  training loss:		0.567332
  validation loss:		0.616310
  validation accuracy:		82.07 %
Epoch 1682 of 2000 took 0.103s
  training loss:		0.568218
  validation loss:		0.682881
  validation accuracy:		79.02 %
Epoch 1683 of 2000 took 0.103s
  training loss:		0.596254
  validation loss:		0.612718
  validation accuracy:		81.63 %
Epoch 1684 of 2000 took 0.103s
  training loss:		0.570756
  validation loss:		0.591903
  validation accuracy:		82.50 %
Epoch 1685 of 2000 took 0.103s
  training loss:		0.571195
  validation loss:		0.612779
  validation accuracy:		81.85 %
Epoch 1686 of 2000 took 0.103s
  training loss:		0.581125
  validation loss:		0.622531
  validation accuracy:		81.52 %
Epoch 1687 of 2000 took 0.103s
  training loss:		0.572408
  validation loss:		0.620537
  validation accuracy:		81.52 %
Epoch 1688 of 2000 took 0.103s
  training loss:		0.585582
  validation loss:		0.608131
  validation accuracy:		81.41 %
Epoch 1689 of 2000 took 0.103s
  training loss:		0.569381
  validation loss:		0.620128
  validation accuracy:		81.09 %
Epoch 1690 of 2000 took 0.103s
  training loss:		0.582955
  validation loss:		0.616397
  validation accuracy:		81.30 %
Epoch 1691 of 2000 took 0.103s
  training loss:		0.574907
  validation loss:		0.589296
  validation accuracy:		82.28 %
Epoch 1692 of 2000 took 0.103s
  training loss:		0.581038
  validation loss:		0.607801
  validation accuracy:		82.28 %
Epoch 1693 of 2000 took 0.103s
  training loss:		0.590029
  validation loss:		0.588284
  validation accuracy:		82.28 %
Epoch 1694 of 2000 took 0.103s
  training loss:		0.587524
  validation loss:		0.604122
  validation accuracy:		81.85 %
Epoch 1695 of 2000 took 0.103s
  training loss:		0.583785
  validation loss:		0.594439
  validation accuracy:		82.17 %
Epoch 1696 of 2000 took 0.103s
  training loss:		0.569478
  validation loss:		0.612753
  validation accuracy:		81.96 %
Epoch 1697 of 2000 took 0.103s
  training loss:		0.581030
  validation loss:		0.613101
  validation accuracy:		82.17 %
Epoch 1698 of 2000 took 0.103s
  training loss:		0.578404
  validation loss:		0.603457
  validation accuracy:		82.07 %
Epoch 1699 of 2000 took 0.103s
  training loss:		0.580352
  validation loss:		0.618129
  validation accuracy:		82.28 %
Epoch 1700 of 2000 took 0.103s
  training loss:		0.571950
  validation loss:		0.600083
  validation accuracy:		81.96 %
Epoch 1701 of 2000 took 0.103s
  training loss:		0.564886
  validation loss:		0.617578
  validation accuracy:		81.52 %
Epoch 1702 of 2000 took 0.103s
  training loss:		0.585479
  validation loss:		0.603517
  validation accuracy:		81.52 %
Epoch 1703 of 2000 took 0.103s
  training loss:		0.577413
  validation loss:		0.654854
  validation accuracy:		80.22 %
Epoch 1704 of 2000 took 0.103s
  training loss:		0.581030
  validation loss:		0.602906
  validation accuracy:		82.17 %
Epoch 1705 of 2000 took 0.103s
  training loss:		0.582592
  validation loss:		0.604117
  validation accuracy:		82.17 %
Epoch 1706 of 2000 took 0.103s
  training loss:		0.579654
  validation loss:		0.661543
  validation accuracy:		79.78 %
Epoch 1707 of 2000 took 0.103s
  training loss:		0.568204
  validation loss:		0.615043
  validation accuracy:		80.98 %
Epoch 1708 of 2000 took 0.104s
  training loss:		0.578377
  validation loss:		0.604058
  validation accuracy:		82.07 %
Epoch 1709 of 2000 took 0.103s
  training loss:		0.583200
  validation loss:		0.602616
  validation accuracy:		82.17 %
Epoch 1710 of 2000 took 0.103s
  training loss:		0.572280
  validation loss:		0.618048
  validation accuracy:		81.74 %
Epoch 1711 of 2000 took 0.103s
  training loss:		0.578528
  validation loss:		0.640403
  validation accuracy:		80.43 %
Epoch 1712 of 2000 took 0.103s
  training loss:		0.574519
  validation loss:		0.591298
  validation accuracy:		82.17 %
Epoch 1713 of 2000 took 0.103s
  training loss:		0.584557
  validation loss:		0.593473
  validation accuracy:		82.50 %
Epoch 1714 of 2000 took 0.103s
  training loss:		0.578682
  validation loss:		0.626664
  validation accuracy:		80.54 %
Epoch 1715 of 2000 took 0.103s
  training loss:		0.581149
  validation loss:		0.615543
  validation accuracy:		82.17 %
Epoch 1716 of 2000 took 0.103s
  training loss:		0.586495
  validation loss:		0.601021
  validation accuracy:		82.07 %
Epoch 1717 of 2000 took 0.103s
  training loss:		0.576333
  validation loss:		0.606375
  validation accuracy:		81.74 %
Epoch 1718 of 2000 took 0.103s
  training loss:		0.575416
  validation loss:		0.599535
  validation accuracy:		82.39 %
Epoch 1719 of 2000 took 0.103s
  training loss:		0.571564
  validation loss:		0.633043
  validation accuracy:		80.33 %
Epoch 1720 of 2000 took 0.103s
  training loss:		0.575637
  validation loss:		0.609741
  validation accuracy:		81.74 %
Epoch 1721 of 2000 took 0.103s
  training loss:		0.581928
  validation loss:		0.608371
  validation accuracy:		81.96 %
Epoch 1722 of 2000 took 0.103s
  training loss:		0.573596
  validation loss:		0.650245
  validation accuracy:		79.35 %
Epoch 1723 of 2000 took 0.103s
  training loss:		0.570978
  validation loss:		0.622548
  validation accuracy:		80.76 %
Epoch 1724 of 2000 took 0.103s
  training loss:		0.572096
  validation loss:		0.601669
  validation accuracy:		81.63 %
Epoch 1725 of 2000 took 0.103s
  training loss:		0.579319
  validation loss:		0.616910
  validation accuracy:		82.50 %
Epoch 1726 of 2000 took 0.103s
  training loss:		0.582094
  validation loss:		0.597681
  validation accuracy:		82.39 %
Epoch 1727 of 2000 took 0.103s
  training loss:		0.583670
  validation loss:		0.614683
  validation accuracy:		82.39 %
Epoch 1728 of 2000 took 0.103s
  training loss:		0.568486
  validation loss:		0.598298
  validation accuracy:		82.17 %
Epoch 1729 of 2000 took 0.103s
  training loss:		0.579651
  validation loss:		0.620892
  validation accuracy:		81.09 %
Epoch 1730 of 2000 took 0.103s
  training loss:		0.583415
  validation loss:		0.607089
  validation accuracy:		81.41 %
Epoch 1731 of 2000 took 0.103s
  training loss:		0.578821
  validation loss:		0.595597
  validation accuracy:		82.17 %
Epoch 1732 of 2000 took 0.103s
  training loss:		0.575132
  validation loss:		0.604370
  validation accuracy:		81.41 %
Epoch 1733 of 2000 took 0.103s
  training loss:		0.582822
  validation loss:		0.593637
  validation accuracy:		82.28 %
Epoch 1734 of 2000 took 0.103s
  training loss:		0.577686
  validation loss:		0.593201
  validation accuracy:		82.61 %
Epoch 1735 of 2000 took 0.103s
  training loss:		0.578569
  validation loss:		0.596833
  validation accuracy:		82.17 %
Epoch 1736 of 2000 took 0.103s
  training loss:		0.573479
  validation loss:		0.674462
  validation accuracy:		79.57 %
Epoch 1737 of 2000 took 0.104s
  training loss:		0.583859
  validation loss:		0.608384
  validation accuracy:		81.52 %
Epoch 1738 of 2000 took 0.103s
  training loss:		0.580260
  validation loss:		0.624757
  validation accuracy:		80.54 %
Epoch 1739 of 2000 took 0.103s
  training loss:		0.585293
  validation loss:		0.634622
  validation accuracy:		82.07 %
Epoch 1740 of 2000 took 0.103s
  training loss:		0.572216
  validation loss:		0.604764
  validation accuracy:		82.07 %
Epoch 1741 of 2000 took 0.103s
  training loss:		0.578898
  validation loss:		0.598558
  validation accuracy:		82.07 %
Epoch 1742 of 2000 took 0.103s
  training loss:		0.568422
  validation loss:		0.622770
  validation accuracy:		81.41 %
Epoch 1743 of 2000 took 0.103s
  training loss:		0.573967
  validation loss:		0.626115
  validation accuracy:		81.09 %
Epoch 1744 of 2000 took 0.103s
  training loss:		0.588415
  validation loss:		0.598345
  validation accuracy:		82.50 %
Epoch 1745 of 2000 took 0.103s
  training loss:		0.575656
  validation loss:		0.609677
  validation accuracy:		82.07 %
Epoch 1746 of 2000 took 0.103s
  training loss:		0.573816
  validation loss:		0.614367
  validation accuracy:		81.20 %
Epoch 1747 of 2000 took 0.103s
  training loss:		0.575871
  validation loss:		0.635917
  validation accuracy:		80.54 %
Epoch 1748 of 2000 took 0.103s
  training loss:		0.580849
  validation loss:		0.629089
  validation accuracy:		81.74 %
Epoch 1749 of 2000 took 0.103s
  training loss:		0.577998
  validation loss:		0.600046
  validation accuracy:		82.07 %
Epoch 1750 of 2000 took 0.103s
  training loss:		0.580419
  validation loss:		0.612167
  validation accuracy:		81.41 %
Epoch 1751 of 2000 took 0.103s
  training loss:		0.577345
  validation loss:		0.585997
  validation accuracy:		81.85 %
Epoch 1752 of 2000 took 0.103s
  training loss:		0.582776
  validation loss:		0.619969
  validation accuracy:		81.96 %
Epoch 1753 of 2000 took 0.103s
  training loss:		0.574176
  validation loss:		0.623476
  validation accuracy:		82.17 %
Epoch 1754 of 2000 took 0.103s
  training loss:		0.578131
  validation loss:		0.602728
  validation accuracy:		81.63 %
Epoch 1755 of 2000 took 0.103s
  training loss:		0.581121
  validation loss:		0.606169
  validation accuracy:		81.63 %
Epoch 1756 of 2000 took 0.103s
  training loss:		0.576626
  validation loss:		0.609186
  validation accuracy:		81.30 %
Epoch 1757 of 2000 took 0.103s
  training loss:		0.582398
  validation loss:		0.587914
  validation accuracy:		81.96 %
Epoch 1758 of 2000 took 0.103s
  training loss:		0.583888
  validation loss:		0.610627
  validation accuracy:		82.07 %
Epoch 1759 of 2000 took 0.103s
  training loss:		0.569220
  validation loss:		0.613050
  validation accuracy:		81.41 %
Epoch 1760 of 2000 took 0.103s
  training loss:		0.578497
  validation loss:		0.615825
  validation accuracy:		81.74 %
Epoch 1761 of 2000 took 0.103s
  training loss:		0.574156
  validation loss:		0.620276
  validation accuracy:		81.85 %
Epoch 1762 of 2000 took 0.103s
  training loss:		0.578401
  validation loss:		0.636677
  validation accuracy:		80.33 %
Epoch 1763 of 2000 took 0.103s
  training loss:		0.580841
  validation loss:		0.615138
  validation accuracy:		81.30 %
Epoch 1764 of 2000 took 0.103s
  training loss:		0.576585
  validation loss:		0.604571
  validation accuracy:		81.85 %
Epoch 1765 of 2000 took 0.103s
  training loss:		0.572204
  validation loss:		0.603797
  validation accuracy:		81.85 %
Epoch 1766 of 2000 took 0.103s
  training loss:		0.584074
  validation loss:		0.595985
  validation accuracy:		82.50 %
Epoch 1767 of 2000 took 0.103s
  training loss:		0.583531
  validation loss:		0.605850
  validation accuracy:		82.50 %
Epoch 1768 of 2000 took 0.103s
  training loss:		0.573235
  validation loss:		0.621615
  validation accuracy:		81.30 %
Epoch 1769 of 2000 took 0.103s
  training loss:		0.569657
  validation loss:		0.608111
  validation accuracy:		81.74 %
Epoch 1770 of 2000 took 0.103s
  training loss:		0.565743
  validation loss:		0.606343
  validation accuracy:		81.74 %
Epoch 1771 of 2000 took 0.103s
  training loss:		0.571879
  validation loss:		0.603717
  validation accuracy:		81.85 %
Epoch 1772 of 2000 took 0.103s
  training loss:		0.571743
  validation loss:		0.600096
  validation accuracy:		82.07 %
Epoch 1773 of 2000 took 0.103s
  training loss:		0.574161
  validation loss:		0.624521
  validation accuracy:		80.87 %
Epoch 1774 of 2000 took 0.103s
  training loss:		0.587510
  validation loss:		0.629195
  validation accuracy:		80.33 %
Epoch 1775 of 2000 took 0.103s
  training loss:		0.581645
  validation loss:		0.591454
  validation accuracy:		82.07 %
Epoch 1776 of 2000 took 0.103s
  training loss:		0.569819
  validation loss:		0.611128
  validation accuracy:		81.52 %
Epoch 1777 of 2000 took 0.103s
  training loss:		0.586655
  validation loss:		0.607500
  validation accuracy:		81.74 %
Epoch 1778 of 2000 took 0.103s
  training loss:		0.585667
  validation loss:		0.597300
  validation accuracy:		82.50 %
Epoch 1779 of 2000 took 0.103s
  training loss:		0.570900
  validation loss:		0.610476
  validation accuracy:		81.52 %
Epoch 1780 of 2000 took 0.103s
  training loss:		0.582248
  validation loss:		0.587702
  validation accuracy:		82.17 %
Epoch 1781 of 2000 took 0.103s
  training loss:		0.581761
  validation loss:		0.616702
  validation accuracy:		82.28 %
Epoch 1782 of 2000 took 0.103s
  training loss:		0.577954
  validation loss:		0.607150
  validation accuracy:		82.28 %
Epoch 1783 of 2000 took 0.103s
  training loss:		0.578774
  validation loss:		0.643175
  validation accuracy:		80.76 %
Epoch 1784 of 2000 took 0.103s
  training loss:		0.581905
  validation loss:		0.600573
  validation accuracy:		81.96 %
Epoch 1785 of 2000 took 0.098s
  training loss:		0.577487
  validation loss:		0.583944
  validation accuracy:		81.41 %
Epoch 1786 of 2000 took 0.097s
  training loss:		0.584834
  validation loss:		0.620002
  validation accuracy:		81.63 %
Epoch 1787 of 2000 took 0.096s
  training loss:		0.580155
  validation loss:		0.615679
  validation accuracy:		81.85 %
Epoch 1788 of 2000 took 0.097s
  training loss:		0.577265
  validation loss:		0.612801
  validation accuracy:		81.52 %
Epoch 1789 of 2000 took 0.097s
  training loss:		0.582919
  validation loss:		0.598361
  validation accuracy:		82.50 %
Epoch 1790 of 2000 took 0.097s
  training loss:		0.584222
  validation loss:		0.606035
  validation accuracy:		82.28 %
Epoch 1791 of 2000 took 0.096s
  training loss:		0.581918
  validation loss:		0.606101
  validation accuracy:		81.09 %
Epoch 1792 of 2000 took 0.097s
  training loss:		0.572369
  validation loss:		0.609531
  validation accuracy:		80.98 %
Epoch 1793 of 2000 took 0.096s
  training loss:		0.574055
  validation loss:		0.586971
  validation accuracy:		82.17 %
Epoch 1794 of 2000 took 0.096s
  training loss:		0.581630
  validation loss:		0.605802
  validation accuracy:		82.28 %
Epoch 1795 of 2000 took 0.097s
  training loss:		0.582616
  validation loss:		0.612579
  validation accuracy:		81.63 %
Epoch 1796 of 2000 took 0.097s
  training loss:		0.576303
  validation loss:		0.590933
  validation accuracy:		82.07 %
Epoch 1797 of 2000 took 0.097s
  training loss:		0.569724
  validation loss:		0.598586
  validation accuracy:		82.17 %
Epoch 1798 of 2000 took 0.096s
  training loss:		0.577591
  validation loss:		0.595131
  validation accuracy:		82.39 %
Epoch 1799 of 2000 took 0.096s
  training loss:		0.573722
  validation loss:		0.600838
  validation accuracy:		82.07 %
Epoch 1800 of 2000 took 0.097s
  training loss:		0.577491
  validation loss:		0.607223
  validation accuracy:		81.85 %
Epoch 1801 of 2000 took 0.096s
  training loss:		0.583803
  validation loss:		0.607215
  validation accuracy:		81.30 %
Epoch 1802 of 2000 took 0.097s
  training loss:		0.573165
  validation loss:		0.632736
  validation accuracy:		80.22 %
Epoch 1803 of 2000 took 0.097s
  training loss:		0.578928
  validation loss:		0.665276
  validation accuracy:		79.57 %
Epoch 1804 of 2000 took 0.096s
  training loss:		0.592837
  validation loss:		0.603127
  validation accuracy:		81.20 %
Epoch 1805 of 2000 took 0.096s
  training loss:		0.579287
  validation loss:		0.603382
  validation accuracy:		82.17 %
Epoch 1806 of 2000 took 0.097s
  training loss:		0.577942
  validation loss:		0.588795
  validation accuracy:		82.28 %
Epoch 1807 of 2000 took 0.097s
  training loss:		0.585630
  validation loss:		0.595827
  validation accuracy:		82.39 %
Epoch 1808 of 2000 took 0.096s
  training loss:		0.578232
  validation loss:		0.596175
  validation accuracy:		82.28 %
Epoch 1809 of 2000 took 0.096s
  training loss:		0.574558
  validation loss:		0.597310
  validation accuracy:		82.07 %
Epoch 1810 of 2000 took 0.097s
  training loss:		0.575433
  validation loss:		0.606750
  validation accuracy:		81.41 %
Epoch 1811 of 2000 took 0.097s
  training loss:		0.575266
  validation loss:		0.595136
  validation accuracy:		81.96 %
Epoch 1812 of 2000 took 0.096s
  training loss:		0.570302
  validation loss:		0.602520
  validation accuracy:		81.96 %
Epoch 1813 of 2000 took 0.096s
  training loss:		0.573639
  validation loss:		0.594582
  validation accuracy:		82.17 %
Epoch 1814 of 2000 took 0.096s
  training loss:		0.570167
  validation loss:		0.593922
  validation accuracy:		82.61 %
Epoch 1815 of 2000 took 0.096s
  training loss:		0.579518
  validation loss:		0.615534
  validation accuracy:		81.30 %
Epoch 1816 of 2000 took 0.097s
  training loss:		0.573018
  validation loss:		0.594394
  validation accuracy:		82.39 %
Epoch 1817 of 2000 took 0.096s
  training loss:		0.573439
  validation loss:		0.613956
  validation accuracy:		82.50 %
Epoch 1818 of 2000 took 0.096s
  training loss:		0.577388
  validation loss:		0.613006
  validation accuracy:		82.07 %
Epoch 1819 of 2000 took 0.096s
  training loss:		0.579072
  validation loss:		0.612210
  validation accuracy:		81.63 %
Epoch 1820 of 2000 took 0.096s
  training loss:		0.575546
  validation loss:		0.606463
  validation accuracy:		82.28 %
Epoch 1821 of 2000 took 0.097s
  training loss:		0.576051
  validation loss:		0.600749
  validation accuracy:		82.28 %
Epoch 1822 of 2000 took 0.096s
  training loss:		0.584043
  validation loss:		0.630739
  validation accuracy:		80.76 %
Epoch 1823 of 2000 took 0.097s
  training loss:		0.579478
  validation loss:		0.587527
  validation accuracy:		82.17 %
Epoch 1824 of 2000 took 0.096s
  training loss:		0.590579
  validation loss:		0.595912
  validation accuracy:		82.39 %
Epoch 1825 of 2000 took 0.096s
  training loss:		0.574275
  validation loss:		0.597957
  validation accuracy:		81.74 %
Epoch 1826 of 2000 took 0.097s
  training loss:		0.580588
  validation loss:		0.622092
  validation accuracy:		81.63 %
Epoch 1827 of 2000 took 0.097s
  training loss:		0.569730
  validation loss:		0.599418
  validation accuracy:		82.07 %
Epoch 1828 of 2000 took 0.098s
  training loss:		0.588520
  validation loss:		0.599554
  validation accuracy:		82.07 %
Epoch 1829 of 2000 took 0.097s
  training loss:		0.580291
  validation loss:		0.604837
  validation accuracy:		82.28 %
Epoch 1830 of 2000 took 0.097s
  training loss:		0.584255
  validation loss:		0.623152
  validation accuracy:		81.30 %
Epoch 1831 of 2000 took 0.097s
  training loss:		0.574681
  validation loss:		0.622018
  validation accuracy:		80.98 %
Epoch 1832 of 2000 took 0.097s
  training loss:		0.586495
  validation loss:		0.601022
  validation accuracy:		82.39 %
Epoch 1833 of 2000 took 0.096s
  training loss:		0.576832
  validation loss:		0.628496
  validation accuracy:		81.52 %
Epoch 1834 of 2000 took 0.096s
  training loss:		0.577130
  validation loss:		0.597935
  validation accuracy:		82.28 %
Epoch 1835 of 2000 took 0.096s
  training loss:		0.569832
  validation loss:		0.612755
  validation accuracy:		82.07 %
Epoch 1836 of 2000 took 0.096s
  training loss:		0.581614
  validation loss:		0.596341
  validation accuracy:		81.85 %
Epoch 1837 of 2000 took 0.097s
  training loss:		0.581235
  validation loss:		0.588476
  validation accuracy:		82.83 %
Epoch 1838 of 2000 took 0.096s
  training loss:		0.579049
  validation loss:		0.604127
  validation accuracy:		82.50 %
Epoch 1839 of 2000 took 0.097s
  training loss:		0.573544
  validation loss:		0.592574
  validation accuracy:		82.28 %
Epoch 1840 of 2000 took 0.096s
  training loss:		0.585364
  validation loss:		0.595297
  validation accuracy:		82.39 %
Epoch 1841 of 2000 took 0.096s
  training loss:		0.578060
  validation loss:		0.603849
  validation accuracy:		81.63 %
Epoch 1842 of 2000 took 0.097s
  training loss:		0.573206
  validation loss:		0.669401
  validation accuracy:		79.57 %
Epoch 1843 of 2000 took 0.096s
  training loss:		0.578461
  validation loss:		0.619888
  validation accuracy:		80.76 %
Epoch 1844 of 2000 took 0.096s
  training loss:		0.568588
  validation loss:		0.600274
  validation accuracy:		82.39 %
Epoch 1845 of 2000 took 0.096s
  training loss:		0.578908
  validation loss:		0.596998
  validation accuracy:		82.07 %
Epoch 1846 of 2000 took 0.096s
  training loss:		0.582826
  validation loss:		0.595674
  validation accuracy:		82.28 %
Epoch 1847 of 2000 took 0.097s
  training loss:		0.575741
  validation loss:		0.602435
  validation accuracy:		82.50 %
Epoch 1848 of 2000 took 0.098s
  training loss:		0.580958
  validation loss:		0.607890
  validation accuracy:		81.74 %
Epoch 1849 of 2000 took 0.096s
  training loss:		0.583822
  validation loss:		0.602067
  validation accuracy:		82.39 %
Epoch 1850 of 2000 took 0.097s
  training loss:		0.577512
  validation loss:		0.636400
  validation accuracy:		81.52 %
Epoch 1851 of 2000 took 0.096s
  training loss:		0.583036
  validation loss:		0.598436
  validation accuracy:		82.61 %
Epoch 1852 of 2000 took 0.097s
  training loss:		0.579535
  validation loss:		0.598444
  validation accuracy:		81.96 %
Epoch 1853 of 2000 took 0.097s
  training loss:		0.584222
  validation loss:		0.595581
  validation accuracy:		81.96 %
Epoch 1854 of 2000 took 0.097s
  training loss:		0.575820
  validation loss:		0.596855
  validation accuracy:		82.61 %
Epoch 1855 of 2000 took 0.096s
  training loss:		0.570092
  validation loss:		0.604292
  validation accuracy:		81.52 %
Epoch 1856 of 2000 took 0.096s
  training loss:		0.574889
  validation loss:		0.587201
  validation accuracy:		81.20 %
Epoch 1857 of 2000 took 0.097s
  training loss:		0.579694
  validation loss:		0.597740
  validation accuracy:		82.39 %
Epoch 1858 of 2000 took 0.097s
  training loss:		0.578452
  validation loss:		0.599106
  validation accuracy:		82.17 %
Epoch 1859 of 2000 took 0.097s
  training loss:		0.591956
  validation loss:		0.607054
  validation accuracy:		81.74 %
Epoch 1860 of 2000 took 0.097s
  training loss:		0.573019
  validation loss:		0.615713
  validation accuracy:		81.96 %
Epoch 1861 of 2000 took 0.096s
  training loss:		0.575307
  validation loss:		0.603587
  validation accuracy:		82.17 %
Epoch 1862 of 2000 took 0.097s
  training loss:		0.577067
  validation loss:		0.595487
  validation accuracy:		82.61 %
Epoch 1863 of 2000 took 0.097s
  training loss:		0.574723
  validation loss:		0.606287
  validation accuracy:		81.41 %
Epoch 1864 of 2000 took 0.097s
  training loss:		0.561960
  validation loss:		0.600192
  validation accuracy:		82.07 %
Epoch 1865 of 2000 took 0.096s
  training loss:		0.570868
  validation loss:		0.598387
  validation accuracy:		81.96 %
Epoch 1866 of 2000 took 0.097s
  training loss:		0.574297
  validation loss:		0.597597
  validation accuracy:		82.61 %
Epoch 1867 of 2000 took 0.097s
  training loss:		0.571023
  validation loss:		0.614038
  validation accuracy:		80.87 %
Epoch 1868 of 2000 took 0.097s
  training loss:		0.574087
  validation loss:		0.603372
  validation accuracy:		82.50 %
Epoch 1869 of 2000 took 0.096s
  training loss:		0.585504
  validation loss:		0.609221
  validation accuracy:		81.63 %
Epoch 1870 of 2000 took 0.097s
  training loss:		0.577343
  validation loss:		0.612262
  validation accuracy:		81.20 %
Epoch 1871 of 2000 took 0.097s
  training loss:		0.576418
  validation loss:		0.586789
  validation accuracy:		81.52 %
Epoch 1872 of 2000 took 0.096s
  training loss:		0.580746
  validation loss:		0.587501
  validation accuracy:		80.76 %
Epoch 1873 of 2000 took 0.097s
  training loss:		0.587125
  validation loss:		0.648287
  validation accuracy:		79.24 %
Epoch 1874 of 2000 took 0.096s
  training loss:		0.587467
  validation loss:		0.600087
  validation accuracy:		81.74 %
Epoch 1875 of 2000 took 0.097s
  training loss:		0.570083
  validation loss:		0.619322
  validation accuracy:		81.74 %
Epoch 1876 of 2000 took 0.096s
  training loss:		0.575175
  validation loss:		0.603375
  validation accuracy:		82.61 %
Epoch 1877 of 2000 took 0.097s
  training loss:		0.576528
  validation loss:		0.598861
  validation accuracy:		81.96 %
Epoch 1878 of 2000 took 0.097s
  training loss:		0.578498
  validation loss:		0.609756
  validation accuracy:		82.39 %
Epoch 1879 of 2000 took 0.097s
  training loss:		0.574812
  validation loss:		0.633699
  validation accuracy:		80.54 %
Epoch 1880 of 2000 took 0.096s
  training loss:		0.576202
  validation loss:		0.597728
  validation accuracy:		82.61 %
Epoch 1881 of 2000 took 0.097s
  training loss:		0.572336
  validation loss:		0.634403
  validation accuracy:		79.89 %
Epoch 1882 of 2000 took 0.097s
  training loss:		0.577954
  validation loss:		0.594490
  validation accuracy:		82.28 %
Epoch 1883 of 2000 took 0.097s
  training loss:		0.571396
  validation loss:		0.599145
  validation accuracy:		82.17 %
Epoch 1884 of 2000 took 0.096s
  training loss:		0.584566
  validation loss:		0.616098
  validation accuracy:		81.74 %
Epoch 1885 of 2000 took 0.097s
  training loss:		0.574992
  validation loss:		0.613055
  validation accuracy:		81.85 %
Epoch 1886 of 2000 took 0.096s
  training loss:		0.592728
  validation loss:		0.624526
  validation accuracy:		81.63 %
Epoch 1887 of 2000 took 0.097s
  training loss:		0.583631
  validation loss:		0.583521
  validation accuracy:		81.96 %
Epoch 1888 of 2000 took 0.096s
  training loss:		0.577984
  validation loss:		0.606557
  validation accuracy:		82.17 %
Epoch 1889 of 2000 took 0.097s
  training loss:		0.572436
  validation loss:		0.592975
  validation accuracy:		82.61 %
Epoch 1890 of 2000 took 0.098s
  training loss:		0.578659
  validation loss:		0.611728
  validation accuracy:		81.20 %
Epoch 1891 of 2000 took 0.097s
  training loss:		0.577466
  validation loss:		0.646872
  validation accuracy:		80.76 %
Epoch 1892 of 2000 took 0.096s
  training loss:		0.581033
  validation loss:		0.601532
  validation accuracy:		82.39 %
Epoch 1893 of 2000 took 0.097s
  training loss:		0.581736
  validation loss:		0.627485
  validation accuracy:		81.20 %
Epoch 1894 of 2000 took 0.097s
  training loss:		0.577740
  validation loss:		0.594125
  validation accuracy:		82.72 %
Epoch 1895 of 2000 took 0.097s
  training loss:		0.574011
  validation loss:		0.608094
  validation accuracy:		81.74 %
Epoch 1896 of 2000 took 0.096s
  training loss:		0.570598
  validation loss:		0.613397
  validation accuracy:		81.30 %
Epoch 1897 of 2000 took 0.097s
  training loss:		0.573979
  validation loss:		0.628921
  validation accuracy:		80.11 %
Epoch 1898 of 2000 took 0.096s
  training loss:		0.583657
  validation loss:		0.590340
  validation accuracy:		82.61 %
Epoch 1899 of 2000 took 0.097s
  training loss:		0.565290
  validation loss:		0.617261
  validation accuracy:		82.28 %
Epoch 1900 of 2000 took 0.096s
  training loss:		0.577012
  validation loss:		0.624040
  validation accuracy:		80.98 %
Epoch 1901 of 2000 took 0.097s
  training loss:		0.577318
  validation loss:		0.602541
  validation accuracy:		81.74 %
Epoch 1902 of 2000 took 0.097s
  training loss:		0.581785
  validation loss:		0.590299
  validation accuracy:		82.61 %
Epoch 1903 of 2000 took 0.096s
  training loss:		0.575967
  validation loss:		0.600645
  validation accuracy:		82.17 %
Epoch 1904 of 2000 took 0.097s
  training loss:		0.564277
  validation loss:		0.613215
  validation accuracy:		81.96 %
Epoch 1905 of 2000 took 0.096s
  training loss:		0.574765
  validation loss:		0.616034
  validation accuracy:		81.52 %
Epoch 1906 of 2000 took 0.097s
  training loss:		0.571430
  validation loss:		0.599032
  validation accuracy:		82.50 %
Epoch 1907 of 2000 took 0.097s
  training loss:		0.577474
  validation loss:		0.598299
  validation accuracy:		82.72 %
Epoch 1908 of 2000 took 0.097s
  training loss:		0.573215
  validation loss:		0.617159
  validation accuracy:		81.96 %
Epoch 1909 of 2000 took 0.097s
  training loss:		0.581752
  validation loss:		0.611957
  validation accuracy:		81.85 %
Epoch 1910 of 2000 took 0.097s
  training loss:		0.580188
  validation loss:		0.588386
  validation accuracy:		82.50 %
Epoch 1911 of 2000 took 0.096s
  training loss:		0.574156
  validation loss:		0.621735
  validation accuracy:		82.17 %
Epoch 1912 of 2000 took 0.097s
  training loss:		0.570933
  validation loss:		0.603959
  validation accuracy:		82.61 %
Epoch 1913 of 2000 took 0.097s
  training loss:		0.583324
  validation loss:		0.590228
  validation accuracy:		81.85 %
Epoch 1914 of 2000 took 0.097s
  training loss:		0.580448
  validation loss:		0.624130
  validation accuracy:		80.76 %
Epoch 1915 of 2000 took 0.096s
  training loss:		0.583456
  validation loss:		0.607471
  validation accuracy:		82.50 %
Epoch 1916 of 2000 took 0.097s
  training loss:		0.579755
  validation loss:		0.591842
  validation accuracy:		82.07 %
Epoch 1917 of 2000 took 0.096s
  training loss:		0.575741
  validation loss:		0.595759
  validation accuracy:		82.07 %
Epoch 1918 of 2000 took 0.097s
  training loss:		0.579367
  validation loss:		0.586561
  validation accuracy:		82.28 %
Epoch 1919 of 2000 took 0.096s
  training loss:		0.580182
  validation loss:		0.600735
  validation accuracy:		82.28 %
Epoch 1920 of 2000 took 0.097s
  training loss:		0.573065
  validation loss:		0.607116
  validation accuracy:		81.63 %
Epoch 1921 of 2000 took 0.097s
  training loss:		0.581548
  validation loss:		0.635237
  validation accuracy:		80.43 %
Epoch 1922 of 2000 took 0.097s
  training loss:		0.581243
  validation loss:		0.603107
  validation accuracy:		82.61 %
Epoch 1923 of 2000 took 0.096s
  training loss:		0.560526
  validation loss:		0.596864
  validation accuracy:		82.50 %
Epoch 1924 of 2000 took 0.097s
  training loss:		0.577439
  validation loss:		0.614362
  validation accuracy:		81.63 %
Epoch 1925 of 2000 took 0.097s
  training loss:		0.573474
  validation loss:		0.600134
  validation accuracy:		82.61 %
Epoch 1926 of 2000 took 0.097s
  training loss:		0.582677
  validation loss:		0.603736
  validation accuracy:		82.17 %
Epoch 1927 of 2000 took 0.096s
  training loss:		0.567800
  validation loss:		0.624507
  validation accuracy:		81.41 %
Epoch 1928 of 2000 took 0.096s
  training loss:		0.580360
  validation loss:		0.615552
  validation accuracy:		81.74 %
Epoch 1929 of 2000 took 0.096s
  training loss:		0.573717
  validation loss:		0.636514
  validation accuracy:		80.54 %
Epoch 1930 of 2000 took 0.099s
  training loss:		0.576093
  validation loss:		0.589248
  validation accuracy:		81.85 %
Epoch 1931 of 2000 took 0.097s
  training loss:		0.577598
  validation loss:		0.618545
  validation accuracy:		81.74 %
Epoch 1932 of 2000 took 0.096s
  training loss:		0.575315
  validation loss:		0.591915
  validation accuracy:		81.74 %
Epoch 1933 of 2000 took 0.097s
  training loss:		0.579946
  validation loss:		0.595262
  validation accuracy:		82.83 %
Epoch 1934 of 2000 took 0.097s
  training loss:		0.580598
  validation loss:		0.613973
  validation accuracy:		80.98 %
Epoch 1935 of 2000 took 0.097s
  training loss:		0.573590
  validation loss:		0.619396
  validation accuracy:		81.63 %
Epoch 1936 of 2000 took 0.097s
  training loss:		0.576048
  validation loss:		0.613602
  validation accuracy:		81.52 %
Epoch 1937 of 2000 took 0.097s
  training loss:		0.578228
  validation loss:		0.625314
  validation accuracy:		80.22 %
Epoch 1938 of 2000 took 0.096s
  training loss:		0.576632
  validation loss:		0.633530
  validation accuracy:		80.87 %
Epoch 1939 of 2000 took 0.097s
  training loss:		0.574330
  validation loss:		0.614206
  validation accuracy:		81.63 %
Epoch 1940 of 2000 took 0.097s
  training loss:		0.578159
  validation loss:		0.599428
  validation accuracy:		81.96 %
Epoch 1941 of 2000 took 0.097s
  training loss:		0.584597
  validation loss:		0.621586
  validation accuracy:		81.30 %
Epoch 1942 of 2000 took 0.096s
  training loss:		0.581388
  validation loss:		0.608545
  validation accuracy:		82.39 %
Epoch 1943 of 2000 took 0.097s
  training loss:		0.573701
  validation loss:		0.621161
  validation accuracy:		80.65 %
Epoch 1944 of 2000 took 0.096s
  training loss:		0.570467
  validation loss:		0.603665
  validation accuracy:		82.61 %
Epoch 1945 of 2000 took 0.097s
  training loss:		0.573204
  validation loss:		0.599256
  validation accuracy:		82.17 %
Epoch 1946 of 2000 took 0.097s
  training loss:		0.584160
  validation loss:		0.614847
  validation accuracy:		81.41 %
Epoch 1947 of 2000 took 0.097s
  training loss:		0.574617
  validation loss:		0.605054
  validation accuracy:		81.96 %
Epoch 1948 of 2000 took 0.096s
  training loss:		0.579887
  validation loss:		0.616737
  validation accuracy:		81.09 %
Epoch 1949 of 2000 took 0.097s
  training loss:		0.566888
  validation loss:		0.609600
  validation accuracy:		82.28 %
Epoch 1950 of 2000 took 0.097s
  training loss:		0.579178
  validation loss:		0.601567
  validation accuracy:		81.96 %
Epoch 1951 of 2000 took 0.097s
  training loss:		0.579222
  validation loss:		0.609652
  validation accuracy:		82.39 %
Epoch 1952 of 2000 took 0.097s
  training loss:		0.578039
  validation loss:		0.603931
  validation accuracy:		82.17 %
Epoch 1953 of 2000 took 0.098s
  training loss:		0.582617
  validation loss:		0.602294
  validation accuracy:		82.28 %
Epoch 1954 of 2000 took 0.097s
  training loss:		0.581029
  validation loss:		0.616823
  validation accuracy:		81.09 %
Epoch 1955 of 2000 took 0.097s
  training loss:		0.574321
  validation loss:		0.604631
  validation accuracy:		82.07 %
Epoch 1956 of 2000 took 0.097s
  training loss:		0.583707
  validation loss:		0.590388
  validation accuracy:		82.07 %
Epoch 1957 of 2000 took 0.097s
  training loss:		0.578180
  validation loss:		0.635879
  validation accuracy:		81.52 %
Epoch 1958 of 2000 took 0.096s
  training loss:		0.574825
  validation loss:		0.592055
  validation accuracy:		81.74 %
Epoch 1959 of 2000 took 0.097s
  training loss:		0.584101
  validation loss:		0.648166
  validation accuracy:		79.57 %
Epoch 1960 of 2000 took 0.096s
  training loss:		0.575689
  validation loss:		0.597481
  validation accuracy:		82.50 %
Epoch 1961 of 2000 took 0.096s
  training loss:		0.582100
  validation loss:		0.593235
  validation accuracy:		82.28 %
Epoch 1962 of 2000 took 0.097s
  training loss:		0.563301
  validation loss:		0.605085
  validation accuracy:		82.28 %
Epoch 1963 of 2000 took 0.096s
  training loss:		0.573428
  validation loss:		0.603476
  validation accuracy:		81.85 %
Epoch 1964 of 2000 took 0.097s
  training loss:		0.573398
  validation loss:		0.603972
  validation accuracy:		82.50 %
Epoch 1965 of 2000 took 0.096s
  training loss:		0.570231
  validation loss:		0.595751
  validation accuracy:		82.61 %
Epoch 1966 of 2000 took 0.097s
  training loss:		0.576943
  validation loss:		0.650143
  validation accuracy:		80.11 %
Epoch 1967 of 2000 took 0.097s
  training loss:		0.579590
  validation loss:		0.595078
  validation accuracy:		82.61 %
Epoch 1968 of 2000 took 0.097s
  training loss:		0.578485
  validation loss:		0.617633
  validation accuracy:		81.09 %
Epoch 1969 of 2000 took 0.096s
  training loss:		0.582766
  validation loss:		0.605134
  validation accuracy:		82.61 %
Epoch 1970 of 2000 took 0.097s
  training loss:		0.571762
  validation loss:		0.600071
  validation accuracy:		82.39 %
Epoch 1971 of 2000 took 0.097s
  training loss:		0.575758
  validation loss:		0.600157
  validation accuracy:		82.17 %
Epoch 1972 of 2000 took 0.097s
  training loss:		0.584216
  validation loss:		0.603068
  validation accuracy:		82.07 %
Epoch 1973 of 2000 took 0.096s
  training loss:		0.574364
  validation loss:		0.603669
  validation accuracy:		82.39 %
Epoch 1974 of 2000 took 0.096s
  training loss:		0.581299
  validation loss:		0.602938
  validation accuracy:		82.07 %
Epoch 1975 of 2000 took 0.096s
  training loss:		0.572438
  validation loss:		0.626124
  validation accuracy:		80.54 %
Epoch 1976 of 2000 took 0.097s
  training loss:		0.575935
  validation loss:		0.600125
  validation accuracy:		81.85 %
Epoch 1977 of 2000 took 0.097s
  training loss:		0.575834
  validation loss:		0.607605
  validation accuracy:		81.52 %
Epoch 1978 of 2000 took 0.097s
  training loss:		0.578922
  validation loss:		0.620504
  validation accuracy:		81.30 %
Epoch 1979 of 2000 took 0.096s
  training loss:		0.577087
  validation loss:		0.591434
  validation accuracy:		82.50 %
Epoch 1980 of 2000 took 0.097s
  training loss:		0.573587
  validation loss:		0.588744
  validation accuracy:		81.85 %
Epoch 1981 of 2000 took 0.099s
  training loss:		0.580951
  validation loss:		0.605940
  validation accuracy:		82.61 %
Epoch 1982 of 2000 took 0.100s
  training loss:		0.581682
  validation loss:		0.620021
  validation accuracy:		81.20 %
Epoch 1983 of 2000 took 0.100s
  training loss:		0.578144
  validation loss:		0.598052
  validation accuracy:		82.72 %
Epoch 1984 of 2000 took 0.100s
  training loss:		0.582408
  validation loss:		0.586650
  validation accuracy:		81.85 %
Epoch 1985 of 2000 took 0.100s
  training loss:		0.579543
  validation loss:		0.607637
  validation accuracy:		81.52 %
Epoch 1986 of 2000 took 0.100s
  training loss:		0.580534
  validation loss:		0.624715
  validation accuracy:		81.20 %
Epoch 1987 of 2000 took 0.100s
  training loss:		0.570160
  validation loss:		0.605343
  validation accuracy:		82.17 %
Epoch 1988 of 2000 took 0.100s
  training loss:		0.577271
  validation loss:		0.602647
  validation accuracy:		82.61 %
Epoch 1989 of 2000 took 0.100s
  training loss:		0.564844
  validation loss:		0.617130
  validation accuracy:		81.74 %
Epoch 1990 of 2000 took 0.100s
  training loss:		0.572728
  validation loss:		0.604829
  validation accuracy:		80.98 %
Epoch 1991 of 2000 took 0.100s
  training loss:		0.583863
  validation loss:		0.629996
  validation accuracy:		81.41 %
Epoch 1992 of 2000 took 0.100s
  training loss:		0.583990
  validation loss:		0.620054
  validation accuracy:		81.52 %
Epoch 1993 of 2000 took 0.100s
  training loss:		0.572175
  validation loss:		0.605151
  validation accuracy:		82.07 %
Epoch 1994 of 2000 took 0.100s
  training loss:		0.575712
  validation loss:		0.595999
  validation accuracy:		82.28 %
Epoch 1995 of 2000 took 0.098s
  training loss:		0.583624
  validation loss:		0.623282
  validation accuracy:		80.22 %
Epoch 1996 of 2000 took 0.097s
  training loss:		0.580323
  validation loss:		0.590993
  validation accuracy:		82.07 %
Epoch 1997 of 2000 took 0.097s
  training loss:		0.573526
  validation loss:		0.603433
  validation accuracy:		81.41 %
Epoch 1998 of 2000 took 0.097s
  training loss:		0.582707
  validation loss:		0.608017
  validation accuracy:		81.52 %
Epoch 1999 of 2000 took 0.097s
  training loss:		0.580528
  validation loss:		0.609650
  validation accuracy:		81.52 %
Epoch 2000 of 2000 took 0.097s
  training loss:		0.564432
  validation loss:		0.601823
  validation accuracy:		82.39 %
Final results:
  test loss:			0.838686
  test accuracy:		74.38 %
