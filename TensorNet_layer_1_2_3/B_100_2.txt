Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 200),b=(200,)
w=(200, 200),b=(200,)
w=(200, 200),b=(200,)
decomposing tensor W of shape (3, 200, 200)...
decomposing tensor B of shape (3, 200)...
Starting training...
Epoch 1 of 2000 took 0.042s
  training loss:		3.039536
  validation loss:		2.228817
  validation accuracy:		34.02 %
Epoch 2 of 2000 took 0.037s
  training loss:		1.892335
  validation loss:		1.568969
  validation accuracy:		47.39 %
Epoch 3 of 2000 took 0.035s
  training loss:		1.499142
  validation loss:		1.367047
  validation accuracy:		53.59 %
Epoch 4 of 2000 took 0.058s
  training loss:		1.372971
  validation loss:		1.266712
  validation accuracy:		56.63 %
Epoch 5 of 2000 took 0.050s
  training loss:		1.284827
  validation loss:		1.179835
  validation accuracy:		60.43 %
Epoch 6 of 2000 took 0.043s
  training loss:		1.222626
  validation loss:		1.132429
  validation accuracy:		61.52 %
Epoch 7 of 2000 took 0.039s
  training loss:		1.161365
  validation loss:		1.068956
  validation accuracy:		63.26 %
Epoch 8 of 2000 took 0.036s
  training loss:		1.097772
  validation loss:		1.019854
  validation accuracy:		65.22 %
Epoch 9 of 2000 took 0.035s
  training loss:		1.052509
  validation loss:		0.981286
  validation accuracy:		67.72 %
Epoch 10 of 2000 took 0.035s
  training loss:		1.005658
  validation loss:		0.930413
  validation accuracy:		68.59 %
Epoch 11 of 2000 took 0.035s
  training loss:		0.964188
  validation loss:		0.895014
  validation accuracy:		70.00 %
Epoch 12 of 2000 took 0.035s
  training loss:		0.916131
  validation loss:		0.855038
  validation accuracy:		71.74 %
Epoch 13 of 2000 took 0.036s
  training loss:		0.874549
  validation loss:		0.820758
  validation accuracy:		73.80 %
Epoch 14 of 2000 took 0.035s
  training loss:		0.841855
  validation loss:		0.777175
  validation accuracy:		74.57 %
Epoch 15 of 2000 took 0.035s
  training loss:		0.808528
  validation loss:		0.767141
  validation accuracy:		74.67 %
Epoch 16 of 2000 took 0.035s
  training loss:		0.778413
  validation loss:		0.722076
  validation accuracy:		76.52 %
Epoch 17 of 2000 took 0.035s
  training loss:		0.748675
  validation loss:		0.689163
  validation accuracy:		77.28 %
Epoch 18 of 2000 took 0.035s
  training loss:		0.724571
  validation loss:		0.689525
  validation accuracy:		77.50 %
Epoch 19 of 2000 took 0.035s
  training loss:		0.693632
  validation loss:		0.663017
  validation accuracy:		78.70 %
Epoch 20 of 2000 took 0.035s
  training loss:		0.664523
  validation loss:		0.641940
  validation accuracy:		79.46 %
Epoch 21 of 2000 took 0.035s
  training loss:		0.638410
  validation loss:		0.620526
  validation accuracy:		79.78 %
Epoch 22 of 2000 took 0.035s
  training loss:		0.618136
  validation loss:		0.594121
  validation accuracy:		81.30 %
Epoch 23 of 2000 took 0.035s
  training loss:		0.601558
  validation loss:		0.584113
  validation accuracy:		81.20 %
Epoch 24 of 2000 took 0.035s
  training loss:		0.586707
  validation loss:		0.561789
  validation accuracy:		82.39 %
Epoch 25 of 2000 took 0.035s
  training loss:		0.575929
  validation loss:		0.555424
  validation accuracy:		82.39 %
Epoch 26 of 2000 took 0.035s
  training loss:		0.558977
  validation loss:		0.521653
  validation accuracy:		83.91 %
Epoch 27 of 2000 took 0.035s
  training loss:		0.541302
  validation loss:		0.525378
  validation accuracy:		83.59 %
Epoch 28 of 2000 took 0.035s
  training loss:		0.524311
  validation loss:		0.509416
  validation accuracy:		83.91 %
Epoch 29 of 2000 took 0.035s
  training loss:		0.518966
  validation loss:		0.487183
  validation accuracy:		84.24 %
Epoch 30 of 2000 took 0.035s
  training loss:		0.504470
  validation loss:		0.491633
  validation accuracy:		84.67 %
Epoch 31 of 2000 took 0.035s
  training loss:		0.489239
  validation loss:		0.481793
  validation accuracy:		84.57 %
Epoch 32 of 2000 took 0.035s
  training loss:		0.474359
  validation loss:		0.471553
  validation accuracy:		85.33 %
Epoch 33 of 2000 took 0.035s
  training loss:		0.478505
  validation loss:		0.475627
  validation accuracy:		84.89 %
Epoch 34 of 2000 took 0.035s
  training loss:		0.459162
  validation loss:		0.447779
  validation accuracy:		86.41 %
Epoch 35 of 2000 took 0.035s
  training loss:		0.449787
  validation loss:		0.459723
  validation accuracy:		85.76 %
Epoch 36 of 2000 took 0.035s
  training loss:		0.446336
  validation loss:		0.436814
  validation accuracy:		86.41 %
Epoch 37 of 2000 took 0.036s
  training loss:		0.438532
  validation loss:		0.422569
  validation accuracy:		87.07 %
Epoch 38 of 2000 took 0.035s
  training loss:		0.426749
  validation loss:		0.415306
  validation accuracy:		86.96 %
Epoch 39 of 2000 took 0.035s
  training loss:		0.421342
  validation loss:		0.422032
  validation accuracy:		86.74 %
Epoch 40 of 2000 took 0.035s
  training loss:		0.415612
  validation loss:		0.413979
  validation accuracy:		86.85 %
Epoch 41 of 2000 took 0.035s
  training loss:		0.408610
  validation loss:		0.411583
  validation accuracy:		87.07 %
Epoch 42 of 2000 took 0.035s
  training loss:		0.404221
  validation loss:		0.400286
  validation accuracy:		87.50 %
Epoch 43 of 2000 took 0.035s
  training loss:		0.396486
  validation loss:		0.401682
  validation accuracy:		87.07 %
Epoch 44 of 2000 took 0.035s
  training loss:		0.386057
  validation loss:		0.396450
  validation accuracy:		87.17 %
Epoch 45 of 2000 took 0.035s
  training loss:		0.386792
  validation loss:		0.385000
  validation accuracy:		87.83 %
Epoch 46 of 2000 took 0.035s
  training loss:		0.381240
  validation loss:		0.381220
  validation accuracy:		87.83 %
Epoch 47 of 2000 took 0.035s
  training loss:		0.369588
  validation loss:		0.380093
  validation accuracy:		88.26 %
Epoch 48 of 2000 took 0.035s
  training loss:		0.365459
  validation loss:		0.363479
  validation accuracy:		88.26 %
Epoch 49 of 2000 took 0.035s
  training loss:		0.361142
  validation loss:		0.386537
  validation accuracy:		87.83 %
Epoch 50 of 2000 took 0.035s
  training loss:		0.359067
  validation loss:		0.365146
  validation accuracy:		88.59 %
Epoch 51 of 2000 took 0.035s
  training loss:		0.356604
  validation loss:		0.389322
  validation accuracy:		87.61 %
Epoch 52 of 2000 took 0.035s
  training loss:		0.350017
  validation loss:		0.365384
  validation accuracy:		88.26 %
Epoch 53 of 2000 took 0.035s
  training loss:		0.345974
  validation loss:		0.356056
  validation accuracy:		89.13 %
Epoch 54 of 2000 took 0.035s
  training loss:		0.342704
  validation loss:		0.355611
  validation accuracy:		88.91 %
Epoch 55 of 2000 took 0.035s
  training loss:		0.339377
  validation loss:		0.348123
  validation accuracy:		89.13 %
Epoch 56 of 2000 took 0.035s
  training loss:		0.333516
  validation loss:		0.342592
  validation accuracy:		89.46 %
Epoch 57 of 2000 took 0.035s
  training loss:		0.330872
  validation loss:		0.340095
  validation accuracy:		89.57 %
Epoch 58 of 2000 took 0.035s
  training loss:		0.325432
  validation loss:		0.343970
  validation accuracy:		88.91 %
Epoch 59 of 2000 took 0.035s
  training loss:		0.322855
  validation loss:		0.329472
  validation accuracy:		89.46 %
Epoch 60 of 2000 took 0.035s
  training loss:		0.315591
  validation loss:		0.340919
  validation accuracy:		89.46 %
Epoch 61 of 2000 took 0.035s
  training loss:		0.316316
  validation loss:		0.334786
  validation accuracy:		89.67 %
Epoch 62 of 2000 took 0.035s
  training loss:		0.318831
  validation loss:		0.337982
  validation accuracy:		89.46 %
Epoch 63 of 2000 took 0.035s
  training loss:		0.311666
  validation loss:		0.329757
  validation accuracy:		89.78 %
Epoch 64 of 2000 took 0.035s
  training loss:		0.308125
  validation loss:		0.323746
  validation accuracy:		89.57 %
Epoch 65 of 2000 took 0.035s
  training loss:		0.305323
  validation loss:		0.325592
  validation accuracy:		89.67 %
Epoch 66 of 2000 took 0.035s
  training loss:		0.292986
  validation loss:		0.327608
  validation accuracy:		90.22 %
Epoch 67 of 2000 took 0.035s
  training loss:		0.305594
  validation loss:		0.321494
  validation accuracy:		89.78 %
Epoch 68 of 2000 took 0.035s
  training loss:		0.295473
  validation loss:		0.323851
  validation accuracy:		90.22 %
Epoch 69 of 2000 took 0.035s
  training loss:		0.291739
  validation loss:		0.316478
  validation accuracy:		90.22 %
Epoch 70 of 2000 took 0.036s
  training loss:		0.289632
  validation loss:		0.339084
  validation accuracy:		88.91 %
Epoch 71 of 2000 took 0.035s
  training loss:		0.290906
  validation loss:		0.335081
  validation accuracy:		89.35 %
Epoch 72 of 2000 took 0.035s
  training loss:		0.293247
  validation loss:		0.316577
  validation accuracy:		90.11 %
Epoch 73 of 2000 took 0.035s
  training loss:		0.285561
  validation loss:		0.307745
  validation accuracy:		90.11 %
Epoch 74 of 2000 took 0.035s
  training loss:		0.278098
  validation loss:		0.322932
  validation accuracy:		89.67 %
Epoch 75 of 2000 took 0.035s
  training loss:		0.280296
  validation loss:		0.313857
  validation accuracy:		90.22 %
Epoch 76 of 2000 took 0.035s
  training loss:		0.277929
  validation loss:		0.308048
  validation accuracy:		90.54 %
Epoch 77 of 2000 took 0.035s
  training loss:		0.274451
  validation loss:		0.313002
  validation accuracy:		90.43 %
Epoch 78 of 2000 took 0.035s
  training loss:		0.270973
  validation loss:		0.312748
  validation accuracy:		90.11 %
Epoch 79 of 2000 took 0.035s
  training loss:		0.270129
  validation loss:		0.313444
  validation accuracy:		90.65 %
Epoch 80 of 2000 took 0.035s
  training loss:		0.268741
  validation loss:		0.299797
  validation accuracy:		90.98 %
Epoch 81 of 2000 took 0.035s
  training loss:		0.270858
  validation loss:		0.299368
  validation accuracy:		90.98 %
Epoch 82 of 2000 took 0.035s
  training loss:		0.264380
  validation loss:		0.305829
  validation accuracy:		90.98 %
Epoch 83 of 2000 took 0.035s
  training loss:		0.261416
  validation loss:		0.289401
  validation accuracy:		91.63 %
Epoch 84 of 2000 took 0.035s
  training loss:		0.258387
  validation loss:		0.297244
  validation accuracy:		90.54 %
Epoch 85 of 2000 took 0.035s
  training loss:		0.257205
  validation loss:		0.304871
  validation accuracy:		90.98 %
Epoch 86 of 2000 took 0.035s
  training loss:		0.261470
  validation loss:		0.295599
  validation accuracy:		91.09 %
Epoch 87 of 2000 took 0.036s
  training loss:		0.256487
  validation loss:		0.297490
  validation accuracy:		91.41 %
Epoch 88 of 2000 took 0.035s
  training loss:		0.254489
  validation loss:		0.295296
  validation accuracy:		90.87 %
Epoch 89 of 2000 took 0.035s
  training loss:		0.254675
  validation loss:		0.294387
  validation accuracy:		91.30 %
Epoch 90 of 2000 took 0.035s
  training loss:		0.248741
  validation loss:		0.292254
  validation accuracy:		91.63 %
Epoch 91 of 2000 took 0.035s
  training loss:		0.251493
  validation loss:		0.289105
  validation accuracy:		91.63 %
Epoch 92 of 2000 took 0.035s
  training loss:		0.242067
  validation loss:		0.289815
  validation accuracy:		91.30 %
Epoch 93 of 2000 took 0.035s
  training loss:		0.246967
  validation loss:		0.290506
  validation accuracy:		91.20 %
Epoch 94 of 2000 took 0.035s
  training loss:		0.242395
  validation loss:		0.287508
  validation accuracy:		91.63 %
Epoch 95 of 2000 took 0.035s
  training loss:		0.241974
  validation loss:		0.284389
  validation accuracy:		91.63 %
Epoch 96 of 2000 took 0.035s
  training loss:		0.237860
  validation loss:		0.285283
  validation accuracy:		91.41 %
Epoch 97 of 2000 took 0.035s
  training loss:		0.237764
  validation loss:		0.273482
  validation accuracy:		92.07 %
Epoch 98 of 2000 took 0.036s
  training loss:		0.233554
  validation loss:		0.291219
  validation accuracy:		91.09 %
Epoch 99 of 2000 took 0.035s
  training loss:		0.238289
  validation loss:		0.285984
  validation accuracy:		91.74 %
Epoch 100 of 2000 took 0.035s
  training loss:		0.228002
  validation loss:		0.290820
  validation accuracy:		91.52 %
Epoch 101 of 2000 took 0.035s
  training loss:		0.227132
  validation loss:		0.274267
  validation accuracy:		91.74 %
Epoch 102 of 2000 took 0.035s
  training loss:		0.230850
  validation loss:		0.279331
  validation accuracy:		91.96 %
Epoch 103 of 2000 took 0.035s
  training loss:		0.228574
  validation loss:		0.285728
  validation accuracy:		91.41 %
Epoch 104 of 2000 took 0.035s
  training loss:		0.226322
  validation loss:		0.283250
  validation accuracy:		91.41 %
Epoch 105 of 2000 took 0.035s
  training loss:		0.227057
  validation loss:		0.283259
  validation accuracy:		91.41 %
Epoch 106 of 2000 took 0.035s
  training loss:		0.223213
  validation loss:		0.281866
  validation accuracy:		91.85 %
Epoch 107 of 2000 took 0.035s
  training loss:		0.226929
  validation loss:		0.280307
  validation accuracy:		91.52 %
Epoch 108 of 2000 took 0.035s
  training loss:		0.222135
  validation loss:		0.271263
  validation accuracy:		92.28 %
Epoch 109 of 2000 took 0.035s
  training loss:		0.220214
  validation loss:		0.281338
  validation accuracy:		91.63 %
Epoch 110 of 2000 took 0.035s
  training loss:		0.223797
  validation loss:		0.266718
  validation accuracy:		92.17 %
Epoch 111 of 2000 took 0.035s
  training loss:		0.215458
  validation loss:		0.269459
  validation accuracy:		91.96 %
Epoch 112 of 2000 took 0.035s
  training loss:		0.218271
  validation loss:		0.286445
  validation accuracy:		91.09 %
Epoch 113 of 2000 took 0.035s
  training loss:		0.213744
  validation loss:		0.267245
  validation accuracy:		92.07 %
Epoch 114 of 2000 took 0.035s
  training loss:		0.216130
  validation loss:		0.280004
  validation accuracy:		91.74 %
Epoch 115 of 2000 took 0.035s
  training loss:		0.213243
  validation loss:		0.264348
  validation accuracy:		92.17 %
Epoch 116 of 2000 took 0.035s
  training loss:		0.208579
  validation loss:		0.275776
  validation accuracy:		91.85 %
Epoch 117 of 2000 took 0.035s
  training loss:		0.209569
  validation loss:		0.284191
  validation accuracy:		91.30 %
Epoch 118 of 2000 took 0.035s
  training loss:		0.210514
  validation loss:		0.276011
  validation accuracy:		91.52 %
Epoch 119 of 2000 took 0.035s
  training loss:		0.205248
  validation loss:		0.277121
  validation accuracy:		91.41 %
Epoch 120 of 2000 took 0.035s
  training loss:		0.211504
  validation loss:		0.270112
  validation accuracy:		91.85 %
Epoch 121 of 2000 took 0.035s
  training loss:		0.210120
  validation loss:		0.264977
  validation accuracy:		91.96 %
Epoch 122 of 2000 took 0.035s
  training loss:		0.208635
  validation loss:		0.267084
  validation accuracy:		91.96 %
Epoch 123 of 2000 took 0.035s
  training loss:		0.205824
  validation loss:		0.277140
  validation accuracy:		91.74 %
Epoch 124 of 2000 took 0.035s
  training loss:		0.204400
  validation loss:		0.273676
  validation accuracy:		91.85 %
Epoch 125 of 2000 took 0.035s
  training loss:		0.203934
  validation loss:		0.273488
  validation accuracy:		91.85 %
Epoch 126 of 2000 took 0.036s
  training loss:		0.200603
  validation loss:		0.261466
  validation accuracy:		92.39 %
Epoch 127 of 2000 took 0.035s
  training loss:		0.196017
  validation loss:		0.278578
  validation accuracy:		90.87 %
Epoch 128 of 2000 took 0.035s
  training loss:		0.198328
  validation loss:		0.272486
  validation accuracy:		91.63 %
Epoch 129 of 2000 took 0.035s
  training loss:		0.202806
  validation loss:		0.285268
  validation accuracy:		91.41 %
Epoch 130 of 2000 took 0.035s
  training loss:		0.196666
  validation loss:		0.270453
  validation accuracy:		92.28 %
Epoch 131 of 2000 took 0.035s
  training loss:		0.198027
  validation loss:		0.266633
  validation accuracy:		91.74 %
Epoch 132 of 2000 took 0.035s
  training loss:		0.192911
  validation loss:		0.270084
  validation accuracy:		91.41 %
Epoch 133 of 2000 took 0.035s
  training loss:		0.192456
  validation loss:		0.269294
  validation accuracy:		91.63 %
Epoch 134 of 2000 took 0.035s
  training loss:		0.195398
  validation loss:		0.262569
  validation accuracy:		92.07 %
Epoch 135 of 2000 took 0.035s
  training loss:		0.192256
  validation loss:		0.268663
  validation accuracy:		92.17 %
Epoch 136 of 2000 took 0.035s
  training loss:		0.192489
  validation loss:		0.256176
  validation accuracy:		92.28 %
Epoch 137 of 2000 took 0.035s
  training loss:		0.188528
  validation loss:		0.266908
  validation accuracy:		92.07 %
Epoch 138 of 2000 took 0.035s
  training loss:		0.184266
  validation loss:		0.272402
  validation accuracy:		91.52 %
Epoch 139 of 2000 took 0.035s
  training loss:		0.188881
  validation loss:		0.272546
  validation accuracy:		91.96 %
Epoch 140 of 2000 took 0.035s
  training loss:		0.190093
  validation loss:		0.266574
  validation accuracy:		92.28 %
Epoch 141 of 2000 took 0.035s
  training loss:		0.185635
  validation loss:		0.268605
  validation accuracy:		91.63 %
Epoch 142 of 2000 took 0.035s
  training loss:		0.189142
  validation loss:		0.264342
  validation accuracy:		92.07 %
Epoch 143 of 2000 took 0.035s
  training loss:		0.185708
  validation loss:		0.258107
  validation accuracy:		92.07 %
Epoch 144 of 2000 took 0.035s
  training loss:		0.184519
  validation loss:		0.262246
  validation accuracy:		92.07 %
Epoch 145 of 2000 took 0.035s
  training loss:		0.185574
  validation loss:		0.255102
  validation accuracy:		92.07 %
Epoch 146 of 2000 took 0.035s
  training loss:		0.179817
  validation loss:		0.252945
  validation accuracy:		92.50 %
Epoch 147 of 2000 took 0.035s
  training loss:		0.184452
  validation loss:		0.258911
  validation accuracy:		92.07 %
Epoch 148 of 2000 took 0.035s
  training loss:		0.185929
  validation loss:		0.257828
  validation accuracy:		92.07 %
Epoch 149 of 2000 took 0.035s
  training loss:		0.176553
  validation loss:		0.255344
  validation accuracy:		92.17 %
Epoch 150 of 2000 took 0.035s
  training loss:		0.182181
  validation loss:		0.257938
  validation accuracy:		92.07 %
Epoch 151 of 2000 took 0.035s
  training loss:		0.176857
  validation loss:		0.256812
  validation accuracy:		92.28 %
Epoch 152 of 2000 took 0.035s
  training loss:		0.177550
  validation loss:		0.251263
  validation accuracy:		92.39 %
Epoch 153 of 2000 took 0.035s
  training loss:		0.172551
  validation loss:		0.264425
  validation accuracy:		91.96 %
Epoch 154 of 2000 took 0.035s
  training loss:		0.176074
  validation loss:		0.261668
  validation accuracy:		91.96 %
Epoch 155 of 2000 took 0.035s
  training loss:		0.170675
  validation loss:		0.269276
  validation accuracy:		91.20 %
Epoch 156 of 2000 took 0.035s
  training loss:		0.174328
  validation loss:		0.259131
  validation accuracy:		92.07 %
Epoch 157 of 2000 took 0.035s
  training loss:		0.174940
  validation loss:		0.255372
  validation accuracy:		92.28 %
Epoch 158 of 2000 took 0.035s
  training loss:		0.173712
  validation loss:		0.262913
  validation accuracy:		92.07 %
Epoch 159 of 2000 took 0.035s
  training loss:		0.171810
  validation loss:		0.263277
  validation accuracy:		91.96 %
Epoch 160 of 2000 took 0.035s
  training loss:		0.171966
  validation loss:		0.264114
  validation accuracy:		91.85 %
Epoch 161 of 2000 took 0.035s
  training loss:		0.172641
  validation loss:		0.263939
  validation accuracy:		91.41 %
Epoch 162 of 2000 took 0.035s
  training loss:		0.166631
  validation loss:		0.251984
  validation accuracy:		92.28 %
Epoch 163 of 2000 took 0.035s
  training loss:		0.167344
  validation loss:		0.256605
  validation accuracy:		92.39 %
Epoch 164 of 2000 took 0.035s
  training loss:		0.169037
  validation loss:		0.256275
  validation accuracy:		92.28 %
Epoch 165 of 2000 took 0.035s
  training loss:		0.167750
  validation loss:		0.251717
  validation accuracy:		92.28 %
Epoch 166 of 2000 took 0.035s
  training loss:		0.167649
  validation loss:		0.268595
  validation accuracy:		91.52 %
Epoch 167 of 2000 took 0.035s
  training loss:		0.170009
  validation loss:		0.246271
  validation accuracy:		92.93 %
Epoch 168 of 2000 took 0.035s
  training loss:		0.166365
  validation loss:		0.259202
  validation accuracy:		92.07 %
Epoch 169 of 2000 took 0.035s
  training loss:		0.166400
  validation loss:		0.259497
  validation accuracy:		92.07 %
Epoch 170 of 2000 took 0.035s
  training loss:		0.162465
  validation loss:		0.244512
  validation accuracy:		92.61 %
Epoch 171 of 2000 took 0.035s
  training loss:		0.162427
  validation loss:		0.257516
  validation accuracy:		92.17 %
Epoch 172 of 2000 took 0.035s
  training loss:		0.162390
  validation loss:		0.259984
  validation accuracy:		91.96 %
Epoch 173 of 2000 took 0.035s
  training loss:		0.164758
  validation loss:		0.248335
  validation accuracy:		92.61 %
Epoch 174 of 2000 took 0.035s
  training loss:		0.160175
  validation loss:		0.250529
  validation accuracy:		92.61 %
Epoch 175 of 2000 took 0.035s
  training loss:		0.158234
  validation loss:		0.258049
  validation accuracy:		92.17 %
Epoch 176 of 2000 took 0.035s
  training loss:		0.155413
  validation loss:		0.254279
  validation accuracy:		92.39 %
Epoch 177 of 2000 took 0.035s
  training loss:		0.156979
  validation loss:		0.257537
  validation accuracy:		92.28 %
Epoch 178 of 2000 took 0.035s
  training loss:		0.154535
  validation loss:		0.254555
  validation accuracy:		92.17 %
Epoch 179 of 2000 took 0.035s
  training loss:		0.158428
  validation loss:		0.266556
  validation accuracy:		91.74 %
Epoch 180 of 2000 took 0.035s
  training loss:		0.159256
  validation loss:		0.243527
  validation accuracy:		92.83 %
Epoch 181 of 2000 took 0.035s
  training loss:		0.157398
  validation loss:		0.266163
  validation accuracy:		91.85 %
Epoch 182 of 2000 took 0.035s
  training loss:		0.156779
  validation loss:		0.254788
  validation accuracy:		92.50 %
Epoch 183 of 2000 took 0.035s
  training loss:		0.149659
  validation loss:		0.263708
  validation accuracy:		91.63 %
Epoch 184 of 2000 took 0.035s
  training loss:		0.154892
  validation loss:		0.246771
  validation accuracy:		92.50 %
Epoch 185 of 2000 took 0.035s
  training loss:		0.156339
  validation loss:		0.256782
  validation accuracy:		91.96 %
Epoch 186 of 2000 took 0.035s
  training loss:		0.151660
  validation loss:		0.256534
  validation accuracy:		92.50 %
Epoch 187 of 2000 took 0.035s
  training loss:		0.153109
  validation loss:		0.256784
  validation accuracy:		92.17 %
Epoch 188 of 2000 took 0.035s
  training loss:		0.156719
  validation loss:		0.253454
  validation accuracy:		92.39 %
Epoch 189 of 2000 took 0.035s
  training loss:		0.152897
  validation loss:		0.260513
  validation accuracy:		91.85 %
Epoch 190 of 2000 took 0.035s
  training loss:		0.151839
  validation loss:		0.255803
  validation accuracy:		92.50 %
Epoch 191 of 2000 took 0.035s
  training loss:		0.149690
  validation loss:		0.268450
  validation accuracy:		91.63 %
Epoch 192 of 2000 took 0.035s
  training loss:		0.149830
  validation loss:		0.252664
  validation accuracy:		92.28 %
Epoch 193 of 2000 took 0.035s
  training loss:		0.149762
  validation loss:		0.248253
  validation accuracy:		92.61 %
Epoch 194 of 2000 took 0.035s
  training loss:		0.147004
  validation loss:		0.252870
  validation accuracy:		92.28 %
Epoch 195 of 2000 took 0.035s
  training loss:		0.149571
  validation loss:		0.259530
  validation accuracy:		91.85 %
Epoch 196 of 2000 took 0.035s
  training loss:		0.148134
  validation loss:		0.255403
  validation accuracy:		92.50 %
Epoch 197 of 2000 took 0.035s
  training loss:		0.148091
  validation loss:		0.271263
  validation accuracy:		91.85 %
Epoch 198 of 2000 took 0.035s
  training loss:		0.147687
  validation loss:		0.255180
  validation accuracy:		92.61 %
Epoch 199 of 2000 took 0.035s
  training loss:		0.148446
  validation loss:		0.249598
  validation accuracy:		92.72 %
Epoch 200 of 2000 took 0.035s
  training loss:		0.143958
  validation loss:		0.254181
  validation accuracy:		92.39 %
Epoch 201 of 2000 took 0.035s
  training loss:		0.144186
  validation loss:		0.255714
  validation accuracy:		91.85 %
Epoch 202 of 2000 took 0.035s
  training loss:		0.143466
  validation loss:		0.251340
  validation accuracy:		92.28 %
Epoch 203 of 2000 took 0.035s
  training loss:		0.141363
  validation loss:		0.260334
  validation accuracy:		91.74 %
Epoch 204 of 2000 took 0.035s
  training loss:		0.138763
  validation loss:		0.261889
  validation accuracy:		91.85 %
Epoch 205 of 2000 took 0.035s
  training loss:		0.144303
  validation loss:		0.258898
  validation accuracy:		91.96 %
Epoch 206 of 2000 took 0.035s
  training loss:		0.143821
  validation loss:		0.251068
  validation accuracy:		92.17 %
Epoch 207 of 2000 took 0.035s
  training loss:		0.139608
  validation loss:		0.254538
  validation accuracy:		92.28 %
Epoch 208 of 2000 took 0.035s
  training loss:		0.143423
  validation loss:		0.267823
  validation accuracy:		91.74 %
Epoch 209 of 2000 took 0.035s
  training loss:		0.140496
  validation loss:		0.250315
  validation accuracy:		92.72 %
Epoch 210 of 2000 took 0.035s
  training loss:		0.139445
  validation loss:		0.251509
  validation accuracy:		92.39 %
Epoch 211 of 2000 took 0.035s
  training loss:		0.136693
  validation loss:		0.253997
  validation accuracy:		92.50 %
Epoch 212 of 2000 took 0.035s
  training loss:		0.137658
  validation loss:		0.263084
  validation accuracy:		91.85 %
Epoch 213 of 2000 took 0.035s
  training loss:		0.138307
  validation loss:		0.248685
  validation accuracy:		92.50 %
Epoch 214 of 2000 took 0.035s
  training loss:		0.138769
  validation loss:		0.257612
  validation accuracy:		92.17 %
Epoch 215 of 2000 took 0.035s
  training loss:		0.137980
  validation loss:		0.248291
  validation accuracy:		92.61 %
Epoch 216 of 2000 took 0.035s
  training loss:		0.136019
  validation loss:		0.255862
  validation accuracy:		92.61 %
Epoch 217 of 2000 took 0.036s
  training loss:		0.136649
  validation loss:		0.254125
  validation accuracy:		92.17 %
Epoch 218 of 2000 took 0.035s
  training loss:		0.134456
  validation loss:		0.266669
  validation accuracy:		91.74 %
Epoch 219 of 2000 took 0.035s
  training loss:		0.138585
  validation loss:		0.246942
  validation accuracy:		92.83 %
Epoch 220 of 2000 took 0.035s
  training loss:		0.135034
  validation loss:		0.258264
  validation accuracy:		92.50 %
Epoch 221 of 2000 took 0.035s
  training loss:		0.130783
  validation loss:		0.247228
  validation accuracy:		92.61 %
Epoch 222 of 2000 took 0.035s
  training loss:		0.132443
  validation loss:		0.255732
  validation accuracy:		92.39 %
Epoch 223 of 2000 took 0.035s
  training loss:		0.132473
  validation loss:		0.249858
  validation accuracy:		92.61 %
Epoch 224 of 2000 took 0.035s
  training loss:		0.128714
  validation loss:		0.245918
  validation accuracy:		92.72 %
Epoch 225 of 2000 took 0.035s
  training loss:		0.130512
  validation loss:		0.249309
  validation accuracy:		92.83 %
Epoch 226 of 2000 took 0.035s
  training loss:		0.134053
  validation loss:		0.256770
  validation accuracy:		93.04 %
Epoch 227 of 2000 took 0.035s
  training loss:		0.132719
  validation loss:		0.252604
  validation accuracy:		92.17 %
Epoch 228 of 2000 took 0.035s
  training loss:		0.130120
  validation loss:		0.266541
  validation accuracy:		92.07 %
Epoch 229 of 2000 took 0.035s
  training loss:		0.130413
  validation loss:		0.257158
  validation accuracy:		91.85 %
Epoch 230 of 2000 took 0.035s
  training loss:		0.126737
  validation loss:		0.251310
  validation accuracy:		92.93 %
Epoch 231 of 2000 took 0.035s
  training loss:		0.125416
  validation loss:		0.253866
  validation accuracy:		92.50 %
Epoch 232 of 2000 took 0.035s
  training loss:		0.131858
  validation loss:		0.252032
  validation accuracy:		92.28 %
Epoch 233 of 2000 took 0.035s
  training loss:		0.129194
  validation loss:		0.284254
  validation accuracy:		91.20 %
Epoch 234 of 2000 took 0.035s
  training loss:		0.131531
  validation loss:		0.256866
  validation accuracy:		92.93 %
Epoch 235 of 2000 took 0.035s
  training loss:		0.125720
  validation loss:		0.255111
  validation accuracy:		92.39 %
Epoch 236 of 2000 took 0.035s
  training loss:		0.131639
  validation loss:		0.265908
  validation accuracy:		92.07 %
Epoch 237 of 2000 took 0.035s
  training loss:		0.127671
  validation loss:		0.260544
  validation accuracy:		92.17 %
Epoch 238 of 2000 took 0.035s
  training loss:		0.127988
  validation loss:		0.257709
  validation accuracy:		92.28 %
Epoch 239 of 2000 took 0.035s
  training loss:		0.124711
  validation loss:		0.252940
  validation accuracy:		93.48 %
Epoch 240 of 2000 took 0.035s
  training loss:		0.126018
  validation loss:		0.251531
  validation accuracy:		92.72 %
Epoch 241 of 2000 took 0.035s
  training loss:		0.122284
  validation loss:		0.246387
  validation accuracy:		93.26 %
Epoch 242 of 2000 took 0.035s
  training loss:		0.121985
  validation loss:		0.254742
  validation accuracy:		92.61 %
Epoch 243 of 2000 took 0.035s
  training loss:		0.125962
  validation loss:		0.258797
  validation accuracy:		92.07 %
Epoch 244 of 2000 took 0.035s
  training loss:		0.121758
  validation loss:		0.252517
  validation accuracy:		92.28 %
Epoch 245 of 2000 took 0.035s
  training loss:		0.123089
  validation loss:		0.271633
  validation accuracy:		91.30 %
Epoch 246 of 2000 took 0.035s
  training loss:		0.125861
  validation loss:		0.250741
  validation accuracy:		92.61 %
Epoch 247 of 2000 took 0.035s
  training loss:		0.122167
  validation loss:		0.267932
  validation accuracy:		91.74 %
Epoch 248 of 2000 took 0.035s
  training loss:		0.123483
  validation loss:		0.250584
  validation accuracy:		93.04 %
Epoch 249 of 2000 took 0.035s
  training loss:		0.125405
  validation loss:		0.261961
  validation accuracy:		92.72 %
Epoch 250 of 2000 took 0.035s
  training loss:		0.124757
  validation loss:		0.274841
  validation accuracy:		91.52 %
Epoch 251 of 2000 took 0.035s
  training loss:		0.123052
  validation loss:		0.245252
  validation accuracy:		92.93 %
Epoch 252 of 2000 took 0.035s
  training loss:		0.120706
  validation loss:		0.258114
  validation accuracy:		92.72 %
Epoch 253 of 2000 took 0.035s
  training loss:		0.116835
  validation loss:		0.263821
  validation accuracy:		91.85 %
Epoch 254 of 2000 took 0.035s
  training loss:		0.116922
  validation loss:		0.256702
  validation accuracy:		92.61 %
Epoch 255 of 2000 took 0.035s
  training loss:		0.118871
  validation loss:		0.254476
  validation accuracy:		92.83 %
Epoch 256 of 2000 took 0.035s
  training loss:		0.117000
  validation loss:		0.260826
  validation accuracy:		91.96 %
Epoch 257 of 2000 took 0.035s
  training loss:		0.115256
  validation loss:		0.255134
  validation accuracy:		92.93 %
Epoch 258 of 2000 took 0.035s
  training loss:		0.116672
  validation loss:		0.262908
  validation accuracy:		92.07 %
Epoch 259 of 2000 took 0.035s
  training loss:		0.119125
  validation loss:		0.267624
  validation accuracy:		91.85 %
Epoch 260 of 2000 took 0.035s
  training loss:		0.117594
  validation loss:		0.261432
  validation accuracy:		92.17 %
Epoch 261 of 2000 took 0.035s
  training loss:		0.119799
  validation loss:		0.254111
  validation accuracy:		92.28 %
Epoch 262 of 2000 took 0.035s
  training loss:		0.119731
  validation loss:		0.265333
  validation accuracy:		92.07 %
Epoch 263 of 2000 took 0.035s
  training loss:		0.113972
  validation loss:		0.253187
  validation accuracy:		92.39 %
Epoch 264 of 2000 took 0.035s
  training loss:		0.112801
  validation loss:		0.260740
  validation accuracy:		91.96 %
Epoch 265 of 2000 took 0.035s
  training loss:		0.113458
  validation loss:		0.252881
  validation accuracy:		92.61 %
Epoch 266 of 2000 took 0.035s
  training loss:		0.115481
  validation loss:		0.269027
  validation accuracy:		91.52 %
Epoch 267 of 2000 took 0.035s
  training loss:		0.117024
  validation loss:		0.250143
  validation accuracy:		93.04 %
Epoch 268 of 2000 took 0.035s
  training loss:		0.116433
  validation loss:		0.259669
  validation accuracy:		92.50 %
Epoch 269 of 2000 took 0.035s
  training loss:		0.113103
  validation loss:		0.255420
  validation accuracy:		92.28 %
Epoch 270 of 2000 took 0.035s
  training loss:		0.116042
  validation loss:		0.255561
  validation accuracy:		93.15 %
Epoch 271 of 2000 took 0.035s
  training loss:		0.112048
  validation loss:		0.256539
  validation accuracy:		92.61 %
Epoch 272 of 2000 took 0.035s
  training loss:		0.112553
  validation loss:		0.251499
  validation accuracy:		93.37 %
Epoch 273 of 2000 took 0.035s
  training loss:		0.112780
  validation loss:		0.257728
  validation accuracy:		92.93 %
Epoch 274 of 2000 took 0.035s
  training loss:		0.112312
  validation loss:		0.264136
  validation accuracy:		92.07 %
Epoch 275 of 2000 took 0.035s
  training loss:		0.113474
  validation loss:		0.264628
  validation accuracy:		91.85 %
Epoch 276 of 2000 took 0.035s
  training loss:		0.113252
  validation loss:		0.264592
  validation accuracy:		92.17 %
Epoch 277 of 2000 took 0.035s
  training loss:		0.110461
  validation loss:		0.259830
  validation accuracy:		92.39 %
Epoch 278 of 2000 took 0.035s
  training loss:		0.108889
  validation loss:		0.254120
  validation accuracy:		93.04 %
Epoch 279 of 2000 took 0.035s
  training loss:		0.110965
  validation loss:		0.260236
  validation accuracy:		92.28 %
Epoch 280 of 2000 took 0.035s
  training loss:		0.110299
  validation loss:		0.256144
  validation accuracy:		92.93 %
Epoch 281 of 2000 took 0.035s
  training loss:		0.110546
  validation loss:		0.263696
  validation accuracy:		92.17 %
Epoch 282 of 2000 took 0.035s
  training loss:		0.109297
  validation loss:		0.258671
  validation accuracy:		92.50 %
Epoch 283 of 2000 took 0.035s
  training loss:		0.108273
  validation loss:		0.261677
  validation accuracy:		92.39 %
Epoch 284 of 2000 took 0.035s
  training loss:		0.109700
  validation loss:		0.266971
  validation accuracy:		92.07 %
Epoch 285 of 2000 took 0.036s
  training loss:		0.108931
  validation loss:		0.261968
  validation accuracy:		92.83 %
Epoch 286 of 2000 took 0.035s
  training loss:		0.112017
  validation loss:		0.260015
  validation accuracy:		92.83 %
Epoch 287 of 2000 took 0.035s
  training loss:		0.110130
  validation loss:		0.269325
  validation accuracy:		91.96 %
Epoch 288 of 2000 took 0.035s
  training loss:		0.108002
  validation loss:		0.256251
  validation accuracy:		92.83 %
Epoch 289 of 2000 took 0.035s
  training loss:		0.106818
  validation loss:		0.259454
  validation accuracy:		92.72 %
Epoch 290 of 2000 took 0.035s
  training loss:		0.105975
  validation loss:		0.276346
  validation accuracy:		91.85 %
Epoch 291 of 2000 took 0.035s
  training loss:		0.103541
  validation loss:		0.257220
  validation accuracy:		92.93 %
Epoch 292 of 2000 took 0.035s
  training loss:		0.105505
  validation loss:		0.251782
  validation accuracy:		93.15 %
Epoch 293 of 2000 took 0.035s
  training loss:		0.102667
  validation loss:		0.263496
  validation accuracy:		92.72 %
Epoch 294 of 2000 took 0.035s
  training loss:		0.105565
  validation loss:		0.257585
  validation accuracy:		93.04 %
Epoch 295 of 2000 took 0.035s
  training loss:		0.104576
  validation loss:		0.255872
  validation accuracy:		92.83 %
Epoch 296 of 2000 took 0.035s
  training loss:		0.107503
  validation loss:		0.255614
  validation accuracy:		92.39 %
Epoch 297 of 2000 took 0.035s
  training loss:		0.106545
  validation loss:		0.257208
  validation accuracy:		93.15 %
Epoch 298 of 2000 took 0.035s
  training loss:		0.105764
  validation loss:		0.270052
  validation accuracy:		92.07 %
Epoch 299 of 2000 took 0.035s
  training loss:		0.097542
  validation loss:		0.259229
  validation accuracy:		92.50 %
Epoch 300 of 2000 took 0.035s
  training loss:		0.105225
  validation loss:		0.265538
  validation accuracy:		92.72 %
Epoch 301 of 2000 took 0.035s
  training loss:		0.103850
  validation loss:		0.262964
  validation accuracy:		92.50 %
Epoch 302 of 2000 took 0.035s
  training loss:		0.102335
  validation loss:		0.265157
  validation accuracy:		92.28 %
Epoch 303 of 2000 took 0.035s
  training loss:		0.102686
  validation loss:		0.263640
  validation accuracy:		92.83 %
Epoch 304 of 2000 took 0.035s
  training loss:		0.103384
  validation loss:		0.259615
  validation accuracy:		92.72 %
Epoch 305 of 2000 took 0.035s
  training loss:		0.102832
  validation loss:		0.277912
  validation accuracy:		91.96 %
Epoch 306 of 2000 took 0.035s
  training loss:		0.102028
  validation loss:		0.272054
  validation accuracy:		92.17 %
Epoch 307 of 2000 took 0.035s
  training loss:		0.101300
  validation loss:		0.263209
  validation accuracy:		92.50 %
Epoch 308 of 2000 took 0.035s
  training loss:		0.100364
  validation loss:		0.267876
  validation accuracy:		92.39 %
Epoch 309 of 2000 took 0.035s
  training loss:		0.102821
  validation loss:		0.263324
  validation accuracy:		93.15 %
Epoch 310 of 2000 took 0.035s
  training loss:		0.100743
  validation loss:		0.256149
  validation accuracy:		93.04 %
Epoch 311 of 2000 took 0.035s
  training loss:		0.102641
  validation loss:		0.256693
  validation accuracy:		93.15 %
Epoch 312 of 2000 took 0.035s
  training loss:		0.100067
  validation loss:		0.268880
  validation accuracy:		92.61 %
Epoch 313 of 2000 took 0.035s
  training loss:		0.098239
  validation loss:		0.257934
  validation accuracy:		92.83 %
Epoch 314 of 2000 took 0.035s
  training loss:		0.097268
  validation loss:		0.266867
  validation accuracy:		92.39 %
Epoch 315 of 2000 took 0.035s
  training loss:		0.099049
  validation loss:		0.263926
  validation accuracy:		92.39 %
Epoch 316 of 2000 took 0.035s
  training loss:		0.100365
  validation loss:		0.267484
  validation accuracy:		92.28 %
Epoch 317 of 2000 took 0.035s
  training loss:		0.098896
  validation loss:		0.279587
  validation accuracy:		91.96 %
Epoch 318 of 2000 took 0.035s
  training loss:		0.098534
  validation loss:		0.265828
  validation accuracy:		92.61 %
Epoch 319 of 2000 took 0.035s
  training loss:		0.097769
  validation loss:		0.263916
  validation accuracy:		92.93 %
Epoch 320 of 2000 took 0.035s
  training loss:		0.097319
  validation loss:		0.265546
  validation accuracy:		92.61 %
Epoch 321 of 2000 took 0.035s
  training loss:		0.098075
  validation loss:		0.266896
  validation accuracy:		92.39 %
Epoch 322 of 2000 took 0.035s
  training loss:		0.097214
  validation loss:		0.264259
  validation accuracy:		92.39 %
Epoch 323 of 2000 took 0.035s
  training loss:		0.096729
  validation loss:		0.268468
  validation accuracy:		92.72 %
Epoch 324 of 2000 took 0.035s
  training loss:		0.094845
  validation loss:		0.270078
  validation accuracy:		92.39 %
Epoch 325 of 2000 took 0.035s
  training loss:		0.095839
  validation loss:		0.264568
  validation accuracy:		92.61 %
Epoch 326 of 2000 took 0.035s
  training loss:		0.096254
  validation loss:		0.274409
  validation accuracy:		92.39 %
Epoch 327 of 2000 took 0.035s
  training loss:		0.096908
  validation loss:		0.265585
  validation accuracy:		92.83 %
Epoch 328 of 2000 took 0.035s
  training loss:		0.098452
  validation loss:		0.263395
  validation accuracy:		92.72 %
Epoch 329 of 2000 took 0.035s
  training loss:		0.098839
  validation loss:		0.275998
  validation accuracy:		92.17 %
Epoch 330 of 2000 took 0.035s
  training loss:		0.096720
  validation loss:		0.277051
  validation accuracy:		92.17 %
Epoch 331 of 2000 took 0.035s
  training loss:		0.095437
  validation loss:		0.270568
  validation accuracy:		92.28 %
Epoch 332 of 2000 took 0.035s
  training loss:		0.093918
  validation loss:		0.274479
  validation accuracy:		92.17 %
Epoch 333 of 2000 took 0.035s
  training loss:		0.094670
  validation loss:		0.266261
  validation accuracy:		92.72 %
Epoch 334 of 2000 took 0.035s
  training loss:		0.091884
  validation loss:		0.262136
  validation accuracy:		93.26 %
Epoch 335 of 2000 took 0.035s
  training loss:		0.095225
  validation loss:		0.269411
  validation accuracy:		92.83 %
Epoch 336 of 2000 took 0.035s
  training loss:		0.092231
  validation loss:		0.265867
  validation accuracy:		92.50 %
Epoch 337 of 2000 took 0.035s
  training loss:		0.094064
  validation loss:		0.273844
  validation accuracy:		92.61 %
Epoch 338 of 2000 took 0.035s
  training loss:		0.092550
  validation loss:		0.280175
  validation accuracy:		91.96 %
Epoch 339 of 2000 took 0.035s
  training loss:		0.092716
  validation loss:		0.273670
  validation accuracy:		92.39 %
Epoch 340 of 2000 took 0.035s
  training loss:		0.091942
  validation loss:		0.278835
  validation accuracy:		92.17 %
Epoch 341 of 2000 took 0.035s
  training loss:		0.090830
  validation loss:		0.265854
  validation accuracy:		93.04 %
Epoch 342 of 2000 took 0.035s
  training loss:		0.094470
  validation loss:		0.260665
  validation accuracy:		92.83 %
Epoch 343 of 2000 took 0.035s
  training loss:		0.093492
  validation loss:		0.276312
  validation accuracy:		92.28 %
Epoch 344 of 2000 took 0.035s
  training loss:		0.090328
  validation loss:		0.266655
  validation accuracy:		92.72 %
Epoch 345 of 2000 took 0.035s
  training loss:		0.089855
  validation loss:		0.281867
  validation accuracy:		91.85 %
Epoch 346 of 2000 took 0.035s
  training loss:		0.089317
  validation loss:		0.273330
  validation accuracy:		92.28 %
Epoch 347 of 2000 took 0.035s
  training loss:		0.087810
  validation loss:		0.278397
  validation accuracy:		92.28 %
Epoch 348 of 2000 took 0.035s
  training loss:		0.089314
  validation loss:		0.266905
  validation accuracy:		92.83 %
Epoch 349 of 2000 took 0.035s
  training loss:		0.085614
  validation loss:		0.276420
  validation accuracy:		92.83 %
Epoch 350 of 2000 took 0.035s
  training loss:		0.094211
  validation loss:		0.277943
  validation accuracy:		92.28 %
Epoch 351 of 2000 took 0.035s
  training loss:		0.088935
  validation loss:		0.280246
  validation accuracy:		92.07 %
Epoch 352 of 2000 took 0.035s
  training loss:		0.090007
  validation loss:		0.268581
  validation accuracy:		92.72 %
Epoch 353 of 2000 took 0.035s
  training loss:		0.085930
  validation loss:		0.267582
  validation accuracy:		92.72 %
Epoch 354 of 2000 took 0.035s
  training loss:		0.090057
  validation loss:		0.289682
  validation accuracy:		91.96 %
Epoch 355 of 2000 took 0.035s
  training loss:		0.089971
  validation loss:		0.268869
  validation accuracy:		92.93 %
Epoch 356 of 2000 took 0.035s
  training loss:		0.086957
  validation loss:		0.270098
  validation accuracy:		92.72 %
Epoch 357 of 2000 took 0.035s
  training loss:		0.087316
  validation loss:		0.276255
  validation accuracy:		92.50 %
Epoch 358 of 2000 took 0.035s
  training loss:		0.088817
  validation loss:		0.271889
  validation accuracy:		92.61 %
Epoch 359 of 2000 took 0.035s
  training loss:		0.088129
  validation loss:		0.278838
  validation accuracy:		92.83 %
Epoch 360 of 2000 took 0.035s
  training loss:		0.087988
  validation loss:		0.266597
  validation accuracy:		93.26 %
Epoch 361 of 2000 took 0.035s
  training loss:		0.085799
  validation loss:		0.272737
  validation accuracy:		92.39 %
Epoch 362 of 2000 took 0.035s
  training loss:		0.089027
  validation loss:		0.277689
  validation accuracy:		92.50 %
Epoch 363 of 2000 took 0.035s
  training loss:		0.086406
  validation loss:		0.281918
  validation accuracy:		91.74 %
Epoch 364 of 2000 took 0.035s
  training loss:		0.087493
  validation loss:		0.296185
  validation accuracy:		91.63 %
Epoch 365 of 2000 took 0.035s
  training loss:		0.086045
  validation loss:		0.280837
  validation accuracy:		92.07 %
Epoch 366 of 2000 took 0.035s
  training loss:		0.082846
  validation loss:		0.288216
  validation accuracy:		91.96 %
Epoch 367 of 2000 took 0.035s
  training loss:		0.087724
  validation loss:		0.275756
  validation accuracy:		92.39 %
Epoch 368 of 2000 took 0.035s
  training loss:		0.085686
  validation loss:		0.272397
  validation accuracy:		92.61 %
Epoch 369 of 2000 took 0.035s
  training loss:		0.082748
  validation loss:		0.277369
  validation accuracy:		92.93 %
Epoch 370 of 2000 took 0.035s
  training loss:		0.083518
  validation loss:		0.274822
  validation accuracy:		92.39 %
Epoch 371 of 2000 took 0.035s
  training loss:		0.084477
  validation loss:		0.280973
  validation accuracy:		92.07 %
Epoch 372 of 2000 took 0.035s
  training loss:		0.084945
  validation loss:		0.284809
  validation accuracy:		91.96 %
Epoch 373 of 2000 took 0.035s
  training loss:		0.083146
  validation loss:		0.286749
  validation accuracy:		92.17 %
Epoch 374 of 2000 took 0.035s
  training loss:		0.084375
  validation loss:		0.275577
  validation accuracy:		92.50 %
Epoch 375 of 2000 took 0.035s
  training loss:		0.083497
  validation loss:		0.281985
  validation accuracy:		92.28 %
Epoch 376 of 2000 took 0.035s
  training loss:		0.085134
  validation loss:		0.278545
  validation accuracy:		92.07 %
Epoch 377 of 2000 took 0.036s
  training loss:		0.083307
  validation loss:		0.281021
  validation accuracy:		92.61 %
Epoch 378 of 2000 took 0.035s
  training loss:		0.083434
  validation loss:		0.276016
  validation accuracy:		92.17 %
Epoch 379 of 2000 took 0.035s
  training loss:		0.081086
  validation loss:		0.274519
  validation accuracy:		92.39 %
Epoch 380 of 2000 took 0.035s
  training loss:		0.080700
  validation loss:		0.273093
  validation accuracy:		92.83 %
Epoch 381 of 2000 took 0.035s
  training loss:		0.080777
  validation loss:		0.286383
  validation accuracy:		92.28 %
Epoch 382 of 2000 took 0.035s
  training loss:		0.082131
  validation loss:		0.278322
  validation accuracy:		92.50 %
Epoch 383 of 2000 took 0.035s
  training loss:		0.083146
  validation loss:		0.280403
  validation accuracy:		92.61 %
Epoch 384 of 2000 took 0.035s
  training loss:		0.082071
  validation loss:		0.285869
  validation accuracy:		92.39 %
Epoch 385 of 2000 took 0.035s
  training loss:		0.082321
  validation loss:		0.282002
  validation accuracy:		92.50 %
Epoch 386 of 2000 took 0.035s
  training loss:		0.080637
  validation loss:		0.281820
  validation accuracy:		92.39 %
Epoch 387 of 2000 took 0.035s
  training loss:		0.079734
  validation loss:		0.279361
  validation accuracy:		92.50 %
Epoch 388 of 2000 took 0.035s
  training loss:		0.080270
  validation loss:		0.296280
  validation accuracy:		92.17 %
Epoch 389 of 2000 took 0.035s
  training loss:		0.077455
  validation loss:		0.277495
  validation accuracy:		92.39 %
Epoch 390 of 2000 took 0.035s
  training loss:		0.080438
  validation loss:		0.280836
  validation accuracy:		92.61 %
Epoch 391 of 2000 took 0.035s
  training loss:		0.082139
  validation loss:		0.269593
  validation accuracy:		93.37 %
Epoch 392 of 2000 took 0.035s
  training loss:		0.081233
  validation loss:		0.293072
  validation accuracy:		92.17 %
Epoch 393 of 2000 took 0.035s
  training loss:		0.082445
  validation loss:		0.277375
  validation accuracy:		93.04 %
Epoch 394 of 2000 took 0.035s
  training loss:		0.076588
  validation loss:		0.273563
  validation accuracy:		92.93 %
Epoch 395 of 2000 took 0.035s
  training loss:		0.079760
  validation loss:		0.287821
  validation accuracy:		92.17 %
Epoch 396 of 2000 took 0.035s
  training loss:		0.078370
  validation loss:		0.280401
  validation accuracy:		92.17 %
Epoch 397 of 2000 took 0.035s
  training loss:		0.077977
  validation loss:		0.292742
  validation accuracy:		92.28 %
Epoch 398 of 2000 took 0.035s
  training loss:		0.077237
  validation loss:		0.292628
  validation accuracy:		92.17 %
Epoch 399 of 2000 took 0.035s
  training loss:		0.079253
  validation loss:		0.285940
  validation accuracy:		92.17 %
Epoch 400 of 2000 took 0.035s
  training loss:		0.079901
  validation loss:		0.282206
  validation accuracy:		92.50 %
Epoch 401 of 2000 took 0.035s
  training loss:		0.076940
  validation loss:		0.284989
  validation accuracy:		92.17 %
Epoch 402 of 2000 took 0.035s
  training loss:		0.077368
  validation loss:		0.290125
  validation accuracy:		92.28 %
Epoch 403 of 2000 took 0.035s
  training loss:		0.078331
  validation loss:		0.288439
  validation accuracy:		92.28 %
Epoch 404 of 2000 took 0.035s
  training loss:		0.075472
  validation loss:		0.281934
  validation accuracy:		92.83 %
Epoch 405 of 2000 took 0.035s
  training loss:		0.074073
  validation loss:		0.292602
  validation accuracy:		91.96 %
Epoch 406 of 2000 took 0.035s
  training loss:		0.076591
  validation loss:		0.279496
  validation accuracy:		92.39 %
Epoch 407 of 2000 took 0.035s
  training loss:		0.073839
  validation loss:		0.286875
  validation accuracy:		92.50 %
Epoch 408 of 2000 took 0.035s
  training loss:		0.075923
  validation loss:		0.285020
  validation accuracy:		91.96 %
Epoch 409 of 2000 took 0.035s
  training loss:		0.076417
  validation loss:		0.283050
  validation accuracy:		92.61 %
Epoch 410 of 2000 took 0.036s
  training loss:		0.077735
  validation loss:		0.290141
  validation accuracy:		91.96 %
Epoch 411 of 2000 took 0.035s
  training loss:		0.076659
  validation loss:		0.293974
  validation accuracy:		92.17 %
Epoch 412 of 2000 took 0.035s
  training loss:		0.072508
  validation loss:		0.276896
  validation accuracy:		93.26 %
Epoch 413 of 2000 took 0.035s
  training loss:		0.075957
  validation loss:		0.286177
  validation accuracy:		92.17 %
Epoch 414 of 2000 took 0.035s
  training loss:		0.074869
  validation loss:		0.286657
  validation accuracy:		92.61 %
Epoch 415 of 2000 took 0.035s
  training loss:		0.075284
  validation loss:		0.287385
  validation accuracy:		92.28 %
Epoch 416 of 2000 took 0.035s
  training loss:		0.076853
  validation loss:		0.295481
  validation accuracy:		92.17 %
Epoch 417 of 2000 took 0.035s
  training loss:		0.074940
  validation loss:		0.292923
  validation accuracy:		92.07 %
Epoch 418 of 2000 took 0.035s
  training loss:		0.075374
  validation loss:		0.296356
  validation accuracy:		92.07 %
Epoch 419 of 2000 took 0.035s
  training loss:		0.074574
  validation loss:		0.300541
  validation accuracy:		91.74 %
Epoch 420 of 2000 took 0.035s
  training loss:		0.074244
  validation loss:		0.289547
  validation accuracy:		91.85 %
Epoch 421 of 2000 took 0.035s
  training loss:		0.072342
  validation loss:		0.292136
  validation accuracy:		92.50 %
Epoch 422 of 2000 took 0.035s
  training loss:		0.074602
  validation loss:		0.285878
  validation accuracy:		92.39 %
Epoch 423 of 2000 took 0.035s
  training loss:		0.072538
  validation loss:		0.285589
  validation accuracy:		92.93 %
Epoch 424 of 2000 took 0.035s
  training loss:		0.071104
  validation loss:		0.286037
  validation accuracy:		92.28 %
Epoch 425 of 2000 took 0.035s
  training loss:		0.074563
  validation loss:		0.290934
  validation accuracy:		92.72 %
Epoch 426 of 2000 took 0.035s
  training loss:		0.072287
  validation loss:		0.279175
  validation accuracy:		93.37 %
Epoch 427 of 2000 took 0.035s
  training loss:		0.074112
  validation loss:		0.300929
  validation accuracy:		91.96 %
Epoch 428 of 2000 took 0.035s
  training loss:		0.074605
  validation loss:		0.290631
  validation accuracy:		92.28 %
Epoch 429 of 2000 took 0.035s
  training loss:		0.072037
  validation loss:		0.295414
  validation accuracy:		92.61 %
Epoch 430 of 2000 took 0.035s
  training loss:		0.071550
  validation loss:		0.289049
  validation accuracy:		92.50 %
Epoch 431 of 2000 took 0.035s
  training loss:		0.072606
  validation loss:		0.290340
  validation accuracy:		92.39 %
Epoch 432 of 2000 took 0.035s
  training loss:		0.072073
  validation loss:		0.292121
  validation accuracy:		92.83 %
Epoch 433 of 2000 took 0.035s
  training loss:		0.072171
  validation loss:		0.304333
  validation accuracy:		91.96 %
Epoch 434 of 2000 took 0.035s
  training loss:		0.070295
  validation loss:		0.289512
  validation accuracy:		92.39 %
Epoch 435 of 2000 took 0.035s
  training loss:		0.071193
  validation loss:		0.293673
  validation accuracy:		92.28 %
Epoch 436 of 2000 took 0.035s
  training loss:		0.068234
  validation loss:		0.300150
  validation accuracy:		92.07 %
Epoch 437 of 2000 took 0.035s
  training loss:		0.070752
  validation loss:		0.295222
  validation accuracy:		92.50 %
Epoch 438 of 2000 took 0.035s
  training loss:		0.072553
  validation loss:		0.293084
  validation accuracy:		92.72 %
Epoch 439 of 2000 took 0.035s
  training loss:		0.070271
  validation loss:		0.293435
  validation accuracy:		92.28 %
Epoch 440 of 2000 took 0.035s
  training loss:		0.072312
  validation loss:		0.291854
  validation accuracy:		93.26 %
Epoch 441 of 2000 took 0.035s
  training loss:		0.069185
  validation loss:		0.282924
  validation accuracy:		92.93 %
Epoch 442 of 2000 took 0.035s
  training loss:		0.071163
  validation loss:		0.305431
  validation accuracy:		91.96 %
Epoch 443 of 2000 took 0.035s
  training loss:		0.071792
  validation loss:		0.285622
  validation accuracy:		92.72 %
Epoch 444 of 2000 took 0.035s
  training loss:		0.072128
  validation loss:		0.295339
  validation accuracy:		92.17 %
Epoch 445 of 2000 took 0.035s
  training loss:		0.067990
  validation loss:		0.300423
  validation accuracy:		91.96 %
Epoch 446 of 2000 took 0.035s
  training loss:		0.071462
  validation loss:		0.297424
  validation accuracy:		92.39 %
Epoch 447 of 2000 took 0.035s
  training loss:		0.070654
  validation loss:		0.306949
  validation accuracy:		92.07 %
Epoch 448 of 2000 took 0.035s
  training loss:		0.068058
  validation loss:		0.302548
  validation accuracy:		91.96 %
Epoch 449 of 2000 took 0.035s
  training loss:		0.069643
  validation loss:		0.308669
  validation accuracy:		92.28 %
Epoch 450 of 2000 took 0.035s
  training loss:		0.066598
  validation loss:		0.309892
  validation accuracy:		92.28 %
Epoch 451 of 2000 took 0.035s
  training loss:		0.067972
  validation loss:		0.292056
  validation accuracy:		92.61 %
Epoch 452 of 2000 took 0.035s
  training loss:		0.069384
  validation loss:		0.306598
  validation accuracy:		91.96 %
Epoch 453 of 2000 took 0.035s
  training loss:		0.068622
  validation loss:		0.302923
  validation accuracy:		92.50 %
Epoch 454 of 2000 took 0.035s
  training loss:		0.068024
  validation loss:		0.295180
  validation accuracy:		92.28 %
Epoch 455 of 2000 took 0.035s
  training loss:		0.068130
  validation loss:		0.301751
  validation accuracy:		92.28 %
Epoch 456 of 2000 took 0.035s
  training loss:		0.068551
  validation loss:		0.299937
  validation accuracy:		92.28 %
Epoch 457 of 2000 took 0.035s
  training loss:		0.065148
  validation loss:		0.317341
  validation accuracy:		92.17 %
Epoch 458 of 2000 took 0.035s
  training loss:		0.068123
  validation loss:		0.294063
  validation accuracy:		92.17 %
Epoch 459 of 2000 took 0.035s
  training loss:		0.066187
  validation loss:		0.299169
  validation accuracy:		92.17 %
Epoch 460 of 2000 took 0.035s
  training loss:		0.066453
  validation loss:		0.303102
  validation accuracy:		92.39 %
Epoch 461 of 2000 took 0.035s
  training loss:		0.066560
  validation loss:		0.304361
  validation accuracy:		92.07 %
Epoch 462 of 2000 took 0.035s
  training loss:		0.066918
  validation loss:		0.314342
  validation accuracy:		91.85 %
Epoch 463 of 2000 took 0.035s
  training loss:		0.064675
  validation loss:		0.287170
  validation accuracy:		93.26 %
Epoch 464 of 2000 took 0.035s
  training loss:		0.065984
  validation loss:		0.306676
  validation accuracy:		92.28 %
Epoch 465 of 2000 took 0.035s
  training loss:		0.066189
  validation loss:		0.315847
  validation accuracy:		92.07 %
Epoch 466 of 2000 took 0.035s
  training loss:		0.063903
  validation loss:		0.291207
  validation accuracy:		92.83 %
Epoch 467 of 2000 took 0.035s
  training loss:		0.062997
  validation loss:		0.301831
  validation accuracy:		92.72 %
Epoch 468 of 2000 took 0.035s
  training loss:		0.064908
  validation loss:		0.300228
  validation accuracy:		92.50 %
Epoch 469 of 2000 took 0.035s
  training loss:		0.066614
  validation loss:		0.294042
  validation accuracy:		93.04 %
Epoch 470 of 2000 took 0.035s
  training loss:		0.064114
  validation loss:		0.310021
  validation accuracy:		92.72 %
Epoch 471 of 2000 took 0.035s
  training loss:		0.067760
  validation loss:		0.304895
  validation accuracy:		92.07 %
Epoch 472 of 2000 took 0.035s
  training loss:		0.064226
  validation loss:		0.294594
  validation accuracy:		92.61 %
Epoch 473 of 2000 took 0.035s
  training loss:		0.062130
  validation loss:		0.301383
  validation accuracy:		92.17 %
Epoch 474 of 2000 took 0.035s
  training loss:		0.065498
  validation loss:		0.298228
  validation accuracy:		92.61 %
Epoch 475 of 2000 took 0.035s
  training loss:		0.065878
  validation loss:		0.310323
  validation accuracy:		92.50 %
Epoch 476 of 2000 took 0.035s
  training loss:		0.065027
  validation loss:		0.291498
  validation accuracy:		93.15 %
Epoch 477 of 2000 took 0.035s
  training loss:		0.065330
  validation loss:		0.302826
  validation accuracy:		92.50 %
Epoch 478 of 2000 took 0.035s
  training loss:		0.064287
  validation loss:		0.310810
  validation accuracy:		91.85 %
Epoch 479 of 2000 took 0.035s
  training loss:		0.063701
  validation loss:		0.310540
  validation accuracy:		91.96 %
Epoch 480 of 2000 took 0.035s
  training loss:		0.058308
  validation loss:		0.300934
  validation accuracy:		92.72 %
Epoch 481 of 2000 took 0.035s
  training loss:		0.062897
  validation loss:		0.301934
  validation accuracy:		93.04 %
Epoch 482 of 2000 took 0.035s
  training loss:		0.065258
  validation loss:		0.302932
  validation accuracy:		92.50 %
Epoch 483 of 2000 took 0.035s
  training loss:		0.063478
  validation loss:		0.307318
  validation accuracy:		92.39 %
Epoch 484 of 2000 took 0.035s
  training loss:		0.063558
  validation loss:		0.311739
  validation accuracy:		92.07 %
Epoch 485 of 2000 took 0.035s
  training loss:		0.063289
  validation loss:		0.306528
  validation accuracy:		93.26 %
Epoch 486 of 2000 took 0.035s
  training loss:		0.062398
  validation loss:		0.308872
  validation accuracy:		92.39 %
Epoch 487 of 2000 took 0.035s
  training loss:		0.060191
  validation loss:		0.308006
  validation accuracy:		92.50 %
Epoch 488 of 2000 took 0.035s
  training loss:		0.062502
  validation loss:		0.316502
  validation accuracy:		92.17 %
Epoch 489 of 2000 took 0.036s
  training loss:		0.061172
  validation loss:		0.312814
  validation accuracy:		92.39 %
Epoch 490 of 2000 took 0.035s
  training loss:		0.063342
  validation loss:		0.302329
  validation accuracy:		92.50 %
Epoch 491 of 2000 took 0.035s
  training loss:		0.063917
  validation loss:		0.316680
  validation accuracy:		91.96 %
Epoch 492 of 2000 took 0.035s
  training loss:		0.062844
  validation loss:		0.317833
  validation accuracy:		92.07 %
Epoch 493 of 2000 took 0.035s
  training loss:		0.061180
  validation loss:		0.309604
  validation accuracy:		92.17 %
Epoch 494 of 2000 took 0.035s
  training loss:		0.061402
  validation loss:		0.316057
  validation accuracy:		91.85 %
Epoch 495 of 2000 took 0.036s
  training loss:		0.061860
  validation loss:		0.322363
  validation accuracy:		92.17 %
Epoch 496 of 2000 took 0.035s
  training loss:		0.060391
  validation loss:		0.318660
  validation accuracy:		91.85 %
Epoch 497 of 2000 took 0.035s
  training loss:		0.060835
  validation loss:		0.325522
  validation accuracy:		92.17 %
Epoch 498 of 2000 took 0.035s
  training loss:		0.059348
  validation loss:		0.301714
  validation accuracy:		92.83 %
Epoch 499 of 2000 took 0.035s
  training loss:		0.061168
  validation loss:		0.314682
  validation accuracy:		92.28 %
Epoch 500 of 2000 took 0.035s
  training loss:		0.062146
  validation loss:		0.323680
  validation accuracy:		91.85 %
Epoch 501 of 2000 took 0.035s
  training loss:		0.062407
  validation loss:		0.315716
  validation accuracy:		92.28 %
Epoch 502 of 2000 took 0.035s
  training loss:		0.057920
  validation loss:		0.310114
  validation accuracy:		92.17 %
Epoch 503 of 2000 took 0.035s
  training loss:		0.060666
  validation loss:		0.310132
  validation accuracy:		92.17 %
Epoch 504 of 2000 took 0.035s
  training loss:		0.059910
  validation loss:		0.304215
  validation accuracy:		92.72 %
Epoch 505 of 2000 took 0.035s
  training loss:		0.060182
  validation loss:		0.327161
  validation accuracy:		92.39 %
Epoch 506 of 2000 took 0.035s
  training loss:		0.061170
  validation loss:		0.305320
  validation accuracy:		92.93 %
Epoch 507 of 2000 took 0.035s
  training loss:		0.060461
  validation loss:		0.325382
  validation accuracy:		92.17 %
Epoch 508 of 2000 took 0.035s
  training loss:		0.059798
  validation loss:		0.311705
  validation accuracy:		92.28 %
Epoch 509 of 2000 took 0.035s
  training loss:		0.057717
  validation loss:		0.317565
  validation accuracy:		92.07 %
Epoch 510 of 2000 took 0.035s
  training loss:		0.057165
  validation loss:		0.319284
  validation accuracy:		92.07 %
Epoch 511 of 2000 took 0.035s
  training loss:		0.057361
  validation loss:		0.322056
  validation accuracy:		91.85 %
Epoch 512 of 2000 took 0.035s
  training loss:		0.058966
  validation loss:		0.307272
  validation accuracy:		92.61 %
Epoch 513 of 2000 took 0.035s
  training loss:		0.058160
  validation loss:		0.310720
  validation accuracy:		92.72 %
Epoch 514 of 2000 took 0.035s
  training loss:		0.057670
  validation loss:		0.306178
  validation accuracy:		92.50 %
Epoch 515 of 2000 took 0.035s
  training loss:		0.057468
  validation loss:		0.308620
  validation accuracy:		92.72 %
Epoch 516 of 2000 took 0.035s
  training loss:		0.058954
  validation loss:		0.308787
  validation accuracy:		92.61 %
Epoch 517 of 2000 took 0.035s
  training loss:		0.056449
  validation loss:		0.322655
  validation accuracy:		91.96 %
Epoch 518 of 2000 took 0.035s
  training loss:		0.056432
  validation loss:		0.320187
  validation accuracy:		92.50 %
Epoch 519 of 2000 took 0.035s
  training loss:		0.055386
  validation loss:		0.314422
  validation accuracy:		92.28 %
Epoch 520 of 2000 took 0.035s
  training loss:		0.056698
  validation loss:		0.316574
  validation accuracy:		92.50 %
Epoch 521 of 2000 took 0.035s
  training loss:		0.057916
  validation loss:		0.314948
  validation accuracy:		92.17 %
Epoch 522 of 2000 took 0.035s
  training loss:		0.055786
  validation loss:		0.322892
  validation accuracy:		92.39 %
Epoch 523 of 2000 took 0.035s
  training loss:		0.056644
  validation loss:		0.320808
  validation accuracy:		92.17 %
Epoch 524 of 2000 took 0.035s
  training loss:		0.055779
  validation loss:		0.312461
  validation accuracy:		92.93 %
Epoch 525 of 2000 took 0.035s
  training loss:		0.055905
  validation loss:		0.323270
  validation accuracy:		92.28 %
Epoch 526 of 2000 took 0.035s
  training loss:		0.058330
  validation loss:		0.325608
  validation accuracy:		92.28 %
Epoch 527 of 2000 took 0.035s
  training loss:		0.054904
  validation loss:		0.322274
  validation accuracy:		92.28 %
Epoch 528 of 2000 took 0.035s
  training loss:		0.057653
  validation loss:		0.326992
  validation accuracy:		91.96 %
Epoch 529 of 2000 took 0.035s
  training loss:		0.055367
  validation loss:		0.323725
  validation accuracy:		92.28 %
Epoch 530 of 2000 took 0.035s
  training loss:		0.057297
  validation loss:		0.320877
  validation accuracy:		92.39 %
Epoch 531 of 2000 took 0.035s
  training loss:		0.055401
  validation loss:		0.316881
  validation accuracy:		92.93 %
Epoch 532 of 2000 took 0.035s
  training loss:		0.055294
  validation loss:		0.321362
  validation accuracy:		92.17 %
Epoch 533 of 2000 took 0.035s
  training loss:		0.055331
  validation loss:		0.325646
  validation accuracy:		92.07 %
Epoch 534 of 2000 took 0.035s
  training loss:		0.055384
  validation loss:		0.327873
  validation accuracy:		92.17 %
Epoch 535 of 2000 took 0.035s
  training loss:		0.056612
  validation loss:		0.323496
  validation accuracy:		92.17 %
Epoch 536 of 2000 took 0.035s
  training loss:		0.055882
  validation loss:		0.331413
  validation accuracy:		92.28 %
Epoch 537 of 2000 took 0.035s
  training loss:		0.053416
  validation loss:		0.322869
  validation accuracy:		92.39 %
Epoch 538 of 2000 took 0.035s
  training loss:		0.055437
  validation loss:		0.315665
  validation accuracy:		92.83 %
Epoch 539 of 2000 took 0.035s
  training loss:		0.056865
  validation loss:		0.313603
  validation accuracy:		92.39 %
Epoch 540 of 2000 took 0.035s
  training loss:		0.052956
  validation loss:		0.326331
  validation accuracy:		92.50 %
Epoch 541 of 2000 took 0.035s
  training loss:		0.052105
  validation loss:		0.324620
  validation accuracy:		92.39 %
Epoch 542 of 2000 took 0.035s
  training loss:		0.053548
  validation loss:		0.321379
  validation accuracy:		92.39 %
Epoch 543 of 2000 took 0.035s
  training loss:		0.052378
  validation loss:		0.319114
  validation accuracy:		92.93 %
Epoch 544 of 2000 took 0.035s
  training loss:		0.052594
  validation loss:		0.326066
  validation accuracy:		92.39 %
Epoch 545 of 2000 took 0.035s
  training loss:		0.055679
  validation loss:		0.324525
  validation accuracy:		92.28 %
Epoch 546 of 2000 took 0.035s
  training loss:		0.053783
  validation loss:		0.331134
  validation accuracy:		92.28 %
Epoch 547 of 2000 took 0.036s
  training loss:		0.053251
  validation loss:		0.319764
  validation accuracy:		92.39 %
Epoch 548 of 2000 took 0.035s
  training loss:		0.054730
  validation loss:		0.316229
  validation accuracy:		92.28 %
Epoch 549 of 2000 took 0.035s
  training loss:		0.051357
  validation loss:		0.324586
  validation accuracy:		92.83 %
Epoch 550 of 2000 took 0.035s
  training loss:		0.053527
  validation loss:		0.324218
  validation accuracy:		92.61 %
Epoch 551 of 2000 took 0.035s
  training loss:		0.052737
  validation loss:		0.329332
  validation accuracy:		92.28 %
Epoch 552 of 2000 took 0.035s
  training loss:		0.052996
  validation loss:		0.329865
  validation accuracy:		92.07 %
Epoch 553 of 2000 took 0.035s
  training loss:		0.052108
  validation loss:		0.337479
  validation accuracy:		92.07 %
Epoch 554 of 2000 took 0.035s
  training loss:		0.052755
  validation loss:		0.324485
  validation accuracy:		92.61 %
Epoch 555 of 2000 took 0.035s
  training loss:		0.054169
  validation loss:		0.323789
  validation accuracy:		92.50 %
Epoch 556 of 2000 took 0.035s
  training loss:		0.053540
  validation loss:		0.334401
  validation accuracy:		91.96 %
Epoch 557 of 2000 took 0.035s
  training loss:		0.052609
  validation loss:		0.319880
  validation accuracy:		93.04 %
Epoch 558 of 2000 took 0.035s
  training loss:		0.053865
  validation loss:		0.320276
  validation accuracy:		92.50 %
Epoch 559 of 2000 took 0.035s
  training loss:		0.051118
  validation loss:		0.340157
  validation accuracy:		92.28 %
Epoch 560 of 2000 took 0.035s
  training loss:		0.051548
  validation loss:		0.328594
  validation accuracy:		92.39 %
Epoch 561 of 2000 took 0.035s
  training loss:		0.050513
  validation loss:		0.341584
  validation accuracy:		92.07 %
Epoch 562 of 2000 took 0.035s
  training loss:		0.050839
  validation loss:		0.330701
  validation accuracy:		92.28 %
Epoch 563 of 2000 took 0.035s
  training loss:		0.052438
  validation loss:		0.328842
  validation accuracy:		92.39 %
Epoch 564 of 2000 took 0.035s
  training loss:		0.051007
  validation loss:		0.330911
  validation accuracy:		92.39 %
Epoch 565 of 2000 took 0.035s
  training loss:		0.051126
  validation loss:		0.322004
  validation accuracy:		92.50 %
Epoch 566 of 2000 took 0.035s
  training loss:		0.051796
  validation loss:		0.331944
  validation accuracy:		92.39 %
Epoch 567 of 2000 took 0.035s
  training loss:		0.051072
  validation loss:		0.330402
  validation accuracy:		92.28 %
Epoch 568 of 2000 took 0.035s
  training loss:		0.051531
  validation loss:		0.324661
  validation accuracy:		92.83 %
Epoch 569 of 2000 took 0.035s
  training loss:		0.047930
  validation loss:		0.333960
  validation accuracy:		92.61 %
Epoch 570 of 2000 took 0.035s
  training loss:		0.048005
  validation loss:		0.330812
  validation accuracy:		92.17 %
Epoch 571 of 2000 took 0.035s
  training loss:		0.051842
  validation loss:		0.337087
  validation accuracy:		92.39 %
Epoch 572 of 2000 took 0.035s
  training loss:		0.051977
  validation loss:		0.330269
  validation accuracy:		92.39 %
Epoch 573 of 2000 took 0.035s
  training loss:		0.049694
  validation loss:		0.320574
  validation accuracy:		92.72 %
Epoch 574 of 2000 took 0.035s
  training loss:		0.049635
  validation loss:		0.336775
  validation accuracy:		92.17 %
Epoch 575 of 2000 took 0.035s
  training loss:		0.048579
  validation loss:		0.325708
  validation accuracy:		92.83 %
Epoch 576 of 2000 took 0.035s
  training loss:		0.049625
  validation loss:		0.328708
  validation accuracy:		92.72 %
Epoch 577 of 2000 took 0.035s
  training loss:		0.050150
  validation loss:		0.329703
  validation accuracy:		92.39 %
Epoch 578 of 2000 took 0.035s
  training loss:		0.050282
  validation loss:		0.342939
  validation accuracy:		92.39 %
Epoch 579 of 2000 took 0.035s
  training loss:		0.049815
  validation loss:		0.352561
  validation accuracy:		91.85 %
Epoch 580 of 2000 took 0.035s
  training loss:		0.047418
  validation loss:		0.325492
  validation accuracy:		92.50 %
Epoch 581 of 2000 took 0.035s
  training loss:		0.049831
  validation loss:		0.337345
  validation accuracy:		92.61 %
Epoch 582 of 2000 took 0.035s
  training loss:		0.049702
  validation loss:		0.336445
  validation accuracy:		92.28 %
Epoch 583 of 2000 took 0.035s
  training loss:		0.048649
  validation loss:		0.323063
  validation accuracy:		92.72 %
Epoch 584 of 2000 took 0.035s
  training loss:		0.047925
  validation loss:		0.340800
  validation accuracy:		92.17 %
Epoch 585 of 2000 took 0.035s
  training loss:		0.049196
  validation loss:		0.334406
  validation accuracy:		92.72 %
Epoch 586 of 2000 took 0.035s
  training loss:		0.047805
  validation loss:		0.331284
  validation accuracy:		92.39 %
Epoch 587 of 2000 took 0.035s
  training loss:		0.047967
  validation loss:		0.340924
  validation accuracy:		92.28 %
Epoch 588 of 2000 took 0.035s
  training loss:		0.046874
  validation loss:		0.347466
  validation accuracy:		92.17 %
Epoch 589 of 2000 took 0.035s
  training loss:		0.049262
  validation loss:		0.333311
  validation accuracy:		92.61 %
Epoch 590 of 2000 took 0.035s
  training loss:		0.046396
  validation loss:		0.334818
  validation accuracy:		92.61 %
Epoch 591 of 2000 took 0.035s
  training loss:		0.049860
  validation loss:		0.331489
  validation accuracy:		92.50 %
Epoch 592 of 2000 took 0.035s
  training loss:		0.049199
  validation loss:		0.342798
  validation accuracy:		92.39 %
Epoch 593 of 2000 took 0.035s
  training loss:		0.045520
  validation loss:		0.347094
  validation accuracy:		92.28 %
Epoch 594 of 2000 took 0.035s
  training loss:		0.047533
  validation loss:		0.357622
  validation accuracy:		91.96 %
Epoch 595 of 2000 took 0.035s
  training loss:		0.047784
  validation loss:		0.343874
  validation accuracy:		92.17 %
Epoch 596 of 2000 took 0.035s
  training loss:		0.049383
  validation loss:		0.350335
  validation accuracy:		92.39 %
Epoch 597 of 2000 took 0.035s
  training loss:		0.046402
  validation loss:		0.342920
  validation accuracy:		91.85 %
Epoch 598 of 2000 took 0.035s
  training loss:		0.047999
  validation loss:		0.349174
  validation accuracy:		92.28 %
Epoch 599 of 2000 took 0.035s
  training loss:		0.047825
  validation loss:		0.340249
  validation accuracy:		92.17 %
Epoch 600 of 2000 took 0.035s
  training loss:		0.046270
  validation loss:		0.348308
  validation accuracy:		92.28 %
Epoch 601 of 2000 took 0.035s
  training loss:		0.048373
  validation loss:		0.342497
  validation accuracy:		92.28 %
Epoch 602 of 2000 took 0.035s
  training loss:		0.046132
  validation loss:		0.348500
  validation accuracy:		92.17 %
Epoch 603 of 2000 took 0.040s
  training loss:		0.047412
  validation loss:		0.335356
  validation accuracy:		92.72 %
Epoch 604 of 2000 took 0.036s
  training loss:		0.045861
  validation loss:		0.353608
  validation accuracy:		92.07 %
Epoch 605 of 2000 took 0.035s
  training loss:		0.045643
  validation loss:		0.341833
  validation accuracy:		92.07 %
Epoch 606 of 2000 took 0.035s
  training loss:		0.046842
  validation loss:		0.355714
  validation accuracy:		92.07 %
Epoch 607 of 2000 took 0.035s
  training loss:		0.042610
  validation loss:		0.334364
  validation accuracy:		92.28 %
Epoch 608 of 2000 took 0.035s
  training loss:		0.046107
  validation loss:		0.360764
  validation accuracy:		92.17 %
Epoch 609 of 2000 took 0.035s
  training loss:		0.046286
  validation loss:		0.351345
  validation accuracy:		92.28 %
Epoch 610 of 2000 took 0.035s
  training loss:		0.043680
  validation loss:		0.344175
  validation accuracy:		92.17 %
Epoch 611 of 2000 took 0.035s
  training loss:		0.045192
  validation loss:		0.339903
  validation accuracy:		92.72 %
Epoch 612 of 2000 took 0.035s
  training loss:		0.045585
  validation loss:		0.339493
  validation accuracy:		92.39 %
Epoch 613 of 2000 took 0.035s
  training loss:		0.046846
  validation loss:		0.344029
  validation accuracy:		92.39 %
Epoch 614 of 2000 took 0.035s
  training loss:		0.044295
  validation loss:		0.349607
  validation accuracy:		92.07 %
Epoch 615 of 2000 took 0.035s
  training loss:		0.043359
  validation loss:		0.347574
  validation accuracy:		92.28 %
Epoch 616 of 2000 took 0.035s
  training loss:		0.045889
  validation loss:		0.349867
  validation accuracy:		92.50 %
Epoch 617 of 2000 took 0.035s
  training loss:		0.042759
  validation loss:		0.355784
  validation accuracy:		92.39 %
Epoch 618 of 2000 took 0.035s
  training loss:		0.042724
  validation loss:		0.355822
  validation accuracy:		92.39 %
Epoch 619 of 2000 took 0.035s
  training loss:		0.043799
  validation loss:		0.352647
  validation accuracy:		92.17 %
Epoch 620 of 2000 took 0.035s
  training loss:		0.044680
  validation loss:		0.356940
  validation accuracy:		92.28 %
Epoch 621 of 2000 took 0.035s
  training loss:		0.044218
  validation loss:		0.364481
  validation accuracy:		92.17 %
Epoch 622 of 2000 took 0.035s
  training loss:		0.046579
  validation loss:		0.361768
  validation accuracy:		92.17 %
Epoch 623 of 2000 took 0.035s
  training loss:		0.042237
  validation loss:		0.360440
  validation accuracy:		91.96 %
Epoch 624 of 2000 took 0.035s
  training loss:		0.044055
  validation loss:		0.354811
  validation accuracy:		92.17 %
Epoch 625 of 2000 took 0.035s
  training loss:		0.043432
  validation loss:		0.359901
  validation accuracy:		92.17 %
Epoch 626 of 2000 took 0.035s
  training loss:		0.044315
  validation loss:		0.354434
  validation accuracy:		92.39 %
Epoch 627 of 2000 took 0.035s
  training loss:		0.045334
  validation loss:		0.354816
  validation accuracy:		92.17 %
Epoch 628 of 2000 took 0.035s
  training loss:		0.043296
  validation loss:		0.354139
  validation accuracy:		92.28 %
Epoch 629 of 2000 took 0.035s
  training loss:		0.044522
  validation loss:		0.355875
  validation accuracy:		92.50 %
Epoch 630 of 2000 took 0.035s
  training loss:		0.045320
  validation loss:		0.347914
  validation accuracy:		92.39 %
Epoch 631 of 2000 took 0.035s
  training loss:		0.043958
  validation loss:		0.344298
  validation accuracy:		92.50 %
Epoch 632 of 2000 took 0.035s
  training loss:		0.044381
  validation loss:		0.360405
  validation accuracy:		92.28 %
Epoch 633 of 2000 took 0.035s
  training loss:		0.041299
  validation loss:		0.359960
  validation accuracy:		92.17 %
Epoch 634 of 2000 took 0.035s
  training loss:		0.042474
  validation loss:		0.360482
  validation accuracy:		92.07 %
Epoch 635 of 2000 took 0.035s
  training loss:		0.041815
  validation loss:		0.372728
  validation accuracy:		91.85 %
Epoch 636 of 2000 took 0.035s
  training loss:		0.040826
  validation loss:		0.347033
  validation accuracy:		92.61 %
Epoch 637 of 2000 took 0.036s
  training loss:		0.042963
  validation loss:		0.347683
  validation accuracy:		92.39 %
Epoch 638 of 2000 took 0.035s
  training loss:		0.042426
  validation loss:		0.357743
  validation accuracy:		92.17 %
Epoch 639 of 2000 took 0.035s
  training loss:		0.041120
  validation loss:		0.362229
  validation accuracy:		92.07 %
Epoch 640 of 2000 took 0.035s
  training loss:		0.041859
  validation loss:		0.356708
  validation accuracy:		92.17 %
Epoch 641 of 2000 took 0.035s
  training loss:		0.042681
  validation loss:		0.350198
  validation accuracy:		92.28 %
Epoch 642 of 2000 took 0.035s
  training loss:		0.041458
  validation loss:		0.350949
  validation accuracy:		92.50 %
Epoch 643 of 2000 took 0.035s
  training loss:		0.042990
  validation loss:		0.353428
  validation accuracy:		92.17 %
Epoch 644 of 2000 took 0.035s
  training loss:		0.042203
  validation loss:		0.368800
  validation accuracy:		92.17 %
Epoch 645 of 2000 took 0.035s
  training loss:		0.042261
  validation loss:		0.362670
  validation accuracy:		92.17 %
Epoch 646 of 2000 took 0.035s
  training loss:		0.040864
  validation loss:		0.354505
  validation accuracy:		91.96 %
Epoch 647 of 2000 took 0.035s
  training loss:		0.042317
  validation loss:		0.348566
  validation accuracy:		92.17 %
Epoch 648 of 2000 took 0.035s
  training loss:		0.041902
  validation loss:		0.357186
  validation accuracy:		92.17 %
Epoch 649 of 2000 took 0.035s
  training loss:		0.042448
  validation loss:		0.359221
  validation accuracy:		92.07 %
Epoch 650 of 2000 took 0.035s
  training loss:		0.040437
  validation loss:		0.371447
  validation accuracy:		92.17 %
Epoch 651 of 2000 took 0.035s
  training loss:		0.041040
  validation loss:		0.354551
  validation accuracy:		92.28 %
Epoch 652 of 2000 took 0.035s
  training loss:		0.041467
  validation loss:		0.350233
  validation accuracy:		92.61 %
Epoch 653 of 2000 took 0.035s
  training loss:		0.040573
  validation loss:		0.363688
  validation accuracy:		92.07 %
Epoch 654 of 2000 took 0.035s
  training loss:		0.041098
  validation loss:		0.353553
  validation accuracy:		92.17 %
Epoch 655 of 2000 took 0.035s
  training loss:		0.040835
  validation loss:		0.364181
  validation accuracy:		92.17 %
Epoch 656 of 2000 took 0.035s
  training loss:		0.040804
  validation loss:		0.356762
  validation accuracy:		92.39 %
Epoch 657 of 2000 took 0.035s
  training loss:		0.040102
  validation loss:		0.366956
  validation accuracy:		92.17 %
Epoch 658 of 2000 took 0.035s
  training loss:		0.039645
  validation loss:		0.349833
  validation accuracy:		92.50 %
Epoch 659 of 2000 took 0.035s
  training loss:		0.041555
  validation loss:		0.369044
  validation accuracy:		92.07 %
Epoch 660 of 2000 took 0.035s
  training loss:		0.040677
  validation loss:		0.358348
  validation accuracy:		92.39 %
Epoch 661 of 2000 took 0.035s
  training loss:		0.039926
  validation loss:		0.377238
  validation accuracy:		92.07 %
Epoch 662 of 2000 took 0.035s
  training loss:		0.040515
  validation loss:		0.365044
  validation accuracy:		92.07 %
Epoch 663 of 2000 took 0.035s
  training loss:		0.039238
  validation loss:		0.370884
  validation accuracy:		92.17 %
Epoch 664 of 2000 took 0.035s
  training loss:		0.041398
  validation loss:		0.355576
  validation accuracy:		92.28 %
Epoch 665 of 2000 took 0.035s
  training loss:		0.039233
  validation loss:		0.378815
  validation accuracy:		92.28 %
Epoch 666 of 2000 took 0.035s
  training loss:		0.038093
  validation loss:		0.352842
  validation accuracy:		92.39 %
Epoch 667 of 2000 took 0.035s
  training loss:		0.039142
  validation loss:		0.369661
  validation accuracy:		92.07 %
Epoch 668 of 2000 took 0.035s
  training loss:		0.038438
  validation loss:		0.371634
  validation accuracy:		92.28 %
Epoch 669 of 2000 took 0.035s
  training loss:		0.040470
  validation loss:		0.363849
  validation accuracy:		92.17 %
Epoch 670 of 2000 took 0.035s
  training loss:		0.039499
  validation loss:		0.358958
  validation accuracy:		92.28 %
Epoch 671 of 2000 took 0.035s
  training loss:		0.037101
  validation loss:		0.357107
  validation accuracy:		92.17 %
Epoch 672 of 2000 took 0.035s
  training loss:		0.036914
  validation loss:		0.363900
  validation accuracy:		92.50 %
Epoch 673 of 2000 took 0.035s
  training loss:		0.038948
  validation loss:		0.370242
  validation accuracy:		92.17 %
Epoch 674 of 2000 took 0.035s
  training loss:		0.035697
  validation loss:		0.355782
  validation accuracy:		92.28 %
Epoch 675 of 2000 took 0.035s
  training loss:		0.037957
  validation loss:		0.365763
  validation accuracy:		91.74 %
Epoch 676 of 2000 took 0.035s
  training loss:		0.038149
  validation loss:		0.364708
  validation accuracy:		92.07 %
Epoch 677 of 2000 took 0.035s
  training loss:		0.037764
  validation loss:		0.360458
  validation accuracy:		92.39 %
Epoch 678 of 2000 took 0.035s
  training loss:		0.039201
  validation loss:		0.369391
  validation accuracy:		92.17 %
Epoch 679 of 2000 took 0.035s
  training loss:		0.037830
  validation loss:		0.360982
  validation accuracy:		92.39 %
Epoch 680 of 2000 took 0.035s
  training loss:		0.036157
  validation loss:		0.371739
  validation accuracy:		92.17 %
Epoch 681 of 2000 took 0.035s
  training loss:		0.038409
  validation loss:		0.351199
  validation accuracy:		92.61 %
Epoch 682 of 2000 took 0.035s
  training loss:		0.035606
  validation loss:		0.366815
  validation accuracy:		92.28 %
Epoch 683 of 2000 took 0.035s
  training loss:		0.037331
  validation loss:		0.373852
  validation accuracy:		92.17 %
Epoch 684 of 2000 took 0.035s
  training loss:		0.038424
  validation loss:		0.373767
  validation accuracy:		92.28 %
Epoch 685 of 2000 took 0.035s
  training loss:		0.037899
  validation loss:		0.366201
  validation accuracy:		92.07 %
Epoch 686 of 2000 took 0.035s
  training loss:		0.037802
  validation loss:		0.376345
  validation accuracy:		91.85 %
Epoch 687 of 2000 took 0.035s
  training loss:		0.037104
  validation loss:		0.370881
  validation accuracy:		92.07 %
Epoch 688 of 2000 took 0.035s
  training loss:		0.035992
  validation loss:		0.377691
  validation accuracy:		92.07 %
Epoch 689 of 2000 took 0.035s
  training loss:		0.037226
  validation loss:		0.364720
  validation accuracy:		92.28 %
Epoch 690 of 2000 took 0.035s
  training loss:		0.037267
  validation loss:		0.384129
  validation accuracy:		92.17 %
Epoch 691 of 2000 took 0.035s
  training loss:		0.037058
  validation loss:		0.371697
  validation accuracy:		91.85 %
Epoch 692 of 2000 took 0.035s
  training loss:		0.037178
  validation loss:		0.373406
  validation accuracy:		92.17 %
Epoch 693 of 2000 took 0.036s
  training loss:		0.037907
  validation loss:		0.388320
  validation accuracy:		92.07 %
Epoch 694 of 2000 took 0.035s
  training loss:		0.037020
  validation loss:		0.371616
  validation accuracy:		92.07 %
Epoch 695 of 2000 took 0.035s
  training loss:		0.037023
  validation loss:		0.367976
  validation accuracy:		91.96 %
Epoch 696 of 2000 took 0.035s
  training loss:		0.036463
  validation loss:		0.369368
  validation accuracy:		91.96 %
Epoch 697 of 2000 took 0.035s
  training loss:		0.036924
  validation loss:		0.375139
  validation accuracy:		91.85 %
Epoch 698 of 2000 took 0.035s
  training loss:		0.036761
  validation loss:		0.374196
  validation accuracy:		92.17 %
Epoch 699 of 2000 took 0.035s
  training loss:		0.034733
  validation loss:		0.371005
  validation accuracy:		92.28 %
Epoch 700 of 2000 took 0.035s
  training loss:		0.035263
  validation loss:		0.385296
  validation accuracy:		92.17 %
Epoch 701 of 2000 took 0.035s
  training loss:		0.036196
  validation loss:		0.375683
  validation accuracy:		91.85 %
Epoch 702 of 2000 took 0.035s
  training loss:		0.033492
  validation loss:		0.373269
  validation accuracy:		92.07 %
Epoch 703 of 2000 took 0.035s
  training loss:		0.035543
  validation loss:		0.375056
  validation accuracy:		91.96 %
Epoch 704 of 2000 took 0.035s
  training loss:		0.035280
  validation loss:		0.372803
  validation accuracy:		92.17 %
Epoch 705 of 2000 took 0.035s
  training loss:		0.036532
  validation loss:		0.373552
  validation accuracy:		91.96 %
Epoch 706 of 2000 took 0.035s
  training loss:		0.034909
  validation loss:		0.373609
  validation accuracy:		91.96 %
Epoch 707 of 2000 took 0.035s
  training loss:		0.035618
  validation loss:		0.382696
  validation accuracy:		92.39 %
Epoch 708 of 2000 took 0.035s
  training loss:		0.035146
  validation loss:		0.382014
  validation accuracy:		91.96 %
Epoch 709 of 2000 took 0.035s
  training loss:		0.035142
  validation loss:		0.375232
  validation accuracy:		92.17 %
Epoch 710 of 2000 took 0.035s
  training loss:		0.035485
  validation loss:		0.379435
  validation accuracy:		92.07 %
Epoch 711 of 2000 took 0.035s
  training loss:		0.035552
  validation loss:		0.396304
  validation accuracy:		91.52 %
Epoch 712 of 2000 took 0.035s
  training loss:		0.035027
  validation loss:		0.377800
  validation accuracy:		92.28 %
Epoch 713 of 2000 took 0.035s
  training loss:		0.034756
  validation loss:		0.383641
  validation accuracy:		91.85 %
Epoch 714 of 2000 took 0.035s
  training loss:		0.033710
  validation loss:		0.368874
  validation accuracy:		92.28 %
Epoch 715 of 2000 took 0.035s
  training loss:		0.035720
  validation loss:		0.391833
  validation accuracy:		92.07 %
Epoch 716 of 2000 took 0.035s
  training loss:		0.033639
  validation loss:		0.383643
  validation accuracy:		92.28 %
Epoch 717 of 2000 took 0.035s
  training loss:		0.034557
  validation loss:		0.385828
  validation accuracy:		91.96 %
Epoch 718 of 2000 took 0.035s
  training loss:		0.034013
  validation loss:		0.372546
  validation accuracy:		92.17 %
Epoch 719 of 2000 took 0.035s
  training loss:		0.035804
  validation loss:		0.382184
  validation accuracy:		91.96 %
Epoch 720 of 2000 took 0.035s
  training loss:		0.034677
  validation loss:		0.372270
  validation accuracy:		92.28 %
Epoch 721 of 2000 took 0.035s
  training loss:		0.034121
  validation loss:		0.376259
  validation accuracy:		91.63 %
Epoch 722 of 2000 took 0.035s
  training loss:		0.035299
  validation loss:		0.385760
  validation accuracy:		92.39 %
Epoch 723 of 2000 took 0.035s
  training loss:		0.033898
  validation loss:		0.380869
  validation accuracy:		91.74 %
Epoch 724 of 2000 took 0.035s
  training loss:		0.033035
  validation loss:		0.375686
  validation accuracy:		92.39 %
Epoch 725 of 2000 took 0.035s
  training loss:		0.033225
  validation loss:		0.395948
  validation accuracy:		91.63 %
Epoch 726 of 2000 took 0.035s
  training loss:		0.033126
  validation loss:		0.371505
  validation accuracy:		92.28 %
Epoch 727 of 2000 took 0.035s
  training loss:		0.034022
  validation loss:		0.392813
  validation accuracy:		91.63 %
Epoch 728 of 2000 took 0.035s
  training loss:		0.032747
  validation loss:		0.392393
  validation accuracy:		91.96 %
Epoch 729 of 2000 took 0.035s
  training loss:		0.033088
  validation loss:		0.389355
  validation accuracy:		91.85 %
Epoch 730 of 2000 took 0.035s
  training loss:		0.034051
  validation loss:		0.401193
  validation accuracy:		92.28 %
Epoch 731 of 2000 took 0.035s
  training loss:		0.033505
  validation loss:		0.389353
  validation accuracy:		92.07 %
Epoch 732 of 2000 took 0.035s
  training loss:		0.032577
  validation loss:		0.379494
  validation accuracy:		91.85 %
Epoch 733 of 2000 took 0.035s
  training loss:		0.034422
  validation loss:		0.392693
  validation accuracy:		92.17 %
Epoch 734 of 2000 took 0.035s
  training loss:		0.033187
  validation loss:		0.389419
  validation accuracy:		92.07 %
Epoch 735 of 2000 took 0.035s
  training loss:		0.030653
  validation loss:		0.379456
  validation accuracy:		92.39 %
Epoch 736 of 2000 took 0.035s
  training loss:		0.032677
  validation loss:		0.390230
  validation accuracy:		91.85 %
Epoch 737 of 2000 took 0.035s
  training loss:		0.031899
  validation loss:		0.388473
  validation accuracy:		92.17 %
Epoch 738 of 2000 took 0.035s
  training loss:		0.034041
  validation loss:		0.390180
  validation accuracy:		91.85 %
Epoch 739 of 2000 took 0.035s
  training loss:		0.032278
  validation loss:		0.397754
  validation accuracy:		91.96 %
Epoch 740 of 2000 took 0.035s
  training loss:		0.032195
  validation loss:		0.379795
  validation accuracy:		91.85 %
Epoch 741 of 2000 took 0.035s
  training loss:		0.033514
  validation loss:		0.392810
  validation accuracy:		91.85 %
Epoch 742 of 2000 took 0.035s
  training loss:		0.031412
  validation loss:		0.386444
  validation accuracy:		92.07 %
Epoch 743 of 2000 took 0.035s
  training loss:		0.030852
  validation loss:		0.408100
  validation accuracy:		91.74 %
Epoch 744 of 2000 took 0.035s
  training loss:		0.031940
  validation loss:		0.388827
  validation accuracy:		91.96 %
Epoch 745 of 2000 took 0.035s
  training loss:		0.032335
  validation loss:		0.385766
  validation accuracy:		91.85 %
Epoch 746 of 2000 took 0.035s
  training loss:		0.032631
  validation loss:		0.390419
  validation accuracy:		92.17 %
Epoch 747 of 2000 took 0.035s
  training loss:		0.032437
  validation loss:		0.396303
  validation accuracy:		91.85 %
Epoch 748 of 2000 took 0.035s
  training loss:		0.031784
  validation loss:		0.383672
  validation accuracy:		91.96 %
Epoch 749 of 2000 took 0.035s
  training loss:		0.032562
  validation loss:		0.382796
  validation accuracy:		91.63 %
Epoch 750 of 2000 took 0.035s
  training loss:		0.032429
  validation loss:		0.383453
  validation accuracy:		91.63 %
Epoch 751 of 2000 took 0.035s
  training loss:		0.032252
  validation loss:		0.397572
  validation accuracy:		91.85 %
Epoch 752 of 2000 took 0.035s
  training loss:		0.032391
  validation loss:		0.381362
  validation accuracy:		91.85 %
Epoch 753 of 2000 took 0.035s
  training loss:		0.028531
  validation loss:		0.393993
  validation accuracy:		92.17 %
Epoch 754 of 2000 took 0.035s
  training loss:		0.031101
  validation loss:		0.394936
  validation accuracy:		91.96 %
Epoch 755 of 2000 took 0.035s
  training loss:		0.029188
  validation loss:		0.385301
  validation accuracy:		91.96 %
Epoch 756 of 2000 took 0.035s
  training loss:		0.031307
  validation loss:		0.399131
  validation accuracy:		91.96 %
Epoch 757 of 2000 took 0.035s
  training loss:		0.030737
  validation loss:		0.386607
  validation accuracy:		92.17 %
Epoch 758 of 2000 took 0.035s
  training loss:		0.031030
  validation loss:		0.382456
  validation accuracy:		92.28 %
Epoch 759 of 2000 took 0.035s
  training loss:		0.031230
  validation loss:		0.397842
  validation accuracy:		91.96 %
Epoch 760 of 2000 took 0.035s
  training loss:		0.031057
  validation loss:		0.389589
  validation accuracy:		92.28 %
Epoch 761 of 2000 took 0.035s
  training loss:		0.030178
  validation loss:		0.396215
  validation accuracy:		92.07 %
Epoch 762 of 2000 took 0.035s
  training loss:		0.030787
  validation loss:		0.391989
  validation accuracy:		91.74 %
Epoch 763 of 2000 took 0.035s
  training loss:		0.030746
  validation loss:		0.394871
  validation accuracy:		92.39 %
Epoch 764 of 2000 took 0.035s
  training loss:		0.029958
  validation loss:		0.405719
  validation accuracy:		91.96 %
Epoch 765 of 2000 took 0.035s
  training loss:		0.030680
  validation loss:		0.389719
  validation accuracy:		92.72 %
Epoch 766 of 2000 took 0.035s
  training loss:		0.030162
  validation loss:		0.391584
  validation accuracy:		91.74 %
Epoch 767 of 2000 took 0.035s
  training loss:		0.029637
  validation loss:		0.400146
  validation accuracy:		91.85 %
Epoch 768 of 2000 took 0.035s
  training loss:		0.030461
  validation loss:		0.385560
  validation accuracy:		92.17 %
Epoch 769 of 2000 took 0.035s
  training loss:		0.029729
  validation loss:		0.407304
  validation accuracy:		91.74 %
Epoch 770 of 2000 took 0.035s
  training loss:		0.030696
  validation loss:		0.399859
  validation accuracy:		92.17 %
Epoch 771 of 2000 took 0.035s
  training loss:		0.028748
  validation loss:		0.406823
  validation accuracy:		91.74 %
Epoch 772 of 2000 took 0.036s
  training loss:		0.028976
  validation loss:		0.411853
  validation accuracy:		91.74 %
Epoch 773 of 2000 took 0.035s
  training loss:		0.030542
  validation loss:		0.394966
  validation accuracy:		91.85 %
Epoch 774 of 2000 took 0.035s
  training loss:		0.030088
  validation loss:		0.403002
  validation accuracy:		91.96 %
Epoch 775 of 2000 took 0.035s
  training loss:		0.030328
  validation loss:		0.403193
  validation accuracy:		92.17 %
Epoch 776 of 2000 took 0.035s
  training loss:		0.028504
  validation loss:		0.413443
  validation accuracy:		92.07 %
Epoch 777 of 2000 took 0.035s
  training loss:		0.027240
  validation loss:		0.404000
  validation accuracy:		91.74 %
Epoch 778 of 2000 took 0.035s
  training loss:		0.027395
  validation loss:		0.404855
  validation accuracy:		91.74 %
Epoch 779 of 2000 took 0.035s
  training loss:		0.028914
  validation loss:		0.399782
  validation accuracy:		91.74 %
Epoch 780 of 2000 took 0.035s
  training loss:		0.028947
  validation loss:		0.409105
  validation accuracy:		92.07 %
Epoch 781 of 2000 took 0.035s
  training loss:		0.029673
  validation loss:		0.391548
  validation accuracy:		91.85 %
Epoch 782 of 2000 took 0.035s
  training loss:		0.027085
  validation loss:		0.403480
  validation accuracy:		92.17 %
Epoch 783 of 2000 took 0.035s
  training loss:		0.030153
  validation loss:		0.409634
  validation accuracy:		91.63 %
Epoch 784 of 2000 took 0.035s
  training loss:		0.027954
  validation loss:		0.400251
  validation accuracy:		91.85 %
Epoch 785 of 2000 took 0.035s
  training loss:		0.029366
  validation loss:		0.412457
  validation accuracy:		91.85 %
Epoch 786 of 2000 took 0.035s
  training loss:		0.028678
  validation loss:		0.411075
  validation accuracy:		91.52 %
Epoch 787 of 2000 took 0.035s
  training loss:		0.028899
  validation loss:		0.401180
  validation accuracy:		91.96 %
Epoch 788 of 2000 took 0.035s
  training loss:		0.029563
  validation loss:		0.407313
  validation accuracy:		91.52 %
Epoch 789 of 2000 took 0.035s
  training loss:		0.027648
  validation loss:		0.404682
  validation accuracy:		91.85 %
Epoch 790 of 2000 took 0.035s
  training loss:		0.027071
  validation loss:		0.404759
  validation accuracy:		91.74 %
Epoch 791 of 2000 took 0.035s
  training loss:		0.028891
  validation loss:		0.408934
  validation accuracy:		91.74 %
Epoch 792 of 2000 took 0.035s
  training loss:		0.026811
  validation loss:		0.416719
  validation accuracy:		91.96 %
Epoch 793 of 2000 took 0.035s
  training loss:		0.028777
  validation loss:		0.410970
  validation accuracy:		91.96 %
Epoch 794 of 2000 took 0.035s
  training loss:		0.027407
  validation loss:		0.400332
  validation accuracy:		92.07 %
Epoch 795 of 2000 took 0.035s
  training loss:		0.028758
  validation loss:		0.412718
  validation accuracy:		91.85 %
Epoch 796 of 2000 took 0.035s
  training loss:		0.028741
  validation loss:		0.416508
  validation accuracy:		91.85 %
Epoch 797 of 2000 took 0.035s
  training loss:		0.027552
  validation loss:		0.415800
  validation accuracy:		91.85 %
Epoch 798 of 2000 took 0.035s
  training loss:		0.028007
  validation loss:		0.411925
  validation accuracy:		91.96 %
Epoch 799 of 2000 took 0.035s
  training loss:		0.027712
  validation loss:		0.399828
  validation accuracy:		91.96 %
Epoch 800 of 2000 took 0.035s
  training loss:		0.027609
  validation loss:		0.406466
  validation accuracy:		91.63 %
Epoch 801 of 2000 took 0.035s
  training loss:		0.027081
  validation loss:		0.403306
  validation accuracy:		92.17 %
Epoch 802 of 2000 took 0.035s
  training loss:		0.027684
  validation loss:		0.406417
  validation accuracy:		91.74 %
Epoch 803 of 2000 took 0.035s
  training loss:		0.027634
  validation loss:		0.408839
  validation accuracy:		91.96 %
Epoch 804 of 2000 took 0.035s
  training loss:		0.027871
  validation loss:		0.403079
  validation accuracy:		92.07 %
Epoch 805 of 2000 took 0.035s
  training loss:		0.026120
  validation loss:		0.401776
  validation accuracy:		91.85 %
Epoch 806 of 2000 took 0.035s
  training loss:		0.027984
  validation loss:		0.412636
  validation accuracy:		91.85 %
Epoch 807 of 2000 took 0.035s
  training loss:		0.027549
  validation loss:		0.408614
  validation accuracy:		91.63 %
Epoch 808 of 2000 took 0.035s
  training loss:		0.026943
  validation loss:		0.415849
  validation accuracy:		92.17 %
Epoch 809 of 2000 took 0.035s
  training loss:		0.026735
  validation loss:		0.417524
  validation accuracy:		91.85 %
Epoch 810 of 2000 took 0.035s
  training loss:		0.026113
  validation loss:		0.402767
  validation accuracy:		92.07 %
Epoch 811 of 2000 took 0.035s
  training loss:		0.027769
  validation loss:		0.409137
  validation accuracy:		92.17 %
Epoch 812 of 2000 took 0.035s
  training loss:		0.026574
  validation loss:		0.433338
  validation accuracy:		91.41 %
Epoch 813 of 2000 took 0.035s
  training loss:		0.027674
  validation loss:		0.419467
  validation accuracy:		91.85 %
Epoch 814 of 2000 took 0.035s
  training loss:		0.025149
  validation loss:		0.414119
  validation accuracy:		92.28 %
Epoch 815 of 2000 took 0.035s
  training loss:		0.026998
  validation loss:		0.416175
  validation accuracy:		91.96 %
Epoch 816 of 2000 took 0.035s
  training loss:		0.027267
  validation loss:		0.405355
  validation accuracy:		91.74 %
Epoch 817 of 2000 took 0.035s
  training loss:		0.024573
  validation loss:		0.424241
  validation accuracy:		91.74 %
Epoch 818 of 2000 took 0.035s
  training loss:		0.026183
  validation loss:		0.412611
  validation accuracy:		91.85 %
Epoch 819 of 2000 took 0.035s
  training loss:		0.026680
  validation loss:		0.414631
  validation accuracy:		91.85 %
Epoch 820 of 2000 took 0.035s
  training loss:		0.026681
  validation loss:		0.408648
  validation accuracy:		91.96 %
Epoch 821 of 2000 took 0.035s
  training loss:		0.024563
  validation loss:		0.410266
  validation accuracy:		91.85 %
Epoch 822 of 2000 took 0.035s
  training loss:		0.024941
  validation loss:		0.420220
  validation accuracy:		91.85 %
Epoch 823 of 2000 took 0.035s
  training loss:		0.026519
  validation loss:		0.430003
  validation accuracy:		91.63 %
Epoch 824 of 2000 took 0.035s
  training loss:		0.025815
  validation loss:		0.399514
  validation accuracy:		91.96 %
Epoch 825 of 2000 took 0.035s
  training loss:		0.026936
  validation loss:		0.415901
  validation accuracy:		91.74 %
Epoch 826 of 2000 took 0.035s
  training loss:		0.025514
  validation loss:		0.413662
  validation accuracy:		91.74 %
Epoch 827 of 2000 took 0.035s
  training loss:		0.025993
  validation loss:		0.416094
  validation accuracy:		92.07 %
Epoch 828 of 2000 took 0.035s
  training loss:		0.025626
  validation loss:		0.403683
  validation accuracy:		91.63 %
Epoch 829 of 2000 took 0.035s
  training loss:		0.025864
  validation loss:		0.413792
  validation accuracy:		92.17 %
Epoch 830 of 2000 took 0.035s
  training loss:		0.025319
  validation loss:		0.412796
  validation accuracy:		91.74 %
Epoch 831 of 2000 took 0.035s
  training loss:		0.026292
  validation loss:		0.415559
  validation accuracy:		92.07 %
Epoch 832 of 2000 took 0.035s
  training loss:		0.025426
  validation loss:		0.413120
  validation accuracy:		91.52 %
Epoch 833 of 2000 took 0.035s
  training loss:		0.023209
  validation loss:		0.420722
  validation accuracy:		91.74 %
Epoch 834 of 2000 took 0.035s
  training loss:		0.024871
  validation loss:		0.420809
  validation accuracy:		91.85 %
Epoch 835 of 2000 took 0.035s
  training loss:		0.025592
  validation loss:		0.412513
  validation accuracy:		91.96 %
Epoch 836 of 2000 took 0.035s
  training loss:		0.024716
  validation loss:		0.436551
  validation accuracy:		91.63 %
Epoch 837 of 2000 took 0.035s
  training loss:		0.024153
  validation loss:		0.403245
  validation accuracy:		92.61 %
Epoch 838 of 2000 took 0.035s
  training loss:		0.025721
  validation loss:		0.429603
  validation accuracy:		91.63 %
Epoch 839 of 2000 took 0.035s
  training loss:		0.024926
  validation loss:		0.404551
  validation accuracy:		92.50 %
Epoch 840 of 2000 took 0.035s
  training loss:		0.024768
  validation loss:		0.438469
  validation accuracy:		91.63 %
Epoch 841 of 2000 took 0.035s
  training loss:		0.025852
  validation loss:		0.419421
  validation accuracy:		92.07 %
Epoch 842 of 2000 took 0.035s
  training loss:		0.024767
  validation loss:		0.420810
  validation accuracy:		91.96 %
Epoch 843 of 2000 took 0.035s
  training loss:		0.024260
  validation loss:		0.419400
  validation accuracy:		91.85 %
Epoch 844 of 2000 took 0.035s
  training loss:		0.024475
  validation loss:		0.418343
  validation accuracy:		91.96 %
Epoch 845 of 2000 took 0.035s
  training loss:		0.024711
  validation loss:		0.427202
  validation accuracy:		92.07 %
Epoch 846 of 2000 took 0.035s
  training loss:		0.024555
  validation loss:		0.426640
  validation accuracy:		91.85 %
Epoch 847 of 2000 took 0.035s
  training loss:		0.024875
  validation loss:		0.423113
  validation accuracy:		92.39 %
Epoch 848 of 2000 took 0.035s
  training loss:		0.024996
  validation loss:		0.421413
  validation accuracy:		91.85 %
Epoch 849 of 2000 took 0.035s
  training loss:		0.024108
  validation loss:		0.438679
  validation accuracy:		91.52 %
Epoch 850 of 2000 took 0.035s
  training loss:		0.023779
  validation loss:		0.420194
  validation accuracy:		91.96 %
Epoch 851 of 2000 took 0.035s
  training loss:		0.024547
  validation loss:		0.421493
  validation accuracy:		91.96 %
Epoch 852 of 2000 took 0.036s
  training loss:		0.022741
  validation loss:		0.429392
  validation accuracy:		91.85 %
Epoch 853 of 2000 took 0.035s
  training loss:		0.024180
  validation loss:		0.434391
  validation accuracy:		91.52 %
Epoch 854 of 2000 took 0.035s
  training loss:		0.023920
  validation loss:		0.428733
  validation accuracy:		91.52 %
Epoch 855 of 2000 took 0.035s
  training loss:		0.023569
  validation loss:		0.426550
  validation accuracy:		91.85 %
Epoch 856 of 2000 took 0.035s
  training loss:		0.024078
  validation loss:		0.422581
  validation accuracy:		91.85 %
Epoch 857 of 2000 took 0.035s
  training loss:		0.023733
  validation loss:		0.416438
  validation accuracy:		92.07 %
Epoch 858 of 2000 took 0.035s
  training loss:		0.022393
  validation loss:		0.422372
  validation accuracy:		91.74 %
Epoch 859 of 2000 took 0.035s
  training loss:		0.023609
  validation loss:		0.449296
  validation accuracy:		91.63 %
Epoch 860 of 2000 took 0.035s
  training loss:		0.023681
  validation loss:		0.417835
  validation accuracy:		91.96 %
Epoch 861 of 2000 took 0.035s
  training loss:		0.023934
  validation loss:		0.424358
  validation accuracy:		92.07 %
Epoch 862 of 2000 took 0.035s
  training loss:		0.023802
  validation loss:		0.420310
  validation accuracy:		91.96 %
Epoch 863 of 2000 took 0.035s
  training loss:		0.023880
  validation loss:		0.418859
  validation accuracy:		92.07 %
Epoch 864 of 2000 took 0.035s
  training loss:		0.023992
  validation loss:		0.427966
  validation accuracy:		91.74 %
Epoch 865 of 2000 took 0.035s
  training loss:		0.023938
  validation loss:		0.423455
  validation accuracy:		92.07 %
Epoch 866 of 2000 took 0.035s
  training loss:		0.023274
  validation loss:		0.424496
  validation accuracy:		91.74 %
Epoch 867 of 2000 took 0.035s
  training loss:		0.023832
  validation loss:		0.427083
  validation accuracy:		91.85 %
Epoch 868 of 2000 took 0.035s
  training loss:		0.023431
  validation loss:		0.435296
  validation accuracy:		91.96 %
Epoch 869 of 2000 took 0.035s
  training loss:		0.023664
  validation loss:		0.416124
  validation accuracy:		92.28 %
Epoch 870 of 2000 took 0.035s
  training loss:		0.022997
  validation loss:		0.428658
  validation accuracy:		91.85 %
Epoch 871 of 2000 took 0.035s
  training loss:		0.023032
  validation loss:		0.430363
  validation accuracy:		91.85 %
Epoch 872 of 2000 took 0.035s
  training loss:		0.022997
  validation loss:		0.425041
  validation accuracy:		91.85 %
Epoch 873 of 2000 took 0.035s
  training loss:		0.023133
  validation loss:		0.431496
  validation accuracy:		91.96 %
Epoch 874 of 2000 took 0.035s
  training loss:		0.023539
  validation loss:		0.425156
  validation accuracy:		92.07 %
Epoch 875 of 2000 took 0.035s
  training loss:		0.021632
  validation loss:		0.451669
  validation accuracy:		91.74 %
Epoch 876 of 2000 took 0.035s
  training loss:		0.022165
  validation loss:		0.418614
  validation accuracy:		92.07 %
Epoch 877 of 2000 took 0.035s
  training loss:		0.022390
  validation loss:		0.442817
  validation accuracy:		91.63 %
Epoch 878 of 2000 took 0.035s
  training loss:		0.023770
  validation loss:		0.436038
  validation accuracy:		91.85 %
Epoch 879 of 2000 took 0.035s
  training loss:		0.022946
  validation loss:		0.444140
  validation accuracy:		91.74 %
Epoch 880 of 2000 took 0.035s
  training loss:		0.022612
  validation loss:		0.428675
  validation accuracy:		91.74 %
Epoch 881 of 2000 took 0.035s
  training loss:		0.023186
  validation loss:		0.437986
  validation accuracy:		91.96 %
Epoch 882 of 2000 took 0.035s
  training loss:		0.022698
  validation loss:		0.441222
  validation accuracy:		91.96 %
Epoch 883 of 2000 took 0.035s
  training loss:		0.022455
  validation loss:		0.440845
  validation accuracy:		91.63 %
Epoch 884 of 2000 took 0.035s
  training loss:		0.022030
  validation loss:		0.432951
  validation accuracy:		91.63 %
Epoch 885 of 2000 took 0.035s
  training loss:		0.020057
  validation loss:		0.429258
  validation accuracy:		91.96 %
Epoch 886 of 2000 took 0.035s
  training loss:		0.021604
  validation loss:		0.436627
  validation accuracy:		91.85 %
Epoch 887 of 2000 took 0.035s
  training loss:		0.022491
  validation loss:		0.425670
  validation accuracy:		92.07 %
Epoch 888 of 2000 took 0.035s
  training loss:		0.021077
  validation loss:		0.446672
  validation accuracy:		91.41 %
Epoch 889 of 2000 took 0.035s
  training loss:		0.021126
  validation loss:		0.428386
  validation accuracy:		91.96 %
Epoch 890 of 2000 took 0.035s
  training loss:		0.021703
  validation loss:		0.437347
  validation accuracy:		91.74 %
Epoch 891 of 2000 took 0.035s
  training loss:		0.021317
  validation loss:		0.440586
  validation accuracy:		91.74 %
Epoch 892 of 2000 took 0.035s
  training loss:		0.021546
  validation loss:		0.444396
  validation accuracy:		91.96 %
Epoch 893 of 2000 took 0.035s
  training loss:		0.021619
  validation loss:		0.427218
  validation accuracy:		91.85 %
Epoch 894 of 2000 took 0.035s
  training loss:		0.020503
  validation loss:		0.446091
  validation accuracy:		91.41 %
Epoch 895 of 2000 took 0.035s
  training loss:		0.021559
  validation loss:		0.440267
  validation accuracy:		91.74 %
Epoch 896 of 2000 took 0.035s
  training loss:		0.021524
  validation loss:		0.445432
  validation accuracy:		91.63 %
Epoch 897 of 2000 took 0.035s
  training loss:		0.020318
  validation loss:		0.444558
  validation accuracy:		91.63 %
Epoch 898 of 2000 took 0.035s
  training loss:		0.022812
  validation loss:		0.440710
  validation accuracy:		91.74 %
Epoch 899 of 2000 took 0.035s
  training loss:		0.021004
  validation loss:		0.442225
  validation accuracy:		91.74 %
Epoch 900 of 2000 took 0.035s
  training loss:		0.021507
  validation loss:		0.428152
  validation accuracy:		91.85 %
Epoch 901 of 2000 took 0.035s
  training loss:		0.020795
  validation loss:		0.427964
  validation accuracy:		92.28 %
Epoch 902 of 2000 took 0.035s
  training loss:		0.021790
  validation loss:		0.436100
  validation accuracy:		92.07 %
Epoch 903 of 2000 took 0.035s
  training loss:		0.020966
  validation loss:		0.442601
  validation accuracy:		91.52 %
Epoch 904 of 2000 took 0.035s
  training loss:		0.020909
  validation loss:		0.440656
  validation accuracy:		91.85 %
Epoch 905 of 2000 took 0.035s
  training loss:		0.021762
  validation loss:		0.442178
  validation accuracy:		92.07 %
Epoch 906 of 2000 took 0.035s
  training loss:		0.021673
  validation loss:		0.455169
  validation accuracy:		91.74 %
Epoch 907 of 2000 took 0.035s
  training loss:		0.020177
  validation loss:		0.454693
  validation accuracy:		91.52 %
Epoch 908 of 2000 took 0.035s
  training loss:		0.021105
  validation loss:		0.449984
  validation accuracy:		91.52 %
Epoch 909 of 2000 took 0.035s
  training loss:		0.020739
  validation loss:		0.435025
  validation accuracy:		91.96 %
Epoch 910 of 2000 took 0.035s
  training loss:		0.020791
  validation loss:		0.443714
  validation accuracy:		92.17 %
Epoch 911 of 2000 took 0.035s
  training loss:		0.020694
  validation loss:		0.438978
  validation accuracy:		91.85 %
Epoch 912 of 2000 took 0.035s
  training loss:		0.021142
  validation loss:		0.438962
  validation accuracy:		91.96 %
Epoch 913 of 2000 took 0.035s
  training loss:		0.020395
  validation loss:		0.453295
  validation accuracy:		91.52 %
Epoch 914 of 2000 took 0.035s
  training loss:		0.020878
  validation loss:		0.443523
  validation accuracy:		92.07 %
Epoch 915 of 2000 took 0.035s
  training loss:		0.021013
  validation loss:		0.449034
  validation accuracy:		91.63 %
Epoch 916 of 2000 took 0.035s
  training loss:		0.020302
  validation loss:		0.444092
  validation accuracy:		91.85 %
Epoch 917 of 2000 took 0.035s
  training loss:		0.020710
  validation loss:		0.452879
  validation accuracy:		91.41 %
Epoch 918 of 2000 took 0.035s
  training loss:		0.020137
  validation loss:		0.440267
  validation accuracy:		92.07 %
Epoch 919 of 2000 took 0.035s
  training loss:		0.019656
  validation loss:		0.454922
  validation accuracy:		91.63 %
Epoch 920 of 2000 took 0.035s
  training loss:		0.020719
  validation loss:		0.440967
  validation accuracy:		91.96 %
Epoch 921 of 2000 took 0.035s
  training loss:		0.019489
  validation loss:		0.440225
  validation accuracy:		91.41 %
Epoch 922 of 2000 took 0.035s
  training loss:		0.020532
  validation loss:		0.450318
  validation accuracy:		91.52 %
Epoch 923 of 2000 took 0.035s
  training loss:		0.019981
  validation loss:		0.442748
  validation accuracy:		91.74 %
Epoch 924 of 2000 took 0.035s
  training loss:		0.019375
  validation loss:		0.442916
  validation accuracy:		91.85 %
Epoch 925 of 2000 took 0.035s
  training loss:		0.018482
  validation loss:		0.445271
  validation accuracy:		91.96 %
Epoch 926 of 2000 took 0.035s
  training loss:		0.019595
  validation loss:		0.441226
  validation accuracy:		91.85 %
Epoch 927 of 2000 took 0.035s
  training loss:		0.020300
  validation loss:		0.452375
  validation accuracy:		91.63 %
Epoch 928 of 2000 took 0.035s
  training loss:		0.020307
  validation loss:		0.456613
  validation accuracy:		91.74 %
Epoch 929 of 2000 took 0.035s
  training loss:		0.019516
  validation loss:		0.456610
  validation accuracy:		91.63 %
Epoch 930 of 2000 took 0.035s
  training loss:		0.019456
  validation loss:		0.442832
  validation accuracy:		92.39 %
Epoch 931 of 2000 took 0.035s
  training loss:		0.019787
  validation loss:		0.456334
  validation accuracy:		91.63 %
Epoch 932 of 2000 took 0.035s
  training loss:		0.019313
  validation loss:		0.444679
  validation accuracy:		92.07 %
Epoch 933 of 2000 took 0.035s
  training loss:		0.019506
  validation loss:		0.441575
  validation accuracy:		91.85 %
Epoch 934 of 2000 took 0.035s
  training loss:		0.019594
  validation loss:		0.455448
  validation accuracy:		91.52 %
Epoch 935 of 2000 took 0.035s
  training loss:		0.019553
  validation loss:		0.443961
  validation accuracy:		92.07 %
Epoch 936 of 2000 took 0.035s
  training loss:		0.019528
  validation loss:		0.454267
  validation accuracy:		91.63 %
Epoch 937 of 2000 took 0.035s
  training loss:		0.019547
  validation loss:		0.457683
  validation accuracy:		91.74 %
Epoch 938 of 2000 took 0.035s
  training loss:		0.019297
  validation loss:		0.451225
  validation accuracy:		91.63 %
Epoch 939 of 2000 took 0.035s
  training loss:		0.019108
  validation loss:		0.444744
  validation accuracy:		92.28 %
Epoch 940 of 2000 took 0.035s
  training loss:		0.018844
  validation loss:		0.442924
  validation accuracy:		91.96 %
Epoch 941 of 2000 took 0.035s
  training loss:		0.019289
  validation loss:		0.444313
  validation accuracy:		91.85 %
Epoch 942 of 2000 took 0.035s
  training loss:		0.019377
  validation loss:		0.446136
  validation accuracy:		92.07 %
Epoch 943 of 2000 took 0.035s
  training loss:		0.019527
  validation loss:		0.446476
  validation accuracy:		91.85 %
Epoch 944 of 2000 took 0.035s
  training loss:		0.018956
  validation loss:		0.459679
  validation accuracy:		91.85 %
Epoch 945 of 2000 took 0.035s
  training loss:		0.019328
  validation loss:		0.452437
  validation accuracy:		91.85 %
Epoch 946 of 2000 took 0.035s
  training loss:		0.019084
  validation loss:		0.451807
  validation accuracy:		91.96 %
Epoch 947 of 2000 took 0.035s
  training loss:		0.018733
  validation loss:		0.454541
  validation accuracy:		91.52 %
Epoch 948 of 2000 took 0.035s
  training loss:		0.016614
  validation loss:		0.457828
  validation accuracy:		91.52 %
Epoch 949 of 2000 took 0.035s
  training loss:		0.018920
  validation loss:		0.453720
  validation accuracy:		92.07 %
Epoch 950 of 2000 took 0.035s
  training loss:		0.018866
  validation loss:		0.440761
  validation accuracy:		92.17 %
Epoch 951 of 2000 took 0.035s
  training loss:		0.018301
  validation loss:		0.465135
  validation accuracy:		91.41 %
Epoch 952 of 2000 took 0.035s
  training loss:		0.017028
  validation loss:		0.449992
  validation accuracy:		91.85 %
Epoch 953 of 2000 took 0.035s
  training loss:		0.018634
  validation loss:		0.463920
  validation accuracy:		91.52 %
Epoch 954 of 2000 took 0.035s
  training loss:		0.018812
  validation loss:		0.463886
  validation accuracy:		91.63 %
Epoch 955 of 2000 took 0.035s
  training loss:		0.018243
  validation loss:		0.460787
  validation accuracy:		91.85 %
Epoch 956 of 2000 took 0.035s
  training loss:		0.018467
  validation loss:		0.461953
  validation accuracy:		91.30 %
Epoch 957 of 2000 took 0.035s
  training loss:		0.017078
  validation loss:		0.444072
  validation accuracy:		91.74 %
Epoch 958 of 2000 took 0.035s
  training loss:		0.017781
  validation loss:		0.462575
  validation accuracy:		91.52 %
Epoch 959 of 2000 took 0.035s
  training loss:		0.016870
  validation loss:		0.451015
  validation accuracy:		91.63 %
Epoch 960 of 2000 took 0.035s
  training loss:		0.018370
  validation loss:		0.464022
  validation accuracy:		91.52 %
Epoch 961 of 2000 took 0.035s
  training loss:		0.017637
  validation loss:		0.451702
  validation accuracy:		91.52 %
Epoch 962 of 2000 took 0.035s
  training loss:		0.018046
  validation loss:		0.455647
  validation accuracy:		91.85 %
Epoch 963 of 2000 took 0.035s
  training loss:		0.018163
  validation loss:		0.459700
  validation accuracy:		92.07 %
Epoch 964 of 2000 took 0.035s
  training loss:		0.017115
  validation loss:		0.465569
  validation accuracy:		91.30 %
Epoch 965 of 2000 took 0.035s
  training loss:		0.018655
  validation loss:		0.462616
  validation accuracy:		91.74 %
Epoch 966 of 2000 took 0.035s
  training loss:		0.017973
  validation loss:		0.453172
  validation accuracy:		91.85 %
Epoch 967 of 2000 took 0.035s
  training loss:		0.017760
  validation loss:		0.467207
  validation accuracy:		91.63 %
Epoch 968 of 2000 took 0.035s
  training loss:		0.019208
  validation loss:		0.460547
  validation accuracy:		91.85 %
Epoch 969 of 2000 took 0.035s
  training loss:		0.017633
  validation loss:		0.466705
  validation accuracy:		91.41 %
Epoch 970 of 2000 took 0.035s
  training loss:		0.017897
  validation loss:		0.462189
  validation accuracy:		91.41 %
Epoch 971 of 2000 took 0.036s
  training loss:		0.018483
  validation loss:		0.465051
  validation accuracy:		91.41 %
Epoch 972 of 2000 took 0.035s
  training loss:		0.018211
  validation loss:		0.468575
  validation accuracy:		91.52 %
Epoch 973 of 2000 took 0.035s
  training loss:		0.017818
  validation loss:		0.461439
  validation accuracy:		91.96 %
Epoch 974 of 2000 took 0.035s
  training loss:		0.016399
  validation loss:		0.462267
  validation accuracy:		91.63 %
Epoch 975 of 2000 took 0.035s
  training loss:		0.016531
  validation loss:		0.468009
  validation accuracy:		91.41 %
Epoch 976 of 2000 took 0.035s
  training loss:		0.017368
  validation loss:		0.455356
  validation accuracy:		91.74 %
Epoch 977 of 2000 took 0.035s
  training loss:		0.017652
  validation loss:		0.454809
  validation accuracy:		91.85 %
Epoch 978 of 2000 took 0.035s
  training loss:		0.017368
  validation loss:		0.468023
  validation accuracy:		91.96 %
Epoch 979 of 2000 took 0.035s
  training loss:		0.017130
  validation loss:		0.459474
  validation accuracy:		91.85 %
Epoch 980 of 2000 took 0.035s
  training loss:		0.016842
  validation loss:		0.474223
  validation accuracy:		91.41 %
Epoch 981 of 2000 took 0.035s
  training loss:		0.017085
  validation loss:		0.457682
  validation accuracy:		91.85 %
Epoch 982 of 2000 took 0.035s
  training loss:		0.016597
  validation loss:		0.462916
  validation accuracy:		91.74 %
Epoch 983 of 2000 took 0.035s
  training loss:		0.015328
  validation loss:		0.459822
  validation accuracy:		91.74 %
Epoch 984 of 2000 took 0.035s
  training loss:		0.017561
  validation loss:		0.467899
  validation accuracy:		91.30 %
Epoch 985 of 2000 took 0.035s
  training loss:		0.016908
  validation loss:		0.462282
  validation accuracy:		91.96 %
Epoch 986 of 2000 took 0.035s
  training loss:		0.017142
  validation loss:		0.465669
  validation accuracy:		91.63 %
Epoch 987 of 2000 took 0.035s
  training loss:		0.014790
  validation loss:		0.461079
  validation accuracy:		91.52 %
Epoch 988 of 2000 took 0.035s
  training loss:		0.017109
  validation loss:		0.466952
  validation accuracy:		91.63 %
Epoch 989 of 2000 took 0.035s
  training loss:		0.016771
  validation loss:		0.457592
  validation accuracy:		92.07 %
Epoch 990 of 2000 took 0.035s
  training loss:		0.017012
  validation loss:		0.464453
  validation accuracy:		91.63 %
Epoch 991 of 2000 took 0.035s
  training loss:		0.017090
  validation loss:		0.478730
  validation accuracy:		91.41 %
Epoch 992 of 2000 took 0.035s
  training loss:		0.016910
  validation loss:		0.462164
  validation accuracy:		91.63 %
Epoch 993 of 2000 took 0.035s
  training loss:		0.017025
  validation loss:		0.459794
  validation accuracy:		91.96 %
Epoch 994 of 2000 took 0.035s
  training loss:		0.017133
  validation loss:		0.462414
  validation accuracy:		91.85 %
Epoch 995 of 2000 took 0.035s
  training loss:		0.017304
  validation loss:		0.468209
  validation accuracy:		91.74 %
Epoch 996 of 2000 took 0.035s
  training loss:		0.017243
  validation loss:		0.470715
  validation accuracy:		91.41 %
Epoch 997 of 2000 took 0.035s
  training loss:		0.015679
  validation loss:		0.462494
  validation accuracy:		91.96 %
Epoch 998 of 2000 took 0.035s
  training loss:		0.016167
  validation loss:		0.472789
  validation accuracy:		91.41 %
Epoch 999 of 2000 took 0.035s
  training loss:		0.016355
  validation loss:		0.468086
  validation accuracy:		91.85 %
Epoch 1000 of 2000 took 0.035s
  training loss:		0.017070
  validation loss:		0.480799
  validation accuracy:		91.30 %
Epoch 1001 of 2000 took 0.035s
  training loss:		0.017076
  validation loss:		0.464751
  validation accuracy:		91.74 %
Epoch 1002 of 2000 took 0.035s
  training loss:		0.016631
  validation loss:		0.469842
  validation accuracy:		91.52 %
Epoch 1003 of 2000 took 0.035s
  training loss:		0.015955
  validation loss:		0.464814
  validation accuracy:		91.30 %
Epoch 1004 of 2000 took 0.035s
  training loss:		0.016748
  validation loss:		0.469080
  validation accuracy:		92.07 %
Epoch 1005 of 2000 took 0.035s
  training loss:		0.016253
  validation loss:		0.486296
  validation accuracy:		91.09 %
Epoch 1006 of 2000 took 0.035s
  training loss:		0.016529
  validation loss:		0.464535
  validation accuracy:		91.96 %
Epoch 1007 of 2000 took 0.035s
  training loss:		0.016100
  validation loss:		0.468804
  validation accuracy:		91.74 %
Epoch 1008 of 2000 took 0.035s
  training loss:		0.016230
  validation loss:		0.467101
  validation accuracy:		91.41 %
Epoch 1009 of 2000 took 0.035s
  training loss:		0.015418
  validation loss:		0.474256
  validation accuracy:		91.52 %
Epoch 1010 of 2000 took 0.035s
  training loss:		0.016184
  validation loss:		0.473845
  validation accuracy:		91.63 %
Epoch 1011 of 2000 took 0.035s
  training loss:		0.015769
  validation loss:		0.480408
  validation accuracy:		91.09 %
Epoch 1012 of 2000 took 0.035s
  training loss:		0.016358
  validation loss:		0.471879
  validation accuracy:		91.85 %
Epoch 1013 of 2000 took 0.035s
  training loss:		0.016209
  validation loss:		0.478317
  validation accuracy:		91.30 %
Epoch 1014 of 2000 took 0.035s
  training loss:		0.016406
  validation loss:		0.482168
  validation accuracy:		91.20 %
Epoch 1015 of 2000 took 0.035s
  training loss:		0.016045
  validation loss:		0.474202
  validation accuracy:		91.30 %
Epoch 1016 of 2000 took 0.035s
  training loss:		0.016147
  validation loss:		0.467831
  validation accuracy:		91.74 %
Epoch 1017 of 2000 took 0.035s
  training loss:		0.015211
  validation loss:		0.465153
  validation accuracy:		91.85 %
Epoch 1018 of 2000 took 0.035s
  training loss:		0.015877
  validation loss:		0.474708
  validation accuracy:		91.74 %
Epoch 1019 of 2000 took 0.035s
  training loss:		0.016150
  validation loss:		0.481891
  validation accuracy:		91.74 %
Epoch 1020 of 2000 took 0.035s
  training loss:		0.016291
  validation loss:		0.468405
  validation accuracy:		92.07 %
Epoch 1021 of 2000 took 0.035s
  training loss:		0.016197
  validation loss:		0.481301
  validation accuracy:		91.41 %
Epoch 1022 of 2000 took 0.035s
  training loss:		0.016250
  validation loss:		0.475310
  validation accuracy:		91.63 %
Epoch 1023 of 2000 took 0.035s
  training loss:		0.015882
  validation loss:		0.474620
  validation accuracy:		91.63 %
Epoch 1024 of 2000 took 0.035s
  training loss:		0.015178
  validation loss:		0.481551
  validation accuracy:		91.63 %
Epoch 1025 of 2000 took 0.035s
  training loss:		0.015078
  validation loss:		0.473794
  validation accuracy:		91.52 %
Epoch 1026 of 2000 took 0.035s
  training loss:		0.015498
  validation loss:		0.478950
  validation accuracy:		91.41 %
Epoch 1027 of 2000 took 0.035s
  training loss:		0.015389
  validation loss:		0.477739
  validation accuracy:		91.52 %
Epoch 1028 of 2000 took 0.035s
  training loss:		0.015003
  validation loss:		0.486877
  validation accuracy:		91.52 %
Epoch 1029 of 2000 took 0.035s
  training loss:		0.015252
  validation loss:		0.474122
  validation accuracy:		91.52 %
Epoch 1030 of 2000 took 0.035s
  training loss:		0.015471
  validation loss:		0.471667
  validation accuracy:		91.85 %
Epoch 1031 of 2000 took 0.035s
  training loss:		0.015065
  validation loss:		0.473797
  validation accuracy:		92.07 %
Epoch 1032 of 2000 took 0.035s
  training loss:		0.014925
  validation loss:		0.488774
  validation accuracy:		91.09 %
Epoch 1033 of 2000 took 0.035s
  training loss:		0.014073
  validation loss:		0.474081
  validation accuracy:		91.85 %
Epoch 1034 of 2000 took 0.035s
  training loss:		0.014362
  validation loss:		0.476851
  validation accuracy:		91.41 %
Epoch 1035 of 2000 took 0.035s
  training loss:		0.014628
  validation loss:		0.477036
  validation accuracy:		91.41 %
Epoch 1036 of 2000 took 0.035s
  training loss:		0.015267
  validation loss:		0.493078
  validation accuracy:		91.41 %
Epoch 1037 of 2000 took 0.035s
  training loss:		0.015287
  validation loss:		0.472385
  validation accuracy:		91.63 %
Epoch 1038 of 2000 took 0.035s
  training loss:		0.014857
  validation loss:		0.490932
  validation accuracy:		91.09 %
Epoch 1039 of 2000 took 0.035s
  training loss:		0.014752
  validation loss:		0.474521
  validation accuracy:		91.74 %
Epoch 1040 of 2000 took 0.035s
  training loss:		0.014791
  validation loss:		0.491455
  validation accuracy:		91.30 %
Epoch 1041 of 2000 took 0.035s
  training loss:		0.014867
  validation loss:		0.479517
  validation accuracy:		91.20 %
Epoch 1042 of 2000 took 0.035s
  training loss:		0.014816
  validation loss:		0.485891
  validation accuracy:		91.52 %
Epoch 1043 of 2000 took 0.035s
  training loss:		0.013492
  validation loss:		0.485683
  validation accuracy:		91.41 %
Epoch 1044 of 2000 took 0.035s
  training loss:		0.014687
  validation loss:		0.485823
  validation accuracy:		91.52 %
Epoch 1045 of 2000 took 0.035s
  training loss:		0.015135
  validation loss:		0.490701
  validation accuracy:		91.30 %
Epoch 1046 of 2000 took 0.035s
  training loss:		0.014591
  validation loss:		0.485602
  validation accuracy:		91.41 %
Epoch 1047 of 2000 took 0.035s
  training loss:		0.014487
  validation loss:		0.489145
  validation accuracy:		91.74 %
Epoch 1048 of 2000 took 0.035s
  training loss:		0.014281
  validation loss:		0.487422
  validation accuracy:		90.87 %
Epoch 1049 of 2000 took 0.035s
  training loss:		0.014784
  validation loss:		0.483256
  validation accuracy:		91.74 %
Epoch 1050 of 2000 took 0.035s
  training loss:		0.015045
  validation loss:		0.484627
  validation accuracy:		91.30 %
Epoch 1051 of 2000 took 0.035s
  training loss:		0.014628
  validation loss:		0.475694
  validation accuracy:		91.74 %
Epoch 1052 of 2000 took 0.035s
  training loss:		0.014538
  validation loss:		0.485398
  validation accuracy:		91.52 %
Epoch 1053 of 2000 took 0.035s
  training loss:		0.014508
  validation loss:		0.477860
  validation accuracy:		91.52 %
Epoch 1054 of 2000 took 0.035s
  training loss:		0.015002
  validation loss:		0.482697
  validation accuracy:		91.74 %
Epoch 1055 of 2000 took 0.035s
  training loss:		0.014214
  validation loss:		0.484406
  validation accuracy:		91.30 %
Epoch 1056 of 2000 took 0.035s
  training loss:		0.013179
  validation loss:		0.486898
  validation accuracy:		91.41 %
Epoch 1057 of 2000 took 0.036s
  training loss:		0.014085
  validation loss:		0.485209
  validation accuracy:		91.52 %
Epoch 1058 of 2000 took 0.035s
  training loss:		0.013746
  validation loss:		0.477768
  validation accuracy:		91.41 %
Epoch 1059 of 2000 took 0.035s
  training loss:		0.014118
  validation loss:		0.491759
  validation accuracy:		91.41 %
Epoch 1060 of 2000 took 0.035s
  training loss:		0.014393
  validation loss:		0.487298
  validation accuracy:		91.52 %
Epoch 1061 of 2000 took 0.035s
  training loss:		0.014229
  validation loss:		0.493213
  validation accuracy:		91.74 %
Epoch 1062 of 2000 took 0.035s
  training loss:		0.012690
  validation loss:		0.475969
  validation accuracy:		91.63 %
Epoch 1063 of 2000 took 0.035s
  training loss:		0.013535
  validation loss:		0.497336
  validation accuracy:		91.30 %
Epoch 1064 of 2000 took 0.035s
  training loss:		0.012863
  validation loss:		0.489844
  validation accuracy:		91.52 %
Epoch 1065 of 2000 took 0.035s
  training loss:		0.013959
  validation loss:		0.495629
  validation accuracy:		91.41 %
Epoch 1066 of 2000 took 0.035s
  training loss:		0.014131
  validation loss:		0.482163
  validation accuracy:		91.41 %
Epoch 1067 of 2000 took 0.035s
  training loss:		0.013963
  validation loss:		0.491799
  validation accuracy:		91.52 %
Epoch 1068 of 2000 took 0.035s
  training loss:		0.014411
  validation loss:		0.484689
  validation accuracy:		91.30 %
Epoch 1069 of 2000 took 0.035s
  training loss:		0.014188
  validation loss:		0.491998
  validation accuracy:		91.52 %
Epoch 1070 of 2000 took 0.035s
  training loss:		0.012302
  validation loss:		0.494087
  validation accuracy:		91.74 %
Epoch 1071 of 2000 took 0.035s
  training loss:		0.013963
  validation loss:		0.495566
  validation accuracy:		91.41 %
Epoch 1072 of 2000 took 0.035s
  training loss:		0.013387
  validation loss:		0.490801
  validation accuracy:		91.30 %
Epoch 1073 of 2000 took 0.035s
  training loss:		0.014117
  validation loss:		0.499198
  validation accuracy:		91.41 %
Epoch 1074 of 2000 took 0.035s
  training loss:		0.012700
  validation loss:		0.497122
  validation accuracy:		91.41 %
Epoch 1075 of 2000 took 0.035s
  training loss:		0.014029
  validation loss:		0.499432
  validation accuracy:		91.20 %
Epoch 1076 of 2000 took 0.035s
  training loss:		0.014385
  validation loss:		0.497013
  validation accuracy:		91.52 %
Epoch 1077 of 2000 took 0.035s
  training loss:		0.013207
  validation loss:		0.479282
  validation accuracy:		91.96 %
Epoch 1078 of 2000 took 0.035s
  training loss:		0.013834
  validation loss:		0.505367
  validation accuracy:		91.20 %
Epoch 1079 of 2000 took 0.036s
  training loss:		0.013784
  validation loss:		0.489626
  validation accuracy:		91.85 %
Epoch 1080 of 2000 took 0.035s
  training loss:		0.013493
  validation loss:		0.486105
  validation accuracy:		91.52 %
Epoch 1081 of 2000 took 0.035s
  training loss:		0.013170
  validation loss:		0.483178
  validation accuracy:		92.07 %
Epoch 1082 of 2000 took 0.035s
  training loss:		0.013509
  validation loss:		0.505520
  validation accuracy:		91.20 %
Epoch 1083 of 2000 took 0.035s
  training loss:		0.013321
  validation loss:		0.496713
  validation accuracy:		91.74 %
Epoch 1084 of 2000 took 0.035s
  training loss:		0.013328
  validation loss:		0.490054
  validation accuracy:		91.74 %
Epoch 1085 of 2000 took 0.035s
  training loss:		0.013229
  validation loss:		0.493147
  validation accuracy:		91.63 %
Epoch 1086 of 2000 took 0.035s
  training loss:		0.013627
  validation loss:		0.489816
  validation accuracy:		91.63 %
Epoch 1087 of 2000 took 0.035s
  training loss:		0.012848
  validation loss:		0.498375
  validation accuracy:		91.30 %
Epoch 1088 of 2000 took 0.035s
  training loss:		0.013381
  validation loss:		0.496657
  validation accuracy:		91.74 %
Epoch 1089 of 2000 took 0.035s
  training loss:		0.013272
  validation loss:		0.486090
  validation accuracy:		91.74 %
Epoch 1090 of 2000 took 0.035s
  training loss:		0.013675
  validation loss:		0.495033
  validation accuracy:		91.96 %
Epoch 1091 of 2000 took 0.035s
  training loss:		0.013508
  validation loss:		0.496257
  validation accuracy:		91.41 %
Epoch 1092 of 2000 took 0.035s
  training loss:		0.013286
  validation loss:		0.493229
  validation accuracy:		91.52 %
Epoch 1093 of 2000 took 0.035s
  training loss:		0.013130
  validation loss:		0.503644
  validation accuracy:		91.30 %
Epoch 1094 of 2000 took 0.035s
  training loss:		0.013199
  validation loss:		0.489328
  validation accuracy:		91.85 %
Epoch 1095 of 2000 took 0.035s
  training loss:		0.013084
  validation loss:		0.495962
  validation accuracy:		91.41 %
Epoch 1096 of 2000 took 0.035s
  training loss:		0.012800
  validation loss:		0.504798
  validation accuracy:		91.20 %
Epoch 1097 of 2000 took 0.035s
  training loss:		0.011879
  validation loss:		0.490291
  validation accuracy:		91.63 %
Epoch 1098 of 2000 took 0.035s
  training loss:		0.012958
  validation loss:		0.494364
  validation accuracy:		91.85 %
Epoch 1099 of 2000 took 0.035s
  training loss:		0.013069
  validation loss:		0.498898
  validation accuracy:		91.30 %
Epoch 1100 of 2000 took 0.035s
  training loss:		0.011946
  validation loss:		0.494962
  validation accuracy:		91.41 %
Epoch 1101 of 2000 took 0.035s
  training loss:		0.012884
  validation loss:		0.501173
  validation accuracy:		91.63 %
Epoch 1102 of 2000 took 0.035s
  training loss:		0.012836
  validation loss:		0.493116
  validation accuracy:		91.52 %
Epoch 1103 of 2000 took 0.035s
  training loss:		0.012675
  validation loss:		0.507203
  validation accuracy:		91.30 %
Epoch 1104 of 2000 took 0.035s
  training loss:		0.012009
  validation loss:		0.503307
  validation accuracy:		91.41 %
Epoch 1105 of 2000 took 0.035s
  training loss:		0.013029
  validation loss:		0.507290
  validation accuracy:		91.30 %
Epoch 1106 of 2000 took 0.035s
  training loss:		0.013079
  validation loss:		0.487905
  validation accuracy:		91.41 %
Epoch 1107 of 2000 took 0.035s
  training loss:		0.012919
  validation loss:		0.510550
  validation accuracy:		91.20 %
Epoch 1108 of 2000 took 0.035s
  training loss:		0.012799
  validation loss:		0.502906
  validation accuracy:		91.30 %
Epoch 1109 of 2000 took 0.035s
  training loss:		0.012599
  validation loss:		0.494428
  validation accuracy:		91.20 %
Epoch 1110 of 2000 took 0.035s
  training loss:		0.012212
  validation loss:		0.493813
  validation accuracy:		91.52 %
Epoch 1111 of 2000 took 0.035s
  training loss:		0.013087
  validation loss:		0.512677
  validation accuracy:		91.20 %
Epoch 1112 of 2000 took 0.035s
  training loss:		0.012604
  validation loss:		0.511836
  validation accuracy:		91.41 %
Epoch 1113 of 2000 took 0.035s
  training loss:		0.012395
  validation loss:		0.500521
  validation accuracy:		91.30 %
Epoch 1114 of 2000 took 0.035s
  training loss:		0.012602
  validation loss:		0.504027
  validation accuracy:		91.52 %
Epoch 1115 of 2000 took 0.035s
  training loss:		0.012874
  validation loss:		0.505131
  validation accuracy:		91.52 %
Epoch 1116 of 2000 took 0.035s
  training loss:		0.011984
  validation loss:		0.496506
  validation accuracy:		91.63 %
Epoch 1117 of 2000 took 0.035s
  training loss:		0.012858
  validation loss:		0.510850
  validation accuracy:		91.30 %
Epoch 1118 of 2000 took 0.035s
  training loss:		0.012316
  validation loss:		0.500548
  validation accuracy:		91.20 %
Epoch 1119 of 2000 took 0.035s
  training loss:		0.012470
  validation loss:		0.499415
  validation accuracy:		91.85 %
Epoch 1120 of 2000 took 0.035s
  training loss:		0.011201
  validation loss:		0.506868
  validation accuracy:		91.41 %
Epoch 1121 of 2000 took 0.035s
  training loss:		0.012576
  validation loss:		0.491152
  validation accuracy:		91.85 %
Epoch 1122 of 2000 took 0.035s
  training loss:		0.012129
  validation loss:		0.502059
  validation accuracy:		91.30 %
Epoch 1123 of 2000 took 0.035s
  training loss:		0.011160
  validation loss:		0.494446
  validation accuracy:		91.63 %
Epoch 1124 of 2000 took 0.035s
  training loss:		0.012340
  validation loss:		0.503202
  validation accuracy:		91.52 %
Epoch 1125 of 2000 took 0.035s
  training loss:		0.011948
  validation loss:		0.507515
  validation accuracy:		91.30 %
Epoch 1126 of 2000 took 0.035s
  training loss:		0.011496
  validation loss:		0.501796
  validation accuracy:		91.30 %
Epoch 1127 of 2000 took 0.035s
  training loss:		0.011837
  validation loss:		0.508741
  validation accuracy:		91.52 %
Epoch 1128 of 2000 took 0.035s
  training loss:		0.012510
  validation loss:		0.512348
  validation accuracy:		91.30 %
Epoch 1129 of 2000 took 0.035s
  training loss:		0.011907
  validation loss:		0.505919
  validation accuracy:		91.41 %
Epoch 1130 of 2000 took 0.035s
  training loss:		0.011997
  validation loss:		0.509364
  validation accuracy:		91.30 %
Epoch 1131 of 2000 took 0.035s
  training loss:		0.012077
  validation loss:		0.510538
  validation accuracy:		91.52 %
Epoch 1132 of 2000 took 0.035s
  training loss:		0.012026
  validation loss:		0.501757
  validation accuracy:		91.30 %
Epoch 1133 of 2000 took 0.035s
  training loss:		0.011963
  validation loss:		0.489885
  validation accuracy:		92.28 %
Epoch 1134 of 2000 took 0.035s
  training loss:		0.012254
  validation loss:		0.509834
  validation accuracy:		91.41 %
Epoch 1135 of 2000 took 0.035s
  training loss:		0.011653
  validation loss:		0.509039
  validation accuracy:		91.41 %
Epoch 1136 of 2000 took 0.035s
  training loss:		0.012350
  validation loss:		0.504160
  validation accuracy:		91.52 %
Epoch 1137 of 2000 took 0.035s
  training loss:		0.011879
  validation loss:		0.517976
  validation accuracy:		91.20 %
Epoch 1138 of 2000 took 0.035s
  training loss:		0.010917
  validation loss:		0.507762
  validation accuracy:		91.63 %
Epoch 1139 of 2000 took 0.035s
  training loss:		0.011372
  validation loss:		0.505177
  validation accuracy:		91.52 %
Epoch 1140 of 2000 took 0.035s
  training loss:		0.011437
  validation loss:		0.516679
  validation accuracy:		91.30 %
Epoch 1141 of 2000 took 0.035s
  training loss:		0.011948
  validation loss:		0.521327
  validation accuracy:		91.20 %
Epoch 1142 of 2000 took 0.035s
  training loss:		0.012141
  validation loss:		0.508098
  validation accuracy:		91.30 %
Epoch 1143 of 2000 took 0.035s
  training loss:		0.010535
  validation loss:		0.504872
  validation accuracy:		91.74 %
Epoch 1144 of 2000 took 0.035s
  training loss:		0.009865
  validation loss:		0.525665
  validation accuracy:		91.41 %
Epoch 1145 of 2000 took 0.035s
  training loss:		0.011564
  validation loss:		0.503193
  validation accuracy:		91.20 %
Epoch 1146 of 2000 took 0.035s
  training loss:		0.011458
  validation loss:		0.500903
  validation accuracy:		91.85 %
Epoch 1147 of 2000 took 0.035s
  training loss:		0.011994
  validation loss:		0.516484
  validation accuracy:		91.30 %
Epoch 1148 of 2000 took 0.035s
  training loss:		0.011369
  validation loss:		0.503019
  validation accuracy:		91.63 %
Epoch 1149 of 2000 took 0.035s
  training loss:		0.011457
  validation loss:		0.518418
  validation accuracy:		91.30 %
Epoch 1150 of 2000 took 0.035s
  training loss:		0.011607
  validation loss:		0.514570
  validation accuracy:		91.41 %
Epoch 1151 of 2000 took 0.035s
  training loss:		0.011557
  validation loss:		0.513102
  validation accuracy:		91.41 %
Epoch 1152 of 2000 took 0.035s
  training loss:		0.011537
  validation loss:		0.513188
  validation accuracy:		91.96 %
Epoch 1153 of 2000 took 0.035s
  training loss:		0.011605
  validation loss:		0.509614
  validation accuracy:		91.30 %
Epoch 1154 of 2000 took 0.035s
  training loss:		0.011309
  validation loss:		0.508743
  validation accuracy:		91.96 %
Epoch 1155 of 2000 took 0.035s
  training loss:		0.011227
  validation loss:		0.508894
  validation accuracy:		91.85 %
Epoch 1156 of 2000 took 0.035s
  training loss:		0.011171
  validation loss:		0.509530
  validation accuracy:		91.52 %
Epoch 1157 of 2000 took 0.035s
  training loss:		0.011651
  validation loss:		0.521215
  validation accuracy:		91.41 %
Epoch 1158 of 2000 took 0.035s
  training loss:		0.011006
  validation loss:		0.513999
  validation accuracy:		91.52 %
Epoch 1159 of 2000 took 0.035s
  training loss:		0.011178
  validation loss:		0.516431
  validation accuracy:		91.30 %
Epoch 1160 of 2000 took 0.035s
  training loss:		0.011130
  validation loss:		0.523156
  validation accuracy:		91.30 %
Epoch 1161 of 2000 took 0.035s
  training loss:		0.011235
  validation loss:		0.523547
  validation accuracy:		91.63 %
Epoch 1162 of 2000 took 0.035s
  training loss:		0.011105
  validation loss:		0.516227
  validation accuracy:		91.52 %
Epoch 1163 of 2000 took 0.035s
  training loss:		0.010953
  validation loss:		0.527825
  validation accuracy:		91.30 %
Epoch 1164 of 2000 took 0.035s
  training loss:		0.011327
  validation loss:		0.518336
  validation accuracy:		91.41 %
Epoch 1165 of 2000 took 0.035s
  training loss:		0.011213
  validation loss:		0.518659
  validation accuracy:		91.09 %
Epoch 1166 of 2000 took 0.035s
  training loss:		0.010003
  validation loss:		0.516435
  validation accuracy:		91.74 %
Epoch 1167 of 2000 took 0.035s
  training loss:		0.010990
  validation loss:		0.514310
  validation accuracy:		91.30 %
Epoch 1168 of 2000 took 0.035s
  training loss:		0.010928
  validation loss:		0.513891
  validation accuracy:		91.52 %
Epoch 1169 of 2000 took 0.035s
  training loss:		0.011012
  validation loss:		0.522628
  validation accuracy:		91.52 %
Epoch 1170 of 2000 took 0.035s
  training loss:		0.011177
  validation loss:		0.512945
  validation accuracy:		91.41 %
Epoch 1171 of 2000 took 0.035s
  training loss:		0.010182
  validation loss:		0.531958
  validation accuracy:		91.20 %
Epoch 1172 of 2000 took 0.035s
  training loss:		0.010802
  validation loss:		0.512959
  validation accuracy:		91.63 %
Epoch 1173 of 2000 took 0.035s
  training loss:		0.011148
  validation loss:		0.519748
  validation accuracy:		91.52 %
Epoch 1174 of 2000 took 0.035s
  training loss:		0.011136
  validation loss:		0.519118
  validation accuracy:		91.41 %
Epoch 1175 of 2000 took 0.035s
  training loss:		0.010792
  validation loss:		0.513830
  validation accuracy:		91.74 %
Epoch 1176 of 2000 took 0.035s
  training loss:		0.010603
  validation loss:		0.518004
  validation accuracy:		91.30 %
Epoch 1177 of 2000 took 0.035s
  training loss:		0.010774
  validation loss:		0.534333
  validation accuracy:		91.52 %
Epoch 1178 of 2000 took 0.035s
  training loss:		0.011071
  validation loss:		0.516966
  validation accuracy:		91.85 %
Epoch 1179 of 2000 took 0.035s
  training loss:		0.010937
  validation loss:		0.512386
  validation accuracy:		91.52 %
Epoch 1180 of 2000 took 0.035s
  training loss:		0.010676
  validation loss:		0.520558
  validation accuracy:		91.41 %
Epoch 1181 of 2000 took 0.035s
  training loss:		0.010694
  validation loss:		0.515438
  validation accuracy:		91.63 %
Epoch 1182 of 2000 took 0.035s
  training loss:		0.010093
  validation loss:		0.525277
  validation accuracy:		91.52 %
Epoch 1183 of 2000 took 0.035s
  training loss:		0.011000
  validation loss:		0.528163
  validation accuracy:		91.30 %
Epoch 1184 of 2000 took 0.035s
  training loss:		0.010679
  validation loss:		0.524189
  validation accuracy:		91.41 %
Epoch 1185 of 2000 took 0.035s
  training loss:		0.010563
  validation loss:		0.518307
  validation accuracy:		91.30 %
Epoch 1186 of 2000 took 0.035s
  training loss:		0.010479
  validation loss:		0.519967
  validation accuracy:		91.52 %
Epoch 1187 of 2000 took 0.035s
  training loss:		0.010557
  validation loss:		0.513727
  validation accuracy:		91.85 %
Epoch 1188 of 2000 took 0.035s
  training loss:		0.010469
  validation loss:		0.524178
  validation accuracy:		91.41 %
Epoch 1189 of 2000 took 0.035s
  training loss:		0.010715
  validation loss:		0.517539
  validation accuracy:		91.52 %
Epoch 1190 of 2000 took 0.035s
  training loss:		0.010493
  validation loss:		0.516835
  validation accuracy:		91.96 %
Epoch 1191 of 2000 took 0.035s
  training loss:		0.010566
  validation loss:		0.523707
  validation accuracy:		91.74 %
Epoch 1192 of 2000 took 0.036s
  training loss:		0.010230
  validation loss:		0.516664
  validation accuracy:		91.30 %
Epoch 1193 of 2000 took 0.035s
  training loss:		0.010057
  validation loss:		0.529592
  validation accuracy:		91.30 %
Epoch 1194 of 2000 took 0.035s
  training loss:		0.010635
  validation loss:		0.531913
  validation accuracy:		91.20 %
Epoch 1195 of 2000 took 0.035s
  training loss:		0.010005
  validation loss:		0.526727
  validation accuracy:		91.30 %
Epoch 1196 of 2000 took 0.035s
  training loss:		0.010082
  validation loss:		0.525905
  validation accuracy:		91.52 %
Epoch 1197 of 2000 took 0.035s
  training loss:		0.010224
  validation loss:		0.516241
  validation accuracy:		91.20 %
Epoch 1198 of 2000 took 0.035s
  training loss:		0.009707
  validation loss:		0.522769
  validation accuracy:		91.52 %
Epoch 1199 of 2000 took 0.035s
  training loss:		0.009672
  validation loss:		0.523372
  validation accuracy:		91.30 %
Epoch 1200 of 2000 took 0.035s
  training loss:		0.010154
  validation loss:		0.528349
  validation accuracy:		91.41 %
Epoch 1201 of 2000 took 0.035s
  training loss:		0.010720
  validation loss:		0.527175
  validation accuracy:		91.63 %
Epoch 1202 of 2000 took 0.035s
  training loss:		0.010342
  validation loss:		0.529829
  validation accuracy:		91.41 %
Epoch 1203 of 2000 took 0.035s
  training loss:		0.010230
  validation loss:		0.524188
  validation accuracy:		91.74 %
Epoch 1204 of 2000 took 0.035s
  training loss:		0.010146
  validation loss:		0.526546
  validation accuracy:		91.41 %
Epoch 1205 of 2000 took 0.035s
  training loss:		0.009714
  validation loss:		0.538532
  validation accuracy:		91.41 %
Epoch 1206 of 2000 took 0.035s
  training loss:		0.010150
  validation loss:		0.526540
  validation accuracy:		91.52 %
Epoch 1207 of 2000 took 0.035s
  training loss:		0.010144
  validation loss:		0.520011
  validation accuracy:		91.63 %
Epoch 1208 of 2000 took 0.035s
  training loss:		0.010014
  validation loss:		0.523980
  validation accuracy:		91.41 %
Epoch 1209 of 2000 took 0.035s
  training loss:		0.010051
  validation loss:		0.521526
  validation accuracy:		91.63 %
Epoch 1210 of 2000 took 0.035s
  training loss:		0.010295
  validation loss:		0.520840
  validation accuracy:		91.74 %
Epoch 1211 of 2000 took 0.035s
  training loss:		0.009731
  validation loss:		0.521699
  validation accuracy:		91.52 %
Epoch 1212 of 2000 took 0.035s
  training loss:		0.009625
  validation loss:		0.528478
  validation accuracy:		91.63 %
Epoch 1213 of 2000 took 0.035s
  training loss:		0.009676
  validation loss:		0.525052
  validation accuracy:		91.63 %
Epoch 1214 of 2000 took 0.035s
  training loss:		0.009657
  validation loss:		0.529712
  validation accuracy:		91.30 %
Epoch 1215 of 2000 took 0.035s
  training loss:		0.009661
  validation loss:		0.531725
  validation accuracy:		91.20 %
Epoch 1216 of 2000 took 0.035s
  training loss:		0.009581
  validation loss:		0.526956
  validation accuracy:		91.74 %
Epoch 1217 of 2000 took 0.035s
  training loss:		0.009884
  validation loss:		0.535764
  validation accuracy:		91.41 %
Epoch 1218 of 2000 took 0.035s
  training loss:		0.010002
  validation loss:		0.535595
  validation accuracy:		91.30 %
Epoch 1219 of 2000 took 0.035s
  training loss:		0.008986
  validation loss:		0.536930
  validation accuracy:		91.41 %
Epoch 1220 of 2000 took 0.035s
  training loss:		0.009680
  validation loss:		0.532922
  validation accuracy:		91.20 %
Epoch 1221 of 2000 took 0.035s
  training loss:		0.008633
  validation loss:		0.535208
  validation accuracy:		91.52 %
Epoch 1222 of 2000 took 0.035s
  training loss:		0.009555
  validation loss:		0.533818
  validation accuracy:		91.30 %
Epoch 1223 of 2000 took 0.035s
  training loss:		0.009677
  validation loss:		0.536301
  validation accuracy:		91.20 %
Epoch 1224 of 2000 took 0.035s
  training loss:		0.009540
  validation loss:		0.528102
  validation accuracy:		91.41 %
Epoch 1225 of 2000 took 0.035s
  training loss:		0.009416
  validation loss:		0.533675
  validation accuracy:		91.85 %
Epoch 1226 of 2000 took 0.035s
  training loss:		0.009709
  validation loss:		0.545853
  validation accuracy:		91.09 %
Epoch 1227 of 2000 took 0.035s
  training loss:		0.009694
  validation loss:		0.534990
  validation accuracy:		91.30 %
Epoch 1228 of 2000 took 0.035s
  training loss:		0.009703
  validation loss:		0.525804
  validation accuracy:		91.41 %
Epoch 1229 of 2000 took 0.035s
  training loss:		0.009559
  validation loss:		0.531169
  validation accuracy:		91.63 %
Epoch 1230 of 2000 took 0.035s
  training loss:		0.009283
  validation loss:		0.534813
  validation accuracy:		91.41 %
Epoch 1231 of 2000 took 0.035s
  training loss:		0.009404
  validation loss:		0.532154
  validation accuracy:		91.74 %
Epoch 1232 of 2000 took 0.035s
  training loss:		0.009309
  validation loss:		0.531887
  validation accuracy:		91.52 %
Epoch 1233 of 2000 took 0.035s
  training loss:		0.009117
  validation loss:		0.528872
  validation accuracy:		91.63 %
Epoch 1234 of 2000 took 0.035s
  training loss:		0.009502
  validation loss:		0.533282
  validation accuracy:		91.63 %
Epoch 1235 of 2000 took 0.035s
  training loss:		0.009581
  validation loss:		0.533365
  validation accuracy:		91.74 %
Epoch 1236 of 2000 took 0.035s
  training loss:		0.008722
  validation loss:		0.523893
  validation accuracy:		91.74 %
Epoch 1237 of 2000 took 0.035s
  training loss:		0.009476
  validation loss:		0.529603
  validation accuracy:		91.30 %
Epoch 1238 of 2000 took 0.035s
  training loss:		0.009664
  validation loss:		0.528943
  validation accuracy:		91.63 %
Epoch 1239 of 2000 took 0.035s
  training loss:		0.009616
  validation loss:		0.531738
  validation accuracy:		91.41 %
Epoch 1240 of 2000 took 0.035s
  training loss:		0.009247
  validation loss:		0.542949
  validation accuracy:		91.20 %
Epoch 1241 of 2000 took 0.035s
  training loss:		0.009510
  validation loss:		0.540138
  validation accuracy:		91.52 %
Epoch 1242 of 2000 took 0.035s
  training loss:		0.009652
  validation loss:		0.539356
  validation accuracy:		91.30 %
Epoch 1243 of 2000 took 0.035s
  training loss:		0.009088
  validation loss:		0.531639
  validation accuracy:		91.63 %
Epoch 1244 of 2000 took 0.035s
  training loss:		0.009320
  validation loss:		0.536392
  validation accuracy:		91.52 %
Epoch 1245 of 2000 took 0.035s
  training loss:		0.009268
  validation loss:		0.538319
  validation accuracy:		91.20 %
Epoch 1246 of 2000 took 0.035s
  training loss:		0.009657
  validation loss:		0.543175
  validation accuracy:		91.41 %
Epoch 1247 of 2000 took 0.035s
  training loss:		0.008934
  validation loss:		0.538402
  validation accuracy:		91.63 %
Epoch 1248 of 2000 took 0.035s
  training loss:		0.009137
  validation loss:		0.532236
  validation accuracy:		91.63 %
Epoch 1249 of 2000 took 0.035s
  training loss:		0.009133
  validation loss:		0.538245
  validation accuracy:		91.41 %
Epoch 1250 of 2000 took 0.035s
  training loss:		0.009334
  validation loss:		0.532042
  validation accuracy:		91.63 %
Epoch 1251 of 2000 took 0.035s
  training loss:		0.009068
  validation loss:		0.539914
  validation accuracy:		91.30 %
Epoch 1252 of 2000 took 0.035s
  training loss:		0.009014
  validation loss:		0.553779
  validation accuracy:		91.09 %
Epoch 1253 of 2000 took 0.035s
  training loss:		0.008726
  validation loss:		0.538438
  validation accuracy:		91.52 %
Epoch 1254 of 2000 took 0.035s
  training loss:		0.009063
  validation loss:		0.531328
  validation accuracy:		91.63 %
Epoch 1255 of 2000 took 0.035s
  training loss:		0.008988
  validation loss:		0.542104
  validation accuracy:		91.52 %
Epoch 1256 of 2000 took 0.035s
  training loss:		0.008760
  validation loss:		0.535674
  validation accuracy:		91.74 %
Epoch 1257 of 2000 took 0.035s
  training loss:		0.009244
  validation loss:		0.547467
  validation accuracy:		91.63 %
Epoch 1258 of 2000 took 0.035s
  training loss:		0.009284
  validation loss:		0.538962
  validation accuracy:		91.41 %
Epoch 1259 of 2000 took 0.035s
  training loss:		0.009009
  validation loss:		0.537602
  validation accuracy:		91.41 %
Epoch 1260 of 2000 took 0.036s
  training loss:		0.008554
  validation loss:		0.533023
  validation accuracy:		91.41 %
Epoch 1261 of 2000 took 0.035s
  training loss:		0.008794
  validation loss:		0.541776
  validation accuracy:		91.63 %
Epoch 1262 of 2000 took 0.035s
  training loss:		0.008524
  validation loss:		0.534298
  validation accuracy:		91.52 %
Epoch 1263 of 2000 took 0.035s
  training loss:		0.008917
  validation loss:		0.535976
  validation accuracy:		91.63 %
Epoch 1264 of 2000 took 0.035s
  training loss:		0.009083
  validation loss:		0.543473
  validation accuracy:		91.63 %
Epoch 1265 of 2000 took 0.035s
  training loss:		0.008961
  validation loss:		0.535046
  validation accuracy:		91.63 %
Epoch 1266 of 2000 took 0.035s
  training loss:		0.008533
  validation loss:		0.538272
  validation accuracy:		91.52 %
Epoch 1267 of 2000 took 0.035s
  training loss:		0.008535
  validation loss:		0.535324
  validation accuracy:		91.85 %
Epoch 1268 of 2000 took 0.035s
  training loss:		0.008812
  validation loss:		0.535763
  validation accuracy:		91.85 %
Epoch 1269 of 2000 took 0.035s
  training loss:		0.007898
  validation loss:		0.541335
  validation accuracy:		91.30 %
Epoch 1270 of 2000 took 0.035s
  training loss:		0.008001
  validation loss:		0.534157
  validation accuracy:		91.74 %
Epoch 1271 of 2000 took 0.035s
  training loss:		0.008558
  validation loss:		0.552286
  validation accuracy:		90.87 %
Epoch 1272 of 2000 took 0.035s
  training loss:		0.008530
  validation loss:		0.546920
  validation accuracy:		91.30 %
Epoch 1273 of 2000 took 0.035s
  training loss:		0.008647
  validation loss:		0.539812
  validation accuracy:		91.52 %
Epoch 1274 of 2000 took 0.035s
  training loss:		0.008532
  validation loss:		0.540940
  validation accuracy:		91.52 %
Epoch 1275 of 2000 took 0.035s
  training loss:		0.008764
  validation loss:		0.532589
  validation accuracy:		91.85 %
Epoch 1276 of 2000 took 0.035s
  training loss:		0.008458
  validation loss:		0.536215
  validation accuracy:		91.52 %
Epoch 1277 of 2000 took 0.035s
  training loss:		0.008382
  validation loss:		0.544107
  validation accuracy:		91.41 %
Epoch 1278 of 2000 took 0.035s
  training loss:		0.008338
  validation loss:		0.549018
  validation accuracy:		91.52 %
Epoch 1279 of 2000 took 0.035s
  training loss:		0.008360
  validation loss:		0.540761
  validation accuracy:		91.52 %
Epoch 1280 of 2000 took 0.035s
  training loss:		0.008440
  validation loss:		0.548326
  validation accuracy:		91.41 %
Epoch 1281 of 2000 took 0.035s
  training loss:		0.008645
  validation loss:		0.553091
  validation accuracy:		91.30 %
Epoch 1282 of 2000 took 0.035s
  training loss:		0.008708
  validation loss:		0.544047
  validation accuracy:		91.20 %
Epoch 1283 of 2000 took 0.035s
  training loss:		0.008665
  validation loss:		0.534328
  validation accuracy:		91.96 %
Epoch 1284 of 2000 took 0.035s
  training loss:		0.008468
  validation loss:		0.548406
  validation accuracy:		91.41 %
Epoch 1285 of 2000 took 0.035s
  training loss:		0.008353
  validation loss:		0.551438
  validation accuracy:		91.30 %
Epoch 1286 of 2000 took 0.035s
  training loss:		0.008235
  validation loss:		0.548377
  validation accuracy:		91.41 %
Epoch 1287 of 2000 took 0.035s
  training loss:		0.008451
  validation loss:		0.552816
  validation accuracy:		91.20 %
Epoch 1288 of 2000 took 0.035s
  training loss:		0.008447
  validation loss:		0.543810
  validation accuracy:		91.74 %
Epoch 1289 of 2000 took 0.035s
  training loss:		0.007889
  validation loss:		0.543946
  validation accuracy:		91.30 %
Epoch 1290 of 2000 took 0.035s
  training loss:		0.008034
  validation loss:		0.547867
  validation accuracy:		91.20 %
Epoch 1291 of 2000 took 0.035s
  training loss:		0.008304
  validation loss:		0.545630
  validation accuracy:		91.30 %
Epoch 1292 of 2000 took 0.035s
  training loss:		0.008029
  validation loss:		0.543147
  validation accuracy:		91.74 %
Epoch 1293 of 2000 took 0.035s
  training loss:		0.008120
  validation loss:		0.552129
  validation accuracy:		91.20 %
Epoch 1294 of 2000 took 0.035s
  training loss:		0.007939
  validation loss:		0.539242
  validation accuracy:		91.96 %
Epoch 1295 of 2000 took 0.035s
  training loss:		0.008355
  validation loss:		0.551581
  validation accuracy:		91.52 %
Epoch 1296 of 2000 took 0.035s
  training loss:		0.008057
  validation loss:		0.543826
  validation accuracy:		91.41 %
Epoch 1297 of 2000 took 0.035s
  training loss:		0.008306
  validation loss:		0.546049
  validation accuracy:		91.41 %
Epoch 1298 of 2000 took 0.035s
  training loss:		0.008103
  validation loss:		0.537727
  validation accuracy:		91.41 %
Epoch 1299 of 2000 took 0.035s
  training loss:		0.007925
  validation loss:		0.554501
  validation accuracy:		91.41 %
Epoch 1300 of 2000 took 0.035s
  training loss:		0.007910
  validation loss:		0.544327
  validation accuracy:		91.85 %
Epoch 1301 of 2000 took 0.035s
  training loss:		0.007976
  validation loss:		0.550308
  validation accuracy:		91.41 %
Epoch 1302 of 2000 took 0.035s
  training loss:		0.008404
  validation loss:		0.541373
  validation accuracy:		91.96 %
Epoch 1303 of 2000 took 0.035s
  training loss:		0.008195
  validation loss:		0.550481
  validation accuracy:		91.41 %
Epoch 1304 of 2000 took 0.035s
  training loss:		0.008202
  validation loss:		0.553056
  validation accuracy:		91.74 %
Epoch 1305 of 2000 took 0.035s
  training loss:		0.007716
  validation loss:		0.545050
  validation accuracy:		91.63 %
Epoch 1306 of 2000 took 0.035s
  training loss:		0.007855
  validation loss:		0.558509
  validation accuracy:		91.52 %
Epoch 1307 of 2000 took 0.035s
  training loss:		0.007746
  validation loss:		0.543041
  validation accuracy:		91.74 %
Epoch 1308 of 2000 took 0.035s
  training loss:		0.008088
  validation loss:		0.541479
  validation accuracy:		91.85 %
Epoch 1309 of 2000 took 0.035s
  training loss:		0.008140
  validation loss:		0.555127
  validation accuracy:		91.52 %
Epoch 1310 of 2000 took 0.035s
  training loss:		0.007619
  validation loss:		0.556815
  validation accuracy:		91.30 %
Epoch 1311 of 2000 took 0.035s
  training loss:		0.007852
  validation loss:		0.553299
  validation accuracy:		91.41 %
Epoch 1312 of 2000 took 0.035s
  training loss:		0.007472
  validation loss:		0.544801
  validation accuracy:		91.63 %
Epoch 1313 of 2000 took 0.035s
  training loss:		0.008129
  validation loss:		0.554868
  validation accuracy:		91.41 %
Epoch 1314 of 2000 took 0.035s
  training loss:		0.007925
  validation loss:		0.550439
  validation accuracy:		91.52 %
Epoch 1315 of 2000 took 0.035s
  training loss:		0.007849
  validation loss:		0.553976
  validation accuracy:		91.41 %
Epoch 1316 of 2000 took 0.035s
  training loss:		0.007978
  validation loss:		0.548387
  validation accuracy:		91.74 %
Epoch 1317 of 2000 took 0.035s
  training loss:		0.007553
  validation loss:		0.557750
  validation accuracy:		91.20 %
Epoch 1318 of 2000 took 0.035s
  training loss:		0.007952
  validation loss:		0.556674
  validation accuracy:		91.52 %
Epoch 1319 of 2000 took 0.035s
  training loss:		0.007648
  validation loss:		0.557284
  validation accuracy:		91.52 %
Epoch 1320 of 2000 took 0.035s
  training loss:		0.007738
  validation loss:		0.548437
  validation accuracy:		91.74 %
Epoch 1321 of 2000 took 0.035s
  training loss:		0.007707
  validation loss:		0.560406
  validation accuracy:		91.41 %
Epoch 1322 of 2000 took 0.035s
  training loss:		0.007666
  validation loss:		0.560443
  validation accuracy:		91.30 %
Epoch 1323 of 2000 took 0.035s
  training loss:		0.007943
  validation loss:		0.562884
  validation accuracy:		91.30 %
Epoch 1324 of 2000 took 0.035s
  training loss:		0.007614
  validation loss:		0.554589
  validation accuracy:		91.63 %
Epoch 1325 of 2000 took 0.035s
  training loss:		0.007541
  validation loss:		0.555648
  validation accuracy:		91.52 %
Epoch 1326 of 2000 took 0.035s
  training loss:		0.007718
  validation loss:		0.554676
  validation accuracy:		91.41 %
Epoch 1327 of 2000 took 0.035s
  training loss:		0.007069
  validation loss:		0.550396
  validation accuracy:		91.63 %
Epoch 1328 of 2000 took 0.035s
  training loss:		0.007536
  validation loss:		0.563815
  validation accuracy:		91.09 %
Epoch 1329 of 2000 took 0.035s
  training loss:		0.007043
  validation loss:		0.543206
  validation accuracy:		91.85 %
Epoch 1330 of 2000 took 0.035s
  training loss:		0.007489
  validation loss:		0.557386
  validation accuracy:		91.41 %
Epoch 1331 of 2000 took 0.035s
  training loss:		0.007535
  validation loss:		0.550307
  validation accuracy:		91.63 %
Epoch 1332 of 2000 took 0.035s
  training loss:		0.007768
  validation loss:		0.554458
  validation accuracy:		91.63 %
Epoch 1333 of 2000 took 0.035s
  training loss:		0.007460
  validation loss:		0.547741
  validation accuracy:		91.63 %
Epoch 1334 of 2000 took 0.035s
  training loss:		0.007485
  validation loss:		0.558594
  validation accuracy:		91.20 %
Epoch 1335 of 2000 took 0.035s
  training loss:		0.007468
  validation loss:		0.568454
  validation accuracy:		90.98 %
Epoch 1336 of 2000 took 0.035s
  training loss:		0.007624
  validation loss:		0.548287
  validation accuracy:		91.52 %
Epoch 1337 of 2000 took 0.035s
  training loss:		0.007217
  validation loss:		0.559054
  validation accuracy:		91.52 %
Epoch 1338 of 2000 took 0.035s
  training loss:		0.007409
  validation loss:		0.555722
  validation accuracy:		91.41 %
Epoch 1339 of 2000 took 0.036s
  training loss:		0.007448
  validation loss:		0.557251
  validation accuracy:		91.63 %
Epoch 1340 of 2000 took 0.035s
  training loss:		0.007356
  validation loss:		0.560109
  validation accuracy:		91.30 %
Epoch 1341 of 2000 took 0.035s
  training loss:		0.007408
  validation loss:		0.560962
  validation accuracy:		91.52 %
Epoch 1342 of 2000 took 0.035s
  training loss:		0.007405
  validation loss:		0.549069
  validation accuracy:		91.74 %
Epoch 1343 of 2000 took 0.035s
  training loss:		0.007558
  validation loss:		0.567958
  validation accuracy:		91.30 %
Epoch 1344 of 2000 took 0.035s
  training loss:		0.006810
  validation loss:		0.538813
  validation accuracy:		91.96 %
Epoch 1345 of 2000 took 0.035s
  training loss:		0.007521
  validation loss:		0.558188
  validation accuracy:		91.52 %
Epoch 1346 of 2000 took 0.035s
  training loss:		0.007463
  validation loss:		0.554460
  validation accuracy:		91.85 %
Epoch 1347 of 2000 took 0.035s
  training loss:		0.007140
  validation loss:		0.557539
  validation accuracy:		91.41 %
Epoch 1348 of 2000 took 0.035s
  training loss:		0.007170
  validation loss:		0.571218
  validation accuracy:		91.09 %
Epoch 1349 of 2000 took 0.035s
  training loss:		0.007522
  validation loss:		0.567064
  validation accuracy:		91.41 %
Epoch 1350 of 2000 took 0.035s
  training loss:		0.007235
  validation loss:		0.549770
  validation accuracy:		91.63 %
Epoch 1351 of 2000 took 0.035s
  training loss:		0.007323
  validation loss:		0.564774
  validation accuracy:		91.41 %
Epoch 1352 of 2000 took 0.035s
  training loss:		0.007067
  validation loss:		0.554500
  validation accuracy:		91.74 %
Epoch 1353 of 2000 took 0.035s
  training loss:		0.007136
  validation loss:		0.562879
  validation accuracy:		91.30 %
Epoch 1354 of 2000 took 0.035s
  training loss:		0.007275
  validation loss:		0.564251
  validation accuracy:		91.30 %
Epoch 1355 of 2000 took 0.035s
  training loss:		0.006664
  validation loss:		0.550526
  validation accuracy:		91.85 %
Epoch 1356 of 2000 took 0.035s
  training loss:		0.007321
  validation loss:		0.558610
  validation accuracy:		91.74 %
Epoch 1357 of 2000 took 0.035s
  training loss:		0.007261
  validation loss:		0.566294
  validation accuracy:		91.52 %
Epoch 1358 of 2000 took 0.035s
  training loss:		0.007063
  validation loss:		0.561577
  validation accuracy:		91.85 %
Epoch 1359 of 2000 took 0.035s
  training loss:		0.007014
  validation loss:		0.569228
  validation accuracy:		91.20 %
Epoch 1360 of 2000 took 0.035s
  training loss:		0.007674
  validation loss:		0.560115
  validation accuracy:		91.63 %
Epoch 1361 of 2000 took 0.035s
  training loss:		0.007171
  validation loss:		0.565211
  validation accuracy:		91.63 %
Epoch 1362 of 2000 took 0.035s
  training loss:		0.007095
  validation loss:		0.552513
  validation accuracy:		91.96 %
Epoch 1363 of 2000 took 0.035s
  training loss:		0.006908
  validation loss:		0.563190
  validation accuracy:		91.52 %
Epoch 1364 of 2000 took 0.035s
  training loss:		0.006974
  validation loss:		0.571471
  validation accuracy:		90.98 %
Epoch 1365 of 2000 took 0.035s
  training loss:		0.007159
  validation loss:		0.560710
  validation accuracy:		91.41 %
Epoch 1366 of 2000 took 0.035s
  training loss:		0.007135
  validation loss:		0.563834
  validation accuracy:		91.63 %
Epoch 1367 of 2000 took 0.035s
  training loss:		0.006911
  validation loss:		0.570974
  validation accuracy:		91.41 %
Epoch 1368 of 2000 took 0.035s
  training loss:		0.006873
  validation loss:		0.577034
  validation accuracy:		90.98 %
Epoch 1369 of 2000 took 0.035s
  training loss:		0.007172
  validation loss:		0.556043
  validation accuracy:		91.96 %
Epoch 1370 of 2000 took 0.035s
  training loss:		0.006942
  validation loss:		0.562698
  validation accuracy:		91.52 %
Epoch 1371 of 2000 took 0.035s
  training loss:		0.006958
  validation loss:		0.562695
  validation accuracy:		91.74 %
Epoch 1372 of 2000 took 0.035s
  training loss:		0.006623
  validation loss:		0.568513
  validation accuracy:		91.52 %
Epoch 1373 of 2000 took 0.035s
  training loss:		0.006839
  validation loss:		0.580333
  validation accuracy:		91.41 %
Epoch 1374 of 2000 took 0.035s
  training loss:		0.007033
  validation loss:		0.572239
  validation accuracy:		91.30 %
Epoch 1375 of 2000 took 0.035s
  training loss:		0.007165
  validation loss:		0.569107
  validation accuracy:		91.41 %
Epoch 1376 of 2000 took 0.035s
  training loss:		0.006715
  validation loss:		0.565070
  validation accuracy:		91.63 %
Epoch 1377 of 2000 took 0.035s
  training loss:		0.006719
  validation loss:		0.561099
  validation accuracy:		91.63 %
Epoch 1378 of 2000 took 0.035s
  training loss:		0.006604
  validation loss:		0.566071
  validation accuracy:		91.63 %
Epoch 1379 of 2000 took 0.035s
  training loss:		0.006810
  validation loss:		0.576194
  validation accuracy:		91.30 %
Epoch 1380 of 2000 took 0.035s
  training loss:		0.006816
  validation loss:		0.558714
  validation accuracy:		91.63 %
Epoch 1381 of 2000 took 0.035s
  training loss:		0.006542
  validation loss:		0.556068
  validation accuracy:		91.96 %
Epoch 1382 of 2000 took 0.035s
  training loss:		0.006964
  validation loss:		0.567176
  validation accuracy:		91.30 %
Epoch 1383 of 2000 took 0.035s
  training loss:		0.006445
  validation loss:		0.568497
  validation accuracy:		91.63 %
Epoch 1384 of 2000 took 0.035s
  training loss:		0.006687
  validation loss:		0.565542
  validation accuracy:		91.63 %
Epoch 1385 of 2000 took 0.035s
  training loss:		0.006613
  validation loss:		0.563878
  validation accuracy:		91.74 %
Epoch 1386 of 2000 took 0.035s
  training loss:		0.006564
  validation loss:		0.578090
  validation accuracy:		91.30 %
Epoch 1387 of 2000 took 0.035s
  training loss:		0.006981
  validation loss:		0.568932
  validation accuracy:		91.52 %
Epoch 1388 of 2000 took 0.035s
  training loss:		0.006419
  validation loss:		0.571188
  validation accuracy:		91.30 %
Epoch 1389 of 2000 took 0.035s
  training loss:		0.006544
  validation loss:		0.579842
  validation accuracy:		91.41 %
Epoch 1390 of 2000 took 0.035s
  training loss:		0.006714
  validation loss:		0.568552
  validation accuracy:		91.41 %
Epoch 1391 of 2000 took 0.035s
  training loss:		0.006627
  validation loss:		0.569068
  validation accuracy:		91.85 %
Epoch 1392 of 2000 took 0.035s
  training loss:		0.006793
  validation loss:		0.563226
  validation accuracy:		91.96 %
Epoch 1393 of 2000 took 0.035s
  training loss:		0.006653
  validation loss:		0.567375
  validation accuracy:		91.63 %
Epoch 1394 of 2000 took 0.035s
  training loss:		0.006401
  validation loss:		0.567066
  validation accuracy:		91.74 %
Epoch 1395 of 2000 took 0.035s
  training loss:		0.006563
  validation loss:		0.575968
  validation accuracy:		91.20 %
Epoch 1396 of 2000 took 0.035s
  training loss:		0.006661
  validation loss:		0.564178
  validation accuracy:		91.85 %
Epoch 1397 of 2000 took 0.035s
  training loss:		0.006464
  validation loss:		0.564169
  validation accuracy:		91.63 %
Epoch 1398 of 2000 took 0.035s
  training loss:		0.006312
  validation loss:		0.580086
  validation accuracy:		91.41 %
Epoch 1399 of 2000 took 0.035s
  training loss:		0.006242
  validation loss:		0.570989
  validation accuracy:		91.52 %
Epoch 1400 of 2000 took 0.035s
  training loss:		0.006464
  validation loss:		0.566800
  validation accuracy:		91.85 %
Epoch 1401 of 2000 took 0.035s
  training loss:		0.006508
  validation loss:		0.571133
  validation accuracy:		91.63 %
Epoch 1402 of 2000 took 0.036s
  training loss:		0.006368
  validation loss:		0.566986
  validation accuracy:		91.41 %
Epoch 1403 of 2000 took 0.035s
  training loss:		0.006469
  validation loss:		0.569029
  validation accuracy:		91.96 %
Epoch 1404 of 2000 took 0.035s
  training loss:		0.006418
  validation loss:		0.574018
  validation accuracy:		91.74 %
Epoch 1405 of 2000 took 0.035s
  training loss:		0.006650
  validation loss:		0.572940
  validation accuracy:		91.52 %
Epoch 1406 of 2000 took 0.035s
  training loss:		0.006476
  validation loss:		0.577297
  validation accuracy:		91.30 %
Epoch 1407 of 2000 took 0.035s
  training loss:		0.006287
  validation loss:		0.570916
  validation accuracy:		91.63 %
Epoch 1408 of 2000 took 0.035s
  training loss:		0.006311
  validation loss:		0.571880
  validation accuracy:		91.74 %
Epoch 1409 of 2000 took 0.035s
  training loss:		0.006287
  validation loss:		0.570676
  validation accuracy:		91.52 %
Epoch 1410 of 2000 took 0.035s
  training loss:		0.006144
  validation loss:		0.572270
  validation accuracy:		91.41 %
Epoch 1411 of 2000 took 0.035s
  training loss:		0.006329
  validation loss:		0.567958
  validation accuracy:		91.96 %
Epoch 1412 of 2000 took 0.035s
  training loss:		0.006168
  validation loss:		0.573537
  validation accuracy:		91.52 %
Epoch 1413 of 2000 took 0.035s
  training loss:		0.006418
  validation loss:		0.572542
  validation accuracy:		91.63 %
Epoch 1414 of 2000 took 0.035s
  training loss:		0.006271
  validation loss:		0.583239
  validation accuracy:		91.63 %
Epoch 1415 of 2000 took 0.035s
  training loss:		0.006226
  validation loss:		0.564825
  validation accuracy:		91.85 %
Epoch 1416 of 2000 took 0.035s
  training loss:		0.006280
  validation loss:		0.581544
  validation accuracy:		91.52 %
Epoch 1417 of 2000 took 0.035s
  training loss:		0.006294
  validation loss:		0.573626
  validation accuracy:		91.74 %
Epoch 1418 of 2000 took 0.035s
  training loss:		0.005819
  validation loss:		0.576701
  validation accuracy:		91.52 %
Epoch 1419 of 2000 took 0.036s
  training loss:		0.006111
  validation loss:		0.575159
  validation accuracy:		91.41 %
Epoch 1420 of 2000 took 0.035s
  training loss:		0.006140
  validation loss:		0.575183
  validation accuracy:		91.41 %
Epoch 1421 of 2000 took 0.035s
  training loss:		0.006162
  validation loss:		0.576448
  validation accuracy:		91.52 %
Epoch 1422 of 2000 took 0.035s
  training loss:		0.005831
  validation loss:		0.572772
  validation accuracy:		91.41 %
Epoch 1423 of 2000 took 0.035s
  training loss:		0.006150
  validation loss:		0.572390
  validation accuracy:		91.74 %
Epoch 1424 of 2000 took 0.035s
  training loss:		0.006192
  validation loss:		0.584660
  validation accuracy:		91.41 %
Epoch 1425 of 2000 took 0.035s
  training loss:		0.006112
  validation loss:		0.569877
  validation accuracy:		91.74 %
Epoch 1426 of 2000 took 0.035s
  training loss:		0.006169
  validation loss:		0.578859
  validation accuracy:		91.63 %
Epoch 1427 of 2000 took 0.035s
  training loss:		0.006129
  validation loss:		0.574390
  validation accuracy:		91.41 %
Epoch 1428 of 2000 took 0.035s
  training loss:		0.006201
  validation loss:		0.571049
  validation accuracy:		91.85 %
Epoch 1429 of 2000 took 0.035s
  training loss:		0.005621
  validation loss:		0.573865
  validation accuracy:		91.41 %
Epoch 1430 of 2000 took 0.035s
  training loss:		0.006116
  validation loss:		0.578540
  validation accuracy:		91.30 %
Epoch 1431 of 2000 took 0.035s
  training loss:		0.006008
  validation loss:		0.580867
  validation accuracy:		91.41 %
Epoch 1432 of 2000 took 0.035s
  training loss:		0.005976
  validation loss:		0.591521
  validation accuracy:		91.20 %
Epoch 1433 of 2000 took 0.035s
  training loss:		0.006092
  validation loss:		0.579222
  validation accuracy:		91.63 %
Epoch 1434 of 2000 took 0.035s
  training loss:		0.005945
  validation loss:		0.585006
  validation accuracy:		91.30 %
Epoch 1435 of 2000 took 0.035s
  training loss:		0.006086
  validation loss:		0.580238
  validation accuracy:		91.52 %
Epoch 1436 of 2000 took 0.035s
  training loss:		0.006244
  validation loss:		0.578241
  validation accuracy:		91.41 %
Epoch 1437 of 2000 took 0.035s
  training loss:		0.006166
  validation loss:		0.588346
  validation accuracy:		91.30 %
Epoch 1438 of 2000 took 0.035s
  training loss:		0.006193
  validation loss:		0.581747
  validation accuracy:		91.52 %
Epoch 1439 of 2000 took 0.035s
  training loss:		0.005885
  validation loss:		0.571071
  validation accuracy:		91.74 %
Epoch 1440 of 2000 took 0.035s
  training loss:		0.006052
  validation loss:		0.585159
  validation accuracy:		91.63 %
Epoch 1441 of 2000 took 0.035s
  training loss:		0.005725
  validation loss:		0.572991
  validation accuracy:		91.63 %
Epoch 1442 of 2000 took 0.035s
  training loss:		0.006076
  validation loss:		0.577282
  validation accuracy:		91.52 %
Epoch 1443 of 2000 took 0.035s
  training loss:		0.006008
  validation loss:		0.579043
  validation accuracy:		91.52 %
Epoch 1444 of 2000 took 0.035s
  training loss:		0.005898
  validation loss:		0.580939
  validation accuracy:		91.63 %
Epoch 1445 of 2000 took 0.035s
  training loss:		0.005792
  validation loss:		0.579843
  validation accuracy:		91.74 %
Epoch 1446 of 2000 took 0.035s
  training loss:		0.005729
  validation loss:		0.589192
  validation accuracy:		91.30 %
Epoch 1447 of 2000 took 0.035s
  training loss:		0.006098
  validation loss:		0.574557
  validation accuracy:		91.52 %
Epoch 1448 of 2000 took 0.035s
  training loss:		0.005887
  validation loss:		0.582270
  validation accuracy:		91.41 %
Epoch 1449 of 2000 took 0.035s
  training loss:		0.005913
  validation loss:		0.582991
  validation accuracy:		91.63 %
Epoch 1450 of 2000 took 0.035s
  training loss:		0.005821
  validation loss:		0.583656
  validation accuracy:		91.52 %
Epoch 1451 of 2000 took 0.035s
  training loss:		0.005832
  validation loss:		0.572651
  validation accuracy:		91.52 %
Epoch 1452 of 2000 took 0.035s
  training loss:		0.005752
  validation loss:		0.584480
  validation accuracy:		91.41 %
Epoch 1453 of 2000 took 0.037s
  training loss:		0.006077
  validation loss:		0.581604
  validation accuracy:		91.85 %
Epoch 1454 of 2000 took 0.036s
  training loss:		0.005687
  validation loss:		0.574522
  validation accuracy:		91.63 %
Epoch 1455 of 2000 took 0.035s
  training loss:		0.005945
  validation loss:		0.578390
  validation accuracy:		91.85 %
Epoch 1456 of 2000 took 0.035s
  training loss:		0.005832
  validation loss:		0.584432
  validation accuracy:		91.30 %
Epoch 1457 of 2000 took 0.035s
  training loss:		0.005896
  validation loss:		0.581433
  validation accuracy:		91.74 %
Epoch 1458 of 2000 took 0.035s
  training loss:		0.005764
  validation loss:		0.576661
  validation accuracy:		91.30 %
Epoch 1459 of 2000 took 0.035s
  training loss:		0.005794
  validation loss:		0.584836
  validation accuracy:		91.41 %
Epoch 1460 of 2000 took 0.035s
  training loss:		0.005717
  validation loss:		0.574106
  validation accuracy:		91.96 %
Epoch 1461 of 2000 took 0.035s
  training loss:		0.005728
  validation loss:		0.587932
  validation accuracy:		91.30 %
Epoch 1462 of 2000 took 0.035s
  training loss:		0.005886
  validation loss:		0.574572
  validation accuracy:		91.96 %
Epoch 1463 of 2000 took 0.035s
  training loss:		0.005589
  validation loss:		0.584783
  validation accuracy:		91.52 %
Epoch 1464 of 2000 took 0.035s
  training loss:		0.005590
  validation loss:		0.588396
  validation accuracy:		91.30 %
Epoch 1465 of 2000 took 0.035s
  training loss:		0.005823
  validation loss:		0.578863
  validation accuracy:		91.85 %
Epoch 1466 of 2000 took 0.035s
  training loss:		0.005546
  validation loss:		0.593137
  validation accuracy:		91.41 %
Epoch 1467 of 2000 took 0.035s
  training loss:		0.005609
  validation loss:		0.582566
  validation accuracy:		91.52 %
Epoch 1468 of 2000 took 0.035s
  training loss:		0.005596
  validation loss:		0.582833
  validation accuracy:		91.74 %
Epoch 1469 of 2000 took 0.035s
  training loss:		0.005501
  validation loss:		0.583785
  validation accuracy:		91.52 %
Epoch 1470 of 2000 took 0.035s
  training loss:		0.005433
  validation loss:		0.590963
  validation accuracy:		91.52 %
Epoch 1471 of 2000 took 0.035s
  training loss:		0.005688
  validation loss:		0.586718
  validation accuracy:		91.63 %
Epoch 1472 of 2000 took 0.035s
  training loss:		0.005542
  validation loss:		0.578320
  validation accuracy:		91.74 %
Epoch 1473 of 2000 took 0.035s
  training loss:		0.005837
  validation loss:		0.583248
  validation accuracy:		91.52 %
Epoch 1474 of 2000 took 0.035s
  training loss:		0.005485
  validation loss:		0.587075
  validation accuracy:		91.74 %
Epoch 1475 of 2000 took 0.035s
  training loss:		0.005642
  validation loss:		0.586418
  validation accuracy:		91.63 %
Epoch 1476 of 2000 took 0.035s
  training loss:		0.005579
  validation loss:		0.582134
  validation accuracy:		91.30 %
Epoch 1477 of 2000 took 0.035s
  training loss:		0.005655
  validation loss:		0.579294
  validation accuracy:		91.74 %
Epoch 1478 of 2000 took 0.035s
  training loss:		0.005508
  validation loss:		0.584088
  validation accuracy:		91.52 %
Epoch 1479 of 2000 took 0.035s
  training loss:		0.005323
  validation loss:		0.593070
  validation accuracy:		91.52 %
Epoch 1480 of 2000 took 0.035s
  training loss:		0.005575
  validation loss:		0.583461
  validation accuracy:		91.63 %
Epoch 1481 of 2000 took 0.035s
  training loss:		0.005365
  validation loss:		0.589656
  validation accuracy:		91.52 %
Epoch 1482 of 2000 took 0.035s
  training loss:		0.005276
  validation loss:		0.592823
  validation accuracy:		91.41 %
Epoch 1483 of 2000 took 0.035s
  training loss:		0.005633
  validation loss:		0.590128
  validation accuracy:		91.52 %
Epoch 1484 of 2000 took 0.035s
  training loss:		0.005389
  validation loss:		0.582245
  validation accuracy:		91.52 %
Epoch 1485 of 2000 took 0.035s
  training loss:		0.005369
  validation loss:		0.590762
  validation accuracy:		91.52 %
Epoch 1486 of 2000 took 0.035s
  training loss:		0.005624
  validation loss:		0.579935
  validation accuracy:		91.63 %
Epoch 1487 of 2000 took 0.035s
  training loss:		0.005370
  validation loss:		0.588838
  validation accuracy:		91.52 %
Epoch 1488 of 2000 took 0.035s
  training loss:		0.005512
  validation loss:		0.590339
  validation accuracy:		91.41 %
Epoch 1489 of 2000 took 0.035s
  training loss:		0.005407
  validation loss:		0.585975
  validation accuracy:		91.74 %
Epoch 1490 of 2000 took 0.035s
  training loss:		0.005404
  validation loss:		0.581323
  validation accuracy:		91.74 %
Epoch 1491 of 2000 took 0.035s
  training loss:		0.005329
  validation loss:		0.590975
  validation accuracy:		91.52 %
Epoch 1492 of 2000 took 0.035s
  training loss:		0.005374
  validation loss:		0.586136
  validation accuracy:		91.52 %
Epoch 1493 of 2000 took 0.035s
  training loss:		0.005133
  validation loss:		0.578132
  validation accuracy:		91.85 %
Epoch 1494 of 2000 took 0.035s
  training loss:		0.005275
  validation loss:		0.591746
  validation accuracy:		91.41 %
Epoch 1495 of 2000 took 0.035s
  training loss:		0.005365
  validation loss:		0.592629
  validation accuracy:		91.41 %
Epoch 1496 of 2000 took 0.035s
  training loss:		0.005046
  validation loss:		0.581264
  validation accuracy:		91.85 %
Epoch 1497 of 2000 took 0.035s
  training loss:		0.005621
  validation loss:		0.581399
  validation accuracy:		91.63 %
Epoch 1498 of 2000 took 0.035s
  training loss:		0.005430
  validation loss:		0.586723
  validation accuracy:		91.74 %
Epoch 1499 of 2000 took 0.035s
  training loss:		0.005400
  validation loss:		0.592136
  validation accuracy:		91.30 %
Epoch 1500 of 2000 took 0.035s
  training loss:		0.005283
  validation loss:		0.586143
  validation accuracy:		91.52 %
Epoch 1501 of 2000 took 0.035s
  training loss:		0.005148
  validation loss:		0.589085
  validation accuracy:		91.41 %
Epoch 1502 of 2000 took 0.035s
  training loss:		0.005304
  validation loss:		0.585563
  validation accuracy:		91.85 %
Epoch 1503 of 2000 took 0.035s
  training loss:		0.005437
  validation loss:		0.602561
  validation accuracy:		91.09 %
Epoch 1504 of 2000 took 0.035s
  training loss:		0.005269
  validation loss:		0.582811
  validation accuracy:		91.63 %
Epoch 1505 of 2000 took 0.035s
  training loss:		0.005321
  validation loss:		0.592869
  validation accuracy:		91.52 %
Epoch 1506 of 2000 took 0.035s
  training loss:		0.005311
  validation loss:		0.583256
  validation accuracy:		91.63 %
Epoch 1507 of 2000 took 0.035s
  training loss:		0.005234
  validation loss:		0.597047
  validation accuracy:		91.30 %
Epoch 1508 of 2000 took 0.035s
  training loss:		0.005294
  validation loss:		0.582630
  validation accuracy:		91.63 %
Epoch 1509 of 2000 took 0.035s
  training loss:		0.005067
  validation loss:		0.587876
  validation accuracy:		91.96 %
Epoch 1510 of 2000 took 0.035s
  training loss:		0.005236
  validation loss:		0.586536
  validation accuracy:		91.52 %
Epoch 1511 of 2000 took 0.035s
  training loss:		0.005296
  validation loss:		0.588057
  validation accuracy:		91.52 %
Epoch 1512 of 2000 took 0.035s
  training loss:		0.005252
  validation loss:		0.588081
  validation accuracy:		91.63 %
Epoch 1513 of 2000 took 0.035s
  training loss:		0.005141
  validation loss:		0.592671
  validation accuracy:		91.52 %
Epoch 1514 of 2000 took 0.035s
  training loss:		0.005261
  validation loss:		0.591238
  validation accuracy:		91.41 %
Epoch 1515 of 2000 took 0.035s
  training loss:		0.005091
  validation loss:		0.598423
  validation accuracy:		91.41 %
Epoch 1516 of 2000 took 0.035s
  training loss:		0.005320
  validation loss:		0.590764
  validation accuracy:		91.74 %
Epoch 1517 of 2000 took 0.035s
  training loss:		0.004970
  validation loss:		0.589281
  validation accuracy:		91.74 %
Epoch 1518 of 2000 took 0.035s
  training loss:		0.005103
  validation loss:		0.596316
  validation accuracy:		91.63 %
Epoch 1519 of 2000 took 0.035s
  training loss:		0.005217
  validation loss:		0.594463
  validation accuracy:		91.74 %
Epoch 1520 of 2000 took 0.035s
  training loss:		0.004924
  validation loss:		0.588457
  validation accuracy:		91.74 %
Epoch 1521 of 2000 took 0.035s
  training loss:		0.005141
  validation loss:		0.601875
  validation accuracy:		91.30 %
Epoch 1522 of 2000 took 0.035s
  training loss:		0.005150
  validation loss:		0.589275
  validation accuracy:		91.85 %
Epoch 1523 of 2000 took 0.035s
  training loss:		0.005180
  validation loss:		0.593020
  validation accuracy:		91.30 %
Epoch 1524 of 2000 took 0.035s
  training loss:		0.005011
  validation loss:		0.599588
  validation accuracy:		91.41 %
Epoch 1525 of 2000 took 0.035s
  training loss:		0.005130
  validation loss:		0.597596
  validation accuracy:		91.63 %
Epoch 1526 of 2000 took 0.035s
  training loss:		0.004603
  validation loss:		0.597887
  validation accuracy:		91.74 %
Epoch 1527 of 2000 took 0.035s
  training loss:		0.005104
  validation loss:		0.598198
  validation accuracy:		91.41 %
Epoch 1528 of 2000 took 0.035s
  training loss:		0.004927
  validation loss:		0.596285
  validation accuracy:		91.63 %
Epoch 1529 of 2000 took 0.035s
  training loss:		0.005174
  validation loss:		0.593318
  validation accuracy:		91.52 %
Epoch 1530 of 2000 took 0.035s
  training loss:		0.005124
  validation loss:		0.602636
  validation accuracy:		91.30 %
Epoch 1531 of 2000 took 0.035s
  training loss:		0.005076
  validation loss:		0.594550
  validation accuracy:		91.63 %
Epoch 1532 of 2000 took 0.035s
  training loss:		0.004774
  validation loss:		0.594799
  validation accuracy:		91.74 %
Epoch 1533 of 2000 took 0.035s
  training loss:		0.005065
  validation loss:		0.599784
  validation accuracy:		91.20 %
Epoch 1534 of 2000 took 0.035s
  training loss:		0.004955
  validation loss:		0.590998
  validation accuracy:		91.52 %
Epoch 1535 of 2000 took 0.035s
  training loss:		0.005027
  validation loss:		0.596052
  validation accuracy:		91.20 %
Epoch 1536 of 2000 took 0.035s
  training loss:		0.005013
  validation loss:		0.592345
  validation accuracy:		91.41 %
Epoch 1537 of 2000 took 0.035s
  training loss:		0.005036
  validation loss:		0.598176
  validation accuracy:		91.30 %
Epoch 1538 of 2000 took 0.035s
  training loss:		0.004959
  validation loss:		0.593123
  validation accuracy:		91.52 %
Epoch 1539 of 2000 took 0.035s
  training loss:		0.005018
  validation loss:		0.598058
  validation accuracy:		91.30 %
Epoch 1540 of 2000 took 0.035s
  training loss:		0.004930
  validation loss:		0.597833
  validation accuracy:		91.63 %
Epoch 1541 of 2000 took 0.035s
  training loss:		0.005000
  validation loss:		0.606779
  validation accuracy:		91.41 %
Epoch 1542 of 2000 took 0.035s
  training loss:		0.005007
  validation loss:		0.590213
  validation accuracy:		91.96 %
Epoch 1543 of 2000 took 0.035s
  training loss:		0.005044
  validation loss:		0.597245
  validation accuracy:		91.52 %
Epoch 1544 of 2000 took 0.035s
  training loss:		0.005148
  validation loss:		0.596132
  validation accuracy:		91.85 %
Epoch 1545 of 2000 took 0.035s
  training loss:		0.004943
  validation loss:		0.594736
  validation accuracy:		91.41 %
Epoch 1546 of 2000 took 0.035s
  training loss:		0.004805
  validation loss:		0.603914
  validation accuracy:		91.63 %
Epoch 1547 of 2000 took 0.035s
  training loss:		0.004996
  validation loss:		0.614877
  validation accuracy:		90.98 %
Epoch 1548 of 2000 took 0.035s
  training loss:		0.005137
  validation loss:		0.595067
  validation accuracy:		91.74 %
Epoch 1549 of 2000 took 0.035s
  training loss:		0.004832
  validation loss:		0.602517
  validation accuracy:		91.30 %
Epoch 1550 of 2000 took 0.035s
  training loss:		0.004715
  validation loss:		0.604903
  validation accuracy:		91.52 %
Epoch 1551 of 2000 took 0.035s
  training loss:		0.004884
  validation loss:		0.603265
  validation accuracy:		91.74 %
Epoch 1552 of 2000 took 0.035s
  training loss:		0.004963
  validation loss:		0.598797
  validation accuracy:		91.63 %
Epoch 1553 of 2000 took 0.035s
  training loss:		0.004990
  validation loss:		0.607267
  validation accuracy:		91.74 %
Epoch 1554 of 2000 took 0.035s
  training loss:		0.004907
  validation loss:		0.598523
  validation accuracy:		91.74 %
Epoch 1555 of 2000 took 0.035s
  training loss:		0.004883
  validation loss:		0.594366
  validation accuracy:		91.63 %
Epoch 1556 of 2000 took 0.035s
  training loss:		0.004804
  validation loss:		0.599052
  validation accuracy:		91.41 %
Epoch 1557 of 2000 took 0.035s
  training loss:		0.004668
  validation loss:		0.596745
  validation accuracy:		91.63 %
Epoch 1558 of 2000 took 0.035s
  training loss:		0.004920
  validation loss:		0.595996
  validation accuracy:		91.74 %
Epoch 1559 of 2000 took 0.035s
  training loss:		0.004784
  validation loss:		0.604689
  validation accuracy:		91.52 %
Epoch 1560 of 2000 took 0.035s
  training loss:		0.004595
  validation loss:		0.598687
  validation accuracy:		91.63 %
Epoch 1561 of 2000 took 0.035s
  training loss:		0.004785
  validation loss:		0.600163
  validation accuracy:		91.85 %
Epoch 1562 of 2000 took 0.035s
  training loss:		0.004759
  validation loss:		0.599475
  validation accuracy:		91.41 %
Epoch 1563 of 2000 took 0.035s
  training loss:		0.004746
  validation loss:		0.600592
  validation accuracy:		91.63 %
Epoch 1564 of 2000 took 0.035s
  training loss:		0.004747
  validation loss:		0.605103
  validation accuracy:		91.63 %
Epoch 1565 of 2000 took 0.035s
  training loss:		0.004567
  validation loss:		0.592209
  validation accuracy:		91.96 %
Epoch 1566 of 2000 took 0.035s
  training loss:		0.004572
  validation loss:		0.604277
  validation accuracy:		91.63 %
Epoch 1567 of 2000 took 0.035s
  training loss:		0.004668
  validation loss:		0.601577
  validation accuracy:		91.52 %
Epoch 1568 of 2000 took 0.035s
  training loss:		0.004688
  validation loss:		0.604705
  validation accuracy:		91.74 %
Epoch 1569 of 2000 took 0.035s
  training loss:		0.004696
  validation loss:		0.599479
  validation accuracy:		91.63 %
Epoch 1570 of 2000 took 0.035s
  training loss:		0.004769
  validation loss:		0.599682
  validation accuracy:		91.74 %
Epoch 1571 of 2000 took 0.035s
  training loss:		0.004613
  validation loss:		0.605439
  validation accuracy:		91.63 %
Epoch 1572 of 2000 took 0.035s
  training loss:		0.004616
  validation loss:		0.602082
  validation accuracy:		91.63 %
Epoch 1573 of 2000 took 0.035s
  training loss:		0.004534
  validation loss:		0.604903
  validation accuracy:		91.52 %
Epoch 1574 of 2000 took 0.035s
  training loss:		0.004619
  validation loss:		0.602111
  validation accuracy:		91.41 %
Epoch 1575 of 2000 took 0.035s
  training loss:		0.004472
  validation loss:		0.611851
  validation accuracy:		91.52 %
Epoch 1576 of 2000 took 0.035s
  training loss:		0.004631
  validation loss:		0.604882
  validation accuracy:		91.63 %
Epoch 1577 of 2000 took 0.035s
  training loss:		0.004633
  validation loss:		0.603409
  validation accuracy:		91.52 %
Epoch 1578 of 2000 took 0.035s
  training loss:		0.004674
  validation loss:		0.611163
  validation accuracy:		91.41 %
Epoch 1579 of 2000 took 0.035s
  training loss:		0.004684
  validation loss:		0.605345
  validation accuracy:		91.63 %
Epoch 1580 of 2000 took 0.035s
  training loss:		0.004345
  validation loss:		0.605994
  validation accuracy:		91.74 %
Epoch 1581 of 2000 took 0.035s
  training loss:		0.004612
  validation loss:		0.604629
  validation accuracy:		91.63 %
Epoch 1582 of 2000 took 0.035s
  training loss:		0.004505
  validation loss:		0.599893
  validation accuracy:		91.74 %
Epoch 1583 of 2000 took 0.035s
  training loss:		0.004750
  validation loss:		0.602381
  validation accuracy:		91.63 %
Epoch 1584 of 2000 took 0.035s
  training loss:		0.004348
  validation loss:		0.605444
  validation accuracy:		91.52 %
Epoch 1585 of 2000 took 0.035s
  training loss:		0.004584
  validation loss:		0.606775
  validation accuracy:		91.63 %
Epoch 1586 of 2000 took 0.035s
  training loss:		0.004589
  validation loss:		0.610576
  validation accuracy:		91.63 %
Epoch 1587 of 2000 took 0.035s
  training loss:		0.004581
  validation loss:		0.612035
  validation accuracy:		91.63 %
Epoch 1588 of 2000 took 0.035s
  training loss:		0.004459
  validation loss:		0.604469
  validation accuracy:		91.52 %
Epoch 1589 of 2000 took 0.035s
  training loss:		0.004495
  validation loss:		0.601863
  validation accuracy:		91.63 %
Epoch 1590 of 2000 took 0.035s
  training loss:		0.004546
  validation loss:		0.611128
  validation accuracy:		91.63 %
Epoch 1591 of 2000 took 0.035s
  training loss:		0.004604
  validation loss:		0.601643
  validation accuracy:		91.63 %
Epoch 1592 of 2000 took 0.035s
  training loss:		0.004408
  validation loss:		0.613843
  validation accuracy:		91.41 %
Epoch 1593 of 2000 took 0.035s
  training loss:		0.004637
  validation loss:		0.609534
  validation accuracy:		91.74 %
Epoch 1594 of 2000 took 0.035s
  training loss:		0.004593
  validation loss:		0.608964
  validation accuracy:		91.52 %
Epoch 1595 of 2000 took 0.035s
  training loss:		0.004508
  validation loss:		0.608689
  validation accuracy:		91.30 %
Epoch 1596 of 2000 took 0.035s
  training loss:		0.004499
  validation loss:		0.610197
  validation accuracy:		91.52 %
Epoch 1597 of 2000 took 0.035s
  training loss:		0.004576
  validation loss:		0.606405
  validation accuracy:		91.52 %
Epoch 1598 of 2000 took 0.035s
  training loss:		0.004419
  validation loss:		0.611830
  validation accuracy:		91.63 %
Epoch 1599 of 2000 took 0.035s
  training loss:		0.004422
  validation loss:		0.607353
  validation accuracy:		91.74 %
Epoch 1600 of 2000 took 0.035s
  training loss:		0.004529
  validation loss:		0.615709
  validation accuracy:		91.52 %
Epoch 1601 of 2000 took 0.035s
  training loss:		0.004473
  validation loss:		0.614902
  validation accuracy:		91.63 %
Epoch 1602 of 2000 took 0.035s
  training loss:		0.004481
  validation loss:		0.606688
  validation accuracy:		91.63 %
Epoch 1603 of 2000 took 0.035s
  training loss:		0.004407
  validation loss:		0.610765
  validation accuracy:		91.30 %
Epoch 1604 of 2000 took 0.035s
  training loss:		0.004448
  validation loss:		0.603597
  validation accuracy:		91.74 %
Epoch 1605 of 2000 took 0.035s
  training loss:		0.004482
  validation loss:		0.616697
  validation accuracy:		91.63 %
Epoch 1606 of 2000 took 0.035s
  training loss:		0.004543
  validation loss:		0.608303
  validation accuracy:		91.74 %
Epoch 1607 of 2000 took 0.035s
  training loss:		0.004360
  validation loss:		0.615417
  validation accuracy:		91.52 %
Epoch 1608 of 2000 took 0.035s
  training loss:		0.004352
  validation loss:		0.609637
  validation accuracy:		91.63 %
Epoch 1609 of 2000 took 0.035s
  training loss:		0.004514
  validation loss:		0.610865
  validation accuracy:		91.41 %
Epoch 1610 of 2000 took 0.035s
  training loss:		0.004449
  validation loss:		0.607309
  validation accuracy:		91.74 %
Epoch 1611 of 2000 took 0.035s
  training loss:		0.004358
  validation loss:		0.607258
  validation accuracy:		91.74 %
Epoch 1612 of 2000 took 0.035s
  training loss:		0.004405
  validation loss:		0.615412
  validation accuracy:		91.41 %
Epoch 1613 of 2000 took 0.035s
  training loss:		0.004300
  validation loss:		0.605617
  validation accuracy:		91.96 %
Epoch 1614 of 2000 took 0.035s
  training loss:		0.004289
  validation loss:		0.609997
  validation accuracy:		91.74 %
Epoch 1615 of 2000 took 0.035s
  training loss:		0.004446
  validation loss:		0.615733
  validation accuracy:		91.30 %
Epoch 1616 of 2000 took 0.035s
  training loss:		0.004345
  validation loss:		0.605957
  validation accuracy:		91.85 %
Epoch 1617 of 2000 took 0.035s
  training loss:		0.004523
  validation loss:		0.612545
  validation accuracy:		91.52 %
Epoch 1618 of 2000 took 0.035s
  training loss:		0.004220
  validation loss:		0.615626
  validation accuracy:		91.74 %
Epoch 1619 of 2000 took 0.035s
  training loss:		0.004300
  validation loss:		0.607818
  validation accuracy:		91.52 %
Epoch 1620 of 2000 took 0.035s
  training loss:		0.004367
  validation loss:		0.615508
  validation accuracy:		91.30 %
Epoch 1621 of 2000 took 0.035s
  training loss:		0.004366
  validation loss:		0.608091
  validation accuracy:		91.74 %
Epoch 1622 of 2000 took 0.035s
  training loss:		0.004274
  validation loss:		0.610034
  validation accuracy:		91.63 %
Epoch 1623 of 2000 took 0.035s
  training loss:		0.004161
  validation loss:		0.615879
  validation accuracy:		91.52 %
Epoch 1624 of 2000 took 0.035s
  training loss:		0.004247
  validation loss:		0.614951
  validation accuracy:		91.30 %
Epoch 1625 of 2000 took 0.035s
  training loss:		0.004331
  validation loss:		0.604144
  validation accuracy:		91.85 %
Epoch 1626 of 2000 took 0.035s
  training loss:		0.004275
  validation loss:		0.619662
  validation accuracy:		91.41 %
Epoch 1627 of 2000 took 0.035s
  training loss:		0.004389
  validation loss:		0.609799
  validation accuracy:		91.74 %
Epoch 1628 of 2000 took 0.035s
  training loss:		0.004233
  validation loss:		0.609050
  validation accuracy:		91.63 %
Epoch 1629 of 2000 took 0.035s
  training loss:		0.004270
  validation loss:		0.613667
  validation accuracy:		91.63 %
Epoch 1630 of 2000 took 0.035s
  training loss:		0.004091
  validation loss:		0.617153
  validation accuracy:		91.63 %
Epoch 1631 of 2000 took 0.035s
  training loss:		0.004248
  validation loss:		0.615759
  validation accuracy:		91.30 %
Epoch 1632 of 2000 took 0.035s
  training loss:		0.004155
  validation loss:		0.613029
  validation accuracy:		91.63 %
Epoch 1633 of 2000 took 0.035s
  training loss:		0.004173
  validation loss:		0.624086
  validation accuracy:		91.20 %
Epoch 1634 of 2000 took 0.035s
  training loss:		0.004298
  validation loss:		0.610321
  validation accuracy:		91.74 %
Epoch 1635 of 2000 took 0.035s
  training loss:		0.004152
  validation loss:		0.614821
  validation accuracy:		91.63 %
Epoch 1636 of 2000 took 0.035s
  training loss:		0.004178
  validation loss:		0.613352
  validation accuracy:		91.52 %
Epoch 1637 of 2000 took 0.035s
  training loss:		0.004210
  validation loss:		0.621024
  validation accuracy:		91.52 %
Epoch 1638 of 2000 took 0.035s
  training loss:		0.004322
  validation loss:		0.613717
  validation accuracy:		91.52 %
Epoch 1639 of 2000 took 0.035s
  training loss:		0.004117
  validation loss:		0.612799
  validation accuracy:		91.63 %
Epoch 1640 of 2000 took 0.035s
  training loss:		0.004183
  validation loss:		0.618260
  validation accuracy:		91.41 %
Epoch 1641 of 2000 took 0.035s
  training loss:		0.004211
  validation loss:		0.616787
  validation accuracy:		91.74 %
Epoch 1642 of 2000 took 0.035s
  training loss:		0.004245
  validation loss:		0.612593
  validation accuracy:		91.52 %
Epoch 1643 of 2000 took 0.035s
  training loss:		0.004100
  validation loss:		0.616240
  validation accuracy:		91.52 %
Epoch 1644 of 2000 took 0.035s
  training loss:		0.004219
  validation loss:		0.613940
  validation accuracy:		91.74 %
Epoch 1645 of 2000 took 0.035s
  training loss:		0.004091
  validation loss:		0.615133
  validation accuracy:		91.63 %
Epoch 1646 of 2000 took 0.036s
  training loss:		0.004177
  validation loss:		0.621424
  validation accuracy:		91.41 %
Epoch 1647 of 2000 took 0.035s
  training loss:		0.004141
  validation loss:		0.617862
  validation accuracy:		91.41 %
Epoch 1648 of 2000 took 0.035s
  training loss:		0.004297
  validation loss:		0.616515
  validation accuracy:		91.63 %
Epoch 1649 of 2000 took 0.035s
  training loss:		0.004150
  validation loss:		0.623242
  validation accuracy:		91.41 %
Epoch 1650 of 2000 took 0.035s
  training loss:		0.004053
  validation loss:		0.616475
  validation accuracy:		91.74 %
Epoch 1651 of 2000 took 0.035s
  training loss:		0.003937
  validation loss:		0.619104
  validation accuracy:		91.30 %
Epoch 1652 of 2000 took 0.035s
  training loss:		0.004110
  validation loss:		0.618697
  validation accuracy:		91.63 %
Epoch 1653 of 2000 took 0.035s
  training loss:		0.004042
  validation loss:		0.620985
  validation accuracy:		91.63 %
Epoch 1654 of 2000 took 0.035s
  training loss:		0.004090
  validation loss:		0.622347
  validation accuracy:		91.63 %
Epoch 1655 of 2000 took 0.035s
  training loss:		0.004176
  validation loss:		0.622136
  validation accuracy:		91.30 %
Epoch 1656 of 2000 took 0.035s
  training loss:		0.004035
  validation loss:		0.615891
  validation accuracy:		91.74 %
Epoch 1657 of 2000 took 0.035s
  training loss:		0.004108
  validation loss:		0.617089
  validation accuracy:		91.74 %
Epoch 1658 of 2000 took 0.035s
  training loss:		0.004169
  validation loss:		0.628947
  validation accuracy:		91.20 %
Epoch 1659 of 2000 took 0.035s
  training loss:		0.004207
  validation loss:		0.615466
  validation accuracy:		91.74 %
Epoch 1660 of 2000 took 0.035s
  training loss:		0.004070
  validation loss:		0.622741
  validation accuracy:		91.63 %
Epoch 1661 of 2000 took 0.035s
  training loss:		0.004029
  validation loss:		0.620299
  validation accuracy:		91.52 %
Epoch 1662 of 2000 took 0.035s
  training loss:		0.003945
  validation loss:		0.622858
  validation accuracy:		91.52 %
Epoch 1663 of 2000 took 0.035s
  training loss:		0.004088
  validation loss:		0.620639
  validation accuracy:		91.63 %
Epoch 1664 of 2000 took 0.035s
  training loss:		0.004024
  validation loss:		0.620432
  validation accuracy:		91.52 %
Epoch 1665 of 2000 took 0.035s
  training loss:		0.004040
  validation loss:		0.625209
  validation accuracy:		91.52 %
Epoch 1666 of 2000 took 0.035s
  training loss:		0.004041
  validation loss:		0.622907
  validation accuracy:		91.52 %
Epoch 1667 of 2000 took 0.035s
  training loss:		0.003998
  validation loss:		0.620300
  validation accuracy:		91.63 %
Epoch 1668 of 2000 took 0.035s
  training loss:		0.004191
  validation loss:		0.618928
  validation accuracy:		91.52 %
Epoch 1669 of 2000 took 0.035s
  training loss:		0.004018
  validation loss:		0.621037
  validation accuracy:		91.74 %
Epoch 1670 of 2000 took 0.035s
  training loss:		0.004020
  validation loss:		0.620001
  validation accuracy:		91.74 %
Epoch 1671 of 2000 took 0.035s
  training loss:		0.004065
  validation loss:		0.621089
  validation accuracy:		91.41 %
Epoch 1672 of 2000 took 0.035s
  training loss:		0.003883
  validation loss:		0.624099
  validation accuracy:		91.63 %
Epoch 1673 of 2000 took 0.035s
  training loss:		0.004040
  validation loss:		0.624561
  validation accuracy:		91.63 %
Epoch 1674 of 2000 took 0.035s
  training loss:		0.004035
  validation loss:		0.621900
  validation accuracy:		91.52 %
Epoch 1675 of 2000 took 0.035s
  training loss:		0.003950
  validation loss:		0.620545
  validation accuracy:		91.63 %
Epoch 1676 of 2000 took 0.035s
  training loss:		0.004047
  validation loss:		0.624434
  validation accuracy:		91.85 %
Epoch 1677 of 2000 took 0.035s
  training loss:		0.003935
  validation loss:		0.622031
  validation accuracy:		91.52 %
Epoch 1678 of 2000 took 0.035s
  training loss:		0.003894
  validation loss:		0.621225
  validation accuracy:		91.74 %
Epoch 1679 of 2000 took 0.035s
  training loss:		0.003866
  validation loss:		0.621681
  validation accuracy:		91.52 %
Epoch 1680 of 2000 took 0.035s
  training loss:		0.004069
  validation loss:		0.623543
  validation accuracy:		91.63 %
Epoch 1681 of 2000 took 0.036s
  training loss:		0.003929
  validation loss:		0.632688
  validation accuracy:		91.30 %
Epoch 1682 of 2000 took 0.035s
  training loss:		0.004023
  validation loss:		0.626438
  validation accuracy:		91.63 %
Epoch 1683 of 2000 took 0.035s
  training loss:		0.003934
  validation loss:		0.623606
  validation accuracy:		91.63 %
Epoch 1684 of 2000 took 0.035s
  training loss:		0.003837
  validation loss:		0.622748
  validation accuracy:		91.63 %
Epoch 1685 of 2000 took 0.035s
  training loss:		0.003897
  validation loss:		0.627743
  validation accuracy:		91.74 %
Epoch 1686 of 2000 took 0.035s
  training loss:		0.003969
  validation loss:		0.618878
  validation accuracy:		91.63 %
Epoch 1687 of 2000 took 0.035s
  training loss:		0.003796
  validation loss:		0.618738
  validation accuracy:		91.85 %
Epoch 1688 of 2000 took 0.035s
  training loss:		0.004011
  validation loss:		0.627113
  validation accuracy:		91.63 %
Epoch 1689 of 2000 took 0.035s
  training loss:		0.003826
  validation loss:		0.619946
  validation accuracy:		91.74 %
Epoch 1690 of 2000 took 0.035s
  training loss:		0.003773
  validation loss:		0.619358
  validation accuracy:		91.63 %
Epoch 1691 of 2000 took 0.035s
  training loss:		0.003905
  validation loss:		0.621051
  validation accuracy:		91.63 %
Epoch 1692 of 2000 took 0.035s
  training loss:		0.004016
  validation loss:		0.628437
  validation accuracy:		91.41 %
Epoch 1693 of 2000 took 0.035s
  training loss:		0.003962
  validation loss:		0.623239
  validation accuracy:		91.52 %
Epoch 1694 of 2000 took 0.035s
  training loss:		0.003772
  validation loss:		0.623037
  validation accuracy:		91.52 %
Epoch 1695 of 2000 took 0.035s
  training loss:		0.003714
  validation loss:		0.624943
  validation accuracy:		91.63 %
Epoch 1696 of 2000 took 0.035s
  training loss:		0.003861
  validation loss:		0.626108
  validation accuracy:		91.74 %
Epoch 1697 of 2000 took 0.035s
  training loss:		0.003799
  validation loss:		0.626713
  validation accuracy:		91.52 %
Epoch 1698 of 2000 took 0.035s
  training loss:		0.003922
  validation loss:		0.621071
  validation accuracy:		91.74 %
Epoch 1699 of 2000 took 0.035s
  training loss:		0.003770
  validation loss:		0.630821
  validation accuracy:		91.30 %
Epoch 1700 of 2000 took 0.035s
  training loss:		0.004025
  validation loss:		0.626312
  validation accuracy:		91.63 %
Epoch 1701 of 2000 took 0.035s
  training loss:		0.003783
  validation loss:		0.627550
  validation accuracy:		91.52 %
Epoch 1702 of 2000 took 0.035s
  training loss:		0.003770
  validation loss:		0.625437
  validation accuracy:		91.63 %
Epoch 1703 of 2000 took 0.035s
  training loss:		0.003701
  validation loss:		0.629695
  validation accuracy:		91.63 %
Epoch 1704 of 2000 took 0.035s
  training loss:		0.003827
  validation loss:		0.624375
  validation accuracy:		91.41 %
Epoch 1705 of 2000 took 0.035s
  training loss:		0.003771
  validation loss:		0.626679
  validation accuracy:		91.63 %
Epoch 1706 of 2000 took 0.035s
  training loss:		0.003750
  validation loss:		0.626067
  validation accuracy:		91.52 %
Epoch 1707 of 2000 took 0.035s
  training loss:		0.003815
  validation loss:		0.621868
  validation accuracy:		91.63 %
Epoch 1708 of 2000 took 0.035s
  training loss:		0.003830
  validation loss:		0.633191
  validation accuracy:		91.30 %
Epoch 1709 of 2000 took 0.035s
  training loss:		0.003781
  validation loss:		0.626750
  validation accuracy:		91.74 %
Epoch 1710 of 2000 took 0.035s
  training loss:		0.003726
  validation loss:		0.626522
  validation accuracy:		91.52 %
Epoch 1711 of 2000 took 0.035s
  training loss:		0.003800
  validation loss:		0.620109
  validation accuracy:		91.85 %
Epoch 1712 of 2000 took 0.035s
  training loss:		0.003823
  validation loss:		0.625271
  validation accuracy:		91.74 %
Epoch 1713 of 2000 took 0.035s
  training loss:		0.003814
  validation loss:		0.627354
  validation accuracy:		91.63 %
Epoch 1714 of 2000 took 0.035s
  training loss:		0.003678
  validation loss:		0.628750
  validation accuracy:		91.41 %
Epoch 1715 of 2000 took 0.035s
  training loss:		0.003768
  validation loss:		0.634858
  validation accuracy:		91.52 %
Epoch 1716 of 2000 took 0.035s
  training loss:		0.003659
  validation loss:		0.623865
  validation accuracy:		91.52 %
Epoch 1717 of 2000 took 0.035s
  training loss:		0.003738
  validation loss:		0.630869
  validation accuracy:		91.63 %
Epoch 1718 of 2000 took 0.035s
  training loss:		0.003753
  validation loss:		0.636505
  validation accuracy:		91.52 %
Epoch 1719 of 2000 took 0.035s
  training loss:		0.003587
  validation loss:		0.629601
  validation accuracy:		91.63 %
Epoch 1720 of 2000 took 0.035s
  training loss:		0.003721
  validation loss:		0.631183
  validation accuracy:		91.52 %
Epoch 1721 of 2000 took 0.035s
  training loss:		0.003744
  validation loss:		0.639719
  validation accuracy:		91.30 %
Epoch 1722 of 2000 took 0.035s
  training loss:		0.003793
  validation loss:		0.631794
  validation accuracy:		91.63 %
Epoch 1723 of 2000 took 0.035s
  training loss:		0.003725
  validation loss:		0.624825
  validation accuracy:		91.74 %
Epoch 1724 of 2000 took 0.035s
  training loss:		0.003604
  validation loss:		0.631806
  validation accuracy:		91.52 %
Epoch 1725 of 2000 took 0.035s
  training loss:		0.003698
  validation loss:		0.630730
  validation accuracy:		91.74 %
Epoch 1726 of 2000 took 0.035s
  training loss:		0.003662
  validation loss:		0.627272
  validation accuracy:		91.63 %
Epoch 1727 of 2000 took 0.035s
  training loss:		0.003632
  validation loss:		0.633207
  validation accuracy:		91.52 %
Epoch 1728 of 2000 took 0.035s
  training loss:		0.003802
  validation loss:		0.638509
  validation accuracy:		91.41 %
Epoch 1729 of 2000 took 0.035s
  training loss:		0.003711
  validation loss:		0.623639
  validation accuracy:		91.85 %
Epoch 1730 of 2000 took 0.035s
  training loss:		0.003694
  validation loss:		0.636300
  validation accuracy:		91.52 %
Epoch 1731 of 2000 took 0.035s
  training loss:		0.003620
  validation loss:		0.628514
  validation accuracy:		91.74 %
Epoch 1732 of 2000 took 0.035s
  training loss:		0.003615
  validation loss:		0.629405
  validation accuracy:		91.52 %
Epoch 1733 of 2000 took 0.035s
  training loss:		0.003680
  validation loss:		0.633892
  validation accuracy:		91.74 %
Epoch 1734 of 2000 took 0.035s
  training loss:		0.003644
  validation loss:		0.634570
  validation accuracy:		91.52 %
Epoch 1735 of 2000 took 0.035s
  training loss:		0.003605
  validation loss:		0.635253
  validation accuracy:		91.52 %
Epoch 1736 of 2000 took 0.035s
  training loss:		0.003612
  validation loss:		0.632176
  validation accuracy:		91.52 %
Epoch 1737 of 2000 took 0.035s
  training loss:		0.003626
  validation loss:		0.627822
  validation accuracy:		91.74 %
Epoch 1738 of 2000 took 0.035s
  training loss:		0.003613
  validation loss:		0.638292
  validation accuracy:		91.41 %
Epoch 1739 of 2000 took 0.035s
  training loss:		0.003620
  validation loss:		0.624601
  validation accuracy:		91.85 %
Epoch 1740 of 2000 took 0.035s
  training loss:		0.003520
  validation loss:		0.630787
  validation accuracy:		91.74 %
Epoch 1741 of 2000 took 0.035s
  training loss:		0.003475
  validation loss:		0.629783
  validation accuracy:		91.74 %
Epoch 1742 of 2000 took 0.035s
  training loss:		0.003378
  validation loss:		0.627993
  validation accuracy:		91.74 %
Epoch 1743 of 2000 took 0.035s
  training loss:		0.003683
  validation loss:		0.641183
  validation accuracy:		91.52 %
Epoch 1744 of 2000 took 0.035s
  training loss:		0.003593
  validation loss:		0.632253
  validation accuracy:		91.52 %
Epoch 1745 of 2000 took 0.035s
  training loss:		0.003593
  validation loss:		0.628932
  validation accuracy:		91.74 %
Epoch 1746 of 2000 took 0.035s
  training loss:		0.003478
  validation loss:		0.636434
  validation accuracy:		91.52 %
Epoch 1747 of 2000 took 0.035s
  training loss:		0.003539
  validation loss:		0.626579
  validation accuracy:		91.85 %
Epoch 1748 of 2000 took 0.035s
  training loss:		0.003539
  validation loss:		0.632070
  validation accuracy:		91.52 %
Epoch 1749 of 2000 took 0.035s
  training loss:		0.003419
  validation loss:		0.629768
  validation accuracy:		91.74 %
Epoch 1750 of 2000 took 0.035s
  training loss:		0.003517
  validation loss:		0.634910
  validation accuracy:		91.74 %
Epoch 1751 of 2000 took 0.035s
  training loss:		0.003586
  validation loss:		0.636089
  validation accuracy:		91.52 %
Epoch 1752 of 2000 took 0.035s
  training loss:		0.003528
  validation loss:		0.624665
  validation accuracy:		91.85 %
Epoch 1753 of 2000 took 0.035s
  training loss:		0.003477
  validation loss:		0.630693
  validation accuracy:		91.63 %
Epoch 1754 of 2000 took 0.035s
  training loss:		0.003558
  validation loss:		0.637200
  validation accuracy:		91.52 %
Epoch 1755 of 2000 took 0.035s
  training loss:		0.003560
  validation loss:		0.635103
  validation accuracy:		91.41 %
Epoch 1756 of 2000 took 0.035s
  training loss:		0.003366
  validation loss:		0.633621
  validation accuracy:		91.63 %
Epoch 1757 of 2000 took 0.035s
  training loss:		0.003468
  validation loss:		0.630696
  validation accuracy:		91.85 %
Epoch 1758 of 2000 took 0.035s
  training loss:		0.003516
  validation loss:		0.631101
  validation accuracy:		91.85 %
Epoch 1759 of 2000 took 0.035s
  training loss:		0.003481
  validation loss:		0.636349
  validation accuracy:		91.52 %
Epoch 1760 of 2000 took 0.035s
  training loss:		0.003532
  validation loss:		0.635948
  validation accuracy:		91.52 %
Epoch 1761 of 2000 took 0.035s
  training loss:		0.003559
  validation loss:		0.633591
  validation accuracy:		91.74 %
Epoch 1762 of 2000 took 0.035s
  training loss:		0.003515
  validation loss:		0.637976
  validation accuracy:		91.52 %
Epoch 1763 of 2000 took 0.035s
  training loss:		0.003504
  validation loss:		0.633792
  validation accuracy:		91.52 %
Epoch 1764 of 2000 took 0.035s
  training loss:		0.003478
  validation loss:		0.632515
  validation accuracy:		91.85 %
Epoch 1765 of 2000 took 0.035s
  training loss:		0.003561
  validation loss:		0.641003
  validation accuracy:		91.74 %
Epoch 1766 of 2000 took 0.035s
  training loss:		0.003489
  validation loss:		0.628112
  validation accuracy:		91.85 %
Epoch 1767 of 2000 took 0.035s
  training loss:		0.003478
  validation loss:		0.626680
  validation accuracy:		91.85 %
Epoch 1768 of 2000 took 0.035s
  training loss:		0.003503
  validation loss:		0.642704
  validation accuracy:		91.63 %
Epoch 1769 of 2000 took 0.035s
  training loss:		0.003473
  validation loss:		0.637759
  validation accuracy:		91.74 %
Epoch 1770 of 2000 took 0.035s
  training loss:		0.003434
  validation loss:		0.636714
  validation accuracy:		91.52 %
Epoch 1771 of 2000 took 0.035s
  training loss:		0.003339
  validation loss:		0.639188
  validation accuracy:		91.63 %
Epoch 1772 of 2000 took 0.035s
  training loss:		0.003457
  validation loss:		0.645406
  validation accuracy:		91.20 %
Epoch 1773 of 2000 took 0.035s
  training loss:		0.003546
  validation loss:		0.639002
  validation accuracy:		91.63 %
Epoch 1774 of 2000 took 0.035s
  training loss:		0.003475
  validation loss:		0.636635
  validation accuracy:		91.74 %
Epoch 1775 of 2000 took 0.035s
  training loss:		0.003386
  validation loss:		0.633887
  validation accuracy:		91.85 %
Epoch 1776 of 2000 took 0.035s
  training loss:		0.003442
  validation loss:		0.635582
  validation accuracy:		91.52 %
Epoch 1777 of 2000 took 0.035s
  training loss:		0.003460
  validation loss:		0.638121
  validation accuracy:		91.74 %
Epoch 1778 of 2000 took 0.035s
  training loss:		0.003361
  validation loss:		0.637312
  validation accuracy:		91.63 %
Epoch 1779 of 2000 took 0.035s
  training loss:		0.003460
  validation loss:		0.639371
  validation accuracy:		91.52 %
Epoch 1780 of 2000 took 0.035s
  training loss:		0.003363
  validation loss:		0.638054
  validation accuracy:		91.52 %
Epoch 1781 of 2000 took 0.035s
  training loss:		0.003243
  validation loss:		0.637892
  validation accuracy:		91.74 %
Epoch 1782 of 2000 took 0.035s
  training loss:		0.003410
  validation loss:		0.633443
  validation accuracy:		91.85 %
Epoch 1783 of 2000 took 0.035s
  training loss:		0.003389
  validation loss:		0.639900
  validation accuracy:		91.52 %
Epoch 1784 of 2000 took 0.035s
  training loss:		0.003421
  validation loss:		0.636196
  validation accuracy:		91.63 %
Epoch 1785 of 2000 took 0.035s
  training loss:		0.003351
  validation loss:		0.642956
  validation accuracy:		91.63 %
Epoch 1786 of 2000 took 0.035s
  training loss:		0.003342
  validation loss:		0.638660
  validation accuracy:		91.52 %
Epoch 1787 of 2000 took 0.035s
  training loss:		0.003419
  validation loss:		0.633076
  validation accuracy:		91.85 %
Epoch 1788 of 2000 took 0.035s
  training loss:		0.003401
  validation loss:		0.644131
  validation accuracy:		91.63 %
Epoch 1789 of 2000 took 0.035s
  training loss:		0.003439
  validation loss:		0.630918
  validation accuracy:		92.07 %
Epoch 1790 of 2000 took 0.035s
  training loss:		0.003389
  validation loss:		0.643958
  validation accuracy:		91.52 %
Epoch 1791 of 2000 took 0.035s
  training loss:		0.003383
  validation loss:		0.642580
  validation accuracy:		91.52 %
Epoch 1792 of 2000 took 0.035s
  training loss:		0.003452
  validation loss:		0.638351
  validation accuracy:		91.74 %
Epoch 1793 of 2000 took 0.035s
  training loss:		0.003370
  validation loss:		0.639801
  validation accuracy:		91.52 %
Epoch 1794 of 2000 took 0.035s
  training loss:		0.003417
  validation loss:		0.640108
  validation accuracy:		91.63 %
Epoch 1795 of 2000 took 0.035s
  training loss:		0.003401
  validation loss:		0.643466
  validation accuracy:		91.63 %
Epoch 1796 of 2000 took 0.035s
  training loss:		0.003368
  validation loss:		0.641137
  validation accuracy:		91.63 %
Epoch 1797 of 2000 took 0.035s
  training loss:		0.003380
  validation loss:		0.641745
  validation accuracy:		91.52 %
Epoch 1798 of 2000 took 0.035s
  training loss:		0.003258
  validation loss:		0.640517
  validation accuracy:		91.74 %
Epoch 1799 of 2000 took 0.035s
  training loss:		0.003295
  validation loss:		0.642121
  validation accuracy:		91.63 %
Epoch 1800 of 2000 took 0.035s
  training loss:		0.003398
  validation loss:		0.641528
  validation accuracy:		91.63 %
Epoch 1801 of 2000 took 0.035s
  training loss:		0.003333
  validation loss:		0.644309
  validation accuracy:		91.63 %
Epoch 1802 of 2000 took 0.035s
  training loss:		0.003199
  validation loss:		0.640653
  validation accuracy:		91.74 %
Epoch 1803 of 2000 took 0.035s
  training loss:		0.003211
  validation loss:		0.641989
  validation accuracy:		91.63 %
Epoch 1804 of 2000 took 0.035s
  training loss:		0.003361
  validation loss:		0.642494
  validation accuracy:		91.52 %
Epoch 1805 of 2000 took 0.035s
  training loss:		0.003285
  validation loss:		0.640841
  validation accuracy:		91.52 %
Epoch 1806 of 2000 took 0.035s
  training loss:		0.003124
  validation loss:		0.643615
  validation accuracy:		91.63 %
Epoch 1807 of 2000 took 0.035s
  training loss:		0.003388
  validation loss:		0.636947
  validation accuracy:		91.96 %
Epoch 1808 of 2000 took 0.035s
  training loss:		0.003275
  validation loss:		0.644516
  validation accuracy:		91.63 %
Epoch 1809 of 2000 took 0.035s
  training loss:		0.003260
  validation loss:		0.639849
  validation accuracy:		91.74 %
Epoch 1810 of 2000 took 0.035s
  training loss:		0.003190
  validation loss:		0.641483
  validation accuracy:		91.63 %
Epoch 1811 of 2000 took 0.035s
  training loss:		0.003194
  validation loss:		0.646645
  validation accuracy:		91.41 %
Epoch 1812 of 2000 took 0.035s
  training loss:		0.003300
  validation loss:		0.639256
  validation accuracy:		91.85 %
Epoch 1813 of 2000 took 0.035s
  training loss:		0.003214
  validation loss:		0.647194
  validation accuracy:		91.63 %
Epoch 1814 of 2000 took 0.035s
  training loss:		0.003135
  validation loss:		0.644276
  validation accuracy:		91.52 %
Epoch 1815 of 2000 took 0.035s
  training loss:		0.003269
  validation loss:		0.647293
  validation accuracy:		91.63 %
Epoch 1816 of 2000 took 0.035s
  training loss:		0.003274
  validation loss:		0.639202
  validation accuracy:		91.85 %
Epoch 1817 of 2000 took 0.035s
  training loss:		0.003172
  validation loss:		0.648929
  validation accuracy:		91.52 %
Epoch 1818 of 2000 took 0.035s
  training loss:		0.003268
  validation loss:		0.639748
  validation accuracy:		91.85 %
Epoch 1819 of 2000 took 0.035s
  training loss:		0.003273
  validation loss:		0.643523
  validation accuracy:		91.52 %
Epoch 1820 of 2000 took 0.035s
  training loss:		0.003183
  validation loss:		0.648067
  validation accuracy:		91.52 %
Epoch 1821 of 2000 took 0.035s
  training loss:		0.003200
  validation loss:		0.641143
  validation accuracy:		91.74 %
Epoch 1822 of 2000 took 0.035s
  training loss:		0.003214
  validation loss:		0.644160
  validation accuracy:		91.52 %
Epoch 1823 of 2000 took 0.035s
  training loss:		0.003239
  validation loss:		0.642910
  validation accuracy:		91.74 %
Epoch 1824 of 2000 took 0.035s
  training loss:		0.003209
  validation loss:		0.639194
  validation accuracy:		91.85 %
Epoch 1825 of 2000 took 0.035s
  training loss:		0.003195
  validation loss:		0.650775
  validation accuracy:		91.52 %
Epoch 1826 of 2000 took 0.035s
  training loss:		0.003042
  validation loss:		0.640545
  validation accuracy:		91.74 %
Epoch 1827 of 2000 took 0.036s
  training loss:		0.003259
  validation loss:		0.647226
  validation accuracy:		91.63 %
Epoch 1828 of 2000 took 0.035s
  training loss:		0.003187
  validation loss:		0.643919
  validation accuracy:		91.74 %
Epoch 1829 of 2000 took 0.035s
  training loss:		0.003056
  validation loss:		0.645972
  validation accuracy:		91.85 %
Epoch 1830 of 2000 took 0.035s
  training loss:		0.003132
  validation loss:		0.645692
  validation accuracy:		91.63 %
Epoch 1831 of 2000 took 0.035s
  training loss:		0.003128
  validation loss:		0.642503
  validation accuracy:		91.63 %
Epoch 1832 of 2000 took 0.035s
  training loss:		0.003103
  validation loss:		0.644110
  validation accuracy:		91.74 %
Epoch 1833 of 2000 took 0.035s
  training loss:		0.003109
  validation loss:		0.647521
  validation accuracy:		91.63 %
Epoch 1834 of 2000 took 0.035s
  training loss:		0.003131
  validation loss:		0.638575
  validation accuracy:		91.85 %
Epoch 1835 of 2000 took 0.035s
  training loss:		0.003177
  validation loss:		0.646111
  validation accuracy:		91.85 %
Epoch 1836 of 2000 took 0.035s
  training loss:		0.003180
  validation loss:		0.648525
  validation accuracy:		91.52 %
Epoch 1837 of 2000 took 0.035s
  training loss:		0.003088
  validation loss:		0.645323
  validation accuracy:		91.74 %
Epoch 1838 of 2000 took 0.035s
  training loss:		0.003195
  validation loss:		0.648705
  validation accuracy:		91.52 %
Epoch 1839 of 2000 took 0.035s
  training loss:		0.003098
  validation loss:		0.644738
  validation accuracy:		91.74 %
Epoch 1840 of 2000 took 0.035s
  training loss:		0.003162
  validation loss:		0.640610
  validation accuracy:		91.85 %
Epoch 1841 of 2000 took 0.035s
  training loss:		0.003164
  validation loss:		0.648795
  validation accuracy:		91.63 %
Epoch 1842 of 2000 took 0.035s
  training loss:		0.003001
  validation loss:		0.647513
  validation accuracy:		91.85 %
Epoch 1843 of 2000 took 0.035s
  training loss:		0.003173
  validation loss:		0.646229
  validation accuracy:		91.74 %
Epoch 1844 of 2000 took 0.035s
  training loss:		0.003119
  validation loss:		0.651387
  validation accuracy:		91.63 %
Epoch 1845 of 2000 took 0.035s
  training loss:		0.003096
  validation loss:		0.643812
  validation accuracy:		91.85 %
Epoch 1846 of 2000 took 0.035s
  training loss:		0.003101
  validation loss:		0.644231
  validation accuracy:		91.85 %
Epoch 1847 of 2000 took 0.035s
  training loss:		0.003057
  validation loss:		0.651038
  validation accuracy:		91.52 %
Epoch 1848 of 2000 took 0.035s
  training loss:		0.003044
  validation loss:		0.642475
  validation accuracy:		91.74 %
Epoch 1849 of 2000 took 0.035s
  training loss:		0.003178
  validation loss:		0.652804
  validation accuracy:		91.63 %
Epoch 1850 of 2000 took 0.035s
  training loss:		0.003211
  validation loss:		0.646994
  validation accuracy:		91.85 %
Epoch 1851 of 2000 took 0.035s
  training loss:		0.002969
  validation loss:		0.647657
  validation accuracy:		91.74 %
Epoch 1852 of 2000 took 0.035s
  training loss:		0.003085
  validation loss:		0.646722
  validation accuracy:		91.85 %
Epoch 1853 of 2000 took 0.035s
  training loss:		0.003015
  validation loss:		0.645354
  validation accuracy:		91.74 %
Epoch 1854 of 2000 took 0.035s
  training loss:		0.003067
  validation loss:		0.655226
  validation accuracy:		91.63 %
Epoch 1855 of 2000 took 0.035s
  training loss:		0.003027
  validation loss:		0.643946
  validation accuracy:		91.96 %
Epoch 1856 of 2000 took 0.035s
  training loss:		0.003101
  validation loss:		0.651610
  validation accuracy:		91.63 %
Epoch 1857 of 2000 took 0.035s
  training loss:		0.003081
  validation loss:		0.649476
  validation accuracy:		91.63 %
Epoch 1858 of 2000 took 0.035s
  training loss:		0.003076
  validation loss:		0.649366
  validation accuracy:		91.52 %
Epoch 1859 of 2000 took 0.035s
  training loss:		0.003052
  validation loss:		0.648377
  validation accuracy:		91.74 %
Epoch 1860 of 2000 took 0.035s
  training loss:		0.003050
  validation loss:		0.654287
  validation accuracy:		91.52 %
Epoch 1861 of 2000 took 0.035s
  training loss:		0.003013
  validation loss:		0.644481
  validation accuracy:		91.85 %
Epoch 1862 of 2000 took 0.035s
  training loss:		0.003169
  validation loss:		0.649660
  validation accuracy:		91.85 %
Epoch 1863 of 2000 took 0.035s
  training loss:		0.003040
  validation loss:		0.646276
  validation accuracy:		91.85 %
Epoch 1864 of 2000 took 0.035s
  training loss:		0.002958
  validation loss:		0.650298
  validation accuracy:		91.74 %
Epoch 1865 of 2000 took 0.035s
  training loss:		0.003004
  validation loss:		0.651566
  validation accuracy:		91.74 %
Epoch 1866 of 2000 took 0.035s
  training loss:		0.003004
  validation loss:		0.655765
  validation accuracy:		91.74 %
Epoch 1867 of 2000 took 0.035s
  training loss:		0.003005
  validation loss:		0.643791
  validation accuracy:		91.96 %
Epoch 1868 of 2000 took 0.035s
  training loss:		0.003105
  validation loss:		0.645821
  validation accuracy:		91.74 %
Epoch 1869 of 2000 took 0.035s
  training loss:		0.002955
  validation loss:		0.647164
  validation accuracy:		91.96 %
Epoch 1870 of 2000 took 0.035s
  training loss:		0.003011
  validation loss:		0.652253
  validation accuracy:		91.63 %
Epoch 1871 of 2000 took 0.035s
  training loss:		0.002945
  validation loss:		0.646991
  validation accuracy:		91.85 %
Epoch 1872 of 2000 took 0.035s
  training loss:		0.003041
  validation loss:		0.650709
  validation accuracy:		91.74 %
Epoch 1873 of 2000 took 0.035s
  training loss:		0.003022
  validation loss:		0.645474
  validation accuracy:		91.96 %
Epoch 1874 of 2000 took 0.035s
  training loss:		0.003003
  validation loss:		0.652609
  validation accuracy:		91.74 %
Epoch 1875 of 2000 took 0.035s
  training loss:		0.003011
  validation loss:		0.649938
  validation accuracy:		91.63 %
Epoch 1876 of 2000 took 0.035s
  training loss:		0.003086
  validation loss:		0.654740
  validation accuracy:		91.74 %
Epoch 1877 of 2000 took 0.035s
  training loss:		0.003068
  validation loss:		0.654281
  validation accuracy:		91.63 %
Epoch 1878 of 2000 took 0.035s
  training loss:		0.002868
  validation loss:		0.649888
  validation accuracy:		91.85 %
Epoch 1879 of 2000 took 0.035s
  training loss:		0.002978
  validation loss:		0.647435
  validation accuracy:		91.74 %
Epoch 1880 of 2000 took 0.035s
  training loss:		0.002988
  validation loss:		0.650744
  validation accuracy:		91.74 %
Epoch 1881 of 2000 took 0.035s
  training loss:		0.002929
  validation loss:		0.647645
  validation accuracy:		91.96 %
Epoch 1882 of 2000 took 0.035s
  training loss:		0.002974
  validation loss:		0.650399
  validation accuracy:		91.74 %
Epoch 1883 of 2000 took 0.035s
  training loss:		0.002871
  validation loss:		0.654264
  validation accuracy:		91.74 %
Epoch 1884 of 2000 took 0.036s
  training loss:		0.002952
  validation loss:		0.654238
  validation accuracy:		91.52 %
Epoch 1885 of 2000 took 0.035s
  training loss:		0.002947
  validation loss:		0.648190
  validation accuracy:		92.07 %
Epoch 1886 of 2000 took 0.035s
  training loss:		0.002978
  validation loss:		0.652700
  validation accuracy:		91.52 %
Epoch 1887 of 2000 took 0.035s
  training loss:		0.002876
  validation loss:		0.648759
  validation accuracy:		91.96 %
Epoch 1888 of 2000 took 0.035s
  training loss:		0.002986
  validation loss:		0.657462
  validation accuracy:		91.63 %
Epoch 1889 of 2000 took 0.035s
  training loss:		0.002902
  validation loss:		0.653141
  validation accuracy:		91.74 %
Epoch 1890 of 2000 took 0.035s
  training loss:		0.002972
  validation loss:		0.657518
  validation accuracy:		91.52 %
Epoch 1891 of 2000 took 0.035s
  training loss:		0.002990
  validation loss:		0.648329
  validation accuracy:		91.85 %
Epoch 1892 of 2000 took 0.035s
  training loss:		0.002921
  validation loss:		0.654612
  validation accuracy:		91.63 %
Epoch 1893 of 2000 took 0.035s
  training loss:		0.002884
  validation loss:		0.651148
  validation accuracy:		91.85 %
Epoch 1894 of 2000 took 0.035s
  training loss:		0.002921
  validation loss:		0.653554
  validation accuracy:		91.63 %
Epoch 1895 of 2000 took 0.035s
  training loss:		0.002986
  validation loss:		0.656151
  validation accuracy:		91.74 %
Epoch 1896 of 2000 took 0.035s
  training loss:		0.002851
  validation loss:		0.651973
  validation accuracy:		91.85 %
Epoch 1897 of 2000 took 0.035s
  training loss:		0.002986
  validation loss:		0.660430
  validation accuracy:		91.63 %
Epoch 1898 of 2000 took 0.035s
  training loss:		0.002926
  validation loss:		0.651851
  validation accuracy:		91.74 %
Epoch 1899 of 2000 took 0.035s
  training loss:		0.002909
  validation loss:		0.656388
  validation accuracy:		91.63 %
Epoch 1900 of 2000 took 0.035s
  training loss:		0.002765
  validation loss:		0.654050
  validation accuracy:		91.74 %
Epoch 1901 of 2000 took 0.035s
  training loss:		0.002925
  validation loss:		0.651408
  validation accuracy:		91.96 %
Epoch 1902 of 2000 took 0.035s
  training loss:		0.002953
  validation loss:		0.652692
  validation accuracy:		91.85 %
Epoch 1903 of 2000 took 0.035s
  training loss:		0.002976
  validation loss:		0.653762
  validation accuracy:		91.85 %
Epoch 1904 of 2000 took 0.035s
  training loss:		0.002919
  validation loss:		0.654980
  validation accuracy:		91.74 %
Epoch 1905 of 2000 took 0.035s
  training loss:		0.002902
  validation loss:		0.655874
  validation accuracy:		91.63 %
Epoch 1906 of 2000 took 0.035s
  training loss:		0.002825
  validation loss:		0.656788
  validation accuracy:		91.85 %
Epoch 1907 of 2000 took 0.035s
  training loss:		0.002933
  validation loss:		0.654407
  validation accuracy:		91.85 %
Epoch 1908 of 2000 took 0.035s
  training loss:		0.002907
  validation loss:		0.659670
  validation accuracy:		91.74 %
Epoch 1909 of 2000 took 0.035s
  training loss:		0.002859
  validation loss:		0.658014
  validation accuracy:		91.63 %
Epoch 1910 of 2000 took 0.035s
  training loss:		0.002806
  validation loss:		0.654556
  validation accuracy:		91.74 %
Epoch 1911 of 2000 took 0.035s
  training loss:		0.002864
  validation loss:		0.660269
  validation accuracy:		91.63 %
Epoch 1912 of 2000 took 0.035s
  training loss:		0.002793
  validation loss:		0.654256
  validation accuracy:		91.85 %
Epoch 1913 of 2000 took 0.035s
  training loss:		0.002683
  validation loss:		0.657978
  validation accuracy:		91.63 %
Epoch 1914 of 2000 took 0.035s
  training loss:		0.002764
  validation loss:		0.658833
  validation accuracy:		91.74 %
Epoch 1915 of 2000 took 0.035s
  training loss:		0.002795
  validation loss:		0.659728
  validation accuracy:		91.74 %
Epoch 1916 of 2000 took 0.035s
  training loss:		0.002844
  validation loss:		0.657896
  validation accuracy:		91.74 %
Epoch 1917 of 2000 took 0.035s
  training loss:		0.002888
  validation loss:		0.655852
  validation accuracy:		91.74 %
Epoch 1918 of 2000 took 0.035s
  training loss:		0.002900
  validation loss:		0.656047
  validation accuracy:		91.74 %
Epoch 1919 of 2000 took 0.035s
  training loss:		0.002820
  validation loss:		0.655784
  validation accuracy:		91.85 %
Epoch 1920 of 2000 took 0.035s
  training loss:		0.002811
  validation loss:		0.656567
  validation accuracy:		91.85 %
Epoch 1921 of 2000 took 0.035s
  training loss:		0.002771
  validation loss:		0.659852
  validation accuracy:		91.52 %
Epoch 1922 of 2000 took 0.035s
  training loss:		0.002734
  validation loss:		0.658345
  validation accuracy:		91.63 %
Epoch 1923 of 2000 took 0.035s
  training loss:		0.002756
  validation loss:		0.654944
  validation accuracy:		91.96 %
Epoch 1924 of 2000 took 0.035s
  training loss:		0.002750
  validation loss:		0.665816
  validation accuracy:		91.63 %
Epoch 1925 of 2000 took 0.035s
  training loss:		0.002831
  validation loss:		0.655823
  validation accuracy:		91.96 %
Epoch 1926 of 2000 took 0.035s
  training loss:		0.002832
  validation loss:		0.662335
  validation accuracy:		91.85 %
Epoch 1927 of 2000 took 0.035s
  training loss:		0.002797
  validation loss:		0.652147
  validation accuracy:		92.07 %
Epoch 1928 of 2000 took 0.035s
  training loss:		0.002731
  validation loss:		0.657631
  validation accuracy:		91.63 %
Epoch 1929 of 2000 took 0.035s
  training loss:		0.002716
  validation loss:		0.657764
  validation accuracy:		91.74 %
Epoch 1930 of 2000 took 0.035s
  training loss:		0.002788
  validation loss:		0.660530
  validation accuracy:		91.74 %
Epoch 1931 of 2000 took 0.035s
  training loss:		0.002730
  validation loss:		0.655767
  validation accuracy:		91.85 %
Epoch 1932 of 2000 took 0.035s
  training loss:		0.002745
  validation loss:		0.666711
  validation accuracy:		91.52 %
Epoch 1933 of 2000 took 0.035s
  training loss:		0.002787
  validation loss:		0.652394
  validation accuracy:		92.07 %
Epoch 1934 of 2000 took 0.035s
  training loss:		0.002820
  validation loss:		0.659041
  validation accuracy:		91.85 %
Epoch 1935 of 2000 took 0.035s
  training loss:		0.002722
  validation loss:		0.655304
  validation accuracy:		91.96 %
Epoch 1936 of 2000 took 0.035s
  training loss:		0.002855
  validation loss:		0.658355
  validation accuracy:		91.74 %
Epoch 1937 of 2000 took 0.035s
  training loss:		0.002791
  validation loss:		0.653836
  validation accuracy:		91.74 %
Epoch 1938 of 2000 took 0.035s
  training loss:		0.002818
  validation loss:		0.661273
  validation accuracy:		91.74 %
Epoch 1939 of 2000 took 0.035s
  training loss:		0.002782
  validation loss:		0.656786
  validation accuracy:		91.96 %
Epoch 1940 of 2000 took 0.035s
  training loss:		0.002694
  validation loss:		0.668001
  validation accuracy:		91.63 %
Epoch 1941 of 2000 took 0.035s
  training loss:		0.002768
  validation loss:		0.660147
  validation accuracy:		91.85 %
Epoch 1942 of 2000 took 0.035s
  training loss:		0.002784
  validation loss:		0.649938
  validation accuracy:		92.07 %
Epoch 1943 of 2000 took 0.035s
  training loss:		0.002681
  validation loss:		0.668829
  validation accuracy:		91.63 %
Epoch 1944 of 2000 took 0.035s
  training loss:		0.002791
  validation loss:		0.654627
  validation accuracy:		91.96 %
Epoch 1945 of 2000 took 0.035s
  training loss:		0.002792
  validation loss:		0.660725
  validation accuracy:		91.74 %
Epoch 1946 of 2000 took 0.035s
  training loss:		0.002695
  validation loss:		0.658469
  validation accuracy:		91.63 %
Epoch 1947 of 2000 took 0.035s
  training loss:		0.002747
  validation loss:		0.655714
  validation accuracy:		92.07 %
Epoch 1948 of 2000 took 0.035s
  training loss:		0.002754
  validation loss:		0.659059
  validation accuracy:		91.96 %
Epoch 1949 of 2000 took 0.035s
  training loss:		0.002750
  validation loss:		0.659207
  validation accuracy:		91.96 %
Epoch 1950 of 2000 took 0.035s
  training loss:		0.002708
  validation loss:		0.658944
  validation accuracy:		91.85 %
Epoch 1951 of 2000 took 0.035s
  training loss:		0.002660
  validation loss:		0.658605
  validation accuracy:		91.96 %
Epoch 1952 of 2000 took 0.035s
  training loss:		0.002732
  validation loss:		0.662471
  validation accuracy:		91.85 %
Epoch 1953 of 2000 took 0.035s
  training loss:		0.002758
  validation loss:		0.663759
  validation accuracy:		91.85 %
Epoch 1954 of 2000 took 0.035s
  training loss:		0.002750
  validation loss:		0.656082
  validation accuracy:		92.07 %
Epoch 1955 of 2000 took 0.035s
  training loss:		0.002709
  validation loss:		0.663244
  validation accuracy:		91.52 %
Epoch 1956 of 2000 took 0.035s
  training loss:		0.002724
  validation loss:		0.662768
  validation accuracy:		91.74 %
Epoch 1957 of 2000 took 0.035s
  training loss:		0.002689
  validation loss:		0.659747
  validation accuracy:		91.96 %
Epoch 1958 of 2000 took 0.035s
  training loss:		0.002770
  validation loss:		0.661733
  validation accuracy:		91.85 %
Epoch 1959 of 2000 took 0.035s
  training loss:		0.002682
  validation loss:		0.662622
  validation accuracy:		91.74 %
Epoch 1960 of 2000 took 0.035s
  training loss:		0.002719
  validation loss:		0.658810
  validation accuracy:		92.07 %
Epoch 1961 of 2000 took 0.035s
  training loss:		0.002625
  validation loss:		0.657885
  validation accuracy:		92.07 %
Epoch 1962 of 2000 took 0.035s
  training loss:		0.002744
  validation loss:		0.665159
  validation accuracy:		91.63 %
Epoch 1963 of 2000 took 0.035s
  training loss:		0.002686
  validation loss:		0.661767
  validation accuracy:		91.85 %
Epoch 1964 of 2000 took 0.035s
  training loss:		0.002735
  validation loss:		0.665637
  validation accuracy:		91.63 %
Epoch 1965 of 2000 took 0.035s
  training loss:		0.002696
  validation loss:		0.669794
  validation accuracy:		91.74 %
Epoch 1966 of 2000 took 0.035s
  training loss:		0.002718
  validation loss:		0.664442
  validation accuracy:		91.74 %
Epoch 1967 of 2000 took 0.035s
  training loss:		0.002629
  validation loss:		0.662674
  validation accuracy:		91.85 %
Epoch 1968 of 2000 took 0.035s
  training loss:		0.002635
  validation loss:		0.659575
  validation accuracy:		92.07 %
Epoch 1969 of 2000 took 0.035s
  training loss:		0.002686
  validation loss:		0.664697
  validation accuracy:		91.63 %
Epoch 1970 of 2000 took 0.035s
  training loss:		0.002745
  validation loss:		0.660914
  validation accuracy:		92.07 %
Epoch 1971 of 2000 took 0.035s
  training loss:		0.002621
  validation loss:		0.667768
  validation accuracy:		91.85 %
Epoch 1972 of 2000 took 0.035s
  training loss:		0.002677
  validation loss:		0.661433
  validation accuracy:		92.07 %
Epoch 1973 of 2000 took 0.035s
  training loss:		0.002626
  validation loss:		0.660488
  validation accuracy:		91.85 %
Epoch 1974 of 2000 took 0.035s
  training loss:		0.002719
  validation loss:		0.669147
  validation accuracy:		91.74 %
Epoch 1975 of 2000 took 0.035s
  training loss:		0.002664
  validation loss:		0.660581
  validation accuracy:		91.96 %
Epoch 1976 of 2000 took 0.035s
  training loss:		0.002649
  validation loss:		0.662128
  validation accuracy:		91.85 %
Epoch 1977 of 2000 took 0.035s
  training loss:		0.002705
  validation loss:		0.662868
  validation accuracy:		91.96 %
Epoch 1978 of 2000 took 0.035s
  training loss:		0.002654
  validation loss:		0.664449
  validation accuracy:		91.85 %
Epoch 1979 of 2000 took 0.035s
  training loss:		0.002597
  validation loss:		0.666022
  validation accuracy:		91.63 %
Epoch 1980 of 2000 took 0.035s
  training loss:		0.002603
  validation loss:		0.659429
  validation accuracy:		92.07 %
Epoch 1981 of 2000 took 0.035s
  training loss:		0.002601
  validation loss:		0.663531
  validation accuracy:		91.85 %
Epoch 1982 of 2000 took 0.035s
  training loss:		0.002554
  validation loss:		0.670969
  validation accuracy:		91.63 %
Epoch 1983 of 2000 took 0.035s
  training loss:		0.002638
  validation loss:		0.661568
  validation accuracy:		92.07 %
Epoch 1984 of 2000 took 0.035s
  training loss:		0.002612
  validation loss:		0.669016
  validation accuracy:		91.63 %
Epoch 1985 of 2000 took 0.035s
  training loss:		0.002620
  validation loss:		0.663586
  validation accuracy:		91.96 %
Epoch 1986 of 2000 took 0.035s
  training loss:		0.002588
  validation loss:		0.667497
  validation accuracy:		91.85 %
Epoch 1987 of 2000 took 0.035s
  training loss:		0.002659
  validation loss:		0.665245
  validation accuracy:		91.85 %
Epoch 1988 of 2000 took 0.035s
  training loss:		0.002624
  validation loss:		0.668073
  validation accuracy:		91.74 %
Epoch 1989 of 2000 took 0.035s
  training loss:		0.002625
  validation loss:		0.662024
  validation accuracy:		91.96 %
Epoch 1990 of 2000 took 0.035s
  training loss:		0.002551
  validation loss:		0.665909
  validation accuracy:		91.85 %
Epoch 1991 of 2000 took 0.035s
  training loss:		0.002644
  validation loss:		0.664743
  validation accuracy:		91.85 %
Epoch 1992 of 2000 took 0.035s
  training loss:		0.002598
  validation loss:		0.668841
  validation accuracy:		91.85 %
Epoch 1993 of 2000 took 0.035s
  training loss:		0.002741
  validation loss:		0.665020
  validation accuracy:		91.96 %
Epoch 1994 of 2000 took 0.035s
  training loss:		0.002637
  validation loss:		0.663590
  validation accuracy:		91.85 %
Epoch 1995 of 2000 took 0.035s
  training loss:		0.002654
  validation loss:		0.671348
  validation accuracy:		91.85 %
Epoch 1996 of 2000 took 0.035s
  training loss:		0.002622
  validation loss:		0.667346
  validation accuracy:		91.74 %
Epoch 1997 of 2000 took 0.035s
  training loss:		0.002562
  validation loss:		0.665146
  validation accuracy:		91.96 %
Epoch 1998 of 2000 took 0.035s
  training loss:		0.002569
  validation loss:		0.668443
  validation accuracy:		91.74 %
Epoch 1999 of 2000 took 0.035s
  training loss:		0.002465
  validation loss:		0.666369
  validation accuracy:		91.85 %
Epoch 2000 of 2000 took 0.035s
  training loss:		0.002649
  validation loss:		0.668259
  validation accuracy:		91.85 %
Final results:
  test loss:			1.594611
  test accuracy:		83.54 %
