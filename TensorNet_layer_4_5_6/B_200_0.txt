Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
decomposing tensor W of shape (3, 50, 50)...
decomposing tensor B of shape (3, 50)...
Starting training...
Epoch 1 of 2000 took 0.099s
  training loss:		3.023345
  validation loss:		2.937336
  validation accuracy:		10.00 %
Epoch 2 of 2000 took 0.095s
  training loss:		2.915374
  validation loss:		2.800195
  validation accuracy:		15.54 %
Epoch 3 of 2000 took 0.096s
  training loss:		2.805751
  validation loss:		2.659358
  validation accuracy:		13.15 %
Epoch 4 of 2000 took 0.097s
  training loss:		2.690386
  validation loss:		2.506011
  validation accuracy:		12.93 %
Epoch 5 of 2000 took 0.096s
  training loss:		2.572934
  validation loss:		2.357691
  validation accuracy:		15.11 %
Epoch 6 of 2000 took 0.096s
  training loss:		2.465820
  validation loss:		2.259980
  validation accuracy:		21.74 %
Epoch 7 of 2000 took 0.097s
  training loss:		2.384233
  validation loss:		2.223825
  validation accuracy:		22.28 %
Epoch 8 of 2000 took 0.096s
  training loss:		2.325958
  validation loss:		2.219621
  validation accuracy:		23.04 %
Epoch 9 of 2000 took 0.097s
  training loss:		2.290300
  validation loss:		2.215758
  validation accuracy:		25.98 %
Epoch 10 of 2000 took 0.097s
  training loss:		2.267839
  validation loss:		2.199254
  validation accuracy:		28.59 %
Epoch 11 of 2000 took 0.097s
  training loss:		2.253052
  validation loss:		2.180990
  validation accuracy:		29.46 %
Epoch 12 of 2000 took 0.096s
  training loss:		2.241549
  validation loss:		2.167346
  validation accuracy:		29.46 %
Epoch 13 of 2000 took 0.096s
  training loss:		2.231635
  validation loss:		2.160375
  validation accuracy:		31.63 %
Epoch 14 of 2000 took 0.097s
  training loss:		2.222376
  validation loss:		2.149936
  validation accuracy:		34.13 %
Epoch 15 of 2000 took 0.096s
  training loss:		2.210317
  validation loss:		2.133639
  validation accuracy:		33.59 %
Epoch 16 of 2000 took 0.096s
  training loss:		2.202399
  validation loss:		2.128306
  validation accuracy:		32.61 %
Epoch 17 of 2000 took 0.096s
  training loss:		2.190850
  validation loss:		2.108206
  validation accuracy:		37.61 %
Epoch 18 of 2000 took 0.096s
  training loss:		2.176954
  validation loss:		2.095865
  validation accuracy:		39.78 %
Epoch 19 of 2000 took 0.096s
  training loss:		2.163875
  validation loss:		2.075261
  validation accuracy:		38.70 %
Epoch 20 of 2000 took 0.096s
  training loss:		2.148110
  validation loss:		2.058437
  validation accuracy:		40.65 %
Epoch 21 of 2000 took 0.096s
  training loss:		2.130559
  validation loss:		2.033812
  validation accuracy:		40.43 %
Epoch 22 of 2000 took 0.096s
  training loss:		2.113536
  validation loss:		2.019724
  validation accuracy:		44.67 %
Epoch 23 of 2000 took 0.096s
  training loss:		2.091710
  validation loss:		1.997146
  validation accuracy:		40.54 %
Epoch 24 of 2000 took 0.097s
  training loss:		2.065598
  validation loss:		1.957928
  validation accuracy:		44.24 %
Epoch 25 of 2000 took 0.096s
  training loss:		2.040246
  validation loss:		1.931128
  validation accuracy:		46.52 %
Epoch 26 of 2000 took 0.097s
  training loss:		2.014311
  validation loss:		1.898833
  validation accuracy:		48.59 %
Epoch 27 of 2000 took 0.096s
  training loss:		1.983138
  validation loss:		1.868375
  validation accuracy:		46.96 %
Epoch 28 of 2000 took 0.098s
  training loss:		1.952506
  validation loss:		1.819347
  validation accuracy:		51.74 %
Epoch 29 of 2000 took 0.097s
  training loss:		1.918670
  validation loss:		1.795898
  validation accuracy:		51.52 %
Epoch 30 of 2000 took 0.139s
  training loss:		1.886049
  validation loss:		1.757494
  validation accuracy:		54.35 %
Epoch 31 of 2000 took 0.160s
  training loss:		1.845203
  validation loss:		1.703718
  validation accuracy:		56.30 %
Epoch 32 of 2000 took 0.165s
  training loss:		1.809983
  validation loss:		1.677091
  validation accuracy:		55.76 %
Epoch 33 of 2000 took 0.133s
  training loss:		1.761767
  validation loss:		1.632031
  validation accuracy:		57.07 %
Epoch 34 of 2000 took 0.164s
  training loss:		1.726421
  validation loss:		1.588150
  validation accuracy:		59.78 %
Epoch 35 of 2000 took 0.144s
  training loss:		1.686014
  validation loss:		1.550306
  validation accuracy:		61.20 %
Epoch 36 of 2000 took 0.155s
  training loss:		1.652680
  validation loss:		1.518863
  validation accuracy:		62.28 %
Epoch 37 of 2000 took 0.165s
  training loss:		1.611114
  validation loss:		1.483480
  validation accuracy:		61.96 %
Epoch 38 of 2000 took 0.133s
  training loss:		1.574193
  validation loss:		1.441964
  validation accuracy:		65.22 %
Epoch 39 of 2000 took 0.164s
  training loss:		1.544492
  validation loss:		1.399217
  validation accuracy:		65.11 %
Epoch 40 of 2000 took 0.152s
  training loss:		1.499787
  validation loss:		1.370212
  validation accuracy:		66.09 %
Epoch 41 of 2000 took 0.147s
  training loss:		1.464452
  validation loss:		1.339411
  validation accuracy:		65.76 %
Epoch 42 of 2000 took 0.214s
  training loss:		1.429958
  validation loss:		1.300624
  validation accuracy:		66.74 %
Epoch 43 of 2000 took 0.159s
  training loss:		1.392709
  validation loss:		1.267613
  validation accuracy:		67.07 %
Epoch 44 of 2000 took 0.165s
  training loss:		1.360782
  validation loss:		1.246688
  validation accuracy:		67.50 %
Epoch 45 of 2000 took 0.159s
  training loss:		1.326973
  validation loss:		1.207082
  validation accuracy:		67.93 %
Epoch 46 of 2000 took 0.165s
  training loss:		1.292061
  validation loss:		1.183360
  validation accuracy:		67.83 %
Epoch 47 of 2000 took 0.166s
  training loss:		1.259238
  validation loss:		1.182939
  validation accuracy:		68.04 %
Epoch 48 of 2000 took 0.158s
  training loss:		1.254270
  validation loss:		1.107808
  validation accuracy:		71.09 %
Epoch 49 of 2000 took 0.165s
  training loss:		1.199685
  validation loss:		1.079136
  validation accuracy:		71.20 %
Epoch 50 of 2000 took 0.158s
  training loss:		1.169275
  validation loss:		1.052181
  validation accuracy:		71.41 %
Epoch 51 of 2000 took 0.164s
  training loss:		1.139835
  validation loss:		1.021640
  validation accuracy:		72.39 %
Epoch 52 of 2000 took 0.160s
  training loss:		1.127814
  validation loss:		0.992370
  validation accuracy:		73.15 %
Epoch 53 of 2000 took 0.165s
  training loss:		1.094193
  validation loss:		0.975598
  validation accuracy:		71.96 %
Epoch 54 of 2000 took 0.166s
  training loss:		1.048707
  validation loss:		0.952384
  validation accuracy:		73.48 %
Epoch 55 of 2000 took 0.158s
  training loss:		1.029528
  validation loss:		0.911996
  validation accuracy:		74.35 %
Epoch 56 of 2000 took 0.165s
  training loss:		1.076437
  validation loss:		0.893630
  validation accuracy:		74.67 %
Epoch 57 of 2000 took 0.159s
  training loss:		0.969605
  validation loss:		0.859973
  validation accuracy:		75.65 %
Epoch 58 of 2000 took 0.165s
  training loss:		0.941154
  validation loss:		0.860398
  validation accuracy:		74.46 %
Epoch 59 of 2000 took 0.149s
  training loss:		0.923479
  validation loss:		0.805660
  validation accuracy:		77.50 %
Epoch 60 of 2000 took 0.149s
  training loss:		0.913481
  validation loss:		0.786523
  validation accuracy:		77.28 %
Epoch 61 of 2000 took 0.165s
  training loss:		0.869531
  validation loss:		0.763793
  validation accuracy:		79.24 %
Epoch 62 of 2000 took 0.158s
  training loss:		0.859812
  validation loss:		0.801237
  validation accuracy:		76.41 %
Epoch 63 of 2000 took 0.165s
  training loss:		0.848952
  validation loss:		0.786851
  validation accuracy:		76.74 %
Epoch 64 of 2000 took 0.159s
  training loss:		0.831073
  validation loss:		0.743694
  validation accuracy:		77.93 %
Epoch 65 of 2000 took 0.165s
  training loss:		0.814067
  validation loss:		0.697307
  validation accuracy:		79.24 %
Epoch 66 of 2000 took 0.166s
  training loss:		0.776016
  validation loss:		0.675910
  validation accuracy:		80.11 %
Epoch 67 of 2000 took 0.158s
  training loss:		0.764305
  validation loss:		0.646083
  validation accuracy:		80.98 %
Epoch 68 of 2000 took 0.165s
  training loss:		0.743270
  validation loss:		0.646942
  validation accuracy:		80.98 %
Epoch 69 of 2000 took 0.158s
  training loss:		0.728505
  validation loss:		0.652080
  validation accuracy:		81.30 %
Epoch 70 of 2000 took 0.165s
  training loss:		0.714326
  validation loss:		0.642613
  validation accuracy:		81.09 %
Epoch 71 of 2000 took 0.159s
  training loss:		0.691408
  validation loss:		0.618442
  validation accuracy:		81.41 %
Epoch 72 of 2000 took 0.165s
  training loss:		0.720024
  validation loss:		0.599347
  validation accuracy:		82.39 %
Epoch 73 of 2000 took 0.166s
  training loss:		0.664248
  validation loss:		0.580273
  validation accuracy:		83.15 %
Epoch 74 of 2000 took 0.158s
  training loss:		0.646788
  validation loss:		0.552260
  validation accuracy:		83.80 %
Epoch 75 of 2000 took 0.165s
  training loss:		0.642182
  validation loss:		0.559449
  validation accuracy:		83.91 %
Epoch 76 of 2000 took 0.158s
  training loss:		0.628385
  validation loss:		0.558337
  validation accuracy:		83.59 %
Epoch 77 of 2000 took 0.165s
  training loss:		0.618616
  validation loss:		0.543778
  validation accuracy:		84.57 %
Epoch 78 of 2000 took 0.163s
  training loss:		0.625305
  validation loss:		0.539387
  validation accuracy:		84.46 %
Epoch 79 of 2000 took 0.161s
  training loss:		0.589874
  validation loss:		0.510052
  validation accuracy:		84.57 %
Epoch 80 of 2000 took 0.217s
  training loss:		0.649886
  validation loss:		0.513080
  validation accuracy:		84.78 %
Epoch 81 of 2000 took 0.160s
  training loss:		0.586481
  validation loss:		0.531162
  validation accuracy:		84.24 %
Epoch 82 of 2000 took 0.165s
  training loss:		0.563872
  validation loss:		0.497598
  validation accuracy:		85.98 %
Epoch 83 of 2000 took 0.165s
  training loss:		0.562692
  validation loss:		0.486344
  validation accuracy:		86.09 %
Epoch 84 of 2000 took 0.159s
  training loss:		0.547069
  validation loss:		0.485855
  validation accuracy:		85.98 %
Epoch 85 of 2000 took 0.168s
  training loss:		0.538764
  validation loss:		0.480311
  validation accuracy:		85.98 %
Epoch 86 of 2000 took 0.169s
  training loss:		0.528267
  validation loss:		0.468383
  validation accuracy:		86.20 %
Epoch 87 of 2000 took 0.137s
  training loss:		0.520418
  validation loss:		0.483185
  validation accuracy:		85.43 %
Epoch 88 of 2000 took 0.167s
  training loss:		0.511085
  validation loss:		0.478916
  validation accuracy:		85.33 %
Epoch 89 of 2000 took 0.248s
  training loss:		0.522554
  validation loss:		0.476486
  validation accuracy:		85.76 %
Epoch 90 of 2000 took 0.161s
  training loss:		0.511193
  validation loss:		0.463225
  validation accuracy:		86.63 %
Epoch 91 of 2000 took 0.140s
  training loss:		0.490274
  validation loss:		0.458551
  validation accuracy:		86.96 %
Epoch 92 of 2000 took 0.165s
  training loss:		0.487575
  validation loss:		0.461184
  validation accuracy:		86.63 %
Epoch 93 of 2000 took 0.159s
  training loss:		0.496200
  validation loss:		0.452908
  validation accuracy:		86.74 %
Epoch 94 of 2000 took 0.165s
  training loss:		0.475543
  validation loss:		0.433807
  validation accuracy:		86.74 %
Epoch 95 of 2000 took 0.166s
  training loss:		0.461708
  validation loss:		0.449300
  validation accuracy:		86.85 %
Epoch 96 of 2000 took 0.158s
  training loss:		0.457920
  validation loss:		0.440922
  validation accuracy:		86.85 %
Epoch 97 of 2000 took 0.166s
  training loss:		0.460371
  validation loss:		0.428613
  validation accuracy:		87.61 %
Epoch 98 of 2000 took 0.159s
  training loss:		0.449319
  validation loss:		0.447091
  validation accuracy:		86.52 %
Epoch 99 of 2000 took 0.165s
  training loss:		0.438341
  validation loss:		0.421781
  validation accuracy:		87.93 %
Epoch 100 of 2000 took 0.160s
  training loss:		0.443588
  validation loss:		0.416234
  validation accuracy:		86.96 %
Epoch 101 of 2000 took 0.165s
  training loss:		0.433942
  validation loss:		0.429668
  validation accuracy:		87.72 %
Epoch 102 of 2000 took 0.166s
  training loss:		0.426309
  validation loss:		0.422018
  validation accuracy:		86.85 %
Epoch 103 of 2000 took 0.159s
  training loss:		0.429060
  validation loss:		0.427831
  validation accuracy:		87.28 %
Epoch 104 of 2000 took 0.213s
  training loss:		0.418846
  validation loss:		0.416807
  validation accuracy:		86.85 %
Epoch 105 of 2000 took 0.161s
  training loss:		0.419414
  validation loss:		0.405751
  validation accuracy:		87.72 %
Epoch 106 of 2000 took 0.167s
  training loss:		0.413412
  validation loss:		0.416907
  validation accuracy:		87.83 %
Epoch 107 of 2000 took 0.186s
  training loss:		0.405227
  validation loss:		0.427624
  validation accuracy:		87.72 %
Epoch 108 of 2000 took 0.144s
  training loss:		0.420638
  validation loss:		0.431208
  validation accuracy:		87.17 %
Epoch 109 of 2000 took 0.165s
  training loss:		0.398308
  validation loss:		0.405310
  validation accuracy:		87.83 %
Epoch 110 of 2000 took 0.134s
  training loss:		0.400724
  validation loss:		0.417410
  validation accuracy:		87.83 %
Epoch 111 of 2000 took 0.160s
  training loss:		0.400280
  validation loss:		0.402477
  validation accuracy:		88.26 %
Epoch 112 of 2000 took 0.164s
  training loss:		0.397203
  validation loss:		0.395856
  validation accuracy:		88.26 %
Epoch 113 of 2000 took 0.158s
  training loss:		0.389582
  validation loss:		0.411649
  validation accuracy:		87.83 %
Epoch 114 of 2000 took 0.126s
  training loss:		0.377215
  validation loss:		0.412213
  validation accuracy:		87.93 %
Epoch 115 of 2000 took 0.164s
  training loss:		0.378078
  validation loss:		0.402451
  validation accuracy:		88.15 %
Epoch 116 of 2000 took 0.144s
  training loss:		0.390346
  validation loss:		0.432853
  validation accuracy:		87.39 %
Epoch 117 of 2000 took 0.155s
  training loss:		0.384758
  validation loss:		0.390260
  validation accuracy:		88.70 %
Epoch 118 of 2000 took 0.166s
  training loss:		0.378100
  validation loss:		0.400102
  validation accuracy:		88.26 %
Epoch 119 of 2000 took 0.134s
  training loss:		0.372566
  validation loss:		0.404050
  validation accuracy:		88.04 %
Epoch 120 of 2000 took 0.211s
  training loss:		0.370706
  validation loss:		0.382309
  validation accuracy:		88.37 %
Epoch 121 of 2000 took 0.162s
  training loss:		0.367241
  validation loss:		0.418745
  validation accuracy:		87.83 %
Epoch 122 of 2000 took 0.166s
  training loss:		0.368235
  validation loss:		0.394388
  validation accuracy:		88.26 %
Epoch 123 of 2000 took 0.160s
  training loss:		0.366385
  validation loss:		0.405842
  validation accuracy:		88.04 %
Epoch 124 of 2000 took 0.142s
  training loss:		0.356679
  validation loss:		0.385279
  validation accuracy:		89.13 %
Epoch 125 of 2000 took 0.156s
  training loss:		0.355233
  validation loss:		0.405379
  validation accuracy:		88.15 %
Epoch 126 of 2000 took 0.268s
  training loss:		0.348527
  validation loss:		0.409634
  validation accuracy:		87.61 %
Epoch 127 of 2000 took 0.175s
  training loss:		0.365987
  validation loss:		0.382056
  validation accuracy:		88.04 %
Epoch 128 of 2000 took 0.161s
  training loss:		0.344784
  validation loss:		0.389662
  validation accuracy:		89.02 %
Epoch 129 of 2000 took 0.160s
  training loss:		0.348355
  validation loss:		0.394896
  validation accuracy:		88.70 %
Epoch 130 of 2000 took 0.273s
  training loss:		0.336817
  validation loss:		0.388069
  validation accuracy:		88.48 %
Epoch 131 of 2000 took 0.232s
  training loss:		0.339779
  validation loss:		0.384697
  validation accuracy:		89.02 %
Epoch 132 of 2000 took 0.167s
  training loss:		0.341107
  validation loss:		0.394047
  validation accuracy:		88.48 %
Epoch 133 of 2000 took 0.165s
  training loss:		0.331132
  validation loss:		0.368802
  validation accuracy:		89.57 %
Epoch 134 of 2000 took 0.167s
  training loss:		0.336501
  validation loss:		0.368807
  validation accuracy:		89.46 %
Epoch 135 of 2000 took 0.146s
  training loss:		0.340585
  validation loss:		0.372697
  validation accuracy:		89.57 %
Epoch 136 of 2000 took 0.160s
  training loss:		0.324127
  validation loss:		0.400310
  validation accuracy:		88.37 %
Epoch 137 of 2000 took 0.166s
  training loss:		0.334423
  validation loss:		0.383241
  validation accuracy:		89.13 %
Epoch 138 of 2000 took 0.165s
  training loss:		0.327070
  validation loss:		0.360792
  validation accuracy:		89.13 %
Epoch 139 of 2000 took 0.167s
  training loss:		0.338517
  validation loss:		0.364558
  validation accuracy:		88.80 %
Epoch 140 of 2000 took 0.141s
  training loss:		0.332921
  validation loss:		0.374274
  validation accuracy:		88.80 %
Epoch 141 of 2000 took 0.166s
  training loss:		0.331760
  validation loss:		0.384182
  validation accuracy:		89.13 %
Epoch 142 of 2000 took 0.165s
  training loss:		0.317993
  validation loss:		0.398480
  validation accuracy:		88.48 %
Epoch 143 of 2000 took 0.169s
  training loss:		0.319435
  validation loss:		0.384781
  validation accuracy:		89.24 %
Epoch 144 of 2000 took 0.140s
  training loss:		0.319746
  validation loss:		0.369605
  validation accuracy:		89.46 %
Epoch 145 of 2000 took 0.160s
  training loss:		0.318146
  validation loss:		0.386203
  validation accuracy:		88.59 %
Epoch 146 of 2000 took 0.203s
  training loss:		0.325855
  validation loss:		0.365643
  validation accuracy:		90.11 %
Epoch 147 of 2000 took 0.211s
  training loss:		0.319828
  validation loss:		0.372728
  validation accuracy:		89.35 %
Epoch 148 of 2000 took 0.166s
  training loss:		0.317444
  validation loss:		0.372292
  validation accuracy:		89.13 %
Epoch 149 of 2000 took 0.181s
  training loss:		0.320460
  validation loss:		0.369034
  validation accuracy:		90.00 %
Epoch 150 of 2000 took 0.179s
  training loss:		0.315745
  validation loss:		0.372118
  validation accuracy:		89.24 %
Epoch 151 of 2000 took 0.160s
  training loss:		0.310158
  validation loss:		0.380201
  validation accuracy:		89.13 %
Epoch 152 of 2000 took 0.158s
  training loss:		0.308404
  validation loss:		0.379108
  validation accuracy:		89.13 %
Epoch 153 of 2000 took 0.203s
  training loss:		0.311087
  validation loss:		0.375006
  validation accuracy:		89.24 %
Epoch 154 of 2000 took 0.146s
  training loss:		0.308876
  validation loss:		0.395314
  validation accuracy:		88.48 %
Epoch 155 of 2000 took 0.159s
  training loss:		0.312508
  validation loss:		0.355729
  validation accuracy:		89.46 %
Epoch 156 of 2000 took 0.248s
  training loss:		0.309827
  validation loss:		0.367161
  validation accuracy:		89.78 %
Epoch 157 of 2000 took 0.271s
  training loss:		0.310917
  validation loss:		0.361493
  validation accuracy:		89.78 %
Epoch 158 of 2000 took 0.200s
  training loss:		0.301087
  validation loss:		0.395194
  validation accuracy:		88.48 %
Epoch 159 of 2000 took 0.258s
  training loss:		0.301969
  validation loss:		0.357129
  validation accuracy:		89.24 %
Epoch 160 of 2000 took 0.162s
  training loss:		0.302572
  validation loss:		0.361655
  validation accuracy:		90.22 %
Epoch 161 of 2000 took 0.177s
  training loss:		0.295670
  validation loss:		0.387953
  validation accuracy:		88.80 %
Epoch 162 of 2000 took 0.174s
  training loss:		0.291983
  validation loss:		0.363441
  validation accuracy:		89.78 %
Epoch 163 of 2000 took 0.168s
  training loss:		0.299051
  validation loss:		0.379034
  validation accuracy:		89.13 %
Epoch 164 of 2000 took 0.166s
  training loss:		0.292387
  validation loss:		0.405807
  validation accuracy:		88.48 %
Epoch 165 of 2000 took 0.167s
  training loss:		0.295123
  validation loss:		0.367744
  validation accuracy:		89.89 %
Epoch 166 of 2000 took 0.137s
  training loss:		0.291421
  validation loss:		0.408779
  validation accuracy:		88.15 %
Epoch 167 of 2000 took 0.167s
  training loss:		0.284822
  validation loss:		0.363004
  validation accuracy:		89.78 %
Epoch 168 of 2000 took 0.169s
  training loss:		0.287067
  validation loss:		0.363153
  validation accuracy:		89.89 %
Epoch 169 of 2000 took 0.165s
  training loss:		0.282878
  validation loss:		0.365852
  validation accuracy:		89.35 %
Epoch 170 of 2000 took 0.203s
  training loss:		0.284700
  validation loss:		0.360889
  validation accuracy:		89.67 %
Epoch 171 of 2000 took 0.161s
  training loss:		0.287480
  validation loss:		0.369462
  validation accuracy:		89.67 %
Epoch 172 of 2000 took 0.165s
  training loss:		0.283359
  validation loss:		0.373231
  validation accuracy:		89.46 %
Epoch 173 of 2000 took 0.166s
  training loss:		0.281374
  validation loss:		0.360453
  validation accuracy:		90.11 %
Epoch 174 of 2000 took 0.165s
  training loss:		0.282759
  validation loss:		0.362542
  validation accuracy:		89.57 %
Epoch 175 of 2000 took 0.151s
  training loss:		0.284897
  validation loss:		0.375384
  validation accuracy:		89.57 %
Epoch 176 of 2000 took 0.146s
  training loss:		0.276235
  validation loss:		0.365709
  validation accuracy:		90.00 %
Epoch 177 of 2000 took 0.165s
  training loss:		0.274759
  validation loss:		0.353345
  validation accuracy:		90.00 %
Epoch 178 of 2000 took 0.166s
  training loss:		0.276018
  validation loss:		0.388059
  validation accuracy:		88.91 %
Epoch 179 of 2000 took 0.170s
  training loss:		0.275746
  validation loss:		0.372073
  validation accuracy:		89.67 %
Epoch 180 of 2000 took 0.166s
  training loss:		0.274495
  validation loss:		0.368579
  validation accuracy:		89.78 %
Epoch 181 of 2000 took 0.139s
  training loss:		0.275915
  validation loss:		0.365856
  validation accuracy:		89.67 %
Epoch 182 of 2000 took 0.148s
  training loss:		0.274686
  validation loss:		0.364604
  validation accuracy:		89.24 %
Epoch 183 of 2000 took 0.159s
  training loss:		0.276763
  validation loss:		0.368359
  validation accuracy:		89.57 %
Epoch 184 of 2000 took 0.233s
  training loss:		0.280261
  validation loss:		0.381786
  validation accuracy:		89.35 %
Epoch 185 of 2000 took 0.197s
  training loss:		0.273303
  validation loss:		0.352199
  validation accuracy:		90.11 %
Epoch 186 of 2000 took 0.149s
  training loss:		0.270310
  validation loss:		0.361399
  validation accuracy:		89.89 %
Epoch 187 of 2000 took 0.161s
  training loss:		0.273435
  validation loss:		0.370452
  validation accuracy:		89.67 %
Epoch 188 of 2000 took 0.270s
  training loss:		0.270320
  validation loss:		0.373109
  validation accuracy:		89.67 %
Epoch 189 of 2000 took 0.162s
  training loss:		0.270561
  validation loss:		0.353349
  validation accuracy:		90.11 %
Epoch 190 of 2000 took 0.149s
  training loss:		0.268212
  validation loss:		0.386867
  validation accuracy:		89.13 %
Epoch 191 of 2000 took 0.160s
  training loss:		0.265654
  validation loss:		0.367366
  validation accuracy:		89.78 %
Epoch 192 of 2000 took 0.344s
  training loss:		0.263018
  validation loss:		0.378410
  validation accuracy:		89.57 %
Epoch 193 of 2000 took 0.279s
  training loss:		0.269082
  validation loss:		0.356893
  validation accuracy:		90.11 %
Epoch 194 of 2000 took 0.164s
  training loss:		0.263341
  validation loss:		0.363444
  validation accuracy:		90.22 %
Epoch 195 of 2000 took 0.164s
  training loss:		0.262732
  validation loss:		0.387827
  validation accuracy:		88.80 %
Epoch 196 of 2000 took 0.164s
  training loss:		0.270497
  validation loss:		0.354416
  validation accuracy:		90.00 %
Epoch 197 of 2000 took 0.165s
  training loss:		0.261844
  validation loss:		0.371190
  validation accuracy:		90.22 %
Epoch 198 of 2000 took 0.166s
  training loss:		0.257415
  validation loss:		0.367533
  validation accuracy:		89.78 %
Epoch 199 of 2000 took 0.164s
  training loss:		0.260868
  validation loss:		0.346077
  validation accuracy:		90.33 %
Epoch 200 of 2000 took 0.164s
  training loss:		0.260774
  validation loss:		0.370096
  validation accuracy:		89.35 %
Epoch 201 of 2000 took 0.164s
  training loss:		0.255022
  validation loss:		0.350115
  validation accuracy:		90.22 %
Epoch 202 of 2000 took 0.165s
  training loss:		0.256690
  validation loss:		0.352116
  validation accuracy:		90.43 %
Epoch 203 of 2000 took 0.166s
  training loss:		0.256557
  validation loss:		0.353869
  validation accuracy:		89.89 %
Epoch 204 of 2000 took 0.164s
  training loss:		0.258000
  validation loss:		0.369913
  validation accuracy:		89.67 %
Epoch 205 of 2000 took 0.187s
  training loss:		0.258243
  validation loss:		0.346505
  validation accuracy:		90.11 %
Epoch 206 of 2000 took 0.277s
  training loss:		0.265986
  validation loss:		0.352509
  validation accuracy:		90.76 %
Epoch 207 of 2000 took 0.165s
  training loss:		0.253803
  validation loss:		0.341919
  validation accuracy:		90.00 %
Epoch 208 of 2000 took 0.164s
  training loss:		0.260523
  validation loss:		0.361887
  validation accuracy:		89.78 %
Epoch 209 of 2000 took 0.164s
  training loss:		0.247891
  validation loss:		0.371740
  validation accuracy:		90.11 %
Epoch 210 of 2000 took 0.165s
  training loss:		0.251652
  validation loss:		0.351080
  validation accuracy:		90.33 %
Epoch 211 of 2000 took 0.166s
  training loss:		0.250211
  validation loss:		0.355584
  validation accuracy:		90.54 %
Epoch 212 of 2000 took 0.165s
  training loss:		0.251672
  validation loss:		0.367741
  validation accuracy:		89.57 %
Epoch 213 of 2000 took 0.165s
  training loss:		0.248207
  validation loss:		0.367255
  validation accuracy:		90.43 %
Epoch 214 of 2000 took 0.166s
  training loss:		0.250916
  validation loss:		0.357203
  validation accuracy:		89.78 %
Epoch 215 of 2000 took 0.165s
  training loss:		0.249386
  validation loss:		0.356509
  validation accuracy:		90.54 %
Epoch 216 of 2000 took 0.166s
  training loss:		0.251060
  validation loss:		0.352509
  validation accuracy:		90.00 %
Epoch 217 of 2000 took 0.166s
  training loss:		0.248001
  validation loss:		0.365166
  validation accuracy:		89.89 %
Epoch 218 of 2000 took 0.164s
  training loss:		0.254537
  validation loss:		0.382526
  validation accuracy:		89.89 %
Epoch 219 of 2000 took 0.165s
  training loss:		0.246515
  validation loss:		0.356559
  validation accuracy:		90.00 %
Epoch 220 of 2000 took 0.165s
  training loss:		0.249763
  validation loss:		0.359667
  validation accuracy:		90.33 %
Epoch 221 of 2000 took 0.166s
  training loss:		0.244109
  validation loss:		0.361478
  validation accuracy:		89.78 %
Epoch 222 of 2000 took 0.165s
  training loss:		0.246605
  validation loss:		0.359364
  validation accuracy:		90.11 %
Epoch 223 of 2000 took 0.162s
  training loss:		0.258135
  validation loss:		0.377027
  validation accuracy:		90.00 %
Epoch 224 of 2000 took 0.177s
  training loss:		0.246035
  validation loss:		0.358709
  validation accuracy:		90.76 %
Epoch 225 of 2000 took 0.165s
  training loss:		0.252191
  validation loss:		0.354943
  validation accuracy:		90.98 %
Epoch 226 of 2000 took 0.165s
  training loss:		0.250292
  validation loss:		0.349198
  validation accuracy:		90.43 %
Epoch 227 of 2000 took 0.166s
  training loss:		0.246757
  validation loss:		0.359622
  validation accuracy:		90.43 %
Epoch 228 of 2000 took 0.165s
  training loss:		0.242245
  validation loss:		0.349904
  validation accuracy:		90.43 %
Epoch 229 of 2000 took 0.164s
  training loss:		0.240254
  validation loss:		0.364302
  validation accuracy:		89.46 %
Epoch 230 of 2000 took 0.164s
  training loss:		0.245411
  validation loss:		0.387922
  validation accuracy:		89.24 %
Epoch 231 of 2000 took 0.166s
  training loss:		0.242861
  validation loss:		0.361397
  validation accuracy:		90.65 %
Epoch 232 of 2000 took 0.166s
  training loss:		0.242498
  validation loss:		0.336716
  validation accuracy:		90.65 %
Epoch 233 of 2000 took 0.164s
  training loss:		0.240215
  validation loss:		0.347015
  validation accuracy:		90.00 %
Epoch 234 of 2000 took 0.164s
  training loss:		0.238607
  validation loss:		0.364173
  validation accuracy:		89.78 %
Epoch 235 of 2000 took 0.163s
  training loss:		0.237597
  validation loss:		0.357525
  validation accuracy:		89.89 %
Epoch 236 of 2000 took 0.190s
  training loss:		0.237985
  validation loss:		0.346075
  validation accuracy:		90.22 %
Epoch 237 of 2000 took 0.164s
  training loss:		0.236747
  validation loss:		0.351639
  validation accuracy:		89.89 %
Epoch 238 of 2000 took 0.164s
  training loss:		0.233360
  validation loss:		0.360998
  validation accuracy:		90.33 %
Epoch 239 of 2000 took 0.165s
  training loss:		0.235771
  validation loss:		0.375309
  validation accuracy:		89.89 %
Epoch 240 of 2000 took 0.166s
  training loss:		0.237548
  validation loss:		0.345796
  validation accuracy:		90.54 %
Epoch 241 of 2000 took 0.164s
  training loss:		0.237294
  validation loss:		0.344342
  validation accuracy:		90.76 %
Epoch 242 of 2000 took 0.165s
  training loss:		0.237950
  validation loss:		0.355625
  validation accuracy:		90.33 %
Epoch 243 of 2000 took 0.165s
  training loss:		0.234415
  validation loss:		0.382101
  validation accuracy:		89.35 %
Epoch 244 of 2000 took 0.140s
  training loss:		0.231044
  validation loss:		0.352628
  validation accuracy:		89.89 %
Epoch 245 of 2000 took 0.147s
  training loss:		0.233056
  validation loss:		0.361540
  validation accuracy:		89.46 %
Epoch 246 of 2000 took 0.165s
  training loss:		0.231689
  validation loss:		0.338763
  validation accuracy:		90.54 %
Epoch 247 of 2000 took 0.165s
  training loss:		0.228728
  validation loss:		0.354769
  validation accuracy:		89.78 %
Epoch 248 of 2000 took 0.143s
  training loss:		0.228339
  validation loss:		0.374009
  validation accuracy:		89.89 %
Epoch 249 of 2000 took 0.159s
  training loss:		0.231998
  validation loss:		0.373058
  validation accuracy:		90.11 %
Epoch 250 of 2000 took 0.165s
  training loss:		0.239160
  validation loss:		0.338405
  validation accuracy:		90.54 %
Epoch 251 of 2000 took 0.165s
  training loss:		0.226891
  validation loss:		0.347837
  validation accuracy:		90.11 %
Epoch 252 of 2000 took 0.166s
  training loss:		0.229909
  validation loss:		0.380886
  validation accuracy:		89.78 %
Epoch 253 of 2000 took 0.138s
  training loss:		0.227775
  validation loss:		0.337828
  validation accuracy:		90.54 %
Epoch 254 of 2000 took 0.165s
  training loss:		0.240088
  validation loss:		0.340982
  validation accuracy:		90.43 %
Epoch 255 of 2000 took 0.165s
  training loss:		0.236134
  validation loss:		0.369742
  validation accuracy:		90.33 %
Epoch 256 of 2000 took 0.164s
  training loss:		0.227311
  validation loss:		0.351484
  validation accuracy:		90.11 %
Epoch 257 of 2000 took 0.166s
  training loss:		0.236157
  validation loss:		0.360813
  validation accuracy:		90.43 %
Epoch 258 of 2000 took 0.138s
  training loss:		0.224007
  validation loss:		0.345131
  validation accuracy:		90.00 %
Epoch 259 of 2000 took 0.156s
  training loss:		0.224570
  validation loss:		0.353836
  validation accuracy:		90.00 %
Epoch 260 of 2000 took 0.253s
  training loss:		0.231043
  validation loss:		0.348141
  validation accuracy:		91.09 %
Epoch 261 of 2000 took 0.203s
  training loss:		0.225720
  validation loss:		0.342440
  validation accuracy:		90.33 %
Epoch 262 of 2000 took 0.129s
  training loss:		0.226543
  validation loss:		0.347342
  validation accuracy:		90.00 %
Epoch 263 of 2000 took 0.158s
  training loss:		0.222495
  validation loss:		0.403243
  validation accuracy:		88.91 %
Epoch 264 of 2000 took 0.158s
  training loss:		0.227845
  validation loss:		0.334097
  validation accuracy:		90.22 %
Epoch 265 of 2000 took 0.301s
  training loss:		0.221524
  validation loss:		0.343990
  validation accuracy:		90.43 %
Epoch 266 of 2000 took 0.130s
  training loss:		0.223531
  validation loss:		0.346036
  validation accuracy:		90.00 %
Epoch 267 of 2000 took 0.201s
  training loss:		0.215989
  validation loss:		0.334460
  validation accuracy:		90.43 %
Epoch 268 of 2000 took 0.208s
  training loss:		0.228435
  validation loss:		0.341477
  validation accuracy:		90.11 %
Epoch 269 of 2000 took 0.190s
  training loss:		0.223194
  validation loss:		0.355984
  validation accuracy:		90.43 %
Epoch 270 of 2000 took 0.158s
  training loss:		0.221408
  validation loss:		0.355666
  validation accuracy:		90.22 %
Epoch 271 of 2000 took 0.189s
  training loss:		0.225025
  validation loss:		0.349569
  validation accuracy:		90.65 %
Epoch 272 of 2000 took 0.233s
  training loss:		0.223306
  validation loss:		0.348398
  validation accuracy:		90.22 %
Epoch 273 of 2000 took 0.143s
  training loss:		0.221706
  validation loss:		0.330268
  validation accuracy:		90.33 %
Epoch 274 of 2000 took 0.165s
  training loss:		0.219187
  validation loss:		0.347467
  validation accuracy:		90.22 %
Epoch 275 of 2000 took 0.158s
  training loss:		0.220464
  validation loss:		0.332161
  validation accuracy:		90.65 %
Epoch 276 of 2000 took 0.147s
  training loss:		0.223251
  validation loss:		0.330429
  validation accuracy:		91.09 %
Epoch 277 of 2000 took 0.197s
  training loss:		0.224729
  validation loss:		0.339136
  validation accuracy:		89.89 %
Epoch 278 of 2000 took 0.228s
  training loss:		0.217274
  validation loss:		0.349591
  validation accuracy:		89.89 %
Epoch 279 of 2000 took 0.166s
  training loss:		0.220938
  validation loss:		0.343005
  validation accuracy:		89.89 %
Epoch 280 of 2000 took 0.311s
  training loss:		0.212511
  validation loss:		0.351282
  validation accuracy:		89.89 %
Epoch 281 of 2000 took 0.175s
  training loss:		0.214391
  validation loss:		0.336599
  validation accuracy:		90.22 %
Epoch 282 of 2000 took 0.154s
  training loss:		0.216036
  validation loss:		0.337673
  validation accuracy:		90.65 %
Epoch 283 of 2000 took 0.240s
  training loss:		0.220563
  validation loss:		0.336475
  validation accuracy:		90.22 %
Epoch 284 of 2000 took 0.166s
  training loss:		0.214723
  validation loss:		0.334807
  validation accuracy:		90.87 %
Epoch 285 of 2000 took 0.252s
  training loss:		0.212310
  validation loss:		0.356474
  validation accuracy:		90.43 %
Epoch 286 of 2000 took 0.147s
  training loss:		0.212712
  validation loss:		0.331722
  validation accuracy:		90.43 %
Epoch 287 of 2000 took 0.140s
  training loss:		0.214189
  validation loss:		0.351413
  validation accuracy:		90.43 %
Epoch 288 of 2000 took 0.184s
  training loss:		0.217140
  validation loss:		0.339313
  validation accuracy:		90.33 %
Epoch 289 of 2000 took 0.311s
  training loss:		0.208787
  validation loss:		0.346863
  validation accuracy:		90.65 %
Epoch 290 of 2000 took 0.152s
  training loss:		0.215665
  validation loss:		0.359637
  validation accuracy:		90.54 %
Epoch 291 of 2000 took 0.158s
  training loss:		0.218925
  validation loss:		0.389481
  validation accuracy:		89.13 %
Epoch 292 of 2000 took 0.157s
  training loss:		0.217802
  validation loss:		0.355063
  validation accuracy:		90.33 %
Epoch 293 of 2000 took 0.156s
  training loss:		0.214802
  validation loss:		0.331827
  validation accuracy:		90.11 %
Epoch 294 of 2000 took 0.177s
  training loss:		0.209305
  validation loss:		0.324983
  validation accuracy:		90.43 %
Epoch 295 of 2000 took 0.151s
  training loss:		0.217001
  validation loss:		0.341983
  validation accuracy:		90.00 %
Epoch 296 of 2000 took 0.157s
  training loss:		0.208746
  validation loss:		0.335392
  validation accuracy:		90.54 %
Epoch 297 of 2000 took 0.156s
  training loss:		0.209908
  validation loss:		0.327598
  validation accuracy:		90.33 %
Epoch 298 of 2000 took 0.175s
  training loss:		0.210821
  validation loss:		0.341886
  validation accuracy:		89.89 %
Epoch 299 of 2000 took 0.151s
  training loss:		0.213528
  validation loss:		0.353633
  validation accuracy:		90.33 %
Epoch 300 of 2000 took 0.225s
  training loss:		0.203219
  validation loss:		0.370149
  validation accuracy:		89.24 %
Epoch 301 of 2000 took 0.158s
  training loss:		0.214117
  validation loss:		0.324101
  validation accuracy:		90.76 %
Epoch 302 of 2000 took 0.136s
  training loss:		0.206057
  validation loss:		0.362701
  validation accuracy:		90.43 %
Epoch 303 of 2000 took 0.156s
  training loss:		0.209691
  validation loss:		0.354339
  validation accuracy:		90.65 %
Epoch 304 of 2000 took 0.158s
  training loss:		0.209407
  validation loss:		0.340661
  validation accuracy:		90.65 %
Epoch 305 of 2000 took 0.137s
  training loss:		0.199427
  validation loss:		0.340925
  validation accuracy:		90.33 %
Epoch 306 of 2000 took 0.155s
  training loss:		0.205609
  validation loss:		0.330520
  validation accuracy:		90.87 %
Epoch 307 of 2000 took 0.158s
  training loss:		0.204468
  validation loss:		0.347955
  validation accuracy:		90.11 %
Epoch 308 of 2000 took 0.155s
  training loss:		0.208826
  validation loss:		0.350711
  validation accuracy:		89.89 %
Epoch 309 of 2000 took 0.157s
  training loss:		0.202262
  validation loss:		0.365049
  validation accuracy:		90.43 %
Epoch 310 of 2000 took 0.157s
  training loss:		0.205714
  validation loss:		0.334454
  validation accuracy:		90.76 %
Epoch 311 of 2000 took 0.199s
  training loss:		0.208704
  validation loss:		0.346158
  validation accuracy:		90.00 %
Epoch 312 of 2000 took 0.147s
  training loss:		0.196740
  validation loss:		0.332287
  validation accuracy:		90.65 %
Epoch 313 of 2000 took 0.157s
  training loss:		0.204272
  validation loss:		0.331670
  validation accuracy:		90.54 %
Epoch 314 of 2000 took 0.200s
  training loss:		0.201418
  validation loss:		0.337954
  validation accuracy:		91.09 %
Epoch 315 of 2000 took 0.212s
  training loss:		0.200184
  validation loss:		0.363571
  validation accuracy:		89.67 %
Epoch 316 of 2000 took 0.153s
  training loss:		0.203474
  validation loss:		0.332367
  validation accuracy:		90.98 %
Epoch 317 of 2000 took 0.238s
  training loss:		0.206466
  validation loss:		0.347076
  validation accuracy:		90.43 %
Epoch 318 of 2000 took 0.155s
  training loss:		0.202438
  validation loss:		0.366991
  validation accuracy:		89.57 %
Epoch 319 of 2000 took 0.174s
  training loss:		0.202443
  validation loss:		0.333495
  validation accuracy:		90.87 %
Epoch 320 of 2000 took 0.186s
  training loss:		0.202686
  validation loss:		0.351440
  validation accuracy:		90.00 %
Epoch 321 of 2000 took 0.157s
  training loss:		0.196164
  validation loss:		0.358534
  validation accuracy:		90.33 %
Epoch 322 of 2000 took 0.155s
  training loss:		0.210993
  validation loss:		0.378266
  validation accuracy:		89.78 %
Epoch 323 of 2000 took 0.169s
  training loss:		0.201374
  validation loss:		0.368103
  validation accuracy:		90.22 %
Epoch 324 of 2000 took 0.110s
  training loss:		0.215364
  validation loss:		0.330863
  validation accuracy:		90.76 %
Epoch 325 of 2000 took 0.164s
  training loss:		0.196696
  validation loss:		0.332150
  validation accuracy:		90.87 %
Epoch 326 of 2000 took 0.172s
  training loss:		0.202772
  validation loss:		0.376845
  validation accuracy:		89.13 %
Epoch 327 of 2000 took 0.170s
  training loss:		0.197744
  validation loss:		0.335162
  validation accuracy:		90.54 %
Epoch 328 of 2000 took 0.164s
  training loss:		0.196843
  validation loss:		0.335692
  validation accuracy:		90.33 %
Epoch 329 of 2000 took 0.124s
  training loss:		0.195905
  validation loss:		0.339719
  validation accuracy:		90.76 %
Epoch 330 of 2000 took 0.159s
  training loss:		0.201548
  validation loss:		0.345882
  validation accuracy:		90.98 %
Epoch 331 of 2000 took 0.156s
  training loss:		0.197349
  validation loss:		0.354186
  validation accuracy:		90.22 %
Epoch 332 of 2000 took 0.166s
  training loss:		0.195458
  validation loss:		0.342337
  validation accuracy:		90.11 %
Epoch 333 of 2000 took 0.114s
  training loss:		0.197529
  validation loss:		0.337561
  validation accuracy:		90.87 %
Epoch 334 of 2000 took 0.137s
  training loss:		0.195882
  validation loss:		0.327899
  validation accuracy:		91.30 %
Epoch 335 of 2000 took 0.254s
  training loss:		0.196777
  validation loss:		0.342306
  validation accuracy:		90.76 %
Epoch 336 of 2000 took 0.151s
  training loss:		0.187699
  validation loss:		0.321988
  validation accuracy:		90.98 %
Epoch 337 of 2000 took 0.134s
  training loss:		0.196602
  validation loss:		0.331667
  validation accuracy:		90.65 %
Epoch 338 of 2000 took 0.220s
  training loss:		0.199555
  validation loss:		0.325984
  validation accuracy:		90.87 %
Epoch 339 of 2000 took 0.224s
  training loss:		0.196145
  validation loss:		0.343025
  validation accuracy:		90.98 %
Epoch 340 of 2000 took 0.322s
  training loss:		0.191237
  validation loss:		0.392622
  validation accuracy:		89.02 %
Epoch 341 of 2000 took 0.324s
  training loss:		0.199958
  validation loss:		0.327244
  validation accuracy:		91.20 %
Epoch 342 of 2000 took 0.275s
  training loss:		0.187889
  validation loss:		0.362175
  validation accuracy:		89.57 %
Epoch 343 of 2000 took 0.167s
  training loss:		0.192987
  validation loss:		0.339178
  validation accuracy:		90.76 %
Epoch 344 of 2000 took 0.149s
  training loss:		0.190062
  validation loss:		0.354205
  validation accuracy:		89.89 %
Epoch 345 of 2000 took 0.157s
  training loss:		0.196369
  validation loss:		0.337574
  validation accuracy:		90.87 %
Epoch 346 of 2000 took 0.302s
  training loss:		0.190373
  validation loss:		0.377268
  validation accuracy:		89.13 %
Epoch 347 of 2000 took 0.242s
  training loss:		0.196445
  validation loss:		0.333428
  validation accuracy:		90.76 %
Epoch 348 of 2000 took 0.135s
  training loss:		0.186553
  validation loss:		0.346203
  validation accuracy:		90.33 %
Epoch 349 of 2000 took 0.164s
  training loss:		0.189936
  validation loss:		0.350305
  validation accuracy:		90.00 %
Epoch 350 of 2000 took 0.164s
  training loss:		0.191894
  validation loss:		0.334947
  validation accuracy:		90.54 %
Epoch 351 of 2000 took 0.131s
  training loss:		0.193569
  validation loss:		0.335633
  validation accuracy:		90.65 %
Epoch 352 of 2000 took 0.144s
  training loss:		0.187384
  validation loss:		0.359727
  validation accuracy:		90.22 %
Epoch 353 of 2000 took 0.156s
  training loss:		0.198631
  validation loss:		0.341269
  validation accuracy:		90.76 %
Epoch 354 of 2000 took 0.144s
  training loss:		0.188635
  validation loss:		0.350890
  validation accuracy:		90.11 %
Epoch 355 of 2000 took 0.151s
  training loss:		0.190117
  validation loss:		0.357589
  validation accuracy:		89.78 %
Epoch 356 of 2000 took 0.165s
  training loss:		0.188677
  validation loss:		0.339908
  validation accuracy:		90.43 %
Epoch 357 of 2000 took 0.133s
  training loss:		0.191565
  validation loss:		0.347101
  validation accuracy:		90.65 %
Epoch 358 of 2000 took 0.155s
  training loss:		0.194112
  validation loss:		0.328102
  validation accuracy:		90.98 %
Epoch 359 of 2000 took 0.164s
  training loss:		0.186293
  validation loss:		0.327973
  validation accuracy:		91.09 %
Epoch 360 of 2000 took 0.123s
  training loss:		0.190584
  validation loss:		0.341230
  validation accuracy:		90.98 %
Epoch 361 of 2000 took 0.164s
  training loss:		0.186162
  validation loss:		0.351423
  validation accuracy:		90.22 %
Epoch 362 of 2000 took 0.160s
  training loss:		0.187140
  validation loss:		0.353418
  validation accuracy:		90.65 %
Epoch 363 of 2000 took 0.126s
  training loss:		0.190066
  validation loss:		0.331003
  validation accuracy:		90.43 %
Epoch 364 of 2000 took 0.164s
  training loss:		0.184755
  validation loss:		0.357549
  validation accuracy:		90.76 %
Epoch 365 of 2000 took 0.164s
  training loss:		0.187897
  validation loss:		0.339265
  validation accuracy:		90.87 %
Epoch 366 of 2000 took 0.156s
  training loss:		0.182900
  validation loss:		0.332923
  validation accuracy:		90.76 %
Epoch 367 of 2000 took 0.194s
  training loss:		0.185365
  validation loss:		0.382941
  validation accuracy:		89.02 %
Epoch 368 of 2000 took 0.188s
  training loss:		0.187403
  validation loss:		0.331977
  validation accuracy:		90.98 %
Epoch 369 of 2000 took 0.161s
  training loss:		0.192011
  validation loss:		0.349094
  validation accuracy:		90.43 %
Epoch 370 of 2000 took 0.239s
  training loss:		0.184853
  validation loss:		0.359947
  validation accuracy:		90.54 %
Epoch 371 of 2000 took 0.226s
  training loss:		0.185535
  validation loss:		0.347263
  validation accuracy:		90.54 %
Epoch 372 of 2000 took 0.164s
  training loss:		0.175545
  validation loss:		0.348110
  validation accuracy:		90.65 %
Epoch 373 of 2000 took 0.163s
  training loss:		0.182179
  validation loss:		0.343914
  validation accuracy:		90.00 %
Epoch 374 of 2000 took 0.173s
  training loss:		0.183050
  validation loss:		0.339394
  validation accuracy:		90.87 %
Epoch 375 of 2000 took 0.168s
  training loss:		0.183047
  validation loss:		0.334776
  validation accuracy:		90.65 %
Epoch 376 of 2000 took 0.159s
  training loss:		0.178467
  validation loss:		0.328580
  validation accuracy:		90.43 %
Epoch 377 of 2000 took 0.171s
  training loss:		0.180445
  validation loss:		0.350313
  validation accuracy:		90.43 %
Epoch 378 of 2000 took 0.166s
  training loss:		0.185715
  validation loss:		0.352208
  validation accuracy:		90.11 %
Epoch 379 of 2000 took 0.166s
  training loss:		0.189794
  validation loss:		0.339201
  validation accuracy:		90.54 %
Epoch 380 of 2000 took 0.162s
  training loss:		0.187599
  validation loss:		0.343527
  validation accuracy:		90.33 %
Epoch 381 of 2000 took 0.238s
  training loss:		0.172373
  validation loss:		0.337338
  validation accuracy:		90.87 %
Epoch 382 of 2000 took 0.235s
  training loss:		0.176695
  validation loss:		0.333078
  validation accuracy:		90.98 %
Epoch 383 of 2000 took 0.161s
  training loss:		0.184810
  validation loss:		0.397992
  validation accuracy:		89.35 %
Epoch 384 of 2000 took 0.222s
  training loss:		0.184847
  validation loss:		0.347939
  validation accuracy:		90.65 %
Epoch 385 of 2000 took 0.162s
  training loss:		0.180427
  validation loss:		0.357709
  validation accuracy:		90.87 %
Epoch 386 of 2000 took 0.178s
  training loss:		0.180927
  validation loss:		0.344808
  validation accuracy:		90.65 %
Epoch 387 of 2000 took 0.211s
  training loss:		0.175749
  validation loss:		0.338447
  validation accuracy:		90.54 %
Epoch 388 of 2000 took 0.161s
  training loss:		0.186997
  validation loss:		0.342511
  validation accuracy:		90.65 %
Epoch 389 of 2000 took 0.211s
  training loss:		0.178047
  validation loss:		0.356493
  validation accuracy:		90.11 %
Epoch 390 of 2000 took 0.133s
  training loss:		0.181907
  validation loss:		0.344618
  validation accuracy:		90.65 %
Epoch 391 of 2000 took 0.165s
  training loss:		0.178571
  validation loss:		0.347785
  validation accuracy:		90.43 %
Epoch 392 of 2000 took 0.159s
  training loss:		0.177574
  validation loss:		0.332003
  validation accuracy:		90.54 %
Epoch 393 of 2000 took 0.144s
  training loss:		0.172743
  validation loss:		0.333513
  validation accuracy:		90.65 %
Epoch 394 of 2000 took 0.165s
  training loss:		0.176576
  validation loss:		0.343174
  validation accuracy:		90.87 %
Epoch 395 of 2000 took 0.161s
  training loss:		0.178278
  validation loss:		0.330157
  validation accuracy:		90.43 %
Epoch 396 of 2000 took 0.143s
  training loss:		0.172799
  validation loss:		0.342951
  validation accuracy:		91.20 %
Epoch 397 of 2000 took 0.165s
  training loss:		0.180232
  validation loss:		0.345526
  validation accuracy:		90.54 %
Epoch 398 of 2000 took 0.145s
  training loss:		0.172334
  validation loss:		0.349457
  validation accuracy:		90.65 %
Epoch 399 of 2000 took 0.157s
  training loss:		0.173776
  validation loss:		0.343311
  validation accuracy:		90.33 %
Epoch 400 of 2000 took 0.164s
  training loss:		0.177268
  validation loss:		0.331997
  validation accuracy:		91.20 %
Epoch 401 of 2000 took 0.138s
  training loss:		0.175200
  validation loss:		0.337741
  validation accuracy:		91.41 %
Epoch 402 of 2000 took 0.165s
  training loss:		0.182791
  validation loss:		0.357844
  validation accuracy:		89.89 %
Epoch 403 of 2000 took 0.139s
  training loss:		0.170345
  validation loss:		0.339289
  validation accuracy:		90.54 %
Epoch 404 of 2000 took 0.163s
  training loss:		0.177584
  validation loss:		0.391848
  validation accuracy:		89.57 %
Epoch 405 of 2000 took 0.164s
  training loss:		0.171185
  validation loss:		0.356544
  validation accuracy:		90.00 %
Epoch 406 of 2000 took 0.137s
  training loss:		0.176078
  validation loss:		0.340120
  validation accuracy:		91.20 %
Epoch 407 of 2000 took 0.165s
  training loss:		0.176082
  validation loss:		0.335579
  validation accuracy:		90.43 %
Epoch 408 of 2000 took 0.139s
  training loss:		0.175374
  validation loss:		0.336688
  validation accuracy:		91.20 %
Epoch 409 of 2000 took 0.162s
  training loss:		0.166659
  validation loss:		0.345448
  validation accuracy:		90.87 %
Epoch 410 of 2000 took 0.164s
  training loss:		0.168448
  validation loss:		0.323951
  validation accuracy:		91.09 %
Epoch 411 of 2000 took 0.140s
  training loss:		0.171291
  validation loss:		0.340864
  validation accuracy:		90.87 %
Epoch 412 of 2000 took 0.165s
  training loss:		0.169499
  validation loss:		0.355377
  validation accuracy:		90.43 %
Epoch 413 of 2000 took 0.138s
  training loss:		0.169227
  validation loss:		0.328036
  validation accuracy:		90.76 %
Epoch 414 of 2000 took 0.165s
  training loss:		0.168324
  validation loss:		0.345040
  validation accuracy:		90.65 %
Epoch 415 of 2000 took 0.153s
  training loss:		0.170100
  validation loss:		0.336477
  validation accuracy:		90.98 %
Epoch 416 of 2000 took 0.150s
  training loss:		0.165134
  validation loss:		0.334023
  validation accuracy:		90.76 %
Epoch 417 of 2000 took 0.165s
  training loss:		0.170694
  validation loss:		0.361474
  validation accuracy:		90.11 %
Epoch 418 of 2000 took 0.117s
  training loss:		0.171643
  validation loss:		0.336209
  validation accuracy:		91.20 %
Epoch 419 of 2000 took 0.160s
  training loss:		0.165450
  validation loss:		0.323457
  validation accuracy:		90.65 %
Epoch 420 of 2000 took 0.152s
  training loss:		0.171578
  validation loss:		0.334246
  validation accuracy:		91.30 %
Epoch 421 of 2000 took 0.145s
  training loss:		0.168942
  validation loss:		0.380151
  validation accuracy:		90.11 %
Epoch 422 of 2000 took 0.144s
  training loss:		0.172733
  validation loss:		0.337256
  validation accuracy:		90.87 %
Epoch 423 of 2000 took 0.165s
  training loss:		0.173217
  validation loss:		0.360004
  validation accuracy:		90.11 %
Epoch 424 of 2000 took 0.164s
  training loss:		0.165849
  validation loss:		0.328795
  validation accuracy:		90.65 %
Epoch 425 of 2000 took 0.137s
  training loss:		0.173378
  validation loss:		0.349198
  validation accuracy:		90.43 %
Epoch 426 of 2000 took 0.150s
  training loss:		0.166078
  validation loss:		0.339536
  validation accuracy:		90.65 %
Epoch 427 of 2000 took 0.165s
  training loss:		0.175645
  validation loss:		0.335266
  validation accuracy:		90.98 %
Epoch 428 of 2000 took 0.124s
  training loss:		0.161809
  validation loss:		0.326715
  validation accuracy:		90.76 %
Epoch 429 of 2000 took 0.165s
  training loss:		0.165504
  validation loss:		0.340690
  validation accuracy:		90.00 %
Epoch 430 of 2000 took 0.159s
  training loss:		0.168373
  validation loss:		0.356380
  validation accuracy:		90.43 %
Epoch 431 of 2000 took 0.131s
  training loss:		0.168361
  validation loss:		0.349918
  validation accuracy:		90.22 %
Epoch 432 of 2000 took 0.166s
  training loss:		0.167609
  validation loss:		0.390040
  validation accuracy:		89.67 %
Epoch 433 of 2000 took 0.138s
  training loss:		0.169007
  validation loss:		0.342866
  validation accuracy:		90.54 %
Epoch 434 of 2000 took 0.151s
  training loss:		0.162513
  validation loss:		0.334782
  validation accuracy:		90.54 %
Epoch 435 of 2000 took 0.165s
  training loss:		0.168551
  validation loss:		0.341113
  validation accuracy:		90.54 %
Epoch 436 of 2000 took 0.125s
  training loss:		0.164812
  validation loss:		0.334333
  validation accuracy:		90.43 %
Epoch 437 of 2000 took 0.165s
  training loss:		0.163521
  validation loss:		0.324451
  validation accuracy:		91.20 %
Epoch 438 of 2000 took 0.154s
  training loss:		0.159820
  validation loss:		0.337562
  validation accuracy:		90.33 %
Epoch 439 of 2000 took 0.135s
  training loss:		0.159444
  validation loss:		0.334788
  validation accuracy:		90.54 %
Epoch 440 of 2000 took 0.166s
  training loss:		0.160171
  validation loss:		0.348265
  validation accuracy:		90.33 %
Epoch 441 of 2000 took 0.133s
  training loss:		0.159101
  validation loss:		0.329190
  validation accuracy:		90.65 %
Epoch 442 of 2000 took 0.157s
  training loss:		0.163403
  validation loss:		0.348950
  validation accuracy:		90.98 %
Epoch 443 of 2000 took 0.165s
  training loss:		0.168104
  validation loss:		0.339899
  validation accuracy:		90.65 %
Epoch 444 of 2000 took 0.124s
  training loss:		0.163747
  validation loss:		0.325127
  validation accuracy:		91.20 %
Epoch 445 of 2000 took 0.165s
  training loss:		0.156438
  validation loss:		0.365654
  validation accuracy:		90.33 %
Epoch 446 of 2000 took 0.149s
  training loss:		0.154738
  validation loss:		0.336941
  validation accuracy:		90.22 %
Epoch 447 of 2000 took 0.141s
  training loss:		0.158286
  validation loss:		0.347940
  validation accuracy:		90.00 %
Epoch 448 of 2000 took 0.166s
  training loss:		0.158898
  validation loss:		0.339592
  validation accuracy:		90.43 %
Epoch 449 of 2000 took 0.127s
  training loss:		0.158794
  validation loss:		0.365935
  validation accuracy:		90.54 %
Epoch 450 of 2000 took 0.163s
  training loss:		0.163334
  validation loss:		0.348603
  validation accuracy:		90.54 %
Epoch 451 of 2000 took 0.164s
  training loss:		0.161398
  validation loss:		0.335320
  validation accuracy:		90.43 %
Epoch 452 of 2000 took 0.126s
  training loss:		0.158143
  validation loss:		0.335815
  validation accuracy:		91.30 %
Epoch 453 of 2000 took 0.166s
  training loss:		0.157980
  validation loss:		0.352241
  validation accuracy:		91.09 %
Epoch 454 of 2000 took 0.142s
  training loss:		0.158869
  validation loss:		0.328145
  validation accuracy:		91.20 %
Epoch 455 of 2000 took 0.146s
  training loss:		0.153988
  validation loss:		0.340069
  validation accuracy:		90.11 %
Epoch 456 of 2000 took 0.166s
  training loss:		0.158291
  validation loss:		0.350483
  validation accuracy:		90.54 %
Epoch 457 of 2000 took 0.125s
  training loss:		0.157283
  validation loss:		0.332476
  validation accuracy:		90.65 %
Epoch 458 of 2000 took 0.165s
  training loss:		0.156226
  validation loss:		0.359286
  validation accuracy:		89.89 %
Epoch 459 of 2000 took 0.165s
  training loss:		0.155275
  validation loss:		0.353522
  validation accuracy:		89.78 %
Epoch 460 of 2000 took 0.125s
  training loss:		0.161322
  validation loss:		0.354181
  validation accuracy:		90.54 %
Epoch 461 of 2000 took 0.165s
  training loss:		0.162136
  validation loss:		0.349949
  validation accuracy:		90.11 %
Epoch 462 of 2000 took 0.157s
  training loss:		0.158498
  validation loss:		0.342670
  validation accuracy:		90.11 %
Epoch 463 of 2000 took 0.133s
  training loss:		0.151745
  validation loss:		0.343277
  validation accuracy:		91.63 %
Epoch 464 of 2000 took 0.166s
  training loss:		0.152306
  validation loss:		0.327990
  validation accuracy:		90.87 %
Epoch 465 of 2000 took 0.135s
  training loss:		0.152869
  validation loss:		0.342099
  validation accuracy:		90.11 %
Epoch 466 of 2000 took 0.154s
  training loss:		0.153778
  validation loss:		0.327327
  validation accuracy:		90.65 %
Epoch 467 of 2000 took 0.165s
  training loss:		0.150852
  validation loss:		0.343354
  validation accuracy:		90.33 %
Epoch 468 of 2000 took 0.125s
  training loss:		0.156461
  validation loss:		0.354030
  validation accuracy:		90.54 %
Epoch 469 of 2000 took 0.165s
  training loss:		0.153457
  validation loss:		0.338965
  validation accuracy:		91.09 %
Epoch 470 of 2000 took 0.151s
  training loss:		0.156015
  validation loss:		0.357800
  validation accuracy:		90.22 %
Epoch 471 of 2000 took 0.151s
  training loss:		0.151488
  validation loss:		0.327777
  validation accuracy:		91.09 %
Epoch 472 of 2000 took 0.165s
  training loss:		0.162380
  validation loss:		0.331211
  validation accuracy:		90.65 %
Epoch 473 of 2000 took 0.134s
  training loss:		0.154517
  validation loss:		0.340342
  validation accuracy:		90.65 %
Epoch 474 of 2000 took 0.164s
  training loss:		0.152810
  validation loss:		0.347502
  validation accuracy:		90.43 %
Epoch 475 of 2000 took 0.142s
  training loss:		0.152217
  validation loss:		0.337742
  validation accuracy:		90.33 %
Epoch 476 of 2000 took 0.156s
  training loss:		0.154980
  validation loss:		0.346866
  validation accuracy:		90.76 %
Epoch 477 of 2000 took 0.165s
  training loss:		0.145354
  validation loss:		0.356882
  validation accuracy:		90.65 %
Epoch 478 of 2000 took 0.134s
  training loss:		0.151272
  validation loss:		0.341397
  validation accuracy:		91.20 %
Epoch 479 of 2000 took 0.164s
  training loss:		0.147462
  validation loss:		0.341432
  validation accuracy:		90.43 %
Epoch 480 of 2000 took 0.140s
  training loss:		0.146394
  validation loss:		0.368184
  validation accuracy:		90.54 %
Epoch 481 of 2000 took 0.159s
  training loss:		0.151292
  validation loss:		0.360363
  validation accuracy:		90.33 %
Epoch 482 of 2000 took 0.165s
  training loss:		0.152574
  validation loss:		0.343540
  validation accuracy:		91.41 %
Epoch 483 of 2000 took 0.134s
  training loss:		0.148979
  validation loss:		0.337523
  validation accuracy:		91.20 %
Epoch 484 of 2000 took 0.164s
  training loss:		0.140495
  validation loss:		0.345744
  validation accuracy:		91.09 %
Epoch 485 of 2000 took 0.137s
  training loss:		0.147035
  validation loss:		0.339277
  validation accuracy:		90.54 %
Epoch 486 of 2000 took 0.161s
  training loss:		0.152183
  validation loss:		0.368148
  validation accuracy:		89.57 %
Epoch 487 of 2000 took 0.166s
  training loss:		0.149225
  validation loss:		0.334462
  validation accuracy:		90.76 %
Epoch 488 of 2000 took 0.134s
  training loss:		0.149189
  validation loss:		0.340070
  validation accuracy:		90.22 %
Epoch 489 of 2000 took 0.165s
  training loss:		0.146969
  validation loss:		0.332144
  validation accuracy:		91.41 %
Epoch 490 of 2000 took 0.134s
  training loss:		0.147563
  validation loss:		0.329272
  validation accuracy:		90.65 %
Epoch 491 of 2000 took 0.164s
  training loss:		0.144755
  validation loss:		0.354138
  validation accuracy:		90.22 %
Epoch 492 of 2000 took 0.163s
  training loss:		0.145975
  validation loss:		0.372710
  validation accuracy:		90.54 %
Epoch 493 of 2000 took 0.137s
  training loss:		0.141233
  validation loss:		0.351124
  validation accuracy:		91.20 %
Epoch 494 of 2000 took 0.165s
  training loss:		0.142399
  validation loss:		0.346495
  validation accuracy:		90.33 %
Epoch 495 of 2000 took 0.135s
  training loss:		0.148897
  validation loss:		0.335109
  validation accuracy:		90.33 %
Epoch 496 of 2000 took 0.163s
  training loss:		0.143841
  validation loss:		0.347343
  validation accuracy:		90.00 %
Epoch 497 of 2000 took 0.163s
  training loss:		0.145624
  validation loss:		0.340273
  validation accuracy:		90.87 %
Epoch 498 of 2000 took 0.137s
  training loss:		0.143449
  validation loss:		0.341468
  validation accuracy:		91.09 %
Epoch 499 of 2000 took 0.165s
  training loss:		0.140374
  validation loss:		0.340204
  validation accuracy:		90.54 %
Epoch 500 of 2000 took 0.134s
  training loss:		0.147050
  validation loss:		0.340864
  validation accuracy:		91.30 %
Epoch 501 of 2000 took 0.164s
  training loss:		0.145119
  validation loss:		0.351223
  validation accuracy:		90.54 %
Epoch 502 of 2000 took 0.159s
  training loss:		0.143952
  validation loss:		0.364552
  validation accuracy:		90.00 %
Epoch 503 of 2000 took 0.141s
  training loss:		0.146273
  validation loss:		0.345471
  validation accuracy:		90.11 %
Epoch 504 of 2000 took 0.165s
  training loss:		0.150009
  validation loss:		0.340302
  validation accuracy:		91.20 %
Epoch 505 of 2000 took 0.134s
  training loss:		0.143477
  validation loss:		0.330148
  validation accuracy:		92.07 %
Epoch 506 of 2000 took 0.164s
  training loss:		0.143442
  validation loss:		0.374718
  validation accuracy:		90.43 %
Epoch 507 of 2000 took 0.156s
  training loss:		0.141608
  validation loss:		0.349125
  validation accuracy:		90.76 %
Epoch 508 of 2000 took 0.144s
  training loss:		0.144899
  validation loss:		0.335353
  validation accuracy:		90.43 %
Epoch 509 of 2000 took 0.165s
  training loss:		0.141439
  validation loss:		0.337985
  validation accuracy:		91.09 %
Epoch 510 of 2000 took 0.134s
  training loss:		0.139950
  validation loss:		0.344213
  validation accuracy:		91.63 %
Epoch 511 of 2000 took 0.164s
  training loss:		0.139782
  validation loss:		0.334150
  validation accuracy:		91.20 %
Epoch 512 of 2000 took 0.152s
  training loss:		0.141933
  validation loss:		0.333277
  validation accuracy:		90.54 %
Epoch 513 of 2000 took 0.147s
  training loss:		0.140682
  validation loss:		0.390297
  validation accuracy:		90.54 %
Epoch 514 of 2000 took 0.165s
  training loss:		0.145673
  validation loss:		0.345073
  validation accuracy:		91.20 %
Epoch 515 of 2000 took 0.134s
  training loss:		0.141158
  validation loss:		0.360117
  validation accuracy:		89.78 %
Epoch 516 of 2000 took 0.164s
  training loss:		0.141163
  validation loss:		0.350833
  validation accuracy:		90.76 %
Epoch 517 of 2000 took 0.148s
  training loss:		0.134057
  validation loss:		0.340841
  validation accuracy:		90.76 %
Epoch 518 of 2000 took 0.152s
  training loss:		0.135977
  validation loss:		0.363605
  validation accuracy:		90.98 %
Epoch 519 of 2000 took 0.165s
  training loss:		0.142739
  validation loss:		0.343070
  validation accuracy:		91.20 %
Epoch 520 of 2000 took 0.134s
  training loss:		0.137393
  validation loss:		0.342053
  validation accuracy:		90.65 %
Epoch 521 of 2000 took 0.164s
  training loss:		0.135658
  validation loss:		0.349681
  validation accuracy:		91.30 %
Epoch 522 of 2000 took 0.144s
  training loss:		0.140958
  validation loss:		0.356888
  validation accuracy:		90.54 %
Epoch 523 of 2000 took 0.155s
  training loss:		0.147165
  validation loss:		0.337904
  validation accuracy:		90.65 %
Epoch 524 of 2000 took 0.165s
  training loss:		0.140116
  validation loss:		0.351015
  validation accuracy:		91.30 %
Epoch 525 of 2000 took 0.134s
  training loss:		0.138014
  validation loss:		0.353444
  validation accuracy:		91.20 %
Epoch 526 of 2000 took 0.164s
  training loss:		0.140177
  validation loss:		0.353717
  validation accuracy:		90.00 %
Epoch 527 of 2000 took 0.140s
  training loss:		0.137795
  validation loss:		0.409112
  validation accuracy:		89.89 %
Epoch 528 of 2000 took 0.159s
  training loss:		0.142530
  validation loss:		0.354929
  validation accuracy:		90.98 %
Epoch 529 of 2000 took 0.165s
  training loss:		0.139809
  validation loss:		0.355803
  validation accuracy:		90.76 %
Epoch 530 of 2000 took 0.134s
  training loss:		0.137072
  validation loss:		0.358242
  validation accuracy:		90.98 %
Epoch 531 of 2000 took 0.165s
  training loss:		0.135721
  validation loss:		0.353377
  validation accuracy:		91.41 %
Epoch 532 of 2000 took 0.136s
  training loss:		0.146195
  validation loss:		0.340428
  validation accuracy:		91.52 %
Epoch 533 of 2000 took 0.164s
  training loss:		0.140201
  validation loss:		0.351560
  validation accuracy:		90.22 %
Epoch 534 of 2000 took 0.162s
  training loss:		0.134495
  validation loss:		0.360213
  validation accuracy:		90.43 %
Epoch 535 of 2000 took 0.137s
  training loss:		0.134213
  validation loss:		0.351773
  validation accuracy:		91.09 %
Epoch 536 of 2000 took 0.165s
  training loss:		0.136472
  validation loss:		0.368388
  validation accuracy:		90.22 %
Epoch 537 of 2000 took 0.134s
  training loss:		0.136558
  validation loss:		0.357764
  validation accuracy:		90.87 %
Epoch 538 of 2000 took 0.164s
  training loss:		0.133414
  validation loss:		0.349194
  validation accuracy:		90.54 %
Epoch 539 of 2000 took 0.159s
  training loss:		0.136799
  validation loss:		0.389723
  validation accuracy:		90.22 %
Epoch 540 of 2000 took 0.140s
  training loss:		0.140988
  validation loss:		0.363396
  validation accuracy:		91.20 %
Epoch 541 of 2000 took 0.165s
  training loss:		0.137166
  validation loss:		0.349366
  validation accuracy:		90.43 %
Epoch 542 of 2000 took 0.135s
  training loss:		0.135605
  validation loss:		0.359095
  validation accuracy:		90.54 %
Epoch 543 of 2000 took 0.164s
  training loss:		0.134554
  validation loss:		0.366038
  validation accuracy:		89.78 %
Epoch 544 of 2000 took 0.155s
  training loss:		0.137006
  validation loss:		0.363588
  validation accuracy:		90.76 %
Epoch 545 of 2000 took 0.143s
  training loss:		0.136127
  validation loss:		0.381079
  validation accuracy:		90.65 %
Epoch 546 of 2000 took 0.165s
  training loss:		0.136722
  validation loss:		0.363042
  validation accuracy:		90.98 %
Epoch 547 of 2000 took 0.135s
  training loss:		0.130028
  validation loss:		0.351623
  validation accuracy:		90.76 %
Epoch 548 of 2000 took 0.164s
  training loss:		0.132867
  validation loss:		0.356416
  validation accuracy:		90.98 %
Epoch 549 of 2000 took 0.154s
  training loss:		0.134244
  validation loss:		0.356204
  validation accuracy:		90.65 %
Epoch 550 of 2000 took 0.145s
  training loss:		0.128160
  validation loss:		0.338641
  validation accuracy:		91.52 %
Epoch 551 of 2000 took 0.165s
  training loss:		0.136336
  validation loss:		0.353663
  validation accuracy:		90.54 %
Epoch 552 of 2000 took 0.134s
  training loss:		0.132722
  validation loss:		0.353094
  validation accuracy:		90.87 %
Epoch 553 of 2000 took 0.164s
  training loss:		0.131760
  validation loss:		0.362942
  validation accuracy:		91.09 %
Epoch 554 of 2000 took 0.150s
  training loss:		0.134612
  validation loss:		0.341157
  validation accuracy:		91.20 %
Epoch 555 of 2000 took 0.149s
  training loss:		0.131591
  validation loss:		0.357255
  validation accuracy:		90.76 %
Epoch 556 of 2000 took 0.165s
  training loss:		0.131468
  validation loss:		0.372044
  validation accuracy:		90.76 %
Epoch 557 of 2000 took 0.135s
  training loss:		0.134557
  validation loss:		0.381711
  validation accuracy:		90.54 %
Epoch 558 of 2000 took 0.164s
  training loss:		0.131310
  validation loss:		0.366033
  validation accuracy:		90.98 %
Epoch 559 of 2000 took 0.147s
  training loss:		0.131821
  validation loss:		0.351632
  validation accuracy:		90.65 %
Epoch 560 of 2000 took 0.152s
  training loss:		0.138905
  validation loss:		0.361697
  validation accuracy:		90.22 %
Epoch 561 of 2000 took 0.165s
  training loss:		0.126158
  validation loss:		0.367907
  validation accuracy:		90.22 %
Epoch 562 of 2000 took 0.135s
  training loss:		0.128825
  validation loss:		0.346169
  validation accuracy:		91.09 %
Epoch 563 of 2000 took 0.164s
  training loss:		0.130202
  validation loss:		0.355739
  validation accuracy:		90.54 %
Epoch 564 of 2000 took 0.143s
  training loss:		0.132474
  validation loss:		0.355402
  validation accuracy:		91.30 %
Epoch 565 of 2000 took 0.156s
  training loss:		0.132106
  validation loss:		0.367651
  validation accuracy:		90.76 %
Epoch 566 of 2000 took 0.166s
  training loss:		0.127773
  validation loss:		0.356099
  validation accuracy:		91.52 %
Epoch 567 of 2000 took 0.134s
  training loss:		0.128185
  validation loss:		0.377493
  validation accuracy:		90.87 %
Epoch 568 of 2000 took 0.164s
  training loss:		0.132268
  validation loss:		0.363461
  validation accuracy:		91.20 %
Epoch 569 of 2000 took 0.142s
  training loss:		0.127400
  validation loss:		0.363589
  validation accuracy:		90.33 %
Epoch 570 of 2000 took 0.157s
  training loss:		0.128198
  validation loss:		0.368775
  validation accuracy:		90.11 %
Epoch 571 of 2000 took 0.165s
  training loss:		0.129519
  validation loss:		0.357021
  validation accuracy:		90.76 %
Epoch 572 of 2000 took 0.134s
  training loss:		0.133596
  validation loss:		0.358588
  validation accuracy:		90.11 %
Epoch 573 of 2000 took 0.164s
  training loss:		0.128379
  validation loss:		0.366479
  validation accuracy:		90.76 %
Epoch 574 of 2000 took 0.138s
  training loss:		0.125082
  validation loss:		0.363588
  validation accuracy:		91.30 %
Epoch 575 of 2000 took 0.160s
  training loss:		0.128262
  validation loss:		0.355884
  validation accuracy:		90.98 %
Epoch 576 of 2000 took 0.166s
  training loss:		0.126297
  validation loss:		0.375829
  validation accuracy:		90.54 %
Epoch 577 of 2000 took 0.134s
  training loss:		0.135015
  validation loss:		0.380703
  validation accuracy:		89.35 %
Epoch 578 of 2000 took 0.165s
  training loss:		0.131669
  validation loss:		0.354511
  validation accuracy:		91.20 %
Epoch 579 of 2000 took 0.134s
  training loss:		0.130609
  validation loss:		0.361824
  validation accuracy:		90.33 %
Epoch 580 of 2000 took 0.164s
  training loss:		0.129102
  validation loss:		0.373996
  validation accuracy:		90.65 %
Epoch 581 of 2000 took 0.162s
  training loss:		0.128817
  validation loss:		0.405887
  validation accuracy:		90.00 %
Epoch 582 of 2000 took 0.135s
  training loss:		0.133107
  validation loss:		0.368373
  validation accuracy:		90.33 %
Epoch 583 of 2000 took 0.165s
  training loss:		0.128580
  validation loss:		0.368574
  validation accuracy:		91.30 %
Epoch 584 of 2000 took 0.134s
  training loss:		0.134605
  validation loss:		0.383679
  validation accuracy:		90.33 %
Epoch 585 of 2000 took 0.164s
  training loss:		0.127228
  validation loss:		0.349518
  validation accuracy:		91.41 %
Epoch 586 of 2000 took 0.161s
  training loss:		0.127627
  validation loss:		0.354303
  validation accuracy:		91.20 %
Epoch 587 of 2000 took 0.139s
  training loss:		0.125034
  validation loss:		0.376528
  validation accuracy:		90.11 %
Epoch 588 of 2000 took 0.165s
  training loss:		0.128078
  validation loss:		0.366432
  validation accuracy:		91.20 %
Epoch 589 of 2000 took 0.134s
  training loss:		0.120589
  validation loss:		0.362137
  validation accuracy:		90.65 %
Epoch 590 of 2000 took 0.164s
  training loss:		0.125654
  validation loss:		0.371271
  validation accuracy:		90.54 %
Epoch 591 of 2000 took 0.158s
  training loss:		0.125401
  validation loss:		0.356626
  validation accuracy:		91.30 %
Epoch 592 of 2000 took 0.142s
  training loss:		0.125187
  validation loss:		0.376811
  validation accuracy:		90.11 %
Epoch 593 of 2000 took 0.165s
  training loss:		0.125232
  validation loss:		0.369494
  validation accuracy:		91.20 %
Epoch 594 of 2000 took 0.133s
  training loss:		0.126283
  validation loss:		0.370934
  validation accuracy:		90.87 %
Epoch 595 of 2000 took 0.164s
  training loss:		0.122528
  validation loss:		0.369354
  validation accuracy:		91.30 %
Epoch 596 of 2000 took 0.155s
  training loss:		0.126701
  validation loss:		0.376735
  validation accuracy:		90.00 %
Epoch 597 of 2000 took 0.144s
  training loss:		0.120161
  validation loss:		0.366715
  validation accuracy:		90.43 %
Epoch 598 of 2000 took 0.165s
  training loss:		0.128830
  validation loss:		0.366141
  validation accuracy:		90.76 %
Epoch 599 of 2000 took 0.134s
  training loss:		0.126225
  validation loss:		0.372806
  validation accuracy:		90.98 %
Epoch 600 of 2000 took 0.164s
  training loss:		0.131705
  validation loss:		0.363740
  validation accuracy:		91.20 %
Epoch 601 of 2000 took 0.152s
  training loss:		0.125417
  validation loss:		0.363735
  validation accuracy:		91.09 %
Epoch 602 of 2000 took 0.147s
  training loss:		0.126257
  validation loss:		0.383096
  validation accuracy:		90.43 %
Epoch 603 of 2000 took 0.165s
  training loss:		0.123055
  validation loss:		0.366633
  validation accuracy:		90.76 %
Epoch 604 of 2000 took 0.133s
  training loss:		0.131636
  validation loss:		0.375566
  validation accuracy:		90.00 %
Epoch 605 of 2000 took 0.164s
  training loss:		0.123420
  validation loss:		0.368333
  validation accuracy:		91.20 %
Epoch 606 of 2000 took 0.149s
  training loss:		0.119427
  validation loss:		0.368820
  validation accuracy:		91.30 %
Epoch 607 of 2000 took 0.151s
  training loss:		0.124753
  validation loss:		0.372525
  validation accuracy:		90.98 %
Epoch 608 of 2000 took 0.165s
  training loss:		0.121365
  validation loss:		0.366425
  validation accuracy:		91.20 %
Epoch 609 of 2000 took 0.134s
  training loss:		0.122154
  validation loss:		0.371963
  validation accuracy:		90.98 %
Epoch 610 of 2000 took 0.164s
  training loss:		0.127168
  validation loss:		0.369265
  validation accuracy:		90.54 %
Epoch 611 of 2000 took 0.148s
  training loss:		0.125233
  validation loss:		0.369803
  validation accuracy:		90.65 %
Epoch 612 of 2000 took 0.151s
  training loss:		0.115782
  validation loss:		0.376146
  validation accuracy:		91.20 %
Epoch 613 of 2000 took 0.165s
  training loss:		0.124501
  validation loss:		0.372033
  validation accuracy:		90.33 %
Epoch 614 of 2000 took 0.134s
  training loss:		0.129829
  validation loss:		0.388870
  validation accuracy:		90.11 %
Epoch 615 of 2000 took 0.164s
  training loss:		0.119857
  validation loss:		0.384022
  validation accuracy:		91.20 %
Epoch 616 of 2000 took 0.144s
  training loss:		0.120954
  validation loss:		0.382471
  validation accuracy:		90.65 %
Epoch 617 of 2000 took 0.155s
  training loss:		0.121265
  validation loss:		0.373665
  validation accuracy:		91.30 %
Epoch 618 of 2000 took 0.165s
  training loss:		0.119978
  validation loss:		0.384122
  validation accuracy:		90.00 %
Epoch 619 of 2000 took 0.134s
  training loss:		0.124274
  validation loss:		0.392262
  validation accuracy:		90.22 %
Epoch 620 of 2000 took 0.164s
  training loss:		0.119788
  validation loss:		0.390560
  validation accuracy:		90.76 %
Epoch 621 of 2000 took 0.140s
  training loss:		0.122982
  validation loss:		0.383196
  validation accuracy:		90.98 %
Epoch 622 of 2000 took 0.159s
  training loss:		0.121175
  validation loss:		0.374151
  validation accuracy:		91.20 %
Epoch 623 of 2000 took 0.165s
  training loss:		0.121798
  validation loss:		0.381405
  validation accuracy:		90.00 %
Epoch 624 of 2000 took 0.133s
  training loss:		0.118573
  validation loss:		0.378041
  validation accuracy:		90.54 %
Epoch 625 of 2000 took 0.165s
  training loss:		0.117548
  validation loss:		0.398433
  validation accuracy:		90.00 %
Epoch 626 of 2000 took 0.136s
  training loss:		0.121124
  validation loss:		0.372617
  validation accuracy:		90.65 %
Epoch 627 of 2000 took 0.163s
  training loss:		0.118195
  validation loss:		0.371638
  validation accuracy:		90.98 %
Epoch 628 of 2000 took 0.163s
  training loss:		0.121994
  validation loss:		0.404746
  validation accuracy:		90.54 %
Epoch 629 of 2000 took 0.136s
  training loss:		0.119718
  validation loss:		0.381935
  validation accuracy:		90.87 %
Epoch 630 of 2000 took 0.165s
  training loss:		0.123658
  validation loss:		0.374698
  validation accuracy:		90.54 %
Epoch 631 of 2000 took 0.135s
  training loss:		0.123601
  validation loss:		0.381812
  validation accuracy:		90.22 %
Epoch 632 of 2000 took 0.164s
  training loss:		0.122229
  validation loss:		0.376937
  validation accuracy:		91.30 %
Epoch 633 of 2000 took 0.159s
  training loss:		0.119648
  validation loss:		0.399624
  validation accuracy:		90.11 %
Epoch 634 of 2000 took 0.141s
  training loss:		0.123642
  validation loss:		0.380411
  validation accuracy:		91.09 %
Epoch 635 of 2000 took 0.165s
  training loss:		0.118735
  validation loss:		0.379904
  validation accuracy:		90.00 %
Epoch 636 of 2000 took 0.134s
  training loss:		0.118188
  validation loss:		0.376960
  validation accuracy:		91.20 %
Epoch 637 of 2000 took 0.164s
  training loss:		0.117724
  validation loss:		0.396559
  validation accuracy:		89.78 %
Epoch 638 of 2000 took 0.155s
  training loss:		0.123586
  validation loss:		0.373061
  validation accuracy:		90.65 %
Epoch 639 of 2000 took 0.144s
  training loss:		0.114933
  validation loss:		0.391773
  validation accuracy:		90.00 %
Epoch 640 of 2000 took 0.165s
  training loss:		0.123957
  validation loss:		0.381366
  validation accuracy:		90.22 %
Epoch 641 of 2000 took 0.134s
  training loss:		0.118054
  validation loss:		0.388263
  validation accuracy:		91.09 %
Epoch 642 of 2000 took 0.164s
  training loss:		0.115927
  validation loss:		0.376685
  validation accuracy:		90.87 %
Epoch 643 of 2000 took 0.151s
  training loss:		0.116421
  validation loss:		0.401409
  validation accuracy:		90.11 %
Epoch 644 of 2000 took 0.148s
  training loss:		0.116885
  validation loss:		0.398635
  validation accuracy:		89.67 %
Epoch 645 of 2000 took 0.165s
  training loss:		0.118850
  validation loss:		0.397328
  validation accuracy:		90.76 %
Epoch 646 of 2000 took 0.135s
  training loss:		0.118750
  validation loss:		0.380255
  validation accuracy:		91.30 %
Epoch 647 of 2000 took 0.164s
  training loss:		0.114278
  validation loss:		0.385020
  validation accuracy:		90.11 %
Epoch 648 of 2000 took 0.146s
  training loss:		0.114560
  validation loss:		0.406268
  validation accuracy:		90.11 %
Epoch 649 of 2000 took 0.153s
  training loss:		0.118902
  validation loss:		0.394521
  validation accuracy:		89.78 %
Epoch 650 of 2000 took 0.165s
  training loss:		0.117012
  validation loss:		0.391238
  validation accuracy:		90.00 %
Epoch 651 of 2000 took 0.134s
  training loss:		0.117075
  validation loss:		0.388159
  validation accuracy:		91.30 %
Epoch 652 of 2000 took 0.164s
  training loss:		0.115477
  validation loss:		0.376519
  validation accuracy:		91.52 %
Epoch 653 of 2000 took 0.142s
  training loss:		0.111784
  validation loss:		0.396857
  validation accuracy:		90.11 %
Epoch 654 of 2000 took 0.157s
  training loss:		0.124069
  validation loss:		0.393333
  validation accuracy:		90.87 %
Epoch 655 of 2000 took 0.165s
  training loss:		0.116082
  validation loss:		0.381438
  validation accuracy:		91.30 %
Epoch 656 of 2000 took 0.134s
  training loss:		0.108998
  validation loss:		0.378336
  validation accuracy:		91.20 %
Epoch 657 of 2000 took 0.164s
  training loss:		0.116960
  validation loss:		0.397963
  validation accuracy:		90.76 %
Epoch 658 of 2000 took 0.137s
  training loss:		0.118987
  validation loss:		0.379047
  validation accuracy:		91.20 %
Epoch 659 of 2000 took 0.161s
  training loss:		0.114146
  validation loss:		0.397622
  validation accuracy:		90.76 %
Epoch 660 of 2000 took 0.165s
  training loss:		0.115526
  validation loss:		0.393333
  validation accuracy:		91.20 %
Epoch 661 of 2000 took 0.135s
  training loss:		0.117541
  validation loss:		0.396141
  validation accuracy:		91.30 %
Epoch 662 of 2000 took 0.164s
  training loss:		0.110218
  validation loss:		0.387501
  validation accuracy:		90.76 %
Epoch 663 of 2000 took 0.158s
  training loss:		0.118422
  validation loss:		0.386965
  validation accuracy:		90.76 %
Epoch 664 of 2000 took 0.142s
  training loss:		0.113412
  validation loss:		0.415093
  validation accuracy:		90.22 %
Epoch 665 of 2000 took 0.165s
  training loss:		0.110030
  validation loss:		0.396167
  validation accuracy:		90.87 %
Epoch 666 of 2000 took 0.134s
  training loss:		0.113828
  validation loss:		0.403646
  validation accuracy:		91.09 %
Epoch 667 of 2000 took 0.164s
  training loss:		0.116411
  validation loss:		0.418480
  validation accuracy:		90.33 %
Epoch 668 of 2000 took 0.154s
  training loss:		0.116355
  validation loss:		0.415792
  validation accuracy:		90.33 %
Epoch 669 of 2000 took 0.146s
  training loss:		0.115423
  validation loss:		0.384687
  validation accuracy:		90.65 %
Epoch 670 of 2000 took 0.165s
  training loss:		0.108002
  validation loss:		0.407511
  validation accuracy:		90.43 %
Epoch 671 of 2000 took 0.134s
  training loss:		0.113985
  validation loss:		0.396664
  validation accuracy:		91.09 %
Epoch 672 of 2000 took 0.164s
  training loss:		0.114469
  validation loss:		0.399580
  validation accuracy:		91.09 %
Epoch 673 of 2000 took 0.150s
  training loss:		0.117191
  validation loss:		0.420464
  validation accuracy:		89.89 %
Epoch 674 of 2000 took 0.149s
  training loss:		0.115559
  validation loss:		0.407017
  validation accuracy:		90.76 %
Epoch 675 of 2000 took 0.165s
  training loss:		0.113338
  validation loss:		0.397261
  validation accuracy:		90.65 %
Epoch 676 of 2000 took 0.134s
  training loss:		0.122906
  validation loss:		0.389585
  validation accuracy:		91.52 %
Epoch 677 of 2000 took 0.164s
  training loss:		0.109877
  validation loss:		0.405448
  validation accuracy:		90.43 %
Epoch 678 of 2000 took 0.146s
  training loss:		0.113233
  validation loss:		0.399377
  validation accuracy:		90.33 %
Epoch 679 of 2000 took 0.153s
  training loss:		0.118193
  validation loss:		0.400833
  validation accuracy:		91.20 %
Epoch 680 of 2000 took 0.165s
  training loss:		0.116553
  validation loss:		0.425982
  validation accuracy:		89.78 %
Epoch 681 of 2000 took 0.134s
  training loss:		0.116582
  validation loss:		0.404228
  validation accuracy:		90.87 %
Epoch 682 of 2000 took 0.164s
  training loss:		0.118992
  validation loss:		0.395201
  validation accuracy:		90.43 %
Epoch 683 of 2000 took 0.142s
  training loss:		0.115252
  validation loss:		0.408446
  validation accuracy:		90.43 %
Epoch 684 of 2000 took 0.157s
  training loss:		0.116099
  validation loss:		0.393137
  validation accuracy:		90.54 %
Epoch 685 of 2000 took 0.165s
  training loss:		0.115634
  validation loss:		0.422741
  validation accuracy:		90.00 %
Epoch 686 of 2000 took 0.134s
  training loss:		0.109761
  validation loss:		0.397895
  validation accuracy:		91.41 %
Epoch 687 of 2000 took 0.165s
  training loss:		0.111049
  validation loss:		0.405483
  validation accuracy:		90.65 %
Epoch 688 of 2000 took 0.136s
  training loss:		0.111774
  validation loss:		0.424998
  validation accuracy:		90.54 %
Epoch 689 of 2000 took 0.161s
  training loss:		0.113599
  validation loss:		0.407382
  validation accuracy:		90.33 %
Epoch 690 of 2000 took 0.164s
  training loss:		0.115945
  validation loss:		0.413123
  validation accuracy:		90.76 %
Epoch 691 of 2000 took 0.136s
  training loss:		0.116088
  validation loss:		0.404832
  validation accuracy:		90.54 %
Epoch 692 of 2000 took 0.165s
  training loss:		0.113056
  validation loss:		0.405099
  validation accuracy:		90.65 %
Epoch 693 of 2000 took 0.134s
  training loss:		0.111663
  validation loss:		0.426749
  validation accuracy:		90.43 %
Epoch 694 of 2000 took 0.164s
  training loss:		0.113029
  validation loss:		0.405475
  validation accuracy:		90.33 %
Epoch 695 of 2000 took 0.160s
  training loss:		0.112406
  validation loss:		0.389502
  validation accuracy:		91.30 %
Epoch 696 of 2000 took 0.140s
  training loss:		0.110385
  validation loss:		0.396124
  validation accuracy:		91.30 %
Epoch 697 of 2000 took 0.165s
  training loss:		0.116328
  validation loss:		0.407582
  validation accuracy:		90.76 %
Epoch 698 of 2000 took 0.134s
  training loss:		0.108904
  validation loss:		0.395697
  validation accuracy:		90.98 %
Epoch 699 of 2000 took 0.164s
  training loss:		0.112801
  validation loss:		0.466585
  validation accuracy:		89.89 %
Epoch 700 of 2000 took 0.156s
  training loss:		0.113232
  validation loss:		0.408275
  validation accuracy:		91.41 %
Epoch 701 of 2000 took 0.144s
  training loss:		0.116262
  validation loss:		0.407180
  validation accuracy:		91.41 %
Epoch 702 of 2000 took 0.165s
  training loss:		0.115155
  validation loss:		0.432608
  validation accuracy:		90.33 %
Epoch 703 of 2000 took 0.134s
  training loss:		0.111165
  validation loss:		0.442149
  validation accuracy:		90.65 %
Epoch 704 of 2000 took 0.164s
  training loss:		0.109185
  validation loss:		0.425048
  validation accuracy:		90.33 %
Epoch 705 of 2000 took 0.151s
  training loss:		0.108206
  validation loss:		0.401385
  validation accuracy:		90.76 %
Epoch 706 of 2000 took 0.148s
  training loss:		0.100777
  validation loss:		0.402424
  validation accuracy:		91.20 %
Epoch 707 of 2000 took 0.165s
  training loss:		0.107821
  validation loss:		0.429730
  validation accuracy:		91.09 %
Epoch 708 of 2000 took 0.134s
  training loss:		0.117247
  validation loss:		0.394896
  validation accuracy:		91.63 %
Epoch 709 of 2000 took 0.164s
  training loss:		0.108340
  validation loss:		0.414034
  validation accuracy:		91.09 %
Epoch 710 of 2000 took 0.147s
  training loss:		0.116620
  validation loss:		0.415982
  validation accuracy:		90.22 %
Epoch 711 of 2000 took 0.152s
  training loss:		0.109873
  validation loss:		0.425987
  validation accuracy:		90.43 %
Epoch 712 of 2000 took 0.165s
  training loss:		0.113325
  validation loss:		0.409036
  validation accuracy:		90.65 %
Epoch 713 of 2000 took 0.134s
  training loss:		0.113244
  validation loss:		0.423709
  validation accuracy:		90.65 %
Epoch 714 of 2000 took 0.164s
  training loss:		0.112341
  validation loss:		0.431683
  validation accuracy:		90.87 %
Epoch 715 of 2000 took 0.143s
  training loss:		0.110462
  validation loss:		0.446411
  validation accuracy:		90.33 %
Epoch 716 of 2000 took 0.156s
  training loss:		0.108777
  validation loss:		0.404441
  validation accuracy:		91.09 %
Epoch 717 of 2000 took 0.165s
  training loss:		0.103852
  validation loss:		0.418912
  validation accuracy:		90.11 %
Epoch 718 of 2000 took 0.133s
  training loss:		0.111208
  validation loss:		0.419642
  validation accuracy:		90.98 %
Epoch 719 of 2000 took 0.164s
  training loss:		0.111948
  validation loss:		0.417218
  validation accuracy:		91.09 %
Epoch 720 of 2000 took 0.139s
  training loss:		0.111194
  validation loss:		0.430722
  validation accuracy:		89.57 %
Epoch 721 of 2000 took 0.160s
  training loss:		0.108551
  validation loss:		0.423206
  validation accuracy:		90.54 %
Epoch 722 of 2000 took 0.166s
  training loss:		0.108428
  validation loss:		0.418119
  validation accuracy:		90.43 %
Epoch 723 of 2000 took 0.134s
  training loss:		0.110074
  validation loss:		0.410379
  validation accuracy:		91.30 %
Epoch 724 of 2000 took 0.165s
  training loss:		0.113080
  validation loss:		0.414279
  validation accuracy:		91.09 %
Epoch 725 of 2000 took 0.136s
  training loss:		0.105685
  validation loss:		0.422935
  validation accuracy:		91.09 %
Epoch 726 of 2000 took 0.188s
  training loss:		0.107185
  validation loss:		0.419911
  validation accuracy:		90.11 %
Epoch 727 of 2000 took 0.277s
  training loss:		0.109791
  validation loss:		0.427631
  validation accuracy:		90.98 %
Epoch 728 of 2000 took 0.164s
  training loss:		0.112929
  validation loss:		0.434824
  validation accuracy:		90.54 %
Epoch 729 of 2000 took 0.165s
  training loss:		0.106109
  validation loss:		0.436021
  validation accuracy:		90.87 %
Epoch 730 of 2000 took 0.158s
  training loss:		0.106184
  validation loss:		0.418060
  validation accuracy:		90.76 %
Epoch 731 of 2000 took 0.165s
  training loss:		0.109632
  validation loss:		0.434110
  validation accuracy:		90.22 %
Epoch 732 of 2000 took 0.158s
  training loss:		0.108353
  validation loss:		0.411716
  validation accuracy:		90.65 %
Epoch 733 of 2000 took 0.164s
  training loss:		0.107660
  validation loss:		0.419504
  validation accuracy:		90.98 %
Epoch 734 of 2000 took 0.159s
  training loss:		0.114220
  validation loss:		0.423551
  validation accuracy:		90.98 %
Epoch 735 of 2000 took 0.164s
  training loss:		0.105497
  validation loss:		0.429343
  validation accuracy:		90.65 %
Epoch 736 of 2000 took 0.162s
  training loss:		0.107632
  validation loss:		0.426437
  validation accuracy:		90.76 %
Epoch 737 of 2000 took 0.161s
  training loss:		0.102435
  validation loss:		0.449062
  validation accuracy:		90.54 %
Epoch 738 of 2000 took 0.165s
  training loss:		0.109024
  validation loss:		0.418345
  validation accuracy:		90.54 %
Epoch 739 of 2000 took 0.158s
  training loss:		0.103236
  validation loss:		0.435735
  validation accuracy:		90.33 %
Epoch 740 of 2000 took 0.164s
  training loss:		0.103298
  validation loss:		0.419403
  validation accuracy:		90.76 %
Epoch 741 of 2000 took 0.159s
  training loss:		0.107040
  validation loss:		0.409860
  validation accuracy:		90.65 %
Epoch 742 of 2000 took 0.164s
  training loss:		0.102677
  validation loss:		0.451393
  validation accuracy:		89.67 %
Epoch 743 of 2000 took 0.159s
  training loss:		0.106371
  validation loss:		0.422917
  validation accuracy:		90.65 %
Epoch 744 of 2000 took 0.164s
  training loss:		0.105913
  validation loss:		0.451385
  validation accuracy:		89.57 %
Epoch 745 of 2000 took 0.165s
  training loss:		0.109569
  validation loss:		0.438446
  validation accuracy:		90.54 %
Epoch 746 of 2000 took 0.157s
  training loss:		0.105486
  validation loss:		0.429174
  validation accuracy:		90.98 %
Epoch 747 of 2000 took 0.164s
  training loss:		0.105529
  validation loss:		0.428754
  validation accuracy:		90.87 %
Epoch 748 of 2000 took 0.162s
  training loss:		0.108732
  validation loss:		0.431493
  validation accuracy:		90.98 %
Epoch 749 of 2000 took 0.164s
  training loss:		0.107468
  validation loss:		0.445116
  validation accuracy:		89.89 %
Epoch 750 of 2000 took 0.158s
  training loss:		0.102208
  validation loss:		0.422093
  validation accuracy:		91.20 %
Epoch 751 of 2000 took 0.164s
  training loss:		0.104458
  validation loss:		0.420990
  validation accuracy:		90.43 %
Epoch 752 of 2000 took 0.165s
  training loss:		0.112410
  validation loss:		0.457155
  validation accuracy:		90.76 %
Epoch 753 of 2000 took 0.157s
  training loss:		0.113225
  validation loss:		0.435093
  validation accuracy:		90.65 %
Epoch 754 of 2000 took 0.165s
  training loss:		0.105631
  validation loss:		0.427375
  validation accuracy:		90.76 %
Epoch 755 of 2000 took 0.159s
  training loss:		0.101308
  validation loss:		0.430748
  validation accuracy:		90.54 %
Epoch 756 of 2000 took 0.164s
  training loss:		0.098093
  validation loss:		0.428631
  validation accuracy:		90.87 %
Epoch 757 of 2000 took 0.159s
  training loss:		0.115804
  validation loss:		0.423801
  validation accuracy:		90.43 %
Epoch 758 of 2000 took 0.164s
  training loss:		0.103565
  validation loss:		0.429586
  validation accuracy:		90.22 %
Epoch 759 of 2000 took 0.165s
  training loss:		0.101021
  validation loss:		0.428661
  validation accuracy:		90.43 %
Epoch 760 of 2000 took 0.157s
  training loss:		0.115012
  validation loss:		0.454731
  validation accuracy:		90.76 %
Epoch 761 of 2000 took 0.165s
  training loss:		0.107382
  validation loss:		0.449896
  validation accuracy:		90.54 %
Epoch 762 of 2000 took 0.158s
  training loss:		0.109086
  validation loss:		0.462181
  validation accuracy:		89.46 %
Epoch 763 of 2000 took 0.164s
  training loss:		0.101823
  validation loss:		0.429073
  validation accuracy:		90.65 %
Epoch 764 of 2000 took 0.167s
  training loss:		0.097607
  validation loss:		0.435735
  validation accuracy:		90.98 %
Epoch 765 of 2000 took 0.164s
  training loss:		0.103292
  validation loss:		0.434336
  validation accuracy:		91.20 %
Epoch 766 of 2000 took 0.165s
  training loss:		0.099574
  validation loss:		0.449852
  validation accuracy:		89.89 %
Epoch 767 of 2000 took 0.158s
  training loss:		0.104805
  validation loss:		0.457326
  validation accuracy:		90.11 %
Epoch 768 of 2000 took 0.165s
  training loss:		0.111592
  validation loss:		0.449638
  validation accuracy:		89.89 %
Epoch 769 of 2000 took 0.158s
  training loss:		0.103410
  validation loss:		0.444674
  validation accuracy:		90.87 %
Epoch 770 of 2000 took 0.164s
  training loss:		0.107722
  validation loss:		0.438251
  validation accuracy:		90.87 %
Epoch 771 of 2000 took 0.159s
  training loss:		0.100655
  validation loss:		0.448822
  validation accuracy:		90.87 %
Epoch 772 of 2000 took 0.164s
  training loss:		0.112720
  validation loss:		0.429531
  validation accuracy:		90.43 %
Epoch 773 of 2000 took 0.164s
  training loss:		0.106060
  validation loss:		0.445643
  validation accuracy:		89.89 %
Epoch 774 of 2000 took 0.159s
  training loss:		0.102939
  validation loss:		0.446430
  validation accuracy:		90.43 %
Epoch 775 of 2000 took 0.165s
  training loss:		0.101667
  validation loss:		0.438961
  validation accuracy:		90.76 %
Epoch 776 of 2000 took 0.158s
  training loss:		0.110257
  validation loss:		0.528230
  validation accuracy:		89.02 %
Epoch 777 of 2000 took 0.164s
  training loss:		0.109142
  validation loss:		0.456506
  validation accuracy:		90.11 %
Epoch 778 of 2000 took 0.159s
  training loss:		0.108145
  validation loss:		0.438517
  validation accuracy:		90.76 %
Epoch 779 of 2000 took 0.164s
  training loss:		0.105340
  validation loss:		0.432489
  validation accuracy:		90.22 %
Epoch 780 of 2000 took 0.161s
  training loss:		0.100899
  validation loss:		0.452986
  validation accuracy:		90.98 %
Epoch 781 of 2000 took 0.163s
  training loss:		0.101445
  validation loss:		0.467835
  validation accuracy:		90.65 %
Epoch 782 of 2000 took 0.165s
  training loss:		0.106498
  validation loss:		0.455107
  validation accuracy:		90.54 %
Epoch 783 of 2000 took 0.158s
  training loss:		0.103974
  validation loss:		0.455987
  validation accuracy:		91.09 %
Epoch 784 of 2000 took 0.164s
  training loss:		0.103364
  validation loss:		0.448079
  validation accuracy:		90.11 %
Epoch 785 of 2000 took 0.159s
  training loss:		0.098819
  validation loss:		0.450486
  validation accuracy:		90.54 %
Epoch 786 of 2000 took 0.164s
  training loss:		0.100136
  validation loss:		0.444065
  validation accuracy:		90.98 %
Epoch 787 of 2000 took 0.159s
  training loss:		0.099053
  validation loss:		0.458337
  validation accuracy:		90.65 %
Epoch 788 of 2000 took 0.164s
  training loss:		0.106015
  validation loss:		0.436120
  validation accuracy:		90.43 %
Epoch 789 of 2000 took 0.165s
  training loss:		0.102450
  validation loss:		0.463545
  validation accuracy:		90.65 %
Epoch 790 of 2000 took 0.158s
  training loss:		0.101946
  validation loss:		0.484979
  validation accuracy:		89.78 %
Epoch 791 of 2000 took 0.165s
  training loss:		0.106294
  validation loss:		0.451204
  validation accuracy:		90.76 %
Epoch 792 of 2000 took 0.175s
  training loss:		0.103917
  validation loss:		0.441844
  validation accuracy:		90.54 %
Epoch 793 of 2000 took 0.164s
  training loss:		0.103565
  validation loss:		0.457742
  validation accuracy:		90.65 %
Epoch 794 of 2000 took 0.160s
  training loss:		0.099656
  validation loss:		0.435178
  validation accuracy:		90.65 %
Epoch 795 of 2000 took 0.164s
  training loss:		0.103591
  validation loss:		0.448636
  validation accuracy:		90.65 %
Epoch 796 of 2000 took 0.165s
  training loss:		0.110670
  validation loss:		0.478482
  validation accuracy:		90.00 %
Epoch 797 of 2000 took 0.157s
  training loss:		0.102465
  validation loss:		0.460005
  validation accuracy:		90.98 %
Epoch 798 of 2000 took 0.165s
  training loss:		0.103059
  validation loss:		0.453331
  validation accuracy:		90.76 %
Epoch 799 of 2000 took 0.158s
  training loss:		0.102552
  validation loss:		0.455023
  validation accuracy:		90.76 %
Epoch 800 of 2000 took 0.164s
  training loss:		0.102300
  validation loss:		0.450616
  validation accuracy:		90.76 %
Epoch 801 of 2000 took 0.159s
  training loss:		0.102219
  validation loss:		0.458291
  validation accuracy:		90.65 %
Epoch 802 of 2000 took 0.164s
  training loss:		0.098478
  validation loss:		0.472302
  validation accuracy:		89.67 %
Epoch 803 of 2000 took 0.162s
  training loss:		0.103211
  validation loss:		0.470805
  validation accuracy:		90.65 %
Epoch 804 of 2000 took 0.160s
  training loss:		0.099443
  validation loss:		0.481002
  validation accuracy:		90.54 %
Epoch 805 of 2000 took 0.165s
  training loss:		0.098531
  validation loss:		0.470981
  validation accuracy:		89.89 %
Epoch 806 of 2000 took 0.158s
  training loss:		0.104164
  validation loss:		0.461282
  validation accuracy:		90.54 %
Epoch 807 of 2000 took 0.164s
  training loss:		0.100406
  validation loss:		0.471078
  validation accuracy:		90.98 %
Epoch 808 of 2000 took 0.159s
  training loss:		0.103827
  validation loss:		0.458692
  validation accuracy:		90.54 %
Epoch 809 of 2000 took 0.164s
  training loss:		0.100747
  validation loss:		0.460870
  validation accuracy:		90.65 %
Epoch 810 of 2000 took 0.160s
  training loss:		0.097760
  validation loss:		0.464846
  validation accuracy:		90.43 %
Epoch 811 of 2000 took 0.162s
  training loss:		0.094604
  validation loss:		0.461352
  validation accuracy:		90.76 %
Epoch 812 of 2000 took 0.165s
  training loss:		0.098723
  validation loss:		0.466140
  validation accuracy:		90.65 %
Epoch 813 of 2000 took 0.158s
  training loss:		0.101802
  validation loss:		0.457908
  validation accuracy:		90.00 %
Epoch 814 of 2000 took 0.164s
  training loss:		0.099285
  validation loss:		0.464574
  validation accuracy:		90.33 %
Epoch 815 of 2000 took 0.158s
  training loss:		0.098911
  validation loss:		0.485682
  validation accuracy:		90.22 %
Epoch 816 of 2000 took 0.164s
  training loss:		0.103099
  validation loss:		0.475869
  validation accuracy:		90.54 %
Epoch 817 of 2000 took 0.159s
  training loss:		0.101870
  validation loss:		0.474043
  validation accuracy:		90.54 %
Epoch 818 of 2000 took 0.164s
  training loss:		0.099240
  validation loss:		0.458084
  validation accuracy:		90.98 %
Epoch 819 of 2000 took 0.165s
  training loss:		0.096795
  validation loss:		0.492962
  validation accuracy:		90.43 %
Epoch 820 of 2000 took 0.158s
  training loss:		0.095886
  validation loss:		0.466277
  validation accuracy:		90.43 %
Epoch 821 of 2000 took 0.164s
  training loss:		0.097457
  validation loss:		0.470372
  validation accuracy:		90.65 %
Epoch 822 of 2000 took 0.159s
  training loss:		0.095325
  validation loss:		0.487304
  validation accuracy:		90.22 %
Epoch 823 of 2000 took 0.164s
  training loss:		0.096802
  validation loss:		0.469592
  validation accuracy:		90.76 %
Epoch 824 of 2000 took 0.158s
  training loss:		0.101561
  validation loss:		0.467273
  validation accuracy:		90.98 %
Epoch 825 of 2000 took 0.164s
  training loss:		0.098671
  validation loss:		0.457824
  validation accuracy:		91.30 %
Epoch 826 of 2000 took 0.165s
  training loss:		0.105768
  validation loss:		0.466072
  validation accuracy:		90.98 %
Epoch 827 of 2000 took 0.158s
  training loss:		0.092962
  validation loss:		0.467719
  validation accuracy:		90.76 %
Epoch 828 of 2000 took 0.164s
  training loss:		0.097114
  validation loss:		0.474753
  validation accuracy:		90.33 %
Epoch 829 of 2000 took 0.161s
  training loss:		0.096352
  validation loss:		0.492065
  validation accuracy:		90.43 %
Epoch 830 of 2000 took 0.164s
  training loss:		0.102010
  validation loss:		0.544722
  validation accuracy:		89.67 %
Epoch 831 of 2000 took 0.170s
  training loss:		0.100591
  validation loss:		0.460634
  validation accuracy:		90.65 %
Epoch 832 of 2000 took 0.163s
  training loss:		0.096064
  validation loss:		0.475039
  validation accuracy:		90.54 %
Epoch 833 of 2000 took 0.163s
  training loss:		0.099104
  validation loss:		0.471367
  validation accuracy:		90.33 %
Epoch 834 of 2000 took 0.161s
  training loss:		0.092697
  validation loss:		0.461283
  validation accuracy:		90.22 %
Epoch 835 of 2000 took 0.164s
  training loss:		0.098970
  validation loss:		0.485907
  validation accuracy:		90.33 %
Epoch 836 of 2000 took 0.161s
  training loss:		0.096968
  validation loss:		0.484475
  validation accuracy:		90.54 %
Epoch 837 of 2000 took 0.164s
  training loss:		0.097165
  validation loss:		0.461525
  validation accuracy:		90.87 %
Epoch 838 of 2000 took 0.160s
  training loss:		0.098200
  validation loss:		0.480038
  validation accuracy:		90.54 %
Epoch 839 of 2000 took 0.164s
  training loss:		0.099289
  validation loss:		0.490162
  validation accuracy:		90.22 %
Epoch 840 of 2000 took 0.162s
  training loss:		0.098641
  validation loss:		0.463037
  validation accuracy:		90.98 %
Epoch 841 of 2000 took 0.163s
  training loss:		0.100165
  validation loss:		0.467847
  validation accuracy:		90.11 %
Epoch 842 of 2000 took 0.164s
  training loss:		0.096538
  validation loss:		0.487288
  validation accuracy:		90.33 %
Epoch 843 of 2000 took 0.161s
  training loss:		0.096155
  validation loss:		0.474512
  validation accuracy:		90.11 %
Epoch 844 of 2000 took 0.164s
  training loss:		0.107053
  validation loss:		0.472113
  validation accuracy:		90.33 %
Epoch 845 of 2000 took 0.161s
  training loss:		0.104536
  validation loss:		0.465911
  validation accuracy:		90.87 %
Epoch 846 of 2000 took 0.164s
  training loss:		0.101172
  validation loss:		0.479655
  validation accuracy:		90.33 %
Epoch 847 of 2000 took 0.161s
  training loss:		0.098245
  validation loss:		0.501950
  validation accuracy:		90.22 %
Epoch 848 of 2000 took 0.163s
  training loss:		0.093298
  validation loss:		0.528945
  validation accuracy:		89.24 %
Epoch 849 of 2000 took 0.163s
  training loss:		0.095548
  validation loss:		0.474936
  validation accuracy:		90.76 %
Epoch 850 of 2000 took 0.161s
  training loss:		0.099999
  validation loss:		0.470595
  validation accuracy:		90.76 %
Epoch 851 of 2000 took 0.164s
  training loss:		0.095469
  validation loss:		0.480414
  validation accuracy:		90.76 %
Epoch 852 of 2000 took 0.161s
  training loss:		0.094830
  validation loss:		0.483705
  validation accuracy:		90.22 %
Epoch 853 of 2000 took 0.164s
  training loss:		0.092121
  validation loss:		0.489715
  validation accuracy:		90.00 %
Epoch 854 of 2000 took 0.161s
  training loss:		0.096200
  validation loss:		0.481341
  validation accuracy:		89.89 %
Epoch 855 of 2000 took 0.164s
  training loss:		0.097520
  validation loss:		0.493575
  validation accuracy:		90.43 %
Epoch 856 of 2000 took 0.164s
  training loss:		0.095355
  validation loss:		0.475186
  validation accuracy:		90.00 %
Epoch 857 of 2000 took 0.161s
  training loss:		0.101325
  validation loss:		0.504071
  validation accuracy:		90.65 %
Epoch 858 of 2000 took 0.164s
  training loss:		0.100229
  validation loss:		0.506016
  validation accuracy:		90.43 %
Epoch 859 of 2000 took 0.169s
  training loss:		0.089812
  validation loss:		0.484805
  validation accuracy:		90.65 %
Epoch 860 of 2000 took 0.164s
  training loss:		0.094215
  validation loss:		0.496901
  validation accuracy:		90.65 %
Epoch 861 of 2000 took 0.161s
  training loss:		0.095624
  validation loss:		0.478960
  validation accuracy:		90.43 %
Epoch 862 of 2000 took 0.164s
  training loss:		0.102404
  validation loss:		0.529535
  validation accuracy:		90.11 %
Epoch 863 of 2000 took 0.161s
  training loss:		0.101970
  validation loss:		0.483767
  validation accuracy:		90.22 %
Epoch 864 of 2000 took 0.163s
  training loss:		0.097482
  validation loss:		0.493645
  validation accuracy:		90.54 %
Epoch 865 of 2000 took 0.164s
  training loss:		0.091616
  validation loss:		0.488902
  validation accuracy:		90.54 %
Epoch 866 of 2000 took 0.161s
  training loss:		0.094457
  validation loss:		0.501861
  validation accuracy:		90.76 %
Epoch 867 of 2000 took 0.164s
  training loss:		0.089856
  validation loss:		0.488966
  validation accuracy:		90.98 %
Epoch 868 of 2000 took 0.161s
  training loss:		0.107285
  validation loss:		0.516141
  validation accuracy:		90.11 %
Epoch 869 of 2000 took 0.164s
  training loss:		0.095306
  validation loss:		0.494229
  validation accuracy:		90.87 %
Epoch 870 of 2000 took 0.161s
  training loss:		0.116769
  validation loss:		0.522150
  validation accuracy:		89.78 %
Epoch 871 of 2000 took 0.163s
  training loss:		0.090723
  validation loss:		0.513511
  validation accuracy:		90.54 %
Epoch 872 of 2000 took 0.162s
  training loss:		0.093778
  validation loss:		0.504105
  validation accuracy:		90.65 %
Epoch 873 of 2000 took 0.163s
  training loss:		0.095591
  validation loss:		0.491513
  validation accuracy:		90.54 %
Epoch 874 of 2000 took 0.164s
  training loss:		0.096339
  validation loss:		0.488371
  validation accuracy:		90.87 %
Epoch 875 of 2000 took 0.161s
  training loss:		0.103623
  validation loss:		0.507583
  validation accuracy:		89.46 %
Epoch 876 of 2000 took 0.164s
  training loss:		0.102499
  validation loss:		0.508332
  validation accuracy:		90.33 %
Epoch 877 of 2000 took 0.161s
  training loss:		0.093344
  validation loss:		0.483947
  validation accuracy:		90.87 %
Epoch 878 of 2000 took 0.164s
  training loss:		0.097657
  validation loss:		0.493609
  validation accuracy:		90.76 %
Epoch 879 of 2000 took 0.161s
  training loss:		0.092901
  validation loss:		0.492126
  validation accuracy:		90.00 %
Epoch 880 of 2000 took 0.163s
  training loss:		0.093116
  validation loss:		0.510601
  validation accuracy:		89.67 %
Epoch 881 of 2000 took 0.164s
  training loss:		0.092724
  validation loss:		0.498764
  validation accuracy:		90.98 %
Epoch 882 of 2000 took 0.161s
  training loss:		0.096239
  validation loss:		0.503478
  validation accuracy:		90.54 %
Epoch 883 of 2000 took 0.164s
  training loss:		0.094660
  validation loss:		0.488982
  validation accuracy:		90.54 %
Epoch 884 of 2000 took 0.161s
  training loss:		0.092116
  validation loss:		0.529520
  validation accuracy:		89.57 %
Epoch 885 of 2000 took 0.164s
  training loss:		0.101602
  validation loss:		0.502917
  validation accuracy:		89.67 %
Epoch 886 of 2000 took 0.161s
  training loss:		0.091631
  validation loss:		0.537684
  validation accuracy:		89.78 %
Epoch 887 of 2000 took 0.163s
  training loss:		0.094185
  validation loss:		0.568529
  validation accuracy:		90.33 %
Epoch 888 of 2000 took 0.163s
  training loss:		0.099175
  validation loss:		0.508131
  validation accuracy:		90.11 %
Epoch 889 of 2000 took 0.161s
  training loss:		0.093445
  validation loss:		0.494415
  validation accuracy:		89.89 %
Epoch 890 of 2000 took 0.164s
  training loss:		0.099248
  validation loss:		0.506828
  validation accuracy:		90.33 %
Epoch 891 of 2000 took 0.161s
  training loss:		0.098164
  validation loss:		0.508644
  validation accuracy:		89.89 %
Epoch 892 of 2000 took 0.163s
  training loss:		0.094017
  validation loss:		0.516286
  validation accuracy:		90.33 %
Epoch 893 of 2000 took 0.164s
  training loss:		0.089171
  validation loss:		0.508419
  validation accuracy:		90.43 %
Epoch 894 of 2000 took 0.161s
  training loss:		0.090908
  validation loss:		0.518643
  validation accuracy:		90.76 %
Epoch 895 of 2000 took 0.164s
  training loss:		0.086363
  validation loss:		0.492067
  validation accuracy:		90.33 %
Epoch 896 of 2000 took 0.161s
  training loss:		0.093750
  validation loss:		0.540152
  validation accuracy:		89.78 %
Epoch 897 of 2000 took 0.163s
  training loss:		0.096447
  validation loss:		0.525525
  validation accuracy:		90.11 %
Epoch 898 of 2000 took 0.162s
  training loss:		0.095585
  validation loss:		0.521479
  validation accuracy:		89.78 %
Epoch 899 of 2000 took 0.162s
  training loss:		0.090553
  validation loss:		0.508687
  validation accuracy:		89.67 %
Epoch 900 of 2000 took 0.164s
  training loss:		0.120720
  validation loss:		0.496399
  validation accuracy:		90.54 %
Epoch 901 of 2000 took 0.161s
  training loss:		0.092808
  validation loss:		0.525955
  validation accuracy:		90.11 %
Epoch 902 of 2000 took 0.164s
  training loss:		0.095029
  validation loss:		0.488860
  validation accuracy:		91.09 %
Epoch 903 of 2000 took 0.161s
  training loss:		0.097882
  validation loss:		0.491271
  validation accuracy:		90.76 %
Epoch 904 of 2000 took 0.164s
  training loss:		0.092848
  validation loss:		0.526497
  validation accuracy:		89.89 %
Epoch 905 of 2000 took 0.162s
  training loss:		0.086159
  validation loss:		0.525998
  validation accuracy:		90.54 %
Epoch 906 of 2000 took 0.163s
  training loss:		0.098201
  validation loss:		0.511194
  validation accuracy:		90.54 %
Epoch 907 of 2000 took 0.164s
  training loss:		0.094163
  validation loss:		0.512010
  validation accuracy:		90.87 %
Epoch 908 of 2000 took 0.161s
  training loss:		0.090848
  validation loss:		0.517859
  validation accuracy:		90.00 %
Epoch 909 of 2000 took 0.164s
  training loss:		0.097474
  validation loss:		0.532138
  validation accuracy:		90.22 %
Epoch 910 of 2000 took 0.169s
  training loss:		0.097984
  validation loss:		0.517739
  validation accuracy:		89.46 %
Epoch 911 of 2000 took 0.164s
  training loss:		0.093337
  validation loss:		0.534121
  validation accuracy:		90.11 %
Epoch 912 of 2000 took 0.161s
  training loss:		0.091574
  validation loss:		0.540099
  validation accuracy:		90.11 %
Epoch 913 of 2000 took 0.163s
  training loss:		0.087630
  validation loss:		0.519512
  validation accuracy:		90.43 %
Epoch 914 of 2000 took 0.162s
  training loss:		0.097052
  validation loss:		0.494830
  validation accuracy:		91.30 %
Epoch 915 of 2000 took 0.162s
  training loss:		0.091274
  validation loss:		0.519030
  validation accuracy:		90.22 %
Epoch 916 of 2000 took 0.164s
  training loss:		0.094893
  validation loss:		0.504184
  validation accuracy:		90.43 %
Epoch 917 of 2000 took 0.161s
  training loss:		0.091277
  validation loss:		0.519180
  validation accuracy:		90.00 %
Epoch 918 of 2000 took 0.164s
  training loss:		0.090716
  validation loss:		0.522286
  validation accuracy:		90.43 %
Epoch 919 of 2000 took 0.161s
  training loss:		0.099089
  validation loss:		0.505096
  validation accuracy:		90.87 %
Epoch 920 of 2000 took 0.164s
  training loss:		0.093936
  validation loss:		0.539187
  validation accuracy:		90.00 %
Epoch 921 of 2000 took 0.161s
  training loss:		0.088988
  validation loss:		0.540283
  validation accuracy:		90.33 %
Epoch 922 of 2000 took 0.163s
  training loss:		0.093591
  validation loss:		0.519943
  validation accuracy:		90.00 %
Epoch 923 of 2000 took 0.164s
  training loss:		0.094067
  validation loss:		0.508626
  validation accuracy:		90.43 %
Epoch 924 of 2000 took 0.161s
  training loss:		0.095797
  validation loss:		0.544456
  validation accuracy:		89.78 %
Epoch 925 of 2000 took 0.164s
  training loss:		0.082797
  validation loss:		0.512311
  validation accuracy:		90.76 %
Epoch 926 of 2000 took 0.161s
  training loss:		0.087780
  validation loss:		0.569328
  validation accuracy:		89.67 %
Epoch 927 of 2000 took 0.164s
  training loss:		0.091395
  validation loss:		0.532419
  validation accuracy:		90.11 %
Epoch 928 of 2000 took 0.161s
  training loss:		0.088651
  validation loss:		0.524932
  validation accuracy:		90.76 %
Epoch 929 of 2000 took 0.163s
  training loss:		0.090657
  validation loss:		0.536472
  validation accuracy:		89.78 %
Epoch 930 of 2000 took 0.164s
  training loss:		0.086831
  validation loss:		0.528290
  validation accuracy:		90.00 %
Epoch 931 of 2000 took 0.161s
  training loss:		0.120598
  validation loss:		0.529117
  validation accuracy:		90.33 %
Epoch 932 of 2000 took 0.164s
  training loss:		0.089307
  validation loss:		0.531348
  validation accuracy:		90.43 %
Epoch 933 of 2000 took 0.161s
  training loss:		0.089554
  validation loss:		0.535261
  validation accuracy:		90.22 %
Epoch 934 of 2000 took 0.164s
  training loss:		0.094087
  validation loss:		0.550204
  validation accuracy:		90.22 %
Epoch 935 of 2000 took 0.161s
  training loss:		0.094568
  validation loss:		0.526240
  validation accuracy:		91.09 %
Epoch 936 of 2000 took 0.164s
  training loss:		0.090550
  validation loss:		0.523430
  validation accuracy:		90.33 %
Epoch 937 of 2000 took 0.157s
  training loss:		0.090841
  validation loss:		0.520984
  validation accuracy:		90.54 %
Epoch 938 of 2000 took 0.145s
  training loss:		0.088053
  validation loss:		0.519628
  validation accuracy:		90.87 %
Epoch 939 of 2000 took 0.164s
  training loss:		0.084943
  validation loss:		0.536349
  validation accuracy:		90.33 %
Epoch 940 of 2000 took 0.136s
  training loss:		0.093512
  validation loss:		0.518205
  validation accuracy:		90.22 %
Epoch 941 of 2000 took 0.164s
  training loss:		0.092544
  validation loss:		0.548696
  validation accuracy:		90.00 %
Epoch 942 of 2000 took 0.147s
  training loss:		0.093220
  validation loss:		0.508704
  validation accuracy:		91.09 %
Epoch 943 of 2000 took 0.153s
  training loss:		0.089660
  validation loss:		0.532126
  validation accuracy:		90.11 %
Epoch 944 of 2000 took 0.164s
  training loss:		0.089641
  validation loss:		0.515138
  validation accuracy:		90.33 %
Epoch 945 of 2000 took 0.135s
  training loss:		0.090515
  validation loss:		0.558021
  validation accuracy:		90.33 %
Epoch 946 of 2000 took 0.164s
  training loss:		0.094396
  validation loss:		0.550366
  validation accuracy:		89.78 %
Epoch 947 of 2000 took 0.139s
  training loss:		0.099655
  validation loss:		0.555643
  validation accuracy:		90.00 %
Epoch 948 of 2000 took 0.162s
  training loss:		0.091340
  validation loss:		0.534184
  validation accuracy:		90.54 %
Epoch 949 of 2000 took 0.166s
  training loss:		0.087481
  validation loss:		0.559233
  validation accuracy:		89.57 %
Epoch 950 of 2000 took 0.137s
  training loss:		0.087967
  validation loss:		0.534083
  validation accuracy:		89.89 %
Epoch 951 of 2000 took 0.173s
  training loss:		0.088360
  validation loss:		0.538695
  validation accuracy:		89.57 %
Epoch 952 of 2000 took 0.137s
  training loss:		0.091551
  validation loss:		0.538565
  validation accuracy:		90.43 %
Epoch 953 of 2000 took 0.162s
  training loss:		0.094925
  validation loss:		0.537792
  validation accuracy:		91.09 %
Epoch 954 of 2000 took 0.163s
  training loss:		0.082736
  validation loss:		0.561986
  validation accuracy:		89.78 %
Epoch 955 of 2000 took 0.137s
  training loss:		0.100887
  validation loss:		0.543779
  validation accuracy:		90.11 %
Epoch 956 of 2000 took 0.164s
  training loss:		0.085621
  validation loss:		0.556550
  validation accuracy:		90.11 %
Epoch 957 of 2000 took 0.136s
  training loss:		0.090488
  validation loss:		0.545463
  validation accuracy:		90.65 %
Epoch 958 of 2000 took 0.164s
  training loss:		0.093410
  validation loss:		0.530266
  validation accuracy:		90.65 %
Epoch 959 of 2000 took 0.155s
  training loss:		0.098617
  validation loss:		0.546155
  validation accuracy:		90.22 %
Epoch 960 of 2000 took 0.144s
  training loss:		0.093465
  validation loss:		0.534434
  validation accuracy:		90.65 %
Epoch 961 of 2000 took 0.164s
  training loss:		0.085489
  validation loss:		0.546093
  validation accuracy:		90.22 %
Epoch 962 of 2000 took 0.137s
  training loss:		0.090020
  validation loss:		0.522956
  validation accuracy:		90.43 %
Epoch 963 of 2000 took 0.164s
  training loss:		0.094629
  validation loss:		0.541219
  validation accuracy:		90.33 %
Epoch 964 of 2000 took 0.147s
  training loss:		0.088044
  validation loss:		0.541375
  validation accuracy:		90.43 %
Epoch 965 of 2000 took 0.152s
  training loss:		0.093499
  validation loss:		0.543699
  validation accuracy:		90.11 %
Epoch 966 of 2000 took 0.164s
  training loss:		0.084373
  validation loss:		0.532156
  validation accuracy:		90.43 %
Epoch 967 of 2000 took 0.137s
  training loss:		0.093068
  validation loss:		0.548666
  validation accuracy:		90.11 %
Epoch 968 of 2000 took 0.164s
  training loss:		0.094509
  validation loss:		0.562994
  validation accuracy:		89.78 %
Epoch 969 of 2000 took 0.145s
  training loss:		0.089201
  validation loss:		0.549869
  validation accuracy:		89.35 %
Epoch 970 of 2000 took 0.155s
  training loss:		0.091401
  validation loss:		0.564922
  validation accuracy:		90.00 %
Epoch 971 of 2000 took 0.164s
  training loss:		0.085759
  validation loss:		0.556995
  validation accuracy:		90.33 %
Epoch 972 of 2000 took 0.136s
  training loss:		0.083189
  validation loss:		0.524704
  validation accuracy:		90.76 %
Epoch 973 of 2000 took 0.164s
  training loss:		0.081949
  validation loss:		0.559380
  validation accuracy:		90.43 %
Epoch 974 of 2000 took 0.137s
  training loss:		0.096906
  validation loss:		0.540590
  validation accuracy:		90.54 %
Epoch 975 of 2000 took 0.163s
  training loss:		0.086039
  validation loss:		0.566566
  validation accuracy:		90.11 %
Epoch 976 of 2000 took 0.163s
  training loss:		0.100146
  validation loss:		0.548328
  validation accuracy:		90.11 %
Epoch 977 of 2000 took 0.138s
  training loss:		0.079908
  validation loss:		0.549516
  validation accuracy:		90.11 %
Epoch 978 of 2000 took 0.164s
  training loss:		0.088299
  validation loss:		0.556356
  validation accuracy:		90.11 %
Epoch 979 of 2000 took 0.136s
  training loss:		0.090605
  validation loss:		0.547830
  validation accuracy:		90.00 %
Epoch 980 of 2000 took 0.164s
  training loss:		0.083280
  validation loss:		0.553091
  validation accuracy:		90.33 %
Epoch 981 of 2000 took 0.155s
  training loss:		0.084857
  validation loss:		0.543362
  validation accuracy:		90.22 %
Epoch 982 of 2000 took 0.105s
  training loss:		0.094974
  validation loss:		0.553392
  validation accuracy:		90.33 %
Epoch 983 of 2000 took 0.105s
  training loss:		0.082526
  validation loss:		0.552844
  validation accuracy:		90.65 %
Epoch 984 of 2000 took 0.105s
  training loss:		0.090538
  validation loss:		0.562899
  validation accuracy:		89.67 %
Epoch 985 of 2000 took 0.105s
  training loss:		0.087307
  validation loss:		0.563676
  validation accuracy:		89.89 %
Epoch 986 of 2000 took 0.105s
  training loss:		0.084475
  validation loss:		0.554355
  validation accuracy:		90.22 %
Epoch 987 of 2000 took 0.105s
  training loss:		0.094710
  validation loss:		0.550061
  validation accuracy:		90.76 %
Epoch 988 of 2000 took 0.105s
  training loss:		0.087134
  validation loss:		0.580190
  validation accuracy:		90.22 %
Epoch 989 of 2000 took 0.105s
  training loss:		0.095861
  validation loss:		0.557737
  validation accuracy:		89.89 %
Epoch 990 of 2000 took 0.105s
  training loss:		0.083796
  validation loss:		0.570792
  validation accuracy:		90.00 %
Epoch 991 of 2000 took 0.105s
  training loss:		0.085990
  validation loss:		0.554991
  validation accuracy:		90.54 %
Epoch 992 of 2000 took 0.105s
  training loss:		0.085704
  validation loss:		0.551907
  validation accuracy:		90.22 %
Epoch 993 of 2000 took 0.105s
  training loss:		0.081656
  validation loss:		0.600017
  validation accuracy:		88.80 %
Epoch 994 of 2000 took 0.105s
  training loss:		0.087575
  validation loss:		0.592492
  validation accuracy:		89.46 %
Epoch 995 of 2000 took 0.105s
  training loss:		0.081534
  validation loss:		0.575925
  validation accuracy:		89.67 %
Epoch 996 of 2000 took 0.105s
  training loss:		0.088263
  validation loss:		0.575489
  validation accuracy:		89.89 %
Epoch 997 of 2000 took 0.105s
  training loss:		0.097627
  validation loss:		0.575568
  validation accuracy:		89.57 %
Epoch 998 of 2000 took 0.105s
  training loss:		0.086875
  validation loss:		0.554835
  validation accuracy:		90.00 %
Epoch 999 of 2000 took 0.105s
  training loss:		0.091441
  validation loss:		0.628687
  validation accuracy:		89.78 %
Epoch 1000 of 2000 took 0.105s
  training loss:		0.088789
  validation loss:		0.578279
  validation accuracy:		89.67 %
Epoch 1001 of 2000 took 0.105s
  training loss:		0.090286
  validation loss:		0.565500
  validation accuracy:		90.11 %
Epoch 1002 of 2000 took 0.105s
  training loss:		0.084401
  validation loss:		0.585750
  validation accuracy:		89.57 %
Epoch 1003 of 2000 took 0.105s
  training loss:		0.084565
  validation loss:		0.582355
  validation accuracy:		90.00 %
Epoch 1004 of 2000 took 0.105s
  training loss:		0.078789
  validation loss:		0.568934
  validation accuracy:		90.11 %
Epoch 1005 of 2000 took 0.105s
  training loss:		0.088338
  validation loss:		0.565700
  validation accuracy:		90.33 %
Epoch 1006 of 2000 took 0.105s
  training loss:		0.086622
  validation loss:		0.589958
  validation accuracy:		89.46 %
Epoch 1007 of 2000 took 0.105s
  training loss:		0.088437
  validation loss:		0.577701
  validation accuracy:		89.67 %
Epoch 1008 of 2000 took 0.105s
  training loss:		0.090157
  validation loss:		0.566906
  validation accuracy:		90.33 %
Epoch 1009 of 2000 took 0.105s
  training loss:		0.081611
  validation loss:		0.575101
  validation accuracy:		89.57 %
Epoch 1010 of 2000 took 0.105s
  training loss:		0.097597
  validation loss:		0.587079
  validation accuracy:		90.00 %
Epoch 1011 of 2000 took 0.105s
  training loss:		0.094073
  validation loss:		0.577251
  validation accuracy:		90.33 %
Epoch 1012 of 2000 took 0.105s
  training loss:		0.084438
  validation loss:		0.581921
  validation accuracy:		90.22 %
Epoch 1013 of 2000 took 0.105s
  training loss:		0.083991
  validation loss:		0.566149
  validation accuracy:		90.54 %
Epoch 1014 of 2000 took 0.105s
  training loss:		0.081349
  validation loss:		0.576417
  validation accuracy:		89.78 %
Epoch 1015 of 2000 took 0.105s
  training loss:		0.079889
  validation loss:		0.579730
  validation accuracy:		89.78 %
Epoch 1016 of 2000 took 0.105s
  training loss:		0.097874
  validation loss:		0.570122
  validation accuracy:		90.33 %
Epoch 1017 of 2000 took 0.105s
  training loss:		0.083911
  validation loss:		0.583089
  validation accuracy:		90.54 %
Epoch 1018 of 2000 took 0.105s
  training loss:		0.088170
  validation loss:		0.587216
  validation accuracy:		90.11 %
Epoch 1019 of 2000 took 0.105s
  training loss:		0.083294
  validation loss:		0.581807
  validation accuracy:		89.89 %
Epoch 1020 of 2000 took 0.105s
  training loss:		0.084722
  validation loss:		0.562503
  validation accuracy:		90.11 %
Epoch 1021 of 2000 took 0.105s
  training loss:		0.092578
  validation loss:		0.574682
  validation accuracy:		89.46 %
Epoch 1022 of 2000 took 0.105s
  training loss:		0.092205
  validation loss:		0.629416
  validation accuracy:		89.89 %
Epoch 1023 of 2000 took 0.105s
  training loss:		0.093570
  validation loss:		0.598596
  validation accuracy:		89.57 %
Epoch 1024 of 2000 took 0.105s
  training loss:		0.095408
  validation loss:		0.573718
  validation accuracy:		89.78 %
Epoch 1025 of 2000 took 0.105s
  training loss:		0.078056
  validation loss:		0.586720
  validation accuracy:		89.78 %
Epoch 1026 of 2000 took 0.105s
  training loss:		0.087418
  validation loss:		0.613048
  validation accuracy:		89.89 %
Epoch 1027 of 2000 took 0.105s
  training loss:		0.083306
  validation loss:		0.599714
  validation accuracy:		89.67 %
Epoch 1028 of 2000 took 0.105s
  training loss:		0.082267
  validation loss:		0.636020
  validation accuracy:		89.67 %
Epoch 1029 of 2000 took 0.105s
  training loss:		0.079193
  validation loss:		0.575291
  validation accuracy:		90.00 %
Epoch 1030 of 2000 took 0.105s
  training loss:		0.087604
  validation loss:		0.574026
  validation accuracy:		90.11 %
Epoch 1031 of 2000 took 0.105s
  training loss:		0.090453
  validation loss:		0.595190
  validation accuracy:		89.67 %
Epoch 1032 of 2000 took 0.105s
  training loss:		0.092885
  validation loss:		0.578183
  validation accuracy:		89.78 %
Epoch 1033 of 2000 took 0.105s
  training loss:		0.094284
  validation loss:		0.595175
  validation accuracy:		89.89 %
Epoch 1034 of 2000 took 0.105s
  training loss:		0.080740
  validation loss:		0.608318
  validation accuracy:		89.13 %
Epoch 1035 of 2000 took 0.105s
  training loss:		0.082224
  validation loss:		0.628513
  validation accuracy:		89.67 %
Epoch 1036 of 2000 took 0.105s
  training loss:		0.084948
  validation loss:		0.593295
  validation accuracy:		90.00 %
Epoch 1037 of 2000 took 0.105s
  training loss:		0.083640
  validation loss:		0.588806
  validation accuracy:		90.11 %
Epoch 1038 of 2000 took 0.105s
  training loss:		0.081279
  validation loss:		0.613860
  validation accuracy:		89.46 %
Epoch 1039 of 2000 took 0.105s
  training loss:		0.085402
  validation loss:		0.573405
  validation accuracy:		90.54 %
Epoch 1040 of 2000 took 0.105s
  training loss:		0.085553
  validation loss:		0.595526
  validation accuracy:		90.33 %
Epoch 1041 of 2000 took 0.105s
  training loss:		0.088852
  validation loss:		0.594516
  validation accuracy:		90.11 %
Epoch 1042 of 2000 took 0.105s
  training loss:		0.087713
  validation loss:		0.577715
  validation accuracy:		90.54 %
Epoch 1043 of 2000 took 0.105s
  training loss:		0.087331
  validation loss:		0.587154
  validation accuracy:		90.11 %
Epoch 1044 of 2000 took 0.105s
  training loss:		0.085303
  validation loss:		0.604985
  validation accuracy:		90.22 %
Epoch 1045 of 2000 took 0.105s
  training loss:		0.082767
  validation loss:		0.594367
  validation accuracy:		90.22 %
Epoch 1046 of 2000 took 0.105s
  training loss:		0.085713
  validation loss:		0.585277
  validation accuracy:		90.33 %
Epoch 1047 of 2000 took 0.105s
  training loss:		0.082995
  validation loss:		0.585362
  validation accuracy:		90.76 %
Epoch 1048 of 2000 took 0.105s
  training loss:		0.077018
  validation loss:		0.596960
  validation accuracy:		89.35 %
Epoch 1049 of 2000 took 0.105s
  training loss:		0.080141
  validation loss:		0.611501
  validation accuracy:		89.89 %
Epoch 1050 of 2000 took 0.105s
  training loss:		0.083303
  validation loss:		0.626623
  validation accuracy:		90.11 %
Epoch 1051 of 2000 took 0.105s
  training loss:		0.083905
  validation loss:		0.588030
  validation accuracy:		90.87 %
Epoch 1052 of 2000 took 0.105s
  training loss:		0.081704
  validation loss:		0.598643
  validation accuracy:		89.89 %
Epoch 1053 of 2000 took 0.105s
  training loss:		0.080880
  validation loss:		0.592889
  validation accuracy:		90.33 %
Epoch 1054 of 2000 took 0.105s
  training loss:		0.093588
  validation loss:		0.591896
  validation accuracy:		90.00 %
Epoch 1055 of 2000 took 0.105s
  training loss:		0.096223
  validation loss:		0.612111
  validation accuracy:		90.22 %
Epoch 1056 of 2000 took 0.105s
  training loss:		0.084461
  validation loss:		0.571844
  validation accuracy:		90.33 %
Epoch 1057 of 2000 took 0.105s
  training loss:		0.084735
  validation loss:		0.587698
  validation accuracy:		90.22 %
Epoch 1058 of 2000 took 0.105s
  training loss:		0.085503
  validation loss:		0.611367
  validation accuracy:		90.11 %
Epoch 1059 of 2000 took 0.105s
  training loss:		0.085785
  validation loss:		0.625128
  validation accuracy:		90.00 %
Epoch 1060 of 2000 took 0.105s
  training loss:		0.095498
  validation loss:		0.587930
  validation accuracy:		89.78 %
Epoch 1061 of 2000 took 0.105s
  training loss:		0.080716
  validation loss:		0.614886
  validation accuracy:		90.11 %
Epoch 1062 of 2000 took 0.105s
  training loss:		0.081769
  validation loss:		0.619393
  validation accuracy:		89.78 %
Epoch 1063 of 2000 took 0.105s
  training loss:		0.084343
  validation loss:		0.642165
  validation accuracy:		89.78 %
Epoch 1064 of 2000 took 0.105s
  training loss:		0.083242
  validation loss:		0.617763
  validation accuracy:		89.24 %
Epoch 1065 of 2000 took 0.105s
  training loss:		0.086788
  validation loss:		0.626973
  validation accuracy:		90.11 %
Epoch 1066 of 2000 took 0.105s
  training loss:		0.094063
  validation loss:		0.618345
  validation accuracy:		90.00 %
Epoch 1067 of 2000 took 0.105s
  training loss:		0.080748
  validation loss:		0.633051
  validation accuracy:		89.35 %
Epoch 1068 of 2000 took 0.105s
  training loss:		0.081759
  validation loss:		0.622463
  validation accuracy:		90.00 %
Epoch 1069 of 2000 took 0.105s
  training loss:		0.088370
  validation loss:		0.628374
  validation accuracy:		89.78 %
Epoch 1070 of 2000 took 0.105s
  training loss:		0.095049
  validation loss:		0.609913
  validation accuracy:		90.11 %
Epoch 1071 of 2000 took 0.105s
  training loss:		0.081174
  validation loss:		0.609389
  validation accuracy:		89.35 %
Epoch 1072 of 2000 took 0.105s
  training loss:		0.084079
  validation loss:		0.648144
  validation accuracy:		89.78 %
Epoch 1073 of 2000 took 0.105s
  training loss:		0.090286
  validation loss:		0.608130
  validation accuracy:		90.54 %
Epoch 1074 of 2000 took 0.105s
  training loss:		0.087149
  validation loss:		0.610952
  validation accuracy:		89.78 %
Epoch 1075 of 2000 took 0.105s
  training loss:		0.082511
  validation loss:		0.631626
  validation accuracy:		89.57 %
Epoch 1076 of 2000 took 0.105s
  training loss:		0.080672
  validation loss:		0.617158
  validation accuracy:		90.00 %
Epoch 1077 of 2000 took 0.105s
  training loss:		0.088455
  validation loss:		0.601729
  validation accuracy:		89.78 %
Epoch 1078 of 2000 took 0.105s
  training loss:		0.082870
  validation loss:		0.648340
  validation accuracy:		89.46 %
Epoch 1079 of 2000 took 0.105s
  training loss:		0.087373
  validation loss:		0.612454
  validation accuracy:		89.67 %
Epoch 1080 of 2000 took 0.105s
  training loss:		0.090935
  validation loss:		0.589279
  validation accuracy:		90.43 %
Epoch 1081 of 2000 took 0.105s
  training loss:		0.075526
  validation loss:		0.592387
  validation accuracy:		90.65 %
Epoch 1082 of 2000 took 0.105s
  training loss:		0.080376
  validation loss:		0.642115
  validation accuracy:		89.24 %
Epoch 1083 of 2000 took 0.105s
  training loss:		0.082670
  validation loss:		0.610215
  validation accuracy:		90.00 %
Epoch 1084 of 2000 took 0.105s
  training loss:		0.096258
  validation loss:		0.616896
  validation accuracy:		89.67 %
Epoch 1085 of 2000 took 0.105s
  training loss:		0.105078
  validation loss:		0.636945
  validation accuracy:		89.89 %
Epoch 1086 of 2000 took 0.105s
  training loss:		0.097047
  validation loss:		0.606193
  validation accuracy:		89.67 %
Epoch 1087 of 2000 took 0.105s
  training loss:		0.078221
  validation loss:		0.655257
  validation accuracy:		89.46 %
Epoch 1088 of 2000 took 0.105s
  training loss:		0.096218
  validation loss:		0.630482
  validation accuracy:		89.46 %
Epoch 1089 of 2000 took 0.105s
  training loss:		0.086019
  validation loss:		0.663167
  validation accuracy:		89.02 %
Epoch 1090 of 2000 took 0.105s
  training loss:		0.090158
  validation loss:		0.603134
  validation accuracy:		90.00 %
Epoch 1091 of 2000 took 0.105s
  training loss:		0.095916
  validation loss:		0.613468
  validation accuracy:		89.78 %
Epoch 1092 of 2000 took 0.105s
  training loss:		0.088258
  validation loss:		0.642766
  validation accuracy:		89.57 %
Epoch 1093 of 2000 took 0.105s
  training loss:		0.080337
  validation loss:		0.626697
  validation accuracy:		89.78 %
Epoch 1094 of 2000 took 0.105s
  training loss:		0.090733
  validation loss:		0.616070
  validation accuracy:		89.67 %
Epoch 1095 of 2000 took 0.105s
  training loss:		0.088339
  validation loss:		0.641384
  validation accuracy:		89.57 %
Epoch 1096 of 2000 took 0.105s
  training loss:		0.086496
  validation loss:		0.621870
  validation accuracy:		90.00 %
Epoch 1097 of 2000 took 0.105s
  training loss:		0.076821
  validation loss:		0.636528
  validation accuracy:		89.57 %
Epoch 1098 of 2000 took 0.105s
  training loss:		0.079056
  validation loss:		0.655401
  validation accuracy:		89.35 %
Epoch 1099 of 2000 took 0.105s
  training loss:		0.085667
  validation loss:		0.619806
  validation accuracy:		90.33 %
Epoch 1100 of 2000 took 0.105s
  training loss:		0.084659
  validation loss:		0.610184
  validation accuracy:		90.00 %
Epoch 1101 of 2000 took 0.105s
  training loss:		0.080463
  validation loss:		0.612957
  validation accuracy:		90.00 %
Epoch 1102 of 2000 took 0.105s
  training loss:		0.080588
  validation loss:		0.640167
  validation accuracy:		89.35 %
Epoch 1103 of 2000 took 0.105s
  training loss:		0.084300
  validation loss:		0.615263
  validation accuracy:		90.11 %
Epoch 1104 of 2000 took 0.105s
  training loss:		0.087967
  validation loss:		0.650373
  validation accuracy:		89.35 %
Epoch 1105 of 2000 took 0.105s
  training loss:		0.084260
  validation loss:		0.611291
  validation accuracy:		90.00 %
Epoch 1106 of 2000 took 0.105s
  training loss:		0.075152
  validation loss:		0.624128
  validation accuracy:		89.78 %
Epoch 1107 of 2000 took 0.105s
  training loss:		0.084800
  validation loss:		0.631633
  validation accuracy:		89.89 %
Epoch 1108 of 2000 took 0.105s
  training loss:		0.079712
  validation loss:		0.665879
  validation accuracy:		89.24 %
Epoch 1109 of 2000 took 0.105s
  training loss:		0.086810
  validation loss:		0.630783
  validation accuracy:		89.57 %
Epoch 1110 of 2000 took 0.105s
  training loss:		0.080996
  validation loss:		0.627038
  validation accuracy:		90.11 %
Epoch 1111 of 2000 took 0.105s
  training loss:		0.094640
  validation loss:		0.654125
  validation accuracy:		89.35 %
Epoch 1112 of 2000 took 0.105s
  training loss:		0.101173
  validation loss:		0.641234
  validation accuracy:		89.67 %
Epoch 1113 of 2000 took 0.105s
  training loss:		0.081538
  validation loss:		0.669561
  validation accuracy:		88.80 %
Epoch 1114 of 2000 took 0.105s
  training loss:		0.087139
  validation loss:		0.624446
  validation accuracy:		90.00 %
Epoch 1115 of 2000 took 0.105s
  training loss:		0.077757
  validation loss:		0.629345
  validation accuracy:		89.67 %
Epoch 1116 of 2000 took 0.103s
  training loss:		0.080876
  validation loss:		0.627200
  validation accuracy:		89.89 %
Epoch 1117 of 2000 took 0.095s
  training loss:		0.070447
  validation loss:		0.647142
  validation accuracy:		89.78 %
Epoch 1118 of 2000 took 0.095s
  training loss:		0.076219
  validation loss:		0.644223
  validation accuracy:		89.89 %
Epoch 1119 of 2000 took 0.103s
  training loss:		0.083619
  validation loss:		0.656077
  validation accuracy:		89.02 %
Epoch 1120 of 2000 took 0.105s
  training loss:		0.084643
  validation loss:		0.677608
  validation accuracy:		89.13 %
Epoch 1121 of 2000 took 0.104s
  training loss:		0.077491
  validation loss:		0.634905
  validation accuracy:		90.54 %
Epoch 1122 of 2000 took 0.104s
  training loss:		0.086330
  validation loss:		0.685671
  validation accuracy:		89.35 %
Epoch 1123 of 2000 took 0.096s
  training loss:		0.086867
  validation loss:		0.639820
  validation accuracy:		89.67 %
Epoch 1124 of 2000 took 0.095s
  training loss:		0.087682
  validation loss:		0.631725
  validation accuracy:		90.00 %
Epoch 1125 of 2000 took 0.096s
  training loss:		0.080713
  validation loss:		0.701105
  validation accuracy:		89.13 %
Epoch 1126 of 2000 took 0.095s
  training loss:		0.095451
  validation loss:		0.655333
  validation accuracy:		89.78 %
Epoch 1127 of 2000 took 0.097s
  training loss:		0.095040
  validation loss:		0.624589
  validation accuracy:		90.54 %
Epoch 1128 of 2000 took 0.096s
  training loss:		0.077414
  validation loss:		0.656701
  validation accuracy:		89.67 %
Epoch 1129 of 2000 took 0.095s
  training loss:		0.086215
  validation loss:		0.662884
  validation accuracy:		89.35 %
Epoch 1130 of 2000 took 0.095s
  training loss:		0.084194
  validation loss:		0.663394
  validation accuracy:		89.35 %
Epoch 1131 of 2000 took 0.095s
  training loss:		0.084984
  validation loss:		0.661469
  validation accuracy:		88.91 %
Epoch 1132 of 2000 took 0.095s
  training loss:		0.090594
  validation loss:		0.638975
  validation accuracy:		90.00 %
Epoch 1133 of 2000 took 0.101s
  training loss:		0.083418
  validation loss:		0.656695
  validation accuracy:		89.67 %
Epoch 1134 of 2000 took 0.102s
  training loss:		0.088795
  validation loss:		0.641268
  validation accuracy:		90.00 %
Epoch 1135 of 2000 took 0.096s
  training loss:		0.089447
  validation loss:		0.651245
  validation accuracy:		89.35 %
Epoch 1136 of 2000 took 0.100s
  training loss:		0.094807
  validation loss:		0.644789
  validation accuracy:		90.00 %
Epoch 1137 of 2000 took 0.099s
  training loss:		0.087370
  validation loss:		0.661059
  validation accuracy:		89.57 %
Epoch 1138 of 2000 took 0.096s
  training loss:		0.084495
  validation loss:		0.669110
  validation accuracy:		89.13 %
Epoch 1139 of 2000 took 0.096s
  training loss:		0.085816
  validation loss:		0.679378
  validation accuracy:		88.80 %
Epoch 1140 of 2000 took 0.096s
  training loss:		0.084055
  validation loss:		0.679280
  validation accuracy:		89.89 %
Epoch 1141 of 2000 took 0.096s
  training loss:		0.079197
  validation loss:		0.625587
  validation accuracy:		90.11 %
Epoch 1142 of 2000 took 0.096s
  training loss:		0.079705
  validation loss:		0.623286
  validation accuracy:		90.65 %
Epoch 1143 of 2000 took 0.096s
  training loss:		0.076108
  validation loss:		0.655939
  validation accuracy:		89.24 %
Epoch 1144 of 2000 took 0.096s
  training loss:		0.090207
  validation loss:		0.691753
  validation accuracy:		89.24 %
Epoch 1145 of 2000 took 0.096s
  training loss:		0.087346
  validation loss:		0.647343
  validation accuracy:		89.78 %
Epoch 1146 of 2000 took 0.096s
  training loss:		0.081412
  validation loss:		0.660074
  validation accuracy:		89.13 %
Epoch 1147 of 2000 took 0.096s
  training loss:		0.077029
  validation loss:		0.639121
  validation accuracy:		90.11 %
Epoch 1148 of 2000 took 0.096s
  training loss:		0.075797
  validation loss:		0.670338
  validation accuracy:		89.89 %
Epoch 1149 of 2000 took 0.096s
  training loss:		0.081087
  validation loss:		0.678157
  validation accuracy:		89.46 %
Epoch 1150 of 2000 took 0.096s
  training loss:		0.079722
  validation loss:		0.673192
  validation accuracy:		89.46 %
Epoch 1151 of 2000 took 0.096s
  training loss:		0.076024
  validation loss:		0.656598
  validation accuracy:		89.89 %
Epoch 1152 of 2000 took 0.096s
  training loss:		0.111365
  validation loss:		0.641975
  validation accuracy:		90.00 %
Epoch 1153 of 2000 took 0.096s
  training loss:		0.107133
  validation loss:		0.666738
  validation accuracy:		90.00 %
Epoch 1154 of 2000 took 0.096s
  training loss:		0.083128
  validation loss:		0.662461
  validation accuracy:		89.57 %
Epoch 1155 of 2000 took 0.096s
  training loss:		0.073430
  validation loss:		0.650542
  validation accuracy:		89.78 %
Epoch 1156 of 2000 took 0.096s
  training loss:		0.070491
  validation loss:		0.642224
  validation accuracy:		89.78 %
Epoch 1157 of 2000 took 0.096s
  training loss:		0.083671
  validation loss:		0.686365
  validation accuracy:		89.78 %
Epoch 1158 of 2000 took 0.096s
  training loss:		0.074335
  validation loss:		0.675307
  validation accuracy:		89.89 %
Epoch 1159 of 2000 took 0.096s
  training loss:		0.081522
  validation loss:		0.653950
  validation accuracy:		89.57 %
Epoch 1160 of 2000 took 0.096s
  training loss:		0.077340
  validation loss:		0.677921
  validation accuracy:		89.57 %
Epoch 1161 of 2000 took 0.096s
  training loss:		0.081637
  validation loss:		0.671403
  validation accuracy:		89.67 %
Epoch 1162 of 2000 took 0.096s
  training loss:		0.077674
  validation loss:		0.681729
  validation accuracy:		89.57 %
Epoch 1163 of 2000 took 0.096s
  training loss:		0.094191
  validation loss:		0.683328
  validation accuracy:		89.24 %
Epoch 1164 of 2000 took 0.096s
  training loss:		0.080825
  validation loss:		0.686653
  validation accuracy:		89.35 %
Epoch 1165 of 2000 took 0.096s
  training loss:		0.089623
  validation loss:		0.683320
  validation accuracy:		89.46 %
Epoch 1166 of 2000 took 0.096s
  training loss:		0.081097
  validation loss:		0.720140
  validation accuracy:		89.67 %
Epoch 1167 of 2000 took 0.096s
  training loss:		0.091537
  validation loss:		0.649966
  validation accuracy:		90.11 %
Epoch 1168 of 2000 took 0.097s
  training loss:		0.078380
  validation loss:		0.649530
  validation accuracy:		90.11 %
Epoch 1169 of 2000 took 0.096s
  training loss:		0.079833
  validation loss:		0.664428
  validation accuracy:		89.89 %
Epoch 1170 of 2000 took 0.096s
  training loss:		0.072983
  validation loss:		0.671736
  validation accuracy:		89.46 %
Epoch 1171 of 2000 took 0.096s
  training loss:		0.084067
  validation loss:		0.646490
  validation accuracy:		90.22 %
Epoch 1172 of 2000 took 0.096s
  training loss:		0.086507
  validation loss:		0.692367
  validation accuracy:		89.24 %
Epoch 1173 of 2000 took 0.096s
  training loss:		0.077706
  validation loss:		0.685939
  validation accuracy:		89.57 %
Epoch 1174 of 2000 took 0.096s
  training loss:		0.079761
  validation loss:		0.673023
  validation accuracy:		89.89 %
Epoch 1175 of 2000 took 0.096s
  training loss:		0.071369
  validation loss:		0.647930
  validation accuracy:		90.33 %
Epoch 1176 of 2000 took 0.096s
  training loss:		0.084265
  validation loss:		0.676176
  validation accuracy:		89.46 %
Epoch 1177 of 2000 took 0.096s
  training loss:		0.075160
  validation loss:		0.695278
  validation accuracy:		89.78 %
Epoch 1178 of 2000 took 0.096s
  training loss:		0.077759
  validation loss:		0.690391
  validation accuracy:		90.00 %
Epoch 1179 of 2000 took 0.096s
  training loss:		0.106420
  validation loss:		0.663354
  validation accuracy:		90.00 %
Epoch 1180 of 2000 took 0.096s
  training loss:		0.077769
  validation loss:		0.720816
  validation accuracy:		89.24 %
Epoch 1181 of 2000 took 0.096s
  training loss:		0.101115
  validation loss:		0.692474
  validation accuracy:		89.46 %
Epoch 1182 of 2000 took 0.096s
  training loss:		0.093151
  validation loss:		0.674329
  validation accuracy:		89.67 %
Epoch 1183 of 2000 took 0.096s
  training loss:		0.078782
  validation loss:		0.676495
  validation accuracy:		89.67 %
Epoch 1184 of 2000 took 0.096s
  training loss:		0.083230
  validation loss:		0.657382
  validation accuracy:		90.00 %
Epoch 1185 of 2000 took 0.096s
  training loss:		0.081057
  validation loss:		0.697803
  validation accuracy:		89.35 %
Epoch 1186 of 2000 took 0.096s
  training loss:		0.082079
  validation loss:		0.675999
  validation accuracy:		90.00 %
Epoch 1187 of 2000 took 0.096s
  training loss:		0.077490
  validation loss:		0.664692
  validation accuracy:		89.78 %
Epoch 1188 of 2000 took 0.096s
  training loss:		0.079272
  validation loss:		0.698209
  validation accuracy:		89.46 %
Epoch 1189 of 2000 took 0.096s
  training loss:		0.076910
  validation loss:		0.679018
  validation accuracy:		90.00 %
Epoch 1190 of 2000 took 0.096s
  training loss:		0.071031
  validation loss:		0.680880
  validation accuracy:		89.67 %
Epoch 1191 of 2000 took 0.096s
  training loss:		0.075698
  validation loss:		0.666629
  validation accuracy:		89.78 %
Epoch 1192 of 2000 took 0.096s
  training loss:		0.078936
  validation loss:		0.672035
  validation accuracy:		89.57 %
Epoch 1193 of 2000 took 0.096s
  training loss:		0.087382
  validation loss:		0.648101
  validation accuracy:		90.11 %
Epoch 1194 of 2000 took 0.096s
  training loss:		0.080216
  validation loss:		0.737359
  validation accuracy:		89.13 %
Epoch 1195 of 2000 took 0.096s
  training loss:		0.080066
  validation loss:		0.683737
  validation accuracy:		89.46 %
Epoch 1196 of 2000 took 0.096s
  training loss:		0.072132
  validation loss:		0.695968
  validation accuracy:		89.24 %
Epoch 1197 of 2000 took 0.096s
  training loss:		0.083223
  validation loss:		0.664677
  validation accuracy:		90.11 %
Epoch 1198 of 2000 took 0.096s
  training loss:		0.077885
  validation loss:		0.684702
  validation accuracy:		89.67 %
Epoch 1199 of 2000 took 0.097s
  training loss:		0.078542
  validation loss:		0.710814
  validation accuracy:		88.80 %
Epoch 1200 of 2000 took 0.096s
  training loss:		0.083654
  validation loss:		0.686754
  validation accuracy:		89.67 %
Epoch 1201 of 2000 took 0.096s
  training loss:		0.075036
  validation loss:		0.685175
  validation accuracy:		89.78 %
Epoch 1202 of 2000 took 0.096s
  training loss:		0.086044
  validation loss:		0.706226
  validation accuracy:		89.46 %
Epoch 1203 of 2000 took 0.098s
  training loss:		0.073593
  validation loss:		0.695081
  validation accuracy:		89.67 %
Epoch 1204 of 2000 took 0.096s
  training loss:		0.075053
  validation loss:		0.686072
  validation accuracy:		89.46 %
Epoch 1205 of 2000 took 0.096s
  training loss:		0.081839
  validation loss:		0.697034
  validation accuracy:		89.24 %
Epoch 1206 of 2000 took 0.096s
  training loss:		0.075293
  validation loss:		0.663456
  validation accuracy:		90.11 %
Epoch 1207 of 2000 took 0.096s
  training loss:		0.079419
  validation loss:		0.721218
  validation accuracy:		89.46 %
Epoch 1208 of 2000 took 0.096s
  training loss:		0.083427
  validation loss:		0.679216
  validation accuracy:		89.89 %
Epoch 1209 of 2000 took 0.096s
  training loss:		0.081974
  validation loss:		0.661579
  validation accuracy:		89.89 %
Epoch 1210 of 2000 took 0.096s
  training loss:		0.078474
  validation loss:		0.752330
  validation accuracy:		89.35 %
Epoch 1211 of 2000 took 0.096s
  training loss:		0.094617
  validation loss:		0.688281
  validation accuracy:		90.11 %
Epoch 1212 of 2000 took 0.096s
  training loss:		0.080714
  validation loss:		0.716965
  validation accuracy:		89.46 %
Epoch 1213 of 2000 took 0.096s
  training loss:		0.073073
  validation loss:		0.684254
  validation accuracy:		89.78 %
Epoch 1214 of 2000 took 0.096s
  training loss:		0.082333
  validation loss:		0.683817
  validation accuracy:		89.67 %
Epoch 1215 of 2000 took 0.096s
  training loss:		0.074462
  validation loss:		0.698562
  validation accuracy:		89.57 %
Epoch 1216 of 2000 took 0.096s
  training loss:		0.083163
  validation loss:		0.667294
  validation accuracy:		90.33 %
Epoch 1217 of 2000 took 0.096s
  training loss:		0.074079
  validation loss:		0.701648
  validation accuracy:		89.89 %
Epoch 1218 of 2000 took 0.096s
  training loss:		0.083561
  validation loss:		0.725380
  validation accuracy:		88.91 %
Epoch 1219 of 2000 took 0.096s
  training loss:		0.079451
  validation loss:		0.709239
  validation accuracy:		89.57 %
Epoch 1220 of 2000 took 0.096s
  training loss:		0.074304
  validation loss:		0.685334
  validation accuracy:		89.78 %
Epoch 1221 of 2000 took 0.096s
  training loss:		0.091368
  validation loss:		0.695793
  validation accuracy:		89.67 %
Epoch 1222 of 2000 took 0.096s
  training loss:		0.081938
  validation loss:		0.706340
  validation accuracy:		89.24 %
Epoch 1223 of 2000 took 0.096s
  training loss:		0.086960
  validation loss:		0.680142
  validation accuracy:		90.33 %
Epoch 1224 of 2000 took 0.096s
  training loss:		0.080056
  validation loss:		0.696856
  validation accuracy:		89.13 %
Epoch 1225 of 2000 took 0.096s
  training loss:		0.076461
  validation loss:		0.687825
  validation accuracy:		89.78 %
Epoch 1226 of 2000 took 0.096s
  training loss:		0.073102
  validation loss:		0.689062
  validation accuracy:		90.11 %
Epoch 1227 of 2000 took 0.096s
  training loss:		0.090174
  validation loss:		0.682877
  validation accuracy:		90.00 %
Epoch 1228 of 2000 took 0.096s
  training loss:		0.071947
  validation loss:		0.725672
  validation accuracy:		89.35 %
Epoch 1229 of 2000 took 0.096s
  training loss:		0.086617
  validation loss:		0.691226
  validation accuracy:		90.00 %
Epoch 1230 of 2000 took 0.096s
  training loss:		0.072787
  validation loss:		0.681294
  validation accuracy:		89.89 %
Epoch 1231 of 2000 took 0.097s
  training loss:		0.092630
  validation loss:		0.744606
  validation accuracy:		89.02 %
Epoch 1232 of 2000 took 0.096s
  training loss:		0.091249
  validation loss:		0.689977
  validation accuracy:		89.89 %
Epoch 1233 of 2000 took 0.096s
  training loss:		0.074580
  validation loss:		0.710096
  validation accuracy:		89.57 %
Epoch 1234 of 2000 took 0.096s
  training loss:		0.078782
  validation loss:		0.695654
  validation accuracy:		89.57 %
Epoch 1235 of 2000 took 0.096s
  training loss:		0.075058
  validation loss:		0.694066
  validation accuracy:		89.89 %
Epoch 1236 of 2000 took 0.096s
  training loss:		0.077481
  validation loss:		0.703190
  validation accuracy:		89.78 %
Epoch 1237 of 2000 took 0.096s
  training loss:		0.075544
  validation loss:		0.681208
  validation accuracy:		90.22 %
Epoch 1238 of 2000 took 0.096s
  training loss:		0.098935
  validation loss:		0.746208
  validation accuracy:		89.46 %
Epoch 1239 of 2000 took 0.096s
  training loss:		0.083784
  validation loss:		0.707655
  validation accuracy:		89.46 %
Epoch 1240 of 2000 took 0.096s
  training loss:		0.098310
  validation loss:		0.708167
  validation accuracy:		89.57 %
Epoch 1241 of 2000 took 0.096s
  training loss:		0.075273
  validation loss:		0.716728
  validation accuracy:		89.57 %
Epoch 1242 of 2000 took 0.096s
  training loss:		0.079225
  validation loss:		0.712109
  validation accuracy:		89.67 %
Epoch 1243 of 2000 took 0.096s
  training loss:		0.077997
  validation loss:		0.713342
  validation accuracy:		89.46 %
Epoch 1244 of 2000 took 0.096s
  training loss:		0.078557
  validation loss:		0.729786
  validation accuracy:		89.57 %
Epoch 1245 of 2000 took 0.096s
  training loss:		0.093736
  validation loss:		0.689628
  validation accuracy:		89.67 %
Epoch 1246 of 2000 took 0.096s
  training loss:		0.082976
  validation loss:		0.711043
  validation accuracy:		89.67 %
Epoch 1247 of 2000 took 0.096s
  training loss:		0.069691
  validation loss:		0.676181
  validation accuracy:		90.54 %
Epoch 1248 of 2000 took 0.096s
  training loss:		0.100244
  validation loss:		0.698371
  validation accuracy:		89.24 %
Epoch 1249 of 2000 took 0.096s
  training loss:		0.078983
  validation loss:		0.696727
  validation accuracy:		89.67 %
Epoch 1250 of 2000 took 0.096s
  training loss:		0.128250
  validation loss:		0.725742
  validation accuracy:		89.57 %
Epoch 1251 of 2000 took 0.096s
  training loss:		0.079912
  validation loss:		0.711198
  validation accuracy:		89.57 %
Epoch 1252 of 2000 took 0.096s
  training loss:		0.078366
  validation loss:		0.695813
  validation accuracy:		89.46 %
Epoch 1253 of 2000 took 0.096s
  training loss:		0.075794
  validation loss:		0.724488
  validation accuracy:		89.13 %
Epoch 1254 of 2000 took 0.096s
  training loss:		0.084323
  validation loss:		0.684609
  validation accuracy:		90.11 %
Epoch 1255 of 2000 took 0.096s
  training loss:		0.084501
  validation loss:		0.716600
  validation accuracy:		89.57 %
Epoch 1256 of 2000 took 0.096s
  training loss:		0.078664
  validation loss:		0.720888
  validation accuracy:		89.35 %
Epoch 1257 of 2000 took 0.096s
  training loss:		0.076306
  validation loss:		0.685291
  validation accuracy:		90.22 %
Epoch 1258 of 2000 took 0.096s
  training loss:		0.079407
  validation loss:		0.693230
  validation accuracy:		90.00 %
Epoch 1259 of 2000 took 0.096s
  training loss:		0.083654
  validation loss:		0.750843
  validation accuracy:		89.35 %
Epoch 1260 of 2000 took 0.096s
  training loss:		0.078806
  validation loss:		0.709819
  validation accuracy:		90.00 %
Epoch 1261 of 2000 took 0.096s
  training loss:		0.075754
  validation loss:		0.732286
  validation accuracy:		89.57 %
Epoch 1262 of 2000 took 0.097s
  training loss:		0.077532
  validation loss:		0.712420
  validation accuracy:		90.00 %
Epoch 1263 of 2000 took 0.096s
  training loss:		0.073953
  validation loss:		0.700560
  validation accuracy:		89.46 %
Epoch 1264 of 2000 took 0.096s
  training loss:		0.075012
  validation loss:		0.707496
  validation accuracy:		89.78 %
Epoch 1265 of 2000 took 0.096s
  training loss:		0.081553
  validation loss:		0.775469
  validation accuracy:		88.80 %
Epoch 1266 of 2000 took 0.096s
  training loss:		0.082966
  validation loss:		0.706295
  validation accuracy:		90.00 %
Epoch 1267 of 2000 took 0.096s
  training loss:		0.073200
  validation loss:		0.709334
  validation accuracy:		90.00 %
Epoch 1268 of 2000 took 0.096s
  training loss:		0.077647
  validation loss:		0.732289
  validation accuracy:		89.46 %
Epoch 1269 of 2000 took 0.096s
  training loss:		0.079259
  validation loss:		0.768744
  validation accuracy:		89.02 %
Epoch 1270 of 2000 took 0.096s
  training loss:		0.084377
  validation loss:		0.770623
  validation accuracy:		88.80 %
Epoch 1271 of 2000 took 0.096s
  training loss:		0.094412
  validation loss:		0.693220
  validation accuracy:		90.11 %
Epoch 1272 of 2000 took 0.096s
  training loss:		0.073830
  validation loss:		0.714368
  validation accuracy:		89.46 %
Epoch 1273 of 2000 took 0.096s
  training loss:		0.079469
  validation loss:		0.731384
  validation accuracy:		89.67 %
Epoch 1274 of 2000 took 0.096s
  training loss:		0.095702
  validation loss:		0.728367
  validation accuracy:		89.78 %
Epoch 1275 of 2000 took 0.096s
  training loss:		0.076802
  validation loss:		0.733437
  validation accuracy:		89.57 %
Epoch 1276 of 2000 took 0.096s
  training loss:		0.092699
  validation loss:		0.693014
  validation accuracy:		90.33 %
Epoch 1277 of 2000 took 0.096s
  training loss:		0.086573
  validation loss:		0.717792
  validation accuracy:		89.67 %
Epoch 1278 of 2000 took 0.096s
  training loss:		0.077159
  validation loss:		0.731666
  validation accuracy:		89.67 %
Epoch 1279 of 2000 took 0.096s
  training loss:		0.070695
  validation loss:		0.723653
  validation accuracy:		89.89 %
Epoch 1280 of 2000 took 0.096s
  training loss:		0.086188
  validation loss:		0.728597
  validation accuracy:		89.46 %
Epoch 1281 of 2000 took 0.096s
  training loss:		0.081223
  validation loss:		0.714692
  validation accuracy:		89.89 %
Epoch 1282 of 2000 took 0.096s
  training loss:		0.095838
  validation loss:		0.707886
  validation accuracy:		89.89 %
Epoch 1283 of 2000 took 0.096s
  training loss:		0.088138
  validation loss:		0.722066
  validation accuracy:		89.89 %
Epoch 1284 of 2000 took 0.096s
  training loss:		0.097653
  validation loss:		0.712288
  validation accuracy:		89.89 %
Epoch 1285 of 2000 took 0.096s
  training loss:		0.078489
  validation loss:		0.751445
  validation accuracy:		89.02 %
Epoch 1286 of 2000 took 0.096s
  training loss:		0.103684
  validation loss:		0.717818
  validation accuracy:		90.33 %
Epoch 1287 of 2000 took 0.096s
  training loss:		0.073341
  validation loss:		0.721837
  validation accuracy:		89.57 %
Epoch 1288 of 2000 took 0.096s
  training loss:		0.081095
  validation loss:		0.732586
  validation accuracy:		89.46 %
Epoch 1289 of 2000 took 0.096s
  training loss:		0.073579
  validation loss:		0.713420
  validation accuracy:		90.33 %
Epoch 1290 of 2000 took 0.096s
  training loss:		0.073345
  validation loss:		0.710785
  validation accuracy:		89.35 %
Epoch 1291 of 2000 took 0.096s
  training loss:		0.136797
  validation loss:		0.722256
  validation accuracy:		89.35 %
Epoch 1292 of 2000 took 0.096s
  training loss:		0.077891
  validation loss:		0.747854
  validation accuracy:		89.35 %
Epoch 1293 of 2000 took 0.097s
  training loss:		0.085996
  validation loss:		0.753331
  validation accuracy:		89.35 %
Epoch 1294 of 2000 took 0.096s
  training loss:		0.087504
  validation loss:		0.738329
  validation accuracy:		89.67 %
Epoch 1295 of 2000 took 0.096s
  training loss:		0.086452
  validation loss:		0.789188
  validation accuracy:		88.48 %
Epoch 1296 of 2000 took 0.096s
  training loss:		0.079721
  validation loss:		0.702236
  validation accuracy:		89.89 %
Epoch 1297 of 2000 took 0.096s
  training loss:		0.072604
  validation loss:		0.742476
  validation accuracy:		89.24 %
Epoch 1298 of 2000 took 0.096s
  training loss:		0.076963
  validation loss:		0.701596
  validation accuracy:		89.78 %
Epoch 1299 of 2000 took 0.096s
  training loss:		0.089777
  validation loss:		0.768031
  validation accuracy:		89.13 %
Epoch 1300 of 2000 took 0.096s
  training loss:		0.081858
  validation loss:		0.747281
  validation accuracy:		89.24 %
Epoch 1301 of 2000 took 0.096s
  training loss:		0.078986
  validation loss:		0.739492
  validation accuracy:		89.35 %
Epoch 1302 of 2000 took 0.097s
  training loss:		0.077208
  validation loss:		0.709838
  validation accuracy:		89.78 %
Epoch 1303 of 2000 took 0.096s
  training loss:		0.077306
  validation loss:		0.743358
  validation accuracy:		89.35 %
Epoch 1304 of 2000 took 0.096s
  training loss:		0.075717
  validation loss:		0.754739
  validation accuracy:		89.02 %
Epoch 1305 of 2000 took 0.096s
  training loss:		0.085431
  validation loss:		0.698646
  validation accuracy:		90.22 %
Epoch 1306 of 2000 took 0.096s
  training loss:		0.095779
  validation loss:		0.776507
  validation accuracy:		88.37 %
Epoch 1307 of 2000 took 0.096s
  training loss:		0.080576
  validation loss:		0.717038
  validation accuracy:		89.46 %
Epoch 1308 of 2000 took 0.096s
  training loss:		0.078985
  validation loss:		0.684639
  validation accuracy:		90.22 %
Epoch 1309 of 2000 took 0.096s
  training loss:		0.076158
  validation loss:		0.721187
  validation accuracy:		89.13 %
Epoch 1310 of 2000 took 0.096s
  training loss:		0.081946
  validation loss:		0.787673
  validation accuracy:		88.80 %
Epoch 1311 of 2000 took 0.096s
  training loss:		0.081358
  validation loss:		0.710203
  validation accuracy:		90.22 %
Epoch 1312 of 2000 took 0.096s
  training loss:		0.078239
  validation loss:		0.740214
  validation accuracy:		89.89 %
Epoch 1313 of 2000 took 0.096s
  training loss:		0.078183
  validation loss:		0.734808
  validation accuracy:		90.22 %
Epoch 1314 of 2000 took 0.096s
  training loss:		0.072169
  validation loss:		0.732594
  validation accuracy:		89.67 %
Epoch 1315 of 2000 took 0.096s
  training loss:		0.087405
  validation loss:		0.751232
  validation accuracy:		88.91 %
Epoch 1316 of 2000 took 0.096s
  training loss:		0.084194
  validation loss:		0.705406
  validation accuracy:		89.78 %
Epoch 1317 of 2000 took 0.096s
  training loss:		0.072026
  validation loss:		0.764287
  validation accuracy:		89.46 %
Epoch 1318 of 2000 took 0.096s
  training loss:		0.081762
  validation loss:		0.770863
  validation accuracy:		88.70 %
Epoch 1319 of 2000 took 0.096s
  training loss:		0.087436
  validation loss:		0.748275
  validation accuracy:		89.13 %
Epoch 1320 of 2000 took 0.096s
  training loss:		0.086340
  validation loss:		0.756314
  validation accuracy:		89.13 %
Epoch 1321 of 2000 took 0.096s
  training loss:		0.073236
  validation loss:		0.744413
  validation accuracy:		89.78 %
Epoch 1322 of 2000 took 0.096s
  training loss:		0.070306
  validation loss:		0.756133
  validation accuracy:		89.24 %
Epoch 1323 of 2000 took 0.096s
  training loss:		0.078112
  validation loss:		0.779718
  validation accuracy:		89.02 %
Epoch 1324 of 2000 took 0.096s
  training loss:		0.080985
  validation loss:		0.724096
  validation accuracy:		90.11 %
Epoch 1325 of 2000 took 0.097s
  training loss:		0.069187
  validation loss:		0.752985
  validation accuracy:		90.00 %
Epoch 1326 of 2000 took 0.096s
  training loss:		0.078170
  validation loss:		0.735297
  validation accuracy:		89.57 %
Epoch 1327 of 2000 took 0.096s
  training loss:		0.067950
  validation loss:		0.764136
  validation accuracy:		89.02 %
Epoch 1328 of 2000 took 0.096s
  training loss:		0.079194
  validation loss:		0.737505
  validation accuracy:		89.46 %
Epoch 1329 of 2000 took 0.096s
  training loss:		0.111151
  validation loss:		0.795380
  validation accuracy:		88.48 %
Epoch 1330 of 2000 took 0.096s
  training loss:		0.098267
  validation loss:		0.754657
  validation accuracy:		89.46 %
Epoch 1331 of 2000 took 0.096s
  training loss:		0.068196
  validation loss:		0.713533
  validation accuracy:		90.33 %
Epoch 1332 of 2000 took 0.096s
  training loss:		0.073607
  validation loss:		0.742694
  validation accuracy:		89.46 %
Epoch 1333 of 2000 took 0.096s
  training loss:		0.076130
  validation loss:		0.822632
  validation accuracy:		88.26 %
Epoch 1334 of 2000 took 0.096s
  training loss:		0.085249
  validation loss:		0.745398
  validation accuracy:		89.02 %
Epoch 1335 of 2000 took 0.096s
  training loss:		0.086396
  validation loss:		0.734410
  validation accuracy:		89.89 %
Epoch 1336 of 2000 took 0.096s
  training loss:		0.079452
  validation loss:		0.734335
  validation accuracy:		89.89 %
Epoch 1337 of 2000 took 0.096s
  training loss:		0.072016
  validation loss:		0.750809
  validation accuracy:		89.67 %
Epoch 1338 of 2000 took 0.096s
  training loss:		0.068536
  validation loss:		0.763545
  validation accuracy:		89.78 %
Epoch 1339 of 2000 took 0.096s
  training loss:		0.074502
  validation loss:		0.756967
  validation accuracy:		89.02 %
Epoch 1340 of 2000 took 0.096s
  training loss:		0.070497
  validation loss:		0.762628
  validation accuracy:		89.57 %
Epoch 1341 of 2000 took 0.096s
  training loss:		0.085406
  validation loss:		0.739372
  validation accuracy:		89.57 %
Epoch 1342 of 2000 took 0.096s
  training loss:		0.079402
  validation loss:		0.749568
  validation accuracy:		89.46 %
Epoch 1343 of 2000 took 0.096s
  training loss:		0.086820
  validation loss:		0.738323
  validation accuracy:		89.89 %
Epoch 1344 of 2000 took 0.096s
  training loss:		0.076267
  validation loss:		0.791118
  validation accuracy:		88.59 %
Epoch 1345 of 2000 took 0.096s
  training loss:		0.071249
  validation loss:		0.772222
  validation accuracy:		89.57 %
Epoch 1346 of 2000 took 0.096s
  training loss:		0.069906
  validation loss:		0.757366
  validation accuracy:		89.57 %
Epoch 1347 of 2000 took 0.096s
  training loss:		0.081198
  validation loss:		0.744324
  validation accuracy:		89.57 %
Epoch 1348 of 2000 took 0.096s
  training loss:		0.074185
  validation loss:		0.772616
  validation accuracy:		89.78 %
Epoch 1349 of 2000 took 0.096s
  training loss:		0.079831
  validation loss:		0.816247
  validation accuracy:		88.15 %
Epoch 1350 of 2000 took 0.096s
  training loss:		0.089799
  validation loss:		0.734105
  validation accuracy:		89.46 %
Epoch 1351 of 2000 took 0.096s
  training loss:		0.076730
  validation loss:		0.754911
  validation accuracy:		89.57 %
Epoch 1352 of 2000 took 0.096s
  training loss:		0.091026
  validation loss:		0.756050
  validation accuracy:		89.46 %
Epoch 1353 of 2000 took 0.096s
  training loss:		0.063555
  validation loss:		0.741020
  validation accuracy:		89.57 %
Epoch 1354 of 2000 took 0.096s
  training loss:		0.069769
  validation loss:		0.753907
  validation accuracy:		89.24 %
Epoch 1355 of 2000 took 0.096s
  training loss:		0.090594
  validation loss:		0.776683
  validation accuracy:		88.91 %
Epoch 1356 of 2000 took 0.097s
  training loss:		0.087386
  validation loss:		0.768056
  validation accuracy:		89.57 %
Epoch 1357 of 2000 took 0.096s
  training loss:		0.079882
  validation loss:		0.735477
  validation accuracy:		89.46 %
Epoch 1358 of 2000 took 0.096s
  training loss:		0.072057
  validation loss:		0.740592
  validation accuracy:		89.78 %
Epoch 1359 of 2000 took 0.096s
  training loss:		0.079145
  validation loss:		0.776038
  validation accuracy:		89.24 %
Epoch 1360 of 2000 took 0.096s
  training loss:		0.080921
  validation loss:		0.730195
  validation accuracy:		89.46 %
Epoch 1361 of 2000 took 0.096s
  training loss:		0.093360
  validation loss:		0.757222
  validation accuracy:		89.46 %
Epoch 1362 of 2000 took 0.096s
  training loss:		0.076716
  validation loss:		0.730976
  validation accuracy:		90.54 %
Epoch 1363 of 2000 took 0.096s
  training loss:		0.067561
  validation loss:		0.759131
  validation accuracy:		89.46 %
Epoch 1364 of 2000 took 0.096s
  training loss:		0.072277
  validation loss:		0.764238
  validation accuracy:		89.67 %
Epoch 1365 of 2000 took 0.096s
  training loss:		0.076766
  validation loss:		0.743325
  validation accuracy:		90.11 %
Epoch 1366 of 2000 took 0.096s
  training loss:		0.070500
  validation loss:		0.792868
  validation accuracy:		88.70 %
Epoch 1367 of 2000 took 0.096s
  training loss:		0.077639
  validation loss:		0.764438
  validation accuracy:		89.57 %
Epoch 1368 of 2000 took 0.096s
  training loss:		0.080639
  validation loss:		0.764320
  validation accuracy:		89.35 %
Epoch 1369 of 2000 took 0.096s
  training loss:		0.068471
  validation loss:		0.743936
  validation accuracy:		90.00 %
Epoch 1370 of 2000 took 0.096s
  training loss:		0.072617
  validation loss:		0.735795
  validation accuracy:		89.78 %
Epoch 1371 of 2000 took 0.096s
  training loss:		0.075167
  validation loss:		0.793105
  validation accuracy:		89.13 %
Epoch 1372 of 2000 took 0.096s
  training loss:		0.080225
  validation loss:		0.722555
  validation accuracy:		89.78 %
Epoch 1373 of 2000 took 0.096s
  training loss:		0.089453
  validation loss:		0.751722
  validation accuracy:		89.46 %
Epoch 1374 of 2000 took 0.096s
  training loss:		0.074892
  validation loss:		0.740503
  validation accuracy:		90.33 %
Epoch 1375 of 2000 took 0.096s
  training loss:		0.081239
  validation loss:		0.849919
  validation accuracy:		88.26 %
Epoch 1376 of 2000 took 0.096s
  training loss:		0.084835
  validation loss:		0.733865
  validation accuracy:		89.78 %
Epoch 1377 of 2000 took 0.096s
  training loss:		0.075468
  validation loss:		0.747522
  validation accuracy:		89.89 %
Epoch 1378 of 2000 took 0.096s
  training loss:		0.085083
  validation loss:		0.751374
  validation accuracy:		89.89 %
Epoch 1379 of 2000 took 0.096s
  training loss:		0.072044
  validation loss:		0.761045
  validation accuracy:		89.78 %
Epoch 1380 of 2000 took 0.096s
  training loss:		0.078875
  validation loss:		0.766008
  validation accuracy:		89.89 %
Epoch 1381 of 2000 took 0.096s
  training loss:		0.071450
  validation loss:		0.751114
  validation accuracy:		89.78 %
Epoch 1382 of 2000 took 0.096s
  training loss:		0.071231
  validation loss:		0.745176
  validation accuracy:		89.89 %
Epoch 1383 of 2000 took 0.096s
  training loss:		0.069000
  validation loss:		0.767909
  validation accuracy:		90.00 %
Epoch 1384 of 2000 took 0.096s
  training loss:		0.078069
  validation loss:		0.780520
  validation accuracy:		89.89 %
Epoch 1385 of 2000 took 0.096s
  training loss:		0.071849
  validation loss:		0.769637
  validation accuracy:		89.35 %
Epoch 1386 of 2000 took 0.096s
  training loss:		0.078500
  validation loss:		0.822874
  validation accuracy:		89.02 %
Epoch 1387 of 2000 took 0.097s
  training loss:		0.091091
  validation loss:		0.762366
  validation accuracy:		89.67 %
Epoch 1388 of 2000 took 0.096s
  training loss:		0.084790
  validation loss:		0.761236
  validation accuracy:		89.67 %
Epoch 1389 of 2000 took 0.096s
  training loss:		0.131387
  validation loss:		0.769619
  validation accuracy:		89.57 %
Epoch 1390 of 2000 took 0.096s
  training loss:		0.081002
  validation loss:		0.743395
  validation accuracy:		90.00 %
Epoch 1391 of 2000 took 0.096s
  training loss:		0.074293
  validation loss:		0.753874
  validation accuracy:		89.67 %
Epoch 1392 of 2000 took 0.096s
  training loss:		0.075211
  validation loss:		0.775879
  validation accuracy:		89.13 %
Epoch 1393 of 2000 took 0.096s
  training loss:		0.072563
  validation loss:		0.794769
  validation accuracy:		88.80 %
Epoch 1394 of 2000 took 0.096s
  training loss:		0.069123
  validation loss:		0.762756
  validation accuracy:		90.11 %
Epoch 1395 of 2000 took 0.096s
  training loss:		0.069744
  validation loss:		0.782605
  validation accuracy:		89.24 %
Epoch 1396 of 2000 took 0.096s
  training loss:		0.071783
  validation loss:		0.766610
  validation accuracy:		89.35 %
Epoch 1397 of 2000 took 0.096s
  training loss:		0.078656
  validation loss:		0.773655
  validation accuracy:		89.46 %
Epoch 1398 of 2000 took 0.096s
  training loss:		0.065109
  validation loss:		0.778395
  validation accuracy:		89.89 %
Epoch 1399 of 2000 took 0.096s
  training loss:		0.074375
  validation loss:		0.772257
  validation accuracy:		89.35 %
Epoch 1400 of 2000 took 0.096s
  training loss:		0.090970
  validation loss:		0.760450
  validation accuracy:		89.46 %
Epoch 1401 of 2000 took 0.096s
  training loss:		0.078782
  validation loss:		0.776740
  validation accuracy:		89.78 %
Epoch 1402 of 2000 took 0.096s
  training loss:		0.092917
  validation loss:		0.813160
  validation accuracy:		88.70 %
Epoch 1403 of 2000 took 0.096s
  training loss:		0.067545
  validation loss:		0.793727
  validation accuracy:		89.24 %
Epoch 1404 of 2000 took 0.096s
  training loss:		0.060773
  validation loss:		0.754584
  validation accuracy:		89.78 %
Epoch 1405 of 2000 took 0.096s
  training loss:		0.071455
  validation loss:		0.781629
  validation accuracy:		89.24 %
Epoch 1406 of 2000 took 0.096s
  training loss:		0.071713
  validation loss:		0.783049
  validation accuracy:		89.02 %
Epoch 1407 of 2000 took 0.096s
  training loss:		0.073695
  validation loss:		0.762598
  validation accuracy:		89.67 %
Epoch 1408 of 2000 took 0.096s
  training loss:		0.083513
  validation loss:		0.788483
  validation accuracy:		89.35 %
Epoch 1409 of 2000 took 0.096s
  training loss:		0.071515
  validation loss:		0.812091
  validation accuracy:		88.80 %
Epoch 1410 of 2000 took 0.096s
  training loss:		0.087251
  validation loss:		0.800658
  validation accuracy:		89.02 %
Epoch 1411 of 2000 took 0.096s
  training loss:		0.095568
  validation loss:		0.945131
  validation accuracy:		87.50 %
Epoch 1412 of 2000 took 0.096s
  training loss:		0.123613
  validation loss:		0.828819
  validation accuracy:		88.59 %
Epoch 1413 of 2000 took 0.096s
  training loss:		0.076937
  validation loss:		0.776940
  validation accuracy:		89.35 %
Epoch 1414 of 2000 took 0.096s
  training loss:		0.081003
  validation loss:		0.762235
  validation accuracy:		89.67 %
Epoch 1415 of 2000 took 0.096s
  training loss:		0.084385
  validation loss:		0.739948
  validation accuracy:		90.33 %
Epoch 1416 of 2000 took 0.096s
  training loss:		0.074909
  validation loss:		0.810152
  validation accuracy:		89.35 %
Epoch 1417 of 2000 took 0.096s
  training loss:		0.111761
  validation loss:		0.770411
  validation accuracy:		90.11 %
Epoch 1418 of 2000 took 0.096s
  training loss:		0.065232
  validation loss:		0.756823
  validation accuracy:		90.22 %
Epoch 1419 of 2000 took 0.097s
  training loss:		0.071461
  validation loss:		0.750696
  validation accuracy:		89.89 %
Epoch 1420 of 2000 took 0.096s
  training loss:		0.064675
  validation loss:		0.770337
  validation accuracy:		89.46 %
Epoch 1421 of 2000 took 0.096s
  training loss:		0.071335
  validation loss:		0.777436
  validation accuracy:		89.67 %
Epoch 1422 of 2000 took 0.096s
  training loss:		0.070511
  validation loss:		0.767809
  validation accuracy:		89.67 %
Epoch 1423 of 2000 took 0.096s
  training loss:		0.072177
  validation loss:		0.811870
  validation accuracy:		89.78 %
Epoch 1424 of 2000 took 0.096s
  training loss:		0.075067
  validation loss:		0.788202
  validation accuracy:		89.35 %
Epoch 1425 of 2000 took 0.096s
  training loss:		0.064702
  validation loss:		0.807637
  validation accuracy:		89.02 %
Epoch 1426 of 2000 took 0.096s
  training loss:		0.074345
  validation loss:		0.786085
  validation accuracy:		89.24 %
Epoch 1427 of 2000 took 0.096s
  training loss:		0.063524
  validation loss:		0.749554
  validation accuracy:		90.33 %
Epoch 1428 of 2000 took 0.096s
  training loss:		0.075198
  validation loss:		0.786900
  validation accuracy:		89.24 %
Epoch 1429 of 2000 took 0.096s
  training loss:		0.076866
  validation loss:		0.795680
  validation accuracy:		89.35 %
Epoch 1430 of 2000 took 0.096s
  training loss:		0.069110
  validation loss:		0.797124
  validation accuracy:		89.57 %
Epoch 1431 of 2000 took 0.096s
  training loss:		0.064942
  validation loss:		0.760529
  validation accuracy:		89.78 %
Epoch 1432 of 2000 took 0.096s
  training loss:		0.100389
  validation loss:		0.867595
  validation accuracy:		88.70 %
Epoch 1433 of 2000 took 0.096s
  training loss:		0.082606
  validation loss:		0.784264
  validation accuracy:		89.67 %
Epoch 1434 of 2000 took 0.096s
  training loss:		0.068588
  validation loss:		0.818957
  validation accuracy:		89.13 %
Epoch 1435 of 2000 took 0.096s
  training loss:		0.069927
  validation loss:		0.771627
  validation accuracy:		89.67 %
Epoch 1436 of 2000 took 0.096s
  training loss:		0.084620
  validation loss:		0.788055
  validation accuracy:		89.78 %
Epoch 1437 of 2000 took 0.096s
  training loss:		0.069658
  validation loss:		0.813600
  validation accuracy:		88.70 %
Epoch 1438 of 2000 took 0.096s
  training loss:		0.064259
  validation loss:		0.812367
  validation accuracy:		89.35 %
Epoch 1439 of 2000 took 0.096s
  training loss:		0.068843
  validation loss:		0.805328
  validation accuracy:		88.91 %
Epoch 1440 of 2000 took 0.096s
  training loss:		0.068471
  validation loss:		0.763285
  validation accuracy:		90.00 %
Epoch 1441 of 2000 took 0.096s
  training loss:		0.075246
  validation loss:		0.826843
  validation accuracy:		89.35 %
Epoch 1442 of 2000 took 0.096s
  training loss:		0.089885
  validation loss:		0.801161
  validation accuracy:		89.35 %
Epoch 1443 of 2000 took 0.096s
  training loss:		0.084236
  validation loss:		0.786233
  validation accuracy:		89.67 %
Epoch 1444 of 2000 took 0.096s
  training loss:		0.068527
  validation loss:		0.810689
  validation accuracy:		89.46 %
Epoch 1445 of 2000 took 0.096s
  training loss:		0.076057
  validation loss:		0.797723
  validation accuracy:		89.46 %
Epoch 1446 of 2000 took 0.096s
  training loss:		0.071611
  validation loss:		0.795717
  validation accuracy:		89.46 %
Epoch 1447 of 2000 took 0.096s
  training loss:		0.069759
  validation loss:		0.781738
  validation accuracy:		89.78 %
Epoch 1448 of 2000 took 0.096s
  training loss:		0.069931
  validation loss:		0.787966
  validation accuracy:		89.89 %
Epoch 1449 of 2000 took 0.096s
  training loss:		0.070374
  validation loss:		0.783463
  validation accuracy:		89.89 %
Epoch 1450 of 2000 took 0.097s
  training loss:		0.073258
  validation loss:		0.807720
  validation accuracy:		89.57 %
Epoch 1451 of 2000 took 0.096s
  training loss:		0.077333
  validation loss:		0.789771
  validation accuracy:		89.57 %
Epoch 1452 of 2000 took 0.096s
  training loss:		0.067772
  validation loss:		0.821336
  validation accuracy:		89.35 %
Epoch 1453 of 2000 took 0.096s
  training loss:		0.071850
  validation loss:		0.790288
  validation accuracy:		89.46 %
Epoch 1454 of 2000 took 0.096s
  training loss:		0.078737
  validation loss:		0.807410
  validation accuracy:		89.67 %
Epoch 1455 of 2000 took 0.096s
  training loss:		0.076130
  validation loss:		0.838458
  validation accuracy:		89.02 %
Epoch 1456 of 2000 took 0.096s
  training loss:		0.076589
  validation loss:		0.803859
  validation accuracy:		89.57 %
Epoch 1457 of 2000 took 0.096s
  training loss:		0.103732
  validation loss:		0.811990
  validation accuracy:		89.24 %
Epoch 1458 of 2000 took 0.096s
  training loss:		0.065910
  validation loss:		0.793666
  validation accuracy:		89.67 %
Epoch 1459 of 2000 took 0.096s
  training loss:		0.063728
  validation loss:		0.772809
  validation accuracy:		90.11 %
Epoch 1460 of 2000 took 0.096s
  training loss:		0.107524
  validation loss:		0.858629
  validation accuracy:		89.24 %
Epoch 1461 of 2000 took 0.096s
  training loss:		0.206560
  validation loss:		0.776505
  validation accuracy:		90.11 %
Epoch 1462 of 2000 took 0.096s
  training loss:		0.071245
  validation loss:		0.777262
  validation accuracy:		90.00 %
Epoch 1463 of 2000 took 0.096s
  training loss:		0.071971
  validation loss:		0.758506
  validation accuracy:		90.22 %
Epoch 1464 of 2000 took 0.096s
  training loss:		0.072750
  validation loss:		0.799122
  validation accuracy:		89.35 %
Epoch 1465 of 2000 took 0.096s
  training loss:		0.093080
  validation loss:		0.835901
  validation accuracy:		89.46 %
Epoch 1466 of 2000 took 0.096s
  training loss:		0.065870
  validation loss:		0.813937
  validation accuracy:		89.57 %
Epoch 1467 of 2000 took 0.096s
  training loss:		0.070798
  validation loss:		0.792962
  validation accuracy:		89.57 %
Epoch 1468 of 2000 took 0.096s
  training loss:		0.066110
  validation loss:		0.801528
  validation accuracy:		89.57 %
Epoch 1469 of 2000 took 0.096s
  training loss:		0.076694
  validation loss:		0.808394
  validation accuracy:		89.57 %
Epoch 1470 of 2000 took 0.096s
  training loss:		0.073759
  validation loss:		0.785250
  validation accuracy:		89.67 %
Epoch 1471 of 2000 took 0.096s
  training loss:		0.068385
  validation loss:		0.876516
  validation accuracy:		88.80 %
Epoch 1472 of 2000 took 0.096s
  training loss:		0.067407
  validation loss:		0.793414
  validation accuracy:		89.89 %
Epoch 1473 of 2000 took 0.096s
  training loss:		0.083428
  validation loss:		0.794413
  validation accuracy:		89.46 %
Epoch 1474 of 2000 took 0.096s
  training loss:		0.072534
  validation loss:		0.805120
  validation accuracy:		89.46 %
Epoch 1475 of 2000 took 0.096s
  training loss:		0.068968
  validation loss:		0.822518
  validation accuracy:		89.35 %
Epoch 1476 of 2000 took 0.096s
  training loss:		0.064107
  validation loss:		0.807004
  validation accuracy:		89.57 %
Epoch 1477 of 2000 took 0.096s
  training loss:		0.073089
  validation loss:		0.847719
  validation accuracy:		88.80 %
Epoch 1478 of 2000 took 0.096s
  training loss:		0.096482
  validation loss:		0.776245
  validation accuracy:		89.89 %
Epoch 1479 of 2000 took 0.096s
  training loss:		0.072737
  validation loss:		0.810956
  validation accuracy:		89.57 %
Epoch 1480 of 2000 took 0.096s
  training loss:		0.072633
  validation loss:		0.834314
  validation accuracy:		89.02 %
Epoch 1481 of 2000 took 0.097s
  training loss:		0.067182
  validation loss:		0.800143
  validation accuracy:		89.67 %
Epoch 1482 of 2000 took 0.096s
  training loss:		0.092931
  validation loss:		0.792906
  validation accuracy:		89.67 %
Epoch 1483 of 2000 took 0.096s
  training loss:		0.070620
  validation loss:		0.818634
  validation accuracy:		89.46 %
Epoch 1484 of 2000 took 0.096s
  training loss:		0.064700
  validation loss:		0.788295
  validation accuracy:		89.67 %
Epoch 1485 of 2000 took 0.096s
  training loss:		0.064679
  validation loss:		0.787303
  validation accuracy:		89.89 %
Epoch 1486 of 2000 took 0.096s
  training loss:		0.067142
  validation loss:		0.802703
  validation accuracy:		89.78 %
Epoch 1487 of 2000 took 0.096s
  training loss:		0.076462
  validation loss:		0.856746
  validation accuracy:		89.24 %
Epoch 1488 of 2000 took 0.096s
  training loss:		0.072732
  validation loss:		0.799670
  validation accuracy:		89.78 %
Epoch 1489 of 2000 took 0.096s
  training loss:		0.069906
  validation loss:		0.798151
  validation accuracy:		89.67 %
Epoch 1490 of 2000 took 0.096s
  training loss:		0.069163
  validation loss:		0.823467
  validation accuracy:		89.35 %
Epoch 1491 of 2000 took 0.096s
  training loss:		0.080872
  validation loss:		0.810188
  validation accuracy:		89.24 %
Epoch 1492 of 2000 took 0.096s
  training loss:		0.068775
  validation loss:		0.817100
  validation accuracy:		89.67 %
Epoch 1493 of 2000 took 0.096s
  training loss:		0.081099
  validation loss:		0.815256
  validation accuracy:		89.13 %
Epoch 1494 of 2000 took 0.096s
  training loss:		0.078289
  validation loss:		0.876780
  validation accuracy:		88.26 %
Epoch 1495 of 2000 took 0.096s
  training loss:		0.083374
  validation loss:		0.789734
  validation accuracy:		90.11 %
Epoch 1496 of 2000 took 0.096s
  training loss:		0.066372
  validation loss:		0.811253
  validation accuracy:		89.67 %
Epoch 1497 of 2000 took 0.096s
  training loss:		0.063643
  validation loss:		0.833616
  validation accuracy:		89.57 %
Epoch 1498 of 2000 took 0.096s
  training loss:		0.069738
  validation loss:		0.828516
  validation accuracy:		89.46 %
Epoch 1499 of 2000 took 0.096s
  training loss:		0.064768
  validation loss:		0.812205
  validation accuracy:		89.78 %
Epoch 1500 of 2000 took 0.096s
  training loss:		0.066077
  validation loss:		0.815339
  validation accuracy:		89.67 %
Epoch 1501 of 2000 took 0.096s
  training loss:		0.063602
  validation loss:		0.835047
  validation accuracy:		88.91 %
Epoch 1502 of 2000 took 0.096s
  training loss:		0.073642
  validation loss:		0.790351
  validation accuracy:		89.89 %
Epoch 1503 of 2000 took 0.096s
  training loss:		0.069461
  validation loss:		0.831209
  validation accuracy:		89.57 %
Epoch 1504 of 2000 took 0.096s
  training loss:		0.072169
  validation loss:		0.861050
  validation accuracy:		88.59 %
Epoch 1505 of 2000 took 0.096s
  training loss:		0.068055
  validation loss:		0.805212
  validation accuracy:		89.57 %
Epoch 1506 of 2000 took 0.096s
  training loss:		0.077036
  validation loss:		0.846833
  validation accuracy:		88.80 %
Epoch 1507 of 2000 took 0.096s
  training loss:		0.078152
  validation loss:		0.836273
  validation accuracy:		89.24 %
Epoch 1508 of 2000 took 0.096s
  training loss:		0.080344
  validation loss:		0.815752
  validation accuracy:		89.57 %
Epoch 1509 of 2000 took 0.096s
  training loss:		0.067126
  validation loss:		0.844572
  validation accuracy:		89.24 %
Epoch 1510 of 2000 took 0.098s
  training loss:		0.086920
  validation loss:		0.816446
  validation accuracy:		89.13 %
Epoch 1511 of 2000 took 0.099s
  training loss:		0.082611
  validation loss:		0.830888
  validation accuracy:		89.57 %
Epoch 1512 of 2000 took 0.099s
  training loss:		0.063769
  validation loss:		0.841368
  validation accuracy:		89.57 %
Epoch 1513 of 2000 took 0.100s
  training loss:		0.062670
  validation loss:		0.794614
  validation accuracy:		89.78 %
Epoch 1514 of 2000 took 0.099s
  training loss:		0.078265
  validation loss:		0.794203
  validation accuracy:		89.89 %
Epoch 1515 of 2000 took 0.099s
  training loss:		0.073134
  validation loss:		0.820462
  validation accuracy:		89.35 %
Epoch 1516 of 2000 took 0.099s
  training loss:		0.073833
  validation loss:		0.800414
  validation accuracy:		89.89 %
Epoch 1517 of 2000 took 0.099s
  training loss:		0.083071
  validation loss:		0.855845
  validation accuracy:		89.35 %
Epoch 1518 of 2000 took 0.099s
  training loss:		0.071713
  validation loss:		0.790805
  validation accuracy:		89.89 %
Epoch 1519 of 2000 took 0.099s
  training loss:		0.078031
  validation loss:		0.863858
  validation accuracy:		88.15 %
Epoch 1520 of 2000 took 0.099s
  training loss:		0.097163
  validation loss:		0.823959
  validation accuracy:		89.67 %
Epoch 1521 of 2000 took 0.099s
  training loss:		0.065867
  validation loss:		0.912140
  validation accuracy:		88.37 %
Epoch 1522 of 2000 took 0.099s
  training loss:		0.093253
  validation loss:		0.839980
  validation accuracy:		89.35 %
Epoch 1523 of 2000 took 0.099s
  training loss:		0.065716
  validation loss:		0.829167
  validation accuracy:		89.57 %
Epoch 1524 of 2000 took 0.099s
  training loss:		0.074308
  validation loss:		0.868644
  validation accuracy:		88.37 %
Epoch 1525 of 2000 took 0.099s
  training loss:		0.078358
  validation loss:		0.881279
  validation accuracy:		88.59 %
Epoch 1526 of 2000 took 0.099s
  training loss:		0.073052
  validation loss:		0.810646
  validation accuracy:		89.57 %
Epoch 1527 of 2000 took 0.099s
  training loss:		0.066550
  validation loss:		0.861531
  validation accuracy:		89.24 %
Epoch 1528 of 2000 took 0.099s
  training loss:		0.080788
  validation loss:		0.866192
  validation accuracy:		88.80 %
Epoch 1529 of 2000 took 0.099s
  training loss:		0.073186
  validation loss:		0.834336
  validation accuracy:		89.46 %
Epoch 1530 of 2000 took 0.099s
  training loss:		0.067890
  validation loss:		0.850857
  validation accuracy:		89.35 %
Epoch 1531 of 2000 took 0.099s
  training loss:		0.071269
  validation loss:		0.817049
  validation accuracy:		89.46 %
Epoch 1532 of 2000 took 0.099s
  training loss:		0.064028
  validation loss:		0.827391
  validation accuracy:		89.46 %
Epoch 1533 of 2000 took 0.099s
  training loss:		0.062039
  validation loss:		0.816147
  validation accuracy:		90.22 %
Epoch 1534 of 2000 took 0.099s
  training loss:		0.082122
  validation loss:		0.882362
  validation accuracy:		88.80 %
Epoch 1535 of 2000 took 0.099s
  training loss:		0.098608
  validation loss:		0.842457
  validation accuracy:		89.35 %
Epoch 1536 of 2000 took 0.099s
  training loss:		0.073844
  validation loss:		0.881916
  validation accuracy:		88.70 %
Epoch 1537 of 2000 took 0.099s
  training loss:		0.085062
  validation loss:		0.798705
  validation accuracy:		89.89 %
Epoch 1538 of 2000 took 0.099s
  training loss:		0.076851
  validation loss:		0.840651
  validation accuracy:		89.02 %
Epoch 1539 of 2000 took 0.099s
  training loss:		0.072019
  validation loss:		0.850834
  validation accuracy:		88.91 %
Epoch 1540 of 2000 took 0.099s
  training loss:		0.060132
  validation loss:		0.844382
  validation accuracy:		89.35 %
Epoch 1541 of 2000 took 0.099s
  training loss:		0.070877
  validation loss:		0.840336
  validation accuracy:		89.46 %
Epoch 1542 of 2000 took 0.099s
  training loss:		0.062601
  validation loss:		0.880551
  validation accuracy:		89.02 %
Epoch 1543 of 2000 took 0.100s
  training loss:		0.069794
  validation loss:		0.833448
  validation accuracy:		89.67 %
Epoch 1544 of 2000 took 0.099s
  training loss:		0.080919
  validation loss:		0.817179
  validation accuracy:		89.67 %
Epoch 1545 of 2000 took 0.099s
  training loss:		0.063103
  validation loss:		0.810573
  validation accuracy:		89.67 %
Epoch 1546 of 2000 took 0.099s
  training loss:		0.080669
  validation loss:		0.841483
  validation accuracy:		89.24 %
Epoch 1547 of 2000 took 0.099s
  training loss:		0.075956
  validation loss:		0.846074
  validation accuracy:		89.13 %
Epoch 1548 of 2000 took 0.099s
  training loss:		0.073564
  validation loss:		0.844802
  validation accuracy:		89.24 %
Epoch 1549 of 2000 took 0.099s
  training loss:		0.123533
  validation loss:		0.825947
  validation accuracy:		89.57 %
Epoch 1550 of 2000 took 0.099s
  training loss:		0.078973
  validation loss:		0.855376
  validation accuracy:		89.13 %
Epoch 1551 of 2000 took 0.096s
  training loss:		0.083495
  validation loss:		0.814156
  validation accuracy:		89.78 %
Epoch 1552 of 2000 took 0.096s
  training loss:		0.075432
  validation loss:		0.847062
  validation accuracy:		89.13 %
Epoch 1553 of 2000 took 0.096s
  training loss:		0.068128
  validation loss:		0.825416
  validation accuracy:		89.67 %
Epoch 1554 of 2000 took 0.096s
  training loss:		0.088897
  validation loss:		0.855855
  validation accuracy:		89.35 %
Epoch 1555 of 2000 took 0.096s
  training loss:		0.069586
  validation loss:		0.876222
  validation accuracy:		88.91 %
Epoch 1556 of 2000 took 0.096s
  training loss:		0.066929
  validation loss:		0.854810
  validation accuracy:		89.24 %
Epoch 1557 of 2000 took 0.096s
  training loss:		0.074290
  validation loss:		0.843281
  validation accuracy:		89.46 %
Epoch 1558 of 2000 took 0.096s
  training loss:		0.066543
  validation loss:		0.896872
  validation accuracy:		88.91 %
Epoch 1559 of 2000 took 0.096s
  training loss:		0.094655
  validation loss:		0.826281
  validation accuracy:		89.78 %
Epoch 1560 of 2000 took 0.096s
  training loss:		0.073235
  validation loss:		0.870706
  validation accuracy:		89.35 %
Epoch 1561 of 2000 took 0.096s
  training loss:		0.069952
  validation loss:		0.811840
  validation accuracy:		90.43 %
Epoch 1562 of 2000 took 0.096s
  training loss:		0.066441
  validation loss:		0.828712
  validation accuracy:		89.57 %
Epoch 1563 of 2000 took 0.096s
  training loss:		0.059761
  validation loss:		0.870246
  validation accuracy:		88.91 %
Epoch 1564 of 2000 took 0.096s
  training loss:		0.068183
  validation loss:		0.861956
  validation accuracy:		89.13 %
Epoch 1565 of 2000 took 0.096s
  training loss:		0.069123
  validation loss:		0.831828
  validation accuracy:		89.67 %
Epoch 1566 of 2000 took 0.096s
  training loss:		0.078676
  validation loss:		0.845041
  validation accuracy:		89.78 %
Epoch 1567 of 2000 took 0.096s
  training loss:		0.095579
  validation loss:		0.911259
  validation accuracy:		88.37 %
Epoch 1568 of 2000 took 0.096s
  training loss:		0.075372
  validation loss:		0.854679
  validation accuracy:		89.24 %
Epoch 1569 of 2000 took 0.096s
  training loss:		0.064935
  validation loss:		0.846694
  validation accuracy:		89.67 %
Epoch 1570 of 2000 took 0.096s
  training loss:		0.088454
  validation loss:		0.833167
  validation accuracy:		89.67 %
Epoch 1571 of 2000 took 0.096s
  training loss:		0.072679
  validation loss:		0.906430
  validation accuracy:		89.13 %
Epoch 1572 of 2000 took 0.096s
  training loss:		0.070062
  validation loss:		0.860074
  validation accuracy:		89.35 %
Epoch 1573 of 2000 took 0.096s
  training loss:		0.063152
  validation loss:		0.864050
  validation accuracy:		89.67 %
Epoch 1574 of 2000 took 0.097s
  training loss:		0.077195
  validation loss:		0.840242
  validation accuracy:		89.57 %
Epoch 1575 of 2000 took 0.096s
  training loss:		0.072648
  validation loss:		0.852295
  validation accuracy:		89.67 %
Epoch 1576 of 2000 took 0.096s
  training loss:		0.069838
  validation loss:		0.831505
  validation accuracy:		89.67 %
Epoch 1577 of 2000 took 0.096s
  training loss:		0.075476
  validation loss:		0.819891
  validation accuracy:		90.00 %
Epoch 1578 of 2000 took 0.096s
  training loss:		0.076558
  validation loss:		0.832658
  validation accuracy:		89.78 %
Epoch 1579 of 2000 took 0.096s
  training loss:		0.068429
  validation loss:		0.851764
  validation accuracy:		89.46 %
Epoch 1580 of 2000 took 0.096s
  training loss:		0.060204
  validation loss:		0.828971
  validation accuracy:		89.78 %
Epoch 1581 of 2000 took 0.096s
  training loss:		0.075773
  validation loss:		0.842681
  validation accuracy:		90.00 %
Epoch 1582 of 2000 took 0.096s
  training loss:		0.082148
  validation loss:		0.866086
  validation accuracy:		89.02 %
Epoch 1583 of 2000 took 0.096s
  training loss:		0.061871
  validation loss:		0.872976
  validation accuracy:		89.02 %
Epoch 1584 of 2000 took 0.096s
  training loss:		0.092166
  validation loss:		0.877428
  validation accuracy:		89.02 %
Epoch 1585 of 2000 took 0.096s
  training loss:		0.068327
  validation loss:		0.832954
  validation accuracy:		89.89 %
Epoch 1586 of 2000 took 0.096s
  training loss:		0.062076
  validation loss:		0.884474
  validation accuracy:		89.35 %
Epoch 1587 of 2000 took 0.096s
  training loss:		0.060138
  validation loss:		0.853486
  validation accuracy:		89.46 %
Epoch 1588 of 2000 took 0.096s
  training loss:		0.084363
  validation loss:		0.843700
  validation accuracy:		89.57 %
Epoch 1589 of 2000 took 0.096s
  training loss:		0.063820
  validation loss:		0.847639
  validation accuracy:		89.67 %
Epoch 1590 of 2000 took 0.096s
  training loss:		0.071241
  validation loss:		0.880336
  validation accuracy:		88.91 %
Epoch 1591 of 2000 took 0.096s
  training loss:		0.077603
  validation loss:		0.863811
  validation accuracy:		89.35 %
Epoch 1592 of 2000 took 0.096s
  training loss:		0.070611
  validation loss:		0.855466
  validation accuracy:		89.02 %
Epoch 1593 of 2000 took 0.096s
  training loss:		0.076003
  validation loss:		0.892370
  validation accuracy:		89.13 %
Epoch 1594 of 2000 took 0.096s
  training loss:		0.073627
  validation loss:		0.850342
  validation accuracy:		89.78 %
Epoch 1595 of 2000 took 0.096s
  training loss:		0.079725
  validation loss:		0.828093
  validation accuracy:		90.33 %
Epoch 1596 of 2000 took 0.096s
  training loss:		0.076451
  validation loss:		0.807068
  validation accuracy:		90.11 %
Epoch 1597 of 2000 took 0.096s
  training loss:		0.069806
  validation loss:		0.841910
  validation accuracy:		89.78 %
Epoch 1598 of 2000 took 0.096s
  training loss:		0.063587
  validation loss:		0.877817
  validation accuracy:		89.35 %
Epoch 1599 of 2000 took 0.096s
  training loss:		0.114252
  validation loss:		0.845330
  validation accuracy:		89.57 %
Epoch 1600 of 2000 took 0.096s
  training loss:		0.064319
  validation loss:		0.890448
  validation accuracy:		88.91 %
Epoch 1601 of 2000 took 0.096s
  training loss:		0.074852
  validation loss:		0.848125
  validation accuracy:		89.35 %
Epoch 1602 of 2000 took 0.096s
  training loss:		0.079897
  validation loss:		0.982666
  validation accuracy:		88.37 %
Epoch 1603 of 2000 took 0.096s
  training loss:		0.082722
  validation loss:		0.816334
  validation accuracy:		89.67 %
Epoch 1604 of 2000 took 0.096s
  training loss:		0.071932
  validation loss:		0.869145
  validation accuracy:		89.35 %
Epoch 1605 of 2000 took 0.096s
  training loss:		0.070021
  validation loss:		0.860244
  validation accuracy:		89.89 %
Epoch 1606 of 2000 took 0.097s
  training loss:		0.078091
  validation loss:		0.869008
  validation accuracy:		89.02 %
Epoch 1607 of 2000 took 0.096s
  training loss:		0.073301
  validation loss:		0.888272
  validation accuracy:		89.02 %
Epoch 1608 of 2000 took 0.096s
  training loss:		0.071369
  validation loss:		0.874807
  validation accuracy:		89.67 %
Epoch 1609 of 2000 took 0.096s
  training loss:		0.064114
  validation loss:		0.847593
  validation accuracy:		89.89 %
Epoch 1610 of 2000 took 0.096s
  training loss:		0.065257
  validation loss:		0.845458
  validation accuracy:		89.67 %
Epoch 1611 of 2000 took 0.096s
  training loss:		0.074825
  validation loss:		0.911716
  validation accuracy:		89.57 %
Epoch 1612 of 2000 took 0.096s
  training loss:		0.137138
  validation loss:		0.847578
  validation accuracy:		89.46 %
Epoch 1613 of 2000 took 0.096s
  training loss:		0.067517
  validation loss:		0.868050
  validation accuracy:		89.35 %
Epoch 1614 of 2000 took 0.096s
  training loss:		0.069578
  validation loss:		0.854836
  validation accuracy:		89.57 %
Epoch 1615 of 2000 took 0.096s
  training loss:		0.075072
  validation loss:		0.827958
  validation accuracy:		90.11 %
Epoch 1616 of 2000 took 0.096s
  training loss:		0.060017
  validation loss:		0.844011
  validation accuracy:		90.11 %
Epoch 1617 of 2000 took 0.096s
  training loss:		0.062221
  validation loss:		0.871120
  validation accuracy:		89.57 %
Epoch 1618 of 2000 took 0.096s
  training loss:		0.070938
  validation loss:		0.868481
  validation accuracy:		89.13 %
Epoch 1619 of 2000 took 0.096s
  training loss:		0.060340
  validation loss:		0.856779
  validation accuracy:		89.78 %
Epoch 1620 of 2000 took 0.096s
  training loss:		0.065013
  validation loss:		0.848196
  validation accuracy:		90.00 %
Epoch 1621 of 2000 took 0.096s
  training loss:		0.087675
  validation loss:		0.852364
  validation accuracy:		88.91 %
Epoch 1622 of 2000 took 0.096s
  training loss:		0.067872
  validation loss:		0.841003
  validation accuracy:		89.78 %
Epoch 1623 of 2000 took 0.096s
  training loss:		0.067989
  validation loss:		0.887607
  validation accuracy:		88.91 %
Epoch 1624 of 2000 took 0.096s
  training loss:		0.065146
  validation loss:		0.851908
  validation accuracy:		89.67 %
Epoch 1625 of 2000 took 0.096s
  training loss:		0.066446
  validation loss:		0.881349
  validation accuracy:		89.46 %
Epoch 1626 of 2000 took 0.096s
  training loss:		0.078273
  validation loss:		0.876837
  validation accuracy:		89.24 %
Epoch 1627 of 2000 took 0.096s
  training loss:		0.130799
  validation loss:		0.949101
  validation accuracy:		88.70 %
Epoch 1628 of 2000 took 0.096s
  training loss:		0.083518
  validation loss:		0.836994
  validation accuracy:		89.89 %
Epoch 1629 of 2000 took 0.096s
  training loss:		0.069182
  validation loss:		0.858696
  validation accuracy:		89.57 %
Epoch 1630 of 2000 took 0.096s
  training loss:		0.065156
  validation loss:		0.852171
  validation accuracy:		90.00 %
Epoch 1631 of 2000 took 0.096s
  training loss:		0.118029
  validation loss:		0.868015
  validation accuracy:		89.57 %
Epoch 1632 of 2000 took 0.096s
  training loss:		0.067285
  validation loss:		0.832199
  validation accuracy:		90.00 %
Epoch 1633 of 2000 took 0.096s
  training loss:		0.068277
  validation loss:		0.860542
  validation accuracy:		89.35 %
Epoch 1634 of 2000 took 0.096s
  training loss:		0.070112
  validation loss:		0.847082
  validation accuracy:		89.67 %
Epoch 1635 of 2000 took 0.096s
  training loss:		0.062897
  validation loss:		0.835477
  validation accuracy:		89.89 %
Epoch 1636 of 2000 took 0.096s
  training loss:		0.069411
  validation loss:		0.889011
  validation accuracy:		89.13 %
Epoch 1637 of 2000 took 0.097s
  training loss:		0.066232
  validation loss:		0.924135
  validation accuracy:		89.02 %
Epoch 1638 of 2000 took 0.096s
  training loss:		0.089204
  validation loss:		0.857340
  validation accuracy:		89.46 %
Epoch 1639 of 2000 took 0.096s
  training loss:		0.070135
  validation loss:		0.887909
  validation accuracy:		89.35 %
Epoch 1640 of 2000 took 0.096s
  training loss:		0.060376
  validation loss:		0.826432
  validation accuracy:		90.00 %
Epoch 1641 of 2000 took 0.096s
  training loss:		0.069350
  validation loss:		0.857149
  validation accuracy:		89.67 %
Epoch 1642 of 2000 took 0.096s
  training loss:		0.076740
  validation loss:		0.860329
  validation accuracy:		89.89 %
Epoch 1643 of 2000 took 0.096s
  training loss:		0.070062
  validation loss:		0.908973
  validation accuracy:		88.37 %
Epoch 1644 of 2000 took 0.096s
  training loss:		0.100310
  validation loss:		0.878758
  validation accuracy:		89.35 %
Epoch 1645 of 2000 took 0.096s
  training loss:		0.076747
  validation loss:		0.889348
  validation accuracy:		89.57 %
Epoch 1646 of 2000 took 0.096s
  training loss:		0.065008
  validation loss:		0.853639
  validation accuracy:		89.57 %
Epoch 1647 of 2000 took 0.096s
  training loss:		0.079961
  validation loss:		0.899044
  validation accuracy:		88.70 %
Epoch 1648 of 2000 took 0.096s
  training loss:		0.089922
  validation loss:		0.877366
  validation accuracy:		89.57 %
Epoch 1649 of 2000 took 0.096s
  training loss:		0.065328
  validation loss:		0.870255
  validation accuracy:		89.35 %
Epoch 1650 of 2000 took 0.096s
  training loss:		0.075979
  validation loss:		0.883316
  validation accuracy:		89.24 %
Epoch 1651 of 2000 took 0.096s
  training loss:		0.067314
  validation loss:		0.867047
  validation accuracy:		89.78 %
Epoch 1652 of 2000 took 0.096s
  training loss:		0.073027
  validation loss:		0.842505
  validation accuracy:		89.78 %
Epoch 1653 of 2000 took 0.096s
  training loss:		0.078683
  validation loss:		0.937662
  validation accuracy:		88.37 %
Epoch 1654 of 2000 took 0.096s
  training loss:		0.085459
  validation loss:		0.858804
  validation accuracy:		89.57 %
Epoch 1655 of 2000 took 0.096s
  training loss:		0.065284
  validation loss:		0.865559
  validation accuracy:		89.67 %
Epoch 1656 of 2000 took 0.096s
  training loss:		0.069195
  validation loss:		0.841219
  validation accuracy:		89.89 %
Epoch 1657 of 2000 took 0.096s
  training loss:		0.066837
  validation loss:		0.876177
  validation accuracy:		89.13 %
Epoch 1658 of 2000 took 0.096s
  training loss:		0.064711
  validation loss:		0.878157
  validation accuracy:		89.24 %
Epoch 1659 of 2000 took 0.096s
  training loss:		0.083544
  validation loss:		0.888982
  validation accuracy:		89.13 %
Epoch 1660 of 2000 took 0.096s
  training loss:		0.077964
  validation loss:		0.836042
  validation accuracy:		89.78 %
Epoch 1661 of 2000 took 0.096s
  training loss:		0.067114
  validation loss:		0.854814
  validation accuracy:		89.57 %
Epoch 1662 of 2000 took 0.096s
  training loss:		0.072293
  validation loss:		0.913579
  validation accuracy:		88.70 %
Epoch 1663 of 2000 took 0.096s
  training loss:		0.076629
  validation loss:		0.861946
  validation accuracy:		89.46 %
Epoch 1664 of 2000 took 0.096s
  training loss:		0.060688
  validation loss:		0.843998
  validation accuracy:		89.78 %
Epoch 1665 of 2000 took 0.096s
  training loss:		0.069847
  validation loss:		0.864234
  validation accuracy:		90.00 %
Epoch 1666 of 2000 took 0.096s
  training loss:		0.063636
  validation loss:		0.916970
  validation accuracy:		88.91 %
Epoch 1667 of 2000 took 0.096s
  training loss:		0.066228
  validation loss:		0.879449
  validation accuracy:		89.24 %
Epoch 1668 of 2000 took 0.097s
  training loss:		0.054353
  validation loss:		0.904562
  validation accuracy:		89.02 %
Epoch 1669 of 2000 took 0.096s
  training loss:		0.067550
  validation loss:		0.936941
  validation accuracy:		88.48 %
Epoch 1670 of 2000 took 0.096s
  training loss:		0.068146
  validation loss:		0.905555
  validation accuracy:		88.91 %
Epoch 1671 of 2000 took 0.096s
  training loss:		0.079704
  validation loss:		0.908071
  validation accuracy:		89.35 %
Epoch 1672 of 2000 took 0.096s
  training loss:		0.082296
  validation loss:		0.877730
  validation accuracy:		89.57 %
Epoch 1673 of 2000 took 0.096s
  training loss:		0.068409
  validation loss:		0.848505
  validation accuracy:		89.89 %
Epoch 1674 of 2000 took 0.096s
  training loss:		0.054304
  validation loss:		0.878959
  validation accuracy:		89.57 %
Epoch 1675 of 2000 took 0.096s
  training loss:		0.059042
  validation loss:		0.881531
  validation accuracy:		89.35 %
Epoch 1676 of 2000 took 0.096s
  training loss:		0.061166
  validation loss:		0.911871
  validation accuracy:		88.91 %
Epoch 1677 of 2000 took 0.096s
  training loss:		0.072442
  validation loss:		0.928207
  validation accuracy:		88.70 %
Epoch 1678 of 2000 took 0.096s
  training loss:		0.211808
  validation loss:		0.856303
  validation accuracy:		89.67 %
Epoch 1679 of 2000 took 0.096s
  training loss:		0.073872
  validation loss:		0.871365
  validation accuracy:		89.13 %
Epoch 1680 of 2000 took 0.096s
  training loss:		0.080110
  validation loss:		1.051836
  validation accuracy:		86.96 %
Epoch 1681 of 2000 took 0.096s
  training loss:		0.096274
  validation loss:		0.891673
  validation accuracy:		89.67 %
Epoch 1682 of 2000 took 0.096s
  training loss:		0.073026
  validation loss:		0.851360
  validation accuracy:		89.89 %
Epoch 1683 of 2000 took 0.096s
  training loss:		0.066642
  validation loss:		0.872522
  validation accuracy:		89.24 %
Epoch 1684 of 2000 took 0.096s
  training loss:		0.072224
  validation loss:		0.884261
  validation accuracy:		89.67 %
Epoch 1685 of 2000 took 0.096s
  training loss:		0.082099
  validation loss:		0.864930
  validation accuracy:		89.67 %
Epoch 1686 of 2000 took 0.096s
  training loss:		0.068320
  validation loss:		0.851970
  validation accuracy:		89.89 %
Epoch 1687 of 2000 took 0.096s
  training loss:		0.064712
  validation loss:		0.861325
  validation accuracy:		89.67 %
Epoch 1688 of 2000 took 0.096s
  training loss:		0.066711
  validation loss:		0.885618
  validation accuracy:		88.91 %
Epoch 1689 of 2000 took 0.096s
  training loss:		0.067182
  validation loss:		0.911564
  validation accuracy:		88.70 %
Epoch 1690 of 2000 took 0.096s
  training loss:		0.061774
  validation loss:		0.884647
  validation accuracy:		89.35 %
Epoch 1691 of 2000 took 0.096s
  training loss:		0.058489
  validation loss:		0.859124
  validation accuracy:		90.11 %
Epoch 1692 of 2000 took 0.096s
  training loss:		0.060396
  validation loss:		0.859146
  validation accuracy:		89.89 %
Epoch 1693 of 2000 took 0.096s
  training loss:		0.063138
  validation loss:		0.881270
  validation accuracy:		90.00 %
Epoch 1694 of 2000 took 0.096s
  training loss:		0.062333
  validation loss:		0.885715
  validation accuracy:		89.13 %
Epoch 1695 of 2000 took 0.096s
  training loss:		0.070489
  validation loss:		0.882184
  validation accuracy:		89.35 %
Epoch 1696 of 2000 took 0.096s
  training loss:		0.067189
  validation loss:		1.014669
  validation accuracy:		88.15 %
Epoch 1697 of 2000 took 0.096s
  training loss:		0.076899
  validation loss:		0.872196
  validation accuracy:		90.00 %
Epoch 1698 of 2000 took 0.096s
  training loss:		0.061217
  validation loss:		0.875934
  validation accuracy:		89.57 %
Epoch 1699 of 2000 took 0.096s
  training loss:		0.076685
  validation loss:		0.933531
  validation accuracy:		88.48 %
Epoch 1700 of 2000 took 0.097s
  training loss:		0.075795
  validation loss:		0.904538
  validation accuracy:		89.02 %
Epoch 1701 of 2000 took 0.096s
  training loss:		0.113926
  validation loss:		0.852684
  validation accuracy:		89.78 %
Epoch 1702 of 2000 took 0.096s
  training loss:		0.077703
  validation loss:		0.861175
  validation accuracy:		89.57 %
Epoch 1703 of 2000 took 0.096s
  training loss:		0.094170
  validation loss:		0.899267
  validation accuracy:		89.13 %
Epoch 1704 of 2000 took 0.096s
  training loss:		0.074206
  validation loss:		0.877522
  validation accuracy:		89.57 %
Epoch 1705 of 2000 took 0.096s
  training loss:		0.061431
  validation loss:		0.888901
  validation accuracy:		89.35 %
Epoch 1706 of 2000 took 0.096s
  training loss:		0.061694
  validation loss:		0.891442
  validation accuracy:		89.24 %
Epoch 1707 of 2000 took 0.096s
  training loss:		0.073562
  validation loss:		0.883729
  validation accuracy:		89.02 %
Epoch 1708 of 2000 took 0.096s
  training loss:		0.071868
  validation loss:		0.891965
  validation accuracy:		89.67 %
Epoch 1709 of 2000 took 0.096s
  training loss:		0.063368
  validation loss:		0.904535
  validation accuracy:		89.67 %
Epoch 1710 of 2000 took 0.096s
  training loss:		0.068372
  validation loss:		0.904947
  validation accuracy:		89.24 %
Epoch 1711 of 2000 took 0.096s
  training loss:		0.063814
  validation loss:		0.904404
  validation accuracy:		89.02 %
Epoch 1712 of 2000 took 0.096s
  training loss:		0.076754
  validation loss:		0.889804
  validation accuracy:		89.24 %
Epoch 1713 of 2000 took 0.096s
  training loss:		0.060762
  validation loss:		0.927844
  validation accuracy:		89.02 %
Epoch 1714 of 2000 took 0.096s
  training loss:		0.067720
  validation loss:		0.868314
  validation accuracy:		89.78 %
Epoch 1715 of 2000 took 0.096s
  training loss:		0.078946
  validation loss:		0.863099
  validation accuracy:		90.00 %
Epoch 1716 of 2000 took 0.096s
  training loss:		0.071450
  validation loss:		0.887708
  validation accuracy:		89.46 %
Epoch 1717 of 2000 took 0.097s
  training loss:		0.066583
  validation loss:		0.883060
  validation accuracy:		89.67 %
Epoch 1718 of 2000 took 0.096s
  training loss:		0.057509
  validation loss:		0.898770
  validation accuracy:		89.57 %
Epoch 1719 of 2000 took 0.096s
  training loss:		0.060808
  validation loss:		0.865403
  validation accuracy:		89.89 %
Epoch 1720 of 2000 took 0.096s
  training loss:		0.070205
  validation loss:		0.914801
  validation accuracy:		89.46 %
Epoch 1721 of 2000 took 0.096s
  training loss:		0.065957
  validation loss:		0.975936
  validation accuracy:		88.59 %
Epoch 1722 of 2000 took 0.096s
  training loss:		0.124364
  validation loss:		0.881611
  validation accuracy:		89.78 %
Epoch 1723 of 2000 took 0.096s
  training loss:		0.069224
  validation loss:		0.924654
  validation accuracy:		89.35 %
Epoch 1724 of 2000 took 0.096s
  training loss:		0.065569
  validation loss:		0.934862
  validation accuracy:		88.59 %
Epoch 1725 of 2000 took 0.096s
  training loss:		0.076717
  validation loss:		0.923901
  validation accuracy:		89.46 %
Epoch 1726 of 2000 took 0.096s
  training loss:		0.067578
  validation loss:		0.910130
  validation accuracy:		89.24 %
Epoch 1727 of 2000 took 0.096s
  training loss:		0.061261
  validation loss:		0.925360
  validation accuracy:		89.02 %
Epoch 1728 of 2000 took 0.096s
  training loss:		0.064140
  validation loss:		0.895284
  validation accuracy:		89.13 %
Epoch 1729 of 2000 took 0.096s
  training loss:		0.060967
  validation loss:		0.908826
  validation accuracy:		89.24 %
Epoch 1730 of 2000 took 0.096s
  training loss:		0.078637
  validation loss:		0.918705
  validation accuracy:		88.80 %
Epoch 1731 of 2000 took 0.097s
  training loss:		0.058325
  validation loss:		0.917575
  validation accuracy:		89.13 %
Epoch 1732 of 2000 took 0.096s
  training loss:		0.057657
  validation loss:		0.906757
  validation accuracy:		89.57 %
Epoch 1733 of 2000 took 0.096s
  training loss:		0.060486
  validation loss:		0.903662
  validation accuracy:		89.57 %
Epoch 1734 of 2000 took 0.096s
  training loss:		0.064792
  validation loss:		0.895516
  validation accuracy:		89.57 %
Epoch 1735 of 2000 took 0.096s
  training loss:		0.063867
  validation loss:		0.891274
  validation accuracy:		89.57 %
Epoch 1736 of 2000 took 0.096s
  training loss:		0.070193
  validation loss:		1.023283
  validation accuracy:		88.59 %
Epoch 1737 of 2000 took 0.096s
  training loss:		0.094098
  validation loss:		0.925149
  validation accuracy:		89.24 %
Epoch 1738 of 2000 took 0.096s
  training loss:		0.080618
  validation loss:		1.031058
  validation accuracy:		88.48 %
Epoch 1739 of 2000 took 0.096s
  training loss:		0.098874
  validation loss:		0.898666
  validation accuracy:		89.46 %
Epoch 1740 of 2000 took 0.096s
  training loss:		0.062817
  validation loss:		0.886205
  validation accuracy:		89.35 %
Epoch 1741 of 2000 took 0.096s
  training loss:		0.081643
  validation loss:		0.926810
  validation accuracy:		89.24 %
Epoch 1742 of 2000 took 0.096s
  training loss:		0.077618
  validation loss:		0.913894
  validation accuracy:		89.46 %
Epoch 1743 of 2000 took 0.096s
  training loss:		0.061462
  validation loss:		0.865756
  validation accuracy:		89.78 %
Epoch 1744 of 2000 took 0.096s
  training loss:		0.068623
  validation loss:		0.883359
  validation accuracy:		89.57 %
Epoch 1745 of 2000 took 0.096s
  training loss:		0.075028
  validation loss:		0.909215
  validation accuracy:		89.46 %
Epoch 1746 of 2000 took 0.096s
  training loss:		0.079485
  validation loss:		0.891624
  validation accuracy:		89.46 %
Epoch 1747 of 2000 took 0.096s
  training loss:		0.063559
  validation loss:		0.892352
  validation accuracy:		89.35 %
Epoch 1748 of 2000 took 0.096s
  training loss:		0.059716
  validation loss:		0.884739
  validation accuracy:		89.35 %
Epoch 1749 of 2000 took 0.096s
  training loss:		0.067003
  validation loss:		0.909409
  validation accuracy:		89.35 %
Epoch 1750 of 2000 took 0.096s
  training loss:		0.060311
  validation loss:		0.925989
  validation accuracy:		89.13 %
Epoch 1751 of 2000 took 0.096s
  training loss:		0.066448
  validation loss:		0.888671
  validation accuracy:		89.24 %
Epoch 1752 of 2000 took 0.096s
  training loss:		0.062277
  validation loss:		0.885071
  validation accuracy:		89.46 %
Epoch 1753 of 2000 took 0.096s
  training loss:		0.073732
  validation loss:		0.900780
  validation accuracy:		90.00 %
Epoch 1754 of 2000 took 0.096s
  training loss:		0.063646
  validation loss:		0.938854
  validation accuracy:		88.37 %
Epoch 1755 of 2000 took 0.096s
  training loss:		0.090965
  validation loss:		0.897942
  validation accuracy:		89.46 %
Epoch 1756 of 2000 took 0.096s
  training loss:		0.065531
  validation loss:		0.917813
  validation accuracy:		89.35 %
Epoch 1757 of 2000 took 0.096s
  training loss:		0.072202
  validation loss:		0.940405
  validation accuracy:		89.13 %
Epoch 1758 of 2000 took 0.096s
  training loss:		0.064976
  validation loss:		0.944288
  validation accuracy:		88.91 %
Epoch 1759 of 2000 took 0.096s
  training loss:		0.064091
  validation loss:		0.901741
  validation accuracy:		89.67 %
Epoch 1760 of 2000 took 0.096s
  training loss:		0.062858
  validation loss:		0.913727
  validation accuracy:		89.13 %
Epoch 1761 of 2000 took 0.096s
  training loss:		0.069609
  validation loss:		0.904099
  validation accuracy:		89.24 %
Epoch 1762 of 2000 took 0.097s
  training loss:		0.059757
  validation loss:		0.900428
  validation accuracy:		89.57 %
Epoch 1763 of 2000 took 0.096s
  training loss:		0.063144
  validation loss:		0.917352
  validation accuracy:		89.13 %
Epoch 1764 of 2000 took 0.096s
  training loss:		0.075459
  validation loss:		0.989640
  validation accuracy:		88.59 %
Epoch 1765 of 2000 took 0.096s
  training loss:		0.161633
  validation loss:		0.917817
  validation accuracy:		89.13 %
Epoch 1766 of 2000 took 0.096s
  training loss:		0.057133
  validation loss:		0.906726
  validation accuracy:		89.67 %
Epoch 1767 of 2000 took 0.096s
  training loss:		0.057125
  validation loss:		0.935746
  validation accuracy:		88.80 %
Epoch 1768 of 2000 took 0.096s
  training loss:		0.067263
  validation loss:		0.906089
  validation accuracy:		89.35 %
Epoch 1769 of 2000 took 0.096s
  training loss:		0.067982
  validation loss:		0.925561
  validation accuracy:		89.35 %
Epoch 1770 of 2000 took 0.096s
  training loss:		0.086218
  validation loss:		0.939944
  validation accuracy:		88.37 %
Epoch 1771 of 2000 took 0.096s
  training loss:		0.063847
  validation loss:		0.905855
  validation accuracy:		89.35 %
Epoch 1772 of 2000 took 0.096s
  training loss:		0.060121
  validation loss:		0.975037
  validation accuracy:		88.91 %
Epoch 1773 of 2000 took 0.096s
  training loss:		0.061438
  validation loss:		0.892873
  validation accuracy:		89.57 %
Epoch 1774 of 2000 took 0.096s
  training loss:		0.064914
  validation loss:		0.919541
  validation accuracy:		89.35 %
Epoch 1775 of 2000 took 0.096s
  training loss:		0.066923
  validation loss:		0.898595
  validation accuracy:		89.35 %
Epoch 1776 of 2000 took 0.096s
  training loss:		0.071800
  validation loss:		0.897093
  validation accuracy:		89.78 %
Epoch 1777 of 2000 took 0.096s
  training loss:		0.064515
  validation loss:		0.915036
  validation accuracy:		89.24 %
Epoch 1778 of 2000 took 0.096s
  training loss:		0.058631
  validation loss:		0.933859
  validation accuracy:		89.13 %
Epoch 1779 of 2000 took 0.096s
  training loss:		0.070169
  validation loss:		0.941775
  validation accuracy:		89.13 %
Epoch 1780 of 2000 took 0.096s
  training loss:		0.071377
  validation loss:		0.911093
  validation accuracy:		89.57 %
Epoch 1781 of 2000 took 0.096s
  training loss:		0.061394
  validation loss:		0.924978
  validation accuracy:		89.02 %
Epoch 1782 of 2000 took 0.096s
  training loss:		0.060502
  validation loss:		0.905571
  validation accuracy:		89.57 %
Epoch 1783 of 2000 took 0.096s
  training loss:		0.059142
  validation loss:		0.920105
  validation accuracy:		89.67 %
Epoch 1784 of 2000 took 0.096s
  training loss:		0.073871
  validation loss:		0.940435
  validation accuracy:		89.13 %
Epoch 1785 of 2000 took 0.096s
  training loss:		0.061423
  validation loss:		0.901481
  validation accuracy:		89.89 %
Epoch 1786 of 2000 took 0.096s
  training loss:		0.062129
  validation loss:		0.916416
  validation accuracy:		89.35 %
Epoch 1787 of 2000 took 0.096s
  training loss:		0.097949
  validation loss:		1.077014
  validation accuracy:		88.15 %
Epoch 1788 of 2000 took 0.096s
  training loss:		0.080311
  validation loss:		0.932234
  validation accuracy:		88.91 %
Epoch 1789 of 2000 took 0.096s
  training loss:		0.064012
  validation loss:		0.935172
  validation accuracy:		89.35 %
Epoch 1790 of 2000 took 0.096s
  training loss:		0.061396
  validation loss:		0.926920
  validation accuracy:		89.13 %
Epoch 1791 of 2000 took 0.096s
  training loss:		0.064275
  validation loss:		0.909290
  validation accuracy:		89.46 %
Epoch 1792 of 2000 took 0.096s
  training loss:		0.065854
  validation loss:		0.941838
  validation accuracy:		88.80 %
Epoch 1793 of 2000 took 0.096s
  training loss:		0.066445
  validation loss:		0.888338
  validation accuracy:		89.78 %
Epoch 1794 of 2000 took 0.097s
  training loss:		0.063421
  validation loss:		0.945491
  validation accuracy:		89.02 %
Epoch 1795 of 2000 took 0.096s
  training loss:		0.067387
  validation loss:		0.905879
  validation accuracy:		89.35 %
Epoch 1796 of 2000 took 0.096s
  training loss:		0.061900
  validation loss:		0.932593
  validation accuracy:		89.57 %
Epoch 1797 of 2000 took 0.096s
  training loss:		0.062229
  validation loss:		0.922558
  validation accuracy:		89.24 %
Epoch 1798 of 2000 took 0.096s
  training loss:		0.072952
  validation loss:		0.975246
  validation accuracy:		89.02 %
Epoch 1799 of 2000 took 0.096s
  training loss:		0.059180
  validation loss:		0.913230
  validation accuracy:		89.46 %
Epoch 1800 of 2000 took 0.096s
  training loss:		0.059467
  validation loss:		0.931344
  validation accuracy:		88.80 %
Epoch 1801 of 2000 took 0.096s
  training loss:		0.069131
  validation loss:		0.911813
  validation accuracy:		89.78 %
Epoch 1802 of 2000 took 0.096s
  training loss:		0.073987
  validation loss:		0.889362
  validation accuracy:		89.89 %
Epoch 1803 of 2000 took 0.096s
  training loss:		0.060952
  validation loss:		0.948935
  validation accuracy:		88.80 %
Epoch 1804 of 2000 took 0.096s
  training loss:		0.068709
  validation loss:		0.981331
  validation accuracy:		88.59 %
Epoch 1805 of 2000 took 0.096s
  training loss:		0.067546
  validation loss:		0.995771
  validation accuracy:		88.80 %
Epoch 1806 of 2000 took 0.096s
  training loss:		0.096680
  validation loss:		0.911533
  validation accuracy:		89.57 %
Epoch 1807 of 2000 took 0.096s
  training loss:		0.063565
  validation loss:		0.913419
  validation accuracy:		89.35 %
Epoch 1808 of 2000 took 0.096s
  training loss:		0.056893
  validation loss:		0.916874
  validation accuracy:		89.57 %
Epoch 1809 of 2000 took 0.096s
  training loss:		0.056791
  validation loss:		0.975296
  validation accuracy:		89.13 %
Epoch 1810 of 2000 took 0.096s
  training loss:		0.086305
  validation loss:		0.935016
  validation accuracy:		89.13 %
Epoch 1811 of 2000 took 0.096s
  training loss:		0.068479
  validation loss:		0.943966
  validation accuracy:		89.46 %
Epoch 1812 of 2000 took 0.096s
  training loss:		0.062226
  validation loss:		0.946898
  validation accuracy:		88.80 %
Epoch 1813 of 2000 took 0.096s
  training loss:		0.071606
  validation loss:		0.999585
  validation accuracy:		88.70 %
Epoch 1814 of 2000 took 0.096s
  training loss:		0.064139
  validation loss:		0.912601
  validation accuracy:		89.57 %
Epoch 1815 of 2000 took 0.096s
  training loss:		0.064801
  validation loss:		0.964473
  validation accuracy:		89.35 %
Epoch 1816 of 2000 took 0.096s
  training loss:		0.067870
  validation loss:		0.960528
  validation accuracy:		89.24 %
Epoch 1817 of 2000 took 0.096s
  training loss:		0.064021
  validation loss:		0.909662
  validation accuracy:		89.67 %
Epoch 1818 of 2000 took 0.096s
  training loss:		0.060815
  validation loss:		0.944623
  validation accuracy:		89.24 %
Epoch 1819 of 2000 took 0.096s
  training loss:		0.065613
  validation loss:		0.966113
  validation accuracy:		89.35 %
Epoch 1820 of 2000 took 0.096s
  training loss:		0.100445
  validation loss:		0.981834
  validation accuracy:		88.59 %
Epoch 1821 of 2000 took 0.096s
  training loss:		0.073322
  validation loss:		0.957994
  validation accuracy:		88.70 %
Epoch 1822 of 2000 took 0.096s
  training loss:		0.057440
  validation loss:		0.941326
  validation accuracy:		89.35 %
Epoch 1823 of 2000 took 0.096s
  training loss:		0.062441
  validation loss:		0.919329
  validation accuracy:		89.78 %
Epoch 1824 of 2000 took 0.096s
  training loss:		0.063838
  validation loss:		0.940791
  validation accuracy:		89.13 %
Epoch 1825 of 2000 took 0.097s
  training loss:		0.068667
  validation loss:		0.937865
  validation accuracy:		89.24 %
Epoch 1826 of 2000 took 0.098s
  training loss:		0.064259
  validation loss:		0.890621
  validation accuracy:		90.11 %
Epoch 1827 of 2000 took 0.096s
  training loss:		0.126416
  validation loss:		0.928613
  validation accuracy:		89.57 %
Epoch 1828 of 2000 took 0.096s
  training loss:		0.062898
  validation loss:		0.911206
  validation accuracy:		89.78 %
Epoch 1829 of 2000 took 0.096s
  training loss:		0.085845
  validation loss:		0.943171
  validation accuracy:		89.24 %
Epoch 1830 of 2000 took 0.096s
  training loss:		0.068220
  validation loss:		0.911400
  validation accuracy:		89.24 %
Epoch 1831 of 2000 took 0.096s
  training loss:		0.060195
  validation loss:		0.922185
  validation accuracy:		89.24 %
Epoch 1832 of 2000 took 0.096s
  training loss:		0.063388
  validation loss:		0.957893
  validation accuracy:		88.80 %
Epoch 1833 of 2000 took 0.096s
  training loss:		0.061457
  validation loss:		0.945160
  validation accuracy:		89.13 %
Epoch 1834 of 2000 took 0.096s
  training loss:		0.053468
  validation loss:		0.978292
  validation accuracy:		88.15 %
Epoch 1835 of 2000 took 0.096s
  training loss:		0.063004
  validation loss:		0.906488
  validation accuracy:		89.89 %
Epoch 1836 of 2000 took 0.096s
  training loss:		0.067994
  validation loss:		1.040563
  validation accuracy:		88.70 %
Epoch 1837 of 2000 took 0.096s
  training loss:		0.072586
  validation loss:		0.976150
  validation accuracy:		88.80 %
Epoch 1838 of 2000 took 0.096s
  training loss:		0.061080
  validation loss:		1.005022
  validation accuracy:		88.70 %
Epoch 1839 of 2000 took 0.096s
  training loss:		0.059430
  validation loss:		0.946405
  validation accuracy:		89.13 %
Epoch 1840 of 2000 took 0.096s
  training loss:		0.083406
  validation loss:		0.931508
  validation accuracy:		89.35 %
Epoch 1841 of 2000 took 0.096s
  training loss:		0.058940
  validation loss:		0.953366
  validation accuracy:		89.02 %
Epoch 1842 of 2000 took 0.096s
  training loss:		0.062976
  validation loss:		0.948970
  validation accuracy:		89.57 %
Epoch 1843 of 2000 took 0.096s
  training loss:		0.061408
  validation loss:		0.940080
  validation accuracy:		89.35 %
Epoch 1844 of 2000 took 0.096s
  training loss:		0.065626
  validation loss:		0.922761
  validation accuracy:		89.78 %
Epoch 1845 of 2000 took 0.096s
  training loss:		0.055688
  validation loss:		0.936011
  validation accuracy:		89.35 %
Epoch 1846 of 2000 took 0.096s
  training loss:		0.063957
  validation loss:		0.917793
  validation accuracy:		89.67 %
Epoch 1847 of 2000 took 0.096s
  training loss:		0.058524
  validation loss:		0.945371
  validation accuracy:		89.13 %
Epoch 1848 of 2000 took 0.096s
  training loss:		0.055974
  validation loss:		0.970353
  validation accuracy:		88.91 %
Epoch 1849 of 2000 took 0.096s
  training loss:		0.055761
  validation loss:		0.952037
  validation accuracy:		89.67 %
Epoch 1850 of 2000 took 0.096s
  training loss:		0.055597
  validation loss:		0.984744
  validation accuracy:		88.70 %
Epoch 1851 of 2000 took 0.096s
  training loss:		0.058144
  validation loss:		0.978951
  validation accuracy:		89.13 %
Epoch 1852 of 2000 took 0.096s
  training loss:		0.062176
  validation loss:		1.031024
  validation accuracy:		88.04 %
Epoch 1853 of 2000 took 0.096s
  training loss:		0.063639
  validation loss:		0.968699
  validation accuracy:		89.67 %
Epoch 1854 of 2000 took 0.096s
  training loss:		0.082238
  validation loss:		0.981209
  validation accuracy:		88.91 %
Epoch 1855 of 2000 took 0.096s
  training loss:		0.062327
  validation loss:		0.961508
  validation accuracy:		89.24 %
Epoch 1856 of 2000 took 0.097s
  training loss:		0.049829
  validation loss:		0.961551
  validation accuracy:		89.46 %
Epoch 1857 of 2000 took 0.096s
  training loss:		0.066357
  validation loss:		0.950635
  validation accuracy:		89.35 %
Epoch 1858 of 2000 took 0.096s
  training loss:		0.100205
  validation loss:		1.025715
  validation accuracy:		88.70 %
Epoch 1859 of 2000 took 0.096s
  training loss:		0.062733
  validation loss:		0.932545
  validation accuracy:		89.89 %
Epoch 1860 of 2000 took 0.096s
  training loss:		0.078198
  validation loss:		0.974650
  validation accuracy:		88.80 %
Epoch 1861 of 2000 took 0.096s
  training loss:		0.066025
  validation loss:		0.951009
  validation accuracy:		89.46 %
Epoch 1862 of 2000 took 0.096s
  training loss:		0.056939
  validation loss:		1.000444
  validation accuracy:		88.91 %
Epoch 1863 of 2000 took 0.096s
  training loss:		0.062284
  validation loss:		0.928628
  validation accuracy:		89.78 %
Epoch 1864 of 2000 took 0.096s
  training loss:		0.061113
  validation loss:		0.964805
  validation accuracy:		89.57 %
Epoch 1865 of 2000 took 0.096s
  training loss:		0.052522
  validation loss:		0.984958
  validation accuracy:		88.70 %
Epoch 1866 of 2000 took 0.096s
  training loss:		0.065638
  validation loss:		0.920697
  validation accuracy:		89.78 %
Epoch 1867 of 2000 took 0.096s
  training loss:		0.063203
  validation loss:		0.935121
  validation accuracy:		89.46 %
Epoch 1868 of 2000 took 0.096s
  training loss:		0.056530
  validation loss:		0.940370
  validation accuracy:		89.46 %
Epoch 1869 of 2000 took 0.096s
  training loss:		0.067612
  validation loss:		0.985413
  validation accuracy:		88.80 %
Epoch 1870 of 2000 took 0.096s
  training loss:		0.076118
  validation loss:		0.975009
  validation accuracy:		88.91 %
Epoch 1871 of 2000 took 0.096s
  training loss:		0.051942
  validation loss:		0.957525
  validation accuracy:		89.02 %
Epoch 1872 of 2000 took 0.096s
  training loss:		0.067292
  validation loss:		0.972757
  validation accuracy:		89.35 %
Epoch 1873 of 2000 took 0.096s
  training loss:		0.068969
  validation loss:		0.969184
  validation accuracy:		89.13 %
Epoch 1874 of 2000 took 0.096s
  training loss:		0.064912
  validation loss:		0.944308
  validation accuracy:		89.35 %
Epoch 1875 of 2000 took 0.096s
  training loss:		0.060913
  validation loss:		0.959701
  validation accuracy:		89.13 %
Epoch 1876 of 2000 took 0.096s
  training loss:		0.060103
  validation loss:		0.924041
  validation accuracy:		89.67 %
Epoch 1877 of 2000 took 0.096s
  training loss:		0.080528
  validation loss:		0.933129
  validation accuracy:		90.33 %
Epoch 1878 of 2000 took 0.096s
  training loss:		0.075310
  validation loss:		0.914713
  validation accuracy:		89.46 %
Epoch 1879 of 2000 took 0.096s
  training loss:		0.083915
  validation loss:		0.938677
  validation accuracy:		89.13 %
Epoch 1880 of 2000 took 0.096s
  training loss:		0.056322
  validation loss:		0.927850
  validation accuracy:		89.78 %
Epoch 1881 of 2000 took 0.096s
  training loss:		0.072961
  validation loss:		1.014300
  validation accuracy:		88.91 %
Epoch 1882 of 2000 took 0.096s
  training loss:		0.105873
  validation loss:		0.923353
  validation accuracy:		89.35 %
Epoch 1883 of 2000 took 0.096s
  training loss:		0.055396
  validation loss:		0.945880
  validation accuracy:		89.78 %
Epoch 1884 of 2000 took 0.096s
  training loss:		0.072481
  validation loss:		0.944151
  validation accuracy:		89.02 %
Epoch 1885 of 2000 took 0.096s
  training loss:		0.062064
  validation loss:		0.941217
  validation accuracy:		89.46 %
Epoch 1886 of 2000 took 0.096s
  training loss:		0.060237
  validation loss:		0.973681
  validation accuracy:		89.02 %
Epoch 1887 of 2000 took 0.096s
  training loss:		0.059951
  validation loss:		0.951117
  validation accuracy:		89.35 %
Epoch 1888 of 2000 took 0.097s
  training loss:		0.059279
  validation loss:		0.935296
  validation accuracy:		89.78 %
Epoch 1889 of 2000 took 0.096s
  training loss:		0.051360
  validation loss:		0.966510
  validation accuracy:		88.91 %
Epoch 1890 of 2000 took 0.096s
  training loss:		0.055749
  validation loss:		0.971410
  validation accuracy:		89.35 %
Epoch 1891 of 2000 took 0.096s
  training loss:		0.070123
  validation loss:		0.954668
  validation accuracy:		89.46 %
Epoch 1892 of 2000 took 0.096s
  training loss:		0.063321
  validation loss:		0.933063
  validation accuracy:		89.89 %
Epoch 1893 of 2000 took 0.096s
  training loss:		0.055768
  validation loss:		0.976638
  validation accuracy:		88.91 %
Epoch 1894 of 2000 took 0.096s
  training loss:		0.084497
  validation loss:		0.941189
  validation accuracy:		89.89 %
Epoch 1895 of 2000 took 0.096s
  training loss:		0.060195
  validation loss:		0.958273
  validation accuracy:		89.46 %
Epoch 1896 of 2000 took 0.096s
  training loss:		0.054156
  validation loss:		0.996203
  validation accuracy:		89.46 %
Epoch 1897 of 2000 took 0.096s
  training loss:		0.056682
  validation loss:		0.949728
  validation accuracy:		89.57 %
Epoch 1898 of 2000 took 0.096s
  training loss:		0.052565
  validation loss:		0.954048
  validation accuracy:		89.57 %
Epoch 1899 of 2000 took 0.096s
  training loss:		0.048747
  validation loss:		0.967656
  validation accuracy:		89.02 %
Epoch 1900 of 2000 took 0.096s
  training loss:		0.073135
  validation loss:		0.991449
  validation accuracy:		89.02 %
Epoch 1901 of 2000 took 0.096s
  training loss:		0.060633
  validation loss:		0.982904
  validation accuracy:		88.91 %
Epoch 1902 of 2000 took 0.096s
  training loss:		0.061725
  validation loss:		0.961959
  validation accuracy:		89.57 %
Epoch 1903 of 2000 took 0.096s
  training loss:		0.058285
  validation loss:		0.963388
  validation accuracy:		89.02 %
Epoch 1904 of 2000 took 0.096s
  training loss:		0.061589
  validation loss:		0.977323
  validation accuracy:		88.91 %
Epoch 1905 of 2000 took 0.096s
  training loss:		0.075414
  validation loss:		1.267114
  validation accuracy:		85.00 %
Epoch 1906 of 2000 took 0.096s
  training loss:		0.105898
  validation loss:		0.962577
  validation accuracy:		88.91 %
Epoch 1907 of 2000 took 0.096s
  training loss:		0.069691
  validation loss:		0.975074
  validation accuracy:		89.46 %
Epoch 1908 of 2000 took 0.096s
  training loss:		0.066274
  validation loss:		1.019493
  validation accuracy:		88.70 %
Epoch 1909 of 2000 took 0.096s
  training loss:		0.085533
  validation loss:		0.973091
  validation accuracy:		89.35 %
Epoch 1910 of 2000 took 0.096s
  training loss:		0.069572
  validation loss:		1.039496
  validation accuracy:		88.48 %
Epoch 1911 of 2000 took 0.096s
  training loss:		0.070121
  validation loss:		0.967263
  validation accuracy:		89.13 %
Epoch 1912 of 2000 took 0.096s
  training loss:		0.058324
  validation loss:		0.988900
  validation accuracy:		89.35 %
Epoch 1913 of 2000 took 0.096s
  training loss:		0.053634
  validation loss:		0.996527
  validation accuracy:		88.80 %
Epoch 1914 of 2000 took 0.096s
  training loss:		0.084033
  validation loss:		0.954690
  validation accuracy:		89.02 %
Epoch 1915 of 2000 took 0.096s
  training loss:		0.058142
  validation loss:		1.000155
  validation accuracy:		89.02 %
Epoch 1916 of 2000 took 0.096s
  training loss:		0.054320
  validation loss:		0.969339
  validation accuracy:		89.46 %
Epoch 1917 of 2000 took 0.096s
  training loss:		0.061344
  validation loss:		0.962869
  validation accuracy:		89.89 %
Epoch 1918 of 2000 took 0.096s
  training loss:		0.077713
  validation loss:		1.066265
  validation accuracy:		88.26 %
Epoch 1919 of 2000 took 0.097s
  training loss:		0.058669
  validation loss:		0.971706
  validation accuracy:		89.46 %
Epoch 1920 of 2000 took 0.096s
  training loss:		0.052543
  validation loss:		0.976533
  validation accuracy:		89.24 %
Epoch 1921 of 2000 took 0.096s
  training loss:		0.057886
  validation loss:		0.956759
  validation accuracy:		89.57 %
Epoch 1922 of 2000 took 0.096s
  training loss:		0.052566
  validation loss:		0.963551
  validation accuracy:		89.46 %
Epoch 1923 of 2000 took 0.096s
  training loss:		0.059888
  validation loss:		0.964643
  validation accuracy:		89.67 %
Epoch 1924 of 2000 took 0.096s
  training loss:		0.060094
  validation loss:		0.955408
  validation accuracy:		89.89 %
Epoch 1925 of 2000 took 0.096s
  training loss:		0.055528
  validation loss:		0.994539
  validation accuracy:		88.70 %
Epoch 1926 of 2000 took 0.096s
  training loss:		0.060063
  validation loss:		0.981103
  validation accuracy:		88.80 %
Epoch 1927 of 2000 took 0.096s
  training loss:		0.049217
  validation loss:		0.979001
  validation accuracy:		89.24 %
Epoch 1928 of 2000 took 0.096s
  training loss:		0.066371
  validation loss:		1.016845
  validation accuracy:		89.02 %
Epoch 1929 of 2000 took 0.096s
  training loss:		0.051207
  validation loss:		0.993104
  validation accuracy:		89.35 %
Epoch 1930 of 2000 took 0.096s
  training loss:		0.054200
  validation loss:		0.990865
  validation accuracy:		89.24 %
Epoch 1931 of 2000 took 0.096s
  training loss:		0.054336
  validation loss:		0.962937
  validation accuracy:		89.46 %
Epoch 1932 of 2000 took 0.096s
  training loss:		0.058273
  validation loss:		0.985132
  validation accuracy:		88.91 %
Epoch 1933 of 2000 took 0.096s
  training loss:		0.058471
  validation loss:		0.975523
  validation accuracy:		89.46 %
Epoch 1934 of 2000 took 0.096s
  training loss:		0.053912
  validation loss:		0.963381
  validation accuracy:		89.57 %
Epoch 1935 of 2000 took 0.096s
  training loss:		0.093043
  validation loss:		1.340473
  validation accuracy:		85.22 %
Epoch 1936 of 2000 took 0.096s
  training loss:		0.198398
  validation loss:		0.990881
  validation accuracy:		89.13 %
Epoch 1937 of 2000 took 0.096s
  training loss:		0.060508
  validation loss:		0.963213
  validation accuracy:		89.24 %
Epoch 1938 of 2000 took 0.096s
  training loss:		0.067714
  validation loss:		0.965434
  validation accuracy:		89.02 %
Epoch 1939 of 2000 took 0.096s
  training loss:		0.057610
  validation loss:		0.964491
  validation accuracy:		89.35 %
Epoch 1940 of 2000 took 0.096s
  training loss:		0.055708
  validation loss:		0.950222
  validation accuracy:		89.35 %
Epoch 1941 of 2000 took 0.096s
  training loss:		0.062045
  validation loss:		0.967915
  validation accuracy:		89.13 %
Epoch 1942 of 2000 took 0.096s
  training loss:		0.053794
  validation loss:		0.930786
  validation accuracy:		90.00 %
Epoch 1943 of 2000 took 0.096s
  training loss:		0.058790
  validation loss:		0.952126
  validation accuracy:		89.67 %
Epoch 1944 of 2000 took 0.096s
  training loss:		0.047526
  validation loss:		0.953098
  validation accuracy:		89.57 %
Epoch 1945 of 2000 took 0.096s
  training loss:		0.061707
  validation loss:		0.963794
  validation accuracy:		89.57 %
Epoch 1946 of 2000 took 0.096s
  training loss:		0.055085
  validation loss:		0.957880
  validation accuracy:		89.57 %
Epoch 1947 of 2000 took 0.096s
  training loss:		0.056845
  validation loss:		0.980892
  validation accuracy:		89.24 %
Epoch 1948 of 2000 took 0.096s
  training loss:		0.074902
  validation loss:		0.955534
  validation accuracy:		89.67 %
Epoch 1949 of 2000 took 0.096s
  training loss:		0.052918
  validation loss:		0.975465
  validation accuracy:		89.57 %
Epoch 1950 of 2000 took 0.096s
  training loss:		0.058230
  validation loss:		0.946281
  validation accuracy:		89.57 %
Epoch 1951 of 2000 took 0.097s
  training loss:		0.064180
  validation loss:		0.988887
  validation accuracy:		89.57 %
Epoch 1952 of 2000 took 0.096s
  training loss:		0.053752
  validation loss:		0.992943
  validation accuracy:		89.46 %
Epoch 1953 of 2000 took 0.096s
  training loss:		0.084117
  validation loss:		0.989861
  validation accuracy:		89.02 %
Epoch 1954 of 2000 took 0.096s
  training loss:		0.057421
  validation loss:		0.956271
  validation accuracy:		89.67 %
Epoch 1955 of 2000 took 0.096s
  training loss:		0.065809
  validation loss:		0.992680
  validation accuracy:		88.91 %
Epoch 1956 of 2000 took 0.096s
  training loss:		0.051203
  validation loss:		0.992656
  validation accuracy:		89.02 %
Epoch 1957 of 2000 took 0.096s
  training loss:		0.056519
  validation loss:		1.027062
  validation accuracy:		88.48 %
Epoch 1958 of 2000 took 0.096s
  training loss:		0.058462
  validation loss:		0.983143
  validation accuracy:		89.24 %
Epoch 1959 of 2000 took 0.096s
  training loss:		0.056088
  validation loss:		0.981959
  validation accuracy:		89.24 %
Epoch 1960 of 2000 took 0.096s
  training loss:		0.051988
  validation loss:		0.989494
  validation accuracy:		89.13 %
Epoch 1961 of 2000 took 0.096s
  training loss:		0.059713
  validation loss:		0.971384
  validation accuracy:		89.89 %
Epoch 1962 of 2000 took 0.096s
  training loss:		0.058515
  validation loss:		1.015154
  validation accuracy:		89.02 %
Epoch 1963 of 2000 took 0.096s
  training loss:		0.060311
  validation loss:		1.003869
  validation accuracy:		89.24 %
Epoch 1964 of 2000 took 0.096s
  training loss:		0.053687
  validation loss:		0.998915
  validation accuracy:		89.24 %
Epoch 1965 of 2000 took 0.096s
  training loss:		0.056531
  validation loss:		0.977117
  validation accuracy:		89.78 %
Epoch 1966 of 2000 took 0.096s
  training loss:		0.080504
  validation loss:		0.986258
  validation accuracy:		89.57 %
Epoch 1967 of 2000 took 0.096s
  training loss:		0.072558
  validation loss:		0.980329
  validation accuracy:		89.13 %
Epoch 1968 of 2000 took 0.096s
  training loss:		0.065984
  validation loss:		0.972356
  validation accuracy:		89.78 %
Epoch 1969 of 2000 took 0.096s
  training loss:		0.052964
  validation loss:		0.993006
  validation accuracy:		89.24 %
Epoch 1970 of 2000 took 0.096s
  training loss:		0.055350
  validation loss:		0.966884
  validation accuracy:		89.67 %
Epoch 1971 of 2000 took 0.096s
  training loss:		0.052125
  validation loss:		0.969228
  validation accuracy:		89.67 %
Epoch 1972 of 2000 took 0.096s
  training loss:		0.053122
  validation loss:		1.009727
  validation accuracy:		88.80 %
Epoch 1973 of 2000 took 0.096s
  training loss:		0.055962
  validation loss:		1.056950
  validation accuracy:		88.37 %
Epoch 1974 of 2000 took 0.096s
  training loss:		0.059240
  validation loss:		1.082433
  validation accuracy:		88.48 %
Epoch 1975 of 2000 took 0.096s
  training loss:		0.062503
  validation loss:		1.002819
  validation accuracy:		89.02 %
Epoch 1976 of 2000 took 0.096s
  training loss:		0.057443
  validation loss:		0.988015
  validation accuracy:		89.46 %
Epoch 1977 of 2000 took 0.096s
  training loss:		0.048520
  validation loss:		1.006936
  validation accuracy:		89.13 %
Epoch 1978 of 2000 took 0.096s
  training loss:		0.054818
  validation loss:		0.983124
  validation accuracy:		89.35 %
Epoch 1979 of 2000 took 0.096s
  training loss:		0.091513
  validation loss:		1.076015
  validation accuracy:		88.59 %
Epoch 1980 of 2000 took 0.096s
  training loss:		0.073651
  validation loss:		1.024466
  validation accuracy:		89.02 %
Epoch 1981 of 2000 took 0.096s
  training loss:		0.057230
  validation loss:		0.980101
  validation accuracy:		89.89 %
Epoch 1982 of 2000 took 0.097s
  training loss:		0.053400
  validation loss:		0.993338
  validation accuracy:		89.35 %
Epoch 1983 of 2000 took 0.096s
  training loss:		0.051881
  validation loss:		1.022272
  validation accuracy:		88.91 %
Epoch 1984 of 2000 took 0.096s
  training loss:		0.062020
  validation loss:		0.998527
  validation accuracy:		89.13 %
Epoch 1985 of 2000 took 0.096s
  training loss:		0.056377
  validation loss:		1.020860
  validation accuracy:		89.13 %
Epoch 1986 of 2000 took 0.096s
  training loss:		0.049527
  validation loss:		0.991660
  validation accuracy:		89.67 %
Epoch 1987 of 2000 took 0.096s
  training loss:		0.049653
  validation loss:		0.982849
  validation accuracy:		89.35 %
Epoch 1988 of 2000 took 0.096s
  training loss:		0.057928
  validation loss:		1.020732
  validation accuracy:		88.70 %
Epoch 1989 of 2000 took 0.096s
  training loss:		0.055324
  validation loss:		0.991752
  validation accuracy:		89.46 %
Epoch 1990 of 2000 took 0.096s
  training loss:		0.057152
  validation loss:		1.098301
  validation accuracy:		88.26 %
Epoch 1991 of 2000 took 0.096s
  training loss:		0.062890
  validation loss:		1.034549
  validation accuracy:		89.13 %
Epoch 1992 of 2000 took 0.096s
  training loss:		0.055464
  validation loss:		0.998614
  validation accuracy:		89.35 %
Epoch 1993 of 2000 took 0.096s
  training loss:		0.051390
  validation loss:		0.982838
  validation accuracy:		89.57 %
Epoch 1994 of 2000 took 0.096s
  training loss:		0.064912
  validation loss:		1.043174
  validation accuracy:		89.02 %
Epoch 1995 of 2000 took 0.096s
  training loss:		0.083700
  validation loss:		1.020620
  validation accuracy:		89.46 %
Epoch 1996 of 2000 took 0.096s
  training loss:		0.058867
  validation loss:		1.014321
  validation accuracy:		89.02 %
Epoch 1997 of 2000 took 0.096s
  training loss:		0.058777
  validation loss:		0.991610
  validation accuracy:		89.57 %
Epoch 1998 of 2000 took 0.096s
  training loss:		0.049829
  validation loss:		0.989352
  validation accuracy:		89.46 %
Epoch 1999 of 2000 took 0.096s
  training loss:		0.057163
  validation loss:		0.988665
  validation accuracy:		89.35 %
Epoch 2000 of 2000 took 0.096s
  training loss:		0.055861
  validation loss:		1.038563
  validation accuracy:		88.80 %
Final results:
  test loss:			1.926737
  test accuracy:		80.84 %
