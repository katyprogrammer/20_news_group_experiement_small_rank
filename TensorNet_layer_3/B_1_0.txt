Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 200),b=(200,)
decomposing tensor W of shape (1, 200, 200)...
decomposing tensor B of shape (1, 200)...
Starting training...
Epoch 1 of 2000 took 0.162s
  training loss:		2.970411
  validation loss:		2.893240
  validation accuracy:		12.93 %
Epoch 2 of 2000 took 0.158s
  training loss:		2.862143
  validation loss:		2.746346
  validation accuracy:		12.93 %
Epoch 3 of 2000 took 0.165s
  training loss:		2.725461
  validation loss:		2.579225
  validation accuracy:		12.93 %
Epoch 4 of 2000 took 0.140s
  training loss:		2.581253
  validation loss:		2.410641
  validation accuracy:		12.93 %
Epoch 5 of 2000 took 0.139s
  training loss:		2.440499
  validation loss:		2.286467
  validation accuracy:		13.91 %
Epoch 6 of 2000 took 0.145s
  training loss:		2.350664
  validation loss:		2.247155
  validation accuracy:		13.04 %
Epoch 7 of 2000 took 0.144s
  training loss:		2.308677
  validation loss:		2.253699
  validation accuracy:		30.22 %
Epoch 8 of 2000 took 0.144s
  training loss:		2.291612
  validation loss:		2.241557
  validation accuracy:		26.52 %
Epoch 9 of 2000 took 0.145s
  training loss:		2.284127
  validation loss:		2.226096
  validation accuracy:		34.24 %
Epoch 10 of 2000 took 0.144s
  training loss:		2.278447
  validation loss:		2.214720
  validation accuracy:		44.35 %
Epoch 11 of 2000 took 0.141s
  training loss:		2.273596
  validation loss:		2.219185
  validation accuracy:		51.30 %
Epoch 12 of 2000 took 0.172s
  training loss:		2.268294
  validation loss:		2.207141
  validation accuracy:		49.02 %
Epoch 13 of 2000 took 0.185s
  training loss:		2.265589
  validation loss:		2.212757
  validation accuracy:		33.04 %
Epoch 14 of 2000 took 0.135s
  training loss:		2.262281
  validation loss:		2.203292
  validation accuracy:		35.87 %
Epoch 15 of 2000 took 0.147s
  training loss:		2.257234
  validation loss:		2.196355
  validation accuracy:		35.54 %
Epoch 16 of 2000 took 0.149s
  training loss:		2.254662
  validation loss:		2.196602
  validation accuracy:		42.28 %
Epoch 17 of 2000 took 0.141s
  training loss:		2.249372
  validation loss:		2.187815
  validation accuracy:		68.91 %
Epoch 18 of 2000 took 0.138s
  training loss:		2.243114
  validation loss:		2.175722
  validation accuracy:		48.26 %
Epoch 19 of 2000 took 0.157s
  training loss:		2.238192
  validation loss:		2.178519
  validation accuracy:		35.00 %
Epoch 20 of 2000 took 0.136s
  training loss:		2.234920
  validation loss:		2.173911
  validation accuracy:		48.91 %
Epoch 21 of 2000 took 0.147s
  training loss:		2.228938
  validation loss:		2.167935
  validation accuracy:		58.37 %
Epoch 22 of 2000 took 0.143s
  training loss:		2.222083
  validation loss:		2.154785
  validation accuracy:		63.59 %
Epoch 23 of 2000 took 0.141s
  training loss:		2.216282
  validation loss:		2.152338
  validation accuracy:		61.63 %
Epoch 24 of 2000 took 0.140s
  training loss:		2.207965
  validation loss:		2.147361
  validation accuracy:		51.09 %
Epoch 25 of 2000 took 0.143s
  training loss:		2.200920
  validation loss:		2.133100
  validation accuracy:		50.22 %
Epoch 26 of 2000 took 0.143s
  training loss:		2.192499
  validation loss:		2.128760
  validation accuracy:		64.67 %
Epoch 27 of 2000 took 0.143s
  training loss:		2.182644
  validation loss:		2.116699
  validation accuracy:		64.35 %
Epoch 28 of 2000 took 0.145s
  training loss:		2.174573
  validation loss:		2.091721
  validation accuracy:		57.39 %
Epoch 29 of 2000 took 0.142s
  training loss:		2.164895
  validation loss:		2.095146
  validation accuracy:		71.85 %
Epoch 30 of 2000 took 0.138s
  training loss:		2.148495
  validation loss:		2.074749
  validation accuracy:		74.35 %
Epoch 31 of 2000 took 0.146s
  training loss:		2.134684
  validation loss:		2.055304
  validation accuracy:		70.54 %
Epoch 32 of 2000 took 0.138s
  training loss:		2.118713
  validation loss:		2.043296
  validation accuracy:		65.43 %
Epoch 33 of 2000 took 0.142s
  training loss:		2.102968
  validation loss:		2.025081
  validation accuracy:		79.78 %
Epoch 34 of 2000 took 0.138s
  training loss:		2.081672
  validation loss:		1.997486
  validation accuracy:		74.46 %
Epoch 35 of 2000 took 0.142s
  training loss:		2.060255
  validation loss:		1.972494
  validation accuracy:		82.07 %
Epoch 36 of 2000 took 0.177s
  training loss:		2.034916
  validation loss:		1.942612
  validation accuracy:		82.72 %
Epoch 37 of 2000 took 0.143s
  training loss:		2.008225
  validation loss:		1.911949
  validation accuracy:		85.76 %
Epoch 38 of 2000 took 0.155s
  training loss:		1.974056
  validation loss:		1.870581
  validation accuracy:		82.17 %
Epoch 39 of 2000 took 0.151s
  training loss:		1.939894
  validation loss:		1.832100
  validation accuracy:		78.15 %
Epoch 40 of 2000 took 0.147s
  training loss:		1.900205
  validation loss:		1.784613
  validation accuracy:		82.28 %
Epoch 41 of 2000 took 0.146s
  training loss:		1.857292
  validation loss:		1.742531
  validation accuracy:		84.35 %
Epoch 42 of 2000 took 0.151s
  training loss:		1.809914
  validation loss:		1.683139
  validation accuracy:		83.15 %
Epoch 43 of 2000 took 0.147s
  training loss:		1.756673
  validation loss:		1.620493
  validation accuracy:		87.72 %
Epoch 44 of 2000 took 0.147s
  training loss:		1.693765
  validation loss:		1.556351
  validation accuracy:		87.39 %
Epoch 45 of 2000 took 0.138s
  training loss:		1.640347
  validation loss:		1.501901
  validation accuracy:		85.00 %
Epoch 46 of 2000 took 0.150s
  training loss:		1.574998
  validation loss:		1.430057
  validation accuracy:		87.93 %
Epoch 47 of 2000 took 0.179s
  training loss:		1.511942
  validation loss:		1.358414
  validation accuracy:		87.17 %
Epoch 48 of 2000 took 0.182s
  training loss:		1.446885
  validation loss:		1.295015
  validation accuracy:		88.59 %
Epoch 49 of 2000 took 0.146s
  training loss:		1.382540
  validation loss:		1.220876
  validation accuracy:		88.26 %
Epoch 50 of 2000 took 0.148s
  training loss:		1.320680
  validation loss:		1.162720
  validation accuracy:		89.13 %
Epoch 51 of 2000 took 0.156s
  training loss:		1.252473
  validation loss:		1.091544
  validation accuracy:		88.80 %
Epoch 52 of 2000 took 0.148s
  training loss:		1.200190
  validation loss:		1.041061
  validation accuracy:		87.07 %
Epoch 53 of 2000 took 0.144s
  training loss:		1.140621
  validation loss:		0.980263
  validation accuracy:		89.13 %
Epoch 54 of 2000 took 0.152s
  training loss:		1.090098
  validation loss:		0.930296
  validation accuracy:		88.91 %
Epoch 55 of 2000 took 0.148s
  training loss:		1.041982
  validation loss:		0.889644
  validation accuracy:		88.37 %
Epoch 56 of 2000 took 0.150s
  training loss:		0.993703
  validation loss:		0.841272
  validation accuracy:		89.02 %
Epoch 57 of 2000 took 0.160s
  training loss:		0.951905
  validation loss:		0.803770
  validation accuracy:		89.57 %
Epoch 58 of 2000 took 0.188s
  training loss:		0.908670
  validation loss:		0.770838
  validation accuracy:		89.13 %
Epoch 59 of 2000 took 0.149s
  training loss:		0.883588
  validation loss:		0.733207
  validation accuracy:		89.57 %
Epoch 60 of 2000 took 0.141s
  training loss:		0.844782
  validation loss:		0.712872
  validation accuracy:		89.57 %
Epoch 61 of 2000 took 0.144s
  training loss:		0.810400
  validation loss:		0.676869
  validation accuracy:		89.57 %
Epoch 62 of 2000 took 0.142s
  training loss:		0.781988
  validation loss:		0.650644
  validation accuracy:		89.35 %
Epoch 63 of 2000 took 0.139s
  training loss:		0.757240
  validation loss:		0.619864
  validation accuracy:		89.89 %
Epoch 64 of 2000 took 0.146s
  training loss:		0.727651
  validation loss:		0.605593
  validation accuracy:		90.22 %
Epoch 65 of 2000 took 0.140s
  training loss:		0.701416
  validation loss:		0.578937
  validation accuracy:		89.67 %
Epoch 66 of 2000 took 0.148s
  training loss:		0.682774
  validation loss:		0.565299
  validation accuracy:		89.89 %
Epoch 67 of 2000 took 0.138s
  training loss:		0.658887
  validation loss:		0.552793
  validation accuracy:		90.43 %
Epoch 68 of 2000 took 0.146s
  training loss:		0.639533
  validation loss:		0.530153
  validation accuracy:		90.22 %
Epoch 69 of 2000 took 0.142s
  training loss:		0.618329
  validation loss:		0.518425
  validation accuracy:		90.22 %
Epoch 70 of 2000 took 0.145s
  training loss:		0.601735
  validation loss:		0.494763
  validation accuracy:		90.43 %
Epoch 71 of 2000 took 0.147s
  training loss:		0.576227
  validation loss:		0.490536
  validation accuracy:		90.22 %
Epoch 72 of 2000 took 0.140s
  training loss:		0.567281
  validation loss:		0.471846
  validation accuracy:		90.43 %
Epoch 73 of 2000 took 0.148s
  training loss:		0.550540
  validation loss:		0.457418
  validation accuracy:		90.98 %
Epoch 74 of 2000 took 0.136s
  training loss:		0.536349
  validation loss:		0.446602
  validation accuracy:		91.20 %
Epoch 75 of 2000 took 0.138s
  training loss:		0.522320
  validation loss:		0.437071
  validation accuracy:		90.98 %
Epoch 76 of 2000 took 0.158s
  training loss:		0.508785
  validation loss:		0.420967
  validation accuracy:		90.98 %
Epoch 77 of 2000 took 0.147s
  training loss:		0.494878
  validation loss:		0.413398
  validation accuracy:		91.41 %
Epoch 78 of 2000 took 0.141s
  training loss:		0.479188
  validation loss:		0.408587
  validation accuracy:		90.76 %
Epoch 79 of 2000 took 0.141s
  training loss:		0.469267
  validation loss:		0.389484
  validation accuracy:		91.30 %
Epoch 80 of 2000 took 0.145s
  training loss:		0.457843
  validation loss:		0.392908
  validation accuracy:		90.98 %
Epoch 81 of 2000 took 0.140s
  training loss:		0.445281
  validation loss:		0.378474
  validation accuracy:		91.52 %
Epoch 82 of 2000 took 0.142s
  training loss:		0.435211
  validation loss:		0.372029
  validation accuracy:		91.41 %
Epoch 83 of 2000 took 0.142s
  training loss:		0.422647
  validation loss:		0.372456
  validation accuracy:		91.41 %
Epoch 84 of 2000 took 0.136s
  training loss:		0.419204
  validation loss:		0.355409
  validation accuracy:		91.74 %
Epoch 85 of 2000 took 0.148s
  training loss:		0.405176
  validation loss:		0.356482
  validation accuracy:		91.63 %
Epoch 86 of 2000 took 0.145s
  training loss:		0.398606
  validation loss:		0.349975
  validation accuracy:		91.63 %
Epoch 87 of 2000 took 0.145s
  training loss:		0.389335
  validation loss:		0.338337
  validation accuracy:		92.07 %
Epoch 88 of 2000 took 0.155s
  training loss:		0.384133
  validation loss:		0.332339
  validation accuracy:		91.85 %
Epoch 89 of 2000 took 0.143s
  training loss:		0.372578
  validation loss:		0.325540
  validation accuracy:		92.28 %
Epoch 90 of 2000 took 0.134s
  training loss:		0.367799
  validation loss:		0.318538
  validation accuracy:		91.96 %
Epoch 91 of 2000 took 0.140s
  training loss:		0.368726
  validation loss:		0.313211
  validation accuracy:		92.07 %
Epoch 92 of 2000 took 0.179s
  training loss:		0.358128
  validation loss:		0.311047
  validation accuracy:		91.96 %
Epoch 93 of 2000 took 0.149s
  training loss:		0.349527
  validation loss:		0.311458
  validation accuracy:		92.28 %
Epoch 94 of 2000 took 0.141s
  training loss:		0.342527
  validation loss:		0.315869
  validation accuracy:		92.39 %
Epoch 95 of 2000 took 0.138s
  training loss:		0.337878
  validation loss:		0.295324
  validation accuracy:		91.74 %
Epoch 96 of 2000 took 0.147s
  training loss:		0.330653
  validation loss:		0.302771
  validation accuracy:		92.50 %
Epoch 97 of 2000 took 0.141s
  training loss:		0.327499
  validation loss:		0.297308
  validation accuracy:		92.17 %
Epoch 98 of 2000 took 0.146s
  training loss:		0.320557
  validation loss:		0.299756
  validation accuracy:		92.50 %
Epoch 99 of 2000 took 0.137s
  training loss:		0.317343
  validation loss:		0.289384
  validation accuracy:		92.72 %
Epoch 100 of 2000 took 0.158s
  training loss:		0.312167
  validation loss:		0.283046
  validation accuracy:		92.61 %
Epoch 101 of 2000 took 0.146s
  training loss:		0.309462
  validation loss:		0.283824
  validation accuracy:		92.93 %
Epoch 102 of 2000 took 0.136s
  training loss:		0.308313
  validation loss:		0.279947
  validation accuracy:		92.50 %
Epoch 103 of 2000 took 0.144s
  training loss:		0.301604
  validation loss:		0.278707
  validation accuracy:		92.83 %
Epoch 104 of 2000 took 0.150s
  training loss:		0.297149
  validation loss:		0.276354
  validation accuracy:		92.61 %
Epoch 105 of 2000 took 0.147s
  training loss:		0.294833
  validation loss:		0.270364
  validation accuracy:		93.04 %
Epoch 106 of 2000 took 0.148s
  training loss:		0.287176
  validation loss:		0.273921
  validation accuracy:		92.93 %
Epoch 107 of 2000 took 0.143s
  training loss:		0.284884
  validation loss:		0.262121
  validation accuracy:		92.72 %
Epoch 108 of 2000 took 0.142s
  training loss:		0.284597
  validation loss:		0.269171
  validation accuracy:		92.50 %
Epoch 109 of 2000 took 0.146s
  training loss:		0.278787
  validation loss:		0.260559
  validation accuracy:		93.04 %
Epoch 110 of 2000 took 0.146s
  training loss:		0.274615
  validation loss:		0.255646
  validation accuracy:		93.04 %
Epoch 111 of 2000 took 0.143s
  training loss:		0.272947
  validation loss:		0.258556
  validation accuracy:		93.04 %
Epoch 112 of 2000 took 0.143s
  training loss:		0.271535
  validation loss:		0.256832
  validation accuracy:		93.04 %
Epoch 113 of 2000 took 0.142s
  training loss:		0.265656
  validation loss:		0.262305
  validation accuracy:		92.93 %
Epoch 114 of 2000 took 0.141s
  training loss:		0.263193
  validation loss:		0.263705
  validation accuracy:		93.04 %
Epoch 115 of 2000 took 0.144s
  training loss:		0.260589
  validation loss:		0.253127
  validation accuracy:		93.04 %
Epoch 116 of 2000 took 0.164s
  training loss:		0.259844
  validation loss:		0.250292
  validation accuracy:		92.83 %
Epoch 117 of 2000 took 0.146s
  training loss:		0.257487
  validation loss:		0.254996
  validation accuracy:		92.93 %
Epoch 118 of 2000 took 0.140s
  training loss:		0.253224
  validation loss:		0.242890
  validation accuracy:		92.93 %
Epoch 119 of 2000 took 0.140s
  training loss:		0.252461
  validation loss:		0.252586
  validation accuracy:		93.15 %
Epoch 120 of 2000 took 0.141s
  training loss:		0.248813
  validation loss:		0.245511
  validation accuracy:		93.04 %
Epoch 121 of 2000 took 0.138s
  training loss:		0.244584
  validation loss:		0.243917
  validation accuracy:		92.93 %
Epoch 122 of 2000 took 0.165s
  training loss:		0.244236
  validation loss:		0.244570
  validation accuracy:		93.48 %
Epoch 123 of 2000 took 0.147s
  training loss:		0.240062
  validation loss:		0.234739
  validation accuracy:		93.26 %
Epoch 124 of 2000 took 0.147s
  training loss:		0.235968
  validation loss:		0.233807
  validation accuracy:		93.37 %
Epoch 125 of 2000 took 0.151s
  training loss:		0.234768
  validation loss:		0.229866
  validation accuracy:		93.80 %
Epoch 126 of 2000 took 0.142s
  training loss:		0.234405
  validation loss:		0.228243
  validation accuracy:		93.26 %
Epoch 127 of 2000 took 0.162s
  training loss:		0.233506
  validation loss:		0.231348
  validation accuracy:		93.04 %
Epoch 128 of 2000 took 0.146s
  training loss:		0.230900
  validation loss:		0.241701
  validation accuracy:		93.48 %
Epoch 129 of 2000 took 0.151s
  training loss:		0.230977
  validation loss:		0.225855
  validation accuracy:		92.93 %
Epoch 130 of 2000 took 0.143s
  training loss:		0.230637
  validation loss:		0.236004
  validation accuracy:		93.48 %
Epoch 131 of 2000 took 0.182s
  training loss:		0.226391
  validation loss:		0.234046
  validation accuracy:		93.37 %
Epoch 132 of 2000 took 0.146s
  training loss:		0.225019
  validation loss:		0.229779
  validation accuracy:		93.48 %
Epoch 133 of 2000 took 0.142s
  training loss:		0.222982
  validation loss:		0.226842
  validation accuracy:		93.15 %
Epoch 134 of 2000 took 0.152s
  training loss:		0.223207
  validation loss:		0.225603
  validation accuracy:		93.59 %
Epoch 135 of 2000 took 0.152s
  training loss:		0.218390
  validation loss:		0.220416
  validation accuracy:		94.13 %
Epoch 136 of 2000 took 0.192s
  training loss:		0.216562
  validation loss:		0.230272
  validation accuracy:		93.48 %
Epoch 137 of 2000 took 0.157s
  training loss:		0.219045
  validation loss:		0.224733
  validation accuracy:		93.15 %
Epoch 138 of 2000 took 0.140s
  training loss:		0.215139
  validation loss:		0.215394
  validation accuracy:		93.80 %
Epoch 139 of 2000 took 0.145s
  training loss:		0.211241
  validation loss:		0.222181
  validation accuracy:		94.24 %
Epoch 140 of 2000 took 0.139s
  training loss:		0.211041
  validation loss:		0.215837
  validation accuracy:		93.80 %
Epoch 141 of 2000 took 0.144s
  training loss:		0.207114
  validation loss:		0.218995
  validation accuracy:		93.80 %
Epoch 142 of 2000 took 0.146s
  training loss:		0.208003
  validation loss:		0.219186
  validation accuracy:		93.59 %
Epoch 143 of 2000 took 0.150s
  training loss:		0.207016
  validation loss:		0.219661
  validation accuracy:		93.48 %
Epoch 144 of 2000 took 0.136s
  training loss:		0.201387
  validation loss:		0.208948
  validation accuracy:		94.02 %
Epoch 145 of 2000 took 0.170s
  training loss:		0.205359
  validation loss:		0.218847
  validation accuracy:		93.70 %
Epoch 146 of 2000 took 0.174s
  training loss:		0.202617
  validation loss:		0.212278
  validation accuracy:		93.91 %
Epoch 147 of 2000 took 0.139s
  training loss:		0.203112
  validation loss:		0.212260
  validation accuracy:		94.13 %
Epoch 148 of 2000 took 0.134s
  training loss:		0.201910
  validation loss:		0.209495
  validation accuracy:		94.13 %
Epoch 149 of 2000 took 0.143s
  training loss:		0.201503
  validation loss:		0.206964
  validation accuracy:		93.91 %
Epoch 150 of 2000 took 0.141s
  training loss:		0.197452
  validation loss:		0.209927
  validation accuracy:		94.24 %
Epoch 151 of 2000 took 0.145s
  training loss:		0.192616
  validation loss:		0.221344
  validation accuracy:		93.91 %
Epoch 152 of 2000 took 0.147s
  training loss:		0.199684
  validation loss:		0.210091
  validation accuracy:		94.35 %
Epoch 153 of 2000 took 0.142s
  training loss:		0.195868
  validation loss:		0.214426
  validation accuracy:		94.02 %
Epoch 154 of 2000 took 0.174s
  training loss:		0.192898
  validation loss:		0.205693
  validation accuracy:		94.35 %
Epoch 155 of 2000 took 0.137s
  training loss:		0.193686
  validation loss:		0.205888
  validation accuracy:		94.57 %
Epoch 156 of 2000 took 0.142s
  training loss:		0.192110
  validation loss:		0.209012
  validation accuracy:		94.24 %
Epoch 157 of 2000 took 0.138s
  training loss:		0.192290
  validation loss:		0.205471
  validation accuracy:		94.35 %
Epoch 158 of 2000 took 0.144s
  training loss:		0.189331
  validation loss:		0.202465
  validation accuracy:		94.35 %
Epoch 159 of 2000 took 0.146s
  training loss:		0.190133
  validation loss:		0.205959
  validation accuracy:		94.24 %
Epoch 160 of 2000 took 0.155s
  training loss:		0.187866
  validation loss:		0.206240
  validation accuracy:		94.24 %
Epoch 161 of 2000 took 0.135s
  training loss:		0.185520
  validation loss:		0.202533
  validation accuracy:		94.57 %
Epoch 162 of 2000 took 0.144s
  training loss:		0.180898
  validation loss:		0.204111
  validation accuracy:		94.46 %
Epoch 163 of 2000 took 0.136s
  training loss:		0.184156
  validation loss:		0.203375
  validation accuracy:		94.46 %
Epoch 164 of 2000 took 0.143s
  training loss:		0.182121
  validation loss:		0.207765
  validation accuracy:		94.13 %
Epoch 165 of 2000 took 0.140s
  training loss:		0.183678
  validation loss:		0.204055
  validation accuracy:		94.57 %
Epoch 166 of 2000 took 0.149s
  training loss:		0.181292
  validation loss:		0.198995
  validation accuracy:		94.46 %
Epoch 167 of 2000 took 0.167s
  training loss:		0.177026
  validation loss:		0.198147
  validation accuracy:		94.35 %
Epoch 168 of 2000 took 0.171s
  training loss:		0.178816
  validation loss:		0.202391
  validation accuracy:		94.78 %
Epoch 169 of 2000 took 0.151s
  training loss:		0.174629
  validation loss:		0.201994
  validation accuracy:		94.13 %
Epoch 170 of 2000 took 0.165s
  training loss:		0.181248
  validation loss:		0.198742
  validation accuracy:		94.78 %
Epoch 171 of 2000 took 0.147s
  training loss:		0.176507
  validation loss:		0.195648
  validation accuracy:		94.89 %
Epoch 172 of 2000 took 0.149s
  training loss:		0.173601
  validation loss:		0.203404
  validation accuracy:		94.46 %
Epoch 173 of 2000 took 0.151s
  training loss:		0.172536
  validation loss:		0.210839
  validation accuracy:		93.80 %
Epoch 174 of 2000 took 0.142s
  training loss:		0.175606
  validation loss:		0.198176
  validation accuracy:		94.57 %
Epoch 175 of 2000 took 0.146s
  training loss:		0.169977
  validation loss:		0.198479
  validation accuracy:		94.78 %
Epoch 176 of 2000 took 0.137s
  training loss:		0.174147
  validation loss:		0.196620
  validation accuracy:		94.78 %
Epoch 177 of 2000 took 0.153s
  training loss:		0.171600
  validation loss:		0.194678
  validation accuracy:		94.57 %
Epoch 178 of 2000 took 0.137s
  training loss:		0.169781
  validation loss:		0.200770
  validation accuracy:		94.57 %
Epoch 179 of 2000 took 0.149s
  training loss:		0.167966
  validation loss:		0.208675
  validation accuracy:		94.46 %
Epoch 180 of 2000 took 0.134s
  training loss:		0.170797
  validation loss:		0.196527
  validation accuracy:		94.67 %
Epoch 181 of 2000 took 0.143s
  training loss:		0.170343
  validation loss:		0.201493
  validation accuracy:		94.35 %
Epoch 182 of 2000 took 0.145s
  training loss:		0.167004
  validation loss:		0.192630
  validation accuracy:		95.00 %
Epoch 183 of 2000 took 0.141s
  training loss:		0.166053
  validation loss:		0.201769
  validation accuracy:		94.78 %
Epoch 184 of 2000 took 0.144s
  training loss:		0.162033
  validation loss:		0.197887
  validation accuracy:		94.35 %
Epoch 185 of 2000 took 0.142s
  training loss:		0.165355
  validation loss:		0.195128
  validation accuracy:		94.57 %
Epoch 186 of 2000 took 0.148s
  training loss:		0.164138
  validation loss:		0.191388
  validation accuracy:		95.00 %
Epoch 187 of 2000 took 0.147s
  training loss:		0.163468
  validation loss:		0.194045
  validation accuracy:		94.57 %
Epoch 188 of 2000 took 0.140s
  training loss:		0.162071
  validation loss:		0.192083
  validation accuracy:		95.22 %
Epoch 189 of 2000 took 0.140s
  training loss:		0.165472
  validation loss:		0.194190
  validation accuracy:		94.67 %
Epoch 190 of 2000 took 0.147s
  training loss:		0.163903
  validation loss:		0.193760
  validation accuracy:		95.00 %
Epoch 191 of 2000 took 0.148s
  training loss:		0.161272
  validation loss:		0.189437
  validation accuracy:		95.00 %
Epoch 192 of 2000 took 0.139s
  training loss:		0.159750
  validation loss:		0.191921
  validation accuracy:		95.00 %
Epoch 193 of 2000 took 0.141s
  training loss:		0.161472
  validation loss:		0.198024
  validation accuracy:		94.67 %
Epoch 194 of 2000 took 0.140s
  training loss:		0.159191
  validation loss:		0.193812
  validation accuracy:		94.89 %
Epoch 195 of 2000 took 0.146s
  training loss:		0.156657
  validation loss:		0.193610
  validation accuracy:		94.78 %
Epoch 196 of 2000 took 0.141s
  training loss:		0.156783
  validation loss:		0.193434
  validation accuracy:		94.67 %
Epoch 197 of 2000 took 0.140s
  training loss:		0.157490
  validation loss:		0.193791
  validation accuracy:		94.78 %
Epoch 198 of 2000 took 0.140s
  training loss:		0.157616
  validation loss:		0.192435
  validation accuracy:		94.89 %
Epoch 199 of 2000 took 0.136s
  training loss:		0.154640
  validation loss:		0.191094
  validation accuracy:		94.78 %
Epoch 200 of 2000 took 0.145s
  training loss:		0.152805
  validation loss:		0.194152
  validation accuracy:		94.46 %
Epoch 201 of 2000 took 0.136s
  training loss:		0.156219
  validation loss:		0.193357
  validation accuracy:		94.67 %
Epoch 202 of 2000 took 0.143s
  training loss:		0.153519
  validation loss:		0.193100
  validation accuracy:		94.89 %
Epoch 203 of 2000 took 0.142s
  training loss:		0.153441
  validation loss:		0.191568
  validation accuracy:		94.78 %
Epoch 204 of 2000 took 0.147s
  training loss:		0.152070
  validation loss:		0.188686
  validation accuracy:		95.00 %
Epoch 205 of 2000 took 0.166s
  training loss:		0.154257
  validation loss:		0.184211
  validation accuracy:		95.22 %
Epoch 206 of 2000 took 0.169s
  training loss:		0.150514
  validation loss:		0.188202
  validation accuracy:		95.22 %
Epoch 207 of 2000 took 0.165s
  training loss:		0.151013
  validation loss:		0.185617
  validation accuracy:		95.22 %
Epoch 208 of 2000 took 0.158s
  training loss:		0.147984
  validation loss:		0.187478
  validation accuracy:		95.11 %
Epoch 209 of 2000 took 0.154s
  training loss:		0.148106
  validation loss:		0.199920
  validation accuracy:		94.67 %
Epoch 210 of 2000 took 0.153s
  training loss:		0.147045
  validation loss:		0.188180
  validation accuracy:		95.00 %
Epoch 211 of 2000 took 0.153s
  training loss:		0.145461
  validation loss:		0.198789
  validation accuracy:		94.78 %
Epoch 212 of 2000 took 0.147s
  training loss:		0.147865
  validation loss:		0.199525
  validation accuracy:		94.67 %
Epoch 213 of 2000 took 0.144s
  training loss:		0.149770
  validation loss:		0.188675
  validation accuracy:		95.22 %
Epoch 214 of 2000 took 0.176s
  training loss:		0.148776
  validation loss:		0.187641
  validation accuracy:		94.89 %
Epoch 215 of 2000 took 0.149s
  training loss:		0.145118
  validation loss:		0.191696
  validation accuracy:		95.00 %
Epoch 216 of 2000 took 0.182s
  training loss:		0.144556
  validation loss:		0.191693
  validation accuracy:		95.11 %
Epoch 217 of 2000 took 0.152s
  training loss:		0.143607
  validation loss:		0.191449
  validation accuracy:		94.78 %
Epoch 218 of 2000 took 0.194s
  training loss:		0.145464
  validation loss:		0.187158
  validation accuracy:		95.22 %
Epoch 219 of 2000 took 0.169s
  training loss:		0.143924
  validation loss:		0.186536
  validation accuracy:		95.11 %
Epoch 220 of 2000 took 0.140s
  training loss:		0.142507
  validation loss:		0.182546
  validation accuracy:		95.11 %
Epoch 221 of 2000 took 0.145s
  training loss:		0.143021
  validation loss:		0.186411
  validation accuracy:		95.22 %
Epoch 222 of 2000 took 0.144s
  training loss:		0.142987
  validation loss:		0.190557
  validation accuracy:		94.78 %
Epoch 223 of 2000 took 0.150s
  training loss:		0.138630
  validation loss:		0.186584
  validation accuracy:		94.89 %
Epoch 224 of 2000 took 0.142s
  training loss:		0.137393
  validation loss:		0.191597
  validation accuracy:		94.89 %
Epoch 225 of 2000 took 0.147s
  training loss:		0.140087
  validation loss:		0.199690
  validation accuracy:		94.46 %
Epoch 226 of 2000 took 0.149s
  training loss:		0.139736
  validation loss:		0.186659
  validation accuracy:		95.11 %
Epoch 227 of 2000 took 0.184s
  training loss:		0.137768
  validation loss:		0.192197
  validation accuracy:		95.11 %
Epoch 228 of 2000 took 0.161s
  training loss:		0.138639
  validation loss:		0.185422
  validation accuracy:		95.43 %
Epoch 229 of 2000 took 0.142s
  training loss:		0.139552
  validation loss:		0.189552
  validation accuracy:		94.78 %
Epoch 230 of 2000 took 0.144s
  training loss:		0.137711
  validation loss:		0.185885
  validation accuracy:		95.11 %
Epoch 231 of 2000 took 0.148s
  training loss:		0.136142
  validation loss:		0.189310
  validation accuracy:		94.78 %
Epoch 232 of 2000 took 0.143s
  training loss:		0.135240
  validation loss:		0.183832
  validation accuracy:		95.00 %
Epoch 233 of 2000 took 0.150s
  training loss:		0.133955
  validation loss:		0.188759
  validation accuracy:		95.00 %
Epoch 234 of 2000 took 0.144s
  training loss:		0.140181
  validation loss:		0.185501
  validation accuracy:		95.11 %
Epoch 235 of 2000 took 0.141s
  training loss:		0.136669
  validation loss:		0.189663
  validation accuracy:		94.89 %
Epoch 236 of 2000 took 0.148s
  training loss:		0.135393
  validation loss:		0.197939
  validation accuracy:		94.46 %
Epoch 237 of 2000 took 0.146s
  training loss:		0.137702
  validation loss:		0.186565
  validation accuracy:		94.89 %
Epoch 238 of 2000 took 0.149s
  training loss:		0.134689
  validation loss:		0.182326
  validation accuracy:		95.43 %
Epoch 239 of 2000 took 0.153s
  training loss:		0.133936
  validation loss:		0.187840
  validation accuracy:		95.00 %
Epoch 240 of 2000 took 0.145s
  training loss:		0.133765
  validation loss:		0.182335
  validation accuracy:		95.54 %
Epoch 241 of 2000 took 0.149s
  training loss:		0.134453
  validation loss:		0.183752
  validation accuracy:		95.22 %
Epoch 242 of 2000 took 0.156s
  training loss:		0.131945
  validation loss:		0.188049
  validation accuracy:		94.89 %
Epoch 243 of 2000 took 0.148s
  training loss:		0.132463
  validation loss:		0.199372
  validation accuracy:		94.46 %
Epoch 244 of 2000 took 0.163s
  training loss:		0.131793
  validation loss:		0.187013
  validation accuracy:		95.00 %
Epoch 245 of 2000 took 0.145s
  training loss:		0.130883
  validation loss:		0.195263
  validation accuracy:		95.11 %
Epoch 246 of 2000 took 0.162s
  training loss:		0.129590
  validation loss:		0.186124
  validation accuracy:		95.00 %
Epoch 247 of 2000 took 0.151s
  training loss:		0.133554
  validation loss:		0.184327
  validation accuracy:		95.00 %
Epoch 248 of 2000 took 0.185s
  training loss:		0.131098
  validation loss:		0.183551
  validation accuracy:		95.43 %
Epoch 249 of 2000 took 0.155s
  training loss:		0.131107
  validation loss:		0.196635
  validation accuracy:		94.78 %
Epoch 250 of 2000 took 0.169s
  training loss:		0.132604
  validation loss:		0.186060
  validation accuracy:		95.22 %
Epoch 251 of 2000 took 0.163s
  training loss:		0.128651
  validation loss:		0.185163
  validation accuracy:		95.00 %
Epoch 252 of 2000 took 0.196s
  training loss:		0.127926
  validation loss:		0.183412
  validation accuracy:		95.33 %
Epoch 253 of 2000 took 0.150s
  training loss:		0.128559
  validation loss:		0.187455
  validation accuracy:		95.00 %
Epoch 254 of 2000 took 0.174s
  training loss:		0.128758
  validation loss:		0.181809
  validation accuracy:		95.22 %
Epoch 255 of 2000 took 0.147s
  training loss:		0.130625
  validation loss:		0.182721
  validation accuracy:		95.11 %
Epoch 256 of 2000 took 0.175s
  training loss:		0.124979
  validation loss:		0.183288
  validation accuracy:		95.11 %
Epoch 257 of 2000 took 0.154s
  training loss:		0.122647
  validation loss:		0.185799
  validation accuracy:		95.65 %
Epoch 258 of 2000 took 0.171s
  training loss:		0.123495
  validation loss:		0.180648
  validation accuracy:		95.11 %
Epoch 259 of 2000 took 0.147s
  training loss:		0.126043
  validation loss:		0.185958
  validation accuracy:		95.00 %
Epoch 260 of 2000 took 0.162s
  training loss:		0.126167
  validation loss:		0.181587
  validation accuracy:		95.33 %
Epoch 261 of 2000 took 0.150s
  training loss:		0.127039
  validation loss:		0.185488
  validation accuracy:		95.11 %
Epoch 262 of 2000 took 0.144s
  training loss:		0.124531
  validation loss:		0.183219
  validation accuracy:		95.00 %
Epoch 263 of 2000 took 0.147s
  training loss:		0.126035
  validation loss:		0.182232
  validation accuracy:		95.22 %
Epoch 264 of 2000 took 0.144s
  training loss:		0.123019
  validation loss:		0.183482
  validation accuracy:		95.11 %
Epoch 265 of 2000 took 0.144s
  training loss:		0.122841
  validation loss:		0.186315
  validation accuracy:		94.89 %
Epoch 266 of 2000 took 0.149s
  training loss:		0.123723
  validation loss:		0.188604
  validation accuracy:		95.00 %
Epoch 267 of 2000 took 0.149s
  training loss:		0.123705
  validation loss:		0.179621
  validation accuracy:		94.89 %
Epoch 268 of 2000 took 0.145s
  training loss:		0.123416
  validation loss:		0.183607
  validation accuracy:		95.00 %
Epoch 269 of 2000 took 0.149s
  training loss:		0.121891
  validation loss:		0.182191
  validation accuracy:		95.22 %
Epoch 270 of 2000 took 0.152s
  training loss:		0.123127
  validation loss:		0.184130
  validation accuracy:		95.11 %
Epoch 271 of 2000 took 0.146s
  training loss:		0.119807
  validation loss:		0.187164
  validation accuracy:		94.89 %
Epoch 272 of 2000 took 0.148s
  training loss:		0.118203
  validation loss:		0.185365
  validation accuracy:		95.33 %
Epoch 273 of 2000 took 0.148s
  training loss:		0.122462
  validation loss:		0.183373
  validation accuracy:		95.11 %
Epoch 274 of 2000 took 0.149s
  training loss:		0.118108
  validation loss:		0.180226
  validation accuracy:		95.22 %
Epoch 275 of 2000 took 0.142s
  training loss:		0.122928
  validation loss:		0.185587
  validation accuracy:		94.89 %
Epoch 276 of 2000 took 0.141s
  training loss:		0.119176
  validation loss:		0.190486
  validation accuracy:		95.22 %
Epoch 277 of 2000 took 0.150s
  training loss:		0.118499
  validation loss:		0.185606
  validation accuracy:		95.00 %
Epoch 278 of 2000 took 0.151s
  training loss:		0.120456
  validation loss:		0.186644
  validation accuracy:		95.43 %
Epoch 279 of 2000 took 0.161s
  training loss:		0.115101
  validation loss:		0.190735
  validation accuracy:		95.11 %
Epoch 280 of 2000 took 0.156s
  training loss:		0.117648
  validation loss:		0.186627
  validation accuracy:		95.00 %
Epoch 281 of 2000 took 0.150s
  training loss:		0.115402
  validation loss:		0.185615
  validation accuracy:		95.22 %
Epoch 282 of 2000 took 0.153s
  training loss:		0.115598
  validation loss:		0.183553
  validation accuracy:		95.22 %
Epoch 283 of 2000 took 0.147s
  training loss:		0.114785
  validation loss:		0.183157
  validation accuracy:		95.33 %
Epoch 284 of 2000 took 0.145s
  training loss:		0.114364
  validation loss:		0.181328
  validation accuracy:		94.89 %
Epoch 285 of 2000 took 0.150s
  training loss:		0.114220
  validation loss:		0.185749
  validation accuracy:		94.89 %
Epoch 286 of 2000 took 0.148s
  training loss:		0.116925
  validation loss:		0.184704
  validation accuracy:		94.89 %
Epoch 287 of 2000 took 0.161s
  training loss:		0.119233
  validation loss:		0.185610
  validation accuracy:		95.22 %
Epoch 288 of 2000 took 0.183s
  training loss:		0.114584
  validation loss:		0.197384
  validation accuracy:		95.00 %
Epoch 289 of 2000 took 0.174s
  training loss:		0.113519
  validation loss:		0.180356
  validation accuracy:		95.22 %
Epoch 290 of 2000 took 0.148s
  training loss:		0.111708
  validation loss:		0.188373
  validation accuracy:		94.89 %
Epoch 291 of 2000 took 0.168s
  training loss:		0.113912
  validation loss:		0.185844
  validation accuracy:		95.00 %
Epoch 292 of 2000 took 0.148s
  training loss:		0.113204
  validation loss:		0.185781
  validation accuracy:		95.11 %
Epoch 293 of 2000 took 0.157s
  training loss:		0.115227
  validation loss:		0.184707
  validation accuracy:		94.89 %
Epoch 294 of 2000 took 0.148s
  training loss:		0.112949
  validation loss:		0.182835
  validation accuracy:		95.54 %
Epoch 295 of 2000 took 0.139s
  training loss:		0.112680
  validation loss:		0.191370
  validation accuracy:		95.00 %
Epoch 296 of 2000 took 0.132s
  training loss:		0.110108
  validation loss:		0.185518
  validation accuracy:		95.00 %
Epoch 297 of 2000 took 0.133s
  training loss:		0.112724
  validation loss:		0.187998
  validation accuracy:		95.00 %
Epoch 298 of 2000 took 0.146s
  training loss:		0.110501
  validation loss:		0.185416
  validation accuracy:		95.00 %
Epoch 299 of 2000 took 0.140s
  training loss:		0.110961
  validation loss:		0.194201
  validation accuracy:		95.22 %
Epoch 300 of 2000 took 0.146s
  training loss:		0.108601
  validation loss:		0.185181
  validation accuracy:		95.11 %
Epoch 301 of 2000 took 0.142s
  training loss:		0.111063
  validation loss:		0.183418
  validation accuracy:		95.33 %
Epoch 302 of 2000 took 0.137s
  training loss:		0.108588
  validation loss:		0.183200
  validation accuracy:		95.00 %
Epoch 303 of 2000 took 0.141s
  training loss:		0.110018
  validation loss:		0.184883
  validation accuracy:		95.11 %
Epoch 304 of 2000 took 0.133s
  training loss:		0.110277
  validation loss:		0.197037
  validation accuracy:		94.78 %
Epoch 305 of 2000 took 0.151s
  training loss:		0.111032
  validation loss:		0.186712
  validation accuracy:		94.78 %
Epoch 306 of 2000 took 0.139s
  training loss:		0.109197
  validation loss:		0.185486
  validation accuracy:		95.22 %
Epoch 307 of 2000 took 0.177s
  training loss:		0.109044
  validation loss:		0.189054
  validation accuracy:		94.67 %
Epoch 308 of 2000 took 0.200s
  training loss:		0.108688
  validation loss:		0.189023
  validation accuracy:		94.89 %
Epoch 309 of 2000 took 0.171s
  training loss:		0.108596
  validation loss:		0.193061
  validation accuracy:		94.89 %
Epoch 310 of 2000 took 0.147s
  training loss:		0.105202
  validation loss:		0.188722
  validation accuracy:		95.00 %
Epoch 311 of 2000 took 0.165s
  training loss:		0.106397
  validation loss:		0.185673
  validation accuracy:		95.22 %
Epoch 312 of 2000 took 0.152s
  training loss:		0.105067
  validation loss:		0.198187
  validation accuracy:		94.46 %
Epoch 313 of 2000 took 0.151s
  training loss:		0.105845
  validation loss:		0.186684
  validation accuracy:		95.22 %
Epoch 314 of 2000 took 0.147s
  training loss:		0.108343
  validation loss:		0.193909
  validation accuracy:		94.89 %
Epoch 315 of 2000 took 0.148s
  training loss:		0.105889
  validation loss:		0.189041
  validation accuracy:		95.00 %
Epoch 316 of 2000 took 0.154s
  training loss:		0.104512
  validation loss:		0.188052
  validation accuracy:		95.11 %
Epoch 317 of 2000 took 0.150s
  training loss:		0.102991
  validation loss:		0.185346
  validation accuracy:		94.78 %
Epoch 318 of 2000 took 0.146s
  training loss:		0.105355
  validation loss:		0.188875
  validation accuracy:		94.78 %
Epoch 319 of 2000 took 0.137s
  training loss:		0.104250
  validation loss:		0.190990
  validation accuracy:		95.22 %
Epoch 320 of 2000 took 0.148s
  training loss:		0.103016
  validation loss:		0.185301
  validation accuracy:		95.11 %
Epoch 321 of 2000 took 0.148s
  training loss:		0.104659
  validation loss:		0.186020
  validation accuracy:		94.89 %
Epoch 322 of 2000 took 0.143s
  training loss:		0.105819
  validation loss:		0.184930
  validation accuracy:		95.22 %
Epoch 323 of 2000 took 0.146s
  training loss:		0.103306
  validation loss:		0.192346
  validation accuracy:		95.00 %
Epoch 324 of 2000 took 0.147s
  training loss:		0.103996
  validation loss:		0.189015
  validation accuracy:		94.78 %
Epoch 325 of 2000 took 0.146s
  training loss:		0.103994
  validation loss:		0.189578
  validation accuracy:		94.89 %
Epoch 326 of 2000 took 0.149s
  training loss:		0.103997
  validation loss:		0.188994
  validation accuracy:		95.33 %
Epoch 327 of 2000 took 0.150s
  training loss:		0.105868
  validation loss:		0.185903
  validation accuracy:		95.22 %
Epoch 328 of 2000 took 0.145s
  training loss:		0.102810
  validation loss:		0.189369
  validation accuracy:		94.57 %
Epoch 329 of 2000 took 0.156s
  training loss:		0.100744
  validation loss:		0.192797
  validation accuracy:		94.78 %
Epoch 330 of 2000 took 0.136s
  training loss:		0.102449
  validation loss:		0.187222
  validation accuracy:		94.57 %
Epoch 331 of 2000 took 0.147s
  training loss:		0.102458
  validation loss:		0.199445
  validation accuracy:		94.89 %
Epoch 332 of 2000 took 0.144s
  training loss:		0.100119
  validation loss:		0.200553
  validation accuracy:		94.46 %
Epoch 333 of 2000 took 0.141s
  training loss:		0.101399
  validation loss:		0.186257
  validation accuracy:		94.78 %
Epoch 334 of 2000 took 0.144s
  training loss:		0.101958
  validation loss:		0.196159
  validation accuracy:		94.57 %
Epoch 335 of 2000 took 0.142s
  training loss:		0.101639
  validation loss:		0.182714
  validation accuracy:		95.22 %
Epoch 336 of 2000 took 0.137s
  training loss:		0.100494
  validation loss:		0.187117
  validation accuracy:		94.78 %
Epoch 337 of 2000 took 0.142s
  training loss:		0.100674
  validation loss:		0.197566
  validation accuracy:		94.24 %
Epoch 338 of 2000 took 0.153s
  training loss:		0.097288
  validation loss:		0.188257
  validation accuracy:		95.11 %
Epoch 339 of 2000 took 0.168s
  training loss:		0.099809
  validation loss:		0.191311
  validation accuracy:		95.00 %
Epoch 340 of 2000 took 0.145s
  training loss:		0.095448
  validation loss:		0.185524
  validation accuracy:		95.22 %
Epoch 341 of 2000 took 0.137s
  training loss:		0.097626
  validation loss:		0.185870
  validation accuracy:		94.78 %
Epoch 342 of 2000 took 0.143s
  training loss:		0.095543
  validation loss:		0.189018
  validation accuracy:		94.57 %
Epoch 343 of 2000 took 0.144s
  training loss:		0.097420
  validation loss:		0.190447
  validation accuracy:		94.57 %
Epoch 344 of 2000 took 0.141s
  training loss:		0.099357
  validation loss:		0.191855
  validation accuracy:		94.78 %
Epoch 345 of 2000 took 0.138s
  training loss:		0.099151
  validation loss:		0.194093
  validation accuracy:		94.78 %
Epoch 346 of 2000 took 0.137s
  training loss:		0.096813
  validation loss:		0.195158
  validation accuracy:		94.67 %
Epoch 347 of 2000 took 0.145s
  training loss:		0.099588
  validation loss:		0.195519
  validation accuracy:		94.46 %
Epoch 348 of 2000 took 0.148s
  training loss:		0.096639
  validation loss:		0.190625
  validation accuracy:		94.67 %
Epoch 349 of 2000 took 0.145s
  training loss:		0.094911
  validation loss:		0.192876
  validation accuracy:		94.67 %
Epoch 350 of 2000 took 0.144s
  training loss:		0.092893
  validation loss:		0.190160
  validation accuracy:		94.78 %
Epoch 351 of 2000 took 0.134s
  training loss:		0.091944
  validation loss:		0.191026
  validation accuracy:		94.67 %
Epoch 352 of 2000 took 0.139s
  training loss:		0.095156
  validation loss:		0.186452
  validation accuracy:		95.11 %
Epoch 353 of 2000 took 0.141s
  training loss:		0.097657
  validation loss:		0.191918
  validation accuracy:		94.89 %
Epoch 354 of 2000 took 0.140s
  training loss:		0.092863
  validation loss:		0.188519
  validation accuracy:		94.89 %
Epoch 355 of 2000 took 0.144s
  training loss:		0.091669
  validation loss:		0.188238
  validation accuracy:		95.11 %
Epoch 356 of 2000 took 0.147s
  training loss:		0.093804
  validation loss:		0.199501
  validation accuracy:		94.57 %
Epoch 357 of 2000 took 0.137s
  training loss:		0.094962
  validation loss:		0.189677
  validation accuracy:		94.89 %
Epoch 358 of 2000 took 0.141s
  training loss:		0.094760
  validation loss:		0.188875
  validation accuracy:		95.00 %
Epoch 359 of 2000 took 0.141s
  training loss:		0.093546
  validation loss:		0.194416
  validation accuracy:		94.57 %
Epoch 360 of 2000 took 0.144s
  training loss:		0.093463
  validation loss:		0.197023
  validation accuracy:		94.35 %
Epoch 361 of 2000 took 0.138s
  training loss:		0.095154
  validation loss:		0.187347
  validation accuracy:		95.00 %
Epoch 362 of 2000 took 0.137s
  training loss:		0.093119
  validation loss:		0.191973
  validation accuracy:		94.78 %
Epoch 363 of 2000 took 0.141s
  training loss:		0.094867
  validation loss:		0.199188
  validation accuracy:		94.57 %
Epoch 364 of 2000 took 0.154s
  training loss:		0.088800
  validation loss:		0.189328
  validation accuracy:		95.00 %
Epoch 365 of 2000 took 0.147s
  training loss:		0.094260
  validation loss:		0.197019
  validation accuracy:		94.46 %
Epoch 366 of 2000 took 0.148s
  training loss:		0.092955
  validation loss:		0.199978
  validation accuracy:		94.57 %
Epoch 367 of 2000 took 0.138s
  training loss:		0.095081
  validation loss:		0.193496
  validation accuracy:		94.78 %
Epoch 368 of 2000 took 0.143s
  training loss:		0.091212
  validation loss:		0.189530
  validation accuracy:		94.67 %
Epoch 369 of 2000 took 0.138s
  training loss:		0.088933
  validation loss:		0.194770
  validation accuracy:		94.35 %
Epoch 370 of 2000 took 0.143s
  training loss:		0.090035
  validation loss:		0.190989
  validation accuracy:		94.67 %
Epoch 371 of 2000 took 0.144s
  training loss:		0.091038
  validation loss:		0.192390
  validation accuracy:		94.46 %
Epoch 372 of 2000 took 0.138s
  training loss:		0.091174
  validation loss:		0.196949
  validation accuracy:		94.46 %
Epoch 373 of 2000 took 0.147s
  training loss:		0.089617
  validation loss:		0.197938
  validation accuracy:		94.35 %
Epoch 374 of 2000 took 0.140s
  training loss:		0.089735
  validation loss:		0.198346
  validation accuracy:		94.67 %
Epoch 375 of 2000 took 0.142s
  training loss:		0.089657
  validation loss:		0.196997
  validation accuracy:		94.57 %
Epoch 376 of 2000 took 0.145s
  training loss:		0.089555
  validation loss:		0.194711
  validation accuracy:		94.46 %
Epoch 377 of 2000 took 0.141s
  training loss:		0.088489
  validation loss:		0.190193
  validation accuracy:		94.89 %
Epoch 378 of 2000 took 0.143s
  training loss:		0.085306
  validation loss:		0.197904
  validation accuracy:		94.35 %
Epoch 379 of 2000 took 0.140s
  training loss:		0.088828
  validation loss:		0.198627
  validation accuracy:		94.57 %
Epoch 380 of 2000 took 0.141s
  training loss:		0.088991
  validation loss:		0.195710
  validation accuracy:		94.46 %
Epoch 381 of 2000 took 0.141s
  training loss:		0.086273
  validation loss:		0.189350
  validation accuracy:		94.89 %
Epoch 382 of 2000 took 0.146s
  training loss:		0.086426
  validation loss:		0.195586
  validation accuracy:		94.46 %
Epoch 383 of 2000 took 0.143s
  training loss:		0.088644
  validation loss:		0.191269
  validation accuracy:		94.46 %
Epoch 384 of 2000 took 0.141s
  training loss:		0.081776
  validation loss:		0.196411
  validation accuracy:		94.89 %
Epoch 385 of 2000 took 0.144s
  training loss:		0.086050
  validation loss:		0.203992
  validation accuracy:		94.24 %
Epoch 386 of 2000 took 0.146s
  training loss:		0.088686
  validation loss:		0.195560
  validation accuracy:		95.00 %
Epoch 387 of 2000 took 0.155s
  training loss:		0.086274
  validation loss:		0.190208
  validation accuracy:		95.00 %
Epoch 388 of 2000 took 0.144s
  training loss:		0.090121
  validation loss:		0.202615
  validation accuracy:		94.46 %
Epoch 389 of 2000 took 0.146s
  training loss:		0.087116
  validation loss:		0.202407
  validation accuracy:		94.13 %
Epoch 390 of 2000 took 0.156s
  training loss:		0.083803
  validation loss:		0.202505
  validation accuracy:		94.35 %
Epoch 391 of 2000 took 0.142s
  training loss:		0.084177
  validation loss:		0.193846
  validation accuracy:		95.22 %
Epoch 392 of 2000 took 0.138s
  training loss:		0.086438
  validation loss:		0.197656
  validation accuracy:		94.35 %
Epoch 393 of 2000 took 0.138s
  training loss:		0.086013
  validation loss:		0.197587
  validation accuracy:		94.46 %
Epoch 394 of 2000 took 0.148s
  training loss:		0.085620
  validation loss:		0.196652
  validation accuracy:		94.67 %
Epoch 395 of 2000 took 0.144s
  training loss:		0.085263
  validation loss:		0.194074
  validation accuracy:		94.78 %
Epoch 396 of 2000 took 0.143s
  training loss:		0.083717
  validation loss:		0.194502
  validation accuracy:		94.24 %
Epoch 397 of 2000 took 0.147s
  training loss:		0.086021
  validation loss:		0.203879
  validation accuracy:		94.35 %
Epoch 398 of 2000 took 0.142s
  training loss:		0.082721
  validation loss:		0.196604
  validation accuracy:		94.57 %
Epoch 399 of 2000 took 0.137s
  training loss:		0.083639
  validation loss:		0.199124
  validation accuracy:		94.13 %
Epoch 400 of 2000 took 0.144s
  training loss:		0.082470
  validation loss:		0.190235
  validation accuracy:		94.89 %
Epoch 401 of 2000 took 0.145s
  training loss:		0.083899
  validation loss:		0.193669
  validation accuracy:		94.57 %
Epoch 402 of 2000 took 0.141s
  training loss:		0.081060
  validation loss:		0.197526
  validation accuracy:		94.46 %
Epoch 403 of 2000 took 0.135s
  training loss:		0.083781
  validation loss:		0.195989
  validation accuracy:		94.67 %
Epoch 404 of 2000 took 0.148s
  training loss:		0.082612
  validation loss:		0.201867
  validation accuracy:		94.57 %
Epoch 405 of 2000 took 0.148s
  training loss:		0.084375
  validation loss:		0.200010
  validation accuracy:		94.57 %
Epoch 406 of 2000 took 0.143s
  training loss:		0.084512
  validation loss:		0.200254
  validation accuracy:		94.57 %
Epoch 407 of 2000 took 0.174s
  training loss:		0.081032
  validation loss:		0.209057
  validation accuracy:		94.57 %
Epoch 408 of 2000 took 0.139s
  training loss:		0.083238
  validation loss:		0.205795
  validation accuracy:		94.02 %
Epoch 409 of 2000 took 0.150s
  training loss:		0.082762
  validation loss:		0.195460
  validation accuracy:		94.57 %
Epoch 410 of 2000 took 0.141s
  training loss:		0.081472
  validation loss:		0.197911
  validation accuracy:		94.13 %
Epoch 411 of 2000 took 0.148s
  training loss:		0.079504
  validation loss:		0.200950
  validation accuracy:		94.46 %
Epoch 412 of 2000 took 0.141s
  training loss:		0.080465
  validation loss:		0.202532
  validation accuracy:		94.24 %
Epoch 413 of 2000 took 0.178s
  training loss:		0.081086
  validation loss:		0.201443
  validation accuracy:		94.35 %
Epoch 414 of 2000 took 0.152s
  training loss:		0.082188
  validation loss:		0.198836
  validation accuracy:		94.35 %
Epoch 415 of 2000 took 0.142s
  training loss:		0.081254
  validation loss:		0.210300
  validation accuracy:		93.91 %
Epoch 416 of 2000 took 0.142s
  training loss:		0.079898
  validation loss:		0.199771
  validation accuracy:		94.57 %
Epoch 417 of 2000 took 0.139s
  training loss:		0.080929
  validation loss:		0.196559
  validation accuracy:		94.46 %
Epoch 418 of 2000 took 0.139s
  training loss:		0.078914
  validation loss:		0.197908
  validation accuracy:		94.35 %
Epoch 419 of 2000 took 0.141s
  training loss:		0.076834
  validation loss:		0.201226
  validation accuracy:		94.13 %
Epoch 420 of 2000 took 0.148s
  training loss:		0.078742
  validation loss:		0.200963
  validation accuracy:		94.13 %
Epoch 421 of 2000 took 0.146s
  training loss:		0.080461
  validation loss:		0.200992
  validation accuracy:		94.24 %
Epoch 422 of 2000 took 0.140s
  training loss:		0.080257
  validation loss:		0.198235
  validation accuracy:		94.46 %
Epoch 423 of 2000 took 0.143s
  training loss:		0.079495
  validation loss:		0.196223
  validation accuracy:		94.57 %
Epoch 424 of 2000 took 0.142s
  training loss:		0.078018
  validation loss:		0.199723
  validation accuracy:		94.57 %
Epoch 425 of 2000 took 0.143s
  training loss:		0.077966
  validation loss:		0.201343
  validation accuracy:		94.35 %
Epoch 426 of 2000 took 0.140s
  training loss:		0.076219
  validation loss:		0.204285
  validation accuracy:		94.13 %
Epoch 427 of 2000 took 0.143s
  training loss:		0.076864
  validation loss:		0.199535
  validation accuracy:		94.35 %
Epoch 428 of 2000 took 0.135s
  training loss:		0.076790
  validation loss:		0.209647
  validation accuracy:		94.24 %
Epoch 429 of 2000 took 0.144s
  training loss:		0.077991
  validation loss:		0.202475
  validation accuracy:		94.35 %
Epoch 430 of 2000 took 0.140s
  training loss:		0.077824
  validation loss:		0.207833
  validation accuracy:		93.80 %
Epoch 431 of 2000 took 0.139s
  training loss:		0.077041
  validation loss:		0.205006
  validation accuracy:		94.46 %
Epoch 432 of 2000 took 0.139s
  training loss:		0.076669
  validation loss:		0.204047
  validation accuracy:		94.24 %
Epoch 433 of 2000 took 0.148s
  training loss:		0.075889
  validation loss:		0.211405
  validation accuracy:		93.91 %
Epoch 434 of 2000 took 0.143s
  training loss:		0.074137
  validation loss:		0.213995
  validation accuracy:		93.91 %
Epoch 435 of 2000 took 0.142s
  training loss:		0.074345
  validation loss:		0.205914
  validation accuracy:		94.13 %
Epoch 436 of 2000 took 0.151s
  training loss:		0.077758
  validation loss:		0.204192
  validation accuracy:		94.24 %
Epoch 437 of 2000 took 0.143s
  training loss:		0.077066
  validation loss:		0.213973
  validation accuracy:		94.24 %
Epoch 438 of 2000 took 0.145s
  training loss:		0.076584
  validation loss:		0.206384
  validation accuracy:		94.35 %
Epoch 439 of 2000 took 0.144s
  training loss:		0.075132
  validation loss:		0.200867
  validation accuracy:		94.67 %
Epoch 440 of 2000 took 0.148s
  training loss:		0.074341
  validation loss:		0.214257
  validation accuracy:		94.02 %
Epoch 441 of 2000 took 0.140s
  training loss:		0.073415
  validation loss:		0.203652
  validation accuracy:		94.24 %
Epoch 442 of 2000 took 0.142s
  training loss:		0.075493
  validation loss:		0.218129
  validation accuracy:		93.91 %
Epoch 443 of 2000 took 0.139s
  training loss:		0.073695
  validation loss:		0.202680
  validation accuracy:		94.13 %
Epoch 444 of 2000 took 0.133s
  training loss:		0.074492
  validation loss:		0.215806
  validation accuracy:		93.80 %
Epoch 445 of 2000 took 0.151s
  training loss:		0.072074
  validation loss:		0.211532
  validation accuracy:		94.57 %
Epoch 446 of 2000 took 0.181s
  training loss:		0.076808
  validation loss:		0.206833
  validation accuracy:		94.02 %
Epoch 447 of 2000 took 0.138s
  training loss:		0.074964
  validation loss:		0.205742
  validation accuracy:		94.24 %
Epoch 448 of 2000 took 0.140s
  training loss:		0.072817
  validation loss:		0.197810
  validation accuracy:		94.24 %
Epoch 449 of 2000 took 0.168s
  training loss:		0.074355
  validation loss:		0.205675
  validation accuracy:		94.24 %
Epoch 450 of 2000 took 0.148s
  training loss:		0.071827
  validation loss:		0.213795
  validation accuracy:		93.91 %
Epoch 451 of 2000 took 0.147s
  training loss:		0.072853
  validation loss:		0.204105
  validation accuracy:		94.67 %
Epoch 452 of 2000 took 0.157s
  training loss:		0.072095
  validation loss:		0.206579
  validation accuracy:		94.13 %
Epoch 453 of 2000 took 0.165s
  training loss:		0.073781
  validation loss:		0.208746
  validation accuracy:		94.24 %
Epoch 454 of 2000 took 0.173s
  training loss:		0.072325
  validation loss:		0.207313
  validation accuracy:		94.02 %
Epoch 455 of 2000 took 0.152s
  training loss:		0.072315
  validation loss:		0.213479
  validation accuracy:		94.13 %
Epoch 456 of 2000 took 0.150s
  training loss:		0.071431
  validation loss:		0.212073
  validation accuracy:		93.91 %
Epoch 457 of 2000 took 0.148s
  training loss:		0.069666
  validation loss:		0.211067
  validation accuracy:		93.91 %
Epoch 458 of 2000 took 0.147s
  training loss:		0.071644
  validation loss:		0.206421
  validation accuracy:		94.46 %
Epoch 459 of 2000 took 0.149s
  training loss:		0.072750
  validation loss:		0.207075
  validation accuracy:		94.13 %
Epoch 460 of 2000 took 0.141s
  training loss:		0.069406
  validation loss:		0.217990
  validation accuracy:		93.80 %
Epoch 461 of 2000 took 0.162s
  training loss:		0.070501
  validation loss:		0.213607
  validation accuracy:		93.80 %
Epoch 462 of 2000 took 0.149s
  training loss:		0.070905
  validation loss:		0.209536
  validation accuracy:		94.24 %
Epoch 463 of 2000 took 0.141s
  training loss:		0.071722
  validation loss:		0.209241
  validation accuracy:		94.02 %
Epoch 464 of 2000 took 0.150s
  training loss:		0.070581
  validation loss:		0.205695
  validation accuracy:		94.46 %
Epoch 465 of 2000 took 0.147s
  training loss:		0.070450
  validation loss:		0.210511
  validation accuracy:		94.13 %
Epoch 466 of 2000 took 0.149s
  training loss:		0.072434
  validation loss:		0.219137
  validation accuracy:		93.91 %
Epoch 467 of 2000 took 0.149s
  training loss:		0.070064
  validation loss:		0.210708
  validation accuracy:		94.02 %
Epoch 468 of 2000 took 0.155s
  training loss:		0.068586
  validation loss:		0.208937
  validation accuracy:		94.13 %
Epoch 469 of 2000 took 0.168s
  training loss:		0.068491
  validation loss:		0.216329
  validation accuracy:		94.13 %
Epoch 470 of 2000 took 0.146s
  training loss:		0.066621
  validation loss:		0.216897
  validation accuracy:		94.02 %
Epoch 471 of 2000 took 0.190s
  training loss:		0.066617
  validation loss:		0.211309
  validation accuracy:		94.02 %
Epoch 472 of 2000 took 0.160s
  training loss:		0.069649
  validation loss:		0.209321
  validation accuracy:		94.13 %
Epoch 473 of 2000 took 0.146s
  training loss:		0.070304
  validation loss:		0.206404
  validation accuracy:		94.13 %
Epoch 474 of 2000 took 0.152s
  training loss:		0.066783
  validation loss:		0.215685
  validation accuracy:		94.13 %
Epoch 475 of 2000 took 0.157s
  training loss:		0.066471
  validation loss:		0.213603
  validation accuracy:		94.13 %
Epoch 476 of 2000 took 0.138s
  training loss:		0.069524
  validation loss:		0.211189
  validation accuracy:		94.35 %
Epoch 477 of 2000 took 0.142s
  training loss:		0.069474
  validation loss:		0.212136
  validation accuracy:		94.13 %
Epoch 478 of 2000 took 0.144s
  training loss:		0.066293
  validation loss:		0.210836
  validation accuracy:		94.57 %
Epoch 479 of 2000 took 0.143s
  training loss:		0.067226
  validation loss:		0.212785
  validation accuracy:		94.02 %
Epoch 480 of 2000 took 0.135s
  training loss:		0.066991
  validation loss:		0.216192
  validation accuracy:		93.91 %
Epoch 481 of 2000 took 0.133s
  training loss:		0.066804
  validation loss:		0.214155
  validation accuracy:		94.13 %
Epoch 482 of 2000 took 0.140s
  training loss:		0.069427
  validation loss:		0.210797
  validation accuracy:		94.46 %
Epoch 483 of 2000 took 0.158s
  training loss:		0.067038
  validation loss:		0.214623
  validation accuracy:		93.91 %
Epoch 484 of 2000 took 0.154s
  training loss:		0.066994
  validation loss:		0.214562
  validation accuracy:		94.02 %
Epoch 485 of 2000 took 0.136s
  training loss:		0.067336
  validation loss:		0.211683
  validation accuracy:		94.57 %
Epoch 486 of 2000 took 0.143s
  training loss:		0.066716
  validation loss:		0.229136
  validation accuracy:		93.70 %
Epoch 487 of 2000 took 0.166s
  training loss:		0.065267
  validation loss:		0.215050
  validation accuracy:		94.02 %
Epoch 488 of 2000 took 0.174s
  training loss:		0.065739
  validation loss:		0.217194
  validation accuracy:		93.91 %
Epoch 489 of 2000 took 0.148s
  training loss:		0.064808
  validation loss:		0.216677
  validation accuracy:		93.91 %
Epoch 490 of 2000 took 0.151s
  training loss:		0.065865
  validation loss:		0.214440
  validation accuracy:		94.35 %
Epoch 491 of 2000 took 0.167s
  training loss:		0.063128
  validation loss:		0.223046
  validation accuracy:		93.91 %
Epoch 492 of 2000 took 0.146s
  training loss:		0.066239
  validation loss:		0.222869
  validation accuracy:		93.91 %
Epoch 493 of 2000 took 0.147s
  training loss:		0.067390
  validation loss:		0.220486
  validation accuracy:		94.13 %
Epoch 494 of 2000 took 0.152s
  training loss:		0.066965
  validation loss:		0.213760
  validation accuracy:		94.13 %
Epoch 495 of 2000 took 0.179s
  training loss:		0.063622
  validation loss:		0.217782
  validation accuracy:		94.13 %
Epoch 496 of 2000 took 0.134s
  training loss:		0.064702
  validation loss:		0.217455
  validation accuracy:		94.13 %
Epoch 497 of 2000 took 0.152s
  training loss:		0.066410
  validation loss:		0.218771
  validation accuracy:		94.13 %
Epoch 498 of 2000 took 0.144s
  training loss:		0.062308
  validation loss:		0.236994
  validation accuracy:		93.48 %
Epoch 499 of 2000 took 0.168s
  training loss:		0.065155
  validation loss:		0.229007
  validation accuracy:		93.70 %
Epoch 500 of 2000 took 0.165s
  training loss:		0.064013
  validation loss:		0.222978
  validation accuracy:		94.02 %
Epoch 501 of 2000 took 0.150s
  training loss:		0.061103
  validation loss:		0.212645
  validation accuracy:		94.02 %
Epoch 502 of 2000 took 0.196s
  training loss:		0.064567
  validation loss:		0.226764
  validation accuracy:		93.59 %
Epoch 503 of 2000 took 0.149s
  training loss:		0.062953
  validation loss:		0.232709
  validation accuracy:		93.70 %
Epoch 504 of 2000 took 0.140s
  training loss:		0.063641
  validation loss:		0.214936
  validation accuracy:		94.02 %
Epoch 505 of 2000 took 0.133s
  training loss:		0.064617
  validation loss:		0.213539
  validation accuracy:		94.35 %
Epoch 506 of 2000 took 0.141s
  training loss:		0.063003
  validation loss:		0.229710
  validation accuracy:		93.80 %
Epoch 507 of 2000 took 0.144s
  training loss:		0.063895
  validation loss:		0.226442
  validation accuracy:		93.59 %
Epoch 508 of 2000 took 0.139s
  training loss:		0.062563
  validation loss:		0.229086
  validation accuracy:		93.91 %
Epoch 509 of 2000 took 0.141s
  training loss:		0.063937
  validation loss:		0.218397
  validation accuracy:		94.02 %
Epoch 510 of 2000 took 0.132s
  training loss:		0.060865
  validation loss:		0.221707
  validation accuracy:		93.91 %
Epoch 511 of 2000 took 0.130s
  training loss:		0.062416
  validation loss:		0.215905
  validation accuracy:		94.13 %
Epoch 512 of 2000 took 0.138s
  training loss:		0.062060
  validation loss:		0.215069
  validation accuracy:		94.02 %
Epoch 513 of 2000 took 0.144s
  training loss:		0.059809
  validation loss:		0.222116
  validation accuracy:		94.13 %
Epoch 514 of 2000 took 0.143s
  training loss:		0.058959
  validation loss:		0.215684
  validation accuracy:		93.91 %
Epoch 515 of 2000 took 0.147s
  training loss:		0.059409
  validation loss:		0.219906
  validation accuracy:		94.13 %
Epoch 516 of 2000 took 0.168s
  training loss:		0.063148
  validation loss:		0.218758
  validation accuracy:		93.91 %
Epoch 517 of 2000 took 0.138s
  training loss:		0.064549
  validation loss:		0.227615
  validation accuracy:		93.80 %
Epoch 518 of 2000 took 0.140s
  training loss:		0.063251
  validation loss:		0.216790
  validation accuracy:		94.24 %
Epoch 519 of 2000 took 0.144s
  training loss:		0.059431
  validation loss:		0.219973
  validation accuracy:		94.02 %
Epoch 520 of 2000 took 0.141s
  training loss:		0.059165
  validation loss:		0.221338
  validation accuracy:		94.13 %
Epoch 521 of 2000 took 0.141s
  training loss:		0.062272
  validation loss:		0.228773
  validation accuracy:		94.02 %
Epoch 522 of 2000 took 0.142s
  training loss:		0.060922
  validation loss:		0.221319
  validation accuracy:		93.91 %
Epoch 523 of 2000 took 0.143s
  training loss:		0.057752
  validation loss:		0.218724
  validation accuracy:		94.35 %
Epoch 524 of 2000 took 0.140s
  training loss:		0.057694
  validation loss:		0.236451
  validation accuracy:		93.59 %
Epoch 525 of 2000 took 0.142s
  training loss:		0.060504
  validation loss:		0.225294
  validation accuracy:		94.02 %
Epoch 526 of 2000 took 0.143s
  training loss:		0.060523
  validation loss:		0.216069
  validation accuracy:		94.13 %
Epoch 527 of 2000 took 0.147s
  training loss:		0.061340
  validation loss:		0.223184
  validation accuracy:		94.13 %
Epoch 528 of 2000 took 0.139s
  training loss:		0.058830
  validation loss:		0.237087
  validation accuracy:		93.91 %
Epoch 529 of 2000 took 0.143s
  training loss:		0.059147
  validation loss:		0.233869
  validation accuracy:		93.70 %
Epoch 530 of 2000 took 0.143s
  training loss:		0.059944
  validation loss:		0.224750
  validation accuracy:		93.91 %
Epoch 531 of 2000 took 0.138s
  training loss:		0.058683
  validation loss:		0.229380
  validation accuracy:		93.91 %
Epoch 532 of 2000 took 0.145s
  training loss:		0.056671
  validation loss:		0.222114
  validation accuracy:		94.02 %
Epoch 533 of 2000 took 0.145s
  training loss:		0.061874
  validation loss:		0.223522
  validation accuracy:		94.02 %
Epoch 534 of 2000 took 0.143s
  training loss:		0.057815
  validation loss:		0.221376
  validation accuracy:		94.24 %
Epoch 535 of 2000 took 0.141s
  training loss:		0.060390
  validation loss:		0.224679
  validation accuracy:		94.24 %
Epoch 536 of 2000 took 0.145s
  training loss:		0.058070
  validation loss:		0.225234
  validation accuracy:		94.02 %
Epoch 537 of 2000 took 0.143s
  training loss:		0.059462
  validation loss:		0.226199
  validation accuracy:		94.02 %
Epoch 538 of 2000 took 0.141s
  training loss:		0.058733
  validation loss:		0.233617
  validation accuracy:		94.02 %
Epoch 539 of 2000 took 0.142s
  training loss:		0.058466
  validation loss:		0.227155
  validation accuracy:		93.91 %
Epoch 540 of 2000 took 0.144s
  training loss:		0.056386
  validation loss:		0.234321
  validation accuracy:		93.70 %
Epoch 541 of 2000 took 0.145s
  training loss:		0.057866
  validation loss:		0.229265
  validation accuracy:		93.80 %
Epoch 542 of 2000 took 0.142s
  training loss:		0.056633
  validation loss:		0.229226
  validation accuracy:		93.91 %
Epoch 543 of 2000 took 0.160s
  training loss:		0.059162
  validation loss:		0.232554
  validation accuracy:		93.91 %
Epoch 544 of 2000 took 0.183s
  training loss:		0.058024
  validation loss:		0.228268
  validation accuracy:		93.80 %
Epoch 545 of 2000 took 0.181s
  training loss:		0.056398
  validation loss:		0.241620
  validation accuracy:		93.91 %
Epoch 546 of 2000 took 0.172s
  training loss:		0.058421
  validation loss:		0.227216
  validation accuracy:		93.91 %
Epoch 547 of 2000 took 0.137s
  training loss:		0.056777
  validation loss:		0.229489
  validation accuracy:		93.91 %
Epoch 548 of 2000 took 0.133s
  training loss:		0.058134
  validation loss:		0.233738
  validation accuracy:		93.70 %
Epoch 549 of 2000 took 0.137s
  training loss:		0.057561
  validation loss:		0.231394
  validation accuracy:		94.02 %
Epoch 550 of 2000 took 0.167s
  training loss:		0.056427
  validation loss:		0.226833
  validation accuracy:		94.24 %
Epoch 551 of 2000 took 0.152s
  training loss:		0.055756
  validation loss:		0.224690
  validation accuracy:		94.02 %
Epoch 552 of 2000 took 0.146s
  training loss:		0.055997
  validation loss:		0.228310
  validation accuracy:		93.91 %
Epoch 553 of 2000 took 0.156s
  training loss:		0.054713
  validation loss:		0.231365
  validation accuracy:		93.91 %
Epoch 554 of 2000 took 0.143s
  training loss:		0.055313
  validation loss:		0.225235
  validation accuracy:		94.24 %
Epoch 555 of 2000 took 0.135s
  training loss:		0.056344
  validation loss:		0.223719
  validation accuracy:		94.24 %
Epoch 556 of 2000 took 0.149s
  training loss:		0.057783
  validation loss:		0.236784
  validation accuracy:		94.02 %
Epoch 557 of 2000 took 0.160s
  training loss:		0.054583
  validation loss:		0.240294
  validation accuracy:		93.48 %
Epoch 558 of 2000 took 0.175s
  training loss:		0.057182
  validation loss:		0.231282
  validation accuracy:		93.70 %
Epoch 559 of 2000 took 0.182s
  training loss:		0.055508
  validation loss:		0.238172
  validation accuracy:		93.80 %
Epoch 560 of 2000 took 0.135s
  training loss:		0.056338
  validation loss:		0.234287
  validation accuracy:		93.80 %
Epoch 561 of 2000 took 0.148s
  training loss:		0.055888
  validation loss:		0.240710
  validation accuracy:		93.70 %
Epoch 562 of 2000 took 0.167s
  training loss:		0.054562
  validation loss:		0.231389
  validation accuracy:		94.02 %
Epoch 563 of 2000 took 0.151s
  training loss:		0.055418
  validation loss:		0.234628
  validation accuracy:		93.91 %
Epoch 564 of 2000 took 0.150s
  training loss:		0.053612
  validation loss:		0.234550
  validation accuracy:		93.70 %
Epoch 565 of 2000 took 0.141s
  training loss:		0.053791
  validation loss:		0.231907
  validation accuracy:		93.80 %
Epoch 566 of 2000 took 0.139s
  training loss:		0.054810
  validation loss:		0.235298
  validation accuracy:		93.91 %
Epoch 567 of 2000 took 0.145s
  training loss:		0.053675
  validation loss:		0.227706
  validation accuracy:		94.02 %
Epoch 568 of 2000 took 0.144s
  training loss:		0.055291
  validation loss:		0.230231
  validation accuracy:		94.13 %
Epoch 569 of 2000 took 0.143s
  training loss:		0.055832
  validation loss:		0.233305
  validation accuracy:		94.02 %
Epoch 570 of 2000 took 0.140s
  training loss:		0.054289
  validation loss:		0.249449
  validation accuracy:		93.48 %
Epoch 571 of 2000 took 0.146s
  training loss:		0.054709
  validation loss:		0.237424
  validation accuracy:		93.91 %
Epoch 572 of 2000 took 0.140s
  training loss:		0.054769
  validation loss:		0.230901
  validation accuracy:		93.91 %
Epoch 573 of 2000 took 0.142s
  training loss:		0.054299
  validation loss:		0.240236
  validation accuracy:		93.80 %
Epoch 574 of 2000 took 0.143s
  training loss:		0.053846
  validation loss:		0.238881
  validation accuracy:		93.48 %
Epoch 575 of 2000 took 0.141s
  training loss:		0.052215
  validation loss:		0.240412
  validation accuracy:		94.02 %
Epoch 576 of 2000 took 0.143s
  training loss:		0.052142
  validation loss:		0.236727
  validation accuracy:		93.80 %
Epoch 577 of 2000 took 0.141s
  training loss:		0.053793
  validation loss:		0.236475
  validation accuracy:		93.80 %
Epoch 578 of 2000 took 0.145s
  training loss:		0.054371
  validation loss:		0.239408
  validation accuracy:		93.59 %
Epoch 579 of 2000 took 0.173s
  training loss:		0.055233
  validation loss:		0.239376
  validation accuracy:		93.91 %
Epoch 580 of 2000 took 0.190s
  training loss:		0.053721
  validation loss:		0.234443
  validation accuracy:		94.24 %
Epoch 581 of 2000 took 0.160s
  training loss:		0.050414
  validation loss:		0.248046
  validation accuracy:		93.37 %
Epoch 582 of 2000 took 0.151s
  training loss:		0.052183
  validation loss:		0.237711
  validation accuracy:		93.70 %
Epoch 583 of 2000 took 0.165s
  training loss:		0.053853
  validation loss:		0.240885
  validation accuracy:		93.91 %
Epoch 584 of 2000 took 0.171s
  training loss:		0.053562
  validation loss:		0.233424
  validation accuracy:		94.24 %
Epoch 585 of 2000 took 0.160s
  training loss:		0.052680
  validation loss:		0.240029
  validation accuracy:		94.02 %
Epoch 586 of 2000 took 0.151s
  training loss:		0.052927
  validation loss:		0.236245
  validation accuracy:		94.13 %
Epoch 587 of 2000 took 0.162s
  training loss:		0.052710
  validation loss:		0.239489
  validation accuracy:		93.91 %
Epoch 588 of 2000 took 0.140s
  training loss:		0.052451
  validation loss:		0.233889
  validation accuracy:		94.02 %
Epoch 589 of 2000 took 0.142s
  training loss:		0.050628
  validation loss:		0.243568
  validation accuracy:		93.91 %
Epoch 590 of 2000 took 0.142s
  training loss:		0.053178
  validation loss:		0.239576
  validation accuracy:		94.02 %
Epoch 591 of 2000 took 0.134s
  training loss:		0.051230
  validation loss:		0.242680
  validation accuracy:		93.91 %
Epoch 592 of 2000 took 0.139s
  training loss:		0.049374
  validation loss:		0.242832
  validation accuracy:		94.02 %
Epoch 593 of 2000 took 0.145s
  training loss:		0.053936
  validation loss:		0.241112
  validation accuracy:		93.80 %
Epoch 594 of 2000 took 0.137s
  training loss:		0.050773
  validation loss:		0.250659
  validation accuracy:		93.26 %
Epoch 595 of 2000 took 0.144s
  training loss:		0.049821
  validation loss:		0.237497
  validation accuracy:		94.13 %
Epoch 596 of 2000 took 0.146s
  training loss:		0.052064
  validation loss:		0.236424
  validation accuracy:		93.91 %
Epoch 597 of 2000 took 0.139s
  training loss:		0.049449
  validation loss:		0.248037
  validation accuracy:		93.48 %
Epoch 598 of 2000 took 0.141s
  training loss:		0.051331
  validation loss:		0.235951
  validation accuracy:		93.80 %
Epoch 599 of 2000 took 0.142s
  training loss:		0.049643
  validation loss:		0.255833
  validation accuracy:		93.48 %
Epoch 600 of 2000 took 0.145s
  training loss:		0.051066
  validation loss:		0.243831
  validation accuracy:		93.70 %
Epoch 601 of 2000 took 0.155s
  training loss:		0.050252
  validation loss:		0.238154
  validation accuracy:		93.91 %
Epoch 602 of 2000 took 0.165s
  training loss:		0.051748
  validation loss:		0.234816
  validation accuracy:		93.91 %
Epoch 603 of 2000 took 0.148s
  training loss:		0.050579
  validation loss:		0.233944
  validation accuracy:		94.13 %
Epoch 604 of 2000 took 0.147s
  training loss:		0.049526
  validation loss:		0.249403
  validation accuracy:		93.70 %
Epoch 605 of 2000 took 0.179s
  training loss:		0.048967
  validation loss:		0.238328
  validation accuracy:		94.02 %
Epoch 606 of 2000 took 0.185s
  training loss:		0.050343
  validation loss:		0.245085
  validation accuracy:		93.80 %
Epoch 607 of 2000 took 0.144s
  training loss:		0.049416
  validation loss:		0.246827
  validation accuracy:		94.02 %
Epoch 608 of 2000 took 0.148s
  training loss:		0.049061
  validation loss:		0.245588
  validation accuracy:		93.91 %
Epoch 609 of 2000 took 0.141s
  training loss:		0.048348
  validation loss:		0.251213
  validation accuracy:		93.70 %
Epoch 610 of 2000 took 0.144s
  training loss:		0.049648
  validation loss:		0.240831
  validation accuracy:		93.91 %
Epoch 611 of 2000 took 0.145s
  training loss:		0.049382
  validation loss:		0.249544
  validation accuracy:		93.91 %
Epoch 612 of 2000 took 0.138s
  training loss:		0.049589
  validation loss:		0.248969
  validation accuracy:		93.80 %
Epoch 613 of 2000 took 0.132s
  training loss:		0.048132
  validation loss:		0.245839
  validation accuracy:		93.80 %
Epoch 614 of 2000 took 0.136s
  training loss:		0.049259
  validation loss:		0.254422
  validation accuracy:		93.70 %
Epoch 615 of 2000 took 0.144s
  training loss:		0.048764
  validation loss:		0.247090
  validation accuracy:		93.91 %
Epoch 616 of 2000 took 0.161s
  training loss:		0.049855
  validation loss:		0.242289
  validation accuracy:		93.91 %
Epoch 617 of 2000 took 0.151s
  training loss:		0.048333
  validation loss:		0.245137
  validation accuracy:		94.02 %
Epoch 618 of 2000 took 0.197s
  training loss:		0.048252
  validation loss:		0.250602
  validation accuracy:		93.80 %
Epoch 619 of 2000 took 0.166s
  training loss:		0.047145
  validation loss:		0.261300
  validation accuracy:		93.37 %
Epoch 620 of 2000 took 0.161s
  training loss:		0.047649
  validation loss:		0.242685
  validation accuracy:		93.91 %
Epoch 621 of 2000 took 0.178s
  training loss:		0.047521
  validation loss:		0.246638
  validation accuracy:		93.80 %
Epoch 622 of 2000 took 0.135s
  training loss:		0.049128
  validation loss:		0.244179
  validation accuracy:		93.91 %
Epoch 623 of 2000 took 0.141s
  training loss:		0.047453
  validation loss:		0.241415
  validation accuracy:		93.91 %
Epoch 624 of 2000 took 0.139s
  training loss:		0.046672
  validation loss:		0.249267
  validation accuracy:		94.02 %
Epoch 625 of 2000 took 0.135s
  training loss:		0.045996
  validation loss:		0.249284
  validation accuracy:		93.91 %
Epoch 626 of 2000 took 0.179s
  training loss:		0.047880
  validation loss:		0.244850
  validation accuracy:		93.70 %
Epoch 627 of 2000 took 0.168s
  training loss:		0.048178
  validation loss:		0.252430
  validation accuracy:		93.70 %
Epoch 628 of 2000 took 0.165s
  training loss:		0.047281
  validation loss:		0.244618
  validation accuracy:		93.80 %
Epoch 629 of 2000 took 0.147s
  training loss:		0.047644
  validation loss:		0.245467
  validation accuracy:		94.13 %
Epoch 630 of 2000 took 0.186s
  training loss:		0.048416
  validation loss:		0.256548
  validation accuracy:		93.59 %
Epoch 631 of 2000 took 0.191s
  training loss:		0.046816
  validation loss:		0.245267
  validation accuracy:		93.91 %
Epoch 632 of 2000 took 0.173s
  training loss:		0.046465
  validation loss:		0.258709
  validation accuracy:		93.48 %
Epoch 633 of 2000 took 0.150s
  training loss:		0.048018
  validation loss:		0.249818
  validation accuracy:		94.02 %
Epoch 634 of 2000 took 0.154s
  training loss:		0.047001
  validation loss:		0.256765
  validation accuracy:		93.70 %
Epoch 635 of 2000 took 0.150s
  training loss:		0.047056
  validation loss:		0.253941
  validation accuracy:		93.70 %
Epoch 636 of 2000 took 0.153s
  training loss:		0.046761
  validation loss:		0.250449
  validation accuracy:		93.91 %
Epoch 637 of 2000 took 0.164s
  training loss:		0.045677
  validation loss:		0.256589
  validation accuracy:		93.59 %
Epoch 638 of 2000 took 0.139s
  training loss:		0.047244
  validation loss:		0.253872
  validation accuracy:		93.91 %
Epoch 639 of 2000 took 0.144s
  training loss:		0.046618
  validation loss:		0.265554
  validation accuracy:		93.48 %
Epoch 640 of 2000 took 0.143s
  training loss:		0.045581
  validation loss:		0.250250
  validation accuracy:		93.91 %
Epoch 641 of 2000 took 0.170s
  training loss:		0.046113
  validation loss:		0.251388
  validation accuracy:		93.80 %
Epoch 642 of 2000 took 0.146s
  training loss:		0.045338
  validation loss:		0.257246
  validation accuracy:		93.70 %
Epoch 643 of 2000 took 0.151s
  training loss:		0.046305
  validation loss:		0.254578
  validation accuracy:		93.70 %
Epoch 644 of 2000 took 0.166s
  training loss:		0.045632
  validation loss:		0.254478
  validation accuracy:		93.48 %
Epoch 645 of 2000 took 0.162s
  training loss:		0.045022
  validation loss:		0.259891
  validation accuracy:		93.80 %
Epoch 646 of 2000 took 0.152s
  training loss:		0.045467
  validation loss:		0.252322
  validation accuracy:		93.91 %
Epoch 647 of 2000 took 0.155s
  training loss:		0.045627
  validation loss:		0.249397
  validation accuracy:		93.91 %
Epoch 648 of 2000 took 0.140s
  training loss:		0.044843
  validation loss:		0.258375
  validation accuracy:		93.80 %
Epoch 649 of 2000 took 0.183s
  training loss:		0.044214
  validation loss:		0.260223
  validation accuracy:		93.80 %
Epoch 650 of 2000 took 0.184s
  training loss:		0.045876
  validation loss:		0.262044
  validation accuracy:		93.80 %
Epoch 651 of 2000 took 0.161s
  training loss:		0.044089
  validation loss:		0.254313
  validation accuracy:		94.02 %
Epoch 652 of 2000 took 0.178s
  training loss:		0.044348
  validation loss:		0.255729
  validation accuracy:		93.80 %
Epoch 653 of 2000 took 0.150s
  training loss:		0.044192
  validation loss:		0.261639
  validation accuracy:		93.91 %
Epoch 654 of 2000 took 0.186s
  training loss:		0.044419
  validation loss:		0.254274
  validation accuracy:		93.70 %
Epoch 655 of 2000 took 0.169s
  training loss:		0.046455
  validation loss:		0.252584
  validation accuracy:		94.02 %
Epoch 656 of 2000 took 0.160s
  training loss:		0.044274
  validation loss:		0.256850
  validation accuracy:		94.02 %
Epoch 657 of 2000 took 0.158s
  training loss:		0.045360
  validation loss:		0.260123
  validation accuracy:		93.91 %
Epoch 658 of 2000 took 0.157s
  training loss:		0.044451
  validation loss:		0.259006
  validation accuracy:		93.59 %
Epoch 659 of 2000 took 0.146s
  training loss:		0.043118
  validation loss:		0.258093
  validation accuracy:		93.80 %
Epoch 660 of 2000 took 0.150s
  training loss:		0.044033
  validation loss:		0.256308
  validation accuracy:		93.80 %
Epoch 661 of 2000 took 0.159s
  training loss:		0.044549
  validation loss:		0.257863
  validation accuracy:		93.80 %
Epoch 662 of 2000 took 0.144s
  training loss:		0.041976
  validation loss:		0.256934
  validation accuracy:		94.02 %
Epoch 663 of 2000 took 0.144s
  training loss:		0.043293
  validation loss:		0.257283
  validation accuracy:		94.02 %
Epoch 664 of 2000 took 0.148s
  training loss:		0.042920
  validation loss:		0.266264
  validation accuracy:		93.48 %
Epoch 665 of 2000 took 0.149s
  training loss:		0.043838
  validation loss:		0.255784
  validation accuracy:		93.70 %
Epoch 666 of 2000 took 0.148s
  training loss:		0.043531
  validation loss:		0.254064
  validation accuracy:		94.02 %
Epoch 667 of 2000 took 0.148s
  training loss:		0.043193
  validation loss:		0.261936
  validation accuracy:		93.48 %
Epoch 668 of 2000 took 0.152s
  training loss:		0.043308
  validation loss:		0.254761
  validation accuracy:		93.70 %
Epoch 669 of 2000 took 0.145s
  training loss:		0.043255
  validation loss:		0.256922
  validation accuracy:		93.80 %
Epoch 670 of 2000 took 0.148s
  training loss:		0.042705
  validation loss:		0.260415
  validation accuracy:		93.91 %
Epoch 671 of 2000 took 0.150s
  training loss:		0.041276
  validation loss:		0.271736
  validation accuracy:		93.37 %
Epoch 672 of 2000 took 0.168s
  training loss:		0.043563
  validation loss:		0.265124
  validation accuracy:		93.48 %
Epoch 673 of 2000 took 0.142s
  training loss:		0.042684
  validation loss:		0.262701
  validation accuracy:		93.80 %
Epoch 674 of 2000 took 0.142s
  training loss:		0.041530
  validation loss:		0.270984
  validation accuracy:		93.37 %
Epoch 675 of 2000 took 0.153s
  training loss:		0.042438
  validation loss:		0.267186
  validation accuracy:		93.59 %
Epoch 676 of 2000 took 0.195s
  training loss:		0.041341
  validation loss:		0.263039
  validation accuracy:		93.59 %
Epoch 677 of 2000 took 0.151s
  training loss:		0.042552
  validation loss:		0.260805
  validation accuracy:		93.70 %
Epoch 678 of 2000 took 0.165s
  training loss:		0.042476
  validation loss:		0.258541
  validation accuracy:		93.80 %
Epoch 679 of 2000 took 0.166s
  training loss:		0.042169
  validation loss:		0.266623
  validation accuracy:		93.70 %
Epoch 680 of 2000 took 0.150s
  training loss:		0.041138
  validation loss:		0.260409
  validation accuracy:		93.91 %
Epoch 681 of 2000 took 0.144s
  training loss:		0.041940
  validation loss:		0.264522
  validation accuracy:		93.70 %
Epoch 682 of 2000 took 0.146s
  training loss:		0.041136
  validation loss:		0.258235
  validation accuracy:		93.91 %
Epoch 683 of 2000 took 0.146s
  training loss:		0.039043
  validation loss:		0.263554
  validation accuracy:		94.02 %
Epoch 684 of 2000 took 0.148s
  training loss:		0.042310
  validation loss:		0.262877
  validation accuracy:		93.80 %
Epoch 685 of 2000 took 0.150s
  training loss:		0.041820
  validation loss:		0.267726
  validation accuracy:		93.70 %
Epoch 686 of 2000 took 0.145s
  training loss:		0.042870
  validation loss:		0.264471
  validation accuracy:		93.70 %
Epoch 687 of 2000 took 0.147s
  training loss:		0.040845
  validation loss:		0.263974
  validation accuracy:		93.70 %
Epoch 688 of 2000 took 0.170s
  training loss:		0.040865
  validation loss:		0.260268
  validation accuracy:		93.80 %
Epoch 689 of 2000 took 0.183s
  training loss:		0.040497
  validation loss:		0.268295
  validation accuracy:		93.48 %
Epoch 690 of 2000 took 0.152s
  training loss:		0.040811
  validation loss:		0.272566
  validation accuracy:		93.70 %
Epoch 691 of 2000 took 0.143s
  training loss:		0.040761
  validation loss:		0.263286
  validation accuracy:		93.80 %
Epoch 692 of 2000 took 0.147s
  training loss:		0.040113
  validation loss:		0.268029
  validation accuracy:		93.48 %
Epoch 693 of 2000 took 0.145s
  training loss:		0.039361
  validation loss:		0.260117
  validation accuracy:		93.91 %
Epoch 694 of 2000 took 0.159s
  training loss:		0.038214
  validation loss:		0.267019
  validation accuracy:		93.80 %
Epoch 695 of 2000 took 0.167s
  training loss:		0.039067
  validation loss:		0.268909
  validation accuracy:		93.70 %
Epoch 696 of 2000 took 0.191s
  training loss:		0.039871
  validation loss:		0.264257
  validation accuracy:		93.80 %
Epoch 697 of 2000 took 0.154s
  training loss:		0.040098
  validation loss:		0.268011
  validation accuracy:		93.80 %
Epoch 698 of 2000 took 0.146s
  training loss:		0.040783
  validation loss:		0.274518
  validation accuracy:		93.48 %
Epoch 699 of 2000 took 0.147s
  training loss:		0.038824
  validation loss:		0.269643
  validation accuracy:		93.70 %
Epoch 700 of 2000 took 0.139s
  training loss:		0.040610
  validation loss:		0.271453
  validation accuracy:		93.70 %
Epoch 701 of 2000 took 0.142s
  training loss:		0.042072
  validation loss:		0.261807
  validation accuracy:		93.70 %
Epoch 702 of 2000 took 0.151s
  training loss:		0.039890
  validation loss:		0.272247
  validation accuracy:		93.91 %
Epoch 703 of 2000 took 0.147s
  training loss:		0.040158
  validation loss:		0.271074
  validation accuracy:		93.80 %
Epoch 704 of 2000 took 0.139s
  training loss:		0.039709
  validation loss:		0.264978
  validation accuracy:		93.91 %
Epoch 705 of 2000 took 0.153s
  training loss:		0.040034
  validation loss:		0.274415
  validation accuracy:		93.59 %
Epoch 706 of 2000 took 0.165s
  training loss:		0.039325
  validation loss:		0.264919
  validation accuracy:		93.80 %
Epoch 707 of 2000 took 0.179s
  training loss:		0.037294
  validation loss:		0.278967
  validation accuracy:		93.48 %
Epoch 708 of 2000 took 0.169s
  training loss:		0.038528
  validation loss:		0.281525
  validation accuracy:		93.37 %
Epoch 709 of 2000 took 0.141s
  training loss:		0.039749
  validation loss:		0.273157
  validation accuracy:		93.70 %
Epoch 710 of 2000 took 0.148s
  training loss:		0.039806
  validation loss:		0.264962
  validation accuracy:		93.80 %
Epoch 711 of 2000 took 0.160s
  training loss:		0.039133
  validation loss:		0.279857
  validation accuracy:		93.48 %
Epoch 712 of 2000 took 0.196s
  training loss:		0.039358
  validation loss:		0.263875
  validation accuracy:		93.59 %
Epoch 713 of 2000 took 0.142s
  training loss:		0.039442
  validation loss:		0.269426
  validation accuracy:		93.70 %
Epoch 714 of 2000 took 0.186s
  training loss:		0.039054
  validation loss:		0.269915
  validation accuracy:		93.70 %
Epoch 715 of 2000 took 0.151s
  training loss:		0.038922
  validation loss:		0.272550
  validation accuracy:		93.70 %
Epoch 716 of 2000 took 0.145s
  training loss:		0.037850
  validation loss:		0.269069
  validation accuracy:		93.80 %
Epoch 717 of 2000 took 0.146s
  training loss:		0.038378
  validation loss:		0.281720
  validation accuracy:		93.26 %
Epoch 718 of 2000 took 0.149s
  training loss:		0.038853
  validation loss:		0.269582
  validation accuracy:		93.70 %
Epoch 719 of 2000 took 0.148s
  training loss:		0.038826
  validation loss:		0.275445
  validation accuracy:		93.59 %
Epoch 720 of 2000 took 0.152s
  training loss:		0.038102
  validation loss:		0.269366
  validation accuracy:		93.70 %
Epoch 721 of 2000 took 0.178s
  training loss:		0.037173
  validation loss:		0.264979
  validation accuracy:		93.91 %
Epoch 722 of 2000 took 0.138s
  training loss:		0.037950
  validation loss:		0.290489
  validation accuracy:		93.37 %
Epoch 723 of 2000 took 0.149s
  training loss:		0.038991
  validation loss:		0.270173
  validation accuracy:		93.80 %
Epoch 724 of 2000 took 0.145s
  training loss:		0.038275
  validation loss:		0.282268
  validation accuracy:		93.37 %
Epoch 725 of 2000 took 0.145s
  training loss:		0.035962
  validation loss:		0.280292
  validation accuracy:		93.37 %
Epoch 726 of 2000 took 0.159s
  training loss:		0.038146
  validation loss:		0.279062
  validation accuracy:		93.37 %
Epoch 727 of 2000 took 0.154s
  training loss:		0.037423
  validation loss:		0.283855
  validation accuracy:		93.59 %
Epoch 728 of 2000 took 0.189s
  training loss:		0.035722
  validation loss:		0.268944
  validation accuracy:		93.70 %
Epoch 729 of 2000 took 0.146s
  training loss:		0.035976
  validation loss:		0.271939
  validation accuracy:		93.80 %
Epoch 730 of 2000 took 0.149s
  training loss:		0.036464
  validation loss:		0.280169
  validation accuracy:		93.48 %
Epoch 731 of 2000 took 0.149s
  training loss:		0.037056
  validation loss:		0.284018
  validation accuracy:		93.59 %
Epoch 732 of 2000 took 0.145s
  training loss:		0.037615
  validation loss:		0.274984
  validation accuracy:		93.70 %
Epoch 733 of 2000 took 0.156s
  training loss:		0.038652
  validation loss:		0.276179
  validation accuracy:		93.59 %
Epoch 734 of 2000 took 0.155s
  training loss:		0.036653
  validation loss:		0.269694
  validation accuracy:		93.59 %
Epoch 735 of 2000 took 0.168s
  training loss:		0.038158
  validation loss:		0.276483
  validation accuracy:		93.80 %
Epoch 736 of 2000 took 0.191s
  training loss:		0.037108
  validation loss:		0.274274
  validation accuracy:		93.70 %
Epoch 737 of 2000 took 0.199s
  training loss:		0.036569
  validation loss:		0.271714
  validation accuracy:		93.59 %
Epoch 738 of 2000 took 0.183s
  training loss:		0.035003
  validation loss:		0.278547
  validation accuracy:		93.59 %
Epoch 739 of 2000 took 0.184s
  training loss:		0.036588
  validation loss:		0.277980
  validation accuracy:		93.59 %
Epoch 740 of 2000 took 0.185s
  training loss:		0.036381
  validation loss:		0.279655
  validation accuracy:		93.48 %
Epoch 741 of 2000 took 0.180s
  training loss:		0.036382
  validation loss:		0.274924
  validation accuracy:		93.70 %
Epoch 742 of 2000 took 0.161s
  training loss:		0.035703
  validation loss:		0.295922
  validation accuracy:		93.48 %
Epoch 743 of 2000 took 0.174s
  training loss:		0.036935
  validation loss:		0.276841
  validation accuracy:		93.80 %
Epoch 744 of 2000 took 0.172s
  training loss:		0.035364
  validation loss:		0.286227
  validation accuracy:		93.48 %
Epoch 745 of 2000 took 0.189s
  training loss:		0.035846
  validation loss:		0.282128
  validation accuracy:		93.48 %
Epoch 746 of 2000 took 0.200s
  training loss:		0.036075
  validation loss:		0.296398
  validation accuracy:		93.26 %
Epoch 747 of 2000 took 0.187s
  training loss:		0.035295
  validation loss:		0.275853
  validation accuracy:		93.70 %
Epoch 748 of 2000 took 0.152s
  training loss:		0.034640
  validation loss:		0.275379
  validation accuracy:		93.59 %
Epoch 749 of 2000 took 0.143s
  training loss:		0.034756
  validation loss:		0.278366
  validation accuracy:		93.80 %
Epoch 750 of 2000 took 0.148s
  training loss:		0.035751
  validation loss:		0.280350
  validation accuracy:		93.59 %
Epoch 751 of 2000 took 0.147s
  training loss:		0.034917
  validation loss:		0.274116
  validation accuracy:		93.70 %
Epoch 752 of 2000 took 0.147s
  training loss:		0.034807
  validation loss:		0.283682
  validation accuracy:		93.59 %
Epoch 753 of 2000 took 0.152s
  training loss:		0.035234
  validation loss:		0.284387
  validation accuracy:		93.59 %
Epoch 754 of 2000 took 0.141s
  training loss:		0.032827
  validation loss:		0.292541
  validation accuracy:		93.48 %
Epoch 755 of 2000 took 0.150s
  training loss:		0.036034
  validation loss:		0.286444
  validation accuracy:		93.48 %
Epoch 756 of 2000 took 0.154s
  training loss:		0.036341
  validation loss:		0.288785
  validation accuracy:		93.48 %
Epoch 757 of 2000 took 0.140s
  training loss:		0.035318
  validation loss:		0.288859
  validation accuracy:		93.59 %
Epoch 758 of 2000 took 0.145s
  training loss:		0.034571
  validation loss:		0.293538
  validation accuracy:		93.59 %
Epoch 759 of 2000 took 0.142s
  training loss:		0.035000
  validation loss:		0.285002
  validation accuracy:		93.26 %
Epoch 760 of 2000 took 0.146s
  training loss:		0.035021
  validation loss:		0.283448
  validation accuracy:		93.80 %
Epoch 761 of 2000 took 0.146s
  training loss:		0.033534
  validation loss:		0.285005
  validation accuracy:		93.48 %
Epoch 762 of 2000 took 0.159s
  training loss:		0.033695
  validation loss:		0.282415
  validation accuracy:		93.37 %
Epoch 763 of 2000 took 0.146s
  training loss:		0.035633
  validation loss:		0.290407
  validation accuracy:		93.37 %
Epoch 764 of 2000 took 0.144s
  training loss:		0.034890
  validation loss:		0.288772
  validation accuracy:		93.37 %
Epoch 765 of 2000 took 0.186s
  training loss:		0.034645
  validation loss:		0.277956
  validation accuracy:		93.59 %
Epoch 766 of 2000 took 0.167s
  training loss:		0.034307
  validation loss:		0.284784
  validation accuracy:		93.70 %
Epoch 767 of 2000 took 0.180s
  training loss:		0.033598
  validation loss:		0.290641
  validation accuracy:		93.48 %
Epoch 768 of 2000 took 0.192s
  training loss:		0.033879
  validation loss:		0.294286
  validation accuracy:		93.48 %
Epoch 769 of 2000 took 0.149s
  training loss:		0.033191
  validation loss:		0.298152
  validation accuracy:		93.59 %
Epoch 770 of 2000 took 0.154s
  training loss:		0.033362
  validation loss:		0.294789
  validation accuracy:		93.26 %
Epoch 771 of 2000 took 0.146s
  training loss:		0.034328
  validation loss:		0.290937
  validation accuracy:		93.48 %
Epoch 772 of 2000 took 0.144s
  training loss:		0.033169
  validation loss:		0.279406
  validation accuracy:		93.70 %
Epoch 773 of 2000 took 0.148s
  training loss:		0.032969
  validation loss:		0.299352
  validation accuracy:		93.37 %
Epoch 774 of 2000 took 0.169s
  training loss:		0.034375
  validation loss:		0.290402
  validation accuracy:		93.37 %
Epoch 775 of 2000 took 0.144s
  training loss:		0.033658
  validation loss:		0.290188
  validation accuracy:		93.70 %
Epoch 776 of 2000 took 0.140s
  training loss:		0.032593
  validation loss:		0.289531
  validation accuracy:		93.37 %
Epoch 777 of 2000 took 0.147s
  training loss:		0.032966
  validation loss:		0.284230
  validation accuracy:		93.37 %
Epoch 778 of 2000 took 0.141s
  training loss:		0.034109
  validation loss:		0.298432
  validation accuracy:		93.26 %
Epoch 779 of 2000 took 0.146s
  training loss:		0.033122
  validation loss:		0.300459
  validation accuracy:		93.48 %
Epoch 780 of 2000 took 0.141s
  training loss:		0.033476
  validation loss:		0.289555
  validation accuracy:		93.70 %
Epoch 781 of 2000 took 0.139s
  training loss:		0.033670
  validation loss:		0.282659
  validation accuracy:		93.59 %
Epoch 782 of 2000 took 0.144s
  training loss:		0.032580
  validation loss:		0.285335
  validation accuracy:		93.48 %
Epoch 783 of 2000 took 0.140s
  training loss:		0.033023
  validation loss:		0.307554
  validation accuracy:		93.04 %
Epoch 784 of 2000 took 0.149s
  training loss:		0.033861
  validation loss:		0.294436
  validation accuracy:		93.37 %
Epoch 785 of 2000 took 0.143s
  training loss:		0.033189
  validation loss:		0.290301
  validation accuracy:		93.26 %
Epoch 786 of 2000 took 0.144s
  training loss:		0.032041
  validation loss:		0.287546
  validation accuracy:		93.48 %
Epoch 787 of 2000 took 0.150s
  training loss:		0.031521
  validation loss:		0.294725
  validation accuracy:		93.48 %
Epoch 788 of 2000 took 0.139s
  training loss:		0.033318
  validation loss:		0.290158
  validation accuracy:		93.48 %
Epoch 789 of 2000 took 0.163s
  training loss:		0.031154
  validation loss:		0.295749
  validation accuracy:		93.37 %
Epoch 790 of 2000 took 0.142s
  training loss:		0.031364
  validation loss:		0.288380
  validation accuracy:		93.59 %
Epoch 791 of 2000 took 0.140s
  training loss:		0.031838
  validation loss:		0.304240
  validation accuracy:		93.26 %
Epoch 792 of 2000 took 0.149s
  training loss:		0.034112
  validation loss:		0.294444
  validation accuracy:		93.48 %
Epoch 793 of 2000 took 0.165s
  training loss:		0.032069
  validation loss:		0.292168
  validation accuracy:		93.80 %
Epoch 794 of 2000 took 0.144s
  training loss:		0.031264
  validation loss:		0.289426
  validation accuracy:		93.70 %
Epoch 795 of 2000 took 0.142s
  training loss:		0.031822
  validation loss:		0.295018
  validation accuracy:		93.48 %
Epoch 796 of 2000 took 0.163s
  training loss:		0.031169
  validation loss:		0.292007
  validation accuracy:		93.48 %
Epoch 797 of 2000 took 0.149s
  training loss:		0.031415
  validation loss:		0.292342
  validation accuracy:		93.37 %
Epoch 798 of 2000 took 0.145s
  training loss:		0.032267
  validation loss:		0.297374
  validation accuracy:		93.26 %
Epoch 799 of 2000 took 0.153s
  training loss:		0.030879
  validation loss:		0.298512
  validation accuracy:		93.37 %
Epoch 800 of 2000 took 0.145s
  training loss:		0.031284
  validation loss:		0.292891
  validation accuracy:		93.37 %
Epoch 801 of 2000 took 0.146s
  training loss:		0.032198
  validation loss:		0.296487
  validation accuracy:		93.26 %
Epoch 802 of 2000 took 0.157s
  training loss:		0.032197
  validation loss:		0.299316
  validation accuracy:		93.59 %
Epoch 803 of 2000 took 0.146s
  training loss:		0.030447
  validation loss:		0.290074
  validation accuracy:		93.59 %
Epoch 804 of 2000 took 0.186s
  training loss:		0.031162
  validation loss:		0.298642
  validation accuracy:		93.48 %
Epoch 805 of 2000 took 0.157s
  training loss:		0.031620
  validation loss:		0.293111
  validation accuracy:		93.70 %
Epoch 806 of 2000 took 0.157s
  training loss:		0.032020
  validation loss:		0.291301
  validation accuracy:		93.48 %
Epoch 807 of 2000 took 0.154s
  training loss:		0.031296
  validation loss:		0.301970
  validation accuracy:		93.37 %
Epoch 808 of 2000 took 0.154s
  training loss:		0.030498
  validation loss:		0.298351
  validation accuracy:		93.48 %
Epoch 809 of 2000 took 0.163s
  training loss:		0.032025
  validation loss:		0.292199
  validation accuracy:		93.48 %
Epoch 810 of 2000 took 0.146s
  training loss:		0.029144
  validation loss:		0.300905
  validation accuracy:		93.37 %
Epoch 811 of 2000 took 0.150s
  training loss:		0.030069
  validation loss:		0.286897
  validation accuracy:		93.70 %
Epoch 812 of 2000 took 0.149s
  training loss:		0.031040
  validation loss:		0.297297
  validation accuracy:		93.15 %
Epoch 813 of 2000 took 0.150s
  training loss:		0.030801
  validation loss:		0.297993
  validation accuracy:		93.48 %
Epoch 814 of 2000 took 0.144s
  training loss:		0.031310
  validation loss:		0.296737
  validation accuracy:		93.48 %
Epoch 815 of 2000 took 0.150s
  training loss:		0.029241
  validation loss:		0.299316
  validation accuracy:		93.26 %
Epoch 816 of 2000 took 0.142s
  training loss:		0.030278
  validation loss:		0.293074
  validation accuracy:		93.48 %
Epoch 817 of 2000 took 0.157s
  training loss:		0.029911
  validation loss:		0.306099
  validation accuracy:		93.15 %
Epoch 818 of 2000 took 0.150s
  training loss:		0.030223
  validation loss:		0.303738
  validation accuracy:		93.48 %
Epoch 819 of 2000 took 0.151s
  training loss:		0.029488
  validation loss:		0.297709
  validation accuracy:		93.59 %
Epoch 820 of 2000 took 0.156s
  training loss:		0.030286
  validation loss:		0.306926
  validation accuracy:		93.26 %
Epoch 821 of 2000 took 0.135s
  training loss:		0.029984
  validation loss:		0.309916
  validation accuracy:		92.83 %
Epoch 822 of 2000 took 0.146s
  training loss:		0.030166
  validation loss:		0.303110
  validation accuracy:		93.48 %
Epoch 823 of 2000 took 0.144s
  training loss:		0.029285
  validation loss:		0.302363
  validation accuracy:		93.59 %
Epoch 824 of 2000 took 0.143s
  training loss:		0.029956
  validation loss:		0.301299
  validation accuracy:		93.26 %
Epoch 825 of 2000 took 0.145s
  training loss:		0.030122
  validation loss:		0.301551
  validation accuracy:		93.48 %
Epoch 826 of 2000 took 0.150s
  training loss:		0.029632
  validation loss:		0.306632
  validation accuracy:		93.15 %
Epoch 827 of 2000 took 0.142s
  training loss:		0.030345
  validation loss:		0.297763
  validation accuracy:		93.37 %
Epoch 828 of 2000 took 0.150s
  training loss:		0.029815
  validation loss:		0.309994
  validation accuracy:		93.37 %
Epoch 829 of 2000 took 0.144s
  training loss:		0.030302
  validation loss:		0.302785
  validation accuracy:		93.48 %
Epoch 830 of 2000 took 0.143s
  training loss:		0.029513
  validation loss:		0.308068
  validation accuracy:		93.37 %
Epoch 831 of 2000 took 0.146s
  training loss:		0.029250
  validation loss:		0.308704
  validation accuracy:		93.15 %
Epoch 832 of 2000 took 0.149s
  training loss:		0.028298
  validation loss:		0.309574
  validation accuracy:		93.15 %
Epoch 833 of 2000 took 0.152s
  training loss:		0.029374
  validation loss:		0.310036
  validation accuracy:		93.37 %
Epoch 834 of 2000 took 0.151s
  training loss:		0.029295
  validation loss:		0.300864
  validation accuracy:		93.59 %
Epoch 835 of 2000 took 0.149s
  training loss:		0.028654
  validation loss:		0.306419
  validation accuracy:		93.37 %
Epoch 836 of 2000 took 0.150s
  training loss:		0.027774
  validation loss:		0.304212
  validation accuracy:		93.37 %
Epoch 837 of 2000 took 0.147s
  training loss:		0.029416
  validation loss:		0.301797
  validation accuracy:		93.80 %
Epoch 838 of 2000 took 0.158s
  training loss:		0.030372
  validation loss:		0.307335
  validation accuracy:		93.59 %
Epoch 839 of 2000 took 0.147s
  training loss:		0.029319
  validation loss:		0.306120
  validation accuracy:		93.48 %
Epoch 840 of 2000 took 0.154s
  training loss:		0.028765
  validation loss:		0.311232
  validation accuracy:		93.37 %
Epoch 841 of 2000 took 0.182s
  training loss:		0.028543
  validation loss:		0.300808
  validation accuracy:		93.37 %
Epoch 842 of 2000 took 0.152s
  training loss:		0.027781
  validation loss:		0.299470
  validation accuracy:		93.59 %
Epoch 843 of 2000 took 0.146s
  training loss:		0.029442
  validation loss:		0.305691
  validation accuracy:		93.59 %
Epoch 844 of 2000 took 0.142s
  training loss:		0.028953
  validation loss:		0.312203
  validation accuracy:		93.15 %
Epoch 845 of 2000 took 0.145s
  training loss:		0.028406
  validation loss:		0.303557
  validation accuracy:		93.37 %
Epoch 846 of 2000 took 0.148s
  training loss:		0.027471
  validation loss:		0.313797
  validation accuracy:		93.26 %
Epoch 847 of 2000 took 0.152s
  training loss:		0.027856
  validation loss:		0.311555
  validation accuracy:		93.26 %
Epoch 848 of 2000 took 0.145s
  training loss:		0.028915
  validation loss:		0.307070
  validation accuracy:		93.26 %
Epoch 849 of 2000 took 0.143s
  training loss:		0.028192
  validation loss:		0.304476
  validation accuracy:		93.15 %
Epoch 850 of 2000 took 0.147s
  training loss:		0.028337
  validation loss:		0.307490
  validation accuracy:		93.26 %
Epoch 851 of 2000 took 0.172s
  training loss:		0.028786
  validation loss:		0.304524
  validation accuracy:		93.59 %
Epoch 852 of 2000 took 0.147s
  training loss:		0.028984
  validation loss:		0.319862
  validation accuracy:		93.04 %
Epoch 853 of 2000 took 0.145s
  training loss:		0.026580
  validation loss:		0.316773
  validation accuracy:		93.37 %
Epoch 854 of 2000 took 0.136s
  training loss:		0.027855
  validation loss:		0.307910
  validation accuracy:		93.37 %
Epoch 855 of 2000 took 0.126s
  training loss:		0.027676
  validation loss:		0.311783
  validation accuracy:		93.26 %
Epoch 856 of 2000 took 0.226s
  training loss:		0.025950
  validation loss:		0.306370
  validation accuracy:		93.37 %
Epoch 857 of 2000 took 0.124s
  training loss:		0.027687
  validation loss:		0.317394
  validation accuracy:		92.93 %
Epoch 858 of 2000 took 0.130s
  training loss:		0.027687
  validation loss:		0.310746
  validation accuracy:		93.26 %
Epoch 859 of 2000 took 0.131s
  training loss:		0.026632
  validation loss:		0.306856
  validation accuracy:		93.70 %
Epoch 860 of 2000 took 0.127s
  training loss:		0.027436
  validation loss:		0.306624
  validation accuracy:		93.70 %
Epoch 861 of 2000 took 0.148s
  training loss:		0.027063
  validation loss:		0.313435
  validation accuracy:		93.26 %
Epoch 862 of 2000 took 0.094s
  training loss:		0.026762
  validation loss:		0.309584
  validation accuracy:		93.37 %
Epoch 863 of 2000 took 0.071s
  training loss:		0.025987
  validation loss:		0.316134
  validation accuracy:		93.26 %
Epoch 864 of 2000 took 0.113s
  training loss:		0.026606
  validation loss:		0.310148
  validation accuracy:		93.59 %
Epoch 865 of 2000 took 0.121s
  training loss:		0.026469
  validation loss:		0.312291
  validation accuracy:		93.48 %
Epoch 866 of 2000 took 0.126s
  training loss:		0.025300
  validation loss:		0.308359
  validation accuracy:		93.37 %
Epoch 867 of 2000 took 0.112s
  training loss:		0.026763
  validation loss:		0.314255
  validation accuracy:		93.04 %
Epoch 868 of 2000 took 0.120s
  training loss:		0.027653
  validation loss:		0.321851
  validation accuracy:		93.04 %
Epoch 869 of 2000 took 0.090s
  training loss:		0.026431
  validation loss:		0.314500
  validation accuracy:		93.48 %
Epoch 870 of 2000 took 0.104s
  training loss:		0.026252
  validation loss:		0.309972
  validation accuracy:		93.48 %
Epoch 871 of 2000 took 0.127s
  training loss:		0.026038
  validation loss:		0.320666
  validation accuracy:		93.04 %
Epoch 872 of 2000 took 0.103s
  training loss:		0.025430
  validation loss:		0.312160
  validation accuracy:		93.15 %
Epoch 873 of 2000 took 0.118s
  training loss:		0.026776
  validation loss:		0.309355
  validation accuracy:		93.59 %
Epoch 874 of 2000 took 0.102s
  training loss:		0.026236
  validation loss:		0.314576
  validation accuracy:		93.26 %
Epoch 875 of 2000 took 0.097s
  training loss:		0.026768
  validation loss:		0.317119
  validation accuracy:		92.93 %
Epoch 876 of 2000 took 0.110s
  training loss:		0.025733
  validation loss:		0.310897
  validation accuracy:		93.37 %
Epoch 877 of 2000 took 0.110s
  training loss:		0.025786
  validation loss:		0.327533
  validation accuracy:		93.26 %
Epoch 878 of 2000 took 0.120s
  training loss:		0.026556
  validation loss:		0.317745
  validation accuracy:		93.37 %
Epoch 879 of 2000 took 0.111s
  training loss:		0.026193
  validation loss:		0.320352
  validation accuracy:		93.15 %
Epoch 880 of 2000 took 0.187s
  training loss:		0.026135
  validation loss:		0.316268
  validation accuracy:		93.37 %
Epoch 881 of 2000 took 0.229s
  training loss:		0.026119
  validation loss:		0.313219
  validation accuracy:		93.26 %
Epoch 882 of 2000 took 0.124s
  training loss:		0.025540
  validation loss:		0.324529
  validation accuracy:		93.04 %
Epoch 883 of 2000 took 0.127s
  training loss:		0.026007
  validation loss:		0.319460
  validation accuracy:		93.48 %
Epoch 884 of 2000 took 0.120s
  training loss:		0.025390
  validation loss:		0.327683
  validation accuracy:		93.26 %
Epoch 885 of 2000 took 0.127s
  training loss:		0.025786
  validation loss:		0.312775
  validation accuracy:		93.48 %
Epoch 886 of 2000 took 0.121s
  training loss:		0.025444
  validation loss:		0.320210
  validation accuracy:		93.04 %
Epoch 887 of 2000 took 0.117s
  training loss:		0.024837
  validation loss:		0.328389
  validation accuracy:		93.15 %
Epoch 888 of 2000 took 0.122s
  training loss:		0.025664
  validation loss:		0.318840
  validation accuracy:		93.48 %
Epoch 889 of 2000 took 0.128s
  training loss:		0.026539
  validation loss:		0.317611
  validation accuracy:		93.37 %
Epoch 890 of 2000 took 0.118s
  training loss:		0.024613
  validation loss:		0.319992
  validation accuracy:		93.15 %
Epoch 891 of 2000 took 0.125s
  training loss:		0.025731
  validation loss:		0.328200
  validation accuracy:		92.83 %
Epoch 892 of 2000 took 0.133s
  training loss:		0.024937
  validation loss:		0.320283
  validation accuracy:		93.15 %
Epoch 893 of 2000 took 0.125s
  training loss:		0.024771
  validation loss:		0.310796
  validation accuracy:		93.48 %
Epoch 894 of 2000 took 0.125s
  training loss:		0.026149
  validation loss:		0.325464
  validation accuracy:		93.26 %
Epoch 895 of 2000 took 0.123s
  training loss:		0.023044
  validation loss:		0.325437
  validation accuracy:		93.37 %
Epoch 896 of 2000 took 0.118s
  training loss:		0.026600
  validation loss:		0.320502
  validation accuracy:		93.26 %
Epoch 897 of 2000 took 0.124s
  training loss:		0.024678
  validation loss:		0.317276
  validation accuracy:		93.26 %
Epoch 898 of 2000 took 0.124s
  training loss:		0.025037
  validation loss:		0.326969
  validation accuracy:		92.93 %
Epoch 899 of 2000 took 0.123s
  training loss:		0.024513
  validation loss:		0.320343
  validation accuracy:		93.26 %
Epoch 900 of 2000 took 0.122s
  training loss:		0.025197
  validation loss:		0.318382
  validation accuracy:		93.26 %
Epoch 901 of 2000 took 0.122s
  training loss:		0.025540
  validation loss:		0.326535
  validation accuracy:		93.04 %
Epoch 902 of 2000 took 0.127s
  training loss:		0.024443
  validation loss:		0.316235
  validation accuracy:		93.48 %
Epoch 903 of 2000 took 0.126s
  training loss:		0.024604
  validation loss:		0.332437
  validation accuracy:		92.93 %
Epoch 904 of 2000 took 0.125s
  training loss:		0.024165
  validation loss:		0.317877
  validation accuracy:		93.48 %
Epoch 905 of 2000 took 0.124s
  training loss:		0.025202
  validation loss:		0.323833
  validation accuracy:		93.04 %
Epoch 906 of 2000 took 0.119s
  training loss:		0.025390
  validation loss:		0.330985
  validation accuracy:		93.04 %
Epoch 907 of 2000 took 0.123s
  training loss:		0.023204
  validation loss:		0.323623
  validation accuracy:		93.15 %
Epoch 908 of 2000 took 0.127s
  training loss:		0.025602
  validation loss:		0.326939
  validation accuracy:		93.04 %
Epoch 909 of 2000 took 0.123s
  training loss:		0.024277
  validation loss:		0.329162
  validation accuracy:		93.26 %
Epoch 910 of 2000 took 0.127s
  training loss:		0.024962
  validation loss:		0.324184
  validation accuracy:		93.15 %
Epoch 911 of 2000 took 0.127s
  training loss:		0.024497
  validation loss:		0.317761
  validation accuracy:		93.37 %
Epoch 912 of 2000 took 0.121s
  training loss:		0.024616
  validation loss:		0.338623
  validation accuracy:		93.04 %
Epoch 913 of 2000 took 0.123s
  training loss:		0.023870
  validation loss:		0.323431
  validation accuracy:		93.37 %
Epoch 914 of 2000 took 0.126s
  training loss:		0.024373
  validation loss:		0.332802
  validation accuracy:		93.15 %
Epoch 915 of 2000 took 0.118s
  training loss:		0.023680
  validation loss:		0.321910
  validation accuracy:		93.48 %
Epoch 916 of 2000 took 0.121s
  training loss:		0.025553
  validation loss:		0.327736
  validation accuracy:		93.15 %
Epoch 917 of 2000 took 0.122s
  training loss:		0.024375
  validation loss:		0.327136
  validation accuracy:		93.04 %
Epoch 918 of 2000 took 0.125s
  training loss:		0.023045
  validation loss:		0.324380
  validation accuracy:		93.26 %
Epoch 919 of 2000 took 0.122s
  training loss:		0.023574
  validation loss:		0.329822
  validation accuracy:		92.93 %
Epoch 920 of 2000 took 0.115s
  training loss:		0.023681
  validation loss:		0.324325
  validation accuracy:		93.37 %
Epoch 921 of 2000 took 0.120s
  training loss:		0.023601
  validation loss:		0.330042
  validation accuracy:		93.04 %
Epoch 922 of 2000 took 0.120s
  training loss:		0.024445
  validation loss:		0.333002
  validation accuracy:		93.04 %
Epoch 923 of 2000 took 0.122s
  training loss:		0.024200
  validation loss:		0.320627
  validation accuracy:		93.37 %
Epoch 924 of 2000 took 0.125s
  training loss:		0.023220
  validation loss:		0.331587
  validation accuracy:		93.26 %
Epoch 925 of 2000 took 0.124s
  training loss:		0.023038
  validation loss:		0.329235
  validation accuracy:		93.15 %
Epoch 926 of 2000 took 0.123s
  training loss:		0.023866
  validation loss:		0.333898
  validation accuracy:		92.93 %
Epoch 927 of 2000 took 0.127s
  training loss:		0.023123
  validation loss:		0.340655
  validation accuracy:		93.15 %
Epoch 928 of 2000 took 0.125s
  training loss:		0.022161
  validation loss:		0.324627
  validation accuracy:		93.15 %
Epoch 929 of 2000 took 0.121s
  training loss:		0.024516
  validation loss:		0.331135
  validation accuracy:		93.26 %
Epoch 930 of 2000 took 0.124s
  training loss:		0.023144
  validation loss:		0.344782
  validation accuracy:		92.93 %
Epoch 931 of 2000 took 0.126s
  training loss:		0.023969
  validation loss:		0.327294
  validation accuracy:		93.26 %
Epoch 932 of 2000 took 0.126s
  training loss:		0.023042
  validation loss:		0.344723
  validation accuracy:		93.26 %
Epoch 933 of 2000 took 0.127s
  training loss:		0.024704
  validation loss:		0.344123
  validation accuracy:		93.15 %
Epoch 934 of 2000 took 0.127s
  training loss:		0.024573
  validation loss:		0.338928
  validation accuracy:		92.93 %
Epoch 935 of 2000 took 0.125s
  training loss:		0.023254
  validation loss:		0.346542
  validation accuracy:		93.15 %
Epoch 936 of 2000 took 0.128s
  training loss:		0.022458
  validation loss:		0.338299
  validation accuracy:		92.93 %
Epoch 937 of 2000 took 0.128s
  training loss:		0.021979
  validation loss:		0.325305
  validation accuracy:		93.26 %
Epoch 938 of 2000 took 0.125s
  training loss:		0.022747
  validation loss:		0.323388
  validation accuracy:		93.26 %
Epoch 939 of 2000 took 0.126s
  training loss:		0.023230
  validation loss:		0.335763
  validation accuracy:		93.04 %
Epoch 940 of 2000 took 0.128s
  training loss:		0.023678
  validation loss:		0.337210
  validation accuracy:		93.15 %
Epoch 941 of 2000 took 0.122s
  training loss:		0.023191
  validation loss:		0.329784
  validation accuracy:		93.48 %
Epoch 942 of 2000 took 0.127s
  training loss:		0.023416
  validation loss:		0.333053
  validation accuracy:		93.26 %
Epoch 943 of 2000 took 0.111s
  training loss:		0.021917
  validation loss:		0.329852
  validation accuracy:		93.37 %
Epoch 944 of 2000 took 0.125s
  training loss:		0.022754
  validation loss:		0.342119
  validation accuracy:		92.93 %
Epoch 945 of 2000 took 0.123s
  training loss:		0.022592
  validation loss:		0.328966
  validation accuracy:		93.15 %
Epoch 946 of 2000 took 0.125s
  training loss:		0.022484
  validation loss:		0.329091
  validation accuracy:		93.15 %
Epoch 947 of 2000 took 0.091s
  training loss:		0.022639
  validation loss:		0.334744
  validation accuracy:		93.04 %
Epoch 948 of 2000 took 0.120s
  training loss:		0.021809
  validation loss:		0.333364
  validation accuracy:		93.15 %
Epoch 949 of 2000 took 0.124s
  training loss:		0.022287
  validation loss:		0.331242
  validation accuracy:		93.04 %
Epoch 950 of 2000 took 0.122s
  training loss:		0.021546
  validation loss:		0.327186
  validation accuracy:		93.26 %
Epoch 951 of 2000 took 0.123s
  training loss:		0.022629
  validation loss:		0.335546
  validation accuracy:		93.15 %
Epoch 952 of 2000 took 0.123s
  training loss:		0.022333
  validation loss:		0.330153
  validation accuracy:		93.26 %
Epoch 953 of 2000 took 0.126s
  training loss:		0.022253
  validation loss:		0.337683
  validation accuracy:		92.93 %
Epoch 954 of 2000 took 0.126s
  training loss:		0.021580
  validation loss:		0.343743
  validation accuracy:		92.93 %
Epoch 955 of 2000 took 0.129s
  training loss:		0.021430
  validation loss:		0.330927
  validation accuracy:		93.26 %
Epoch 956 of 2000 took 0.124s
  training loss:		0.021527
  validation loss:		0.343407
  validation accuracy:		93.04 %
Epoch 957 of 2000 took 0.122s
  training loss:		0.020587
  validation loss:		0.339231
  validation accuracy:		92.93 %
Epoch 958 of 2000 took 0.121s
  training loss:		0.021216
  validation loss:		0.325098
  validation accuracy:		93.26 %
Epoch 959 of 2000 took 0.131s
  training loss:		0.022095
  validation loss:		0.340342
  validation accuracy:		93.04 %
Epoch 960 of 2000 took 0.123s
  training loss:		0.022052
  validation loss:		0.342316
  validation accuracy:		93.26 %
Epoch 961 of 2000 took 0.123s
  training loss:		0.021081
  validation loss:		0.344739
  validation accuracy:		92.93 %
Epoch 962 of 2000 took 0.141s
  training loss:		0.021736
  validation loss:		0.341579
  validation accuracy:		93.15 %
Epoch 963 of 2000 took 0.124s
  training loss:		0.021260
  validation loss:		0.344953
  validation accuracy:		92.72 %
Epoch 964 of 2000 took 0.143s
  training loss:		0.022344
  validation loss:		0.335082
  validation accuracy:		93.04 %
Epoch 965 of 2000 took 0.119s
  training loss:		0.021792
  validation loss:		0.340575
  validation accuracy:		93.15 %
Epoch 966 of 2000 took 0.135s
  training loss:		0.020944
  validation loss:		0.356616
  validation accuracy:		93.15 %
Epoch 967 of 2000 took 0.126s
  training loss:		0.021271
  validation loss:		0.335032
  validation accuracy:		93.37 %
Epoch 968 of 2000 took 0.136s
  training loss:		0.021107
  validation loss:		0.341498
  validation accuracy:		92.93 %
Epoch 969 of 2000 took 0.148s
  training loss:		0.021625
  validation loss:		0.331749
  validation accuracy:		93.26 %
Epoch 970 of 2000 took 0.125s
  training loss:		0.020356
  validation loss:		0.340795
  validation accuracy:		93.15 %
Epoch 971 of 2000 took 0.105s
  training loss:		0.021516
  validation loss:		0.334877
  validation accuracy:		93.15 %
Epoch 972 of 2000 took 0.117s
  training loss:		0.021662
  validation loss:		0.337435
  validation accuracy:		93.15 %
Epoch 973 of 2000 took 0.132s
  training loss:		0.020729
  validation loss:		0.340491
  validation accuracy:		93.04 %
Epoch 974 of 2000 took 0.103s
  training loss:		0.021335
  validation loss:		0.337815
  validation accuracy:		93.15 %
Epoch 975 of 2000 took 0.134s
  training loss:		0.021011
  validation loss:		0.345240
  validation accuracy:		92.83 %
Epoch 976 of 2000 took 0.163s
  training loss:		0.021534
  validation loss:		0.339573
  validation accuracy:		93.04 %
Epoch 977 of 2000 took 0.146s
  training loss:		0.019856
  validation loss:		0.352384
  validation accuracy:		92.93 %
Epoch 978 of 2000 took 0.171s
  training loss:		0.022101
  validation loss:		0.336413
  validation accuracy:		93.04 %
Epoch 979 of 2000 took 0.149s
  training loss:		0.019691
  validation loss:		0.337656
  validation accuracy:		93.26 %
Epoch 980 of 2000 took 0.234s
  training loss:		0.020463
  validation loss:		0.345904
  validation accuracy:		93.04 %
Epoch 981 of 2000 took 0.240s
  training loss:		0.020426
  validation loss:		0.333844
  validation accuracy:		93.26 %
Epoch 982 of 2000 took 0.178s
  training loss:		0.020511
  validation loss:		0.357820
  validation accuracy:		93.15 %
Epoch 983 of 2000 took 0.150s
  training loss:		0.021061
  validation loss:		0.350840
  validation accuracy:		92.93 %
Epoch 984 of 2000 took 0.169s
  training loss:		0.020665
  validation loss:		0.339588
  validation accuracy:		93.15 %
Epoch 985 of 2000 took 0.134s
  training loss:		0.021308
  validation loss:		0.351435
  validation accuracy:		92.93 %
Epoch 986 of 2000 took 0.114s
  training loss:		0.021569
  validation loss:		0.342905
  validation accuracy:		92.93 %
Epoch 987 of 2000 took 0.182s
  training loss:		0.019720
  validation loss:		0.343227
  validation accuracy:		93.04 %
Epoch 988 of 2000 took 0.148s
  training loss:		0.019329
  validation loss:		0.353249
  validation accuracy:		93.04 %
Epoch 989 of 2000 took 0.182s
  training loss:		0.020126
  validation loss:		0.340286
  validation accuracy:		93.04 %
Epoch 990 of 2000 took 0.219s
  training loss:		0.019792
  validation loss:		0.345967
  validation accuracy:		92.93 %
Epoch 991 of 2000 took 0.159s
  training loss:		0.019897
  validation loss:		0.346293
  validation accuracy:		93.04 %
Epoch 992 of 2000 took 0.184s
  training loss:		0.020092
  validation loss:		0.348552
  validation accuracy:		92.93 %
Epoch 993 of 2000 took 0.170s
  training loss:		0.019998
  validation loss:		0.345571
  validation accuracy:		93.04 %
Epoch 994 of 2000 took 0.171s
  training loss:		0.019990
  validation loss:		0.346488
  validation accuracy:		93.26 %
Epoch 995 of 2000 took 0.139s
  training loss:		0.020025
  validation loss:		0.344062
  validation accuracy:		93.15 %
Epoch 996 of 2000 took 0.162s
  training loss:		0.020704
  validation loss:		0.340091
  validation accuracy:		93.04 %
Epoch 997 of 2000 took 0.164s
  training loss:		0.019893
  validation loss:		0.348936
  validation accuracy:		93.04 %
Epoch 998 of 2000 took 0.175s
  training loss:		0.019280
  validation loss:		0.344539
  validation accuracy:		93.04 %
Epoch 999 of 2000 took 0.164s
  training loss:		0.020145
  validation loss:		0.348299
  validation accuracy:		92.93 %
Epoch 1000 of 2000 took 0.177s
  training loss:		0.019243
  validation loss:		0.348464
  validation accuracy:		92.93 %
Epoch 1001 of 2000 took 0.144s
  training loss:		0.019172
  validation loss:		0.339478
  validation accuracy:		92.83 %
Epoch 1002 of 2000 took 0.129s
  training loss:		0.018680
  validation loss:		0.354974
  validation accuracy:		93.04 %
Epoch 1003 of 2000 took 0.135s
  training loss:		0.019931
  validation loss:		0.358322
  validation accuracy:		93.15 %
Epoch 1004 of 2000 took 0.129s
  training loss:		0.019358
  validation loss:		0.346364
  validation accuracy:		93.26 %
Epoch 1005 of 2000 took 0.134s
  training loss:		0.019652
  validation loss:		0.344208
  validation accuracy:		92.93 %
Epoch 1006 of 2000 took 0.133s
  training loss:		0.020491
  validation loss:		0.349220
  validation accuracy:		93.04 %
Epoch 1007 of 2000 took 0.181s
  training loss:		0.019771
  validation loss:		0.358772
  validation accuracy:		93.04 %
Epoch 1008 of 2000 took 0.171s
  training loss:		0.019902
  validation loss:		0.353058
  validation accuracy:		93.15 %
Epoch 1009 of 2000 took 0.158s
  training loss:		0.019045
  validation loss:		0.367333
  validation accuracy:		92.93 %
Epoch 1010 of 2000 took 0.186s
  training loss:		0.020650
  validation loss:		0.351253
  validation accuracy:		93.15 %
Epoch 1011 of 2000 took 0.209s
  training loss:		0.019119
  validation loss:		0.349921
  validation accuracy:		92.93 %
Epoch 1012 of 2000 took 0.121s
  training loss:		0.019417
  validation loss:		0.347860
  validation accuracy:		93.04 %
Epoch 1013 of 2000 took 0.153s
  training loss:		0.019739
  validation loss:		0.351192
  validation accuracy:		93.04 %
Epoch 1014 of 2000 took 0.186s
  training loss:		0.017744
  validation loss:		0.357713
  validation accuracy:		92.83 %
Epoch 1015 of 2000 took 0.168s
  training loss:		0.018754
  validation loss:		0.361167
  validation accuracy:		92.93 %
Epoch 1016 of 2000 took 0.194s
  training loss:		0.019502
  validation loss:		0.348602
  validation accuracy:		92.93 %
Epoch 1017 of 2000 took 0.198s
  training loss:		0.018243
  validation loss:		0.364986
  validation accuracy:		92.93 %
Epoch 1018 of 2000 took 0.196s
  training loss:		0.018976
  validation loss:		0.350802
  validation accuracy:		92.93 %
Epoch 1019 of 2000 took 0.212s
  training loss:		0.017933
  validation loss:		0.353440
  validation accuracy:		93.04 %
Epoch 1020 of 2000 took 0.140s
  training loss:		0.020167
  validation loss:		0.363663
  validation accuracy:		93.04 %
Epoch 1021 of 2000 took 0.225s
  training loss:		0.018834
  validation loss:		0.362771
  validation accuracy:		92.93 %
Epoch 1022 of 2000 took 0.144s
  training loss:		0.017415
  validation loss:		0.351460
  validation accuracy:		93.04 %
Epoch 1023 of 2000 took 0.228s
  training loss:		0.018028
  validation loss:		0.362641
  validation accuracy:		92.93 %
Epoch 1024 of 2000 took 0.135s
  training loss:		0.019025
  validation loss:		0.357337
  validation accuracy:		92.83 %
Epoch 1025 of 2000 took 0.152s
  training loss:		0.018925
  validation loss:		0.349115
  validation accuracy:		93.15 %
Epoch 1026 of 2000 took 0.181s
  training loss:		0.018813
  validation loss:		0.357748
  validation accuracy:		92.93 %
Epoch 1027 of 2000 took 0.171s
  training loss:		0.018018
  validation loss:		0.354826
  validation accuracy:		93.04 %
Epoch 1028 of 2000 took 0.140s
  training loss:		0.018660
  validation loss:		0.360295
  validation accuracy:		92.93 %
Epoch 1029 of 2000 took 0.132s
  training loss:		0.018247
  validation loss:		0.357032
  validation accuracy:		93.04 %
Epoch 1030 of 2000 took 0.117s
  training loss:		0.018156
  validation loss:		0.355664
  validation accuracy:		92.83 %
Epoch 1031 of 2000 took 0.125s
  training loss:		0.018846
  validation loss:		0.355119
  validation accuracy:		93.04 %
Epoch 1032 of 2000 took 0.134s
  training loss:		0.018709
  validation loss:		0.356959
  validation accuracy:		93.04 %
Epoch 1033 of 2000 took 0.106s
  training loss:		0.018504
  validation loss:		0.364456
  validation accuracy:		92.83 %
Epoch 1034 of 2000 took 0.111s
  training loss:		0.018063
  validation loss:		0.361382
  validation accuracy:		92.93 %
Epoch 1035 of 2000 took 0.095s
  training loss:		0.017320
  validation loss:		0.358013
  validation accuracy:		93.04 %
Epoch 1036 of 2000 took 0.124s
  training loss:		0.018399
  validation loss:		0.360936
  validation accuracy:		92.93 %
Epoch 1037 of 2000 took 0.127s
  training loss:		0.017610
  validation loss:		0.365047
  validation accuracy:		93.04 %
Epoch 1038 of 2000 took 0.105s
  training loss:		0.018356
  validation loss:		0.358785
  validation accuracy:		92.93 %
Epoch 1039 of 2000 took 0.119s
  training loss:		0.018154
  validation loss:		0.358947
  validation accuracy:		92.93 %
Epoch 1040 of 2000 took 0.132s
  training loss:		0.018717
  validation loss:		0.367008
  validation accuracy:		92.83 %
Epoch 1041 of 2000 took 0.105s
  training loss:		0.018288
  validation loss:		0.367156
  validation accuracy:		93.04 %
Epoch 1042 of 2000 took 0.120s
  training loss:		0.018042
  validation loss:		0.349531
  validation accuracy:		93.04 %
Epoch 1043 of 2000 took 0.121s
  training loss:		0.018178
  validation loss:		0.358067
  validation accuracy:		92.93 %
Epoch 1044 of 2000 took 0.135s
  training loss:		0.017946
  validation loss:		0.373141
  validation accuracy:		92.93 %
Epoch 1045 of 2000 took 0.190s
  training loss:		0.018187
  validation loss:		0.372792
  validation accuracy:		92.83 %
Epoch 1046 of 2000 took 0.202s
  training loss:		0.017486
  validation loss:		0.363689
  validation accuracy:		93.15 %
Epoch 1047 of 2000 took 0.216s
  training loss:		0.017434
  validation loss:		0.359502
  validation accuracy:		93.04 %
Epoch 1048 of 2000 took 0.186s
  training loss:		0.017893
  validation loss:		0.360808
  validation accuracy:		92.93 %
Epoch 1049 of 2000 took 0.190s
  training loss:		0.017598
  validation loss:		0.351739
  validation accuracy:		92.83 %
Epoch 1050 of 2000 took 0.094s
  training loss:		0.017825
  validation loss:		0.354484
  validation accuracy:		93.04 %
Epoch 1051 of 2000 took 0.112s
  training loss:		0.017733
  validation loss:		0.356252
  validation accuracy:		92.72 %
Epoch 1052 of 2000 took 0.114s
  training loss:		0.018708
  validation loss:		0.385188
  validation accuracy:		92.93 %
Epoch 1053 of 2000 took 0.100s
  training loss:		0.018029
  validation loss:		0.365756
  validation accuracy:		92.93 %
Epoch 1054 of 2000 took 0.132s
  training loss:		0.017366
  validation loss:		0.362398
  validation accuracy:		93.15 %
Epoch 1055 of 2000 took 0.109s
  training loss:		0.017559
  validation loss:		0.366529
  validation accuracy:		92.93 %
Epoch 1056 of 2000 took 0.120s
  training loss:		0.016995
  validation loss:		0.375913
  validation accuracy:		93.04 %
Epoch 1057 of 2000 took 0.110s
  training loss:		0.017951
  validation loss:		0.369214
  validation accuracy:		93.04 %
Epoch 1058 of 2000 took 0.146s
  training loss:		0.016815
  validation loss:		0.373837
  validation accuracy:		93.04 %
Epoch 1059 of 2000 took 0.126s
  training loss:		0.017412
  validation loss:		0.368742
  validation accuracy:		92.93 %
Epoch 1060 of 2000 took 0.161s
  training loss:		0.017158
  validation loss:		0.364239
  validation accuracy:		92.93 %
Epoch 1061 of 2000 took 0.118s
  training loss:		0.017308
  validation loss:		0.360637
  validation accuracy:		93.04 %
Epoch 1062 of 2000 took 0.146s
  training loss:		0.016510
  validation loss:		0.371138
  validation accuracy:		93.04 %
Epoch 1063 of 2000 took 0.132s
  training loss:		0.017221
  validation loss:		0.363525
  validation accuracy:		92.93 %
Epoch 1064 of 2000 took 0.135s
  training loss:		0.017601
  validation loss:		0.351709
  validation accuracy:		93.26 %
Epoch 1065 of 2000 took 0.132s
  training loss:		0.017493
  validation loss:		0.370475
  validation accuracy:		92.83 %
Epoch 1066 of 2000 took 0.125s
  training loss:		0.017089
  validation loss:		0.372904
  validation accuracy:		92.83 %
Epoch 1067 of 2000 took 0.123s
  training loss:		0.017799
  validation loss:		0.362560
  validation accuracy:		93.04 %
Epoch 1068 of 2000 took 0.144s
  training loss:		0.016559
  validation loss:		0.376581
  validation accuracy:		92.93 %
Epoch 1069 of 2000 took 0.174s
  training loss:		0.017181
  validation loss:		0.357249
  validation accuracy:		92.93 %
Epoch 1070 of 2000 took 0.190s
  training loss:		0.016672
  validation loss:		0.367967
  validation accuracy:		93.04 %
Epoch 1071 of 2000 took 0.188s
  training loss:		0.016179
  validation loss:		0.373269
  validation accuracy:		92.83 %
Epoch 1072 of 2000 took 0.151s
  training loss:		0.016775
  validation loss:		0.367318
  validation accuracy:		92.93 %
Epoch 1073 of 2000 took 0.148s
  training loss:		0.015815
  validation loss:		0.370067
  validation accuracy:		92.83 %
Epoch 1074 of 2000 took 0.161s
  training loss:		0.017067
  validation loss:		0.359548
  validation accuracy:		93.04 %
Epoch 1075 of 2000 took 0.175s
  training loss:		0.015778
  validation loss:		0.370136
  validation accuracy:		93.26 %
Epoch 1076 of 2000 took 0.165s
  training loss:		0.016790
  validation loss:		0.369563
  validation accuracy:		92.83 %
Epoch 1077 of 2000 took 0.149s
  training loss:		0.016597
  validation loss:		0.367931
  validation accuracy:		92.93 %
Epoch 1078 of 2000 took 0.177s
  training loss:		0.016094
  validation loss:		0.366123
  validation accuracy:		92.93 %
Epoch 1079 of 2000 took 0.189s
  training loss:		0.016567
  validation loss:		0.367186
  validation accuracy:		92.83 %
Epoch 1080 of 2000 took 0.186s
  training loss:		0.016519
  validation loss:		0.361644
  validation accuracy:		92.93 %
Epoch 1081 of 2000 took 0.192s
  training loss:		0.016585
  validation loss:		0.368202
  validation accuracy:		92.83 %
Epoch 1082 of 2000 took 0.186s
  training loss:		0.016710
  validation loss:		0.372167
  validation accuracy:		92.83 %
Epoch 1083 of 2000 took 0.156s
  training loss:		0.016299
  validation loss:		0.376539
  validation accuracy:		92.93 %
Epoch 1084 of 2000 took 0.146s
  training loss:		0.016365
  validation loss:		0.373627
  validation accuracy:		92.83 %
Epoch 1085 of 2000 took 0.182s
  training loss:		0.016777
  validation loss:		0.365399
  validation accuracy:		92.83 %
Epoch 1086 of 2000 took 0.194s
  training loss:		0.016489
  validation loss:		0.365725
  validation accuracy:		92.83 %
Epoch 1087 of 2000 took 0.158s
  training loss:		0.016850
  validation loss:		0.369903
  validation accuracy:		92.83 %
Epoch 1088 of 2000 took 0.162s
  training loss:		0.016018
  validation loss:		0.370107
  validation accuracy:		92.93 %
Epoch 1089 of 2000 took 0.148s
  training loss:		0.016692
  validation loss:		0.378702
  validation accuracy:		92.93 %
Epoch 1090 of 2000 took 0.149s
  training loss:		0.016950
  validation loss:		0.365665
  validation accuracy:		92.83 %
Epoch 1091 of 2000 took 0.143s
  training loss:		0.016045
  validation loss:		0.372463
  validation accuracy:		92.83 %
Epoch 1092 of 2000 took 0.141s
  training loss:		0.015637
  validation loss:		0.369883
  validation accuracy:		93.04 %
Epoch 1093 of 2000 took 0.144s
  training loss:		0.016685
  validation loss:		0.376625
  validation accuracy:		92.93 %
Epoch 1094 of 2000 took 0.161s
  training loss:		0.015711
  validation loss:		0.375212
  validation accuracy:		92.83 %
Epoch 1095 of 2000 took 0.187s
  training loss:		0.015967
  validation loss:		0.375157
  validation accuracy:		93.04 %
Epoch 1096 of 2000 took 0.187s
  training loss:		0.015454
  validation loss:		0.384071
  validation accuracy:		92.93 %
Epoch 1097 of 2000 took 0.176s
  training loss:		0.016548
  validation loss:		0.371487
  validation accuracy:		92.93 %
Epoch 1098 of 2000 took 0.139s
  training loss:		0.015612
  validation loss:		0.386187
  validation accuracy:		92.83 %
Epoch 1099 of 2000 took 0.151s
  training loss:		0.015902
  validation loss:		0.373225
  validation accuracy:		92.93 %
Epoch 1100 of 2000 took 0.160s
  training loss:		0.015084
  validation loss:		0.380722
  validation accuracy:		92.93 %
Epoch 1101 of 2000 took 0.154s
  training loss:		0.015904
  validation loss:		0.377708
  validation accuracy:		92.83 %
Epoch 1102 of 2000 took 0.147s
  training loss:		0.015275
  validation loss:		0.377415
  validation accuracy:		92.72 %
Epoch 1103 of 2000 took 0.143s
  training loss:		0.014839
  validation loss:		0.385178
  validation accuracy:		92.83 %
Epoch 1104 of 2000 took 0.144s
  training loss:		0.015022
  validation loss:		0.381659
  validation accuracy:		92.83 %
Epoch 1105 of 2000 took 0.158s
  training loss:		0.015780
  validation loss:		0.372116
  validation accuracy:		92.83 %
Epoch 1106 of 2000 took 0.172s
  training loss:		0.016408
  validation loss:		0.382601
  validation accuracy:		93.04 %
Epoch 1107 of 2000 took 0.148s
  training loss:		0.014941
  validation loss:		0.387553
  validation accuracy:		92.72 %
Epoch 1108 of 2000 took 0.146s
  training loss:		0.015533
  validation loss:		0.381430
  validation accuracy:		93.04 %
Epoch 1109 of 2000 took 0.141s
  training loss:		0.015315
  validation loss:		0.379686
  validation accuracy:		93.04 %
Epoch 1110 of 2000 took 0.138s
  training loss:		0.015516
  validation loss:		0.374819
  validation accuracy:		92.93 %
Epoch 1111 of 2000 took 0.148s
  training loss:		0.015421
  validation loss:		0.389780
  validation accuracy:		92.72 %
Epoch 1112 of 2000 took 0.157s
  training loss:		0.014763
  validation loss:		0.374902
  validation accuracy:		92.83 %
Epoch 1113 of 2000 took 0.156s
  training loss:		0.014537
  validation loss:		0.378208
  validation accuracy:		92.93 %
Epoch 1114 of 2000 took 0.151s
  training loss:		0.015222
  validation loss:		0.384936
  validation accuracy:		92.83 %
Epoch 1115 of 2000 took 0.168s
  training loss:		0.015695
  validation loss:		0.380530
  validation accuracy:		92.72 %
Epoch 1116 of 2000 took 0.178s
  training loss:		0.016025
  validation loss:		0.373140
  validation accuracy:		93.15 %
Epoch 1117 of 2000 took 0.148s
  training loss:		0.015535
  validation loss:		0.373038
  validation accuracy:		92.83 %
Epoch 1118 of 2000 took 0.149s
  training loss:		0.015114
  validation loss:		0.377091
  validation accuracy:		92.93 %
Epoch 1119 of 2000 took 0.148s
  training loss:		0.014815
  validation loss:		0.376275
  validation accuracy:		92.83 %
Epoch 1120 of 2000 took 0.145s
  training loss:		0.014577
  validation loss:		0.384338
  validation accuracy:		92.83 %
Epoch 1121 of 2000 took 0.145s
  training loss:		0.015513
  validation loss:		0.389719
  validation accuracy:		92.83 %
Epoch 1122 of 2000 took 0.158s
  training loss:		0.014729
  validation loss:		0.383226
  validation accuracy:		93.04 %
Epoch 1123 of 2000 took 0.151s
  training loss:		0.014921
  validation loss:		0.373461
  validation accuracy:		92.83 %
Epoch 1124 of 2000 took 0.175s
  training loss:		0.014802
  validation loss:		0.383269
  validation accuracy:		92.83 %
Epoch 1125 of 2000 took 0.184s
  training loss:		0.015062
  validation loss:		0.392463
  validation accuracy:		92.93 %
Epoch 1126 of 2000 took 0.178s
  training loss:		0.014783
  validation loss:		0.387111
  validation accuracy:		92.72 %
Epoch 1127 of 2000 took 0.185s
  training loss:		0.014932
  validation loss:		0.387386
  validation accuracy:		93.04 %
Epoch 1128 of 2000 took 0.165s
  training loss:		0.014965
  validation loss:		0.387927
  validation accuracy:		92.72 %
Epoch 1129 of 2000 took 0.155s
  training loss:		0.015054
  validation loss:		0.389430
  validation accuracy:		92.83 %
Epoch 1130 of 2000 took 0.184s
  training loss:		0.014697
  validation loss:		0.385510
  validation accuracy:		92.93 %
Epoch 1131 of 2000 took 0.164s
  training loss:		0.014928
  validation loss:		0.390834
  validation accuracy:		92.72 %
Epoch 1132 of 2000 took 0.153s
  training loss:		0.014586
  validation loss:		0.384446
  validation accuracy:		92.72 %
Epoch 1133 of 2000 took 0.164s
  training loss:		0.014425
  validation loss:		0.393058
  validation accuracy:		92.72 %
Epoch 1134 of 2000 took 0.187s
  training loss:		0.014664
  validation loss:		0.391425
  validation accuracy:		92.93 %
Epoch 1135 of 2000 took 0.163s
  training loss:		0.015996
  validation loss:		0.395210
  validation accuracy:		92.83 %
Epoch 1136 of 2000 took 0.142s
  training loss:		0.015066
  validation loss:		0.378644
  validation accuracy:		92.83 %
Epoch 1137 of 2000 took 0.151s
  training loss:		0.014555
  validation loss:		0.388705
  validation accuracy:		92.72 %
Epoch 1138 of 2000 took 0.184s
  training loss:		0.014161
  validation loss:		0.373596
  validation accuracy:		92.83 %
Epoch 1139 of 2000 took 0.164s
  training loss:		0.014185
  validation loss:		0.397645
  validation accuracy:		92.72 %
Epoch 1140 of 2000 took 0.133s
  training loss:		0.014683
  validation loss:		0.392195
  validation accuracy:		92.83 %
Epoch 1141 of 2000 took 0.147s
  training loss:		0.015027
  validation loss:		0.385981
  validation accuracy:		93.04 %
Epoch 1142 of 2000 took 0.156s
  training loss:		0.014079
  validation loss:		0.379593
  validation accuracy:		92.93 %
Epoch 1143 of 2000 took 0.154s
  training loss:		0.014730
  validation loss:		0.383438
  validation accuracy:		92.83 %
Epoch 1144 of 2000 took 0.190s
  training loss:		0.014346
  validation loss:		0.391324
  validation accuracy:		92.83 %
Epoch 1145 of 2000 took 0.191s
  training loss:		0.014428
  validation loss:		0.384579
  validation accuracy:		92.83 %
Epoch 1146 of 2000 took 0.190s
  training loss:		0.014039
  validation loss:		0.390426
  validation accuracy:		93.04 %
Epoch 1147 of 2000 took 0.175s
  training loss:		0.014732
  validation loss:		0.400304
  validation accuracy:		92.93 %
Epoch 1148 of 2000 took 0.186s
  training loss:		0.013527
  validation loss:		0.385961
  validation accuracy:		92.83 %
Epoch 1149 of 2000 took 0.186s
  training loss:		0.013849
  validation loss:		0.392675
  validation accuracy:		92.72 %
Epoch 1150 of 2000 took 0.149s
  training loss:		0.013588
  validation loss:		0.396256
  validation accuracy:		92.83 %
Epoch 1151 of 2000 took 0.128s
  training loss:		0.014152
  validation loss:		0.382329
  validation accuracy:		92.83 %
Epoch 1152 of 2000 took 0.164s
  training loss:		0.013750
  validation loss:		0.396239
  validation accuracy:		92.39 %
Epoch 1153 of 2000 took 0.156s
  training loss:		0.014079
  validation loss:		0.389793
  validation accuracy:		92.93 %
Epoch 1154 of 2000 took 0.183s
  training loss:		0.013866
  validation loss:		0.399507
  validation accuracy:		92.72 %
Epoch 1155 of 2000 took 0.184s
  training loss:		0.013347
  validation loss:		0.379962
  validation accuracy:		92.83 %
Epoch 1156 of 2000 took 0.161s
  training loss:		0.013297
  validation loss:		0.381234
  validation accuracy:		92.83 %
Epoch 1157 of 2000 took 0.185s
  training loss:		0.013947
  validation loss:		0.391123
  validation accuracy:		92.83 %
Epoch 1158 of 2000 took 0.187s
  training loss:		0.013814
  validation loss:		0.384824
  validation accuracy:		93.04 %
Epoch 1159 of 2000 took 0.150s
  training loss:		0.013710
  validation loss:		0.389958
  validation accuracy:		92.83 %
Epoch 1160 of 2000 took 0.173s
  training loss:		0.014252
  validation loss:		0.389983
  validation accuracy:		92.83 %
Epoch 1161 of 2000 took 0.183s
  training loss:		0.014017
  validation loss:		0.390218
  validation accuracy:		92.93 %
Epoch 1162 of 2000 took 0.141s
  training loss:		0.013718
  validation loss:		0.392065
  validation accuracy:		92.83 %
Epoch 1163 of 2000 took 0.141s
  training loss:		0.013677
  validation loss:		0.400945
  validation accuracy:		92.72 %
Epoch 1164 of 2000 took 0.146s
  training loss:		0.013632
  validation loss:		0.400638
  validation accuracy:		92.72 %
Epoch 1165 of 2000 took 0.137s
  training loss:		0.014582
  validation loss:		0.397522
  validation accuracy:		92.83 %
Epoch 1166 of 2000 took 0.154s
  training loss:		0.013823
  validation loss:		0.392369
  validation accuracy:		92.93 %
Epoch 1167 of 2000 took 0.165s
  training loss:		0.013411
  validation loss:		0.396837
  validation accuracy:		92.83 %
Epoch 1168 of 2000 took 0.186s
  training loss:		0.012886
  validation loss:		0.398782
  validation accuracy:		93.04 %
Epoch 1169 of 2000 took 0.156s
  training loss:		0.013315
  validation loss:		0.390628
  validation accuracy:		92.83 %
Epoch 1170 of 2000 took 0.160s
  training loss:		0.013475
  validation loss:		0.394514
  validation accuracy:		92.83 %
Epoch 1171 of 2000 took 0.186s
  training loss:		0.013344
  validation loss:		0.391277
  validation accuracy:		92.93 %
Epoch 1172 of 2000 took 0.169s
  training loss:		0.013190
  validation loss:		0.393176
  validation accuracy:		92.93 %
Epoch 1173 of 2000 took 0.145s
  training loss:		0.013463
  validation loss:		0.391280
  validation accuracy:		92.83 %
Epoch 1174 of 2000 took 0.148s
  training loss:		0.013128
  validation loss:		0.408946
  validation accuracy:		92.83 %
Epoch 1175 of 2000 took 0.139s
  training loss:		0.013927
  validation loss:		0.395923
  validation accuracy:		92.83 %
Epoch 1176 of 2000 took 0.141s
  training loss:		0.013276
  validation loss:		0.405715
  validation accuracy:		93.04 %
Epoch 1177 of 2000 took 0.149s
  training loss:		0.013034
  validation loss:		0.387148
  validation accuracy:		93.04 %
Epoch 1178 of 2000 took 0.159s
  training loss:		0.013174
  validation loss:		0.397239
  validation accuracy:		92.93 %
Epoch 1179 of 2000 took 0.190s
  training loss:		0.013250
  validation loss:		0.395602
  validation accuracy:		92.72 %
Epoch 1180 of 2000 took 0.161s
  training loss:		0.013160
  validation loss:		0.397660
  validation accuracy:		92.72 %
Epoch 1181 of 2000 took 0.179s
  training loss:		0.013144
  validation loss:		0.399532
  validation accuracy:		93.04 %
Epoch 1182 of 2000 took 0.192s
  training loss:		0.012524
  validation loss:		0.393025
  validation accuracy:		92.72 %
Epoch 1183 of 2000 took 0.192s
  training loss:		0.012410
  validation loss:		0.391692
  validation accuracy:		92.83 %
Epoch 1184 of 2000 took 0.189s
  training loss:		0.012462
  validation loss:		0.395064
  validation accuracy:		93.04 %
Epoch 1185 of 2000 took 0.182s
  training loss:		0.012820
  validation loss:		0.397455
  validation accuracy:		92.83 %
Epoch 1186 of 2000 took 0.141s
  training loss:		0.012626
  validation loss:		0.397092
  validation accuracy:		93.04 %
Epoch 1187 of 2000 took 0.164s
  training loss:		0.013137
  validation loss:		0.400764
  validation accuracy:		92.83 %
Epoch 1188 of 2000 took 0.148s
  training loss:		0.012912
  validation loss:		0.393768
  validation accuracy:		92.83 %
Epoch 1189 of 2000 took 0.155s
  training loss:		0.012929
  validation loss:		0.406283
  validation accuracy:		92.61 %
Epoch 1190 of 2000 took 0.193s
  training loss:		0.012896
  validation loss:		0.397255
  validation accuracy:		92.83 %
Epoch 1191 of 2000 took 0.182s
  training loss:		0.012859
  validation loss:		0.400098
  validation accuracy:		93.04 %
Epoch 1192 of 2000 took 0.184s
  training loss:		0.012652
  validation loss:		0.411934
  validation accuracy:		92.72 %
Epoch 1193 of 2000 took 0.185s
  training loss:		0.013074
  validation loss:		0.402819
  validation accuracy:		92.83 %
Epoch 1194 of 2000 took 0.198s
  training loss:		0.012795
  validation loss:		0.407354
  validation accuracy:		92.72 %
Epoch 1195 of 2000 took 0.184s
  training loss:		0.012488
  validation loss:		0.394647
  validation accuracy:		92.83 %
Epoch 1196 of 2000 took 0.191s
  training loss:		0.013012
  validation loss:		0.405452
  validation accuracy:		92.83 %
Epoch 1197 of 2000 took 0.185s
  training loss:		0.012679
  validation loss:		0.408532
  validation accuracy:		92.72 %
Epoch 1198 of 2000 took 0.188s
  training loss:		0.012796
  validation loss:		0.408914
  validation accuracy:		92.93 %
Epoch 1199 of 2000 took 0.191s
  training loss:		0.012235
  validation loss:		0.391606
  validation accuracy:		92.93 %
Epoch 1200 of 2000 took 0.181s
  training loss:		0.012730
  validation loss:		0.403040
  validation accuracy:		92.83 %
Epoch 1201 of 2000 took 0.187s
  training loss:		0.012307
  validation loss:		0.395030
  validation accuracy:		92.72 %
Epoch 1202 of 2000 took 0.171s
  training loss:		0.012431
  validation loss:		0.396872
  validation accuracy:		93.15 %
Epoch 1203 of 2000 took 0.165s
  training loss:		0.011953
  validation loss:		0.404396
  validation accuracy:		92.83 %
Epoch 1204 of 2000 took 0.175s
  training loss:		0.012062
  validation loss:		0.399885
  validation accuracy:		92.83 %
Epoch 1205 of 2000 took 0.191s
  training loss:		0.012429
  validation loss:		0.406516
  validation accuracy:		92.93 %
Epoch 1206 of 2000 took 0.190s
  training loss:		0.012881
  validation loss:		0.406403
  validation accuracy:		92.93 %
Epoch 1207 of 2000 took 0.180s
  training loss:		0.012682
  validation loss:		0.405208
  validation accuracy:		92.93 %
Epoch 1208 of 2000 took 0.150s
  training loss:		0.012236
  validation loss:		0.400301
  validation accuracy:		92.83 %
Epoch 1209 of 2000 took 0.151s
  training loss:		0.012195
  validation loss:		0.420892
  validation accuracy:		92.72 %
Epoch 1210 of 2000 took 0.172s
  training loss:		0.012197
  validation loss:		0.401680
  validation accuracy:		92.93 %
Epoch 1211 of 2000 took 0.161s
  training loss:		0.012524
  validation loss:		0.409207
  validation accuracy:		92.83 %
Epoch 1212 of 2000 took 0.160s
  training loss:		0.012166
  validation loss:		0.410444
  validation accuracy:		92.83 %
Epoch 1213 of 2000 took 0.179s
  training loss:		0.012653
  validation loss:		0.410056
  validation accuracy:		93.04 %
Epoch 1214 of 2000 took 0.146s
  training loss:		0.012382
  validation loss:		0.410905
  validation accuracy:		92.93 %
Epoch 1215 of 2000 took 0.161s
  training loss:		0.012595
  validation loss:		0.405846
  validation accuracy:		92.93 %
Epoch 1216 of 2000 took 0.150s
  training loss:		0.011976
  validation loss:		0.406180
  validation accuracy:		93.04 %
Epoch 1217 of 2000 took 0.162s
  training loss:		0.012329
  validation loss:		0.406636
  validation accuracy:		92.83 %
Epoch 1218 of 2000 took 0.151s
  training loss:		0.012496
  validation loss:		0.407027
  validation accuracy:		93.04 %
Epoch 1219 of 2000 took 0.146s
  training loss:		0.012182
  validation loss:		0.405444
  validation accuracy:		92.72 %
Epoch 1220 of 2000 took 0.147s
  training loss:		0.012466
  validation loss:		0.411388
  validation accuracy:		92.93 %
Epoch 1221 of 2000 took 0.154s
  training loss:		0.011919
  validation loss:		0.406706
  validation accuracy:		92.83 %
Epoch 1222 of 2000 took 0.171s
  training loss:		0.012044
  validation loss:		0.404072
  validation accuracy:		92.83 %
Epoch 1223 of 2000 took 0.159s
  training loss:		0.012159
  validation loss:		0.408275
  validation accuracy:		92.93 %
Epoch 1224 of 2000 took 0.179s
  training loss:		0.011872
  validation loss:		0.412583
  validation accuracy:		92.83 %
Epoch 1225 of 2000 took 0.146s
  training loss:		0.011908
  validation loss:		0.404219
  validation accuracy:		92.93 %
Epoch 1226 of 2000 took 0.150s
  training loss:		0.012355
  validation loss:		0.410800
  validation accuracy:		93.04 %
Epoch 1227 of 2000 took 0.146s
  training loss:		0.011853
  validation loss:		0.408193
  validation accuracy:		93.04 %
Epoch 1228 of 2000 took 0.146s
  training loss:		0.012016
  validation loss:		0.408312
  validation accuracy:		92.72 %
Epoch 1229 of 2000 took 0.162s
  training loss:		0.011926
  validation loss:		0.411737
  validation accuracy:		92.83 %
Epoch 1230 of 2000 took 0.167s
  training loss:		0.011613
  validation loss:		0.407104
  validation accuracy:		93.04 %
Epoch 1231 of 2000 took 0.171s
  training loss:		0.011875
  validation loss:		0.411742
  validation accuracy:		92.83 %
Epoch 1232 of 2000 took 0.183s
  training loss:		0.011751
  validation loss:		0.410074
  validation accuracy:		92.83 %
Epoch 1233 of 2000 took 0.189s
  training loss:		0.011907
  validation loss:		0.402493
  validation accuracy:		92.72 %
Epoch 1234 of 2000 took 0.151s
  training loss:		0.011834
  validation loss:		0.413182
  validation accuracy:		92.72 %
Epoch 1235 of 2000 took 0.173s
  training loss:		0.011685
  validation loss:		0.407466
  validation accuracy:		92.93 %
Epoch 1236 of 2000 took 0.190s
  training loss:		0.011999
  validation loss:		0.414838
  validation accuracy:		92.83 %
Epoch 1237 of 2000 took 0.184s
  training loss:		0.011982
  validation loss:		0.408869
  validation accuracy:		92.83 %
Epoch 1238 of 2000 took 0.176s
  training loss:		0.011800
  validation loss:		0.413990
  validation accuracy:		92.83 %
Epoch 1239 of 2000 took 0.158s
  training loss:		0.011951
  validation loss:		0.412440
  validation accuracy:		92.83 %
Epoch 1240 of 2000 took 0.147s
  training loss:		0.011351
  validation loss:		0.406282
  validation accuracy:		92.83 %
Epoch 1241 of 2000 took 0.158s
  training loss:		0.011235
  validation loss:		0.415287
  validation accuracy:		92.72 %
Epoch 1242 of 2000 took 0.158s
  training loss:		0.011658
  validation loss:		0.414420
  validation accuracy:		92.72 %
Epoch 1243 of 2000 took 0.181s
  training loss:		0.011683
  validation loss:		0.412263
  validation accuracy:		92.93 %
Epoch 1244 of 2000 took 0.189s
  training loss:		0.011542
  validation loss:		0.419008
  validation accuracy:		92.61 %
Epoch 1245 of 2000 took 0.166s
  training loss:		0.011602
  validation loss:		0.415128
  validation accuracy:		92.83 %
Epoch 1246 of 2000 took 0.158s
  training loss:		0.011141
  validation loss:		0.420769
  validation accuracy:		92.72 %
Epoch 1247 of 2000 took 0.146s
  training loss:		0.011554
  validation loss:		0.409964
  validation accuracy:		92.83 %
Epoch 1248 of 2000 took 0.149s
  training loss:		0.011158
  validation loss:		0.431819
  validation accuracy:		92.61 %
Epoch 1249 of 2000 took 0.147s
  training loss:		0.011438
  validation loss:		0.414530
  validation accuracy:		92.83 %
Epoch 1250 of 2000 took 0.144s
  training loss:		0.011735
  validation loss:		0.417825
  validation accuracy:		92.72 %
Epoch 1251 of 2000 took 0.164s
  training loss:		0.011659
  validation loss:		0.416984
  validation accuracy:		92.83 %
Epoch 1252 of 2000 took 0.155s
  training loss:		0.011019
  validation loss:		0.402692
  validation accuracy:		92.83 %
Epoch 1253 of 2000 took 0.161s
  training loss:		0.011417
  validation loss:		0.414107
  validation accuracy:		92.93 %
Epoch 1254 of 2000 took 0.144s
  training loss:		0.011137
  validation loss:		0.405638
  validation accuracy:		92.83 %
Epoch 1255 of 2000 took 0.168s
  training loss:		0.011599
  validation loss:		0.422543
  validation accuracy:		92.61 %
Epoch 1256 of 2000 took 0.157s
  training loss:		0.011313
  validation loss:		0.413221
  validation accuracy:		92.93 %
Epoch 1257 of 2000 took 0.179s
  training loss:		0.011279
  validation loss:		0.412684
  validation accuracy:		92.83 %
Epoch 1258 of 2000 took 0.160s
  training loss:		0.011364
  validation loss:		0.416196
  validation accuracy:		92.93 %
Epoch 1259 of 2000 took 0.167s
  training loss:		0.010937
  validation loss:		0.411334
  validation accuracy:		92.83 %
Epoch 1260 of 2000 took 0.165s
  training loss:		0.011210
  validation loss:		0.418123
  validation accuracy:		92.83 %
Epoch 1261 of 2000 took 0.151s
  training loss:		0.010664
  validation loss:		0.419994
  validation accuracy:		92.83 %
Epoch 1262 of 2000 took 0.158s
  training loss:		0.010984
  validation loss:		0.418985
  validation accuracy:		92.72 %
Epoch 1263 of 2000 took 0.147s
  training loss:		0.011016
  validation loss:		0.409597
  validation accuracy:		92.83 %
Epoch 1264 of 2000 took 0.147s
  training loss:		0.011532
  validation loss:		0.413019
  validation accuracy:		92.72 %
Epoch 1265 of 2000 took 0.163s
  training loss:		0.010612
  validation loss:		0.425302
  validation accuracy:		92.61 %
Epoch 1266 of 2000 took 0.151s
  training loss:		0.010610
  validation loss:		0.425911
  validation accuracy:		92.72 %
Epoch 1267 of 2000 took 0.141s
  training loss:		0.010771
  validation loss:		0.425069
  validation accuracy:		92.61 %
Epoch 1268 of 2000 took 0.168s
  training loss:		0.011153
  validation loss:		0.421222
  validation accuracy:		92.72 %
Epoch 1269 of 2000 took 0.160s
  training loss:		0.011056
  validation loss:		0.417098
  validation accuracy:		92.83 %
Epoch 1270 of 2000 took 0.190s
  training loss:		0.011186
  validation loss:		0.413097
  validation accuracy:		92.93 %
Epoch 1271 of 2000 took 0.180s
  training loss:		0.010714
  validation loss:		0.414780
  validation accuracy:		92.83 %
Epoch 1272 of 2000 took 0.149s
  training loss:		0.011030
  validation loss:		0.416252
  validation accuracy:		92.83 %
Epoch 1273 of 2000 took 0.184s
  training loss:		0.010601
  validation loss:		0.418108
  validation accuracy:		92.83 %
Epoch 1274 of 2000 took 0.193s
  training loss:		0.010612
  validation loss:		0.422643
  validation accuracy:		92.93 %
Epoch 1275 of 2000 took 0.185s
  training loss:		0.011277
  validation loss:		0.428103
  validation accuracy:		92.72 %
Epoch 1276 of 2000 took 0.195s
  training loss:		0.010763
  validation loss:		0.420012
  validation accuracy:		92.83 %
Epoch 1277 of 2000 took 0.154s
  training loss:		0.010856
  validation loss:		0.424107
  validation accuracy:		92.93 %
Epoch 1278 of 2000 took 0.167s
  training loss:		0.010584
  validation loss:		0.417158
  validation accuracy:		92.83 %
Epoch 1279 of 2000 took 0.147s
  training loss:		0.010904
  validation loss:		0.423557
  validation accuracy:		92.83 %
Epoch 1280 of 2000 took 0.164s
  training loss:		0.010946
  validation loss:		0.418652
  validation accuracy:		92.83 %
Epoch 1281 of 2000 took 0.175s
  training loss:		0.010300
  validation loss:		0.420026
  validation accuracy:		92.83 %
Epoch 1282 of 2000 took 0.191s
  training loss:		0.010456
  validation loss:		0.418731
  validation accuracy:		92.72 %
Epoch 1283 of 2000 took 0.180s
  training loss:		0.010404
  validation loss:		0.422094
  validation accuracy:		92.93 %
Epoch 1284 of 2000 took 0.184s
  training loss:		0.010695
  validation loss:		0.417140
  validation accuracy:		92.83 %
Epoch 1285 of 2000 took 0.192s
  training loss:		0.010588
  validation loss:		0.421305
  validation accuracy:		92.83 %
Epoch 1286 of 2000 took 0.154s
  training loss:		0.010579
  validation loss:		0.420963
  validation accuracy:		92.83 %
Epoch 1287 of 2000 took 0.160s
  training loss:		0.010659
  validation loss:		0.415679
  validation accuracy:		92.83 %
Epoch 1288 of 2000 took 0.136s
  training loss:		0.011091
  validation loss:		0.422493
  validation accuracy:		92.83 %
Epoch 1289 of 2000 took 0.166s
  training loss:		0.010517
  validation loss:		0.428397
  validation accuracy:		92.61 %
Epoch 1290 of 2000 took 0.188s
  training loss:		0.010897
  validation loss:		0.422935
  validation accuracy:		92.83 %
Epoch 1291 of 2000 took 0.193s
  training loss:		0.010343
  validation loss:		0.424506
  validation accuracy:		92.83 %
Epoch 1292 of 2000 took 0.189s
  training loss:		0.010247
  validation loss:		0.426717
  validation accuracy:		92.83 %
Epoch 1293 of 2000 took 0.196s
  training loss:		0.010223
  validation loss:		0.418024
  validation accuracy:		92.83 %
Epoch 1294 of 2000 took 0.188s
  training loss:		0.010233
  validation loss:		0.419311
  validation accuracy:		92.93 %
Epoch 1295 of 2000 took 0.191s
  training loss:		0.011005
  validation loss:		0.420451
  validation accuracy:		92.83 %
Epoch 1296 of 2000 took 0.144s
  training loss:		0.010522
  validation loss:		0.425352
  validation accuracy:		92.83 %
Epoch 1297 of 2000 took 0.142s
  training loss:		0.010218
  validation loss:		0.417967
  validation accuracy:		92.72 %
Epoch 1298 of 2000 took 0.181s
  training loss:		0.010624
  validation loss:		0.428924
  validation accuracy:		92.93 %
Epoch 1299 of 2000 took 0.189s
  training loss:		0.010253
  validation loss:		0.432567
  validation accuracy:		92.61 %
Epoch 1300 of 2000 took 0.184s
  training loss:		0.010227
  validation loss:		0.422656
  validation accuracy:		92.83 %
Epoch 1301 of 2000 took 0.175s
  training loss:		0.009920
  validation loss:		0.431886
  validation accuracy:		92.83 %
Epoch 1302 of 2000 took 0.188s
  training loss:		0.010222
  validation loss:		0.428899
  validation accuracy:		92.83 %
Epoch 1303 of 2000 took 0.188s
  training loss:		0.010390
  validation loss:		0.425409
  validation accuracy:		92.93 %
Epoch 1304 of 2000 took 0.179s
  training loss:		0.010134
  validation loss:		0.433625
  validation accuracy:		92.93 %
Epoch 1305 of 2000 took 0.185s
  training loss:		0.010342
  validation loss:		0.428574
  validation accuracy:		92.83 %
Epoch 1306 of 2000 took 0.188s
  training loss:		0.010415
  validation loss:		0.421700
  validation accuracy:		92.72 %
Epoch 1307 of 2000 took 0.188s
  training loss:		0.010179
  validation loss:		0.427187
  validation accuracy:		93.04 %
Epoch 1308 of 2000 took 0.191s
  training loss:		0.010056
  validation loss:		0.423993
  validation accuracy:		92.83 %
Epoch 1309 of 2000 took 0.189s
  training loss:		0.009726
  validation loss:		0.432938
  validation accuracy:		92.72 %
Epoch 1310 of 2000 took 0.187s
  training loss:		0.009956
  validation loss:		0.434331
  validation accuracy:		92.83 %
Epoch 1311 of 2000 took 0.183s
  training loss:		0.009919
  validation loss:		0.419652
  validation accuracy:		92.83 %
Epoch 1312 of 2000 took 0.150s
  training loss:		0.010009
  validation loss:		0.427695
  validation accuracy:		92.72 %
Epoch 1313 of 2000 took 0.144s
  training loss:		0.009883
  validation loss:		0.428119
  validation accuracy:		92.83 %
Epoch 1314 of 2000 took 0.170s
  training loss:		0.009934
  validation loss:		0.430498
  validation accuracy:		92.93 %
Epoch 1315 of 2000 took 0.162s
  training loss:		0.010210
  validation loss:		0.423637
  validation accuracy:		92.83 %
Epoch 1316 of 2000 took 0.161s
  training loss:		0.009965
  validation loss:		0.432161
  validation accuracy:		92.83 %
Epoch 1317 of 2000 took 0.187s
  training loss:		0.010131
  validation loss:		0.435979
  validation accuracy:		92.72 %
Epoch 1318 of 2000 took 0.188s
  training loss:		0.009857
  validation loss:		0.434361
  validation accuracy:		92.93 %
Epoch 1319 of 2000 took 0.192s
  training loss:		0.009869
  validation loss:		0.431738
  validation accuracy:		92.93 %
Epoch 1320 of 2000 took 0.188s
  training loss:		0.010144
  validation loss:		0.429945
  validation accuracy:		92.83 %
Epoch 1321 of 2000 took 0.189s
  training loss:		0.010013
  validation loss:		0.432530
  validation accuracy:		92.72 %
Epoch 1322 of 2000 took 0.177s
  training loss:		0.009702
  validation loss:		0.436156
  validation accuracy:		92.93 %
Epoch 1323 of 2000 took 0.141s
  training loss:		0.009881
  validation loss:		0.435721
  validation accuracy:		92.83 %
Epoch 1324 of 2000 took 0.179s
  training loss:		0.009793
  validation loss:		0.438547
  validation accuracy:		92.83 %
Epoch 1325 of 2000 took 0.146s
  training loss:		0.009602
  validation loss:		0.427224
  validation accuracy:		92.72 %
Epoch 1326 of 2000 took 0.148s
  training loss:		0.009384
  validation loss:		0.433783
  validation accuracy:		92.83 %
Epoch 1327 of 2000 took 0.151s
  training loss:		0.009747
  validation loss:		0.427329
  validation accuracy:		92.83 %
Epoch 1328 of 2000 took 0.146s
  training loss:		0.009574
  validation loss:		0.437363
  validation accuracy:		92.61 %
Epoch 1329 of 2000 took 0.141s
  training loss:		0.009561
  validation loss:		0.433849
  validation accuracy:		92.93 %
Epoch 1330 of 2000 took 0.160s
  training loss:		0.009718
  validation loss:		0.439564
  validation accuracy:		92.83 %
Epoch 1331 of 2000 took 0.147s
  training loss:		0.009847
  validation loss:		0.434558
  validation accuracy:		92.83 %
Epoch 1332 of 2000 took 0.138s
  training loss:		0.009756
  validation loss:		0.433426
  validation accuracy:		92.93 %
Epoch 1333 of 2000 took 0.153s
  training loss:		0.009411
  validation loss:		0.431287
  validation accuracy:		92.93 %
Epoch 1334 of 2000 took 0.150s
  training loss:		0.009779
  validation loss:		0.438320
  validation accuracy:		92.72 %
Epoch 1335 of 2000 took 0.178s
  training loss:		0.009212
  validation loss:		0.437835
  validation accuracy:		92.93 %
Epoch 1336 of 2000 took 0.140s
  training loss:		0.009668
  validation loss:		0.440574
  validation accuracy:		92.83 %
Epoch 1337 of 2000 took 0.142s
  training loss:		0.009645
  validation loss:		0.434506
  validation accuracy:		92.83 %
Epoch 1338 of 2000 took 0.140s
  training loss:		0.009488
  validation loss:		0.430498
  validation accuracy:		92.83 %
Epoch 1339 of 2000 took 0.162s
  training loss:		0.009843
  validation loss:		0.432063
  validation accuracy:		92.83 %
Epoch 1340 of 2000 took 0.183s
  training loss:		0.009879
  validation loss:		0.426623
  validation accuracy:		92.72 %
Epoch 1341 of 2000 took 0.159s
  training loss:		0.009627
  validation loss:		0.444083
  validation accuracy:		92.83 %
Epoch 1342 of 2000 took 0.157s
  training loss:		0.009593
  validation loss:		0.429153
  validation accuracy:		92.83 %
Epoch 1343 of 2000 took 0.143s
  training loss:		0.009723
  validation loss:		0.434454
  validation accuracy:		92.93 %
Epoch 1344 of 2000 took 0.183s
  training loss:		0.009597
  validation loss:		0.431195
  validation accuracy:		92.93 %
Epoch 1345 of 2000 took 0.155s
  training loss:		0.009385
  validation loss:		0.433740
  validation accuracy:		92.83 %
Epoch 1346 of 2000 took 0.139s
  training loss:		0.009457
  validation loss:		0.431830
  validation accuracy:		92.93 %
Epoch 1347 of 2000 took 0.145s
  training loss:		0.009835
  validation loss:		0.436861
  validation accuracy:		92.83 %
Epoch 1348 of 2000 took 0.187s
  training loss:		0.009543
  validation loss:		0.434562
  validation accuracy:		92.83 %
Epoch 1349 of 2000 took 0.160s
  training loss:		0.009036
  validation loss:		0.434872
  validation accuracy:		92.83 %
Epoch 1350 of 2000 took 0.179s
  training loss:		0.009048
  validation loss:		0.438496
  validation accuracy:		92.83 %
Epoch 1351 of 2000 took 0.180s
  training loss:		0.009279
  validation loss:		0.434829
  validation accuracy:		92.72 %
Epoch 1352 of 2000 took 0.149s
  training loss:		0.009274
  validation loss:		0.440218
  validation accuracy:		92.83 %
Epoch 1353 of 2000 took 0.150s
  training loss:		0.009452
  validation loss:		0.435347
  validation accuracy:		92.83 %
Epoch 1354 of 2000 took 0.138s
  training loss:		0.009263
  validation loss:		0.437558
  validation accuracy:		92.83 %
Epoch 1355 of 2000 took 0.191s
  training loss:		0.008882
  validation loss:		0.432195
  validation accuracy:		92.83 %
Epoch 1356 of 2000 took 0.171s
  training loss:		0.009204
  validation loss:		0.439326
  validation accuracy:		92.61 %
Epoch 1357 of 2000 took 0.186s
  training loss:		0.009131
  validation loss:		0.447002
  validation accuracy:		92.50 %
Epoch 1358 of 2000 took 0.182s
  training loss:		0.009135
  validation loss:		0.434103
  validation accuracy:		92.83 %
Epoch 1359 of 2000 took 0.180s
  training loss:		0.009370
  validation loss:		0.437533
  validation accuracy:		92.83 %
Epoch 1360 of 2000 took 0.164s
  training loss:		0.009119
  validation loss:		0.437909
  validation accuracy:		92.83 %
Epoch 1361 of 2000 took 0.183s
  training loss:		0.009214
  validation loss:		0.449412
  validation accuracy:		92.72 %
Epoch 1362 of 2000 took 0.187s
  training loss:		0.009014
  validation loss:		0.440720
  validation accuracy:		92.83 %
Epoch 1363 of 2000 took 0.182s
  training loss:		0.009307
  validation loss:		0.439394
  validation accuracy:		93.04 %
Epoch 1364 of 2000 took 0.160s
  training loss:		0.009251
  validation loss:		0.441808
  validation accuracy:		92.83 %
Epoch 1365 of 2000 took 0.175s
  training loss:		0.008987
  validation loss:		0.442748
  validation accuracy:		92.83 %
Epoch 1366 of 2000 took 0.182s
  training loss:		0.008973
  validation loss:		0.439782
  validation accuracy:		92.83 %
Epoch 1367 of 2000 took 0.183s
  training loss:		0.009128
  validation loss:		0.440465
  validation accuracy:		92.83 %
Epoch 1368 of 2000 took 0.184s
  training loss:		0.009083
  validation loss:		0.449335
  validation accuracy:		92.83 %
Epoch 1369 of 2000 took 0.173s
  training loss:		0.008797
  validation loss:		0.435144
  validation accuracy:		92.83 %
Epoch 1370 of 2000 took 0.168s
  training loss:		0.008938
  validation loss:		0.451368
  validation accuracy:		92.72 %
Epoch 1371 of 2000 took 0.151s
  training loss:		0.008970
  validation loss:		0.441187
  validation accuracy:		92.83 %
Epoch 1372 of 2000 took 0.161s
  training loss:		0.008724
  validation loss:		0.441565
  validation accuracy:		92.72 %
Epoch 1373 of 2000 took 0.181s
  training loss:		0.008800
  validation loss:		0.432464
  validation accuracy:		92.72 %
Epoch 1374 of 2000 took 0.147s
  training loss:		0.008829
  validation loss:		0.438361
  validation accuracy:		92.83 %
Epoch 1375 of 2000 took 0.138s
  training loss:		0.009137
  validation loss:		0.454752
  validation accuracy:		92.72 %
Epoch 1376 of 2000 took 0.153s
  training loss:		0.008732
  validation loss:		0.441811
  validation accuracy:		92.83 %
Epoch 1377 of 2000 took 0.159s
  training loss:		0.008901
  validation loss:		0.446007
  validation accuracy:		92.83 %
Epoch 1378 of 2000 took 0.132s
  training loss:		0.008796
  validation loss:		0.442722
  validation accuracy:		92.72 %
Epoch 1379 of 2000 took 0.153s
  training loss:		0.008813
  validation loss:		0.443556
  validation accuracy:		92.83 %
Epoch 1380 of 2000 took 0.161s
  training loss:		0.009029
  validation loss:		0.446685
  validation accuracy:		92.83 %
Epoch 1381 of 2000 took 0.183s
  training loss:		0.008687
  validation loss:		0.441337
  validation accuracy:		92.61 %
Epoch 1382 of 2000 took 0.182s
  training loss:		0.008674
  validation loss:		0.444718
  validation accuracy:		92.83 %
Epoch 1383 of 2000 took 0.185s
  training loss:		0.008505
  validation loss:		0.442427
  validation accuracy:		92.61 %
Epoch 1384 of 2000 took 0.157s
  training loss:		0.008840
  validation loss:		0.446699
  validation accuracy:		92.83 %
Epoch 1385 of 2000 took 0.142s
  training loss:		0.008840
  validation loss:		0.441894
  validation accuracy:		92.83 %
Epoch 1386 of 2000 took 0.158s
  training loss:		0.008552
  validation loss:		0.443987
  validation accuracy:		92.72 %
Epoch 1387 of 2000 took 0.138s
  training loss:		0.008687
  validation loss:		0.444144
  validation accuracy:		92.83 %
Epoch 1388 of 2000 took 0.163s
  training loss:		0.008582
  validation loss:		0.448816
  validation accuracy:		92.83 %
Epoch 1389 of 2000 took 0.143s
  training loss:		0.008223
  validation loss:		0.441953
  validation accuracy:		92.83 %
Epoch 1390 of 2000 took 0.154s
  training loss:		0.008630
  validation loss:		0.441629
  validation accuracy:		92.93 %
Epoch 1391 of 2000 took 0.140s
  training loss:		0.008854
  validation loss:		0.443682
  validation accuracy:		92.83 %
Epoch 1392 of 2000 took 0.166s
  training loss:		0.008689
  validation loss:		0.445605
  validation accuracy:		92.83 %
Epoch 1393 of 2000 took 0.179s
  training loss:		0.008680
  validation loss:		0.446937
  validation accuracy:		92.83 %
Epoch 1394 of 2000 took 0.180s
  training loss:		0.008483
  validation loss:		0.447283
  validation accuracy:		92.83 %
Epoch 1395 of 2000 took 0.157s
  training loss:		0.008685
  validation loss:		0.447529
  validation accuracy:		92.83 %
Epoch 1396 of 2000 took 0.179s
  training loss:		0.008474
  validation loss:		0.446038
  validation accuracy:		92.83 %
Epoch 1397 of 2000 took 0.171s
  training loss:		0.008397
  validation loss:		0.460690
  validation accuracy:		92.72 %
Epoch 1398 of 2000 took 0.147s
  training loss:		0.009041
  validation loss:		0.456781
  validation accuracy:		92.61 %
Epoch 1399 of 2000 took 0.154s
  training loss:		0.008474
  validation loss:		0.449146
  validation accuracy:		92.72 %
Epoch 1400 of 2000 took 0.162s
  training loss:		0.008637
  validation loss:		0.440887
  validation accuracy:		92.83 %
Epoch 1401 of 2000 took 0.181s
  training loss:		0.008446
  validation loss:		0.444070
  validation accuracy:		92.93 %
Epoch 1402 of 2000 took 0.145s
  training loss:		0.008490
  validation loss:		0.454441
  validation accuracy:		92.72 %
Epoch 1403 of 2000 took 0.141s
  training loss:		0.008257
  validation loss:		0.448688
  validation accuracy:		92.83 %
Epoch 1404 of 2000 took 0.145s
  training loss:		0.008135
  validation loss:		0.451318
  validation accuracy:		92.93 %
Epoch 1405 of 2000 took 0.147s
  training loss:		0.008447
  validation loss:		0.456422
  validation accuracy:		92.61 %
Epoch 1406 of 2000 took 0.143s
  training loss:		0.008345
  validation loss:		0.444829
  validation accuracy:		92.83 %
Epoch 1407 of 2000 took 0.151s
  training loss:		0.008353
  validation loss:		0.454916
  validation accuracy:		92.83 %
Epoch 1408 of 2000 took 0.143s
  training loss:		0.008370
  validation loss:		0.460641
  validation accuracy:		92.61 %
Epoch 1409 of 2000 took 0.146s
  training loss:		0.008279
  validation loss:		0.442036
  validation accuracy:		92.72 %
Epoch 1410 of 2000 took 0.159s
  training loss:		0.008463
  validation loss:		0.450264
  validation accuracy:		92.83 %
Epoch 1411 of 2000 took 0.155s
  training loss:		0.008156
  validation loss:		0.452832
  validation accuracy:		92.83 %
Epoch 1412 of 2000 took 0.135s
  training loss:		0.008257
  validation loss:		0.449772
  validation accuracy:		92.83 %
Epoch 1413 of 2000 took 0.182s
  training loss:		0.008438
  validation loss:		0.452246
  validation accuracy:		92.72 %
Epoch 1414 of 2000 took 0.178s
  training loss:		0.008177
  validation loss:		0.451288
  validation accuracy:		92.83 %
Epoch 1415 of 2000 took 0.153s
  training loss:		0.008168
  validation loss:		0.446837
  validation accuracy:		92.72 %
Epoch 1416 of 2000 took 0.167s
  training loss:		0.008265
  validation loss:		0.443555
  validation accuracy:		92.83 %
Epoch 1417 of 2000 took 0.152s
  training loss:		0.007880
  validation loss:		0.445499
  validation accuracy:		92.83 %
Epoch 1418 of 2000 took 0.156s
  training loss:		0.008177
  validation loss:		0.452872
  validation accuracy:		92.83 %
Epoch 1419 of 2000 took 0.148s
  training loss:		0.008292
  validation loss:		0.458042
  validation accuracy:		92.93 %
Epoch 1420 of 2000 took 0.156s
  training loss:		0.008321
  validation loss:		0.448134
  validation accuracy:		92.83 %
Epoch 1421 of 2000 took 0.146s
  training loss:		0.008307
  validation loss:		0.459015
  validation accuracy:		92.61 %
Epoch 1422 of 2000 took 0.139s
  training loss:		0.008027
  validation loss:		0.455673
  validation accuracy:		92.72 %
Epoch 1423 of 2000 took 0.178s
  training loss:		0.007957
  validation loss:		0.450900
  validation accuracy:		92.83 %
Epoch 1424 of 2000 took 0.162s
  training loss:		0.008289
  validation loss:		0.446029
  validation accuracy:		92.83 %
Epoch 1425 of 2000 took 0.161s
  training loss:		0.008633
  validation loss:		0.447944
  validation accuracy:		92.93 %
Epoch 1426 of 2000 took 0.194s
  training loss:		0.008040
  validation loss:		0.456720
  validation accuracy:		92.93 %
Epoch 1427 of 2000 took 0.165s
  training loss:		0.008216
  validation loss:		0.460856
  validation accuracy:		92.50 %
Epoch 1428 of 2000 took 0.154s
  training loss:		0.008121
  validation loss:		0.449601
  validation accuracy:		92.72 %
Epoch 1429 of 2000 took 0.184s
  training loss:		0.007992
  validation loss:		0.459563
  validation accuracy:		92.72 %
Epoch 1430 of 2000 took 0.181s
  training loss:		0.008131
  validation loss:		0.464111
  validation accuracy:		92.50 %
Epoch 1431 of 2000 took 0.183s
  training loss:		0.008338
  validation loss:		0.458624
  validation accuracy:		92.72 %
Epoch 1432 of 2000 took 0.182s
  training loss:		0.007792
  validation loss:		0.455832
  validation accuracy:		92.83 %
Epoch 1433 of 2000 took 0.169s
  training loss:		0.008007
  validation loss:		0.454083
  validation accuracy:		92.72 %
Epoch 1434 of 2000 took 0.131s
  training loss:		0.008160
  validation loss:		0.453111
  validation accuracy:		92.72 %
Epoch 1435 of 2000 took 0.148s
  training loss:		0.007775
  validation loss:		0.458980
  validation accuracy:		92.72 %
Epoch 1436 of 2000 took 0.141s
  training loss:		0.008111
  validation loss:		0.455397
  validation accuracy:		92.83 %
Epoch 1437 of 2000 took 0.147s
  training loss:		0.007729
  validation loss:		0.456539
  validation accuracy:		92.61 %
Epoch 1438 of 2000 took 0.160s
  training loss:		0.007721
  validation loss:		0.452903
  validation accuracy:		92.83 %
Epoch 1439 of 2000 took 0.164s
  training loss:		0.007859
  validation loss:		0.453504
  validation accuracy:		92.83 %
Epoch 1440 of 2000 took 0.149s
  training loss:		0.007858
  validation loss:		0.453725
  validation accuracy:		92.83 %
Epoch 1441 of 2000 took 0.138s
  training loss:		0.007772
  validation loss:		0.449301
  validation accuracy:		92.83 %
Epoch 1442 of 2000 took 0.135s
  training loss:		0.007766
  validation loss:		0.451166
  validation accuracy:		92.83 %
Epoch 1443 of 2000 took 0.145s
  training loss:		0.007628
  validation loss:		0.461889
  validation accuracy:		92.83 %
Epoch 1444 of 2000 took 0.173s
  training loss:		0.007656
  validation loss:		0.458803
  validation accuracy:		92.72 %
Epoch 1445 of 2000 took 0.174s
  training loss:		0.007797
  validation loss:		0.458581
  validation accuracy:		92.72 %
Epoch 1446 of 2000 took 0.135s
  training loss:		0.007765
  validation loss:		0.462102
  validation accuracy:		92.93 %
Epoch 1447 of 2000 took 0.180s
  training loss:		0.007985
  validation loss:		0.455014
  validation accuracy:		92.72 %
Epoch 1448 of 2000 took 0.153s
  training loss:		0.007621
  validation loss:		0.462235
  validation accuracy:		92.83 %
Epoch 1449 of 2000 took 0.190s
  training loss:		0.007709
  validation loss:		0.459215
  validation accuracy:		92.83 %
Epoch 1450 of 2000 took 0.181s
  training loss:		0.007819
  validation loss:		0.463998
  validation accuracy:		92.83 %
Epoch 1451 of 2000 took 0.154s
  training loss:		0.008099
  validation loss:		0.460658
  validation accuracy:		92.72 %
Epoch 1452 of 2000 took 0.158s
  training loss:		0.007570
  validation loss:		0.463101
  validation accuracy:		92.83 %
Epoch 1453 of 2000 took 0.145s
  training loss:		0.007850
  validation loss:		0.456315
  validation accuracy:		92.83 %
Epoch 1454 of 2000 took 0.162s
  training loss:		0.007765
  validation loss:		0.463549
  validation accuracy:		92.72 %
Epoch 1455 of 2000 took 0.148s
  training loss:		0.007705
  validation loss:		0.459128
  validation accuracy:		92.83 %
Epoch 1456 of 2000 took 0.144s
  training loss:		0.007479
  validation loss:		0.459196
  validation accuracy:		93.04 %
Epoch 1457 of 2000 took 0.145s
  training loss:		0.007686
  validation loss:		0.463964
  validation accuracy:		92.93 %
Epoch 1458 of 2000 took 0.150s
  training loss:		0.007751
  validation loss:		0.465906
  validation accuracy:		92.61 %
Epoch 1459 of 2000 took 0.143s
  training loss:		0.007232
  validation loss:		0.459596
  validation accuracy:		92.72 %
Epoch 1460 of 2000 took 0.153s
  training loss:		0.007473
  validation loss:		0.460905
  validation accuracy:		92.83 %
Epoch 1461 of 2000 took 0.144s
  training loss:		0.007504
  validation loss:		0.463501
  validation accuracy:		92.72 %
Epoch 1462 of 2000 took 0.139s
  training loss:		0.007357
  validation loss:		0.467586
  validation accuracy:		92.93 %
Epoch 1463 of 2000 took 0.147s
  training loss:		0.007308
  validation loss:		0.457452
  validation accuracy:		92.72 %
Epoch 1464 of 2000 took 0.158s
  training loss:		0.007307
  validation loss:		0.462036
  validation accuracy:		92.72 %
Epoch 1465 of 2000 took 0.156s
  training loss:		0.007636
  validation loss:		0.467773
  validation accuracy:		92.83 %
Epoch 1466 of 2000 took 0.188s
  training loss:		0.007430
  validation loss:		0.460139
  validation accuracy:		92.72 %
Epoch 1467 of 2000 took 0.189s
  training loss:		0.007618
  validation loss:		0.462232
  validation accuracy:		92.83 %
Epoch 1468 of 2000 took 0.177s
  training loss:		0.007543
  validation loss:		0.463977
  validation accuracy:		92.72 %
Epoch 1469 of 2000 took 0.175s
  training loss:		0.007469
  validation loss:		0.459788
  validation accuracy:		92.72 %
Epoch 1470 of 2000 took 0.170s
  training loss:		0.007372
  validation loss:		0.464361
  validation accuracy:		92.72 %
Epoch 1471 of 2000 took 0.145s
  training loss:		0.007382
  validation loss:		0.456751
  validation accuracy:		92.72 %
Epoch 1472 of 2000 took 0.148s
  training loss:		0.007363
  validation loss:		0.470373
  validation accuracy:		92.72 %
Epoch 1473 of 2000 took 0.148s
  training loss:		0.007371
  validation loss:		0.463417
  validation accuracy:		92.83 %
Epoch 1474 of 2000 took 0.149s
  training loss:		0.007465
  validation loss:		0.460627
  validation accuracy:		92.72 %
Epoch 1475 of 2000 took 0.152s
  training loss:		0.007255
  validation loss:		0.469435
  validation accuracy:		92.72 %
Epoch 1476 of 2000 took 0.150s
  training loss:		0.007330
  validation loss:		0.461370
  validation accuracy:		92.83 %
Epoch 1477 of 2000 took 0.141s
  training loss:		0.007085
  validation loss:		0.466872
  validation accuracy:		92.93 %
Epoch 1478 of 2000 took 0.141s
  training loss:		0.007351
  validation loss:		0.467745
  validation accuracy:		92.83 %
Epoch 1479 of 2000 took 0.152s
  training loss:		0.007487
  validation loss:		0.462895
  validation accuracy:		92.83 %
Epoch 1480 of 2000 took 0.132s
  training loss:		0.007162
  validation loss:		0.460782
  validation accuracy:		92.72 %
Epoch 1481 of 2000 took 0.147s
  training loss:		0.007462
  validation loss:		0.460179
  validation accuracy:		92.83 %
Epoch 1482 of 2000 took 0.145s
  training loss:		0.007097
  validation loss:		0.462493
  validation accuracy:		92.83 %
Epoch 1483 of 2000 took 0.143s
  training loss:		0.007483
  validation loss:		0.471178
  validation accuracy:		92.83 %
Epoch 1484 of 2000 took 0.145s
  training loss:		0.007046
  validation loss:		0.467628
  validation accuracy:		92.72 %
Epoch 1485 of 2000 took 0.183s
  training loss:		0.007389
  validation loss:		0.468716
  validation accuracy:		92.72 %
Epoch 1486 of 2000 took 0.183s
  training loss:		0.006858
  validation loss:		0.463735
  validation accuracy:		92.72 %
Epoch 1487 of 2000 took 0.183s
  training loss:		0.007372
  validation loss:		0.470631
  validation accuracy:		92.83 %
Epoch 1488 of 2000 took 0.156s
  training loss:		0.006963
  validation loss:		0.457960
  validation accuracy:		92.93 %
Epoch 1489 of 2000 took 0.149s
  training loss:		0.007265
  validation loss:		0.469876
  validation accuracy:		92.83 %
Epoch 1490 of 2000 took 0.161s
  training loss:		0.007161
  validation loss:		0.469498
  validation accuracy:		92.83 %
Epoch 1491 of 2000 took 0.185s
  training loss:		0.007265
  validation loss:		0.466824
  validation accuracy:		92.61 %
Epoch 1492 of 2000 took 0.169s
  training loss:		0.006851
  validation loss:		0.466743
  validation accuracy:		92.83 %
Epoch 1493 of 2000 took 0.139s
  training loss:		0.006887
  validation loss:		0.469729
  validation accuracy:		92.93 %
Epoch 1494 of 2000 took 0.148s
  training loss:		0.007090
  validation loss:		0.471044
  validation accuracy:		92.72 %
Epoch 1495 of 2000 took 0.141s
  training loss:		0.007466
  validation loss:		0.472192
  validation accuracy:		92.72 %
Epoch 1496 of 2000 took 0.143s
  training loss:		0.007130
  validation loss:		0.478178
  validation accuracy:		92.50 %
Epoch 1497 of 2000 took 0.145s
  training loss:		0.007080
  validation loss:		0.468806
  validation accuracy:		92.72 %
Epoch 1498 of 2000 took 0.184s
  training loss:		0.006823
  validation loss:		0.472207
  validation accuracy:		92.83 %
Epoch 1499 of 2000 took 0.172s
  training loss:		0.007182
  validation loss:		0.474097
  validation accuracy:		92.61 %
Epoch 1500 of 2000 took 0.183s
  training loss:		0.006923
  validation loss:		0.466228
  validation accuracy:		92.61 %
Epoch 1501 of 2000 took 0.155s
  training loss:		0.007236
  validation loss:		0.466455
  validation accuracy:		92.72 %
Epoch 1502 of 2000 took 0.130s
  training loss:		0.007283
  validation loss:		0.466240
  validation accuracy:		92.72 %
Epoch 1503 of 2000 took 0.143s
  training loss:		0.007159
  validation loss:		0.466322
  validation accuracy:		92.61 %
Epoch 1504 of 2000 took 0.143s
  training loss:		0.007015
  validation loss:		0.467053
  validation accuracy:		92.72 %
Epoch 1505 of 2000 took 0.140s
  training loss:		0.007184
  validation loss:		0.474715
  validation accuracy:		92.72 %
Epoch 1506 of 2000 took 0.190s
  training loss:		0.006783
  validation loss:		0.463981
  validation accuracy:		92.72 %
Epoch 1507 of 2000 took 0.150s
  training loss:		0.007138
  validation loss:		0.469277
  validation accuracy:		92.61 %
Epoch 1508 of 2000 took 0.183s
  training loss:		0.007021
  validation loss:		0.468862
  validation accuracy:		92.72 %
Epoch 1509 of 2000 took 0.161s
  training loss:		0.006909
  validation loss:		0.469740
  validation accuracy:		92.83 %
Epoch 1510 of 2000 took 0.155s
  training loss:		0.007155
  validation loss:		0.467653
  validation accuracy:		92.93 %
Epoch 1511 of 2000 took 0.139s
  training loss:		0.006888
  validation loss:		0.478680
  validation accuracy:		92.72 %
Epoch 1512 of 2000 took 0.144s
  training loss:		0.006800
  validation loss:		0.468064
  validation accuracy:		92.72 %
Epoch 1513 of 2000 took 0.140s
  training loss:		0.007056
  validation loss:		0.467196
  validation accuracy:		92.93 %
Epoch 1514 of 2000 took 0.149s
  training loss:		0.007036
  validation loss:		0.475121
  validation accuracy:		92.83 %
Epoch 1515 of 2000 took 0.143s
  training loss:		0.006894
  validation loss:		0.474409
  validation accuracy:		92.72 %
Epoch 1516 of 2000 took 0.157s
  training loss:		0.006770
  validation loss:		0.468721
  validation accuracy:		92.61 %
Epoch 1517 of 2000 took 0.173s
  training loss:		0.006711
  validation loss:		0.472874
  validation accuracy:		92.83 %
Epoch 1518 of 2000 took 0.163s
  training loss:		0.007127
  validation loss:		0.471941
  validation accuracy:		92.61 %
Epoch 1519 of 2000 took 0.191s
  training loss:		0.006937
  validation loss:		0.475775
  validation accuracy:		92.83 %
Epoch 1520 of 2000 took 0.179s
  training loss:		0.006857
  validation loss:		0.464521
  validation accuracy:		92.83 %
Epoch 1521 of 2000 took 0.147s
  training loss:		0.006920
  validation loss:		0.478174
  validation accuracy:		92.72 %
Epoch 1522 of 2000 took 0.141s
  training loss:		0.006889
  validation loss:		0.471016
  validation accuracy:		92.83 %
Epoch 1523 of 2000 took 0.146s
  training loss:		0.006919
  validation loss:		0.476325
  validation accuracy:		92.72 %
Epoch 1524 of 2000 took 0.142s
  training loss:		0.007014
  validation loss:		0.471606
  validation accuracy:		92.72 %
Epoch 1525 of 2000 took 0.179s
  training loss:		0.006851
  validation loss:		0.477381
  validation accuracy:		92.83 %
Epoch 1526 of 2000 took 0.177s
  training loss:		0.006527
  validation loss:		0.468734
  validation accuracy:		92.83 %
Epoch 1527 of 2000 took 0.158s
  training loss:		0.006894
  validation loss:		0.482065
  validation accuracy:		92.72 %
Epoch 1528 of 2000 took 0.158s
  training loss:		0.006804
  validation loss:		0.472664
  validation accuracy:		92.83 %
Epoch 1529 of 2000 took 0.179s
  training loss:		0.006932
  validation loss:		0.475286
  validation accuracy:		92.83 %
Epoch 1530 of 2000 took 0.183s
  training loss:		0.006735
  validation loss:		0.470971
  validation accuracy:		92.83 %
Epoch 1531 of 2000 took 0.176s
  training loss:		0.006760
  validation loss:		0.475354
  validation accuracy:		92.72 %
Epoch 1532 of 2000 took 0.158s
  training loss:		0.006908
  validation loss:		0.471950
  validation accuracy:		92.72 %
Epoch 1533 of 2000 took 0.162s
  training loss:		0.006542
  validation loss:		0.479525
  validation accuracy:		92.72 %
Epoch 1534 of 2000 took 0.180s
  training loss:		0.006662
  validation loss:		0.474177
  validation accuracy:		92.93 %
Epoch 1535 of 2000 took 0.184s
  training loss:		0.006557
  validation loss:		0.476428
  validation accuracy:		92.83 %
Epoch 1536 of 2000 took 0.156s
  training loss:		0.006647
  validation loss:		0.475204
  validation accuracy:		92.72 %
Epoch 1537 of 2000 took 0.146s
  training loss:		0.006522
  validation loss:		0.474296
  validation accuracy:		92.83 %
Epoch 1538 of 2000 took 0.165s
  training loss:		0.006618
  validation loss:		0.482083
  validation accuracy:		92.61 %
Epoch 1539 of 2000 took 0.155s
  training loss:		0.006405
  validation loss:		0.473381
  validation accuracy:		92.83 %
Epoch 1540 of 2000 took 0.152s
  training loss:		0.006588
  validation loss:		0.488914
  validation accuracy:		92.50 %
Epoch 1541 of 2000 took 0.162s
  training loss:		0.006730
  validation loss:		0.483723
  validation accuracy:		92.72 %
Epoch 1542 of 2000 took 0.157s
  training loss:		0.006740
  validation loss:		0.476192
  validation accuracy:		92.83 %
Epoch 1543 of 2000 took 0.130s
  training loss:		0.006697
  validation loss:		0.485012
  validation accuracy:		92.61 %
Epoch 1544 of 2000 took 0.163s
  training loss:		0.006630
  validation loss:		0.479971
  validation accuracy:		92.72 %
Epoch 1545 of 2000 took 0.181s
  training loss:		0.006613
  validation loss:		0.476588
  validation accuracy:		92.83 %
Epoch 1546 of 2000 took 0.181s
  training loss:		0.006613
  validation loss:		0.483882
  validation accuracy:		92.72 %
Epoch 1547 of 2000 took 0.169s
  training loss:		0.006613
  validation loss:		0.482382
  validation accuracy:		92.61 %
Epoch 1548 of 2000 took 0.149s
  training loss:		0.006485
  validation loss:		0.468434
  validation accuracy:		92.72 %
Epoch 1549 of 2000 took 0.142s
  training loss:		0.006501
  validation loss:		0.479015
  validation accuracy:		92.72 %
Epoch 1550 of 2000 took 0.140s
  training loss:		0.006665
  validation loss:		0.481600
  validation accuracy:		92.83 %
Epoch 1551 of 2000 took 0.140s
  training loss:		0.006536
  validation loss:		0.479106
  validation accuracy:		92.72 %
Epoch 1552 of 2000 took 0.153s
  training loss:		0.006416
  validation loss:		0.481321
  validation accuracy:		92.83 %
Epoch 1553 of 2000 took 0.162s
  training loss:		0.006361
  validation loss:		0.481621
  validation accuracy:		92.83 %
Epoch 1554 of 2000 took 0.139s
  training loss:		0.006357
  validation loss:		0.483608
  validation accuracy:		92.50 %
Epoch 1555 of 2000 took 0.140s
  training loss:		0.006548
  validation loss:		0.487819
  validation accuracy:		92.50 %
Epoch 1556 of 2000 took 0.157s
  training loss:		0.006383
  validation loss:		0.473774
  validation accuracy:		92.72 %
Epoch 1557 of 2000 took 0.161s
  training loss:		0.006309
  validation loss:		0.483839
  validation accuracy:		92.83 %
Epoch 1558 of 2000 took 0.176s
  training loss:		0.006458
  validation loss:		0.474236
  validation accuracy:		92.93 %
Epoch 1559 of 2000 took 0.180s
  training loss:		0.006221
  validation loss:		0.487172
  validation accuracy:		92.61 %
Epoch 1560 of 2000 took 0.175s
  training loss:		0.006334
  validation loss:		0.472914
  validation accuracy:		92.83 %
Epoch 1561 of 2000 took 0.151s
  training loss:		0.006432
  validation loss:		0.479835
  validation accuracy:		92.72 %
Epoch 1562 of 2000 took 0.156s
  training loss:		0.006405
  validation loss:		0.477034
  validation accuracy:		92.72 %
Epoch 1563 of 2000 took 0.175s
  training loss:		0.006372
  validation loss:		0.482602
  validation accuracy:		92.61 %
Epoch 1564 of 2000 took 0.145s
  training loss:		0.006690
  validation loss:		0.475563
  validation accuracy:		92.83 %
Epoch 1565 of 2000 took 0.148s
  training loss:		0.006609
  validation loss:		0.483412
  validation accuracy:		92.72 %
Epoch 1566 of 2000 took 0.187s
  training loss:		0.006364
  validation loss:		0.480698
  validation accuracy:		92.83 %
Epoch 1567 of 2000 took 0.175s
  training loss:		0.006138
  validation loss:		0.486751
  validation accuracy:		92.61 %
Epoch 1568 of 2000 took 0.182s
  training loss:		0.006528
  validation loss:		0.488935
  validation accuracy:		92.61 %
Epoch 1569 of 2000 took 0.183s
  training loss:		0.006348
  validation loss:		0.480549
  validation accuracy:		92.72 %
Epoch 1570 of 2000 took 0.181s
  training loss:		0.006323
  validation loss:		0.484660
  validation accuracy:		92.83 %
Epoch 1571 of 2000 took 0.168s
  training loss:		0.006491
  validation loss:		0.479671
  validation accuracy:		92.72 %
Epoch 1572 of 2000 took 0.156s
  training loss:		0.006414
  validation loss:		0.489198
  validation accuracy:		92.61 %
Epoch 1573 of 2000 took 0.174s
  training loss:		0.006429
  validation loss:		0.486985
  validation accuracy:		92.83 %
Epoch 1574 of 2000 took 0.173s
  training loss:		0.006340
  validation loss:		0.485565
  validation accuracy:		92.72 %
Epoch 1575 of 2000 took 0.136s
  training loss:		0.006266
  validation loss:		0.486240
  validation accuracy:		92.61 %
Epoch 1576 of 2000 took 0.141s
  training loss:		0.006357
  validation loss:		0.481917
  validation accuracy:		92.83 %
Epoch 1577 of 2000 took 0.150s
  training loss:		0.006324
  validation loss:		0.484984
  validation accuracy:		92.72 %
Epoch 1578 of 2000 took 0.130s
  training loss:		0.006290
  validation loss:		0.486824
  validation accuracy:		92.61 %
Epoch 1579 of 2000 took 0.150s
  training loss:		0.006282
  validation loss:		0.489881
  validation accuracy:		92.39 %
Epoch 1580 of 2000 took 0.147s
  training loss:		0.006080
  validation loss:		0.484174
  validation accuracy:		92.61 %
Epoch 1581 of 2000 took 0.142s
  training loss:		0.006269
  validation loss:		0.484065
  validation accuracy:		92.50 %
Epoch 1582 of 2000 took 0.144s
  training loss:		0.006314
  validation loss:		0.481500
  validation accuracy:		92.93 %
Epoch 1583 of 2000 took 0.155s
  training loss:		0.006071
  validation loss:		0.493674
  validation accuracy:		92.61 %
Epoch 1584 of 2000 took 0.133s
  training loss:		0.006178
  validation loss:		0.478082
  validation accuracy:		92.83 %
Epoch 1585 of 2000 took 0.173s
  training loss:		0.006377
  validation loss:		0.487949
  validation accuracy:		92.72 %
Epoch 1586 of 2000 took 0.178s
  training loss:		0.006173
  validation loss:		0.480879
  validation accuracy:		92.72 %
Epoch 1587 of 2000 took 0.162s
  training loss:		0.006119
  validation loss:		0.488509
  validation accuracy:		92.83 %
Epoch 1588 of 2000 took 0.137s
  training loss:		0.006070
  validation loss:		0.484887
  validation accuracy:		92.83 %
Epoch 1589 of 2000 took 0.163s
  training loss:		0.006308
  validation loss:		0.487560
  validation accuracy:		92.83 %
Epoch 1590 of 2000 took 0.158s
  training loss:		0.006182
  validation loss:		0.481094
  validation accuracy:		92.83 %
Epoch 1591 of 2000 took 0.148s
  training loss:		0.006053
  validation loss:		0.487724
  validation accuracy:		92.83 %
Epoch 1592 of 2000 took 0.148s
  training loss:		0.006151
  validation loss:		0.487231
  validation accuracy:		92.83 %
Epoch 1593 of 2000 took 0.182s
  training loss:		0.006170
  validation loss:		0.483768
  validation accuracy:		92.93 %
Epoch 1594 of 2000 took 0.146s
  training loss:		0.006151
  validation loss:		0.487466
  validation accuracy:		92.61 %
Epoch 1595 of 2000 took 0.152s
  training loss:		0.006175
  validation loss:		0.486588
  validation accuracy:		92.93 %
Epoch 1596 of 2000 took 0.181s
  training loss:		0.006192
  validation loss:		0.486514
  validation accuracy:		92.72 %
Epoch 1597 of 2000 took 0.174s
  training loss:		0.006207
  validation loss:		0.487923
  validation accuracy:		92.72 %
Epoch 1598 of 2000 took 0.159s
  training loss:		0.006074
  validation loss:		0.495097
  validation accuracy:		92.72 %
Epoch 1599 of 2000 took 0.172s
  training loss:		0.006182
  validation loss:		0.491527
  validation accuracy:		92.72 %
Epoch 1600 of 2000 took 0.180s
  training loss:		0.005902
  validation loss:		0.491134
  validation accuracy:		92.50 %
Epoch 1601 of 2000 took 0.187s
  training loss:		0.005991
  validation loss:		0.487256
  validation accuracy:		92.83 %
Epoch 1602 of 2000 took 0.150s
  training loss:		0.005957
  validation loss:		0.490523
  validation accuracy:		92.72 %
Epoch 1603 of 2000 took 0.165s
  training loss:		0.006148
  validation loss:		0.493382
  validation accuracy:		92.72 %
Epoch 1604 of 2000 took 0.192s
  training loss:		0.005999
  validation loss:		0.492167
  validation accuracy:		92.61 %
Epoch 1605 of 2000 took 0.183s
  training loss:		0.006236
  validation loss:		0.491417
  validation accuracy:		92.83 %
Epoch 1606 of 2000 took 0.185s
  training loss:		0.005936
  validation loss:		0.490166
  validation accuracy:		92.72 %
Epoch 1607 of 2000 took 0.142s
  training loss:		0.005852
  validation loss:		0.483525
  validation accuracy:		92.83 %
Epoch 1608 of 2000 took 0.152s
  training loss:		0.006016
  validation loss:		0.491647
  validation accuracy:		92.83 %
Epoch 1609 of 2000 took 0.138s
  training loss:		0.005850
  validation loss:		0.489943
  validation accuracy:		92.83 %
Epoch 1610 of 2000 took 0.182s
  training loss:		0.006014
  validation loss:		0.490990
  validation accuracy:		92.93 %
Epoch 1611 of 2000 took 0.182s
  training loss:		0.005802
  validation loss:		0.490353
  validation accuracy:		92.61 %
Epoch 1612 of 2000 took 0.184s
  training loss:		0.006010
  validation loss:		0.495125
  validation accuracy:		92.72 %
Epoch 1613 of 2000 took 0.183s
  training loss:		0.005905
  validation loss:		0.486214
  validation accuracy:		92.72 %
Epoch 1614 of 2000 took 0.162s
  training loss:		0.006038
  validation loss:		0.492358
  validation accuracy:		92.50 %
Epoch 1615 of 2000 took 0.177s
  training loss:		0.005986
  validation loss:		0.488902
  validation accuracy:		92.72 %
Epoch 1616 of 2000 took 0.173s
  training loss:		0.005889
  validation loss:		0.490117
  validation accuracy:		92.83 %
Epoch 1617 of 2000 took 0.137s
  training loss:		0.006050
  validation loss:		0.485338
  validation accuracy:		92.93 %
Epoch 1618 of 2000 took 0.171s
  training loss:		0.006103
  validation loss:		0.482674
  validation accuracy:		92.93 %
Epoch 1619 of 2000 took 0.176s
  training loss:		0.005994
  validation loss:		0.499849
  validation accuracy:		92.50 %
Epoch 1620 of 2000 took 0.167s
  training loss:		0.005734
  validation loss:		0.493201
  validation accuracy:		92.83 %
Epoch 1621 of 2000 took 0.152s
  training loss:		0.005796
  validation loss:		0.489704
  validation accuracy:		92.72 %
Epoch 1622 of 2000 took 0.143s
  training loss:		0.005701
  validation loss:		0.490243
  validation accuracy:		92.72 %
Epoch 1623 of 2000 took 0.159s
  training loss:		0.005955
  validation loss:		0.497376
  validation accuracy:		92.50 %
Epoch 1624 of 2000 took 0.179s
  training loss:		0.005858
  validation loss:		0.493256
  validation accuracy:		92.72 %
Epoch 1625 of 2000 took 0.174s
  training loss:		0.006009
  validation loss:		0.492449
  validation accuracy:		92.72 %
Epoch 1626 of 2000 took 0.163s
  training loss:		0.005865
  validation loss:		0.494224
  validation accuracy:		92.83 %
Epoch 1627 of 2000 took 0.163s
  training loss:		0.005954
  validation loss:		0.490098
  validation accuracy:		92.72 %
Epoch 1628 of 2000 took 0.151s
  training loss:		0.005692
  validation loss:		0.494890
  validation accuracy:		92.72 %
Epoch 1629 of 2000 took 0.187s
  training loss:		0.005950
  validation loss:		0.495426
  validation accuracy:		92.72 %
Epoch 1630 of 2000 took 0.139s
  training loss:		0.005677
  validation loss:		0.490969
  validation accuracy:		92.83 %
Epoch 1631 of 2000 took 0.147s
  training loss:		0.005845
  validation loss:		0.491409
  validation accuracy:		92.83 %
Epoch 1632 of 2000 took 0.174s
  training loss:		0.005918
  validation loss:		0.495931
  validation accuracy:		92.61 %
Epoch 1633 of 2000 took 0.184s
  training loss:		0.005803
  validation loss:		0.495447
  validation accuracy:		92.83 %
Epoch 1634 of 2000 took 0.160s
  training loss:		0.005471
  validation loss:		0.498284
  validation accuracy:		92.61 %
Epoch 1635 of 2000 took 0.165s
  training loss:		0.005499
  validation loss:		0.496326
  validation accuracy:		92.72 %
Epoch 1636 of 2000 took 0.141s
  training loss:		0.005804
  validation loss:		0.497370
  validation accuracy:		92.72 %
Epoch 1637 of 2000 took 0.154s
  training loss:		0.005760
  validation loss:		0.487754
  validation accuracy:		92.72 %
Epoch 1638 of 2000 took 0.135s
  training loss:		0.005687
  validation loss:		0.496868
  validation accuracy:		92.72 %
Epoch 1639 of 2000 took 0.135s
  training loss:		0.005880
  validation loss:		0.503442
  validation accuracy:		92.39 %
Epoch 1640 of 2000 took 0.145s
  training loss:		0.005921
  validation loss:		0.499491
  validation accuracy:		92.50 %
Epoch 1641 of 2000 took 0.147s
  training loss:		0.005432
  validation loss:		0.490728
  validation accuracy:		92.83 %
Epoch 1642 of 2000 took 0.139s
  training loss:		0.005603
  validation loss:		0.496079
  validation accuracy:		92.83 %
Epoch 1643 of 2000 took 0.148s
  training loss:		0.005844
  validation loss:		0.502997
  validation accuracy:		92.39 %
Epoch 1644 of 2000 took 0.146s
  training loss:		0.005657
  validation loss:		0.494563
  validation accuracy:		92.72 %
Epoch 1645 of 2000 took 0.147s
  training loss:		0.005788
  validation loss:		0.498009
  validation accuracy:		92.72 %
Epoch 1646 of 2000 took 0.160s
  training loss:		0.005756
  validation loss:		0.503931
  validation accuracy:		92.83 %
Epoch 1647 of 2000 took 0.146s
  training loss:		0.005524
  validation loss:		0.498568
  validation accuracy:		92.83 %
Epoch 1648 of 2000 took 0.149s
  training loss:		0.005513
  validation loss:		0.493943
  validation accuracy:		92.72 %
Epoch 1649 of 2000 took 0.144s
  training loss:		0.005608
  validation loss:		0.499863
  validation accuracy:		92.50 %
Epoch 1650 of 2000 took 0.150s
  training loss:		0.005584
  validation loss:		0.490219
  validation accuracy:		92.83 %
Epoch 1651 of 2000 took 0.177s
  training loss:		0.005402
  validation loss:		0.501228
  validation accuracy:		92.61 %
Epoch 1652 of 2000 took 0.180s
  training loss:		0.005562
  validation loss:		0.493756
  validation accuracy:		92.83 %
Epoch 1653 of 2000 took 0.142s
  training loss:		0.005526
  validation loss:		0.498569
  validation accuracy:		92.72 %
Epoch 1654 of 2000 took 0.152s
  training loss:		0.005714
  validation loss:		0.501159
  validation accuracy:		92.61 %
Epoch 1655 of 2000 took 0.180s
  training loss:		0.005568
  validation loss:		0.499093
  validation accuracy:		92.72 %
Epoch 1656 of 2000 took 0.156s
  training loss:		0.005585
  validation loss:		0.496318
  validation accuracy:		92.72 %
Epoch 1657 of 2000 took 0.150s
  training loss:		0.005673
  validation loss:		0.502872
  validation accuracy:		92.83 %
Epoch 1658 of 2000 took 0.150s
  training loss:		0.005653
  validation loss:		0.501988
  validation accuracy:		92.61 %
Epoch 1659 of 2000 took 0.160s
  training loss:		0.005365
  validation loss:		0.495759
  validation accuracy:		92.83 %
Epoch 1660 of 2000 took 0.181s
  training loss:		0.005466
  validation loss:		0.503724
  validation accuracy:		92.50 %
Epoch 1661 of 2000 took 0.181s
  training loss:		0.005595
  validation loss:		0.497965
  validation accuracy:		92.72 %
Epoch 1662 of 2000 took 0.157s
  training loss:		0.005636
  validation loss:		0.499661
  validation accuracy:		92.83 %
Epoch 1663 of 2000 took 0.159s
  training loss:		0.005722
  validation loss:		0.503844
  validation accuracy:		92.50 %
Epoch 1664 of 2000 took 0.180s
  training loss:		0.005461
  validation loss:		0.500655
  validation accuracy:		92.61 %
Epoch 1665 of 2000 took 0.142s
  training loss:		0.005479
  validation loss:		0.496393
  validation accuracy:		92.83 %
Epoch 1666 of 2000 took 0.162s
  training loss:		0.005549
  validation loss:		0.500544
  validation accuracy:		92.61 %
Epoch 1667 of 2000 took 0.168s
  training loss:		0.005455
  validation loss:		0.503526
  validation accuracy:		92.72 %
Epoch 1668 of 2000 took 0.156s
  training loss:		0.005476
  validation loss:		0.503518
  validation accuracy:		92.61 %
Epoch 1669 of 2000 took 0.138s
  training loss:		0.005460
  validation loss:		0.497530
  validation accuracy:		92.72 %
Epoch 1670 of 2000 took 0.136s
  training loss:		0.005602
  validation loss:		0.500333
  validation accuracy:		92.83 %
Epoch 1671 of 2000 took 0.171s
  training loss:		0.005509
  validation loss:		0.506026
  validation accuracy:		92.61 %
Epoch 1672 of 2000 took 0.168s
  training loss:		0.005360
  validation loss:		0.498870
  validation accuracy:		92.83 %
Epoch 1673 of 2000 took 0.172s
  training loss:		0.005524
  validation loss:		0.503633
  validation accuracy:		92.61 %
Epoch 1674 of 2000 took 0.183s
  training loss:		0.005184
  validation loss:		0.505602
  validation accuracy:		92.72 %
Epoch 1675 of 2000 took 0.183s
  training loss:		0.005238
  validation loss:		0.507607
  validation accuracy:		92.83 %
Epoch 1676 of 2000 took 0.182s
  training loss:		0.005465
  validation loss:		0.504167
  validation accuracy:		92.83 %
Epoch 1677 of 2000 took 0.183s
  training loss:		0.005334
  validation loss:		0.502541
  validation accuracy:		92.83 %
Epoch 1678 of 2000 took 0.148s
  training loss:		0.005217
  validation loss:		0.512139
  validation accuracy:		92.61 %
Epoch 1679 of 2000 took 0.155s
  training loss:		0.005458
  validation loss:		0.506515
  validation accuracy:		92.72 %
Epoch 1680 of 2000 took 0.143s
  training loss:		0.005485
  validation loss:		0.502175
  validation accuracy:		92.83 %
Epoch 1681 of 2000 took 0.148s
  training loss:		0.004919
  validation loss:		0.502281
  validation accuracy:		92.72 %
Epoch 1682 of 2000 took 0.152s
  training loss:		0.005372
  validation loss:		0.511149
  validation accuracy:		92.61 %
Epoch 1683 of 2000 took 0.151s
  training loss:		0.005330
  validation loss:		0.503152
  validation accuracy:		92.83 %
Epoch 1684 of 2000 took 0.139s
  training loss:		0.005178
  validation loss:		0.502999
  validation accuracy:		92.83 %
Epoch 1685 of 2000 took 0.148s
  training loss:		0.005463
  validation loss:		0.509277
  validation accuracy:		92.72 %
Epoch 1686 of 2000 took 0.141s
  training loss:		0.005385
  validation loss:		0.510997
  validation accuracy:		92.50 %
Epoch 1687 of 2000 took 0.147s
  training loss:		0.005151
  validation loss:		0.503765
  validation accuracy:		92.83 %
Epoch 1688 of 2000 took 0.149s
  training loss:		0.005275
  validation loss:		0.502504
  validation accuracy:		92.83 %
Epoch 1689 of 2000 took 0.146s
  training loss:		0.005244
  validation loss:		0.505646
  validation accuracy:		92.61 %
Epoch 1690 of 2000 took 0.142s
  training loss:		0.005305
  validation loss:		0.508194
  validation accuracy:		92.50 %
Epoch 1691 of 2000 took 0.146s
  training loss:		0.005205
  validation loss:		0.509538
  validation accuracy:		92.61 %
Epoch 1692 of 2000 took 0.146s
  training loss:		0.005432
  validation loss:		0.505890
  validation accuracy:		92.61 %
Epoch 1693 of 2000 took 0.187s
  training loss:		0.005338
  validation loss:		0.501647
  validation accuracy:		92.83 %
Epoch 1694 of 2000 took 0.179s
  training loss:		0.005168
  validation loss:		0.499189
  validation accuracy:		92.83 %
Epoch 1695 of 2000 took 0.145s
  training loss:		0.005500
  validation loss:		0.514236
  validation accuracy:		92.39 %
Epoch 1696 of 2000 took 0.172s
  training loss:		0.005539
  validation loss:		0.503970
  validation accuracy:		92.72 %
Epoch 1697 of 2000 took 0.183s
  training loss:		0.005343
  validation loss:		0.507280
  validation accuracy:		92.72 %
Epoch 1698 of 2000 took 0.183s
  training loss:		0.005194
  validation loss:		0.506678
  validation accuracy:		92.61 %
Epoch 1699 of 2000 took 0.177s
  training loss:		0.005267
  validation loss:		0.509358
  validation accuracy:		92.50 %
Epoch 1700 of 2000 took 0.152s
  training loss:		0.005241
  validation loss:		0.510774
  validation accuracy:		92.61 %
Epoch 1701 of 2000 took 0.144s
  training loss:		0.005086
  validation loss:		0.506756
  validation accuracy:		92.72 %
Epoch 1702 of 2000 took 0.150s
  training loss:		0.005181
  validation loss:		0.509907
  validation accuracy:		92.72 %
Epoch 1703 of 2000 took 0.132s
  training loss:		0.005284
  validation loss:		0.509908
  validation accuracy:		92.72 %
Epoch 1704 of 2000 took 0.150s
  training loss:		0.004990
  validation loss:		0.505659
  validation accuracy:		92.72 %
Epoch 1705 of 2000 took 0.183s
  training loss:		0.005172
  validation loss:		0.510279
  validation accuracy:		92.50 %
Epoch 1706 of 2000 took 0.165s
  training loss:		0.005287
  validation loss:		0.506881
  validation accuracy:		92.93 %
Epoch 1707 of 2000 took 0.142s
  training loss:		0.005147
  validation loss:		0.505310
  validation accuracy:		92.83 %
Epoch 1708 of 2000 took 0.171s
  training loss:		0.005056
  validation loss:		0.509756
  validation accuracy:		92.61 %
Epoch 1709 of 2000 took 0.145s
  training loss:		0.005205
  validation loss:		0.515442
  validation accuracy:		92.61 %
Epoch 1710 of 2000 took 0.160s
  training loss:		0.004996
  validation loss:		0.507574
  validation accuracy:		92.72 %
Epoch 1711 of 2000 took 0.147s
  training loss:		0.005133
  validation loss:		0.514897
  validation accuracy:		92.28 %
Epoch 1712 of 2000 took 0.186s
  training loss:		0.005128
  validation loss:		0.511522
  validation accuracy:		92.72 %
Epoch 1713 of 2000 took 0.183s
  training loss:		0.005292
  validation loss:		0.515324
  validation accuracy:		92.50 %
Epoch 1714 of 2000 took 0.152s
  training loss:		0.005091
  validation loss:		0.511357
  validation accuracy:		92.61 %
Epoch 1715 of 2000 took 0.136s
  training loss:		0.005121
  validation loss:		0.517080
  validation accuracy:		92.50 %
Epoch 1716 of 2000 took 0.144s
  training loss:		0.005043
  validation loss:		0.506724
  validation accuracy:		92.72 %
Epoch 1717 of 2000 took 0.154s
  training loss:		0.004968
  validation loss:		0.510962
  validation accuracy:		92.61 %
Epoch 1718 of 2000 took 0.164s
  training loss:		0.005089
  validation loss:		0.508851
  validation accuracy:		92.72 %
Epoch 1719 of 2000 took 0.159s
  training loss:		0.005087
  validation loss:		0.514178
  validation accuracy:		92.61 %
Epoch 1720 of 2000 took 0.144s
  training loss:		0.004995
  validation loss:		0.513240
  validation accuracy:		92.61 %
Epoch 1721 of 2000 took 0.150s
  training loss:		0.004971
  validation loss:		0.514754
  validation accuracy:		92.93 %
Epoch 1722 of 2000 took 0.154s
  training loss:		0.005107
  validation loss:		0.513830
  validation accuracy:		92.50 %
Epoch 1723 of 2000 took 0.154s
  training loss:		0.004940
  validation loss:		0.505512
  validation accuracy:		92.83 %
Epoch 1724 of 2000 took 0.147s
  training loss:		0.004952
  validation loss:		0.514459
  validation accuracy:		92.50 %
Epoch 1725 of 2000 took 0.153s
  training loss:		0.005046
  validation loss:		0.511588
  validation accuracy:		92.61 %
Epoch 1726 of 2000 took 0.155s
  training loss:		0.005021
  validation loss:		0.505773
  validation accuracy:		92.83 %
Epoch 1727 of 2000 took 0.135s
  training loss:		0.004922
  validation loss:		0.512908
  validation accuracy:		92.72 %
Epoch 1728 of 2000 took 0.133s
  training loss:		0.004979
  validation loss:		0.512362
  validation accuracy:		92.50 %
Epoch 1729 of 2000 took 0.157s
  training loss:		0.004887
  validation loss:		0.518508
  validation accuracy:		92.61 %
Epoch 1730 of 2000 took 0.133s
  training loss:		0.004968
  validation loss:		0.512255
  validation accuracy:		92.72 %
Epoch 1731 of 2000 took 0.141s
  training loss:		0.004755
  validation loss:		0.520898
  validation accuracy:		92.39 %
Epoch 1732 of 2000 took 0.147s
  training loss:		0.004890
  validation loss:		0.510016
  validation accuracy:		92.61 %
Epoch 1733 of 2000 took 0.139s
  training loss:		0.004965
  validation loss:		0.518603
  validation accuracy:		92.28 %
Epoch 1734 of 2000 took 0.144s
  training loss:		0.005019
  validation loss:		0.510720
  validation accuracy:		92.72 %
Epoch 1735 of 2000 took 0.145s
  training loss:		0.004919
  validation loss:		0.511671
  validation accuracy:		92.39 %
Epoch 1736 of 2000 took 0.159s
  training loss:		0.004952
  validation loss:		0.514821
  validation accuracy:		92.72 %
Epoch 1737 of 2000 took 0.174s
  training loss:		0.004874
  validation loss:		0.513740
  validation accuracy:		92.50 %
Epoch 1738 of 2000 took 0.171s
  training loss:		0.004722
  validation loss:		0.516150
  validation accuracy:		92.61 %
Epoch 1739 of 2000 took 0.153s
  training loss:		0.004920
  validation loss:		0.517242
  validation accuracy:		92.50 %
Epoch 1740 of 2000 took 0.154s
  training loss:		0.004893
  validation loss:		0.508694
  validation accuracy:		92.72 %
Epoch 1741 of 2000 took 0.156s
  training loss:		0.004874
  validation loss:		0.515225
  validation accuracy:		92.50 %
Epoch 1742 of 2000 took 0.157s
  training loss:		0.005020
  validation loss:		0.512984
  validation accuracy:		92.72 %
Epoch 1743 of 2000 took 0.142s
  training loss:		0.004938
  validation loss:		0.513407
  validation accuracy:		92.72 %
Epoch 1744 of 2000 took 0.149s
  training loss:		0.004774
  validation loss:		0.512109
  validation accuracy:		92.72 %
Epoch 1745 of 2000 took 0.147s
  training loss:		0.004817
  validation loss:		0.516573
  validation accuracy:		92.72 %
Epoch 1746 of 2000 took 0.148s
  training loss:		0.004934
  validation loss:		0.519009
  validation accuracy:		92.61 %
Epoch 1747 of 2000 took 0.146s
  training loss:		0.004868
  validation loss:		0.515759
  validation accuracy:		92.72 %
Epoch 1748 of 2000 took 0.170s
  training loss:		0.004778
  validation loss:		0.510181
  validation accuracy:		92.83 %
Epoch 1749 of 2000 took 0.183s
  training loss:		0.004794
  validation loss:		0.514874
  validation accuracy:		92.61 %
Epoch 1750 of 2000 took 0.185s
  training loss:		0.004833
  validation loss:		0.512458
  validation accuracy:		92.61 %
Epoch 1751 of 2000 took 0.186s
  training loss:		0.004857
  validation loss:		0.514677
  validation accuracy:		92.61 %
Epoch 1752 of 2000 took 0.184s
  training loss:		0.004877
  validation loss:		0.514212
  validation accuracy:		92.61 %
Epoch 1753 of 2000 took 0.177s
  training loss:		0.004948
  validation loss:		0.517177
  validation accuracy:		92.61 %
Epoch 1754 of 2000 took 0.150s
  training loss:		0.004615
  validation loss:		0.517460
  validation accuracy:		92.50 %
Epoch 1755 of 2000 took 0.146s
  training loss:		0.004893
  validation loss:		0.518822
  validation accuracy:		92.50 %
Epoch 1756 of 2000 took 0.145s
  training loss:		0.004802
  validation loss:		0.519070
  validation accuracy:		92.72 %
Epoch 1757 of 2000 took 0.154s
  training loss:		0.004952
  validation loss:		0.512101
  validation accuracy:		92.83 %
Epoch 1758 of 2000 took 0.144s
  training loss:		0.004765
  validation loss:		0.512263
  validation accuracy:		92.72 %
Epoch 1759 of 2000 took 0.134s
  training loss:		0.004767
  validation loss:		0.516930
  validation accuracy:		92.83 %
Epoch 1760 of 2000 took 0.155s
  training loss:		0.004759
  validation loss:		0.526221
  validation accuracy:		92.28 %
Epoch 1761 of 2000 took 0.156s
  training loss:		0.004768
  validation loss:		0.508252
  validation accuracy:		92.83 %
Epoch 1762 of 2000 took 0.185s
  training loss:		0.004948
  validation loss:		0.516779
  validation accuracy:		92.61 %
Epoch 1763 of 2000 took 0.176s
  training loss:		0.004836
  validation loss:		0.514612
  validation accuracy:		92.61 %
Epoch 1764 of 2000 took 0.168s
  training loss:		0.004684
  validation loss:		0.524677
  validation accuracy:		92.50 %
Epoch 1765 of 2000 took 0.155s
  training loss:		0.004593
  validation loss:		0.512354
  validation accuracy:		92.72 %
Epoch 1766 of 2000 took 0.148s
  training loss:		0.004751
  validation loss:		0.514525
  validation accuracy:		92.72 %
Epoch 1767 of 2000 took 0.150s
  training loss:		0.004872
  validation loss:		0.523969
  validation accuracy:		92.50 %
Epoch 1768 of 2000 took 0.180s
  training loss:		0.004784
  validation loss:		0.526093
  validation accuracy:		92.28 %
Epoch 1769 of 2000 took 0.172s
  training loss:		0.004592
  validation loss:		0.513729
  validation accuracy:		92.72 %
Epoch 1770 of 2000 took 0.164s
  training loss:		0.004784
  validation loss:		0.518051
  validation accuracy:		92.61 %
Epoch 1771 of 2000 took 0.136s
  training loss:		0.004729
  validation loss:		0.519386
  validation accuracy:		92.50 %
Epoch 1772 of 2000 took 0.150s
  training loss:		0.004626
  validation loss:		0.514849
  validation accuracy:		92.83 %
Epoch 1773 of 2000 took 0.182s
  training loss:		0.004755
  validation loss:		0.522378
  validation accuracy:		92.50 %
Epoch 1774 of 2000 took 0.147s
  training loss:		0.004723
  validation loss:		0.518314
  validation accuracy:		92.72 %
Epoch 1775 of 2000 took 0.183s
  training loss:		0.004722
  validation loss:		0.519781
  validation accuracy:		92.61 %
Epoch 1776 of 2000 took 0.158s
  training loss:		0.004639
  validation loss:		0.522352
  validation accuracy:		92.50 %
Epoch 1777 of 2000 took 0.150s
  training loss:		0.004601
  validation loss:		0.517880
  validation accuracy:		92.72 %
Epoch 1778 of 2000 took 0.161s
  training loss:		0.004651
  validation loss:		0.521025
  validation accuracy:		92.61 %
Epoch 1779 of 2000 took 0.152s
  training loss:		0.004654
  validation loss:		0.517453
  validation accuracy:		92.72 %
Epoch 1780 of 2000 took 0.170s
  training loss:		0.004674
  validation loss:		0.520970
  validation accuracy:		92.50 %
Epoch 1781 of 2000 took 0.191s
  training loss:		0.004538
  validation loss:		0.522866
  validation accuracy:		92.61 %
Epoch 1782 of 2000 took 0.172s
  training loss:		0.004592
  validation loss:		0.519934
  validation accuracy:		92.72 %
Epoch 1783 of 2000 took 0.190s
  training loss:		0.004629
  validation loss:		0.525577
  validation accuracy:		92.28 %
Epoch 1784 of 2000 took 0.183s
  training loss:		0.004650
  validation loss:		0.524419
  validation accuracy:		92.72 %
Epoch 1785 of 2000 took 0.183s
  training loss:		0.004619
  validation loss:		0.525799
  validation accuracy:		92.61 %
Epoch 1786 of 2000 took 0.177s
  training loss:		0.004609
  validation loss:		0.518511
  validation accuracy:		92.72 %
Epoch 1787 of 2000 took 0.187s
  training loss:		0.004633
  validation loss:		0.520602
  validation accuracy:		92.72 %
Epoch 1788 of 2000 took 0.157s
  training loss:		0.004591
  validation loss:		0.522863
  validation accuracy:		92.50 %
Epoch 1789 of 2000 took 0.178s
  training loss:		0.004808
  validation loss:		0.523538
  validation accuracy:		92.39 %
Epoch 1790 of 2000 took 0.144s
  training loss:		0.004620
  validation loss:		0.523532
  validation accuracy:		92.39 %
Epoch 1791 of 2000 took 0.185s
  training loss:		0.004546
  validation loss:		0.525912
  validation accuracy:		92.50 %
Epoch 1792 of 2000 took 0.184s
  training loss:		0.004505
  validation loss:		0.519220
  validation accuracy:		92.72 %
Epoch 1793 of 2000 took 0.192s
  training loss:		0.004612
  validation loss:		0.526107
  validation accuracy:		92.50 %
Epoch 1794 of 2000 took 0.183s
  training loss:		0.004579
  validation loss:		0.529476
  validation accuracy:		92.28 %
Epoch 1795 of 2000 took 0.164s
  training loss:		0.004550
  validation loss:		0.519093
  validation accuracy:		92.72 %
Epoch 1796 of 2000 took 0.160s
  training loss:		0.004642
  validation loss:		0.524253
  validation accuracy:		92.50 %
Epoch 1797 of 2000 took 0.158s
  training loss:		0.004488
  validation loss:		0.523537
  validation accuracy:		92.39 %
Epoch 1798 of 2000 took 0.183s
  training loss:		0.004439
  validation loss:		0.526396
  validation accuracy:		92.61 %
Epoch 1799 of 2000 took 0.190s
  training loss:		0.004507
  validation loss:		0.517964
  validation accuracy:		92.72 %
Epoch 1800 of 2000 took 0.155s
  training loss:		0.004599
  validation loss:		0.528378
  validation accuracy:		92.28 %
Epoch 1801 of 2000 took 0.169s
  training loss:		0.004413
  validation loss:		0.516825
  validation accuracy:		92.72 %
Epoch 1802 of 2000 took 0.180s
  training loss:		0.004640
  validation loss:		0.521657
  validation accuracy:		92.72 %
Epoch 1803 of 2000 took 0.138s
  training loss:		0.004525
  validation loss:		0.522144
  validation accuracy:		92.61 %
Epoch 1804 of 2000 took 0.166s
  training loss:		0.004611
  validation loss:		0.527590
  validation accuracy:		92.61 %
Epoch 1805 of 2000 took 0.148s
  training loss:		0.004593
  validation loss:		0.523966
  validation accuracy:		92.61 %
Epoch 1806 of 2000 took 0.143s
  training loss:		0.004470
  validation loss:		0.524408
  validation accuracy:		92.72 %
Epoch 1807 of 2000 took 0.158s
  training loss:		0.004329
  validation loss:		0.528588
  validation accuracy:		92.28 %
Epoch 1808 of 2000 took 0.144s
  training loss:		0.004380
  validation loss:		0.528867
  validation accuracy:		92.50 %
Epoch 1809 of 2000 took 0.152s
  training loss:		0.004581
  validation loss:		0.526700
  validation accuracy:		92.50 %
Epoch 1810 of 2000 took 0.146s
  training loss:		0.004487
  validation loss:		0.532257
  validation accuracy:		92.28 %
Epoch 1811 of 2000 took 0.160s
  training loss:		0.004436
  validation loss:		0.524737
  validation accuracy:		92.50 %
Epoch 1812 of 2000 took 0.186s
  training loss:		0.004385
  validation loss:		0.530559
  validation accuracy:		92.50 %
Epoch 1813 of 2000 took 0.172s
  training loss:		0.004398
  validation loss:		0.527759
  validation accuracy:		92.39 %
Epoch 1814 of 2000 took 0.148s
  training loss:		0.004485
  validation loss:		0.521998
  validation accuracy:		92.72 %
Epoch 1815 of 2000 took 0.143s
  training loss:		0.004369
  validation loss:		0.527927
  validation accuracy:		92.61 %
Epoch 1816 of 2000 took 0.150s
  training loss:		0.004480
  validation loss:		0.523285
  validation accuracy:		92.61 %
Epoch 1817 of 2000 took 0.191s
  training loss:		0.004423
  validation loss:		0.524418
  validation accuracy:		92.61 %
Epoch 1818 of 2000 took 0.170s
  training loss:		0.004280
  validation loss:		0.525606
  validation accuracy:		92.39 %
Epoch 1819 of 2000 took 0.141s
  training loss:		0.004327
  validation loss:		0.529060
  validation accuracy:		92.39 %
Epoch 1820 of 2000 took 0.186s
  training loss:		0.004452
  validation loss:		0.524620
  validation accuracy:		92.61 %
Epoch 1821 of 2000 took 0.182s
  training loss:		0.004520
  validation loss:		0.524892
  validation accuracy:		92.72 %
Epoch 1822 of 2000 took 0.179s
  training loss:		0.004479
  validation loss:		0.520861
  validation accuracy:		92.50 %
Epoch 1823 of 2000 took 0.169s
  training loss:		0.004327
  validation loss:		0.529790
  validation accuracy:		92.50 %
Epoch 1824 of 2000 took 0.162s
  training loss:		0.004461
  validation loss:		0.528014
  validation accuracy:		92.61 %
Epoch 1825 of 2000 took 0.141s
  training loss:		0.004215
  validation loss:		0.530313
  validation accuracy:		92.61 %
Epoch 1826 of 2000 took 0.149s
  training loss:		0.004391
  validation loss:		0.525761
  validation accuracy:		92.72 %
Epoch 1827 of 2000 took 0.136s
  training loss:		0.004301
  validation loss:		0.531552
  validation accuracy:		92.39 %
Epoch 1828 of 2000 took 0.135s
  training loss:		0.004316
  validation loss:		0.528346
  validation accuracy:		92.50 %
Epoch 1829 of 2000 took 0.179s
  training loss:		0.004441
  validation loss:		0.526600
  validation accuracy:		92.72 %
Epoch 1830 of 2000 took 0.184s
  training loss:		0.004357
  validation loss:		0.525691
  validation accuracy:		92.61 %
Epoch 1831 of 2000 took 0.151s
  training loss:		0.004393
  validation loss:		0.532641
  validation accuracy:		92.50 %
Epoch 1832 of 2000 took 0.145s
  training loss:		0.004320
  validation loss:		0.523381
  validation accuracy:		92.72 %
Epoch 1833 of 2000 took 0.170s
  training loss:		0.004189
  validation loss:		0.532465
  validation accuracy:		92.28 %
Epoch 1834 of 2000 took 0.167s
  training loss:		0.004316
  validation loss:		0.528474
  validation accuracy:		92.61 %
Epoch 1835 of 2000 took 0.155s
  training loss:		0.004445
  validation loss:		0.526227
  validation accuracy:		92.72 %
Epoch 1836 of 2000 took 0.141s
  training loss:		0.004426
  validation loss:		0.532811
  validation accuracy:		92.50 %
Epoch 1837 of 2000 took 0.141s
  training loss:		0.004002
  validation loss:		0.533824
  validation accuracy:		92.50 %
Epoch 1838 of 2000 took 0.151s
  training loss:		0.004419
  validation loss:		0.527290
  validation accuracy:		92.50 %
Epoch 1839 of 2000 took 0.152s
  training loss:		0.004257
  validation loss:		0.533504
  validation accuracy:		92.28 %
Epoch 1840 of 2000 took 0.159s
  training loss:		0.004281
  validation loss:		0.528273
  validation accuracy:		92.72 %
Epoch 1841 of 2000 took 0.151s
  training loss:		0.004237
  validation loss:		0.526272
  validation accuracy:		92.72 %
Epoch 1842 of 2000 took 0.139s
  training loss:		0.004323
  validation loss:		0.532785
  validation accuracy:		92.39 %
Epoch 1843 of 2000 took 0.141s
  training loss:		0.004330
  validation loss:		0.532204
  validation accuracy:		92.39 %
Epoch 1844 of 2000 took 0.140s
  training loss:		0.004206
  validation loss:		0.525869
  validation accuracy:		92.72 %
Epoch 1845 of 2000 took 0.142s
  training loss:		0.004294
  validation loss:		0.534276
  validation accuracy:		92.39 %
Epoch 1846 of 2000 took 0.179s
  training loss:		0.004271
  validation loss:		0.531205
  validation accuracy:		92.61 %
Epoch 1847 of 2000 took 0.143s
  training loss:		0.004331
  validation loss:		0.533378
  validation accuracy:		92.61 %
Epoch 1848 of 2000 took 0.131s
  training loss:		0.004230
  validation loss:		0.528535
  validation accuracy:		92.50 %
Epoch 1849 of 2000 took 0.142s
  training loss:		0.004274
  validation loss:		0.532012
  validation accuracy:		92.61 %
Epoch 1850 of 2000 took 0.184s
  training loss:		0.004231
  validation loss:		0.533964
  validation accuracy:		92.61 %
Epoch 1851 of 2000 took 0.152s
  training loss:		0.004244
  validation loss:		0.531730
  validation accuracy:		92.61 %
Epoch 1852 of 2000 took 0.143s
  training loss:		0.004156
  validation loss:		0.535213
  validation accuracy:		92.28 %
Epoch 1853 of 2000 took 0.141s
  training loss:		0.004115
  validation loss:		0.533526
  validation accuracy:		92.61 %
Epoch 1854 of 2000 took 0.144s
  training loss:		0.004171
  validation loss:		0.529904
  validation accuracy:		92.61 %
Epoch 1855 of 2000 took 0.138s
  training loss:		0.004177
  validation loss:		0.532564
  validation accuracy:		92.61 %
Epoch 1856 of 2000 took 0.142s
  training loss:		0.004169
  validation loss:		0.537471
  validation accuracy:		92.50 %
Epoch 1857 of 2000 took 0.147s
  training loss:		0.004285
  validation loss:		0.532741
  validation accuracy:		92.50 %
Epoch 1858 of 2000 took 0.145s
  training loss:		0.004122
  validation loss:		0.532417
  validation accuracy:		92.39 %
Epoch 1859 of 2000 took 0.148s
  training loss:		0.004192
  validation loss:		0.533481
  validation accuracy:		92.50 %
Epoch 1860 of 2000 took 0.141s
  training loss:		0.004114
  validation loss:		0.539123
  validation accuracy:		92.28 %
Epoch 1861 of 2000 took 0.143s
  training loss:		0.004228
  validation loss:		0.535027
  validation accuracy:		92.50 %
Epoch 1862 of 2000 took 0.140s
  training loss:		0.004232
  validation loss:		0.539702
  validation accuracy:		92.50 %
Epoch 1863 of 2000 took 0.140s
  training loss:		0.004127
  validation loss:		0.528798
  validation accuracy:		92.61 %
Epoch 1864 of 2000 took 0.145s
  training loss:		0.004219
  validation loss:		0.540274
  validation accuracy:		92.28 %
Epoch 1865 of 2000 took 0.150s
  training loss:		0.004268
  validation loss:		0.533817
  validation accuracy:		92.61 %
Epoch 1866 of 2000 took 0.149s
  training loss:		0.004084
  validation loss:		0.532347
  validation accuracy:		92.61 %
Epoch 1867 of 2000 took 0.144s
  training loss:		0.004089
  validation loss:		0.534487
  validation accuracy:		92.50 %
Epoch 1868 of 2000 took 0.194s
  training loss:		0.004171
  validation loss:		0.529591
  validation accuracy:		92.72 %
Epoch 1869 of 2000 took 0.146s
  training loss:		0.004116
  validation loss:		0.534602
  validation accuracy:		92.61 %
Epoch 1870 of 2000 took 0.175s
  training loss:		0.003978
  validation loss:		0.534813
  validation accuracy:		92.61 %
Epoch 1871 of 2000 took 0.174s
  training loss:		0.004147
  validation loss:		0.534112
  validation accuracy:		92.50 %
Epoch 1872 of 2000 took 0.185s
  training loss:		0.004027
  validation loss:		0.535893
  validation accuracy:		92.50 %
Epoch 1873 of 2000 took 0.174s
  training loss:		0.003993
  validation loss:		0.533275
  validation accuracy:		92.61 %
Epoch 1874 of 2000 took 0.146s
  training loss:		0.004092
  validation loss:		0.536667
  validation accuracy:		92.61 %
Epoch 1875 of 2000 took 0.145s
  training loss:		0.004086
  validation loss:		0.531322
  validation accuracy:		92.50 %
Epoch 1876 of 2000 took 0.143s
  training loss:		0.004074
  validation loss:		0.536386
  validation accuracy:		92.50 %
Epoch 1877 of 2000 took 0.134s
  training loss:		0.004020
  validation loss:		0.540337
  validation accuracy:		92.50 %
Epoch 1878 of 2000 took 0.144s
  training loss:		0.003992
  validation loss:		0.532480
  validation accuracy:		92.50 %
Epoch 1879 of 2000 took 0.143s
  training loss:		0.004068
  validation loss:		0.538505
  validation accuracy:		92.50 %
Epoch 1880 of 2000 took 0.139s
  training loss:		0.004165
  validation loss:		0.544574
  validation accuracy:		92.28 %
Epoch 1881 of 2000 took 0.143s
  training loss:		0.003993
  validation loss:		0.535089
  validation accuracy:		92.61 %
Epoch 1882 of 2000 took 0.144s
  training loss:		0.004150
  validation loss:		0.534876
  validation accuracy:		92.61 %
Epoch 1883 of 2000 took 0.141s
  training loss:		0.004028
  validation loss:		0.534713
  validation accuracy:		92.50 %
Epoch 1884 of 2000 took 0.141s
  training loss:		0.004097
  validation loss:		0.540778
  validation accuracy:		92.50 %
Epoch 1885 of 2000 took 0.142s
  training loss:		0.004044
  validation loss:		0.531032
  validation accuracy:		92.72 %
Epoch 1886 of 2000 took 0.144s
  training loss:		0.004034
  validation loss:		0.536330
  validation accuracy:		92.50 %
Epoch 1887 of 2000 took 0.143s
  training loss:		0.004084
  validation loss:		0.542819
  validation accuracy:		92.39 %
Epoch 1888 of 2000 took 0.143s
  training loss:		0.004046
  validation loss:		0.544408
  validation accuracy:		92.39 %
Epoch 1889 of 2000 took 0.141s
  training loss:		0.003990
  validation loss:		0.535515
  validation accuracy:		92.61 %
Epoch 1890 of 2000 took 0.142s
  training loss:		0.004179
  validation loss:		0.540840
  validation accuracy:		92.39 %
Epoch 1891 of 2000 took 0.146s
  training loss:		0.004071
  validation loss:		0.536840
  validation accuracy:		92.39 %
Epoch 1892 of 2000 took 0.139s
  training loss:		0.003985
  validation loss:		0.541704
  validation accuracy:		92.39 %
Epoch 1893 of 2000 took 0.139s
  training loss:		0.004026
  validation loss:		0.534104
  validation accuracy:		92.61 %
Epoch 1894 of 2000 took 0.140s
  training loss:		0.004033
  validation loss:		0.537240
  validation accuracy:		92.61 %
Epoch 1895 of 2000 took 0.137s
  training loss:		0.004087
  validation loss:		0.543187
  validation accuracy:		92.28 %
Epoch 1896 of 2000 took 0.142s
  training loss:		0.003936
  validation loss:		0.532049
  validation accuracy:		92.61 %
Epoch 1897 of 2000 took 0.144s
  training loss:		0.003948
  validation loss:		0.541885
  validation accuracy:		92.28 %
Epoch 1898 of 2000 took 0.144s
  training loss:		0.003975
  validation loss:		0.542887
  validation accuracy:		92.50 %
Epoch 1899 of 2000 took 0.141s
  training loss:		0.004074
  validation loss:		0.540990
  validation accuracy:		92.50 %
Epoch 1900 of 2000 took 0.143s
  training loss:		0.004094
  validation loss:		0.536710
  validation accuracy:		92.61 %
Epoch 1901 of 2000 took 0.145s
  training loss:		0.004093
  validation loss:		0.537666
  validation accuracy:		92.72 %
Epoch 1902 of 2000 took 0.116s
  training loss:		0.003867
  validation loss:		0.539611
  validation accuracy:		92.61 %
Epoch 1903 of 2000 took 0.126s
  training loss:		0.003931
  validation loss:		0.537367
  validation accuracy:		92.61 %
Epoch 1904 of 2000 took 0.232s
  training loss:		0.003967
  validation loss:		0.539940
  validation accuracy:		92.50 %
Epoch 1905 of 2000 took 0.125s
  training loss:		0.003988
  validation loss:		0.544304
  validation accuracy:		92.28 %
Epoch 1906 of 2000 took 0.149s
  training loss:		0.003902
  validation loss:		0.538860
  validation accuracy:		92.61 %
Epoch 1907 of 2000 took 0.124s
  training loss:		0.003918
  validation loss:		0.540919
  validation accuracy:		92.39 %
Epoch 1908 of 2000 took 0.101s
  training loss:		0.003861
  validation loss:		0.541608
  validation accuracy:		92.39 %
Epoch 1909 of 2000 took 0.103s
  training loss:		0.004053
  validation loss:		0.536939
  validation accuracy:		92.50 %
Epoch 1910 of 2000 took 0.118s
  training loss:		0.003897
  validation loss:		0.540474
  validation accuracy:		92.39 %
Epoch 1911 of 2000 took 0.117s
  training loss:		0.003800
  validation loss:		0.541237
  validation accuracy:		92.61 %
Epoch 1912 of 2000 took 0.130s
  training loss:		0.003861
  validation loss:		0.533970
  validation accuracy:		92.72 %
Epoch 1913 of 2000 took 0.154s
  training loss:		0.003990
  validation loss:		0.542075
  validation accuracy:		92.28 %
Epoch 1914 of 2000 took 0.129s
  training loss:		0.003861
  validation loss:		0.540716
  validation accuracy:		92.50 %
Epoch 1915 of 2000 took 0.130s
  training loss:		0.003846
  validation loss:		0.541527
  validation accuracy:		92.61 %
Epoch 1916 of 2000 took 0.115s
  training loss:		0.003936
  validation loss:		0.540774
  validation accuracy:		92.39 %
Epoch 1917 of 2000 took 0.114s
  training loss:		0.003843
  validation loss:		0.545318
  validation accuracy:		92.28 %
Epoch 1918 of 2000 took 0.116s
  training loss:		0.003929
  validation loss:		0.547415
  validation accuracy:		92.28 %
Epoch 1919 of 2000 took 0.129s
  training loss:		0.003755
  validation loss:		0.539150
  validation accuracy:		92.61 %
Epoch 1920 of 2000 took 0.108s
  training loss:		0.003844
  validation loss:		0.549261
  validation accuracy:		92.39 %
Epoch 1921 of 2000 took 0.126s
  training loss:		0.003919
  validation loss:		0.548991
  validation accuracy:		92.39 %
Epoch 1922 of 2000 took 0.119s
  training loss:		0.003846
  validation loss:		0.539033
  validation accuracy:		92.61 %
Epoch 1923 of 2000 took 0.123s
  training loss:		0.003766
  validation loss:		0.546641
  validation accuracy:		92.39 %
Epoch 1924 of 2000 took 0.351s
  training loss:		0.003800
  validation loss:		0.542402
  validation accuracy:		92.61 %
Epoch 1925 of 2000 took 0.122s
  training loss:		0.003918
  validation loss:		0.538585
  validation accuracy:		92.61 %
Epoch 1926 of 2000 took 0.130s
  training loss:		0.003690
  validation loss:		0.546083
  validation accuracy:		92.28 %
Epoch 1927 of 2000 took 0.128s
  training loss:		0.003820
  validation loss:		0.540624
  validation accuracy:		92.50 %
Epoch 1928 of 2000 took 0.126s
  training loss:		0.003889
  validation loss:		0.547846
  validation accuracy:		92.39 %
Epoch 1929 of 2000 took 0.123s
  training loss:		0.004022
  validation loss:		0.541066
  validation accuracy:		92.50 %
Epoch 1930 of 2000 took 0.125s
  training loss:		0.003811
  validation loss:		0.551748
  validation accuracy:		92.39 %
Epoch 1931 of 2000 took 0.121s
  training loss:		0.003896
  validation loss:		0.539319
  validation accuracy:		92.61 %
Epoch 1932 of 2000 took 0.108s
  training loss:		0.003889
  validation loss:		0.540870
  validation accuracy:		92.61 %
Epoch 1933 of 2000 took 0.117s
  training loss:		0.003834
  validation loss:		0.538741
  validation accuracy:		92.39 %
Epoch 1934 of 2000 took 0.122s
  training loss:		0.003805
  validation loss:		0.545828
  validation accuracy:		92.39 %
Epoch 1935 of 2000 took 0.115s
  training loss:		0.003789
  validation loss:		0.541918
  validation accuracy:		92.50 %
Epoch 1936 of 2000 took 0.114s
  training loss:		0.003711
  validation loss:		0.549924
  validation accuracy:		92.28 %
Epoch 1937 of 2000 took 0.093s
  training loss:		0.003756
  validation loss:		0.545068
  validation accuracy:		92.28 %
Epoch 1938 of 2000 took 0.115s
  training loss:		0.003823
  validation loss:		0.544182
  validation accuracy:		92.39 %
Epoch 1939 of 2000 took 0.115s
  training loss:		0.003706
  validation loss:		0.543192
  validation accuracy:		92.39 %
Epoch 1940 of 2000 took 0.117s
  training loss:		0.003739
  validation loss:		0.547268
  validation accuracy:		92.50 %
Epoch 1941 of 2000 took 0.106s
  training loss:		0.003768
  validation loss:		0.543850
  validation accuracy:		92.50 %
Epoch 1942 of 2000 took 0.125s
  training loss:		0.003778
  validation loss:		0.547472
  validation accuracy:		92.28 %
Epoch 1943 of 2000 took 0.122s
  training loss:		0.003802
  validation loss:		0.548605
  validation accuracy:		92.50 %
Epoch 1944 of 2000 took 0.113s
  training loss:		0.003802
  validation loss:		0.545581
  validation accuracy:		92.61 %
Epoch 1945 of 2000 took 0.122s
  training loss:		0.003701
  validation loss:		0.545791
  validation accuracy:		92.39 %
Epoch 1946 of 2000 took 0.075s
  training loss:		0.003821
  validation loss:		0.551468
  validation accuracy:		92.50 %
Epoch 1947 of 2000 took 0.124s
  training loss:		0.003778
  validation loss:		0.548584
  validation accuracy:		92.28 %
Epoch 1948 of 2000 took 0.115s
  training loss:		0.003817
  validation loss:		0.549002
  validation accuracy:		92.28 %
Epoch 1949 of 2000 took 0.115s
  training loss:		0.003730
  validation loss:		0.544839
  validation accuracy:		92.50 %
Epoch 1950 of 2000 took 0.106s
  training loss:		0.003724
  validation loss:		0.550143
  validation accuracy:		92.28 %
Epoch 1951 of 2000 took 0.106s
  training loss:		0.003776
  validation loss:		0.544337
  validation accuracy:		92.50 %
Epoch 1952 of 2000 took 0.108s
  training loss:		0.003754
  validation loss:		0.544504
  validation accuracy:		92.50 %
Epoch 1953 of 2000 took 0.099s
  training loss:		0.003768
  validation loss:		0.549820
  validation accuracy:		92.50 %
Epoch 1954 of 2000 took 0.103s
  training loss:		0.003870
  validation loss:		0.547369
  validation accuracy:		92.39 %
Epoch 1955 of 2000 took 0.104s
  training loss:		0.003685
  validation loss:		0.549934
  validation accuracy:		92.28 %
Epoch 1956 of 2000 took 0.104s
  training loss:		0.003691
  validation loss:		0.550034
  validation accuracy:		92.50 %
Epoch 1957 of 2000 took 0.108s
  training loss:		0.003768
  validation loss:		0.547587
  validation accuracy:		92.28 %
Epoch 1958 of 2000 took 0.103s
  training loss:		0.003579
  validation loss:		0.546971
  validation accuracy:		92.50 %
Epoch 1959 of 2000 took 0.093s
  training loss:		0.003721
  validation loss:		0.548081
  validation accuracy:		92.28 %
Epoch 1960 of 2000 took 0.115s
  training loss:		0.003657
  validation loss:		0.549381
  validation accuracy:		92.28 %
Epoch 1961 of 2000 took 0.114s
  training loss:		0.003650
  validation loss:		0.549823
  validation accuracy:		92.39 %
Epoch 1962 of 2000 took 0.115s
  training loss:		0.003606
  validation loss:		0.548678
  validation accuracy:		92.39 %
Epoch 1963 of 2000 took 0.112s
  training loss:		0.003631
  validation loss:		0.548870
  validation accuracy:		92.39 %
Epoch 1964 of 2000 took 0.103s
  training loss:		0.003494
  validation loss:		0.547068
  validation accuracy:		92.50 %
Epoch 1965 of 2000 took 0.103s
  training loss:		0.003645
  validation loss:		0.548003
  validation accuracy:		92.50 %
Epoch 1966 of 2000 took 0.078s
  training loss:		0.003752
  validation loss:		0.549312
  validation accuracy:		92.39 %
Epoch 1967 of 2000 took 0.125s
  training loss:		0.003773
  validation loss:		0.546533
  validation accuracy:		92.39 %
Epoch 1968 of 2000 took 0.126s
  training loss:		0.003700
  validation loss:		0.551918
  validation accuracy:		92.50 %
Epoch 1969 of 2000 took 0.126s
  training loss:		0.003665
  validation loss:		0.555127
  validation accuracy:		92.28 %
Epoch 1970 of 2000 took 0.127s
  training loss:		0.003631
  validation loss:		0.544837
  validation accuracy:		92.50 %
Epoch 1971 of 2000 took 0.125s
  training loss:		0.003704
  validation loss:		0.547612
  validation accuracy:		92.39 %
Epoch 1972 of 2000 took 0.126s
  training loss:		0.003682
  validation loss:		0.551327
  validation accuracy:		92.50 %
Epoch 1973 of 2000 took 0.125s
  training loss:		0.003680
  validation loss:		0.554654
  validation accuracy:		92.28 %
Epoch 1974 of 2000 took 0.099s
  training loss:		0.003535
  validation loss:		0.546494
  validation accuracy:		92.50 %
Epoch 1975 of 2000 took 0.102s
  training loss:		0.003617
  validation loss:		0.556312
  validation accuracy:		92.28 %
Epoch 1976 of 2000 took 0.116s
  training loss:		0.003555
  validation loss:		0.546821
  validation accuracy:		92.39 %
Epoch 1977 of 2000 took 0.116s
  training loss:		0.003593
  validation loss:		0.550825
  validation accuracy:		92.50 %
Epoch 1978 of 2000 took 0.113s
  training loss:		0.003461
  validation loss:		0.552116
  validation accuracy:		92.39 %
Epoch 1979 of 2000 took 0.115s
  training loss:		0.003596
  validation loss:		0.555208
  validation accuracy:		92.39 %
Epoch 1980 of 2000 took 0.116s
  training loss:		0.003533
  validation loss:		0.546336
  validation accuracy:		92.50 %
Epoch 1981 of 2000 took 0.126s
  training loss:		0.003564
  validation loss:		0.550224
  validation accuracy:		92.39 %
Epoch 1982 of 2000 took 0.096s
  training loss:		0.003709
  validation loss:		0.553161
  validation accuracy:		92.50 %
Epoch 1983 of 2000 took 0.090s
  training loss:		0.003482
  validation loss:		0.551997
  validation accuracy:		92.39 %
Epoch 1984 of 2000 took 0.112s
  training loss:		0.003591
  validation loss:		0.547785
  validation accuracy:		92.39 %
Epoch 1985 of 2000 took 0.126s
  training loss:		0.003636
  validation loss:		0.558287
  validation accuracy:		92.28 %
Epoch 1986 of 2000 took 0.097s
  training loss:		0.003630
  validation loss:		0.549452
  validation accuracy:		92.50 %
Epoch 1987 of 2000 took 0.110s
  training loss:		0.003488
  validation loss:		0.550055
  validation accuracy:		92.61 %
Epoch 1988 of 2000 took 0.122s
  training loss:		0.003544
  validation loss:		0.548653
  validation accuracy:		92.50 %
Epoch 1989 of 2000 took 0.125s
  training loss:		0.003616
  validation loss:		0.557720
  validation accuracy:		92.28 %
Epoch 1990 of 2000 took 0.107s
  training loss:		0.003584
  validation loss:		0.552309
  validation accuracy:		92.28 %
Epoch 1991 of 2000 took 0.100s
  training loss:		0.003514
  validation loss:		0.552283
  validation accuracy:		92.50 %
Epoch 1992 of 2000 took 0.116s
  training loss:		0.003610
  validation loss:		0.552119
  validation accuracy:		92.39 %
Epoch 1993 of 2000 took 0.115s
  training loss:		0.003456
  validation loss:		0.550535
  validation accuracy:		92.50 %
Epoch 1994 of 2000 took 0.116s
  training loss:		0.003540
  validation loss:		0.553024
  validation accuracy:		92.39 %
Epoch 1995 of 2000 took 0.092s
  training loss:		0.003631
  validation loss:		0.553688
  validation accuracy:		92.28 %
Epoch 1996 of 2000 took 0.099s
  training loss:		0.003571
  validation loss:		0.556524
  validation accuracy:		92.50 %
Epoch 1997 of 2000 took 0.109s
  training loss:		0.003482
  validation loss:		0.548026
  validation accuracy:		92.61 %
Epoch 1998 of 2000 took 0.098s
  training loss:		0.003569
  validation loss:		0.552635
  validation accuracy:		92.50 %
Epoch 1999 of 2000 took 0.105s
  training loss:		0.003537
  validation loss:		0.555223
  validation accuracy:		92.28 %
Epoch 2000 of 2000 took 0.118s
  training loss:		0.003461
  validation loss:		0.553423
  validation accuracy:		92.39 %
Final results:
  test loss:			1.380889
  test accuracy:		84.25 %
