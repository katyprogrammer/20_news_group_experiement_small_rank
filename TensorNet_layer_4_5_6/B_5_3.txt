Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
decomposing tensor W of shape (3, 50, 50)...
decomposing tensor B of shape (3, 50)...
Starting training...
Epoch 1 of 2000 took 0.100s
  training loss:		2.992179
  validation loss:		2.980329
  validation accuracy:		0.00 %
Epoch 2 of 2000 took 0.097s
  training loss:		2.963721
  validation loss:		2.945578
  validation accuracy:		13.04 %
Epoch 3 of 2000 took 0.096s
  training loss:		2.928049
  validation loss:		2.907691
  validation accuracy:		13.04 %
Epoch 4 of 2000 took 0.097s
  training loss:		2.890354
  validation loss:		2.869421
  validation accuracy:		13.04 %
Epoch 5 of 2000 took 0.096s
  training loss:		2.853545
  validation loss:		2.831360
  validation accuracy:		13.04 %
Epoch 6 of 2000 took 0.098s
  training loss:		2.816338
  validation loss:		2.792732
  validation accuracy:		13.04 %
Epoch 7 of 2000 took 0.097s
  training loss:		2.779105
  validation loss:		2.753150
  validation accuracy:		13.04 %
Epoch 8 of 2000 took 0.097s
  training loss:		2.740160
  validation loss:		2.712109
  validation accuracy:		13.04 %
Epoch 9 of 2000 took 0.097s
  training loss:		2.702004
  validation loss:		2.669625
  validation accuracy:		13.04 %
Epoch 10 of 2000 took 0.097s
  training loss:		2.662835
  validation loss:		2.625351
  validation accuracy:		13.04 %
Epoch 11 of 2000 took 0.097s
  training loss:		2.623792
  validation loss:		2.579960
  validation accuracy:		13.04 %
Epoch 12 of 2000 took 0.097s
  training loss:		2.583202
  validation loss:		2.534127
  validation accuracy:		13.04 %
Epoch 13 of 2000 took 0.097s
  training loss:		2.544696
  validation loss:		2.488332
  validation accuracy:		13.04 %
Epoch 14 of 2000 took 0.097s
  training loss:		2.503428
  validation loss:		2.443805
  validation accuracy:		13.04 %
Epoch 15 of 2000 took 0.097s
  training loss:		2.466944
  validation loss:		2.400713
  validation accuracy:		13.04 %
Epoch 16 of 2000 took 0.097s
  training loss:		2.433467
  validation loss:		2.361818
  validation accuracy:		13.04 %
Epoch 17 of 2000 took 0.097s
  training loss:		2.404065
  validation loss:		2.330275
  validation accuracy:		13.04 %
Epoch 18 of 2000 took 0.097s
  training loss:		2.380214
  validation loss:		2.306264
  validation accuracy:		13.04 %
Epoch 19 of 2000 took 0.097s
  training loss:		2.360040
  validation loss:		2.289695
  validation accuracy:		13.04 %
Epoch 20 of 2000 took 0.097s
  training loss:		2.345532
  validation loss:		2.276781
  validation accuracy:		13.04 %
Epoch 21 of 2000 took 0.097s
  training loss:		2.334210
  validation loss:		2.267078
  validation accuracy:		13.04 %
Epoch 22 of 2000 took 0.097s
  training loss:		2.327284
  validation loss:		2.262584
  validation accuracy:		13.04 %
Epoch 23 of 2000 took 0.097s
  training loss:		2.320622
  validation loss:		2.260129
  validation accuracy:		8.26 %
Epoch 24 of 2000 took 0.097s
  training loss:		2.314891
  validation loss:		2.256804
  validation accuracy:		12.93 %
Epoch 25 of 2000 took 0.097s
  training loss:		2.312395
  validation loss:		2.255220
  validation accuracy:		12.93 %
Epoch 26 of 2000 took 0.097s
  training loss:		2.310571
  validation loss:		2.254668
  validation accuracy:		12.83 %
Epoch 27 of 2000 took 0.097s
  training loss:		2.307055
  validation loss:		2.255528
  validation accuracy:		12.93 %
Epoch 28 of 2000 took 0.097s
  training loss:		2.304548
  validation loss:		2.251475
  validation accuracy:		12.93 %
Epoch 29 of 2000 took 0.097s
  training loss:		2.303813
  validation loss:		2.248766
  validation accuracy:		13.26 %
Epoch 30 of 2000 took 0.097s
  training loss:		2.303576
  validation loss:		2.249929
  validation accuracy:		10.76 %
Epoch 31 of 2000 took 0.097s
  training loss:		2.301675
  validation loss:		2.248207
  validation accuracy:		9.57 %
Epoch 32 of 2000 took 0.097s
  training loss:		2.300529
  validation loss:		2.247822
  validation accuracy:		10.76 %
Epoch 33 of 2000 took 0.097s
  training loss:		2.300111
  validation loss:		2.246270
  validation accuracy:		13.26 %
Epoch 34 of 2000 took 0.097s
  training loss:		2.299739
  validation loss:		2.246906
  validation accuracy:		12.83 %
Epoch 35 of 2000 took 0.097s
  training loss:		2.299739
  validation loss:		2.249808
  validation accuracy:		12.93 %
Epoch 36 of 2000 took 0.097s
  training loss:		2.299121
  validation loss:		2.252253
  validation accuracy:		13.04 %
Epoch 37 of 2000 took 0.097s
  training loss:		2.298779
  validation loss:		2.247995
  validation accuracy:		12.93 %
Epoch 38 of 2000 took 0.097s
  training loss:		2.298249
  validation loss:		2.246834
  validation accuracy:		12.72 %
Epoch 39 of 2000 took 0.099s
  training loss:		2.296572
  validation loss:		2.243778
  validation accuracy:		10.00 %
Epoch 40 of 2000 took 0.097s
  training loss:		2.297452
  validation loss:		2.243763
  validation accuracy:		12.93 %
Epoch 41 of 2000 took 0.097s
  training loss:		2.297161
  validation loss:		2.244061
  validation accuracy:		13.15 %
Epoch 42 of 2000 took 0.097s
  training loss:		2.295700
  validation loss:		2.243453
  validation accuracy:		12.83 %
Epoch 43 of 2000 took 0.097s
  training loss:		2.297624
  validation loss:		2.246942
  validation accuracy:		13.04 %
Epoch 44 of 2000 took 0.097s
  training loss:		2.296389
  validation loss:		2.246771
  validation accuracy:		11.52 %
Epoch 45 of 2000 took 0.097s
  training loss:		2.295643
  validation loss:		2.243382
  validation accuracy:		17.50 %
Epoch 46 of 2000 took 0.097s
  training loss:		2.295728
  validation loss:		2.243048
  validation accuracy:		12.93 %
Epoch 47 of 2000 took 0.097s
  training loss:		2.295468
  validation loss:		2.242005
  validation accuracy:		13.04 %
Epoch 48 of 2000 took 0.097s
  training loss:		2.295295
  validation loss:		2.242143
  validation accuracy:		13.15 %
Epoch 49 of 2000 took 0.097s
  training loss:		2.295586
  validation loss:		2.241217
  validation accuracy:		13.59 %
Epoch 50 of 2000 took 0.097s
  training loss:		2.294752
  validation loss:		2.241227
  validation accuracy:		13.26 %
Epoch 51 of 2000 took 0.097s
  training loss:		2.294610
  validation loss:		2.244818
  validation accuracy:		12.93 %
Epoch 52 of 2000 took 0.097s
  training loss:		2.295206
  validation loss:		2.246177
  validation accuracy:		13.26 %
Epoch 53 of 2000 took 0.097s
  training loss:		2.294365
  validation loss:		2.242845
  validation accuracy:		13.04 %
Epoch 54 of 2000 took 0.097s
  training loss:		2.295242
  validation loss:		2.243523
  validation accuracy:		12.07 %
Epoch 55 of 2000 took 0.097s
  training loss:		2.295331
  validation loss:		2.246462
  validation accuracy:		13.59 %
Epoch 56 of 2000 took 0.097s
  training loss:		2.294482
  validation loss:		2.240507
  validation accuracy:		12.93 %
Epoch 57 of 2000 took 0.097s
  training loss:		2.294356
  validation loss:		2.243281
  validation accuracy:		13.04 %
Epoch 58 of 2000 took 0.097s
  training loss:		2.294524
  validation loss:		2.246048
  validation accuracy:		15.11 %
Epoch 59 of 2000 took 0.097s
  training loss:		2.294222
  validation loss:		2.242901
  validation accuracy:		13.26 %
Epoch 60 of 2000 took 0.097s
  training loss:		2.293163
  validation loss:		2.240721
  validation accuracy:		12.93 %
Epoch 61 of 2000 took 0.097s
  training loss:		2.294450
  validation loss:		2.241221
  validation accuracy:		13.04 %
Epoch 62 of 2000 took 0.097s
  training loss:		2.293436
  validation loss:		2.239603
  validation accuracy:		12.93 %
Epoch 63 of 2000 took 0.097s
  training loss:		2.294032
  validation loss:		2.243778
  validation accuracy:		13.48 %
Epoch 64 of 2000 took 0.097s
  training loss:		2.294243
  validation loss:		2.242192
  validation accuracy:		12.93 %
Epoch 65 of 2000 took 0.097s
  training loss:		2.293557
  validation loss:		2.240321
  validation accuracy:		12.93 %
Epoch 66 of 2000 took 0.097s
  training loss:		2.294072
  validation loss:		2.245408
  validation accuracy:		12.93 %
Epoch 67 of 2000 took 0.097s
  training loss:		2.292936
  validation loss:		2.240801
  validation accuracy:		16.74 %
Epoch 68 of 2000 took 0.098s
  training loss:		2.293209
  validation loss:		2.241705
  validation accuracy:		15.98 %
Epoch 69 of 2000 took 0.097s
  training loss:		2.293224
  validation loss:		2.242181
  validation accuracy:		10.22 %
Epoch 70 of 2000 took 0.097s
  training loss:		2.293629
  validation loss:		2.244215
  validation accuracy:		13.70 %
Epoch 71 of 2000 took 0.097s
  training loss:		2.293594
  validation loss:		2.241753
  validation accuracy:		12.93 %
Epoch 72 of 2000 took 0.097s
  training loss:		2.293694
  validation loss:		2.240439
  validation accuracy:		13.48 %
Epoch 73 of 2000 took 0.097s
  training loss:		2.293316
  validation loss:		2.243111
  validation accuracy:		12.93 %
Epoch 74 of 2000 took 0.097s
  training loss:		2.292619
  validation loss:		2.240734
  validation accuracy:		13.04 %
Epoch 75 of 2000 took 0.097s
  training loss:		2.292205
  validation loss:		2.241673
  validation accuracy:		13.15 %
Epoch 76 of 2000 took 0.097s
  training loss:		2.292441
  validation loss:		2.237662
  validation accuracy:		13.26 %
Epoch 77 of 2000 took 0.097s
  training loss:		2.292475
  validation loss:		2.238868
  validation accuracy:		12.50 %
Epoch 78 of 2000 took 0.097s
  training loss:		2.291199
  validation loss:		2.238270
  validation accuracy:		17.17 %
Epoch 79 of 2000 took 0.097s
  training loss:		2.293456
  validation loss:		2.244309
  validation accuracy:		13.26 %
Epoch 80 of 2000 took 0.097s
  training loss:		2.292616
  validation loss:		2.239738
  validation accuracy:		12.93 %
Epoch 81 of 2000 took 0.097s
  training loss:		2.293011
  validation loss:		2.239214
  validation accuracy:		12.83 %
Epoch 82 of 2000 took 0.097s
  training loss:		2.292322
  validation loss:		2.238085
  validation accuracy:		13.26 %
Epoch 83 of 2000 took 0.097s
  training loss:		2.292262
  validation loss:		2.240185
  validation accuracy:		13.26 %
Epoch 84 of 2000 took 0.097s
  training loss:		2.292155
  validation loss:		2.243083
  validation accuracy:		12.93 %
Epoch 85 of 2000 took 0.097s
  training loss:		2.292860
  validation loss:		2.243829
  validation accuracy:		13.26 %
Epoch 86 of 2000 took 0.097s
  training loss:		2.291726
  validation loss:		2.240691
  validation accuracy:		13.04 %
Epoch 87 of 2000 took 0.097s
  training loss:		2.292626
  validation loss:		2.240467
  validation accuracy:		13.91 %
Epoch 88 of 2000 took 0.097s
  training loss:		2.292435
  validation loss:		2.242573
  validation accuracy:		12.83 %
Epoch 89 of 2000 took 0.097s
  training loss:		2.291895
  validation loss:		2.241275
  validation accuracy:		14.13 %
Epoch 90 of 2000 took 0.097s
  training loss:		2.291638
  validation loss:		2.240115
  validation accuracy:		12.93 %
Epoch 91 of 2000 took 0.097s
  training loss:		2.292830
  validation loss:		2.240296
  validation accuracy:		13.59 %
Epoch 92 of 2000 took 0.097s
  training loss:		2.291119
  validation loss:		2.243613
  validation accuracy:		17.39 %
Epoch 93 of 2000 took 0.097s
  training loss:		2.290771
  validation loss:		2.241109
  validation accuracy:		13.04 %
Epoch 94 of 2000 took 0.097s
  training loss:		2.290500
  validation loss:		2.236175
  validation accuracy:		10.87 %
Epoch 95 of 2000 took 0.097s
  training loss:		2.290479
  validation loss:		2.234763
  validation accuracy:		14.46 %
Epoch 96 of 2000 took 0.097s
  training loss:		2.291806
  validation loss:		2.238391
  validation accuracy:		13.04 %
Epoch 97 of 2000 took 0.097s
  training loss:		2.290887
  validation loss:		2.238102
  validation accuracy:		11.52 %
Epoch 98 of 2000 took 0.097s
  training loss:		2.291234
  validation loss:		2.239763
  validation accuracy:		16.20 %
Epoch 99 of 2000 took 0.097s
  training loss:		2.291670
  validation loss:		2.240688
  validation accuracy:		13.26 %
Epoch 100 of 2000 took 0.098s
  training loss:		2.291055
  validation loss:		2.240814
  validation accuracy:		12.17 %
Epoch 101 of 2000 took 0.097s
  training loss:		2.291224
  validation loss:		2.239953
  validation accuracy:		13.04 %
Epoch 102 of 2000 took 0.097s
  training loss:		2.290162
  validation loss:		2.235877
  validation accuracy:		12.72 %
Epoch 103 of 2000 took 0.097s
  training loss:		2.290708
  validation loss:		2.240160
  validation accuracy:		17.50 %
Epoch 104 of 2000 took 0.097s
  training loss:		2.291180
  validation loss:		2.241273
  validation accuracy:		15.33 %
Epoch 105 of 2000 took 0.097s
  training loss:		2.291135
  validation loss:		2.239005
  validation accuracy:		12.83 %
Epoch 106 of 2000 took 0.097s
  training loss:		2.291399
  validation loss:		2.240962
  validation accuracy:		19.24 %
Epoch 107 of 2000 took 0.097s
  training loss:		2.291175
  validation loss:		2.238476
  validation accuracy:		14.78 %
Epoch 108 of 2000 took 0.097s
  training loss:		2.291042
  validation loss:		2.233410
  validation accuracy:		12.93 %
Epoch 109 of 2000 took 0.100s
  training loss:		2.289448
  validation loss:		2.238341
  validation accuracy:		13.37 %
Epoch 110 of 2000 took 0.097s
  training loss:		2.290772
  validation loss:		2.239813
  validation accuracy:		16.96 %
Epoch 111 of 2000 took 0.097s
  training loss:		2.290210
  validation loss:		2.236316
  validation accuracy:		13.37 %
Epoch 112 of 2000 took 0.097s
  training loss:		2.288807
  validation loss:		2.235975
  validation accuracy:		20.11 %
Epoch 113 of 2000 took 0.097s
  training loss:		2.290634
  validation loss:		2.240868
  validation accuracy:		12.07 %
Epoch 114 of 2000 took 0.097s
  training loss:		2.291248
  validation loss:		2.236498
  validation accuracy:		13.37 %
Epoch 115 of 2000 took 0.097s
  training loss:		2.290240
  validation loss:		2.242482
  validation accuracy:		13.91 %
Epoch 116 of 2000 took 0.097s
  training loss:		2.290125
  validation loss:		2.235721
  validation accuracy:		14.67 %
Epoch 117 of 2000 took 0.097s
  training loss:		2.289393
  validation loss:		2.234058
  validation accuracy:		16.30 %
Epoch 118 of 2000 took 0.097s
  training loss:		2.289452
  validation loss:		2.239437
  validation accuracy:		12.39 %
Epoch 119 of 2000 took 0.097s
  training loss:		2.289562
  validation loss:		2.237256
  validation accuracy:		12.50 %
Epoch 120 of 2000 took 0.097s
  training loss:		2.288988
  validation loss:		2.233746
  validation accuracy:		13.59 %
Epoch 121 of 2000 took 0.097s
  training loss:		2.288780
  validation loss:		2.238326
  validation accuracy:		14.57 %
Epoch 122 of 2000 took 0.097s
  training loss:		2.288997
  validation loss:		2.236025
  validation accuracy:		12.28 %
Epoch 123 of 2000 took 0.097s
  training loss:		2.289214
  validation loss:		2.237981
  validation accuracy:		17.39 %
Epoch 124 of 2000 took 0.097s
  training loss:		2.289563
  validation loss:		2.234351
  validation accuracy:		9.35 %
Epoch 125 of 2000 took 0.097s
  training loss:		2.286688
  validation loss:		2.234630
  validation accuracy:		11.74 %
Epoch 126 of 2000 took 0.097s
  training loss:		2.288568
  validation loss:		2.234358
  validation accuracy:		13.70 %
Epoch 127 of 2000 took 0.097s
  training loss:		2.288019
  validation loss:		2.229116
  validation accuracy:		13.15 %
Epoch 128 of 2000 took 0.097s
  training loss:		2.289269
  validation loss:		2.238951
  validation accuracy:		13.26 %
Epoch 129 of 2000 took 0.097s
  training loss:		2.288535
  validation loss:		2.238754
  validation accuracy:		13.15 %
Epoch 130 of 2000 took 0.097s
  training loss:		2.288629
  validation loss:		2.237225
  validation accuracy:		13.37 %
Epoch 131 of 2000 took 0.098s
  training loss:		2.288540
  validation loss:		2.238015
  validation accuracy:		13.26 %
Epoch 132 of 2000 took 0.097s
  training loss:		2.287631
  validation loss:		2.235549
  validation accuracy:		13.26 %
Epoch 133 of 2000 took 0.097s
  training loss:		2.287481
  validation loss:		2.232597
  validation accuracy:		13.59 %
Epoch 134 of 2000 took 0.097s
  training loss:		2.287312
  validation loss:		2.234437
  validation accuracy:		13.15 %
Epoch 135 of 2000 took 0.097s
  training loss:		2.288614
  validation loss:		2.241806
  validation accuracy:		13.26 %
Epoch 136 of 2000 took 0.097s
  training loss:		2.287483
  validation loss:		2.235382
  validation accuracy:		13.48 %
Epoch 137 of 2000 took 0.097s
  training loss:		2.287659
  validation loss:		2.235167
  validation accuracy:		13.37 %
Epoch 138 of 2000 took 0.097s
  training loss:		2.287087
  validation loss:		2.236730
  validation accuracy:		14.46 %
Epoch 139 of 2000 took 0.097s
  training loss:		2.286498
  validation loss:		2.236717
  validation accuracy:		13.70 %
Epoch 140 of 2000 took 0.097s
  training loss:		2.286930
  validation loss:		2.233608
  validation accuracy:		16.74 %
Epoch 141 of 2000 took 0.097s
  training loss:		2.285987
  validation loss:		2.234061
  validation accuracy:		17.93 %
Epoch 142 of 2000 took 0.097s
  training loss:		2.286256
  validation loss:		2.231291
  validation accuracy:		15.54 %
Epoch 143 of 2000 took 0.097s
  training loss:		2.286736
  validation loss:		2.234930
  validation accuracy:		13.37 %
Epoch 144 of 2000 took 0.097s
  training loss:		2.285971
  validation loss:		2.230985
  validation accuracy:		13.91 %
Epoch 145 of 2000 took 0.097s
  training loss:		2.287280
  validation loss:		2.235469
  validation accuracy:		13.26 %
Epoch 146 of 2000 took 0.097s
  training loss:		2.287537
  validation loss:		2.240709
  validation accuracy:		13.91 %
Epoch 147 of 2000 took 0.097s
  training loss:		2.286164
  validation loss:		2.230889
  validation accuracy:		16.41 %
Epoch 148 of 2000 took 0.097s
  training loss:		2.285222
  validation loss:		2.233329
  validation accuracy:		14.89 %
Epoch 149 of 2000 took 0.097s
  training loss:		2.285140
  validation loss:		2.231602
  validation accuracy:		14.13 %
Epoch 150 of 2000 took 0.097s
  training loss:		2.284493
  validation loss:		2.229029
  validation accuracy:		12.83 %
Epoch 151 of 2000 took 0.097s
  training loss:		2.284881
  validation loss:		2.230630
  validation accuracy:		14.89 %
Epoch 152 of 2000 took 0.097s
  training loss:		2.284739
  validation loss:		2.234611
  validation accuracy:		19.13 %
Epoch 153 of 2000 took 0.097s
  training loss:		2.283917
  validation loss:		2.231073
  validation accuracy:		15.33 %
Epoch 154 of 2000 took 0.097s
  training loss:		2.283987
  validation loss:		2.232109
  validation accuracy:		13.15 %
Epoch 155 of 2000 took 0.097s
  training loss:		2.283159
  validation loss:		2.229376
  validation accuracy:		14.67 %
Epoch 156 of 2000 took 0.097s
  training loss:		2.283455
  validation loss:		2.229644
  validation accuracy:		13.80 %
Epoch 157 of 2000 took 0.097s
  training loss:		2.282432
  validation loss:		2.229059
  validation accuracy:		14.24 %
Epoch 158 of 2000 took 0.097s
  training loss:		2.283214
  validation loss:		2.227868
  validation accuracy:		13.59 %
Epoch 159 of 2000 took 0.097s
  training loss:		2.282828
  validation loss:		2.228142
  validation accuracy:		14.13 %
Epoch 160 of 2000 took 0.097s
  training loss:		2.282646
  validation loss:		2.233358
  validation accuracy:		13.91 %
Epoch 161 of 2000 took 0.097s
  training loss:		2.283763
  validation loss:		2.234761
  validation accuracy:		15.11 %
Epoch 162 of 2000 took 0.098s
  training loss:		2.281493
  validation loss:		2.227783
  validation accuracy:		18.15 %
Epoch 163 of 2000 took 0.097s
  training loss:		2.281913
  validation loss:		2.227989
  validation accuracy:		13.59 %
Epoch 164 of 2000 took 0.097s
  training loss:		2.281636
  validation loss:		2.229819
  validation accuracy:		15.76 %
Epoch 165 of 2000 took 0.097s
  training loss:		2.280420
  validation loss:		2.229864
  validation accuracy:		14.46 %
Epoch 166 of 2000 took 0.097s
  training loss:		2.280387
  validation loss:		2.225773
  validation accuracy:		17.83 %
Epoch 167 of 2000 took 0.097s
  training loss:		2.281148
  validation loss:		2.224975
  validation accuracy:		14.67 %
Epoch 168 of 2000 took 0.097s
  training loss:		2.279325
  validation loss:		2.226129
  validation accuracy:		19.13 %
Epoch 169 of 2000 took 0.097s
  training loss:		2.279464
  validation loss:		2.226612
  validation accuracy:		12.50 %
Epoch 170 of 2000 took 0.097s
  training loss:		2.279532
  validation loss:		2.224706
  validation accuracy:		24.24 %
Epoch 171 of 2000 took 0.097s
  training loss:		2.278872
  validation loss:		2.227403
  validation accuracy:		19.78 %
Epoch 172 of 2000 took 0.097s
  training loss:		2.278575
  validation loss:		2.225255
  validation accuracy:		15.54 %
Epoch 173 of 2000 took 0.097s
  training loss:		2.277513
  validation loss:		2.221892
  validation accuracy:		20.54 %
Epoch 174 of 2000 took 0.097s
  training loss:		2.277646
  validation loss:		2.218630
  validation accuracy:		22.28 %
Epoch 175 of 2000 took 0.097s
  training loss:		2.277134
  validation loss:		2.225628
  validation accuracy:		20.33 %
Epoch 176 of 2000 took 0.097s
  training loss:		2.277493
  validation loss:		2.225040
  validation accuracy:		15.33 %
Epoch 177 of 2000 took 0.097s
  training loss:		2.274948
  validation loss:		2.220856
  validation accuracy:		15.65 %
Epoch 178 of 2000 took 0.097s
  training loss:		2.276701
  validation loss:		2.220880
  validation accuracy:		23.80 %
Epoch 179 of 2000 took 0.097s
  training loss:		2.275471
  validation loss:		2.222495
  validation accuracy:		17.17 %
Epoch 180 of 2000 took 0.097s
  training loss:		2.275393
  validation loss:		2.226870
  validation accuracy:		15.22 %
Epoch 181 of 2000 took 0.097s
  training loss:		2.274119
  validation loss:		2.222249
  validation accuracy:		23.91 %
Epoch 182 of 2000 took 0.097s
  training loss:		2.273445
  validation loss:		2.218454
  validation accuracy:		14.89 %
Epoch 183 of 2000 took 0.097s
  training loss:		2.273535
  validation loss:		2.218246
  validation accuracy:		16.74 %
Epoch 184 of 2000 took 0.097s
  training loss:		2.271793
  validation loss:		2.216905
  validation accuracy:		20.33 %
Epoch 185 of 2000 took 0.097s
  training loss:		2.273507
  validation loss:		2.220469
  validation accuracy:		16.30 %
Epoch 186 of 2000 took 0.097s
  training loss:		2.270107
  validation loss:		2.212023
  validation accuracy:		21.20 %
Epoch 187 of 2000 took 0.097s
  training loss:		2.270595
  validation loss:		2.218434
  validation accuracy:		17.93 %
Epoch 188 of 2000 took 0.097s
  training loss:		2.270270
  validation loss:		2.212792
  validation accuracy:		20.98 %
Epoch 189 of 2000 took 0.097s
  training loss:		2.267600
  validation loss:		2.211280
  validation accuracy:		19.35 %
Epoch 190 of 2000 took 0.097s
  training loss:		2.267432
  validation loss:		2.214400
  validation accuracy:		25.33 %
Epoch 191 of 2000 took 0.097s
  training loss:		2.267554
  validation loss:		2.215225
  validation accuracy:		22.39 %
Epoch 192 of 2000 took 0.097s
  training loss:		2.265402
  validation loss:		2.212998
  validation accuracy:		20.87 %
Epoch 193 of 2000 took 0.098s
  training loss:		2.264242
  validation loss:		2.208320
  validation accuracy:		19.78 %
Epoch 194 of 2000 took 0.097s
  training loss:		2.262603
  validation loss:		2.205097
  validation accuracy:		20.98 %
Epoch 195 of 2000 took 0.097s
  training loss:		2.262833
  validation loss:		2.206267
  validation accuracy:		23.26 %
Epoch 196 of 2000 took 0.097s
  training loss:		2.260229
  validation loss:		2.204942
  validation accuracy:		23.48 %
Epoch 197 of 2000 took 0.097s
  training loss:		2.258662
  validation loss:		2.205332
  validation accuracy:		22.17 %
Epoch 198 of 2000 took 0.097s
  training loss:		2.256903
  validation loss:		2.201744
  validation accuracy:		25.54 %
Epoch 199 of 2000 took 0.097s
  training loss:		2.255543
  validation loss:		2.197955
  validation accuracy:		21.74 %
Epoch 200 of 2000 took 0.097s
  training loss:		2.254230
  validation loss:		2.199448
  validation accuracy:		32.72 %
Epoch 201 of 2000 took 0.097s
  training loss:		2.252142
  validation loss:		2.195261
  validation accuracy:		30.65 %
Epoch 202 of 2000 took 0.097s
  training loss:		2.250182
  validation loss:		2.194109
  validation accuracy:		21.85 %
Epoch 203 of 2000 took 0.097s
  training loss:		2.247543
  validation loss:		2.190311
  validation accuracy:		27.83 %
Epoch 204 of 2000 took 0.097s
  training loss:		2.245885
  validation loss:		2.185469
  validation accuracy:		25.43 %
Epoch 205 of 2000 took 0.097s
  training loss:		2.242927
  validation loss:		2.185127
  validation accuracy:		29.67 %
Epoch 206 of 2000 took 0.097s
  training loss:		2.239460
  validation loss:		2.182706
  validation accuracy:		26.52 %
Epoch 207 of 2000 took 0.097s
  training loss:		2.237361
  validation loss:		2.178380
  validation accuracy:		26.74 %
Epoch 208 of 2000 took 0.097s
  training loss:		2.233501
  validation loss:		2.177826
  validation accuracy:		29.13 %
Epoch 209 of 2000 took 0.097s
  training loss:		2.228006
  validation loss:		2.169837
  validation accuracy:		29.13 %
Epoch 210 of 2000 took 0.097s
  training loss:		2.223975
  validation loss:		2.163932
  validation accuracy:		30.43 %
Epoch 211 of 2000 took 0.097s
  training loss:		2.218272
  validation loss:		2.156827
  validation accuracy:		28.70 %
Epoch 212 of 2000 took 0.097s
  training loss:		2.211950
  validation loss:		2.152167
  validation accuracy:		29.46 %
Epoch 213 of 2000 took 0.100s
  training loss:		2.205298
  validation loss:		2.145697
  validation accuracy:		30.98 %
Epoch 214 of 2000 took 0.097s
  training loss:		2.200284
  validation loss:		2.134363
  validation accuracy:		30.11 %
Epoch 215 of 2000 took 0.097s
  training loss:		2.189178
  validation loss:		2.126422
  validation accuracy:		32.61 %
Epoch 216 of 2000 took 0.097s
  training loss:		2.177107
  validation loss:		2.114534
  validation accuracy:		29.35 %
Epoch 217 of 2000 took 0.097s
  training loss:		2.169364
  validation loss:		2.099440
  validation accuracy:		30.43 %
Epoch 218 of 2000 took 0.097s
  training loss:		2.153282
  validation loss:		2.084557
  validation accuracy:		30.87 %
Epoch 219 of 2000 took 0.097s
  training loss:		2.138047
  validation loss:		2.069185
  validation accuracy:		29.78 %
Epoch 220 of 2000 took 0.097s
  training loss:		2.118567
  validation loss:		2.046038
  validation accuracy:		29.78 %
Epoch 221 of 2000 took 0.097s
  training loss:		2.101713
  validation loss:		2.024400
  validation accuracy:		29.78 %
Epoch 222 of 2000 took 0.097s
  training loss:		2.081098
  validation loss:		2.000743
  validation accuracy:		30.98 %
Epoch 223 of 2000 took 0.097s
  training loss:		2.057475
  validation loss:		1.976841
  validation accuracy:		30.65 %
Epoch 224 of 2000 took 0.098s
  training loss:		2.039450
  validation loss:		1.954317
  validation accuracy:		30.87 %
Epoch 225 of 2000 took 0.097s
  training loss:		2.014303
  validation loss:		1.928904
  validation accuracy:		31.09 %
Epoch 226 of 2000 took 0.097s
  training loss:		1.990446
  validation loss:		1.907657
  validation accuracy:		31.52 %
Epoch 227 of 2000 took 0.097s
  training loss:		1.969647
  validation loss:		1.882318
  validation accuracy:		31.85 %
Epoch 228 of 2000 took 0.097s
  training loss:		1.945700
  validation loss:		1.860089
  validation accuracy:		32.93 %
Epoch 229 of 2000 took 0.097s
  training loss:		1.920388
  validation loss:		1.837430
  validation accuracy:		32.50 %
Epoch 230 of 2000 took 0.097s
  training loss:		1.902909
  validation loss:		1.815087
  validation accuracy:		34.57 %
Epoch 231 of 2000 took 0.097s
  training loss:		1.877246
  validation loss:		1.791166
  validation accuracy:		34.57 %
Epoch 232 of 2000 took 0.097s
  training loss:		1.853577
  validation loss:		1.767097
  validation accuracy:		36.09 %
Epoch 233 of 2000 took 0.097s
  training loss:		1.832341
  validation loss:		1.747075
  validation accuracy:		35.87 %
Epoch 234 of 2000 took 0.097s
  training loss:		1.813155
  validation loss:		1.725351
  validation accuracy:		36.41 %
Epoch 235 of 2000 took 0.097s
  training loss:		1.790959
  validation loss:		1.703704
  validation accuracy:		37.17 %
Epoch 236 of 2000 took 0.097s
  training loss:		1.760652
  validation loss:		1.678481
  validation accuracy:		39.13 %
Epoch 237 of 2000 took 0.098s
  training loss:		1.732614
  validation loss:		1.654719
  validation accuracy:		43.59 %
Epoch 238 of 2000 took 0.100s
  training loss:		1.714134
  validation loss:		1.634037
  validation accuracy:		43.80 %
Epoch 239 of 2000 took 0.100s
  training loss:		1.687562
  validation loss:		1.620115
  validation accuracy:		39.57 %
Epoch 240 of 2000 took 0.100s
  training loss:		1.670335
  validation loss:		1.595462
  validation accuracy:		40.98 %
Epoch 241 of 2000 took 0.100s
  training loss:		1.652262
  validation loss:		1.576269
  validation accuracy:		39.78 %
Epoch 242 of 2000 took 0.100s
  training loss:		1.628745
  validation loss:		1.560418
  validation accuracy:		42.93 %
Epoch 243 of 2000 took 0.100s
  training loss:		1.611539
  validation loss:		1.548146
  validation accuracy:		42.83 %
Epoch 244 of 2000 took 0.100s
  training loss:		1.595918
  validation loss:		1.526353
  validation accuracy:		42.39 %
Epoch 245 of 2000 took 0.100s
  training loss:		1.579321
  validation loss:		1.530122
  validation accuracy:		41.74 %
Epoch 246 of 2000 took 0.100s
  training loss:		1.562581
  validation loss:		1.499912
  validation accuracy:		44.57 %
Epoch 247 of 2000 took 0.100s
  training loss:		1.545168
  validation loss:		1.482925
  validation accuracy:		43.26 %
Epoch 248 of 2000 took 0.100s
  training loss:		1.532393
  validation loss:		1.470389
  validation accuracy:		45.22 %
Epoch 249 of 2000 took 0.100s
  training loss:		1.516338
  validation loss:		1.462940
  validation accuracy:		45.22 %
Epoch 250 of 2000 took 0.100s
  training loss:		1.506957
  validation loss:		1.445831
  validation accuracy:		46.41 %
Epoch 251 of 2000 took 0.100s
  training loss:		1.491126
  validation loss:		1.452538
  validation accuracy:		44.57 %
Epoch 252 of 2000 took 0.100s
  training loss:		1.479740
  validation loss:		1.425479
  validation accuracy:		44.89 %
Epoch 253 of 2000 took 0.100s
  training loss:		1.469908
  validation loss:		1.415645
  validation accuracy:		45.87 %
Epoch 254 of 2000 took 0.100s
  training loss:		1.457963
  validation loss:		1.420578
  validation accuracy:		43.37 %
Epoch 255 of 2000 took 0.101s
  training loss:		1.450893
  validation loss:		1.398162
  validation accuracy:		47.07 %
Epoch 256 of 2000 took 0.100s
  training loss:		1.438835
  validation loss:		1.388265
  validation accuracy:		48.15 %
Epoch 257 of 2000 took 0.100s
  training loss:		1.442751
  validation loss:		1.385832
  validation accuracy:		45.98 %
Epoch 258 of 2000 took 0.100s
  training loss:		1.423715
  validation loss:		1.378275
  validation accuracy:		46.20 %
Epoch 259 of 2000 took 0.100s
  training loss:		1.418324
  validation loss:		1.371459
  validation accuracy:		48.04 %
Epoch 260 of 2000 took 0.100s
  training loss:		1.436114
  validation loss:		1.416675
  validation accuracy:		43.37 %
Epoch 261 of 2000 took 0.100s
  training loss:		1.429943
  validation loss:		1.402713
  validation accuracy:		46.74 %
Epoch 262 of 2000 took 0.100s
  training loss:		1.415446
  validation loss:		1.384362
  validation accuracy:		47.28 %
Epoch 263 of 2000 took 0.100s
  training loss:		1.462895
  validation loss:		1.430847
  validation accuracy:		46.20 %
Epoch 264 of 2000 took 0.100s
  training loss:		1.426394
  validation loss:		1.371143
  validation accuracy:		49.46 %
Epoch 265 of 2000 took 0.100s
  training loss:		1.409197
  validation loss:		1.495432
  validation accuracy:		43.91 %
Epoch 266 of 2000 took 0.100s
  training loss:		1.458066
  validation loss:		1.344196
  validation accuracy:		47.61 %
Epoch 267 of 2000 took 0.100s
  training loss:		1.398349
  validation loss:		1.442275
  validation accuracy:		44.13 %
Epoch 268 of 2000 took 0.100s
  training loss:		1.423830
  validation loss:		1.343860
  validation accuracy:		48.15 %
Epoch 269 of 2000 took 0.100s
  training loss:		1.371620
  validation loss:		1.348853
  validation accuracy:		47.17 %
Epoch 270 of 2000 took 0.100s
  training loss:		1.371824
  validation loss:		1.343617
  validation accuracy:		48.04 %
Epoch 271 of 2000 took 0.100s
  training loss:		1.372339
  validation loss:		1.343512
  validation accuracy:		46.63 %
Epoch 272 of 2000 took 0.100s
  training loss:		1.379892
  validation loss:		1.432168
  validation accuracy:		46.74 %
Epoch 273 of 2000 took 0.100s
  training loss:		1.503736
  validation loss:		1.340377
  validation accuracy:		48.59 %
Epoch 274 of 2000 took 0.100s
  training loss:		1.367662
  validation loss:		1.330272
  validation accuracy:		46.09 %
Epoch 275 of 2000 took 0.100s
  training loss:		1.353183
  validation loss:		1.320621
  validation accuracy:		46.74 %
Epoch 276 of 2000 took 0.100s
  training loss:		1.365199
  validation loss:		1.394787
  validation accuracy:		43.59 %
Epoch 277 of 2000 took 0.100s
  training loss:		1.422506
  validation loss:		1.383523
  validation accuracy:		45.98 %
Epoch 278 of 2000 took 0.100s
  training loss:		1.359257
  validation loss:		1.319818
  validation accuracy:		48.15 %
Epoch 279 of 2000 took 0.100s
  training loss:		1.338553
  validation loss:		1.319678
  validation accuracy:		47.28 %
Epoch 280 of 2000 took 0.100s
  training loss:		1.484363
  validation loss:		1.622739
  validation accuracy:		39.24 %
Epoch 281 of 2000 took 0.100s
  training loss:		1.490834
  validation loss:		1.345760
  validation accuracy:		48.48 %
Epoch 282 of 2000 took 0.100s
  training loss:		1.337238
  validation loss:		1.319837
  validation accuracy:		46.63 %
Epoch 283 of 2000 took 0.100s
  training loss:		1.333197
  validation loss:		1.303655
  validation accuracy:		46.74 %
Epoch 284 of 2000 took 0.100s
  training loss:		1.388343
  validation loss:		1.407590
  validation accuracy:		45.33 %
Epoch 285 of 2000 took 0.101s
  training loss:		1.459088
  validation loss:		1.338670
  validation accuracy:		46.63 %
Epoch 286 of 2000 took 0.100s
  training loss:		1.347349
  validation loss:		1.363553
  validation accuracy:		46.96 %
Epoch 287 of 2000 took 0.100s
  training loss:		1.339174
  validation loss:		1.315620
  validation accuracy:		46.85 %
Epoch 288 of 2000 took 0.100s
  training loss:		1.341103
  validation loss:		1.295484
  validation accuracy:		46.63 %
Epoch 289 of 2000 took 0.100s
  training loss:		1.322858
  validation loss:		1.313100
  validation accuracy:		48.70 %
Epoch 290 of 2000 took 0.100s
  training loss:		1.317915
  validation loss:		1.369596
  validation accuracy:		47.07 %
Epoch 291 of 2000 took 0.100s
  training loss:		1.327318
  validation loss:		1.291962
  validation accuracy:		48.70 %
Epoch 292 of 2000 took 0.100s
  training loss:		1.337674
  validation loss:		1.322615
  validation accuracy:		46.96 %
Epoch 293 of 2000 took 0.100s
  training loss:		1.618554
  validation loss:		1.672642
  validation accuracy:		38.04 %
Epoch 294 of 2000 took 0.100s
  training loss:		1.404926
  validation loss:		1.316072
  validation accuracy:		51.52 %
Epoch 295 of 2000 took 0.100s
  training loss:		1.322621
  validation loss:		1.300640
  validation accuracy:		48.48 %
Epoch 296 of 2000 took 0.100s
  training loss:		1.322901
  validation loss:		1.361964
  validation accuracy:		46.96 %
Epoch 297 of 2000 took 0.100s
  training loss:		1.321820
  validation loss:		1.289490
  validation accuracy:		48.59 %
Epoch 298 of 2000 took 0.100s
  training loss:		1.311717
  validation loss:		1.301885
  validation accuracy:		50.87 %
Epoch 299 of 2000 took 0.100s
  training loss:		1.317912
  validation loss:		1.281996
  validation accuracy:		49.13 %
Epoch 300 of 2000 took 0.100s
  training loss:		1.302707
  validation loss:		1.431069
  validation accuracy:		46.85 %
Epoch 301 of 2000 took 0.100s
  training loss:		1.315749
  validation loss:		1.277446
  validation accuracy:		52.93 %
Epoch 302 of 2000 took 0.100s
  training loss:		1.362115
  validation loss:		1.694015
  validation accuracy:		38.04 %
Epoch 303 of 2000 took 0.100s
  training loss:		1.534224
  validation loss:		1.360245
  validation accuracy:		49.35 %
Epoch 304 of 2000 took 0.100s
  training loss:		1.330202
  validation loss:		1.291321
  validation accuracy:		52.39 %
Epoch 305 of 2000 took 0.100s
  training loss:		1.297142
  validation loss:		1.292248
  validation accuracy:		52.17 %
Epoch 306 of 2000 took 0.100s
  training loss:		1.291902
  validation loss:		1.281358
  validation accuracy:		51.74 %
Epoch 307 of 2000 took 0.100s
  training loss:		1.289697
  validation loss:		1.267025
  validation accuracy:		53.70 %
Epoch 308 of 2000 took 0.100s
  training loss:		1.294660
  validation loss:		1.265040
  validation accuracy:		54.46 %
Epoch 309 of 2000 took 0.100s
  training loss:		1.335439
  validation loss:		1.289247
  validation accuracy:		53.91 %
Epoch 310 of 2000 took 0.100s
  training loss:		1.283156
  validation loss:		1.265376
  validation accuracy:		54.57 %
Epoch 311 of 2000 took 0.100s
  training loss:		1.288942
  validation loss:		1.291833
  validation accuracy:		52.61 %
Epoch 312 of 2000 took 0.100s
  training loss:		1.343260
  validation loss:		1.289209
  validation accuracy:		53.91 %
Epoch 313 of 2000 took 0.100s
  training loss:		1.327813
  validation loss:		1.402823
  validation accuracy:		48.26 %
Epoch 314 of 2000 took 0.101s
  training loss:		1.279688
  validation loss:		1.264003
  validation accuracy:		55.22 %
Epoch 315 of 2000 took 0.101s
  training loss:		1.263516
  validation loss:		1.244205
  validation accuracy:		55.76 %
Epoch 316 of 2000 took 0.100s
  training loss:		1.296417
  validation loss:		1.324818
  validation accuracy:		52.83 %
Epoch 317 of 2000 took 0.100s
  training loss:		1.372550
  validation loss:		1.307511
  validation accuracy:		53.91 %
Epoch 318 of 2000 took 0.100s
  training loss:		1.259372
  validation loss:		1.237941
  validation accuracy:		57.17 %
Epoch 319 of 2000 took 0.100s
  training loss:		1.247589
  validation loss:		1.245689
  validation accuracy:		56.09 %
Epoch 320 of 2000 took 0.100s
  training loss:		1.299350
  validation loss:		1.223544
  validation accuracy:		59.02 %
Epoch 321 of 2000 took 0.100s
  training loss:		1.262521
  validation loss:		1.403082
  validation accuracy:		49.35 %
Epoch 322 of 2000 took 0.100s
  training loss:		1.262319
  validation loss:		1.211740
  validation accuracy:		60.22 %
Epoch 323 of 2000 took 0.100s
  training loss:		1.253722
  validation loss:		1.253203
  validation accuracy:		57.72 %
Epoch 324 of 2000 took 0.103s
  training loss:		1.228688
  validation loss:		1.213139
  validation accuracy:		59.57 %
Epoch 325 of 2000 took 0.101s
  training loss:		1.230042
  validation loss:		1.256981
  validation accuracy:		57.93 %
Epoch 326 of 2000 took 0.100s
  training loss:		1.228966
  validation loss:		1.204663
  validation accuracy:		60.54 %
Epoch 327 of 2000 took 0.100s
  training loss:		1.230234
  validation loss:		1.174812
  validation accuracy:		62.83 %
Epoch 328 of 2000 took 0.100s
  training loss:		1.208528
  validation loss:		1.177866
  validation accuracy:		62.61 %
Epoch 329 of 2000 took 0.100s
  training loss:		1.195765
  validation loss:		1.185432
  validation accuracy:		62.28 %
Epoch 330 of 2000 took 0.100s
  training loss:		1.187155
  validation loss:		1.171484
  validation accuracy:		63.37 %
Epoch 331 of 2000 took 0.100s
  training loss:		1.182081
  validation loss:		1.188596
  validation accuracy:		62.39 %
Epoch 332 of 2000 took 0.100s
  training loss:		1.211045
  validation loss:		1.133739
  validation accuracy:		66.09 %
Epoch 333 of 2000 took 0.100s
  training loss:		1.175246
  validation loss:		1.111151
  validation accuracy:		66.09 %
Epoch 334 of 2000 took 0.100s
  training loss:		1.170591
  validation loss:		1.208819
  validation accuracy:		61.41 %
Epoch 335 of 2000 took 0.100s
  training loss:		1.199025
  validation loss:		1.087324
  validation accuracy:		68.37 %
Epoch 336 of 2000 took 0.100s
  training loss:		1.127766
  validation loss:		1.138166
  validation accuracy:		65.22 %
Epoch 337 of 2000 took 0.100s
  training loss:		1.104305
  validation loss:		1.053793
  validation accuracy:		69.35 %
Epoch 338 of 2000 took 0.100s
  training loss:		1.100908
  validation loss:		1.120172
  validation accuracy:		65.00 %
Epoch 339 of 2000 took 0.100s
  training loss:		1.087310
  validation loss:		1.031689
  validation accuracy:		70.33 %
Epoch 340 of 2000 took 0.100s
  training loss:		1.086641
  validation loss:		1.045236
  validation accuracy:		69.24 %
Epoch 341 of 2000 took 0.100s
  training loss:		1.056732
  validation loss:		0.999558
  validation accuracy:		72.07 %
Epoch 342 of 2000 took 0.100s
  training loss:		1.045172
  validation loss:		0.986822
  validation accuracy:		71.41 %
Epoch 343 of 2000 took 0.100s
  training loss:		1.024777
  validation loss:		0.984646
  validation accuracy:		72.07 %
Epoch 344 of 2000 took 0.100s
  training loss:		1.034655
  validation loss:		0.958097
  validation accuracy:		72.61 %
Epoch 345 of 2000 took 0.101s
  training loss:		1.017164
  validation loss:		0.938191
  validation accuracy:		73.15 %
Epoch 346 of 2000 took 0.100s
  training loss:		1.003994
  validation loss:		0.995261
  validation accuracy:		71.96 %
Epoch 347 of 2000 took 0.100s
  training loss:		1.014256
  validation loss:		0.915752
  validation accuracy:		74.13 %
Epoch 348 of 2000 took 0.100s
  training loss:		0.965497
  validation loss:		0.921407
  validation accuracy:		74.57 %
Epoch 349 of 2000 took 0.100s
  training loss:		0.977627
  validation loss:		0.892956
  validation accuracy:		74.67 %
Epoch 350 of 2000 took 0.100s
  training loss:		0.950419
  validation loss:		0.915690
  validation accuracy:		74.78 %
Epoch 351 of 2000 took 0.100s
  training loss:		0.949860
  validation loss:		0.873714
  validation accuracy:		75.65 %
Epoch 352 of 2000 took 0.100s
  training loss:		0.926105
  validation loss:		0.862179
  validation accuracy:		76.09 %
Epoch 353 of 2000 took 0.100s
  training loss:		0.918947
  validation loss:		0.855738
  validation accuracy:		75.98 %
Epoch 354 of 2000 took 0.100s
  training loss:		0.910277
  validation loss:		0.863128
  validation accuracy:		75.65 %
Epoch 355 of 2000 took 0.100s
  training loss:		0.904398
  validation loss:		0.837637
  validation accuracy:		75.98 %
Epoch 356 of 2000 took 0.100s
  training loss:		0.892238
  validation loss:		0.829988
  validation accuracy:		75.65 %
Epoch 357 of 2000 took 0.099s
  training loss:		0.886978
  validation loss:		0.820696
  validation accuracy:		75.11 %
Epoch 358 of 2000 took 0.097s
  training loss:		0.876146
  validation loss:		0.820734
  validation accuracy:		76.09 %
Epoch 359 of 2000 took 0.097s
  training loss:		0.869029
  validation loss:		0.833461
  validation accuracy:		75.65 %
Epoch 360 of 2000 took 0.097s
  training loss:		0.856627
  validation loss:		0.809282
  validation accuracy:		76.52 %
Epoch 361 of 2000 took 0.097s
  training loss:		0.839781
  validation loss:		0.790640
  validation accuracy:		76.85 %
Epoch 362 of 2000 took 0.097s
  training loss:		0.836217
  validation loss:		0.797407
  validation accuracy:		77.07 %
Epoch 363 of 2000 took 0.097s
  training loss:		0.826160
  validation loss:		0.844390
  validation accuracy:		75.00 %
Epoch 364 of 2000 took 0.097s
  training loss:		0.826851
  validation loss:		0.805791
  validation accuracy:		76.30 %
Epoch 365 of 2000 took 0.097s
  training loss:		0.817542
  validation loss:		0.779693
  validation accuracy:		76.74 %
Epoch 366 of 2000 took 0.097s
  training loss:		0.798778
  validation loss:		0.767128
  validation accuracy:		76.52 %
Epoch 367 of 2000 took 0.097s
  training loss:		0.801712
  validation loss:		0.755503
  validation accuracy:		77.07 %
Epoch 368 of 2000 took 0.097s
  training loss:		0.787077
  validation loss:		0.762281
  validation accuracy:		77.07 %
Epoch 369 of 2000 took 0.097s
  training loss:		0.780077
  validation loss:		0.749005
  validation accuracy:		76.63 %
Epoch 370 of 2000 took 0.097s
  training loss:		0.776706
  validation loss:		0.740266
  validation accuracy:		77.50 %
Epoch 371 of 2000 took 0.097s
  training loss:		0.764446
  validation loss:		0.752429
  validation accuracy:		77.72 %
Epoch 372 of 2000 took 0.097s
  training loss:		0.751103
  validation loss:		0.725349
  validation accuracy:		77.39 %
Epoch 373 of 2000 took 0.097s
  training loss:		0.759771
  validation loss:		0.750022
  validation accuracy:		77.93 %
Epoch 374 of 2000 took 0.097s
  training loss:		0.751299
  validation loss:		0.744679
  validation accuracy:		78.04 %
Epoch 375 of 2000 took 0.097s
  training loss:		0.737337
  validation loss:		0.748586
  validation accuracy:		77.61 %
Epoch 376 of 2000 took 0.098s
  training loss:		0.730769
  validation loss:		0.702366
  validation accuracy:		77.83 %
Epoch 377 of 2000 took 0.097s
  training loss:		0.728642
  validation loss:		0.701228
  validation accuracy:		77.93 %
Epoch 378 of 2000 took 0.097s
  training loss:		0.717712
  validation loss:		0.699770
  validation accuracy:		78.15 %
Epoch 379 of 2000 took 0.097s
  training loss:		0.716521
  validation loss:		0.691017
  validation accuracy:		77.83 %
Epoch 380 of 2000 took 0.097s
  training loss:		0.709257
  validation loss:		0.695690
  validation accuracy:		78.26 %
Epoch 381 of 2000 took 0.097s
  training loss:		0.706307
  validation loss:		0.687504
  validation accuracy:		78.26 %
Epoch 382 of 2000 took 0.097s
  training loss:		0.693954
  validation loss:		0.730559
  validation accuracy:		78.15 %
Epoch 383 of 2000 took 0.097s
  training loss:		0.693051
  validation loss:		0.678417
  validation accuracy:		78.37 %
Epoch 384 of 2000 took 0.097s
  training loss:		0.677128
  validation loss:		0.685137
  validation accuracy:		78.91 %
Epoch 385 of 2000 took 0.097s
  training loss:		0.683882
  validation loss:		0.676844
  validation accuracy:		78.91 %
Epoch 386 of 2000 took 0.097s
  training loss:		0.677377
  validation loss:		0.711388
  validation accuracy:		78.26 %
Epoch 387 of 2000 took 0.097s
  training loss:		0.678281
  validation loss:		0.685741
  validation accuracy:		79.35 %
Epoch 388 of 2000 took 0.097s
  training loss:		0.687616
  validation loss:		0.667231
  validation accuracy:		79.24 %
Epoch 389 of 2000 took 0.097s
  training loss:		0.670368
  validation loss:		0.660101
  validation accuracy:		79.13 %
Epoch 390 of 2000 took 0.097s
  training loss:		0.692546
  validation loss:		0.664712
  validation accuracy:		79.67 %
Epoch 391 of 2000 took 0.097s
  training loss:		0.662454
  validation loss:		0.659064
  validation accuracy:		78.70 %
Epoch 392 of 2000 took 0.097s
  training loss:		0.656357
  validation loss:		0.663534
  validation accuracy:		78.91 %
Epoch 393 of 2000 took 0.097s
  training loss:		0.665448
  validation loss:		0.689426
  validation accuracy:		78.59 %
Epoch 394 of 2000 took 0.097s
  training loss:		0.655588
  validation loss:		0.672063
  validation accuracy:		80.11 %
Epoch 395 of 2000 took 0.097s
  training loss:		0.643613
  validation loss:		0.664150
  validation accuracy:		80.54 %
Epoch 396 of 2000 took 0.097s
  training loss:		0.639484
  validation loss:		0.673198
  validation accuracy:		79.89 %
Epoch 397 of 2000 took 0.097s
  training loss:		0.642265
  validation loss:		0.649040
  validation accuracy:		79.89 %
Epoch 398 of 2000 took 0.097s
  training loss:		0.631630
  validation loss:		0.650570
  validation accuracy:		80.33 %
Epoch 399 of 2000 took 0.097s
  training loss:		0.643626
  validation loss:		0.650643
  validation accuracy:		80.22 %
Epoch 400 of 2000 took 0.097s
  training loss:		0.638655
  validation loss:		0.636000
  validation accuracy:		80.00 %
Epoch 401 of 2000 took 0.097s
  training loss:		0.636268
  validation loss:		0.638463
  validation accuracy:		80.11 %
Epoch 402 of 2000 took 0.097s
  training loss:		0.633123
  validation loss:		0.649237
  validation accuracy:		79.78 %
Epoch 403 of 2000 took 0.097s
  training loss:		0.643973
  validation loss:		0.637365
  validation accuracy:		79.02 %
Epoch 404 of 2000 took 0.097s
  training loss:		0.627977
  validation loss:		0.643136
  validation accuracy:		79.46 %
Epoch 405 of 2000 took 0.097s
  training loss:		0.633503
  validation loss:		0.691148
  validation accuracy:		77.83 %
Epoch 406 of 2000 took 0.097s
  training loss:		0.635283
  validation loss:		0.630914
  validation accuracy:		80.00 %
Epoch 407 of 2000 took 0.098s
  training loss:		0.625593
  validation loss:		0.645836
  validation accuracy:		80.54 %
Epoch 408 of 2000 took 0.097s
  training loss:		0.624182
  validation loss:		0.648530
  validation accuracy:		79.46 %
Epoch 409 of 2000 took 0.097s
  training loss:		0.620933
  validation loss:		0.626362
  validation accuracy:		79.89 %
Epoch 410 of 2000 took 0.097s
  training loss:		0.614040
  validation loss:		0.639668
  validation accuracy:		77.61 %
Epoch 411 of 2000 took 0.097s
  training loss:		0.623394
  validation loss:		0.661140
  validation accuracy:		79.35 %
Epoch 412 of 2000 took 0.097s
  training loss:		0.617468
  validation loss:		0.660568
  validation accuracy:		78.80 %
Epoch 413 of 2000 took 0.097s
  training loss:		0.603635
  validation loss:		0.646418
  validation accuracy:		79.57 %
Epoch 414 of 2000 took 0.097s
  training loss:		0.613254
  validation loss:		0.629528
  validation accuracy:		80.76 %
Epoch 415 of 2000 took 0.097s
  training loss:		0.629374
  validation loss:		0.635629
  validation accuracy:		78.80 %
Epoch 416 of 2000 took 0.097s
  training loss:		0.621004
  validation loss:		0.640558
  validation accuracy:		79.46 %
Epoch 417 of 2000 took 0.097s
  training loss:		0.614601
  validation loss:		0.634001
  validation accuracy:		79.35 %
Epoch 418 of 2000 took 0.097s
  training loss:		0.609591
  validation loss:		0.680310
  validation accuracy:		78.37 %
Epoch 419 of 2000 took 0.097s
  training loss:		0.614295
  validation loss:		0.611954
  validation accuracy:		80.98 %
Epoch 420 of 2000 took 0.097s
  training loss:		0.607709
  validation loss:		0.632781
  validation accuracy:		79.57 %
Epoch 421 of 2000 took 0.097s
  training loss:		0.614323
  validation loss:		0.617829
  validation accuracy:		80.11 %
Epoch 422 of 2000 took 0.097s
  training loss:		0.606896
  validation loss:		0.636937
  validation accuracy:		80.00 %
Epoch 423 of 2000 took 0.097s
  training loss:		0.600365
  validation loss:		0.615967
  validation accuracy:		80.22 %
Epoch 424 of 2000 took 0.097s
  training loss:		0.598789
  validation loss:		0.641440
  validation accuracy:		79.78 %
Epoch 425 of 2000 took 0.097s
  training loss:		0.605578
  validation loss:		0.628117
  validation accuracy:		80.11 %
Epoch 426 of 2000 took 0.097s
  training loss:		0.602333
  validation loss:		0.630330
  validation accuracy:		79.57 %
Epoch 427 of 2000 took 0.097s
  training loss:		0.594570
  validation loss:		0.617395
  validation accuracy:		80.33 %
Epoch 428 of 2000 took 0.097s
  training loss:		0.588212
  validation loss:		0.611166
  validation accuracy:		80.76 %
Epoch 429 of 2000 took 0.097s
  training loss:		0.591362
  validation loss:		0.611432
  validation accuracy:		80.22 %
Epoch 430 of 2000 took 0.097s
  training loss:		0.597040
  validation loss:		0.630524
  validation accuracy:		80.33 %
Epoch 431 of 2000 took 0.097s
  training loss:		0.594359
  validation loss:		0.616403
  validation accuracy:		80.00 %
Epoch 432 of 2000 took 0.097s
  training loss:		0.594164
  validation loss:		0.623184
  validation accuracy:		80.11 %
Epoch 433 of 2000 took 0.097s
  training loss:		0.599007
  validation loss:		0.610890
  validation accuracy:		80.43 %
Epoch 434 of 2000 took 0.097s
  training loss:		0.591915
  validation loss:		0.628022
  validation accuracy:		80.11 %
Epoch 435 of 2000 took 0.097s
  training loss:		0.590692
  validation loss:		0.650260
  validation accuracy:		79.57 %
Epoch 436 of 2000 took 0.097s
  training loss:		0.600362
  validation loss:		0.603810
  validation accuracy:		80.65 %
Epoch 437 of 2000 took 0.097s
  training loss:		0.589396
  validation loss:		0.601313
  validation accuracy:		80.87 %
Epoch 438 of 2000 took 0.098s
  training loss:		0.592834
  validation loss:		0.618116
  validation accuracy:		80.11 %
Epoch 439 of 2000 took 0.097s
  training loss:		0.591289
  validation loss:		0.620253
  validation accuracy:		79.67 %
Epoch 440 of 2000 took 0.097s
  training loss:		0.598989
  validation loss:		0.627447
  validation accuracy:		80.22 %
Epoch 441 of 2000 took 0.097s
  training loss:		0.589871
  validation loss:		0.608002
  validation accuracy:		80.43 %
Epoch 442 of 2000 took 0.097s
  training loss:		0.585618
  validation loss:		0.623936
  validation accuracy:		80.54 %
Epoch 443 of 2000 took 0.097s
  training loss:		0.603974
  validation loss:		0.633047
  validation accuracy:		80.43 %
Epoch 444 of 2000 took 0.097s
  training loss:		0.596473
  validation loss:		0.611840
  validation accuracy:		80.00 %
Epoch 445 of 2000 took 0.097s
  training loss:		0.582159
  validation loss:		0.598175
  validation accuracy:		81.09 %
Epoch 446 of 2000 took 0.097s
  training loss:		0.579880
  validation loss:		0.632333
  validation accuracy:		80.54 %
Epoch 447 of 2000 took 0.097s
  training loss:		0.576325
  validation loss:		0.618539
  validation accuracy:		80.00 %
Epoch 448 of 2000 took 0.097s
  training loss:		0.572347
  validation loss:		0.602017
  validation accuracy:		80.65 %
Epoch 449 of 2000 took 0.100s
  training loss:		0.581003
  validation loss:		0.596018
  validation accuracy:		80.98 %
Epoch 450 of 2000 took 0.097s
  training loss:		0.579303
  validation loss:		0.629564
  validation accuracy:		79.67 %
Epoch 451 of 2000 took 0.097s
  training loss:		0.585441
  validation loss:		0.619856
  validation accuracy:		80.43 %
Epoch 452 of 2000 took 0.097s
  training loss:		0.585878
  validation loss:		0.638699
  validation accuracy:		79.78 %
Epoch 453 of 2000 took 0.097s
  training loss:		0.589687
  validation loss:		0.595706
  validation accuracy:		81.09 %
Epoch 454 of 2000 took 0.097s
  training loss:		0.592138
  validation loss:		0.606538
  validation accuracy:		80.43 %
Epoch 455 of 2000 took 0.097s
  training loss:		0.581570
  validation loss:		0.659235
  validation accuracy:		78.48 %
Epoch 456 of 2000 took 0.097s
  training loss:		0.595743
  validation loss:		0.595209
  validation accuracy:		81.09 %
Epoch 457 of 2000 took 0.098s
  training loss:		0.595423
  validation loss:		0.635418
  validation accuracy:		79.46 %
Epoch 458 of 2000 took 0.097s
  training loss:		0.579991
  validation loss:		0.613646
  validation accuracy:		80.43 %
Epoch 459 of 2000 took 0.097s
  training loss:		0.610431
  validation loss:		0.611821
  validation accuracy:		80.76 %
Epoch 460 of 2000 took 0.097s
  training loss:		0.574584
  validation loss:		0.625559
  validation accuracy:		79.67 %
Epoch 461 of 2000 took 0.097s
  training loss:		0.579951
  validation loss:		0.612808
  validation accuracy:		80.65 %
Epoch 462 of 2000 took 0.097s
  training loss:		0.583318
  validation loss:		0.670961
  validation accuracy:		78.91 %
Epoch 463 of 2000 took 0.097s
  training loss:		0.587412
  validation loss:		0.606436
  validation accuracy:		80.87 %
Epoch 464 of 2000 took 0.097s
  training loss:		0.575141
  validation loss:		0.602679
  validation accuracy:		80.98 %
Epoch 465 of 2000 took 0.097s
  training loss:		0.572151
  validation loss:		0.597809
  validation accuracy:		80.87 %
Epoch 466 of 2000 took 0.097s
  training loss:		0.577557
  validation loss:		0.583957
  validation accuracy:		80.98 %
Epoch 467 of 2000 took 0.097s
  training loss:		0.573453
  validation loss:		0.602217
  validation accuracy:		80.87 %
Epoch 468 of 2000 took 0.097s
  training loss:		0.584628
  validation loss:		0.634004
  validation accuracy:		79.35 %
Epoch 469 of 2000 took 0.098s
  training loss:		0.597514
  validation loss:		0.608258
  validation accuracy:		80.98 %
Epoch 470 of 2000 took 0.097s
  training loss:		0.587780
  validation loss:		0.585376
  validation accuracy:		80.87 %
Epoch 471 of 2000 took 0.097s
  training loss:		0.574322
  validation loss:		0.588958
  validation accuracy:		80.65 %
Epoch 472 of 2000 took 0.097s
  training loss:		0.581275
  validation loss:		0.621253
  validation accuracy:		78.48 %
Epoch 473 of 2000 took 0.097s
  training loss:		0.606781
  validation loss:		0.590393
  validation accuracy:		81.30 %
Epoch 474 of 2000 took 0.097s
  training loss:		0.587982
  validation loss:		0.596281
  validation accuracy:		80.65 %
Epoch 475 of 2000 took 0.097s
  training loss:		0.574343
  validation loss:		0.606960
  validation accuracy:		80.33 %
Epoch 476 of 2000 took 0.097s
  training loss:		0.570811
  validation loss:		0.630502
  validation accuracy:		79.35 %
Epoch 477 of 2000 took 0.097s
  training loss:		0.582098
  validation loss:		0.660252
  validation accuracy:		78.80 %
Epoch 478 of 2000 took 0.097s
  training loss:		0.575196
  validation loss:		0.582031
  validation accuracy:		80.43 %
Epoch 479 of 2000 took 0.097s
  training loss:		0.576546
  validation loss:		0.592336
  validation accuracy:		80.54 %
Epoch 480 of 2000 took 0.097s
  training loss:		0.568149
  validation loss:		0.600077
  validation accuracy:		80.98 %
Epoch 481 of 2000 took 0.097s
  training loss:		0.568806
  validation loss:		0.598375
  validation accuracy:		80.98 %
Epoch 482 of 2000 took 0.097s
  training loss:		0.567911
  validation loss:		0.650074
  validation accuracy:		78.26 %
Epoch 483 of 2000 took 0.097s
  training loss:		0.570946
  validation loss:		0.602102
  validation accuracy:		80.54 %
Epoch 484 of 2000 took 0.097s
  training loss:		0.573706
  validation loss:		0.602403
  validation accuracy:		80.54 %
Epoch 485 of 2000 took 0.097s
  training loss:		0.584445
  validation loss:		0.611315
  validation accuracy:		80.11 %
Epoch 486 of 2000 took 0.097s
  training loss:		0.569174
  validation loss:		0.580112
  validation accuracy:		80.76 %
Epoch 487 of 2000 took 0.097s
  training loss:		0.566371
  validation loss:		0.577746
  validation accuracy:		80.65 %
Epoch 488 of 2000 took 0.097s
  training loss:		0.576730
  validation loss:		0.572746
  validation accuracy:		81.20 %
Epoch 489 of 2000 took 0.097s
  training loss:		0.567529
  validation loss:		0.574654
  validation accuracy:		80.76 %
Epoch 490 of 2000 took 0.097s
  training loss:		0.572346
  validation loss:		0.584638
  validation accuracy:		80.54 %
Epoch 491 of 2000 took 0.097s
  training loss:		0.566951
  validation loss:		0.611859
  validation accuracy:		80.33 %
Epoch 492 of 2000 took 0.097s
  training loss:		0.580191
  validation loss:		0.576982
  validation accuracy:		80.76 %
Epoch 493 of 2000 took 0.097s
  training loss:		0.573172
  validation loss:		0.575978
  validation accuracy:		80.43 %
Epoch 494 of 2000 took 0.097s
  training loss:		0.568504
  validation loss:		0.670381
  validation accuracy:		78.26 %
Epoch 495 of 2000 took 0.097s
  training loss:		0.577572
  validation loss:		0.580712
  validation accuracy:		80.76 %
Epoch 496 of 2000 took 0.097s
  training loss:		0.586147
  validation loss:		0.630920
  validation accuracy:		79.35 %
Epoch 497 of 2000 took 0.097s
  training loss:		0.567446
  validation loss:		0.574418
  validation accuracy:		80.33 %
Epoch 498 of 2000 took 0.097s
  training loss:		0.567372
  validation loss:		0.582266
  validation accuracy:		80.54 %
Epoch 499 of 2000 took 0.097s
  training loss:		0.563367
  validation loss:		0.570207
  validation accuracy:		80.65 %
Epoch 500 of 2000 took 0.098s
  training loss:		0.565313
  validation loss:		0.595109
  validation accuracy:		80.98 %
Epoch 501 of 2000 took 0.097s
  training loss:		0.566954
  validation loss:		0.595843
  validation accuracy:		80.87 %
Epoch 502 of 2000 took 0.097s
  training loss:		0.567582
  validation loss:		0.590381
  validation accuracy:		80.98 %
Epoch 503 of 2000 took 0.097s
  training loss:		0.568257
  validation loss:		0.619772
  validation accuracy:		79.78 %
Epoch 504 of 2000 took 0.097s
  training loss:		0.571077
  validation loss:		0.570615
  validation accuracy:		80.76 %
Epoch 505 of 2000 took 0.097s
  training loss:		0.569252
  validation loss:		0.579202
  validation accuracy:		80.65 %
Epoch 506 of 2000 took 0.097s
  training loss:		0.576818
  validation loss:		0.598281
  validation accuracy:		80.33 %
Epoch 507 of 2000 took 0.098s
  training loss:		0.562715
  validation loss:		0.568488
  validation accuracy:		81.41 %
Epoch 508 of 2000 took 0.097s
  training loss:		0.575374
  validation loss:		0.598165
  validation accuracy:		80.65 %
Epoch 509 of 2000 took 0.097s
  training loss:		0.565707
  validation loss:		0.584590
  validation accuracy:		80.65 %
Epoch 510 of 2000 took 0.097s
  training loss:		0.561909
  validation loss:		0.568967
  validation accuracy:		80.54 %
Epoch 511 of 2000 took 0.097s
  training loss:		0.553860
  validation loss:		0.654989
  validation accuracy:		78.37 %
Epoch 512 of 2000 took 0.097s
  training loss:		0.583786
  validation loss:		0.647182
  validation accuracy:		79.67 %
Epoch 513 of 2000 took 0.097s
  training loss:		0.572861
  validation loss:		0.592305
  validation accuracy:		80.76 %
Epoch 514 of 2000 took 0.097s
  training loss:		0.569828
  validation loss:		0.619778
  validation accuracy:		79.67 %
Epoch 515 of 2000 took 0.097s
  training loss:		0.573947
  validation loss:		0.610883
  validation accuracy:		80.33 %
Epoch 516 of 2000 took 0.097s
  training loss:		0.576314
  validation loss:		0.593572
  validation accuracy:		80.98 %
Epoch 517 of 2000 took 0.097s
  training loss:		0.556847
  validation loss:		0.581742
  validation accuracy:		81.20 %
Epoch 518 of 2000 took 0.097s
  training loss:		0.565594
  validation loss:		0.577952
  validation accuracy:		80.76 %
Epoch 519 of 2000 took 0.097s
  training loss:		0.579848
  validation loss:		0.565943
  validation accuracy:		81.63 %
Epoch 520 of 2000 took 0.097s
  training loss:		0.561384
  validation loss:		0.602337
  validation accuracy:		80.22 %
Epoch 521 of 2000 took 0.097s
  training loss:		0.580329
  validation loss:		0.572119
  validation accuracy:		80.43 %
Epoch 522 of 2000 took 0.097s
  training loss:		0.571969
  validation loss:		0.562870
  validation accuracy:		80.33 %
Epoch 523 of 2000 took 0.097s
  training loss:		0.558907
  validation loss:		0.572481
  validation accuracy:		81.09 %
Epoch 524 of 2000 took 0.097s
  training loss:		0.562591
  validation loss:		0.595473
  validation accuracy:		80.22 %
Epoch 525 of 2000 took 0.097s
  training loss:		0.561587
  validation loss:		0.643758
  validation accuracy:		78.37 %
Epoch 526 of 2000 took 0.097s
  training loss:		0.575142
  validation loss:		0.565353
  validation accuracy:		80.98 %
Epoch 527 of 2000 took 0.097s
  training loss:		0.572006
  validation loss:		0.567796
  validation accuracy:		80.43 %
Epoch 528 of 2000 took 0.097s
  training loss:		0.569520
  validation loss:		0.574268
  validation accuracy:		80.87 %
Epoch 529 of 2000 took 0.097s
  training loss:		0.554081
  validation loss:		0.585000
  validation accuracy:		80.87 %
Epoch 530 of 2000 took 0.097s
  training loss:		0.562269
  validation loss:		0.570224
  validation accuracy:		80.11 %
Epoch 531 of 2000 took 0.098s
  training loss:		0.555994
  validation loss:		0.571447
  validation accuracy:		80.22 %
Epoch 532 of 2000 took 0.097s
  training loss:		0.548773
  validation loss:		0.595378
  validation accuracy:		80.65 %
Epoch 533 of 2000 took 0.097s
  training loss:		0.562440
  validation loss:		0.568534
  validation accuracy:		81.09 %
Epoch 534 of 2000 took 0.097s
  training loss:		0.560197
  validation loss:		0.570523
  validation accuracy:		81.09 %
Epoch 535 of 2000 took 0.097s
  training loss:		0.562849
  validation loss:		0.567258
  validation accuracy:		80.22 %
Epoch 536 of 2000 took 0.097s
  training loss:		0.560948
  validation loss:		0.639816
  validation accuracy:		79.46 %
Epoch 537 of 2000 took 0.097s
  training loss:		0.563670
  validation loss:		0.591494
  validation accuracy:		81.20 %
Epoch 538 of 2000 took 0.097s
  training loss:		0.553271
  validation loss:		0.564675
  validation accuracy:		80.98 %
Epoch 539 of 2000 took 0.097s
  training loss:		0.565252
  validation loss:		0.601535
  validation accuracy:		80.00 %
Epoch 540 of 2000 took 0.097s
  training loss:		0.553440
  validation loss:		0.593322
  validation accuracy:		80.65 %
Epoch 541 of 2000 took 0.097s
  training loss:		0.550781
  validation loss:		0.586351
  validation accuracy:		80.54 %
Epoch 542 of 2000 took 0.097s
  training loss:		0.570375
  validation loss:		0.596095
  validation accuracy:		80.22 %
Epoch 543 of 2000 took 0.097s
  training loss:		0.556686
  validation loss:		0.585247
  validation accuracy:		80.65 %
Epoch 544 of 2000 took 0.097s
  training loss:		0.553295
  validation loss:		0.561738
  validation accuracy:		80.54 %
Epoch 545 of 2000 took 0.097s
  training loss:		0.544866
  validation loss:		0.566236
  validation accuracy:		80.43 %
Epoch 546 of 2000 took 0.097s
  training loss:		0.560012
  validation loss:		0.594601
  validation accuracy:		80.65 %
Epoch 547 of 2000 took 0.097s
  training loss:		0.552775
  validation loss:		0.584912
  validation accuracy:		80.33 %
Epoch 548 of 2000 took 0.097s
  training loss:		0.559742
  validation loss:		0.580651
  validation accuracy:		80.33 %
Epoch 549 of 2000 took 0.097s
  training loss:		0.560091
  validation loss:		0.562365
  validation accuracy:		80.43 %
Epoch 550 of 2000 took 0.097s
  training loss:		0.565978
  validation loss:		0.568016
  validation accuracy:		80.33 %
Epoch 551 of 2000 took 0.097s
  training loss:		0.547947
  validation loss:		0.570083
  validation accuracy:		80.87 %
Epoch 552 of 2000 took 0.097s
  training loss:		0.562360
  validation loss:		0.560417
  validation accuracy:		81.20 %
Epoch 553 of 2000 took 0.097s
  training loss:		0.571229
  validation loss:		0.597648
  validation accuracy:		80.65 %
Epoch 554 of 2000 took 0.097s
  training loss:		0.559117
  validation loss:		0.583242
  validation accuracy:		80.54 %
Epoch 555 of 2000 took 0.097s
  training loss:		0.559499
  validation loss:		0.614673
  validation accuracy:		79.57 %
Epoch 556 of 2000 took 0.097s
  training loss:		0.562158
  validation loss:		0.568982
  validation accuracy:		81.09 %
Epoch 557 of 2000 took 0.097s
  training loss:		0.558086
  validation loss:		0.566049
  validation accuracy:		81.20 %
Epoch 558 of 2000 took 0.097s
  training loss:		0.568861
  validation loss:		0.580194
  validation accuracy:		80.00 %
Epoch 559 of 2000 took 0.097s
  training loss:		0.561211
  validation loss:		0.661549
  validation accuracy:		78.91 %
Epoch 560 of 2000 took 0.097s
  training loss:		0.562920
  validation loss:		0.565921
  validation accuracy:		80.98 %
Epoch 561 of 2000 took 0.097s
  training loss:		0.562966
  validation loss:		0.635024
  validation accuracy:		78.70 %
Epoch 562 of 2000 took 0.098s
  training loss:		0.553224
  validation loss:		0.563654
  validation accuracy:		80.87 %
Epoch 563 of 2000 took 0.097s
  training loss:		0.558718
  validation loss:		0.597434
  validation accuracy:		80.22 %
Epoch 564 of 2000 took 0.097s
  training loss:		0.554714
  validation loss:		0.587719
  validation accuracy:		80.65 %
Epoch 565 of 2000 took 0.097s
  training loss:		0.552749
  validation loss:		0.563806
  validation accuracy:		80.65 %
Epoch 566 of 2000 took 0.097s
  training loss:		0.541694
  validation loss:		0.615849
  validation accuracy:		79.67 %
Epoch 567 of 2000 took 0.097s
  training loss:		0.561525
  validation loss:		0.557682
  validation accuracy:		80.87 %
Epoch 568 of 2000 took 0.097s
  training loss:		0.550741
  validation loss:		0.588099
  validation accuracy:		80.11 %
Epoch 569 of 2000 took 0.097s
  training loss:		0.559965
  validation loss:		0.580284
  validation accuracy:		80.65 %
Epoch 570 of 2000 took 0.097s
  training loss:		0.567175
  validation loss:		0.627564
  validation accuracy:		79.67 %
Epoch 571 of 2000 took 0.097s
  training loss:		0.559134
  validation loss:		0.566922
  validation accuracy:		80.54 %
Epoch 572 of 2000 took 0.097s
  training loss:		0.556683
  validation loss:		0.570958
  validation accuracy:		80.54 %
Epoch 573 of 2000 took 0.097s
  training loss:		0.549766
  validation loss:		0.560838
  validation accuracy:		80.65 %
Epoch 574 of 2000 took 0.097s
  training loss:		0.550845
  validation loss:		0.568921
  validation accuracy:		80.43 %
Epoch 575 of 2000 took 0.097s
  training loss:		0.552553
  validation loss:		0.578285
  validation accuracy:		80.33 %
Epoch 576 of 2000 took 0.097s
  training loss:		0.559172
  validation loss:		0.569844
  validation accuracy:		81.30 %
Epoch 577 of 2000 took 0.097s
  training loss:		0.547782
  validation loss:		0.591219
  validation accuracy:		80.65 %
Epoch 578 of 2000 took 0.097s
  training loss:		0.556285
  validation loss:		0.557877
  validation accuracy:		80.87 %
Epoch 579 of 2000 took 0.097s
  training loss:		0.547502
  validation loss:		0.576170
  validation accuracy:		80.43 %
Epoch 580 of 2000 took 0.097s
  training loss:		0.552011
  validation loss:		0.563905
  validation accuracy:		80.76 %
Epoch 581 of 2000 took 0.097s
  training loss:		0.552941
  validation loss:		0.600207
  validation accuracy:		79.57 %
Epoch 582 of 2000 took 0.097s
  training loss:		0.555302
  validation loss:		0.570560
  validation accuracy:		80.87 %
Epoch 583 of 2000 took 0.097s
  training loss:		0.561876
  validation loss:		0.589368
  validation accuracy:		80.33 %
Epoch 584 of 2000 took 0.097s
  training loss:		0.561720
  validation loss:		0.584590
  validation accuracy:		80.65 %
Epoch 585 of 2000 took 0.097s
  training loss:		0.549136
  validation loss:		0.600622
  validation accuracy:		80.00 %
Epoch 586 of 2000 took 0.097s
  training loss:		0.554811
  validation loss:		0.565625
  validation accuracy:		80.98 %
Epoch 587 of 2000 took 0.099s
  training loss:		0.546974
  validation loss:		0.556013
  validation accuracy:		81.20 %
Epoch 588 of 2000 took 0.097s
  training loss:		0.558085
  validation loss:		0.629652
  validation accuracy:		78.48 %
Epoch 589 of 2000 took 0.097s
  training loss:		0.552564
  validation loss:		0.610471
  validation accuracy:		79.67 %
Epoch 590 of 2000 took 0.097s
  training loss:		0.555070
  validation loss:		0.587928
  validation accuracy:		80.11 %
Epoch 591 of 2000 took 0.097s
  training loss:		0.555873
  validation loss:		0.581382
  validation accuracy:		80.65 %
Epoch 592 of 2000 took 0.097s
  training loss:		0.554604
  validation loss:		0.606355
  validation accuracy:		79.46 %
Epoch 593 of 2000 took 0.098s
  training loss:		0.555412
  validation loss:		0.569794
  validation accuracy:		80.54 %
Epoch 594 of 2000 took 0.097s
  training loss:		0.552111
  validation loss:		0.596478
  validation accuracy:		80.00 %
Epoch 595 of 2000 took 0.097s
  training loss:		0.573035
  validation loss:		0.592452
  validation accuracy:		80.22 %
Epoch 596 of 2000 took 0.097s
  training loss:		0.576052
  validation loss:		0.566426
  validation accuracy:		81.30 %
Epoch 597 of 2000 took 0.097s
  training loss:		0.547693
  validation loss:		0.569366
  validation accuracy:		80.33 %
Epoch 598 of 2000 took 0.097s
  training loss:		0.557689
  validation loss:		0.572790
  validation accuracy:		80.54 %
Epoch 599 of 2000 took 0.097s
  training loss:		0.558824
  validation loss:		0.571860
  validation accuracy:		80.76 %
Epoch 600 of 2000 took 0.097s
  training loss:		0.544553
  validation loss:		0.569194
  validation accuracy:		80.11 %
Epoch 601 of 2000 took 0.097s
  training loss:		0.558729
  validation loss:		0.562453
  validation accuracy:		80.65 %
Epoch 602 of 2000 took 0.097s
  training loss:		0.549010
  validation loss:		0.559107
  validation accuracy:		81.30 %
Epoch 603 of 2000 took 0.097s
  training loss:		0.557294
  validation loss:		0.580613
  validation accuracy:		80.65 %
Epoch 604 of 2000 took 0.097s
  training loss:		0.563306
  validation loss:		0.602518
  validation accuracy:		80.00 %
Epoch 605 of 2000 took 0.100s
  training loss:		0.556770
  validation loss:		0.560356
  validation accuracy:		80.65 %
Epoch 606 of 2000 took 0.100s
  training loss:		0.559983
  validation loss:		0.567296
  validation accuracy:		80.87 %
Epoch 607 of 2000 took 0.100s
  training loss:		0.556426
  validation loss:		0.556344
  validation accuracy:		81.20 %
Epoch 608 of 2000 took 0.100s
  training loss:		0.559083
  validation loss:		0.568973
  validation accuracy:		80.76 %
Epoch 609 of 2000 took 0.100s
  training loss:		0.559736
  validation loss:		0.566472
  validation accuracy:		80.11 %
Epoch 610 of 2000 took 0.100s
  training loss:		0.553848
  validation loss:		0.556108
  validation accuracy:		81.41 %
Epoch 611 of 2000 took 0.100s
  training loss:		0.558367
  validation loss:		0.571576
  validation accuracy:		80.54 %
Epoch 612 of 2000 took 0.100s
  training loss:		0.555031
  validation loss:		0.595081
  validation accuracy:		80.22 %
Epoch 613 of 2000 took 0.100s
  training loss:		0.550467
  validation loss:		0.613417
  validation accuracy:		80.00 %
Epoch 614 of 2000 took 0.100s
  training loss:		0.558224
  validation loss:		0.567018
  validation accuracy:		80.22 %
Epoch 615 of 2000 took 0.100s
  training loss:		0.553893
  validation loss:		0.587902
  validation accuracy:		80.65 %
Epoch 616 of 2000 took 0.100s
  training loss:		0.550211
  validation loss:		0.587395
  validation accuracy:		79.78 %
Epoch 617 of 2000 took 0.100s
  training loss:		0.561518
  validation loss:		0.598182
  validation accuracy:		80.33 %
Epoch 618 of 2000 took 0.100s
  training loss:		0.560404
  validation loss:		0.569700
  validation accuracy:		80.22 %
Epoch 619 of 2000 took 0.100s
  training loss:		0.550717
  validation loss:		0.583691
  validation accuracy:		80.54 %
Epoch 620 of 2000 took 0.100s
  training loss:		0.547179
  validation loss:		0.600735
  validation accuracy:		79.57 %
Epoch 621 of 2000 took 0.100s
  training loss:		0.546276
  validation loss:		0.581579
  validation accuracy:		80.22 %
Epoch 622 of 2000 took 0.100s
  training loss:		0.552422
  validation loss:		0.556660
  validation accuracy:		80.98 %
Epoch 623 of 2000 took 0.100s
  training loss:		0.551697
  validation loss:		0.582533
  validation accuracy:		80.22 %
Epoch 624 of 2000 took 0.100s
  training loss:		0.547054
  validation loss:		0.596749
  validation accuracy:		80.54 %
Epoch 625 of 2000 took 0.100s
  training loss:		0.559413
  validation loss:		0.578400
  validation accuracy:		80.00 %
Epoch 626 of 2000 took 0.100s
  training loss:		0.553046
  validation loss:		0.603657
  validation accuracy:		80.00 %
Epoch 627 of 2000 took 0.100s
  training loss:		0.565761
  validation loss:		0.614815
  validation accuracy:		79.78 %
Epoch 628 of 2000 took 0.100s
  training loss:		0.567961
  validation loss:		0.557808
  validation accuracy:		80.76 %
Epoch 629 of 2000 took 0.100s
  training loss:		0.543089
  validation loss:		0.553604
  validation accuracy:		81.63 %
Epoch 630 of 2000 took 0.100s
  training loss:		0.546687
  validation loss:		0.581579
  validation accuracy:		80.98 %
Epoch 631 of 2000 took 0.100s
  training loss:		0.547746
  validation loss:		0.576904
  validation accuracy:		80.76 %
Epoch 632 of 2000 took 0.100s
  training loss:		0.550778
  validation loss:		0.553454
  validation accuracy:		81.30 %
Epoch 633 of 2000 took 0.100s
  training loss:		0.558868
  validation loss:		0.567829
  validation accuracy:		80.65 %
Epoch 634 of 2000 took 0.100s
  training loss:		0.554612
  validation loss:		0.568897
  validation accuracy:		80.33 %
Epoch 635 of 2000 took 0.100s
  training loss:		0.549798
  validation loss:		0.567313
  validation accuracy:		80.43 %
Epoch 636 of 2000 took 0.100s
  training loss:		0.548335
  validation loss:		0.561730
  validation accuracy:		80.43 %
Epoch 637 of 2000 took 0.100s
  training loss:		0.545143
  validation loss:		0.564180
  validation accuracy:		80.87 %
Epoch 638 of 2000 took 0.100s
  training loss:		0.539595
  validation loss:		0.610174
  validation accuracy:		79.46 %
Epoch 639 of 2000 took 0.100s
  training loss:		0.541610
  validation loss:		0.582642
  validation accuracy:		80.98 %
Epoch 640 of 2000 took 0.100s
  training loss:		0.547522
  validation loss:		0.580656
  validation accuracy:		80.65 %
Epoch 641 of 2000 took 0.100s
  training loss:		0.549144
  validation loss:		0.566036
  validation accuracy:		80.87 %
Epoch 642 of 2000 took 0.100s
  training loss:		0.551620
  validation loss:		0.560319
  validation accuracy:		81.41 %
Epoch 643 of 2000 took 0.100s
  training loss:		0.545509
  validation loss:		0.554988
  validation accuracy:		81.30 %
Epoch 644 of 2000 took 0.100s
  training loss:		0.550224
  validation loss:		0.560853
  validation accuracy:		80.87 %
Epoch 645 of 2000 took 0.097s
  training loss:		0.566458
  validation loss:		0.555569
  validation accuracy:		81.52 %
Epoch 646 of 2000 took 0.097s
  training loss:		0.552768
  validation loss:		0.567928
  validation accuracy:		80.98 %
Epoch 647 of 2000 took 0.097s
  training loss:		0.554955
  validation loss:		0.555772
  validation accuracy:		81.20 %
Epoch 648 of 2000 took 0.097s
  training loss:		0.549411
  validation loss:		0.564341
  validation accuracy:		80.76 %
Epoch 649 of 2000 took 0.097s
  training loss:		0.556497
  validation loss:		0.565679
  validation accuracy:		80.76 %
Epoch 650 of 2000 took 0.097s
  training loss:		0.554430
  validation loss:		0.587040
  validation accuracy:		80.33 %
Epoch 651 of 2000 took 0.097s
  training loss:		0.551803
  validation loss:		0.590208
  validation accuracy:		80.33 %
Epoch 652 of 2000 took 0.097s
  training loss:		0.555344
  validation loss:		0.556093
  validation accuracy:		80.87 %
Epoch 653 of 2000 took 0.097s
  training loss:		0.559874
  validation loss:		0.556087
  validation accuracy:		81.20 %
Epoch 654 of 2000 took 0.098s
  training loss:		0.539527
  validation loss:		0.558039
  validation accuracy:		80.87 %
Epoch 655 of 2000 took 0.097s
  training loss:		0.539128
  validation loss:		0.601689
  validation accuracy:		80.00 %
Epoch 656 of 2000 took 0.097s
  training loss:		0.548319
  validation loss:		0.563958
  validation accuracy:		80.87 %
Epoch 657 of 2000 took 0.097s
  training loss:		0.540016
  validation loss:		0.571538
  validation accuracy:		80.87 %
Epoch 658 of 2000 took 0.097s
  training loss:		0.550611
  validation loss:		0.564649
  validation accuracy:		80.76 %
Epoch 659 of 2000 took 0.097s
  training loss:		0.546900
  validation loss:		0.558357
  validation accuracy:		81.20 %
Epoch 660 of 2000 took 0.097s
  training loss:		0.547719
  validation loss:		0.559259
  validation accuracy:		80.87 %
Epoch 661 of 2000 took 0.097s
  training loss:		0.551658
  validation loss:		0.564454
  validation accuracy:		80.65 %
Epoch 662 of 2000 took 0.097s
  training loss:		0.552733
  validation loss:		0.592189
  validation accuracy:		80.11 %
Epoch 663 of 2000 took 0.097s
  training loss:		0.545078
  validation loss:		0.570874
  validation accuracy:		80.87 %
Epoch 664 of 2000 took 0.097s
  training loss:		0.543901
  validation loss:		0.555556
  validation accuracy:		81.20 %
Epoch 665 of 2000 took 0.097s
  training loss:		0.549805
  validation loss:		0.579163
  validation accuracy:		80.33 %
Epoch 666 of 2000 took 0.097s
  training loss:		0.547062
  validation loss:		0.571995
  validation accuracy:		80.33 %
Epoch 667 of 2000 took 0.097s
  training loss:		0.550908
  validation loss:		0.567257
  validation accuracy:		80.54 %
Epoch 668 of 2000 took 0.097s
  training loss:		0.544373
  validation loss:		0.568993
  validation accuracy:		80.76 %
Epoch 669 of 2000 took 0.097s
  training loss:		0.553345
  validation loss:		0.601261
  validation accuracy:		80.11 %
Epoch 670 of 2000 took 0.097s
  training loss:		0.555020
  validation loss:		0.566944
  validation accuracy:		80.54 %
Epoch 671 of 2000 took 0.097s
  training loss:		0.541089
  validation loss:		0.557382
  validation accuracy:		80.65 %
Epoch 672 of 2000 took 0.097s
  training loss:		0.549950
  validation loss:		0.559365
  validation accuracy:		80.87 %
Epoch 673 of 2000 took 0.097s
  training loss:		0.554679
  validation loss:		0.592746
  validation accuracy:		80.33 %
Epoch 674 of 2000 took 0.097s
  training loss:		0.543309
  validation loss:		0.581236
  validation accuracy:		80.11 %
Epoch 675 of 2000 took 0.097s
  training loss:		0.548333
  validation loss:		0.568268
  validation accuracy:		81.41 %
Epoch 676 of 2000 took 0.097s
  training loss:		0.562000
  validation loss:		0.565092
  validation accuracy:		81.09 %
Epoch 677 of 2000 took 0.097s
  training loss:		0.548244
  validation loss:		0.611715
  validation accuracy:		79.67 %
Epoch 678 of 2000 took 0.097s
  training loss:		0.563186
  validation loss:		0.583404
  validation accuracy:		80.22 %
Epoch 679 of 2000 took 0.097s
  training loss:		0.551303
  validation loss:		0.576173
  validation accuracy:		80.98 %
Epoch 680 of 2000 took 0.097s
  training loss:		0.544181
  validation loss:		0.584964
  validation accuracy:		80.11 %
Epoch 681 of 2000 took 0.097s
  training loss:		0.564285
  validation loss:		0.604522
  validation accuracy:		79.46 %
Epoch 682 of 2000 took 0.097s
  training loss:		0.550061
  validation loss:		0.578591
  validation accuracy:		80.87 %
Epoch 683 of 2000 took 0.097s
  training loss:		0.540699
  validation loss:		0.563055
  validation accuracy:		80.87 %
Epoch 684 of 2000 took 0.097s
  training loss:		0.563303
  validation loss:		0.580106
  validation accuracy:		80.65 %
Epoch 685 of 2000 took 0.098s
  training loss:		0.541512
  validation loss:		0.559123
  validation accuracy:		81.20 %
Epoch 686 of 2000 took 0.100s
  training loss:		0.546062
  validation loss:		0.575460
  validation accuracy:		80.98 %
Epoch 687 of 2000 took 0.100s
  training loss:		0.552217
  validation loss:		0.588324
  validation accuracy:		80.22 %
Epoch 688 of 2000 took 0.100s
  training loss:		0.544810
  validation loss:		0.560007
  validation accuracy:		80.87 %
Epoch 689 of 2000 took 0.100s
  training loss:		0.538632
  validation loss:		0.556295
  validation accuracy:		81.09 %
Epoch 690 of 2000 took 0.100s
  training loss:		0.545452
  validation loss:		0.582941
  validation accuracy:		80.65 %
Epoch 691 of 2000 took 0.100s
  training loss:		0.548884
  validation loss:		0.561999
  validation accuracy:		80.43 %
Epoch 692 of 2000 took 0.100s
  training loss:		0.551807
  validation loss:		0.590100
  validation accuracy:		80.65 %
Epoch 693 of 2000 took 0.100s
  training loss:		0.549155
  validation loss:		0.570634
  validation accuracy:		80.43 %
Epoch 694 of 2000 took 0.100s
  training loss:		0.549952
  validation loss:		0.568759
  validation accuracy:		80.33 %
Epoch 695 of 2000 took 0.100s
  training loss:		0.553070
  validation loss:		0.596184
  validation accuracy:		80.65 %
Epoch 696 of 2000 took 0.100s
  training loss:		0.555516
  validation loss:		0.582839
  validation accuracy:		81.09 %
Epoch 697 of 2000 took 0.100s
  training loss:		0.550816
  validation loss:		0.581601
  validation accuracy:		80.76 %
Epoch 698 of 2000 took 0.100s
  training loss:		0.547144
  validation loss:		0.574873
  validation accuracy:		80.54 %
Epoch 699 of 2000 took 0.100s
  training loss:		0.552624
  validation loss:		0.563137
  validation accuracy:		80.98 %
Epoch 700 of 2000 took 0.100s
  training loss:		0.548243
  validation loss:		0.561331
  validation accuracy:		81.30 %
Epoch 701 of 2000 took 0.100s
  training loss:		0.546394
  validation loss:		0.607930
  validation accuracy:		79.89 %
Epoch 702 of 2000 took 0.100s
  training loss:		0.549519
  validation loss:		0.576351
  validation accuracy:		80.76 %
Epoch 703 of 2000 took 0.100s
  training loss:		0.553457
  validation loss:		0.608105
  validation accuracy:		80.11 %
Epoch 704 of 2000 took 0.100s
  training loss:		0.565443
  validation loss:		0.555286
  validation accuracy:		80.98 %
Epoch 705 of 2000 took 0.100s
  training loss:		0.542736
  validation loss:		0.565392
  validation accuracy:		80.87 %
Epoch 706 of 2000 took 0.100s
  training loss:		0.543583
  validation loss:		0.623331
  validation accuracy:		79.13 %
Epoch 707 of 2000 took 0.100s
  training loss:		0.557477
  validation loss:		0.569019
  validation accuracy:		81.20 %
Epoch 708 of 2000 took 0.100s
  training loss:		0.547164
  validation loss:		0.582889
  validation accuracy:		80.65 %
Epoch 709 of 2000 took 0.100s
  training loss:		0.554669
  validation loss:		0.602517
  validation accuracy:		79.67 %
Epoch 710 of 2000 took 0.100s
  training loss:		0.548873
  validation loss:		0.558018
  validation accuracy:		81.20 %
Epoch 711 of 2000 took 0.100s
  training loss:		0.553739
  validation loss:		0.565305
  validation accuracy:		80.65 %
Epoch 712 of 2000 took 0.100s
  training loss:		0.553908
  validation loss:		0.608242
  validation accuracy:		79.78 %
Epoch 713 of 2000 took 0.100s
  training loss:		0.550013
  validation loss:		0.583519
  validation accuracy:		80.87 %
Epoch 714 of 2000 took 0.100s
  training loss:		0.539611
  validation loss:		0.606438
  validation accuracy:		79.46 %
Epoch 715 of 2000 took 0.101s
  training loss:		0.556478
  validation loss:		0.612569
  validation accuracy:		80.00 %
Epoch 716 of 2000 took 0.100s
  training loss:		0.551835
  validation loss:		0.562153
  validation accuracy:		81.09 %
Epoch 717 of 2000 took 0.100s
  training loss:		0.557958
  validation loss:		0.555744
  validation accuracy:		81.85 %
Epoch 718 of 2000 took 0.100s
  training loss:		0.542252
  validation loss:		0.576857
  validation accuracy:		81.09 %
Epoch 719 of 2000 took 0.104s
  training loss:		0.547224
  validation loss:		0.572998
  validation accuracy:		80.33 %
Epoch 720 of 2000 took 0.107s
  training loss:		0.548412
  validation loss:		0.557303
  validation accuracy:		80.98 %
Epoch 721 of 2000 took 0.144s
  training loss:		0.549508
  validation loss:		0.579646
  validation accuracy:		80.98 %
Epoch 722 of 2000 took 0.101s
  training loss:		0.547167
  validation loss:		0.555630
  validation accuracy:		81.52 %
Epoch 723 of 2000 took 0.097s
  training loss:		0.546217
  validation loss:		0.591527
  validation accuracy:		80.54 %
Epoch 724 of 2000 took 0.101s
  training loss:		0.535882
  validation loss:		0.555592
  validation accuracy:		80.98 %
Epoch 725 of 2000 took 0.102s
  training loss:		0.553145
  validation loss:		0.575903
  validation accuracy:		80.98 %
Epoch 726 of 2000 took 0.102s
  training loss:		0.551072
  validation loss:		0.579339
  validation accuracy:		80.76 %
Epoch 727 of 2000 took 0.099s
  training loss:		0.548080
  validation loss:		0.580604
  validation accuracy:		80.87 %
Epoch 728 of 2000 took 0.097s
  training loss:		0.553003
  validation loss:		0.582652
  validation accuracy:		80.76 %
Epoch 729 of 2000 took 0.096s
  training loss:		0.547539
  validation loss:		0.579261
  validation accuracy:		80.98 %
Epoch 730 of 2000 took 0.096s
  training loss:		0.546745
  validation loss:		0.569723
  validation accuracy:		80.98 %
Epoch 731 of 2000 took 0.096s
  training loss:		0.552983
  validation loss:		0.589100
  validation accuracy:		80.33 %
Epoch 732 of 2000 took 0.097s
  training loss:		0.541989
  validation loss:		0.565933
  validation accuracy:		81.20 %
Epoch 733 of 2000 took 0.096s
  training loss:		0.550807
  validation loss:		0.563499
  validation accuracy:		81.09 %
Epoch 734 of 2000 took 0.097s
  training loss:		0.551796
  validation loss:		0.571169
  validation accuracy:		81.09 %
Epoch 735 of 2000 took 0.096s
  training loss:		0.555636
  validation loss:		0.557004
  validation accuracy:		80.98 %
Epoch 736 of 2000 took 0.098s
  training loss:		0.544209
  validation loss:		0.556512
  validation accuracy:		81.41 %
Epoch 737 of 2000 took 0.098s
  training loss:		0.535435
  validation loss:		0.601413
  validation accuracy:		80.00 %
Epoch 738 of 2000 took 0.096s
  training loss:		0.547259
  validation loss:		0.593402
  validation accuracy:		80.11 %
Epoch 739 of 2000 took 0.097s
  training loss:		0.549562
  validation loss:		0.594953
  validation accuracy:		80.33 %
Epoch 740 of 2000 took 0.096s
  training loss:		0.545485
  validation loss:		0.557684
  validation accuracy:		81.41 %
Epoch 741 of 2000 took 0.097s
  training loss:		0.548784
  validation loss:		0.576354
  validation accuracy:		80.11 %
Epoch 742 of 2000 took 0.097s
  training loss:		0.556438
  validation loss:		0.566257
  validation accuracy:		80.76 %
Epoch 743 of 2000 took 0.096s
  training loss:		0.561073
  validation loss:		0.575172
  validation accuracy:		81.20 %
Epoch 744 of 2000 took 0.097s
  training loss:		0.563680
  validation loss:		0.575986
  validation accuracy:		80.98 %
Epoch 745 of 2000 took 0.097s
  training loss:		0.547638
  validation loss:		0.589784
  validation accuracy:		80.43 %
Epoch 746 of 2000 took 0.097s
  training loss:		0.564306
  validation loss:		0.565424
  validation accuracy:		81.09 %
Epoch 747 of 2000 took 0.097s
  training loss:		0.542072
  validation loss:		0.599351
  validation accuracy:		80.11 %
Epoch 748 of 2000 took 0.097s
  training loss:		0.556953
  validation loss:		0.601879
  validation accuracy:		79.78 %
Epoch 749 of 2000 took 0.097s
  training loss:		0.563675
  validation loss:		0.593189
  validation accuracy:		80.00 %
Epoch 750 of 2000 took 0.096s
  training loss:		0.542296
  validation loss:		0.570736
  validation accuracy:		81.09 %
Epoch 751 of 2000 took 0.097s
  training loss:		0.548996
  validation loss:		0.558150
  validation accuracy:		81.74 %
Epoch 752 of 2000 took 0.097s
  training loss:		0.539324
  validation loss:		0.576604
  validation accuracy:		80.43 %
Epoch 753 of 2000 took 0.097s
  training loss:		0.544470
  validation loss:		0.554006
  validation accuracy:		81.41 %
Epoch 754 of 2000 took 0.097s
  training loss:		0.553179
  validation loss:		0.561204
  validation accuracy:		81.30 %
Epoch 755 of 2000 took 0.096s
  training loss:		0.543566
  validation loss:		0.564911
  validation accuracy:		80.76 %
Epoch 756 of 2000 took 0.097s
  training loss:		0.541267
  validation loss:		0.551785
  validation accuracy:		81.20 %
Epoch 757 of 2000 took 0.097s
  training loss:		0.553283
  validation loss:		0.592673
  validation accuracy:		80.33 %
Epoch 758 of 2000 took 0.097s
  training loss:		0.536146
  validation loss:		0.561712
  validation accuracy:		80.76 %
Epoch 759 of 2000 took 0.097s
  training loss:		0.545937
  validation loss:		0.581070
  validation accuracy:		80.43 %
Epoch 760 of 2000 took 0.098s
  training loss:		0.544564
  validation loss:		0.561514
  validation accuracy:		81.30 %
Epoch 761 of 2000 took 0.215s
  training loss:		0.545148
  validation loss:		0.558200
  validation accuracy:		81.41 %
Epoch 762 of 2000 took 0.206s
  training loss:		0.540415
  validation loss:		0.582947
  validation accuracy:		81.09 %
Epoch 763 of 2000 took 0.251s
  training loss:		0.554648
  validation loss:		0.583446
  validation accuracy:		80.54 %
Epoch 764 of 2000 took 0.097s
  training loss:		0.547617
  validation loss:		0.584078
  validation accuracy:		80.76 %
Epoch 765 of 2000 took 0.096s
  training loss:		0.554671
  validation loss:		0.564388
  validation accuracy:		81.41 %
Epoch 766 of 2000 took 0.101s
  training loss:		0.550223
  validation loss:		0.557533
  validation accuracy:		80.98 %
Epoch 767 of 2000 took 0.103s
  training loss:		0.545671
  validation loss:		0.572846
  validation accuracy:		80.98 %
Epoch 768 of 2000 took 0.106s
  training loss:		0.556307
  validation loss:		0.572909
  validation accuracy:		80.98 %
Epoch 769 of 2000 took 0.097s
  training loss:		0.542962
  validation loss:		0.580248
  validation accuracy:		80.65 %
Epoch 770 of 2000 took 0.096s
  training loss:		0.566465
  validation loss:		0.627726
  validation accuracy:		78.48 %
Epoch 771 of 2000 took 0.096s
  training loss:		0.552076
  validation loss:		0.562135
  validation accuracy:		81.30 %
Epoch 772 of 2000 took 0.097s
  training loss:		0.550437
  validation loss:		0.568681
  validation accuracy:		81.20 %
Epoch 773 of 2000 took 0.096s
  training loss:		0.547713
  validation loss:		0.579009
  validation accuracy:		80.33 %
Epoch 774 of 2000 took 0.096s
  training loss:		0.547284
  validation loss:		0.565623
  validation accuracy:		81.20 %
Epoch 775 of 2000 took 0.096s
  training loss:		0.547835
  validation loss:		0.561765
  validation accuracy:		81.09 %
Epoch 776 of 2000 took 0.096s
  training loss:		0.547045
  validation loss:		0.552948
  validation accuracy:		81.09 %
Epoch 777 of 2000 took 0.096s
  training loss:		0.543846
  validation loss:		0.570021
  validation accuracy:		80.98 %
Epoch 778 of 2000 took 0.096s
  training loss:		0.549107
  validation loss:		0.558011
  validation accuracy:		81.41 %
Epoch 779 of 2000 took 0.100s
  training loss:		0.560316
  validation loss:		0.573967
  validation accuracy:		80.65 %
Epoch 780 of 2000 took 0.098s
  training loss:		0.548310
  validation loss:		0.576432
  validation accuracy:		80.87 %
Epoch 781 of 2000 took 0.096s
  training loss:		0.540598
  validation loss:		0.559075
  validation accuracy:		81.09 %
Epoch 782 of 2000 took 0.098s
  training loss:		0.562092
  validation loss:		0.560246
  validation accuracy:		81.41 %
Epoch 783 of 2000 took 0.097s
  training loss:		0.543633
  validation loss:		0.573891
  validation accuracy:		80.65 %
Epoch 784 of 2000 took 0.098s
  training loss:		0.544019
  validation loss:		0.565885
  validation accuracy:		81.41 %
Epoch 785 of 2000 took 0.097s
  training loss:		0.553469
  validation loss:		0.558718
  validation accuracy:		81.09 %
Epoch 786 of 2000 took 0.097s
  training loss:		0.548854
  validation loss:		0.557466
  validation accuracy:		81.30 %
Epoch 787 of 2000 took 0.097s
  training loss:		0.542853
  validation loss:		0.589131
  validation accuracy:		80.43 %
Epoch 788 of 2000 took 0.097s
  training loss:		0.548616
  validation loss:		0.575918
  validation accuracy:		80.76 %
Epoch 789 of 2000 took 0.097s
  training loss:		0.538105
  validation loss:		0.586686
  validation accuracy:		80.76 %
Epoch 790 of 2000 took 0.097s
  training loss:		0.545406
  validation loss:		0.560434
  validation accuracy:		81.41 %
Epoch 791 of 2000 took 0.097s
  training loss:		0.543305
  validation loss:		0.577560
  validation accuracy:		81.30 %
Epoch 792 of 2000 took 0.097s
  training loss:		0.555578
  validation loss:		0.571747
  validation accuracy:		80.98 %
Epoch 793 of 2000 took 0.097s
  training loss:		0.551217
  validation loss:		0.562603
  validation accuracy:		81.20 %
Epoch 794 of 2000 took 0.097s
  training loss:		0.540450
  validation loss:		0.553089
  validation accuracy:		81.30 %
Epoch 795 of 2000 took 0.097s
  training loss:		0.543077
  validation loss:		0.586196
  validation accuracy:		80.43 %
Epoch 796 of 2000 took 0.097s
  training loss:		0.544780
  validation loss:		0.601987
  validation accuracy:		80.22 %
Epoch 797 of 2000 took 0.097s
  training loss:		0.548522
  validation loss:		0.554363
  validation accuracy:		81.09 %
Epoch 798 of 2000 took 0.097s
  training loss:		0.548015
  validation loss:		0.574030
  validation accuracy:		80.76 %
Epoch 799 of 2000 took 0.097s
  training loss:		0.547533
  validation loss:		0.566370
  validation accuracy:		81.09 %
Epoch 800 of 2000 took 0.097s
  training loss:		0.541643
  validation loss:		0.572045
  validation accuracy:		80.76 %
Epoch 801 of 2000 took 0.097s
  training loss:		0.543971
  validation loss:		0.572340
  validation accuracy:		80.76 %
Epoch 802 of 2000 took 0.097s
  training loss:		0.550012
  validation loss:		0.554976
  validation accuracy:		81.30 %
Epoch 803 of 2000 took 0.098s
  training loss:		0.546280
  validation loss:		0.570211
  validation accuracy:		81.41 %
Epoch 804 of 2000 took 0.097s
  training loss:		0.543851
  validation loss:		0.585804
  validation accuracy:		80.33 %
Epoch 805 of 2000 took 0.097s
  training loss:		0.560614
  validation loss:		0.582183
  validation accuracy:		80.76 %
Epoch 806 of 2000 took 0.097s
  training loss:		0.543451
  validation loss:		0.558202
  validation accuracy:		81.63 %
Epoch 807 of 2000 took 0.097s
  training loss:		0.543736
  validation loss:		0.560314
  validation accuracy:		80.87 %
Epoch 808 of 2000 took 0.097s
  training loss:		0.543359
  validation loss:		0.551221
  validation accuracy:		81.09 %
Epoch 809 of 2000 took 0.098s
  training loss:		0.546173
  validation loss:		0.554954
  validation accuracy:		81.41 %
Epoch 810 of 2000 took 0.097s
  training loss:		0.544086
  validation loss:		0.567024
  validation accuracy:		81.20 %
Epoch 811 of 2000 took 0.097s
  training loss:		0.543250
  validation loss:		0.560897
  validation accuracy:		81.20 %
Epoch 812 of 2000 took 0.097s
  training loss:		0.542034
  validation loss:		0.556756
  validation accuracy:		80.65 %
Epoch 813 of 2000 took 0.097s
  training loss:		0.535686
  validation loss:		0.564923
  validation accuracy:		81.20 %
Epoch 814 of 2000 took 0.097s
  training loss:		0.539215
  validation loss:		0.565509
  validation accuracy:		80.76 %
Epoch 815 of 2000 took 0.097s
  training loss:		0.541924
  validation loss:		0.576430
  validation accuracy:		80.65 %
Epoch 816 of 2000 took 0.097s
  training loss:		0.552596
  validation loss:		0.579684
  validation accuracy:		80.87 %
Epoch 817 of 2000 took 0.097s
  training loss:		0.560751
  validation loss:		0.566661
  validation accuracy:		81.09 %
Epoch 818 of 2000 took 0.097s
  training loss:		0.538215
  validation loss:		0.596060
  validation accuracy:		80.11 %
Epoch 819 of 2000 took 0.097s
  training loss:		0.543316
  validation loss:		0.573774
  validation accuracy:		81.41 %
Epoch 820 of 2000 took 0.097s
  training loss:		0.551476
  validation loss:		0.558035
  validation accuracy:		81.20 %
Epoch 821 of 2000 took 0.097s
  training loss:		0.549392
  validation loss:		0.559321
  validation accuracy:		81.09 %
Epoch 822 of 2000 took 0.097s
  training loss:		0.545256
  validation loss:		0.556871
  validation accuracy:		81.30 %
Epoch 823 of 2000 took 0.097s
  training loss:		0.548270
  validation loss:		0.562126
  validation accuracy:		80.87 %
Epoch 824 of 2000 took 0.097s
  training loss:		0.546271
  validation loss:		0.574409
  validation accuracy:		80.76 %
Epoch 825 of 2000 took 0.097s
  training loss:		0.547507
  validation loss:		0.579481
  validation accuracy:		80.98 %
Epoch 826 of 2000 took 0.097s
  training loss:		0.543682
  validation loss:		0.554436
  validation accuracy:		81.30 %
Epoch 827 of 2000 took 0.097s
  training loss:		0.545557
  validation loss:		0.557415
  validation accuracy:		80.54 %
Epoch 828 of 2000 took 0.097s
  training loss:		0.549359
  validation loss:		0.600835
  validation accuracy:		79.67 %
Epoch 829 of 2000 took 0.097s
  training loss:		0.546882
  validation loss:		0.562372
  validation accuracy:		80.65 %
Epoch 830 of 2000 took 0.097s
  training loss:		0.545838
  validation loss:		0.564450
  validation accuracy:		81.20 %
Epoch 831 of 2000 took 0.097s
  training loss:		0.546654
  validation loss:		0.566254
  validation accuracy:		80.87 %
Epoch 832 of 2000 took 0.097s
  training loss:		0.552966
  validation loss:		0.587731
  validation accuracy:		80.43 %
Epoch 833 of 2000 took 0.097s
  training loss:		0.542313
  validation loss:		0.562154
  validation accuracy:		81.30 %
Epoch 834 of 2000 took 0.098s
  training loss:		0.556335
  validation loss:		0.574717
  validation accuracy:		80.54 %
Epoch 835 of 2000 took 0.097s
  training loss:		0.541521
  validation loss:		0.557613
  validation accuracy:		81.63 %
Epoch 836 of 2000 took 0.097s
  training loss:		0.540380
  validation loss:		0.560935
  validation accuracy:		81.41 %
Epoch 837 of 2000 took 0.097s
  training loss:		0.549399
  validation loss:		0.553636
  validation accuracy:		81.41 %
Epoch 838 of 2000 took 0.097s
  training loss:		0.540073
  validation loss:		0.578923
  validation accuracy:		80.76 %
Epoch 839 of 2000 took 0.097s
  training loss:		0.545591
  validation loss:		0.576857
  validation accuracy:		80.87 %
Epoch 840 of 2000 took 0.097s
  training loss:		0.547993
  validation loss:		0.568852
  validation accuracy:		80.98 %
Epoch 841 of 2000 took 0.097s
  training loss:		0.551847
  validation loss:		0.559946
  validation accuracy:		81.41 %
Epoch 842 of 2000 took 0.097s
  training loss:		0.551260
  validation loss:		0.598306
  validation accuracy:		79.78 %
Epoch 843 of 2000 took 0.097s
  training loss:		0.539290
  validation loss:		0.583948
  validation accuracy:		80.43 %
Epoch 844 of 2000 took 0.097s
  training loss:		0.546709
  validation loss:		0.577608
  validation accuracy:		80.98 %
Epoch 845 of 2000 took 0.097s
  training loss:		0.555945
  validation loss:		0.600756
  validation accuracy:		80.22 %
Epoch 846 of 2000 took 0.097s
  training loss:		0.553763
  validation loss:		0.600954
  validation accuracy:		79.57 %
Epoch 847 of 2000 took 0.097s
  training loss:		0.549996
  validation loss:		0.572833
  validation accuracy:		81.09 %
Epoch 848 of 2000 took 0.097s
  training loss:		0.548000
  validation loss:		0.567977
  validation accuracy:		81.30 %
Epoch 849 of 2000 took 0.097s
  training loss:		0.543821
  validation loss:		0.581295
  validation accuracy:		80.65 %
Epoch 850 of 2000 took 0.097s
  training loss:		0.556762
  validation loss:		0.585940
  validation accuracy:		80.65 %
Epoch 851 of 2000 took 0.097s
  training loss:		0.540359
  validation loss:		0.568084
  validation accuracy:		81.20 %
Epoch 852 of 2000 took 0.097s
  training loss:		0.554786
  validation loss:		0.556733
  validation accuracy:		81.63 %
Epoch 853 of 2000 took 0.097s
  training loss:		0.545692
  validation loss:		0.583289
  validation accuracy:		80.43 %
Epoch 854 of 2000 took 0.097s
  training loss:		0.544115
  validation loss:		0.561838
  validation accuracy:		81.20 %
Epoch 855 of 2000 took 0.097s
  training loss:		0.549461
  validation loss:		0.587278
  validation accuracy:		80.33 %
Epoch 856 of 2000 took 0.097s
  training loss:		0.542117
  validation loss:		0.563218
  validation accuracy:		80.87 %
Epoch 857 of 2000 took 0.097s
  training loss:		0.554485
  validation loss:		0.559390
  validation accuracy:		81.09 %
Epoch 858 of 2000 took 0.097s
  training loss:		0.541491
  validation loss:		0.572443
  validation accuracy:		80.87 %
Epoch 859 of 2000 took 0.097s
  training loss:		0.549142
  validation loss:		0.553432
  validation accuracy:		80.98 %
Epoch 860 of 2000 took 0.097s
  training loss:		0.539049
  validation loss:		0.568264
  validation accuracy:		81.41 %
Epoch 861 of 2000 took 0.097s
  training loss:		0.547065
  validation loss:		0.566528
  validation accuracy:		81.09 %
Epoch 862 of 2000 took 0.097s
  training loss:		0.541749
  validation loss:		0.570793
  validation accuracy:		80.76 %
Epoch 863 of 2000 took 0.097s
  training loss:		0.544901
  validation loss:		0.620981
  validation accuracy:		79.67 %
Epoch 864 of 2000 took 0.097s
  training loss:		0.548499
  validation loss:		0.575145
  validation accuracy:		80.65 %
Epoch 865 of 2000 took 0.098s
  training loss:		0.549178
  validation loss:		0.565177
  validation accuracy:		80.65 %
Epoch 866 of 2000 took 0.097s
  training loss:		0.549694
  validation loss:		0.587239
  validation accuracy:		80.22 %
Epoch 867 of 2000 took 0.097s
  training loss:		0.542954
  validation loss:		0.562811
  validation accuracy:		80.87 %
Epoch 868 of 2000 took 0.097s
  training loss:		0.553137
  validation loss:		0.599741
  validation accuracy:		80.76 %
Epoch 869 of 2000 took 0.097s
  training loss:		0.543798
  validation loss:		0.561831
  validation accuracy:		81.41 %
Epoch 870 of 2000 took 0.097s
  training loss:		0.550690
  validation loss:		0.568822
  validation accuracy:		80.87 %
Epoch 871 of 2000 took 0.097s
  training loss:		0.549896
  validation loss:		0.564636
  validation accuracy:		80.76 %
Epoch 872 of 2000 took 0.097s
  training loss:		0.541472
  validation loss:		0.552455
  validation accuracy:		81.52 %
Epoch 873 of 2000 took 0.097s
  training loss:		0.527529
  validation loss:		0.550563
  validation accuracy:		81.41 %
Epoch 874 of 2000 took 0.097s
  training loss:		0.549757
  validation loss:		0.566451
  validation accuracy:		81.30 %
Epoch 875 of 2000 took 0.097s
  training loss:		0.550148
  validation loss:		0.602618
  validation accuracy:		80.43 %
Epoch 876 of 2000 took 0.097s
  training loss:		0.546207
  validation loss:		0.568382
  validation accuracy:		81.30 %
Epoch 877 of 2000 took 0.097s
  training loss:		0.540567
  validation loss:		0.562584
  validation accuracy:		81.41 %
Epoch 878 of 2000 took 0.097s
  training loss:		0.546006
  validation loss:		0.556810
  validation accuracy:		80.98 %
Epoch 879 of 2000 took 0.097s
  training loss:		0.557879
  validation loss:		0.582518
  validation accuracy:		80.76 %
Epoch 880 of 2000 took 0.097s
  training loss:		0.545724
  validation loss:		0.562403
  validation accuracy:		81.30 %
Epoch 881 of 2000 took 0.097s
  training loss:		0.540902
  validation loss:		0.568691
  validation accuracy:		81.09 %
Epoch 882 of 2000 took 0.097s
  training loss:		0.532512
  validation loss:		0.562417
  validation accuracy:		81.20 %
Epoch 883 of 2000 took 0.097s
  training loss:		0.553971
  validation loss:		0.564076
  validation accuracy:		80.98 %
Epoch 884 of 2000 took 0.097s
  training loss:		0.545299
  validation loss:		0.578160
  validation accuracy:		80.22 %
Epoch 885 of 2000 took 0.097s
  training loss:		0.549997
  validation loss:		0.581093
  validation accuracy:		80.22 %
Epoch 886 of 2000 took 0.097s
  training loss:		0.536685
  validation loss:		0.563587
  validation accuracy:		80.54 %
Epoch 887 of 2000 took 0.097s
  training loss:		0.549320
  validation loss:		0.566331
  validation accuracy:		81.30 %
Epoch 888 of 2000 took 0.097s
  training loss:		0.537408
  validation loss:		0.557760
  validation accuracy:		80.43 %
Epoch 889 of 2000 took 0.097s
  training loss:		0.544122
  validation loss:		0.591747
  validation accuracy:		80.87 %
Epoch 890 of 2000 took 0.097s
  training loss:		0.538730
  validation loss:		0.555105
  validation accuracy:		81.30 %
Epoch 891 of 2000 took 0.097s
  training loss:		0.541997
  validation loss:		0.559274
  validation accuracy:		81.09 %
Epoch 892 of 2000 took 0.097s
  training loss:		0.542769
  validation loss:		0.551711
  validation accuracy:		81.41 %
Epoch 893 of 2000 took 0.097s
  training loss:		0.547294
  validation loss:		0.561470
  validation accuracy:		81.41 %
Epoch 894 of 2000 took 0.097s
  training loss:		0.545590
  validation loss:		0.620320
  validation accuracy:		79.02 %
Epoch 895 of 2000 took 0.097s
  training loss:		0.548040
  validation loss:		0.574117
  validation accuracy:		80.87 %
Epoch 896 of 2000 took 0.097s
  training loss:		0.532607
  validation loss:		0.569664
  validation accuracy:		80.76 %
Epoch 897 of 2000 took 0.098s
  training loss:		0.548440
  validation loss:		0.592089
  validation accuracy:		80.00 %
Epoch 898 of 2000 took 0.097s
  training loss:		0.545154
  validation loss:		0.561642
  validation accuracy:		81.09 %
Epoch 899 of 2000 took 0.097s
  training loss:		0.539017
  validation loss:		0.553882
  validation accuracy:		81.41 %
Epoch 900 of 2000 took 0.100s
  training loss:		0.546813
  validation loss:		0.575997
  validation accuracy:		80.65 %
Epoch 901 of 2000 took 0.097s
  training loss:		0.534416
  validation loss:		0.556922
  validation accuracy:		81.20 %
Epoch 902 of 2000 took 0.097s
  training loss:		0.549378
  validation loss:		0.563859
  validation accuracy:		81.20 %
Epoch 903 of 2000 took 0.097s
  training loss:		0.541379
  validation loss:		0.552285
  validation accuracy:		81.52 %
Epoch 904 of 2000 took 0.097s
  training loss:		0.549064
  validation loss:		0.629108
  validation accuracy:		78.70 %
Epoch 905 of 2000 took 0.097s
  training loss:		0.559486
  validation loss:		0.569195
  validation accuracy:		80.76 %
Epoch 906 of 2000 took 0.097s
  training loss:		0.536579
  validation loss:		0.574233
  validation accuracy:		81.41 %
Epoch 907 of 2000 took 0.097s
  training loss:		0.540176
  validation loss:		0.589266
  validation accuracy:		80.33 %
Epoch 908 of 2000 took 0.097s
  training loss:		0.542371
  validation loss:		0.551321
  validation accuracy:		81.30 %
Epoch 909 of 2000 took 0.097s
  training loss:		0.553340
  validation loss:		0.561221
  validation accuracy:		80.87 %
Epoch 910 of 2000 took 0.097s
  training loss:		0.544813
  validation loss:		0.565773
  validation accuracy:		80.98 %
Epoch 911 of 2000 took 0.097s
  training loss:		0.548993
  validation loss:		0.555707
  validation accuracy:		81.41 %
Epoch 912 of 2000 took 0.097s
  training loss:		0.547568
  validation loss:		0.577687
  validation accuracy:		80.65 %
Epoch 913 of 2000 took 0.097s
  training loss:		0.549400
  validation loss:		0.554574
  validation accuracy:		81.52 %
Epoch 914 of 2000 took 0.097s
  training loss:		0.540902
  validation loss:		0.559973
  validation accuracy:		80.87 %
Epoch 915 of 2000 took 0.097s
  training loss:		0.541703
  validation loss:		0.557189
  validation accuracy:		80.98 %
Epoch 916 of 2000 took 0.097s
  training loss:		0.552807
  validation loss:		0.600548
  validation accuracy:		80.22 %
Epoch 917 of 2000 took 0.097s
  training loss:		0.552404
  validation loss:		0.563855
  validation accuracy:		81.09 %
Epoch 918 of 2000 took 0.097s
  training loss:		0.549886
  validation loss:		0.570111
  validation accuracy:		80.76 %
Epoch 919 of 2000 took 0.097s
  training loss:		0.539818
  validation loss:		0.582964
  validation accuracy:		80.22 %
Epoch 920 of 2000 took 0.097s
  training loss:		0.542890
  validation loss:		0.555725
  validation accuracy:		81.96 %
Epoch 921 of 2000 took 0.097s
  training loss:		0.542705
  validation loss:		0.557194
  validation accuracy:		81.41 %
Epoch 922 of 2000 took 0.097s
  training loss:		0.542813
  validation loss:		0.574189
  validation accuracy:		80.87 %
Epoch 923 of 2000 took 0.097s
  training loss:		0.549229
  validation loss:		0.553689
  validation accuracy:		81.41 %
Epoch 924 of 2000 took 0.097s
  training loss:		0.547280
  validation loss:		0.584252
  validation accuracy:		80.76 %
Epoch 925 of 2000 took 0.097s
  training loss:		0.547879
  validation loss:		0.575942
  validation accuracy:		80.54 %
Epoch 926 of 2000 took 0.097s
  training loss:		0.541462
  validation loss:		0.553391
  validation accuracy:		81.30 %
Epoch 927 of 2000 took 0.097s
  training loss:		0.547914
  validation loss:		0.569163
  validation accuracy:		80.76 %
Epoch 928 of 2000 took 0.098s
  training loss:		0.541287
  validation loss:		0.569065
  validation accuracy:		80.87 %
Epoch 929 of 2000 took 0.097s
  training loss:		0.552839
  validation loss:		0.555691
  validation accuracy:		81.74 %
Epoch 930 of 2000 took 0.097s
  training loss:		0.547700
  validation loss:		0.551188
  validation accuracy:		81.09 %
Epoch 931 of 2000 took 0.097s
  training loss:		0.547645
  validation loss:		0.577797
  validation accuracy:		80.65 %
Epoch 932 of 2000 took 0.097s
  training loss:		0.547626
  validation loss:		0.571151
  validation accuracy:		80.76 %
Epoch 933 of 2000 took 0.097s
  training loss:		0.551832
  validation loss:		0.569410
  validation accuracy:		81.52 %
Epoch 934 of 2000 took 0.097s
  training loss:		0.538274
  validation loss:		0.551841
  validation accuracy:		81.52 %
Epoch 935 of 2000 took 0.097s
  training loss:		0.547208
  validation loss:		0.552792
  validation accuracy:		81.30 %
Epoch 936 of 2000 took 0.097s
  training loss:		0.540988
  validation loss:		0.579984
  validation accuracy:		80.54 %
Epoch 937 of 2000 took 0.097s
  training loss:		0.541811
  validation loss:		0.557806
  validation accuracy:		81.20 %
Epoch 938 of 2000 took 0.097s
  training loss:		0.554299
  validation loss:		0.601808
  validation accuracy:		79.46 %
Epoch 939 of 2000 took 0.097s
  training loss:		0.551940
  validation loss:		0.598200
  validation accuracy:		79.78 %
Epoch 940 of 2000 took 0.097s
  training loss:		0.542129
  validation loss:		0.605437
  validation accuracy:		79.78 %
Epoch 941 of 2000 took 0.097s
  training loss:		0.537378
  validation loss:		0.567129
  validation accuracy:		81.09 %
Epoch 942 of 2000 took 0.097s
  training loss:		0.536597
  validation loss:		0.579027
  validation accuracy:		80.33 %
Epoch 943 of 2000 took 0.097s
  training loss:		0.542716
  validation loss:		0.592191
  validation accuracy:		79.78 %
Epoch 944 of 2000 took 0.097s
  training loss:		0.540253
  validation loss:		0.561280
  validation accuracy:		81.09 %
Epoch 945 of 2000 took 0.097s
  training loss:		0.543176
  validation loss:		0.549725
  validation accuracy:		81.41 %
Epoch 946 of 2000 took 0.097s
  training loss:		0.551475
  validation loss:		0.558331
  validation accuracy:		81.30 %
Epoch 947 of 2000 took 0.097s
  training loss:		0.545240
  validation loss:		0.563401
  validation accuracy:		81.30 %
Epoch 948 of 2000 took 0.097s
  training loss:		0.544226
  validation loss:		0.566836
  validation accuracy:		80.98 %
Epoch 949 of 2000 took 0.097s
  training loss:		0.531103
  validation loss:		0.556929
  validation accuracy:		81.41 %
Epoch 950 of 2000 took 0.097s
  training loss:		0.543356
  validation loss:		0.554560
  validation accuracy:		81.09 %
Epoch 951 of 2000 took 0.097s
  training loss:		0.549734
  validation loss:		0.607835
  validation accuracy:		79.78 %
Epoch 952 of 2000 took 0.097s
  training loss:		0.549295
  validation loss:		0.555808
  validation accuracy:		81.20 %
Epoch 953 of 2000 took 0.097s
  training loss:		0.543075
  validation loss:		0.566852
  validation accuracy:		80.87 %
Epoch 954 of 2000 took 0.097s
  training loss:		0.541509
  validation loss:		0.597638
  validation accuracy:		79.57 %
Epoch 955 of 2000 took 0.097s
  training loss:		0.549411
  validation loss:		0.561230
  validation accuracy:		81.20 %
Epoch 956 of 2000 took 0.097s
  training loss:		0.535205
  validation loss:		0.562062
  validation accuracy:		81.41 %
Epoch 957 of 2000 took 0.097s
  training loss:		0.538473
  validation loss:		0.573703
  validation accuracy:		81.20 %
Epoch 958 of 2000 took 0.097s
  training loss:		0.551201
  validation loss:		0.553414
  validation accuracy:		81.52 %
Epoch 959 of 2000 took 0.098s
  training loss:		0.548207
  validation loss:		0.567463
  validation accuracy:		81.20 %
Epoch 960 of 2000 took 0.097s
  training loss:		0.533319
  validation loss:		0.557847
  validation accuracy:		80.98 %
Epoch 961 of 2000 took 0.097s
  training loss:		0.541559
  validation loss:		0.550549
  validation accuracy:		81.20 %
Epoch 962 of 2000 took 0.097s
  training loss:		0.558773
  validation loss:		0.550938
  validation accuracy:		81.30 %
Epoch 963 of 2000 took 0.097s
  training loss:		0.540652
  validation loss:		0.561218
  validation accuracy:		80.98 %
Epoch 964 of 2000 took 0.097s
  training loss:		0.550568
  validation loss:		0.557223
  validation accuracy:		81.30 %
Epoch 965 of 2000 took 0.097s
  training loss:		0.546390
  validation loss:		0.575605
  validation accuracy:		81.30 %
Epoch 966 of 2000 took 0.097s
  training loss:		0.543216
  validation loss:		0.557280
  validation accuracy:		81.20 %
Epoch 967 of 2000 took 0.097s
  training loss:		0.545689
  validation loss:		0.557248
  validation accuracy:		81.41 %
Epoch 968 of 2000 took 0.097s
  training loss:		0.541905
  validation loss:		0.550385
  validation accuracy:		81.52 %
Epoch 969 of 2000 took 0.097s
  training loss:		0.543250
  validation loss:		0.556400
  validation accuracy:		81.52 %
Epoch 970 of 2000 took 0.097s
  training loss:		0.546531
  validation loss:		0.550439
  validation accuracy:		81.20 %
Epoch 971 of 2000 took 0.097s
  training loss:		0.550505
  validation loss:		0.574762
  validation accuracy:		80.87 %
Epoch 972 of 2000 took 0.097s
  training loss:		0.535539
  validation loss:		0.614717
  validation accuracy:		79.35 %
Epoch 973 of 2000 took 0.097s
  training loss:		0.544962
  validation loss:		0.555430
  validation accuracy:		81.20 %
Epoch 974 of 2000 took 0.097s
  training loss:		0.547861
  validation loss:		0.560299
  validation accuracy:		81.30 %
Epoch 975 of 2000 took 0.097s
  training loss:		0.536211
  validation loss:		0.557047
  validation accuracy:		81.41 %
Epoch 976 of 2000 took 0.097s
  training loss:		0.534658
  validation loss:		0.563059
  validation accuracy:		81.30 %
Epoch 977 of 2000 took 0.097s
  training loss:		0.539341
  validation loss:		0.551979
  validation accuracy:		81.85 %
Epoch 978 of 2000 took 0.097s
  training loss:		0.543091
  validation loss:		0.626115
  validation accuracy:		79.46 %
Epoch 979 of 2000 took 0.097s
  training loss:		0.543974
  validation loss:		0.555404
  validation accuracy:		81.52 %
Epoch 980 of 2000 took 0.097s
  training loss:		0.551190
  validation loss:		0.583019
  validation accuracy:		80.11 %
Epoch 981 of 2000 took 0.097s
  training loss:		0.554571
  validation loss:		0.566445
  validation accuracy:		81.20 %
Epoch 982 of 2000 took 0.097s
  training loss:		0.535167
  validation loss:		0.560164
  validation accuracy:		81.09 %
Epoch 983 of 2000 took 0.097s
  training loss:		0.545410
  validation loss:		0.594351
  validation accuracy:		80.00 %
Epoch 984 of 2000 took 0.097s
  training loss:		0.547224
  validation loss:		0.556083
  validation accuracy:		81.52 %
Epoch 985 of 2000 took 0.097s
  training loss:		0.532417
  validation loss:		0.588430
  validation accuracy:		80.65 %
Epoch 986 of 2000 took 0.097s
  training loss:		0.538315
  validation loss:		0.577257
  validation accuracy:		81.30 %
Epoch 987 of 2000 took 0.097s
  training loss:		0.543809
  validation loss:		0.548884
  validation accuracy:		81.96 %
Epoch 988 of 2000 took 0.097s
  training loss:		0.545889
  validation loss:		0.558182
  validation accuracy:		81.30 %
Epoch 989 of 2000 took 0.097s
  training loss:		0.544523
  validation loss:		0.565291
  validation accuracy:		81.09 %
Epoch 990 of 2000 took 0.098s
  training loss:		0.536027
  validation loss:		0.549109
  validation accuracy:		82.07 %
Epoch 991 of 2000 took 0.097s
  training loss:		0.542360
  validation loss:		0.555391
  validation accuracy:		81.52 %
Epoch 992 of 2000 took 0.097s
  training loss:		0.545282
  validation loss:		0.572646
  validation accuracy:		80.65 %
Epoch 993 of 2000 took 0.097s
  training loss:		0.543819
  validation loss:		0.569236
  validation accuracy:		80.65 %
Epoch 994 of 2000 took 0.097s
  training loss:		0.545563
  validation loss:		0.572690
  validation accuracy:		81.09 %
Epoch 995 of 2000 took 0.097s
  training loss:		0.546938
  validation loss:		0.559481
  validation accuracy:		81.52 %
Epoch 996 of 2000 took 0.097s
  training loss:		0.544655
  validation loss:		0.553279
  validation accuracy:		81.41 %
Epoch 997 of 2000 took 0.097s
  training loss:		0.539871
  validation loss:		0.559690
  validation accuracy:		80.98 %
Epoch 998 of 2000 took 0.097s
  training loss:		0.544121
  validation loss:		0.566661
  validation accuracy:		81.09 %
Epoch 999 of 2000 took 0.097s
  training loss:		0.535547
  validation loss:		0.562116
  validation accuracy:		81.52 %
Epoch 1000 of 2000 took 0.097s
  training loss:		0.545244
  validation loss:		0.563737
  validation accuracy:		81.52 %
Epoch 1001 of 2000 took 0.097s
  training loss:		0.549998
  validation loss:		0.560556
  validation accuracy:		81.41 %
Epoch 1002 of 2000 took 0.097s
  training loss:		0.535070
  validation loss:		0.562730
  validation accuracy:		80.98 %
Epoch 1003 of 2000 took 0.097s
  training loss:		0.543148
  validation loss:		0.551017
  validation accuracy:		81.52 %
Epoch 1004 of 2000 took 0.097s
  training loss:		0.542118
  validation loss:		0.561593
  validation accuracy:		81.20 %
Epoch 1005 of 2000 took 0.097s
  training loss:		0.549571
  validation loss:		0.555601
  validation accuracy:		81.41 %
Epoch 1006 of 2000 took 0.097s
  training loss:		0.543440
  validation loss:		0.553680
  validation accuracy:		81.96 %
Epoch 1007 of 2000 took 0.097s
  training loss:		0.547029
  validation loss:		0.558922
  validation accuracy:		81.52 %
Epoch 1008 of 2000 took 0.097s
  training loss:		0.537384
  validation loss:		0.556596
  validation accuracy:		81.09 %
Epoch 1009 of 2000 took 0.097s
  training loss:		0.537526
  validation loss:		0.559459
  validation accuracy:		81.52 %
Epoch 1010 of 2000 took 0.099s
  training loss:		0.547094
  validation loss:		0.551143
  validation accuracy:		81.63 %
Epoch 1011 of 2000 took 0.100s
  training loss:		0.543700
  validation loss:		0.579844
  validation accuracy:		81.09 %
Epoch 1012 of 2000 took 0.100s
  training loss:		0.538403
  validation loss:		0.556427
  validation accuracy:		81.09 %
Epoch 1013 of 2000 took 0.100s
  training loss:		0.547179
  validation loss:		0.572961
  validation accuracy:		80.76 %
Epoch 1014 of 2000 took 0.100s
  training loss:		0.542280
  validation loss:		0.554891
  validation accuracy:		81.41 %
Epoch 1015 of 2000 took 0.100s
  training loss:		0.536012
  validation loss:		0.577914
  validation accuracy:		80.43 %
Epoch 1016 of 2000 took 0.100s
  training loss:		0.540718
  validation loss:		0.573225
  validation accuracy:		80.87 %
Epoch 1017 of 2000 took 0.100s
  training loss:		0.573973
  validation loss:		0.563460
  validation accuracy:		81.09 %
Epoch 1018 of 2000 took 0.100s
  training loss:		0.533673
  validation loss:		0.580123
  validation accuracy:		80.54 %
Epoch 1019 of 2000 took 0.100s
  training loss:		0.541987
  validation loss:		0.562328
  validation accuracy:		81.41 %
Epoch 1020 of 2000 took 0.101s
  training loss:		0.536532
  validation loss:		0.570279
  validation accuracy:		81.20 %
Epoch 1021 of 2000 took 0.100s
  training loss:		0.541986
  validation loss:		0.563908
  validation accuracy:		81.52 %
Epoch 1022 of 2000 took 0.100s
  training loss:		0.547516
  validation loss:		0.565563
  validation accuracy:		81.41 %
Epoch 1023 of 2000 took 0.100s
  training loss:		0.542316
  validation loss:		0.551604
  validation accuracy:		81.96 %
Epoch 1024 of 2000 took 0.100s
  training loss:		0.537317
  validation loss:		0.557766
  validation accuracy:		81.63 %
Epoch 1025 of 2000 took 0.100s
  training loss:		0.539635
  validation loss:		0.557539
  validation accuracy:		81.41 %
Epoch 1026 of 2000 took 0.100s
  training loss:		0.546294
  validation loss:		0.565227
  validation accuracy:		81.41 %
Epoch 1027 of 2000 took 0.100s
  training loss:		0.556564
  validation loss:		0.567731
  validation accuracy:		81.41 %
Epoch 1028 of 2000 took 0.100s
  training loss:		0.535828
  validation loss:		0.559115
  validation accuracy:		81.41 %
Epoch 1029 of 2000 took 0.100s
  training loss:		0.548974
  validation loss:		0.566973
  validation accuracy:		80.87 %
Epoch 1030 of 2000 took 0.100s
  training loss:		0.543912
  validation loss:		0.557500
  validation accuracy:		81.30 %
Epoch 1031 of 2000 took 0.100s
  training loss:		0.547534
  validation loss:		0.545795
  validation accuracy:		81.85 %
Epoch 1032 of 2000 took 0.100s
  training loss:		0.541199
  validation loss:		0.577205
  validation accuracy:		80.65 %
Epoch 1033 of 2000 took 0.100s
  training loss:		0.539257
  validation loss:		0.550561
  validation accuracy:		81.41 %
Epoch 1034 of 2000 took 0.100s
  training loss:		0.549897
  validation loss:		0.563803
  validation accuracy:		80.98 %
Epoch 1035 of 2000 took 0.100s
  training loss:		0.547019
  validation loss:		0.568783
  validation accuracy:		80.98 %
Epoch 1036 of 2000 took 0.100s
  training loss:		0.544274
  validation loss:		0.557581
  validation accuracy:		81.52 %
Epoch 1037 of 2000 took 0.100s
  training loss:		0.546832
  validation loss:		0.576568
  validation accuracy:		80.98 %
Epoch 1038 of 2000 took 0.100s
  training loss:		0.542816
  validation loss:		0.556851
  validation accuracy:		81.52 %
Epoch 1039 of 2000 took 0.100s
  training loss:		0.534784
  validation loss:		0.565255
  validation accuracy:		80.76 %
Epoch 1040 of 2000 took 0.100s
  training loss:		0.546420
  validation loss:		0.549738
  validation accuracy:		81.74 %
Epoch 1041 of 2000 took 0.100s
  training loss:		0.542143
  validation loss:		0.557775
  validation accuracy:		81.30 %
Epoch 1042 of 2000 took 0.100s
  training loss:		0.552035
  validation loss:		0.554435
  validation accuracy:		81.74 %
Epoch 1043 of 2000 took 0.100s
  training loss:		0.557612
  validation loss:		0.586327
  validation accuracy:		81.09 %
Epoch 1044 of 2000 took 0.100s
  training loss:		0.533803
  validation loss:		0.566314
  validation accuracy:		81.20 %
Epoch 1045 of 2000 took 0.100s
  training loss:		0.544712
  validation loss:		0.581055
  validation accuracy:		81.09 %
Epoch 1046 of 2000 took 0.100s
  training loss:		0.533559
  validation loss:		0.572089
  validation accuracy:		80.87 %
Epoch 1047 of 2000 took 0.100s
  training loss:		0.543136
  validation loss:		0.561668
  validation accuracy:		81.41 %
Epoch 1048 of 2000 took 0.100s
  training loss:		0.539019
  validation loss:		0.557381
  validation accuracy:		81.74 %
Epoch 1049 of 2000 took 0.100s
  training loss:		0.549588
  validation loss:		0.568970
  validation accuracy:		80.98 %
Epoch 1050 of 2000 took 0.100s
  training loss:		0.542918
  validation loss:		0.558329
  validation accuracy:		81.20 %
Epoch 1051 of 2000 took 0.101s
  training loss:		0.537810
  validation loss:		0.565966
  validation accuracy:		81.20 %
Epoch 1052 of 2000 took 0.100s
  training loss:		0.543440
  validation loss:		0.561287
  validation accuracy:		81.20 %
Epoch 1053 of 2000 took 0.100s
  training loss:		0.541559
  validation loss:		0.553085
  validation accuracy:		81.63 %
Epoch 1054 of 2000 took 0.100s
  training loss:		0.538419
  validation loss:		0.570291
  validation accuracy:		81.20 %
Epoch 1055 of 2000 took 0.100s
  training loss:		0.539805
  validation loss:		0.552500
  validation accuracy:		81.85 %
Epoch 1056 of 2000 took 0.100s
  training loss:		0.540588
  validation loss:		0.557492
  validation accuracy:		81.63 %
Epoch 1057 of 2000 took 0.100s
  training loss:		0.545960
  validation loss:		0.560320
  validation accuracy:		81.20 %
Epoch 1058 of 2000 took 0.100s
  training loss:		0.534848
  validation loss:		0.568318
  validation accuracy:		81.20 %
Epoch 1059 of 2000 took 0.100s
  training loss:		0.541509
  validation loss:		0.553811
  validation accuracy:		81.74 %
Epoch 1060 of 2000 took 0.100s
  training loss:		0.543565
  validation loss:		0.553549
  validation accuracy:		81.96 %
Epoch 1061 of 2000 took 0.100s
  training loss:		0.546987
  validation loss:		0.574653
  validation accuracy:		80.87 %
Epoch 1062 of 2000 took 0.100s
  training loss:		0.538046
  validation loss:		0.564520
  validation accuracy:		81.20 %
Epoch 1063 of 2000 took 0.100s
  training loss:		0.530807
  validation loss:		0.555025
  validation accuracy:		82.07 %
Epoch 1064 of 2000 took 0.100s
  training loss:		0.539779
  validation loss:		0.558702
  validation accuracy:		81.74 %
Epoch 1065 of 2000 took 0.100s
  training loss:		0.536493
  validation loss:		0.550394
  validation accuracy:		82.07 %
Epoch 1066 of 2000 took 0.100s
  training loss:		0.544386
  validation loss:		0.555254
  validation accuracy:		81.74 %
Epoch 1067 of 2000 took 0.100s
  training loss:		0.543171
  validation loss:		0.567938
  validation accuracy:		81.09 %
Epoch 1068 of 2000 took 0.100s
  training loss:		0.538509
  validation loss:		0.568600
  validation accuracy:		80.98 %
Epoch 1069 of 2000 took 0.100s
  training loss:		0.548860
  validation loss:		0.579674
  validation accuracy:		80.65 %
Epoch 1070 of 2000 took 0.100s
  training loss:		0.531419
  validation loss:		0.575488
  validation accuracy:		81.30 %
Epoch 1071 of 2000 took 0.100s
  training loss:		0.546489
  validation loss:		0.552128
  validation accuracy:		81.63 %
Epoch 1072 of 2000 took 0.100s
  training loss:		0.538322
  validation loss:		0.583015
  validation accuracy:		80.87 %
Epoch 1073 of 2000 took 0.100s
  training loss:		0.541533
  validation loss:		0.575299
  validation accuracy:		80.76 %
Epoch 1074 of 2000 took 0.100s
  training loss:		0.537329
  validation loss:		0.551528
  validation accuracy:		81.52 %
Epoch 1075 of 2000 took 0.100s
  training loss:		0.552083
  validation loss:		0.591478
  validation accuracy:		81.09 %
Epoch 1076 of 2000 took 0.100s
  training loss:		0.541976
  validation loss:		0.570988
  validation accuracy:		81.09 %
Epoch 1077 of 2000 took 0.100s
  training loss:		0.541333
  validation loss:		0.566220
  validation accuracy:		81.20 %
Epoch 1078 of 2000 took 0.100s
  training loss:		0.546673
  validation loss:		0.590869
  validation accuracy:		80.22 %
Epoch 1079 of 2000 took 0.100s
  training loss:		0.546984
  validation loss:		0.564167
  validation accuracy:		81.20 %
Epoch 1080 of 2000 took 0.100s
  training loss:		0.552624
  validation loss:		0.566049
  validation accuracy:		80.98 %
Epoch 1081 of 2000 took 0.101s
  training loss:		0.551281
  validation loss:		0.555661
  validation accuracy:		81.96 %
Epoch 1082 of 2000 took 0.103s
  training loss:		0.547020
  validation loss:		0.554302
  validation accuracy:		81.20 %
Epoch 1083 of 2000 took 0.100s
  training loss:		0.548721
  validation loss:		0.550247
  validation accuracy:		81.96 %
Epoch 1084 of 2000 took 0.100s
  training loss:		0.551892
  validation loss:		0.581509
  validation accuracy:		80.22 %
Epoch 1085 of 2000 took 0.100s
  training loss:		0.542236
  validation loss:		0.554927
  validation accuracy:		81.52 %
Epoch 1086 of 2000 took 0.100s
  training loss:		0.542276
  validation loss:		0.567568
  validation accuracy:		80.87 %
Epoch 1087 of 2000 took 0.100s
  training loss:		0.533335
  validation loss:		0.560359
  validation accuracy:		81.41 %
Epoch 1088 of 2000 took 0.100s
  training loss:		0.540885
  validation loss:		0.547352
  validation accuracy:		81.96 %
Epoch 1089 of 2000 took 0.100s
  training loss:		0.534150
  validation loss:		0.574094
  validation accuracy:		81.30 %
Epoch 1090 of 2000 took 0.098s
  training loss:		0.542837
  validation loss:		0.568859
  validation accuracy:		80.98 %
Epoch 1091 of 2000 took 0.097s
  training loss:		0.545624
  validation loss:		0.569603
  validation accuracy:		81.52 %
Epoch 1092 of 2000 took 0.097s
  training loss:		0.548544
  validation loss:		0.548076
  validation accuracy:		81.52 %
Epoch 1093 of 2000 took 0.097s
  training loss:		0.545133
  validation loss:		0.557616
  validation accuracy:		81.41 %
Epoch 1094 of 2000 took 0.097s
  training loss:		0.543457
  validation loss:		0.571268
  validation accuracy:		80.65 %
Epoch 1095 of 2000 took 0.097s
  training loss:		0.540549
  validation loss:		0.553806
  validation accuracy:		81.85 %
Epoch 1096 of 2000 took 0.097s
  training loss:		0.539635
  validation loss:		0.566755
  validation accuracy:		80.76 %
Epoch 1097 of 2000 took 0.097s
  training loss:		0.540593
  validation loss:		0.553064
  validation accuracy:		81.85 %
Epoch 1098 of 2000 took 0.097s
  training loss:		0.527433
  validation loss:		0.562649
  validation accuracy:		81.09 %
Epoch 1099 of 2000 took 0.097s
  training loss:		0.540951
  validation loss:		0.554866
  validation accuracy:		81.30 %
Epoch 1100 of 2000 took 0.097s
  training loss:		0.539451
  validation loss:		0.552888
  validation accuracy:		81.63 %
Epoch 1101 of 2000 took 0.097s
  training loss:		0.541174
  validation loss:		0.572754
  validation accuracy:		81.09 %
Epoch 1102 of 2000 took 0.097s
  training loss:		0.542400
  validation loss:		0.565443
  validation accuracy:		80.54 %
Epoch 1103 of 2000 took 0.097s
  training loss:		0.534041
  validation loss:		0.549730
  validation accuracy:		82.07 %
Epoch 1104 of 2000 took 0.100s
  training loss:		0.559035
  validation loss:		0.564441
  validation accuracy:		80.98 %
Epoch 1105 of 2000 took 0.100s
  training loss:		0.534617
  validation loss:		0.562366
  validation accuracy:		81.41 %
Epoch 1106 of 2000 took 0.100s
  training loss:		0.537739
  validation loss:		0.555321
  validation accuracy:		81.41 %
Epoch 1107 of 2000 took 0.100s
  training loss:		0.539573
  validation loss:		0.592395
  validation accuracy:		80.11 %
Epoch 1108 of 2000 took 0.100s
  training loss:		0.530577
  validation loss:		0.590426
  validation accuracy:		81.30 %
Epoch 1109 of 2000 took 0.100s
  training loss:		0.541606
  validation loss:		0.547673
  validation accuracy:		82.07 %
Epoch 1110 of 2000 took 0.100s
  training loss:		0.546414
  validation loss:		0.588507
  validation accuracy:		80.43 %
Epoch 1111 of 2000 took 0.100s
  training loss:		0.539923
  validation loss:		0.555213
  validation accuracy:		81.85 %
Epoch 1112 of 2000 took 0.097s
  training loss:		0.545881
  validation loss:		0.558911
  validation accuracy:		81.41 %
Epoch 1113 of 2000 took 0.097s
  training loss:		0.544963
  validation loss:		0.575792
  validation accuracy:		80.33 %
Epoch 1114 of 2000 took 0.097s
  training loss:		0.547998
  validation loss:		0.567327
  validation accuracy:		80.76 %
Epoch 1115 of 2000 took 0.097s
  training loss:		0.542657
  validation loss:		0.617289
  validation accuracy:		80.00 %
Epoch 1116 of 2000 took 0.098s
  training loss:		0.545761
  validation loss:		0.587416
  validation accuracy:		80.54 %
Epoch 1117 of 2000 took 0.097s
  training loss:		0.551403
  validation loss:		0.546768
  validation accuracy:		81.74 %
Epoch 1118 of 2000 took 0.097s
  training loss:		0.539085
  validation loss:		0.549173
  validation accuracy:		81.96 %
Epoch 1119 of 2000 took 0.097s
  training loss:		0.540206
  validation loss:		0.558978
  validation accuracy:		81.41 %
Epoch 1120 of 2000 took 0.097s
  training loss:		0.532440
  validation loss:		0.560404
  validation accuracy:		81.41 %
Epoch 1121 of 2000 took 0.097s
  training loss:		0.534945
  validation loss:		0.545434
  validation accuracy:		81.41 %
Epoch 1122 of 2000 took 0.097s
  training loss:		0.545549
  validation loss:		0.568654
  validation accuracy:		81.63 %
Epoch 1123 of 2000 took 0.097s
  training loss:		0.541291
  validation loss:		0.566919
  validation accuracy:		80.87 %
Epoch 1124 of 2000 took 0.097s
  training loss:		0.535921
  validation loss:		0.570496
  validation accuracy:		80.33 %
Epoch 1125 of 2000 took 0.097s
  training loss:		0.540023
  validation loss:		0.546827
  validation accuracy:		81.85 %
Epoch 1126 of 2000 took 0.097s
  training loss:		0.542670
  validation loss:		0.550914
  validation accuracy:		81.63 %
Epoch 1127 of 2000 took 0.097s
  training loss:		0.527116
  validation loss:		0.551165
  validation accuracy:		81.63 %
Epoch 1128 of 2000 took 0.097s
  training loss:		0.545518
  validation loss:		0.549560
  validation accuracy:		81.74 %
Epoch 1129 of 2000 took 0.097s
  training loss:		0.545163
  validation loss:		0.556746
  validation accuracy:		81.52 %
Epoch 1130 of 2000 took 0.097s
  training loss:		0.538726
  validation loss:		0.563666
  validation accuracy:		81.20 %
Epoch 1131 of 2000 took 0.097s
  training loss:		0.540941
  validation loss:		0.558618
  validation accuracy:		81.41 %
Epoch 1132 of 2000 took 0.097s
  training loss:		0.532965
  validation loss:		0.581706
  validation accuracy:		80.76 %
Epoch 1133 of 2000 took 0.097s
  training loss:		0.537351
  validation loss:		0.564536
  validation accuracy:		81.09 %
Epoch 1134 of 2000 took 0.097s
  training loss:		0.540916
  validation loss:		0.575552
  validation accuracy:		80.87 %
Epoch 1135 of 2000 took 0.097s
  training loss:		0.544762
  validation loss:		0.566699
  validation accuracy:		80.76 %
Epoch 1136 of 2000 took 0.097s
  training loss:		0.544372
  validation loss:		0.563731
  validation accuracy:		80.87 %
Epoch 1137 of 2000 took 0.097s
  training loss:		0.541717
  validation loss:		0.567815
  validation accuracy:		80.65 %
Epoch 1138 of 2000 took 0.097s
  training loss:		0.536659
  validation loss:		0.580271
  validation accuracy:		80.65 %
Epoch 1139 of 2000 took 0.097s
  training loss:		0.540773
  validation loss:		0.578762
  validation accuracy:		80.54 %
Epoch 1140 of 2000 took 0.097s
  training loss:		0.539614
  validation loss:		0.556807
  validation accuracy:		81.63 %
Epoch 1141 of 2000 took 0.097s
  training loss:		0.553968
  validation loss:		0.551604
  validation accuracy:		81.85 %
Epoch 1142 of 2000 took 0.098s
  training loss:		0.545469
  validation loss:		0.575173
  validation accuracy:		80.76 %
Epoch 1143 of 2000 took 0.097s
  training loss:		0.545486
  validation loss:		0.567493
  validation accuracy:		80.98 %
Epoch 1144 of 2000 took 0.097s
  training loss:		0.547398
  validation loss:		0.561520
  validation accuracy:		81.63 %
Epoch 1145 of 2000 took 0.097s
  training loss:		0.543061
  validation loss:		0.547681
  validation accuracy:		81.74 %
Epoch 1146 of 2000 took 0.097s
  training loss:		0.542910
  validation loss:		0.552586
  validation accuracy:		81.52 %
Epoch 1147 of 2000 took 0.097s
  training loss:		0.541678
  validation loss:		0.581051
  validation accuracy:		80.43 %
Epoch 1148 of 2000 took 0.097s
  training loss:		0.543833
  validation loss:		0.554171
  validation accuracy:		81.85 %
Epoch 1149 of 2000 took 0.097s
  training loss:		0.552182
  validation loss:		0.555747
  validation accuracy:		81.63 %
Epoch 1150 of 2000 took 0.097s
  training loss:		0.533254
  validation loss:		0.584114
  validation accuracy:		80.98 %
Epoch 1151 of 2000 took 0.097s
  training loss:		0.542212
  validation loss:		0.557423
  validation accuracy:		81.30 %
Epoch 1152 of 2000 took 0.097s
  training loss:		0.539278
  validation loss:		0.571048
  validation accuracy:		80.87 %
Epoch 1153 of 2000 took 0.097s
  training loss:		0.552030
  validation loss:		0.560399
  validation accuracy:		81.30 %
Epoch 1154 of 2000 took 0.097s
  training loss:		0.543654
  validation loss:		0.558043
  validation accuracy:		81.30 %
Epoch 1155 of 2000 took 0.097s
  training loss:		0.539302
  validation loss:		0.564479
  validation accuracy:		81.09 %
Epoch 1156 of 2000 took 0.097s
  training loss:		0.540329
  validation loss:		0.570213
  validation accuracy:		81.63 %
Epoch 1157 of 2000 took 0.097s
  training loss:		0.537789
  validation loss:		0.547848
  validation accuracy:		81.74 %
Epoch 1158 of 2000 took 0.097s
  training loss:		0.540197
  validation loss:		0.552781
  validation accuracy:		81.63 %
Epoch 1159 of 2000 took 0.097s
  training loss:		0.539949
  validation loss:		0.547305
  validation accuracy:		82.07 %
Epoch 1160 of 2000 took 0.097s
  training loss:		0.538358
  validation loss:		0.545000
  validation accuracy:		81.74 %
Epoch 1161 of 2000 took 0.097s
  training loss:		0.540098
  validation loss:		0.578114
  validation accuracy:		80.43 %
Epoch 1162 of 2000 took 0.097s
  training loss:		0.549466
  validation loss:		0.547734
  validation accuracy:		81.74 %
Epoch 1163 of 2000 took 0.097s
  training loss:		0.545578
  validation loss:		0.570105
  validation accuracy:		81.85 %
Epoch 1164 of 2000 took 0.097s
  training loss:		0.540598
  validation loss:		0.564102
  validation accuracy:		81.09 %
Epoch 1165 of 2000 took 0.097s
  training loss:		0.540130
  validation loss:		0.558780
  validation accuracy:		81.09 %
Epoch 1166 of 2000 took 0.097s
  training loss:		0.538614
  validation loss:		0.551658
  validation accuracy:		81.63 %
Epoch 1167 of 2000 took 0.097s
  training loss:		0.539286
  validation loss:		0.552451
  validation accuracy:		81.52 %
Epoch 1168 of 2000 took 0.097s
  training loss:		0.543120
  validation loss:		0.572495
  validation accuracy:		81.74 %
Epoch 1169 of 2000 took 0.097s
  training loss:		0.538246
  validation loss:		0.560569
  validation accuracy:		81.20 %
Epoch 1170 of 2000 took 0.097s
  training loss:		0.541081
  validation loss:		0.559190
  validation accuracy:		81.09 %
Epoch 1171 of 2000 took 0.097s
  training loss:		0.543267
  validation loss:		0.561959
  validation accuracy:		81.30 %
Epoch 1172 of 2000 took 0.097s
  training loss:		0.543282
  validation loss:		0.578281
  validation accuracy:		80.87 %
Epoch 1173 of 2000 took 0.098s
  training loss:		0.543719
  validation loss:		0.571547
  validation accuracy:		81.41 %
Epoch 1174 of 2000 took 0.097s
  training loss:		0.533539
  validation loss:		0.561892
  validation accuracy:		81.09 %
Epoch 1175 of 2000 took 0.097s
  training loss:		0.538920
  validation loss:		0.558777
  validation accuracy:		80.98 %
Epoch 1176 of 2000 took 0.097s
  training loss:		0.533418
  validation loss:		0.581568
  validation accuracy:		80.43 %
Epoch 1177 of 2000 took 0.097s
  training loss:		0.543591
  validation loss:		0.559180
  validation accuracy:		81.52 %
Epoch 1178 of 2000 took 0.097s
  training loss:		0.540372
  validation loss:		0.556574
  validation accuracy:		81.30 %
Epoch 1179 of 2000 took 0.097s
  training loss:		0.537991
  validation loss:		0.564617
  validation accuracy:		80.98 %
Epoch 1180 of 2000 took 0.097s
  training loss:		0.537930
  validation loss:		0.549780
  validation accuracy:		81.63 %
Epoch 1181 of 2000 took 0.097s
  training loss:		0.540627
  validation loss:		0.590312
  validation accuracy:		80.98 %
Epoch 1182 of 2000 took 0.097s
  training loss:		0.538489
  validation loss:		0.555155
  validation accuracy:		81.63 %
Epoch 1183 of 2000 took 0.097s
  training loss:		0.538144
  validation loss:		0.573723
  validation accuracy:		80.98 %
Epoch 1184 of 2000 took 0.097s
  training loss:		0.534769
  validation loss:		0.569929
  validation accuracy:		80.65 %
Epoch 1185 of 2000 took 0.097s
  training loss:		0.542810
  validation loss:		0.548557
  validation accuracy:		81.85 %
Epoch 1186 of 2000 took 0.097s
  training loss:		0.544738
  validation loss:		0.563620
  validation accuracy:		80.76 %
Epoch 1187 of 2000 took 0.097s
  training loss:		0.537611
  validation loss:		0.580609
  validation accuracy:		80.54 %
Epoch 1188 of 2000 took 0.097s
  training loss:		0.536464
  validation loss:		0.553188
  validation accuracy:		81.85 %
Epoch 1189 of 2000 took 0.097s
  training loss:		0.547258
  validation loss:		0.568458
  validation accuracy:		81.09 %
Epoch 1190 of 2000 took 0.097s
  training loss:		0.536909
  validation loss:		0.569404
  validation accuracy:		81.09 %
Epoch 1191 of 2000 took 0.097s
  training loss:		0.536855
  validation loss:		0.555626
  validation accuracy:		81.41 %
Epoch 1192 of 2000 took 0.097s
  training loss:		0.541329
  validation loss:		0.553402
  validation accuracy:		81.74 %
Epoch 1193 of 2000 took 0.097s
  training loss:		0.551842
  validation loss:		0.550273
  validation accuracy:		81.96 %
Epoch 1194 of 2000 took 0.097s
  training loss:		0.545935
  validation loss:		0.577561
  validation accuracy:		80.98 %
Epoch 1195 of 2000 took 0.097s
  training loss:		0.538993
  validation loss:		0.554823
  validation accuracy:		81.52 %
Epoch 1196 of 2000 took 0.097s
  training loss:		0.535202
  validation loss:		0.575792
  validation accuracy:		80.76 %
Epoch 1197 of 2000 took 0.097s
  training loss:		0.540734
  validation loss:		0.552090
  validation accuracy:		81.30 %
Epoch 1198 of 2000 took 0.097s
  training loss:		0.543592
  validation loss:		0.564007
  validation accuracy:		80.76 %
Epoch 1199 of 2000 took 0.097s
  training loss:		0.535994
  validation loss:		0.572108
  validation accuracy:		81.52 %
Epoch 1200 of 2000 took 0.097s
  training loss:		0.536569
  validation loss:		0.552612
  validation accuracy:		81.63 %
Epoch 1201 of 2000 took 0.097s
  training loss:		0.537179
  validation loss:		0.572445
  validation accuracy:		80.54 %
Epoch 1202 of 2000 took 0.097s
  training loss:		0.542342
  validation loss:		0.558391
  validation accuracy:		81.20 %
Epoch 1203 of 2000 took 0.097s
  training loss:		0.530015
  validation loss:		0.558354
  validation accuracy:		81.41 %
Epoch 1204 of 2000 took 0.098s
  training loss:		0.539263
  validation loss:		0.566401
  validation accuracy:		80.65 %
Epoch 1205 of 2000 took 0.097s
  training loss:		0.540291
  validation loss:		0.565973
  validation accuracy:		81.09 %
Epoch 1206 of 2000 took 0.097s
  training loss:		0.548080
  validation loss:		0.550609
  validation accuracy:		81.85 %
Epoch 1207 of 2000 took 0.097s
  training loss:		0.547779
  validation loss:		0.559345
  validation accuracy:		81.41 %
Epoch 1208 of 2000 took 0.097s
  training loss:		0.534590
  validation loss:		0.552623
  validation accuracy:		81.96 %
Epoch 1209 of 2000 took 0.097s
  training loss:		0.533351
  validation loss:		0.572076
  validation accuracy:		80.87 %
Epoch 1210 of 2000 took 0.097s
  training loss:		0.546829
  validation loss:		0.551987
  validation accuracy:		81.52 %
Epoch 1211 of 2000 took 0.097s
  training loss:		0.540556
  validation loss:		0.556024
  validation accuracy:		81.20 %
Epoch 1212 of 2000 took 0.097s
  training loss:		0.538324
  validation loss:		0.560358
  validation accuracy:		81.09 %
Epoch 1213 of 2000 took 0.097s
  training loss:		0.538042
  validation loss:		0.548247
  validation accuracy:		81.96 %
Epoch 1214 of 2000 took 0.097s
  training loss:		0.540218
  validation loss:		0.551552
  validation accuracy:		81.85 %
Epoch 1215 of 2000 took 0.097s
  training loss:		0.535439
  validation loss:		0.580834
  validation accuracy:		80.43 %
Epoch 1216 of 2000 took 0.097s
  training loss:		0.532087
  validation loss:		0.545435
  validation accuracy:		81.96 %
Epoch 1217 of 2000 took 0.097s
  training loss:		0.540982
  validation loss:		0.543844
  validation accuracy:		81.74 %
Epoch 1218 of 2000 took 0.097s
  training loss:		0.542372
  validation loss:		0.586991
  validation accuracy:		80.43 %
Epoch 1219 of 2000 took 0.097s
  training loss:		0.535694
  validation loss:		0.558361
  validation accuracy:		81.09 %
Epoch 1220 of 2000 took 0.097s
  training loss:		0.544617
  validation loss:		0.545017
  validation accuracy:		81.63 %
Epoch 1221 of 2000 took 0.097s
  training loss:		0.535922
  validation loss:		0.562701
  validation accuracy:		81.30 %
Epoch 1222 of 2000 took 0.097s
  training loss:		0.536431
  validation loss:		0.550236
  validation accuracy:		81.63 %
Epoch 1223 of 2000 took 0.097s
  training loss:		0.542844
  validation loss:		0.548165
  validation accuracy:		81.96 %
Epoch 1224 of 2000 took 0.097s
  training loss:		0.544999
  validation loss:		0.549318
  validation accuracy:		81.63 %
Epoch 1225 of 2000 took 0.097s
  training loss:		0.534874
  validation loss:		0.561292
  validation accuracy:		81.20 %
Epoch 1226 of 2000 took 0.097s
  training loss:		0.546147
  validation loss:		0.550979
  validation accuracy:		81.52 %
Epoch 1227 of 2000 took 0.097s
  training loss:		0.546719
  validation loss:		0.569865
  validation accuracy:		80.76 %
Epoch 1228 of 2000 took 0.097s
  training loss:		0.544229
  validation loss:		0.550344
  validation accuracy:		81.74 %
Epoch 1229 of 2000 took 0.097s
  training loss:		0.537091
  validation loss:		0.554516
  validation accuracy:		81.63 %
Epoch 1230 of 2000 took 0.097s
  training loss:		0.538955
  validation loss:		0.571650
  validation accuracy:		80.76 %
Epoch 1231 of 2000 took 0.097s
  training loss:		0.532721
  validation loss:		0.563029
  validation accuracy:		80.76 %
Epoch 1232 of 2000 took 0.097s
  training loss:		0.539389
  validation loss:		0.550964
  validation accuracy:		81.63 %
Epoch 1233 of 2000 took 0.097s
  training loss:		0.540459
  validation loss:		0.568820
  validation accuracy:		80.65 %
Epoch 1234 of 2000 took 0.097s
  training loss:		0.542940
  validation loss:		0.568027
  validation accuracy:		80.98 %
Epoch 1235 of 2000 took 0.098s
  training loss:		0.537060
  validation loss:		0.559052
  validation accuracy:		81.41 %
Epoch 1236 of 2000 took 0.097s
  training loss:		0.531560
  validation loss:		0.552079
  validation accuracy:		81.63 %
Epoch 1237 of 2000 took 0.097s
  training loss:		0.538209
  validation loss:		0.567731
  validation accuracy:		80.98 %
Epoch 1238 of 2000 took 0.097s
  training loss:		0.541781
  validation loss:		0.549129
  validation accuracy:		81.63 %
Epoch 1239 of 2000 took 0.097s
  training loss:		0.535840
  validation loss:		0.570919
  validation accuracy:		81.52 %
Epoch 1240 of 2000 took 0.097s
  training loss:		0.539528
  validation loss:		0.547730
  validation accuracy:		82.39 %
Epoch 1241 of 2000 took 0.097s
  training loss:		0.538609
  validation loss:		0.564770
  validation accuracy:		81.09 %
Epoch 1242 of 2000 took 0.097s
  training loss:		0.544404
  validation loss:		0.553087
  validation accuracy:		81.30 %
Epoch 1243 of 2000 took 0.097s
  training loss:		0.541819
  validation loss:		0.573661
  validation accuracy:		81.30 %
Epoch 1244 of 2000 took 0.097s
  training loss:		0.535695
  validation loss:		0.571066
  validation accuracy:		80.87 %
Epoch 1245 of 2000 took 0.097s
  training loss:		0.533175
  validation loss:		0.566025
  validation accuracy:		81.09 %
Epoch 1246 of 2000 took 0.097s
  training loss:		0.539380
  validation loss:		0.556620
  validation accuracy:		81.30 %
Epoch 1247 of 2000 took 0.097s
  training loss:		0.533318
  validation loss:		0.562395
  validation accuracy:		81.30 %
Epoch 1248 of 2000 took 0.097s
  training loss:		0.541817
  validation loss:		0.554274
  validation accuracy:		81.63 %
Epoch 1249 of 2000 took 0.097s
  training loss:		0.541188
  validation loss:		0.564107
  validation accuracy:		81.30 %
Epoch 1250 of 2000 took 0.097s
  training loss:		0.550475
  validation loss:		0.572604
  validation accuracy:		81.74 %
Epoch 1251 of 2000 took 0.097s
  training loss:		0.549848
  validation loss:		0.560884
  validation accuracy:		81.20 %
Epoch 1252 of 2000 took 0.097s
  training loss:		0.532699
  validation loss:		0.599822
  validation accuracy:		81.09 %
Epoch 1253 of 2000 took 0.097s
  training loss:		0.537569
  validation loss:		0.553466
  validation accuracy:		81.41 %
Epoch 1254 of 2000 took 0.097s
  training loss:		0.536274
  validation loss:		0.554672
  validation accuracy:		81.30 %
Epoch 1255 of 2000 took 0.100s
  training loss:		0.545880
  validation loss:		0.575987
  validation accuracy:		80.76 %
Epoch 1256 of 2000 took 0.100s
  training loss:		0.535270
  validation loss:		0.561106
  validation accuracy:		81.20 %
Epoch 1257 of 2000 took 0.100s
  training loss:		0.535545
  validation loss:		0.551006
  validation accuracy:		81.74 %
Epoch 1258 of 2000 took 0.100s
  training loss:		0.529255
  validation loss:		0.562875
  validation accuracy:		80.87 %
Epoch 1259 of 2000 took 0.100s
  training loss:		0.546242
  validation loss:		0.554121
  validation accuracy:		81.74 %
Epoch 1260 of 2000 took 0.100s
  training loss:		0.541118
  validation loss:		0.552812
  validation accuracy:		81.30 %
Epoch 1261 of 2000 took 0.100s
  training loss:		0.537666
  validation loss:		0.585065
  validation accuracy:		80.43 %
Epoch 1262 of 2000 took 0.100s
  training loss:		0.537506
  validation loss:		0.549167
  validation accuracy:		81.74 %
Epoch 1263 of 2000 took 0.100s
  training loss:		0.543397
  validation loss:		0.574723
  validation accuracy:		80.65 %
Epoch 1264 of 2000 took 0.100s
  training loss:		0.539170
  validation loss:		0.568936
  validation accuracy:		80.98 %
Epoch 1265 of 2000 took 0.100s
  training loss:		0.542535
  validation loss:		0.563305
  validation accuracy:		81.09 %
Epoch 1266 of 2000 took 0.101s
  training loss:		0.544182
  validation loss:		0.545618
  validation accuracy:		82.17 %
Epoch 1267 of 2000 took 0.100s
  training loss:		0.539036
  validation loss:		0.561704
  validation accuracy:		81.41 %
Epoch 1268 of 2000 took 0.100s
  training loss:		0.537819
  validation loss:		0.546279
  validation accuracy:		81.74 %
Epoch 1269 of 2000 took 0.100s
  training loss:		0.540092
  validation loss:		0.560898
  validation accuracy:		80.65 %
Epoch 1270 of 2000 took 0.097s
  training loss:		0.537945
  validation loss:		0.544677
  validation accuracy:		81.85 %
Epoch 1271 of 2000 took 0.097s
  training loss:		0.538294
  validation loss:		0.551054
  validation accuracy:		81.74 %
Epoch 1272 of 2000 took 0.097s
  training loss:		0.536428
  validation loss:		0.549445
  validation accuracy:		81.41 %
Epoch 1273 of 2000 took 0.097s
  training loss:		0.529672
  validation loss:		0.564463
  validation accuracy:		80.87 %
Epoch 1274 of 2000 took 0.097s
  training loss:		0.544411
  validation loss:		0.545675
  validation accuracy:		82.17 %
Epoch 1275 of 2000 took 0.097s
  training loss:		0.548659
  validation loss:		0.550320
  validation accuracy:		81.74 %
Epoch 1276 of 2000 took 0.097s
  training loss:		0.529289
  validation loss:		0.554199
  validation accuracy:		81.41 %
Epoch 1277 of 2000 took 0.097s
  training loss:		0.538374
  validation loss:		0.553935
  validation accuracy:		81.41 %
Epoch 1278 of 2000 took 0.097s
  training loss:		0.539114
  validation loss:		0.549180
  validation accuracy:		81.74 %
Epoch 1279 of 2000 took 0.097s
  training loss:		0.528886
  validation loss:		0.548775
  validation accuracy:		81.41 %
Epoch 1280 of 2000 took 0.097s
  training loss:		0.541119
  validation loss:		0.555489
  validation accuracy:		81.30 %
Epoch 1281 of 2000 took 0.097s
  training loss:		0.532697
  validation loss:		0.544495
  validation accuracy:		81.85 %
Epoch 1282 of 2000 took 0.097s
  training loss:		0.539041
  validation loss:		0.554838
  validation accuracy:		81.30 %
Epoch 1283 of 2000 took 0.099s
  training loss:		0.537835
  validation loss:		0.563004
  validation accuracy:		80.87 %
Epoch 1284 of 2000 took 0.097s
  training loss:		0.532018
  validation loss:		0.556849
  validation accuracy:		81.09 %
Epoch 1285 of 2000 took 0.097s
  training loss:		0.537455
  validation loss:		0.578852
  validation accuracy:		80.76 %
Epoch 1286 of 2000 took 0.097s
  training loss:		0.533169
  validation loss:		0.545268
  validation accuracy:		81.74 %
Epoch 1287 of 2000 took 0.097s
  training loss:		0.537535
  validation loss:		0.550471
  validation accuracy:		81.85 %
Epoch 1288 of 2000 took 0.097s
  training loss:		0.530568
  validation loss:		0.559060
  validation accuracy:		80.98 %
Epoch 1289 of 2000 took 0.097s
  training loss:		0.542627
  validation loss:		0.551471
  validation accuracy:		81.63 %
Epoch 1290 of 2000 took 0.097s
  training loss:		0.537971
  validation loss:		0.549048
  validation accuracy:		81.85 %
Epoch 1291 of 2000 took 0.097s
  training loss:		0.534336
  validation loss:		0.547436
  validation accuracy:		81.96 %
Epoch 1292 of 2000 took 0.097s
  training loss:		0.551396
  validation loss:		0.564807
  validation accuracy:		81.09 %
Epoch 1293 of 2000 took 0.097s
  training loss:		0.541942
  validation loss:		0.543633
  validation accuracy:		82.07 %
Epoch 1294 of 2000 took 0.097s
  training loss:		0.539846
  validation loss:		0.548126
  validation accuracy:		81.85 %
Epoch 1295 of 2000 took 0.097s
  training loss:		0.534863
  validation loss:		0.548298
  validation accuracy:		81.63 %
Epoch 1296 of 2000 took 0.097s
  training loss:		0.537791
  validation loss:		0.548907
  validation accuracy:		81.74 %
Epoch 1297 of 2000 took 0.098s
  training loss:		0.537240
  validation loss:		0.584774
  validation accuracy:		79.35 %
Epoch 1298 of 2000 took 0.097s
  training loss:		0.548504
  validation loss:		0.553491
  validation accuracy:		81.30 %
Epoch 1299 of 2000 took 0.097s
  training loss:		0.533235
  validation loss:		0.559264
  validation accuracy:		80.76 %
Epoch 1300 of 2000 took 0.097s
  training loss:		0.541455
  validation loss:		0.546599
  validation accuracy:		81.41 %
Epoch 1301 of 2000 took 0.097s
  training loss:		0.537746
  validation loss:		0.577316
  validation accuracy:		80.76 %
Epoch 1302 of 2000 took 0.097s
  training loss:		0.528237
  validation loss:		0.547820
  validation accuracy:		81.63 %
Epoch 1303 of 2000 took 0.097s
  training loss:		0.536599
  validation loss:		0.566370
  validation accuracy:		80.98 %
Epoch 1304 of 2000 took 0.097s
  training loss:		0.531479
  validation loss:		0.559153
  validation accuracy:		81.20 %
Epoch 1305 of 2000 took 0.097s
  training loss:		0.533280
  validation loss:		0.572970
  validation accuracy:		80.98 %
Epoch 1306 of 2000 took 0.097s
  training loss:		0.534781
  validation loss:		0.570456
  validation accuracy:		81.30 %
Epoch 1307 of 2000 took 0.097s
  training loss:		0.532206
  validation loss:		0.553508
  validation accuracy:		81.20 %
Epoch 1308 of 2000 took 0.097s
  training loss:		0.533568
  validation loss:		0.554847
  validation accuracy:		81.52 %
Epoch 1309 of 2000 took 0.097s
  training loss:		0.543480
  validation loss:		0.562075
  validation accuracy:		81.52 %
Epoch 1310 of 2000 took 0.097s
  training loss:		0.537941
  validation loss:		0.581955
  validation accuracy:		81.41 %
Epoch 1311 of 2000 took 0.097s
  training loss:		0.534867
  validation loss:		0.555656
  validation accuracy:		81.09 %
Epoch 1312 of 2000 took 0.097s
  training loss:		0.537518
  validation loss:		0.559883
  validation accuracy:		81.41 %
Epoch 1313 of 2000 took 0.097s
  training loss:		0.540655
  validation loss:		0.585211
  validation accuracy:		80.54 %
Epoch 1314 of 2000 took 0.097s
  training loss:		0.533826
  validation loss:		0.564552
  validation accuracy:		81.20 %
Epoch 1315 of 2000 took 0.097s
  training loss:		0.532889
  validation loss:		0.544789
  validation accuracy:		81.85 %
Epoch 1316 of 2000 took 0.097s
  training loss:		0.528882
  validation loss:		0.545839
  validation accuracy:		81.96 %
Epoch 1317 of 2000 took 0.097s
  training loss:		0.534340
  validation loss:		0.549166
  validation accuracy:		81.96 %
Epoch 1318 of 2000 took 0.097s
  training loss:		0.544740
  validation loss:		0.576001
  validation accuracy:		80.76 %
Epoch 1319 of 2000 took 0.097s
  training loss:		0.540786
  validation loss:		0.565562
  validation accuracy:		80.76 %
Epoch 1320 of 2000 took 0.097s
  training loss:		0.530467
  validation loss:		0.545292
  validation accuracy:		81.41 %
Epoch 1321 of 2000 took 0.097s
  training loss:		0.536017
  validation loss:		0.549764
  validation accuracy:		81.63 %
Epoch 1322 of 2000 took 0.097s
  training loss:		0.536079
  validation loss:		0.561161
  validation accuracy:		81.63 %
Epoch 1323 of 2000 took 0.097s
  training loss:		0.532233
  validation loss:		0.545427
  validation accuracy:		82.07 %
Epoch 1324 of 2000 took 0.097s
  training loss:		0.524783
  validation loss:		0.544217
  validation accuracy:		81.74 %
Epoch 1325 of 2000 took 0.097s
  training loss:		0.540622
  validation loss:		0.550618
  validation accuracy:		81.41 %
Epoch 1326 of 2000 took 0.097s
  training loss:		0.538223
  validation loss:		0.544125
  validation accuracy:		81.96 %
Epoch 1327 of 2000 took 0.097s
  training loss:		0.525272
  validation loss:		0.550711
  validation accuracy:		81.63 %
Epoch 1328 of 2000 took 0.098s
  training loss:		0.527206
  validation loss:		0.573520
  validation accuracy:		81.52 %
Epoch 1329 of 2000 took 0.097s
  training loss:		0.537122
  validation loss:		0.574573
  validation accuracy:		80.87 %
Epoch 1330 of 2000 took 0.097s
  training loss:		0.538197
  validation loss:		0.547988
  validation accuracy:		81.63 %
Epoch 1331 of 2000 took 0.097s
  training loss:		0.536116
  validation loss:		0.549432
  validation accuracy:		81.52 %
Epoch 1332 of 2000 took 0.097s
  training loss:		0.540261
  validation loss:		0.548458
  validation accuracy:		81.52 %
Epoch 1333 of 2000 took 0.097s
  training loss:		0.533503
  validation loss:		0.577015
  validation accuracy:		80.76 %
Epoch 1334 of 2000 took 0.097s
  training loss:		0.530065
  validation loss:		0.539723
  validation accuracy:		81.96 %
Epoch 1335 of 2000 took 0.097s
  training loss:		0.534047
  validation loss:		0.567085
  validation accuracy:		80.87 %
Epoch 1336 of 2000 took 0.097s
  training loss:		0.540124
  validation loss:		0.549781
  validation accuracy:		81.41 %
Epoch 1337 of 2000 took 0.097s
  training loss:		0.537824
  validation loss:		0.577059
  validation accuracy:		81.30 %
Epoch 1338 of 2000 took 0.097s
  training loss:		0.543385
  validation loss:		0.557777
  validation accuracy:		81.20 %
Epoch 1339 of 2000 took 0.097s
  training loss:		0.538284
  validation loss:		0.545617
  validation accuracy:		81.74 %
Epoch 1340 of 2000 took 0.097s
  training loss:		0.535681
  validation loss:		0.559721
  validation accuracy:		80.98 %
Epoch 1341 of 2000 took 0.097s
  training loss:		0.533200
  validation loss:		0.563425
  validation accuracy:		81.30 %
Epoch 1342 of 2000 took 0.097s
  training loss:		0.533866
  validation loss:		0.585021
  validation accuracy:		80.87 %
Epoch 1343 of 2000 took 0.097s
  training loss:		0.538291
  validation loss:		0.556385
  validation accuracy:		81.41 %
Epoch 1344 of 2000 took 0.097s
  training loss:		0.539298
  validation loss:		0.546168
  validation accuracy:		81.85 %
Epoch 1345 of 2000 took 0.097s
  training loss:		0.531191
  validation loss:		0.547741
  validation accuracy:		81.63 %
Epoch 1346 of 2000 took 0.097s
  training loss:		0.531401
  validation loss:		0.554055
  validation accuracy:		81.09 %
Epoch 1347 of 2000 took 0.097s
  training loss:		0.534425
  validation loss:		0.555153
  validation accuracy:		81.30 %
Epoch 1348 of 2000 took 0.097s
  training loss:		0.542851
  validation loss:		0.547555
  validation accuracy:		81.85 %
Epoch 1349 of 2000 took 0.097s
  training loss:		0.533949
  validation loss:		0.567103
  validation accuracy:		81.20 %
Epoch 1350 of 2000 took 0.097s
  training loss:		0.524908
  validation loss:		0.540838
  validation accuracy:		81.85 %
Epoch 1351 of 2000 took 0.097s
  training loss:		0.529202
  validation loss:		0.540846
  validation accuracy:		81.74 %
Epoch 1352 of 2000 took 0.097s
  training loss:		0.533287
  validation loss:		0.546113
  validation accuracy:		81.63 %
Epoch 1353 of 2000 took 0.097s
  training loss:		0.541057
  validation loss:		0.565777
  validation accuracy:		81.41 %
Epoch 1354 of 2000 took 0.097s
  training loss:		0.539319
  validation loss:		0.554606
  validation accuracy:		81.20 %
Epoch 1355 of 2000 took 0.097s
  training loss:		0.538080
  validation loss:		0.555741
  validation accuracy:		81.52 %
Epoch 1356 of 2000 took 0.097s
  training loss:		0.533047
  validation loss:		0.568186
  validation accuracy:		81.30 %
Epoch 1357 of 2000 took 0.097s
  training loss:		0.529807
  validation loss:		0.553928
  validation accuracy:		81.30 %
Epoch 1358 of 2000 took 0.097s
  training loss:		0.532568
  validation loss:		0.552930
  validation accuracy:		81.41 %
Epoch 1359 of 2000 took 0.098s
  training loss:		0.529924
  validation loss:		0.551464
  validation accuracy:		81.41 %
Epoch 1360 of 2000 took 0.097s
  training loss:		0.535167
  validation loss:		0.561291
  validation accuracy:		80.87 %
Epoch 1361 of 2000 took 0.097s
  training loss:		0.535659
  validation loss:		0.560513
  validation accuracy:		81.30 %
Epoch 1362 of 2000 took 0.097s
  training loss:		0.534671
  validation loss:		0.549931
  validation accuracy:		81.30 %
Epoch 1363 of 2000 took 0.097s
  training loss:		0.533859
  validation loss:		0.559807
  validation accuracy:		81.09 %
Epoch 1364 of 2000 took 0.097s
  training loss:		0.531564
  validation loss:		0.559490
  validation accuracy:		80.76 %
Epoch 1365 of 2000 took 0.097s
  training loss:		0.527203
  validation loss:		0.570683
  validation accuracy:		81.20 %
Epoch 1366 of 2000 took 0.097s
  training loss:		0.532155
  validation loss:		0.542541
  validation accuracy:		81.85 %
Epoch 1367 of 2000 took 0.097s
  training loss:		0.528202
  validation loss:		0.559183
  validation accuracy:		81.30 %
Epoch 1368 of 2000 took 0.097s
  training loss:		0.529564
  validation loss:		0.560365
  validation accuracy:		81.09 %
Epoch 1369 of 2000 took 0.097s
  training loss:		0.534378
  validation loss:		0.581706
  validation accuracy:		81.52 %
Epoch 1370 of 2000 took 0.097s
  training loss:		0.529670
  validation loss:		0.545818
  validation accuracy:		82.07 %
Epoch 1371 of 2000 took 0.097s
  training loss:		0.535611
  validation loss:		0.548870
  validation accuracy:		82.07 %
Epoch 1372 of 2000 took 0.097s
  training loss:		0.535320
  validation loss:		0.548879
  validation accuracy:		81.52 %
Epoch 1373 of 2000 took 0.097s
  training loss:		0.527808
  validation loss:		0.548025
  validation accuracy:		81.96 %
Epoch 1374 of 2000 took 0.097s
  training loss:		0.532606
  validation loss:		0.552089
  validation accuracy:		81.52 %
Epoch 1375 of 2000 took 0.097s
  training loss:		0.533960
  validation loss:		0.554830
  validation accuracy:		81.41 %
Epoch 1376 of 2000 took 0.097s
  training loss:		0.534307
  validation loss:		0.560555
  validation accuracy:		81.63 %
Epoch 1377 of 2000 took 0.097s
  training loss:		0.539430
  validation loss:		0.546315
  validation accuracy:		81.52 %
Epoch 1378 of 2000 took 0.097s
  training loss:		0.527386
  validation loss:		0.565515
  validation accuracy:		81.09 %
Epoch 1379 of 2000 took 0.097s
  training loss:		0.532343
  validation loss:		0.571149
  validation accuracy:		81.09 %
Epoch 1380 of 2000 took 0.097s
  training loss:		0.533899
  validation loss:		0.557774
  validation accuracy:		81.41 %
Epoch 1381 of 2000 took 0.097s
  training loss:		0.534228
  validation loss:		0.556197
  validation accuracy:		81.52 %
Epoch 1382 of 2000 took 0.097s
  training loss:		0.542387
  validation loss:		0.551019
  validation accuracy:		81.41 %
Epoch 1383 of 2000 took 0.097s
  training loss:		0.530169
  validation loss:		0.554202
  validation accuracy:		81.41 %
Epoch 1384 of 2000 took 0.097s
  training loss:		0.535991
  validation loss:		0.589081
  validation accuracy:		81.09 %
Epoch 1385 of 2000 took 0.097s
  training loss:		0.533528
  validation loss:		0.573307
  validation accuracy:		81.09 %
Epoch 1386 of 2000 took 0.097s
  training loss:		0.530397
  validation loss:		0.572164
  validation accuracy:		80.76 %
Epoch 1387 of 2000 took 0.097s
  training loss:		0.525652
  validation loss:		0.543033
  validation accuracy:		81.96 %
Epoch 1388 of 2000 took 0.097s
  training loss:		0.530972
  validation loss:		0.558930
  validation accuracy:		81.20 %
Epoch 1389 of 2000 took 0.097s
  training loss:		0.524844
  validation loss:		0.590566
  validation accuracy:		81.30 %
Epoch 1390 of 2000 took 0.098s
  training loss:		0.522636
  validation loss:		0.561657
  validation accuracy:		81.52 %
Epoch 1391 of 2000 took 0.097s
  training loss:		0.529175
  validation loss:		0.537982
  validation accuracy:		82.07 %
Epoch 1392 of 2000 took 0.097s
  training loss:		0.534990
  validation loss:		0.564651
  validation accuracy:		81.30 %
Epoch 1393 of 2000 took 0.097s
  training loss:		0.528666
  validation loss:		0.559110
  validation accuracy:		81.30 %
Epoch 1394 of 2000 took 0.097s
  training loss:		0.527826
  validation loss:		0.576864
  validation accuracy:		80.98 %
Epoch 1395 of 2000 took 0.097s
  training loss:		0.524914
  validation loss:		0.545505
  validation accuracy:		81.63 %
Epoch 1396 of 2000 took 0.097s
  training loss:		0.529027
  validation loss:		0.549574
  validation accuracy:		81.41 %
Epoch 1397 of 2000 took 0.097s
  training loss:		0.525667
  validation loss:		0.559563
  validation accuracy:		81.63 %
Epoch 1398 of 2000 took 0.097s
  training loss:		0.542697
  validation loss:		0.559674
  validation accuracy:		81.20 %
Epoch 1399 of 2000 took 0.097s
  training loss:		0.529821
  validation loss:		0.556018
  validation accuracy:		81.41 %
Epoch 1400 of 2000 took 0.097s
  training loss:		0.532555
  validation loss:		0.578122
  validation accuracy:		82.07 %
Epoch 1401 of 2000 took 0.097s
  training loss:		0.532891
  validation loss:		0.549036
  validation accuracy:		81.41 %
Epoch 1402 of 2000 took 0.097s
  training loss:		0.526086
  validation loss:		0.545170
  validation accuracy:		81.96 %
Epoch 1403 of 2000 took 0.097s
  training loss:		0.522872
  validation loss:		0.547224
  validation accuracy:		81.63 %
Epoch 1404 of 2000 took 0.097s
  training loss:		0.526047
  validation loss:		0.577928
  validation accuracy:		81.20 %
Epoch 1405 of 2000 took 0.097s
  training loss:		0.528879
  validation loss:		0.549388
  validation accuracy:		81.30 %
Epoch 1406 of 2000 took 0.097s
  training loss:		0.531825
  validation loss:		0.543690
  validation accuracy:		81.74 %
Epoch 1407 of 2000 took 0.097s
  training loss:		0.531853
  validation loss:		0.564510
  validation accuracy:		81.85 %
Epoch 1408 of 2000 took 0.097s
  training loss:		0.532872
  validation loss:		0.570332
  validation accuracy:		80.98 %
Epoch 1409 of 2000 took 0.097s
  training loss:		0.528861
  validation loss:		0.552024
  validation accuracy:		81.63 %
Epoch 1410 of 2000 took 0.097s
  training loss:		0.522378
  validation loss:		0.547715
  validation accuracy:		81.63 %
Epoch 1411 of 2000 took 0.097s
  training loss:		0.523999
  validation loss:		0.536721
  validation accuracy:		81.85 %
Epoch 1412 of 2000 took 0.097s
  training loss:		0.534377
  validation loss:		0.541220
  validation accuracy:		81.85 %
Epoch 1413 of 2000 took 0.097s
  training loss:		0.518050
  validation loss:		0.537901
  validation accuracy:		82.17 %
Epoch 1414 of 2000 took 0.097s
  training loss:		0.519587
  validation loss:		0.557095
  validation accuracy:		81.41 %
Epoch 1415 of 2000 took 0.097s
  training loss:		0.521692
  validation loss:		0.548192
  validation accuracy:		81.52 %
Epoch 1416 of 2000 took 0.097s
  training loss:		0.520343
  validation loss:		0.538629
  validation accuracy:		82.07 %
Epoch 1417 of 2000 took 0.097s
  training loss:		0.527970
  validation loss:		0.551330
  validation accuracy:		81.41 %
Epoch 1418 of 2000 took 0.097s
  training loss:		0.513837
  validation loss:		0.544216
  validation accuracy:		81.96 %
Epoch 1419 of 2000 took 0.097s
  training loss:		0.525582
  validation loss:		0.534966
  validation accuracy:		82.50 %
Epoch 1420 of 2000 took 0.097s
  training loss:		0.521490
  validation loss:		0.546472
  validation accuracy:		81.85 %
Epoch 1421 of 2000 took 0.098s
  training loss:		0.517825
  validation loss:		0.529719
  validation accuracy:		82.72 %
Epoch 1422 of 2000 took 0.097s
  training loss:		0.515629
  validation loss:		0.541743
  validation accuracy:		82.17 %
Epoch 1423 of 2000 took 0.097s
  training loss:		0.525676
  validation loss:		0.544431
  validation accuracy:		81.85 %
Epoch 1424 of 2000 took 0.097s
  training loss:		0.520643
  validation loss:		0.543095
  validation accuracy:		81.74 %
Epoch 1425 of 2000 took 0.098s
  training loss:		0.527171
  validation loss:		0.546014
  validation accuracy:		81.41 %
Epoch 1426 of 2000 took 0.097s
  training loss:		0.522965
  validation loss:		0.569524
  validation accuracy:		81.52 %
Epoch 1427 of 2000 took 0.097s
  training loss:		0.520347
  validation loss:		0.543488
  validation accuracy:		81.96 %
Epoch 1428 of 2000 took 0.097s
  training loss:		0.513174
  validation loss:		0.552483
  validation accuracy:		81.41 %
Epoch 1429 of 2000 took 0.097s
  training loss:		0.520296
  validation loss:		0.551152
  validation accuracy:		82.07 %
Epoch 1430 of 2000 took 0.097s
  training loss:		0.515770
  validation loss:		0.539389
  validation accuracy:		82.28 %
Epoch 1431 of 2000 took 0.097s
  training loss:		0.507374
  validation loss:		0.536727
  validation accuracy:		82.39 %
Epoch 1432 of 2000 took 0.097s
  training loss:		0.519836
  validation loss:		0.540733
  validation accuracy:		82.17 %
Epoch 1433 of 2000 took 0.097s
  training loss:		0.518563
  validation loss:		0.542581
  validation accuracy:		81.63 %
Epoch 1434 of 2000 took 0.097s
  training loss:		0.518618
  validation loss:		0.537105
  validation accuracy:		82.28 %
Epoch 1435 of 2000 took 0.097s
  training loss:		0.522653
  validation loss:		0.523438
  validation accuracy:		82.93 %
Epoch 1436 of 2000 took 0.097s
  training loss:		0.518736
  validation loss:		0.543306
  validation accuracy:		81.96 %
Epoch 1437 of 2000 took 0.097s
  training loss:		0.510651
  validation loss:		0.540993
  validation accuracy:		82.39 %
Epoch 1438 of 2000 took 0.097s
  training loss:		0.512950
  validation loss:		0.525278
  validation accuracy:		82.61 %
Epoch 1439 of 2000 took 0.097s
  training loss:		0.525565
  validation loss:		0.539429
  validation accuracy:		82.07 %
Epoch 1440 of 2000 took 0.097s
  training loss:		0.511079
  validation loss:		0.527352
  validation accuracy:		82.83 %
Epoch 1441 of 2000 took 0.097s
  training loss:		0.512985
  validation loss:		0.536763
  validation accuracy:		82.17 %
Epoch 1442 of 2000 took 0.097s
  training loss:		0.519721
  validation loss:		0.533281
  validation accuracy:		82.39 %
Epoch 1443 of 2000 took 0.097s
  training loss:		0.509804
  validation loss:		0.532199
  validation accuracy:		82.83 %
Epoch 1444 of 2000 took 0.097s
  training loss:		0.507696
  validation loss:		0.528951
  validation accuracy:		82.83 %
Epoch 1445 of 2000 took 0.097s
  training loss:		0.506358
  validation loss:		0.534517
  validation accuracy:		81.96 %
Epoch 1446 of 2000 took 0.097s
  training loss:		0.507304
  validation loss:		0.553718
  validation accuracy:		82.28 %
Epoch 1447 of 2000 took 0.097s
  training loss:		0.509759
  validation loss:		0.523527
  validation accuracy:		82.72 %
Epoch 1448 of 2000 took 0.097s
  training loss:		0.506707
  validation loss:		0.520458
  validation accuracy:		83.48 %
Epoch 1449 of 2000 took 0.097s
  training loss:		0.498374
  validation loss:		0.541653
  validation accuracy:		82.28 %
Epoch 1450 of 2000 took 0.097s
  training loss:		0.509660
  validation loss:		0.522345
  validation accuracy:		82.72 %
Epoch 1451 of 2000 took 0.097s
  training loss:		0.503475
  validation loss:		0.537427
  validation accuracy:		82.61 %
Epoch 1452 of 2000 took 0.098s
  training loss:		0.504175
  validation loss:		0.530435
  validation accuracy:		83.04 %
Epoch 1453 of 2000 took 0.097s
  training loss:		0.496716
  validation loss:		0.515363
  validation accuracy:		83.59 %
Epoch 1454 of 2000 took 0.097s
  training loss:		0.501416
  validation loss:		0.524384
  validation accuracy:		83.59 %
Epoch 1455 of 2000 took 0.097s
  training loss:		0.502054
  validation loss:		0.525428
  validation accuracy:		82.83 %
Epoch 1456 of 2000 took 0.097s
  training loss:		0.496107
  validation loss:		0.515147
  validation accuracy:		83.26 %
Epoch 1457 of 2000 took 0.097s
  training loss:		0.501558
  validation loss:		0.512436
  validation accuracy:		83.48 %
Epoch 1458 of 2000 took 0.097s
  training loss:		0.492659
  validation loss:		0.516050
  validation accuracy:		83.37 %
Epoch 1459 of 2000 took 0.097s
  training loss:		0.491988
  validation loss:		0.506129
  validation accuracy:		84.13 %
Epoch 1460 of 2000 took 0.098s
  training loss:		0.489233
  validation loss:		0.521316
  validation accuracy:		83.26 %
Epoch 1461 of 2000 took 0.100s
  training loss:		0.485244
  validation loss:		0.506721
  validation accuracy:		84.02 %
Epoch 1462 of 2000 took 0.100s
  training loss:		0.486957
  validation loss:		0.520897
  validation accuracy:		83.15 %
Epoch 1463 of 2000 took 0.100s
  training loss:		0.480798
  validation loss:		0.520989
  validation accuracy:		83.26 %
Epoch 1464 of 2000 took 0.100s
  training loss:		0.492147
  validation loss:		0.523438
  validation accuracy:		83.37 %
Epoch 1465 of 2000 took 0.100s
  training loss:		0.484872
  validation loss:		0.502692
  validation accuracy:		84.24 %
Epoch 1466 of 2000 took 0.100s
  training loss:		0.483606
  validation loss:		0.503377
  validation accuracy:		84.13 %
Epoch 1467 of 2000 took 0.100s
  training loss:		0.490651
  validation loss:		0.497976
  validation accuracy:		83.91 %
Epoch 1468 of 2000 took 0.100s
  training loss:		0.487811
  validation loss:		0.498605
  validation accuracy:		84.13 %
Epoch 1469 of 2000 took 0.100s
  training loss:		0.479783
  validation loss:		0.503441
  validation accuracy:		83.80 %
Epoch 1470 of 2000 took 0.100s
  training loss:		0.479754
  validation loss:		0.508989
  validation accuracy:		83.59 %
Epoch 1471 of 2000 took 0.100s
  training loss:		0.471219
  validation loss:		0.492150
  validation accuracy:		84.46 %
Epoch 1472 of 2000 took 0.100s
  training loss:		0.469834
  validation loss:		0.496989
  validation accuracy:		84.13 %
Epoch 1473 of 2000 took 0.100s
  training loss:		0.477704
  validation loss:		0.496238
  validation accuracy:		84.46 %
Epoch 1474 of 2000 took 0.100s
  training loss:		0.471021
  validation loss:		0.502573
  validation accuracy:		83.80 %
Epoch 1475 of 2000 took 0.100s
  training loss:		0.469487
  validation loss:		0.496506
  validation accuracy:		84.13 %
Epoch 1476 of 2000 took 0.100s
  training loss:		0.468106
  validation loss:		0.492669
  validation accuracy:		84.24 %
Epoch 1477 of 2000 took 0.100s
  training loss:		0.471157
  validation loss:		0.487596
  validation accuracy:		84.89 %
Epoch 1478 of 2000 took 0.100s
  training loss:		0.461361
  validation loss:		0.497687
  validation accuracy:		84.02 %
Epoch 1479 of 2000 took 0.100s
  training loss:		0.462066
  validation loss:		0.497671
  validation accuracy:		83.80 %
Epoch 1480 of 2000 took 0.100s
  training loss:		0.452832
  validation loss:		0.491364
  validation accuracy:		84.57 %
Epoch 1481 of 2000 took 0.100s
  training loss:		0.460875
  validation loss:		0.488044
  validation accuracy:		85.43 %
Epoch 1482 of 2000 took 0.100s
  training loss:		0.459011
  validation loss:		0.478783
  validation accuracy:		85.22 %
Epoch 1483 of 2000 took 0.101s
  training loss:		0.453282
  validation loss:		0.490339
  validation accuracy:		85.11 %
Epoch 1484 of 2000 took 0.100s
  training loss:		0.447553
  validation loss:		0.477013
  validation accuracy:		84.78 %
Epoch 1485 of 2000 took 0.100s
  training loss:		0.449309
  validation loss:		0.496973
  validation accuracy:		84.78 %
Epoch 1486 of 2000 took 0.100s
  training loss:		0.447605
  validation loss:		0.473887
  validation accuracy:		85.33 %
Epoch 1487 of 2000 took 0.100s
  training loss:		0.445176
  validation loss:		0.463621
  validation accuracy:		85.43 %
Epoch 1488 of 2000 took 0.100s
  training loss:		0.444358
  validation loss:		0.487163
  validation accuracy:		84.67 %
Epoch 1489 of 2000 took 0.100s
  training loss:		0.441532
  validation loss:		0.462783
  validation accuracy:		85.43 %
Epoch 1490 of 2000 took 0.100s
  training loss:		0.452863
  validation loss:		0.484223
  validation accuracy:		85.65 %
Epoch 1491 of 2000 took 0.100s
  training loss:		0.432048
  validation loss:		0.462828
  validation accuracy:		85.76 %
Epoch 1492 of 2000 took 0.100s
  training loss:		0.445717
  validation loss:		0.470094
  validation accuracy:		85.65 %
Epoch 1493 of 2000 took 0.100s
  training loss:		0.435395
  validation loss:		0.470254
  validation accuracy:		85.76 %
Epoch 1494 of 2000 took 0.100s
  training loss:		0.431561
  validation loss:		0.477882
  validation accuracy:		85.33 %
Epoch 1495 of 2000 took 0.100s
  training loss:		0.429763
  validation loss:		0.489289
  validation accuracy:		84.78 %
Epoch 1496 of 2000 took 0.100s
  training loss:		0.433963
  validation loss:		0.478593
  validation accuracy:		85.22 %
Epoch 1497 of 2000 took 0.100s
  training loss:		0.430523
  validation loss:		0.478930
  validation accuracy:		85.65 %
Epoch 1498 of 2000 took 0.100s
  training loss:		0.431104
  validation loss:		0.455689
  validation accuracy:		85.65 %
Epoch 1499 of 2000 took 0.100s
  training loss:		0.430324
  validation loss:		0.455503
  validation accuracy:		85.76 %
Epoch 1500 of 2000 took 0.100s
  training loss:		0.427091
  validation loss:		0.476216
  validation accuracy:		85.33 %
Epoch 1501 of 2000 took 0.100s
  training loss:		0.425624
  validation loss:		0.457864
  validation accuracy:		86.09 %
Epoch 1502 of 2000 took 0.100s
  training loss:		0.424684
  validation loss:		0.454315
  validation accuracy:		85.98 %
Epoch 1503 of 2000 took 0.100s
  training loss:		0.425542
  validation loss:		0.471775
  validation accuracy:		85.43 %
Epoch 1504 of 2000 took 0.100s
  training loss:		0.427029
  validation loss:		0.468563
  validation accuracy:		85.65 %
Epoch 1505 of 2000 took 0.103s
  training loss:		0.426516
  validation loss:		0.457826
  validation accuracy:		85.98 %
Epoch 1506 of 2000 took 0.100s
  training loss:		0.423977
  validation loss:		0.446552
  validation accuracy:		86.41 %
Epoch 1507 of 2000 took 0.100s
  training loss:		0.419524
  validation loss:		0.456329
  validation accuracy:		85.76 %
Epoch 1508 of 2000 took 0.100s
  training loss:		0.417059
  validation loss:		0.444329
  validation accuracy:		86.41 %
Epoch 1509 of 2000 took 0.100s
  training loss:		0.422671
  validation loss:		0.461649
  validation accuracy:		85.98 %
Epoch 1510 of 2000 took 0.100s
  training loss:		0.407344
  validation loss:		0.461922
  validation accuracy:		85.98 %
Epoch 1511 of 2000 took 0.100s
  training loss:		0.413159
  validation loss:		0.443099
  validation accuracy:		86.63 %
Epoch 1512 of 2000 took 0.100s
  training loss:		0.416907
  validation loss:		0.447744
  validation accuracy:		86.20 %
Epoch 1513 of 2000 took 0.101s
  training loss:		0.408744
  validation loss:		0.454953
  validation accuracy:		86.09 %
Epoch 1514 of 2000 took 0.100s
  training loss:		0.408127
  validation loss:		0.452902
  validation accuracy:		86.09 %
Epoch 1515 of 2000 took 0.100s
  training loss:		0.407141
  validation loss:		0.447906
  validation accuracy:		86.52 %
Epoch 1516 of 2000 took 0.100s
  training loss:		0.411106
  validation loss:		0.445329
  validation accuracy:		86.52 %
Epoch 1517 of 2000 took 0.100s
  training loss:		0.411148
  validation loss:		0.453151
  validation accuracy:		86.30 %
Epoch 1518 of 2000 took 0.100s
  training loss:		0.400378
  validation loss:		0.436275
  validation accuracy:		86.74 %
Epoch 1519 of 2000 took 0.100s
  training loss:		0.407898
  validation loss:		0.446297
  validation accuracy:		86.41 %
Epoch 1520 of 2000 took 0.100s
  training loss:		0.406739
  validation loss:		0.439738
  validation accuracy:		86.74 %
Epoch 1521 of 2000 took 0.100s
  training loss:		0.400095
  validation loss:		0.442505
  validation accuracy:		86.63 %
Epoch 1522 of 2000 took 0.100s
  training loss:		0.399213
  validation loss:		0.435888
  validation accuracy:		86.09 %
Epoch 1523 of 2000 took 0.100s
  training loss:		0.401182
  validation loss:		0.459150
  validation accuracy:		86.20 %
Epoch 1524 of 2000 took 0.100s
  training loss:		0.407480
  validation loss:		0.462596
  validation accuracy:		86.30 %
Epoch 1525 of 2000 took 0.100s
  training loss:		0.407607
  validation loss:		0.433044
  validation accuracy:		85.98 %
Epoch 1526 of 2000 took 0.100s
  training loss:		0.401594
  validation loss:		0.445018
  validation accuracy:		86.63 %
Epoch 1527 of 2000 took 0.100s
  training loss:		0.401041
  validation loss:		0.437463
  validation accuracy:		86.74 %
Epoch 1528 of 2000 took 0.100s
  training loss:		0.397094
  validation loss:		0.449313
  validation accuracy:		86.74 %
Epoch 1529 of 2000 took 0.100s
  training loss:		0.399739
  validation loss:		0.430238
  validation accuracy:		86.30 %
Epoch 1530 of 2000 took 0.100s
  training loss:		0.392470
  validation loss:		0.444024
  validation accuracy:		86.63 %
Epoch 1531 of 2000 took 0.100s
  training loss:		0.390556
  validation loss:		0.430281
  validation accuracy:		86.96 %
Epoch 1532 of 2000 took 0.100s
  training loss:		0.398779
  validation loss:		0.434187
  validation accuracy:		86.52 %
Epoch 1533 of 2000 took 0.100s
  training loss:		0.388609
  validation loss:		0.436253
  validation accuracy:		87.17 %
Epoch 1534 of 2000 took 0.100s
  training loss:		0.393144
  validation loss:		0.432973
  validation accuracy:		86.63 %
Epoch 1535 of 2000 took 0.100s
  training loss:		0.394124
  validation loss:		0.434131
  validation accuracy:		86.63 %
Epoch 1536 of 2000 took 0.100s
  training loss:		0.387257
  validation loss:		0.442760
  validation accuracy:		86.52 %
Epoch 1537 of 2000 took 0.100s
  training loss:		0.385343
  validation loss:		0.438385
  validation accuracy:		86.52 %
Epoch 1538 of 2000 took 0.100s
  training loss:		0.392393
  validation loss:		0.442309
  validation accuracy:		86.85 %
Epoch 1539 of 2000 took 0.100s
  training loss:		0.388344
  validation loss:		0.432419
  validation accuracy:		87.07 %
Epoch 1540 of 2000 took 0.100s
  training loss:		0.391335
  validation loss:		0.449543
  validation accuracy:		86.85 %
Epoch 1541 of 2000 took 0.100s
  training loss:		0.385333
  validation loss:		0.432721
  validation accuracy:		86.96 %
Epoch 1542 of 2000 took 0.103s
  training loss:		0.389170
  validation loss:		0.424858
  validation accuracy:		86.74 %
Epoch 1543 of 2000 took 0.102s
  training loss:		0.386203
  validation loss:		0.425888
  validation accuracy:		86.85 %
Epoch 1544 of 2000 took 0.100s
  training loss:		0.381769
  validation loss:		0.422507
  validation accuracy:		86.52 %
Epoch 1545 of 2000 took 0.100s
  training loss:		0.384710
  validation loss:		0.432728
  validation accuracy:		86.96 %
Epoch 1546 of 2000 took 0.100s
  training loss:		0.382002
  validation loss:		0.427192
  validation accuracy:		86.41 %
Epoch 1547 of 2000 took 0.100s
  training loss:		0.388805
  validation loss:		0.430680
  validation accuracy:		87.28 %
Epoch 1548 of 2000 took 0.100s
  training loss:		0.385131
  validation loss:		0.422308
  validation accuracy:		86.63 %
Epoch 1549 of 2000 took 0.100s
  training loss:		0.378942
  validation loss:		0.417855
  validation accuracy:		86.96 %
Epoch 1550 of 2000 took 0.100s
  training loss:		0.380929
  validation loss:		0.424484
  validation accuracy:		86.74 %
Epoch 1551 of 2000 took 0.100s
  training loss:		0.381484
  validation loss:		0.430113
  validation accuracy:		86.85 %
Epoch 1552 of 2000 took 0.100s
  training loss:		0.378170
  validation loss:		0.426494
  validation accuracy:		86.52 %
Epoch 1553 of 2000 took 0.100s
  training loss:		0.372919
  validation loss:		0.425682
  validation accuracy:		87.07 %
Epoch 1554 of 2000 took 0.100s
  training loss:		0.372314
  validation loss:		0.422903
  validation accuracy:		86.96 %
Epoch 1555 of 2000 took 0.100s
  training loss:		0.377028
  validation loss:		0.425195
  validation accuracy:		87.07 %
Epoch 1556 of 2000 took 0.100s
  training loss:		0.375958
  validation loss:		0.425004
  validation accuracy:		87.07 %
Epoch 1557 of 2000 took 0.100s
  training loss:		0.368101
  validation loss:		0.413471
  validation accuracy:		86.96 %
Epoch 1558 of 2000 took 0.100s
  training loss:		0.379678
  validation loss:		0.428058
  validation accuracy:		86.74 %
Epoch 1559 of 2000 took 0.100s
  training loss:		0.368517
  validation loss:		0.427759
  validation accuracy:		87.07 %
Epoch 1560 of 2000 took 0.100s
  training loss:		0.378533
  validation loss:		0.413453
  validation accuracy:		87.28 %
Epoch 1561 of 2000 took 0.100s
  training loss:		0.370916
  validation loss:		0.419702
  validation accuracy:		87.07 %
Epoch 1562 of 2000 took 0.097s
  training loss:		0.375126
  validation loss:		0.414521
  validation accuracy:		87.07 %
Epoch 1563 of 2000 took 0.097s
  training loss:		0.368299
  validation loss:		0.417768
  validation accuracy:		87.17 %
Epoch 1564 of 2000 took 0.097s
  training loss:		0.366813
  validation loss:		0.432649
  validation accuracy:		86.74 %
Epoch 1565 of 2000 took 0.097s
  training loss:		0.374463
  validation loss:		0.422450
  validation accuracy:		86.74 %
Epoch 1566 of 2000 took 0.097s
  training loss:		0.365827
  validation loss:		0.415456
  validation accuracy:		87.39 %
Epoch 1567 of 2000 took 0.097s
  training loss:		0.372127
  validation loss:		0.418948
  validation accuracy:		87.50 %
Epoch 1568 of 2000 took 0.097s
  training loss:		0.362549
  validation loss:		0.408743
  validation accuracy:		87.39 %
Epoch 1569 of 2000 took 0.097s
  training loss:		0.366642
  validation loss:		0.416972
  validation accuracy:		87.07 %
Epoch 1570 of 2000 took 0.097s
  training loss:		0.368969
  validation loss:		0.411725
  validation accuracy:		86.85 %
Epoch 1571 of 2000 took 0.097s
  training loss:		0.365280
  validation loss:		0.414692
  validation accuracy:		87.07 %
Epoch 1572 of 2000 took 0.097s
  training loss:		0.356122
  validation loss:		0.412655
  validation accuracy:		86.96 %
Epoch 1573 of 2000 took 0.098s
  training loss:		0.357900
  validation loss:		0.425016
  validation accuracy:		87.17 %
Epoch 1574 of 2000 took 0.097s
  training loss:		0.357147
  validation loss:		0.408064
  validation accuracy:		87.39 %
Epoch 1575 of 2000 took 0.097s
  training loss:		0.359950
  validation loss:		0.420031
  validation accuracy:		87.61 %
Epoch 1576 of 2000 took 0.097s
  training loss:		0.359931
  validation loss:		0.407438
  validation accuracy:		87.07 %
Epoch 1577 of 2000 took 0.097s
  training loss:		0.361773
  validation loss:		0.408612
  validation accuracy:		87.07 %
Epoch 1578 of 2000 took 0.097s
  training loss:		0.353788
  validation loss:		0.412173
  validation accuracy:		87.50 %
Epoch 1579 of 2000 took 0.097s
  training loss:		0.352245
  validation loss:		0.424024
  validation accuracy:		87.28 %
Epoch 1580 of 2000 took 0.097s
  training loss:		0.360298
  validation loss:		0.415446
  validation accuracy:		87.39 %
Epoch 1581 of 2000 took 0.097s
  training loss:		0.352661
  validation loss:		0.411145
  validation accuracy:		87.17 %
Epoch 1582 of 2000 took 0.097s
  training loss:		0.359418
  validation loss:		0.403438
  validation accuracy:		87.72 %
Epoch 1583 of 2000 took 0.097s
  training loss:		0.351334
  validation loss:		0.425226
  validation accuracy:		86.96 %
Epoch 1584 of 2000 took 0.097s
  training loss:		0.360423
  validation loss:		0.407939
  validation accuracy:		87.17 %
Epoch 1585 of 2000 took 0.097s
  training loss:		0.348930
  validation loss:		0.410496
  validation accuracy:		87.07 %
Epoch 1586 of 2000 took 0.097s
  training loss:		0.355981
  validation loss:		0.405768
  validation accuracy:		87.17 %
Epoch 1587 of 2000 took 0.097s
  training loss:		0.350389
  validation loss:		0.409202
  validation accuracy:		87.83 %
Epoch 1588 of 2000 took 0.097s
  training loss:		0.352890
  validation loss:		0.409658
  validation accuracy:		86.96 %
Epoch 1589 of 2000 took 0.097s
  training loss:		0.344272
  validation loss:		0.407152
  validation accuracy:		87.39 %
Epoch 1590 of 2000 took 0.097s
  training loss:		0.353129
  validation loss:		0.405903
  validation accuracy:		87.50 %
Epoch 1591 of 2000 took 0.097s
  training loss:		0.350053
  validation loss:		0.410782
  validation accuracy:		87.17 %
Epoch 1592 of 2000 took 0.097s
  training loss:		0.346243
  validation loss:		0.421537
  validation accuracy:		86.96 %
Epoch 1593 of 2000 took 0.097s
  training loss:		0.351152
  validation loss:		0.400145
  validation accuracy:		87.39 %
Epoch 1594 of 2000 took 0.097s
  training loss:		0.350458
  validation loss:		0.397233
  validation accuracy:		88.04 %
Epoch 1595 of 2000 took 0.097s
  training loss:		0.348483
  validation loss:		0.407967
  validation accuracy:		87.39 %
Epoch 1596 of 2000 took 0.097s
  training loss:		0.344164
  validation loss:		0.401588
  validation accuracy:		87.61 %
Epoch 1597 of 2000 took 0.097s
  training loss:		0.349661
  validation loss:		0.394857
  validation accuracy:		87.93 %
Epoch 1598 of 2000 took 0.097s
  training loss:		0.342818
  validation loss:		0.396218
  validation accuracy:		87.72 %
Epoch 1599 of 2000 took 0.097s
  training loss:		0.342869
  validation loss:		0.390693
  validation accuracy:		87.61 %
Epoch 1600 of 2000 took 0.097s
  training loss:		0.344945
  validation loss:		0.400428
  validation accuracy:		87.28 %
Epoch 1601 of 2000 took 0.097s
  training loss:		0.335517
  validation loss:		0.402222
  validation accuracy:		87.50 %
Epoch 1602 of 2000 took 0.097s
  training loss:		0.340054
  validation loss:		0.392042
  validation accuracy:		87.61 %
Epoch 1603 of 2000 took 0.097s
  training loss:		0.345401
  validation loss:		0.397657
  validation accuracy:		87.93 %
Epoch 1604 of 2000 took 0.097s
  training loss:		0.342823
  validation loss:		0.403198
  validation accuracy:		87.93 %
Epoch 1605 of 2000 took 0.098s
  training loss:		0.339073
  validation loss:		0.397907
  validation accuracy:		87.50 %
Epoch 1606 of 2000 took 0.097s
  training loss:		0.337350
  validation loss:		0.395046
  validation accuracy:		88.04 %
Epoch 1607 of 2000 took 0.097s
  training loss:		0.337022
  validation loss:		0.401873
  validation accuracy:		87.39 %
Epoch 1608 of 2000 took 0.097s
  training loss:		0.335254
  validation loss:		0.412664
  validation accuracy:		86.96 %
Epoch 1609 of 2000 took 0.097s
  training loss:		0.339108
  validation loss:		0.398918
  validation accuracy:		87.61 %
Epoch 1610 of 2000 took 0.097s
  training loss:		0.336869
  validation loss:		0.398052
  validation accuracy:		87.50 %
Epoch 1611 of 2000 took 0.097s
  training loss:		0.339810
  validation loss:		0.398323
  validation accuracy:		87.83 %
Epoch 1612 of 2000 took 0.097s
  training loss:		0.342677
  validation loss:		0.398638
  validation accuracy:		87.28 %
Epoch 1613 of 2000 took 0.097s
  training loss:		0.331513
  validation loss:		0.400080
  validation accuracy:		87.07 %
Epoch 1614 of 2000 took 0.097s
  training loss:		0.335926
  validation loss:		0.398985
  validation accuracy:		87.17 %
Epoch 1615 of 2000 took 0.097s
  training loss:		0.326979
  validation loss:		0.407798
  validation accuracy:		86.85 %
Epoch 1616 of 2000 took 0.097s
  training loss:		0.335782
  validation loss:		0.395002
  validation accuracy:		87.93 %
Epoch 1617 of 2000 took 0.097s
  training loss:		0.333868
  validation loss:		0.388980
  validation accuracy:		88.15 %
Epoch 1618 of 2000 took 0.097s
  training loss:		0.338018
  validation loss:		0.400062
  validation accuracy:		87.28 %
Epoch 1619 of 2000 took 0.097s
  training loss:		0.329551
  validation loss:		0.406945
  validation accuracy:		87.61 %
Epoch 1620 of 2000 took 0.097s
  training loss:		0.322671
  validation loss:		0.390837
  validation accuracy:		87.61 %
Epoch 1621 of 2000 took 0.097s
  training loss:		0.336216
  validation loss:		0.384634
  validation accuracy:		88.15 %
Epoch 1622 of 2000 took 0.097s
  training loss:		0.329491
  validation loss:		0.386568
  validation accuracy:		88.26 %
Epoch 1623 of 2000 took 0.097s
  training loss:		0.326764
  validation loss:		0.401753
  validation accuracy:		87.39 %
Epoch 1624 of 2000 took 0.097s
  training loss:		0.335455
  validation loss:		0.389590
  validation accuracy:		87.93 %
Epoch 1625 of 2000 took 0.097s
  training loss:		0.333999
  validation loss:		0.395136
  validation accuracy:		87.50 %
Epoch 1626 of 2000 took 0.097s
  training loss:		0.331927
  validation loss:		0.385053
  validation accuracy:		88.26 %
Epoch 1627 of 2000 took 0.097s
  training loss:		0.325654
  validation loss:		0.399414
  validation accuracy:		87.61 %
Epoch 1628 of 2000 took 0.097s
  training loss:		0.327960
  validation loss:		0.386832
  validation accuracy:		88.04 %
Epoch 1629 of 2000 took 0.097s
  training loss:		0.329063
  validation loss:		0.386381
  validation accuracy:		87.83 %
Epoch 1630 of 2000 took 0.097s
  training loss:		0.320952
  validation loss:		0.390600
  validation accuracy:		87.83 %
Epoch 1631 of 2000 took 0.097s
  training loss:		0.332838
  validation loss:		0.389585
  validation accuracy:		87.83 %
Epoch 1632 of 2000 took 0.097s
  training loss:		0.328817
  validation loss:		0.396010
  validation accuracy:		87.72 %
Epoch 1633 of 2000 took 0.097s
  training loss:		0.331249
  validation loss:		0.386886
  validation accuracy:		88.26 %
Epoch 1634 of 2000 took 0.097s
  training loss:		0.327956
  validation loss:		0.389638
  validation accuracy:		87.93 %
Epoch 1635 of 2000 took 0.097s
  training loss:		0.322055
  validation loss:		0.398126
  validation accuracy:		87.39 %
Epoch 1636 of 2000 took 0.098s
  training loss:		0.320377
  validation loss:		0.386220
  validation accuracy:		88.37 %
Epoch 1637 of 2000 took 0.097s
  training loss:		0.323503
  validation loss:		0.379383
  validation accuracy:		88.26 %
Epoch 1638 of 2000 took 0.097s
  training loss:		0.326522
  validation loss:		0.396063
  validation accuracy:		87.83 %
Epoch 1639 of 2000 took 0.097s
  training loss:		0.327632
  validation loss:		0.384396
  validation accuracy:		88.37 %
Epoch 1640 of 2000 took 0.097s
  training loss:		0.329673
  validation loss:		0.380929
  validation accuracy:		88.48 %
Epoch 1641 of 2000 took 0.097s
  training loss:		0.321656
  validation loss:		0.388513
  validation accuracy:		88.15 %
Epoch 1642 of 2000 took 0.097s
  training loss:		0.327874
  validation loss:		0.391261
  validation accuracy:		88.04 %
Epoch 1643 of 2000 took 0.097s
  training loss:		0.323032
  validation loss:		0.386123
  validation accuracy:		87.93 %
Epoch 1644 of 2000 took 0.097s
  training loss:		0.318507
  validation loss:		0.379282
  validation accuracy:		88.26 %
Epoch 1645 of 2000 took 0.097s
  training loss:		0.325261
  validation loss:		0.387171
  validation accuracy:		88.04 %
Epoch 1646 of 2000 took 0.097s
  training loss:		0.315241
  validation loss:		0.386047
  validation accuracy:		88.04 %
Epoch 1647 of 2000 took 0.097s
  training loss:		0.324601
  validation loss:		0.385395
  validation accuracy:		88.15 %
Epoch 1648 of 2000 took 0.097s
  training loss:		0.317331
  validation loss:		0.395945
  validation accuracy:		87.83 %
Epoch 1649 of 2000 took 0.097s
  training loss:		0.318804
  validation loss:		0.382755
  validation accuracy:		88.15 %
Epoch 1650 of 2000 took 0.097s
  training loss:		0.323161
  validation loss:		0.395071
  validation accuracy:		87.61 %
Epoch 1651 of 2000 took 0.097s
  training loss:		0.317232
  validation loss:		0.385470
  validation accuracy:		88.26 %
Epoch 1652 of 2000 took 0.097s
  training loss:		0.323653
  validation loss:		0.382030
  validation accuracy:		88.59 %
Epoch 1653 of 2000 took 0.097s
  training loss:		0.314918
  validation loss:		0.402438
  validation accuracy:		87.39 %
Epoch 1654 of 2000 took 0.097s
  training loss:		0.322264
  validation loss:		0.377093
  validation accuracy:		89.02 %
Epoch 1655 of 2000 took 0.097s
  training loss:		0.319458
  validation loss:		0.377318
  validation accuracy:		88.59 %
Epoch 1656 of 2000 took 0.097s
  training loss:		0.310255
  validation loss:		0.383339
  validation accuracy:		88.70 %
Epoch 1657 of 2000 took 0.097s
  training loss:		0.317658
  validation loss:		0.385617
  validation accuracy:		88.37 %
Epoch 1658 of 2000 took 0.097s
  training loss:		0.322195
  validation loss:		0.375369
  validation accuracy:		88.70 %
Epoch 1659 of 2000 took 0.097s
  training loss:		0.307050
  validation loss:		0.380155
  validation accuracy:		88.48 %
Epoch 1660 of 2000 took 0.097s
  training loss:		0.326209
  validation loss:		0.375352
  validation accuracy:		89.02 %
Epoch 1661 of 2000 took 0.097s
  training loss:		0.315671
  validation loss:		0.387852
  validation accuracy:		88.15 %
Epoch 1662 of 2000 took 0.097s
  training loss:		0.315613
  validation loss:		0.385798
  validation accuracy:		88.15 %
Epoch 1663 of 2000 took 0.097s
  training loss:		0.321453
  validation loss:		0.377788
  validation accuracy:		88.59 %
Epoch 1664 of 2000 took 0.097s
  training loss:		0.315154
  validation loss:		0.391485
  validation accuracy:		87.72 %
Epoch 1665 of 2000 took 0.097s
  training loss:		0.318284
  validation loss:		0.387273
  validation accuracy:		88.26 %
Epoch 1666 of 2000 took 0.097s
  training loss:		0.315770
  validation loss:		0.388472
  validation accuracy:		88.37 %
Epoch 1667 of 2000 took 0.098s
  training loss:		0.315955
  validation loss:		0.393265
  validation accuracy:		88.15 %
Epoch 1668 of 2000 took 0.097s
  training loss:		0.314559
  validation loss:		0.373953
  validation accuracy:		88.80 %
Epoch 1669 of 2000 took 0.097s
  training loss:		0.313866
  validation loss:		0.379390
  validation accuracy:		88.80 %
Epoch 1670 of 2000 took 0.097s
  training loss:		0.311043
  validation loss:		0.375972
  validation accuracy:		88.48 %
Epoch 1671 of 2000 took 0.097s
  training loss:		0.311101
  validation loss:		0.390967
  validation accuracy:		88.04 %
Epoch 1672 of 2000 took 0.097s
  training loss:		0.317537
  validation loss:		0.380120
  validation accuracy:		88.48 %
Epoch 1673 of 2000 took 0.097s
  training loss:		0.306550
  validation loss:		0.386910
  validation accuracy:		88.15 %
Epoch 1674 of 2000 took 0.097s
  training loss:		0.311974
  validation loss:		0.378341
  validation accuracy:		88.37 %
Epoch 1675 of 2000 took 0.097s
  training loss:		0.313574
  validation loss:		0.373694
  validation accuracy:		88.48 %
Epoch 1676 of 2000 took 0.097s
  training loss:		0.313064
  validation loss:		0.404737
  validation accuracy:		87.72 %
Epoch 1677 of 2000 took 0.097s
  training loss:		0.315340
  validation loss:		0.378252
  validation accuracy:		88.59 %
Epoch 1678 of 2000 took 0.097s
  training loss:		0.312519
  validation loss:		0.390899
  validation accuracy:		87.72 %
Epoch 1679 of 2000 took 0.097s
  training loss:		0.308033
  validation loss:		0.376600
  validation accuracy:		88.59 %
Epoch 1680 of 2000 took 0.097s
  training loss:		0.307801
  validation loss:		0.377899
  validation accuracy:		88.48 %
Epoch 1681 of 2000 took 0.097s
  training loss:		0.314223
  validation loss:		0.372114
  validation accuracy:		88.80 %
Epoch 1682 of 2000 took 0.097s
  training loss:		0.306944
  validation loss:		0.372661
  validation accuracy:		89.02 %
Epoch 1683 of 2000 took 0.097s
  training loss:		0.313541
  validation loss:		0.392717
  validation accuracy:		88.15 %
Epoch 1684 of 2000 took 0.097s
  training loss:		0.309927
  validation loss:		0.377595
  validation accuracy:		88.37 %
Epoch 1685 of 2000 took 0.097s
  training loss:		0.308346
  validation loss:		0.393589
  validation accuracy:		87.93 %
Epoch 1686 of 2000 took 0.097s
  training loss:		0.306174
  validation loss:		0.380666
  validation accuracy:		88.37 %
Epoch 1687 of 2000 took 0.097s
  training loss:		0.315279
  validation loss:		0.375534
  validation accuracy:		88.91 %
Epoch 1688 of 2000 took 0.097s
  training loss:		0.308810
  validation loss:		0.378267
  validation accuracy:		88.59 %
Epoch 1689 of 2000 took 0.097s
  training loss:		0.303530
  validation loss:		0.379735
  validation accuracy:		88.26 %
Epoch 1690 of 2000 took 0.097s
  training loss:		0.303811
  validation loss:		0.385587
  validation accuracy:		87.83 %
Epoch 1691 of 2000 took 0.097s
  training loss:		0.311801
  validation loss:		0.388998
  validation accuracy:		87.50 %
Epoch 1692 of 2000 took 0.097s
  training loss:		0.306664
  validation loss:		0.388681
  validation accuracy:		88.15 %
Epoch 1693 of 2000 took 0.097s
  training loss:		0.311854
  validation loss:		0.390187
  validation accuracy:		88.15 %
Epoch 1694 of 2000 took 0.097s
  training loss:		0.303815
  validation loss:		0.379360
  validation accuracy:		88.15 %
Epoch 1695 of 2000 took 0.097s
  training loss:		0.308910
  validation loss:		0.374129
  validation accuracy:		88.26 %
Epoch 1696 of 2000 took 0.097s
  training loss:		0.302170
  validation loss:		0.399457
  validation accuracy:		88.37 %
Epoch 1697 of 2000 took 0.097s
  training loss:		0.309829
  validation loss:		0.373082
  validation accuracy:		88.59 %
Epoch 1698 of 2000 took 0.098s
  training loss:		0.308589
  validation loss:		0.375760
  validation accuracy:		88.91 %
Epoch 1699 of 2000 took 0.097s
  training loss:		0.311845
  validation loss:		0.375968
  validation accuracy:		88.26 %
Epoch 1700 of 2000 took 0.097s
  training loss:		0.302870
  validation loss:		0.372630
  validation accuracy:		89.02 %
Epoch 1701 of 2000 took 0.097s
  training loss:		0.308345
  validation loss:		0.383772
  validation accuracy:		87.83 %
Epoch 1702 of 2000 took 0.097s
  training loss:		0.307294
  validation loss:		0.368904
  validation accuracy:		88.59 %
Epoch 1703 of 2000 took 0.097s
  training loss:		0.306586
  validation loss:		0.374235
  validation accuracy:		88.59 %
Epoch 1704 of 2000 took 0.097s
  training loss:		0.305022
  validation loss:		0.386881
  validation accuracy:		88.26 %
Epoch 1705 of 2000 took 0.097s
  training loss:		0.306895
  validation loss:		0.376963
  validation accuracy:		88.70 %
Epoch 1706 of 2000 took 0.097s
  training loss:		0.300994
  validation loss:		0.366539
  validation accuracy:		89.02 %
Epoch 1707 of 2000 took 0.097s
  training loss:		0.296809
  validation loss:		0.374677
  validation accuracy:		89.13 %
Epoch 1708 of 2000 took 0.097s
  training loss:		0.302868
  validation loss:		0.367476
  validation accuracy:		89.13 %
Epoch 1709 of 2000 took 0.097s
  training loss:		0.305422
  validation loss:		0.377186
  validation accuracy:		88.48 %
Epoch 1710 of 2000 took 0.097s
  training loss:		0.305813
  validation loss:		0.375369
  validation accuracy:		88.59 %
Epoch 1711 of 2000 took 0.097s
  training loss:		0.304462
  validation loss:		0.372276
  validation accuracy:		89.02 %
Epoch 1712 of 2000 took 0.097s
  training loss:		0.301992
  validation loss:		0.379215
  validation accuracy:		88.59 %
Epoch 1713 of 2000 took 0.097s
  training loss:		0.308850
  validation loss:		0.374941
  validation accuracy:		88.48 %
Epoch 1714 of 2000 took 0.097s
  training loss:		0.300537
  validation loss:		0.374545
  validation accuracy:		88.70 %
Epoch 1715 of 2000 took 0.097s
  training loss:		0.299816
  validation loss:		0.378135
  validation accuracy:		88.48 %
Epoch 1716 of 2000 took 0.097s
  training loss:		0.309123
  validation loss:		0.372405
  validation accuracy:		89.13 %
Epoch 1717 of 2000 took 0.097s
  training loss:		0.299827
  validation loss:		0.374585
  validation accuracy:		88.70 %
Epoch 1718 of 2000 took 0.098s
  training loss:		0.299239
  validation loss:		0.367226
  validation accuracy:		89.13 %
Epoch 1719 of 2000 took 0.105s
  training loss:		0.304085
  validation loss:		0.384503
  validation accuracy:		88.37 %
Epoch 1720 of 2000 took 0.111s
  training loss:		0.299476
  validation loss:		0.371077
  validation accuracy:		88.48 %
Epoch 1721 of 2000 took 0.137s
  training loss:		0.300278
  validation loss:		0.367547
  validation accuracy:		88.70 %
Epoch 1722 of 2000 took 0.113s
  training loss:		0.300162
  validation loss:		0.383500
  validation accuracy:		88.80 %
Epoch 1723 of 2000 took 0.101s
  training loss:		0.306245
  validation loss:		0.374443
  validation accuracy:		88.37 %
Epoch 1724 of 2000 took 0.104s
  training loss:		0.304203
  validation loss:		0.387719
  validation accuracy:		88.26 %
Epoch 1725 of 2000 took 0.102s
  training loss:		0.301093
  validation loss:		0.369542
  validation accuracy:		89.35 %
Epoch 1726 of 2000 took 0.104s
  training loss:		0.297196
  validation loss:		0.374436
  validation accuracy:		88.91 %
Epoch 1727 of 2000 took 0.102s
  training loss:		0.300489
  validation loss:		0.376161
  validation accuracy:		88.70 %
Epoch 1728 of 2000 took 0.099s
  training loss:		0.295543
  validation loss:		0.376696
  validation accuracy:		88.59 %
Epoch 1729 of 2000 took 0.097s
  training loss:		0.296579
  validation loss:		0.376028
  validation accuracy:		88.26 %
Epoch 1730 of 2000 took 0.097s
  training loss:		0.295277
  validation loss:		0.373842
  validation accuracy:		88.70 %
Epoch 1731 of 2000 took 0.097s
  training loss:		0.304498
  validation loss:		0.375356
  validation accuracy:		88.91 %
Epoch 1732 of 2000 took 0.096s
  training loss:		0.295105
  validation loss:		0.369418
  validation accuracy:		89.24 %
Epoch 1733 of 2000 took 0.096s
  training loss:		0.298776
  validation loss:		0.369618
  validation accuracy:		89.24 %
Epoch 1734 of 2000 took 0.097s
  training loss:		0.288078
  validation loss:		0.372886
  validation accuracy:		88.91 %
Epoch 1735 of 2000 took 0.096s
  training loss:		0.295273
  validation loss:		0.368580
  validation accuracy:		89.02 %
Epoch 1736 of 2000 took 0.097s
  training loss:		0.301002
  validation loss:		0.373532
  validation accuracy:		88.37 %
Epoch 1737 of 2000 took 0.096s
  training loss:		0.299401
  validation loss:		0.368269
  validation accuracy:		89.13 %
Epoch 1738 of 2000 took 0.097s
  training loss:		0.298014
  validation loss:		0.371847
  validation accuracy:		89.02 %
Epoch 1739 of 2000 took 0.097s
  training loss:		0.294077
  validation loss:		0.371849
  validation accuracy:		89.24 %
Epoch 1740 of 2000 took 0.096s
  training loss:		0.292864
  validation loss:		0.371064
  validation accuracy:		89.02 %
Epoch 1741 of 2000 took 0.097s
  training loss:		0.297585
  validation loss:		0.380210
  validation accuracy:		88.59 %
Epoch 1742 of 2000 took 0.096s
  training loss:		0.299632
  validation loss:		0.369643
  validation accuracy:		89.13 %
Epoch 1743 of 2000 took 0.097s
  training loss:		0.297477
  validation loss:		0.368451
  validation accuracy:		89.35 %
Epoch 1744 of 2000 took 0.097s
  training loss:		0.294285
  validation loss:		0.378835
  validation accuracy:		88.59 %
Epoch 1745 of 2000 took 0.097s
  training loss:		0.301602
  validation loss:		0.375464
  validation accuracy:		89.24 %
Epoch 1746 of 2000 took 0.097s
  training loss:		0.299103
  validation loss:		0.371029
  validation accuracy:		88.70 %
Epoch 1747 of 2000 took 0.100s
  training loss:		0.291332
  validation loss:		0.366570
  validation accuracy:		89.24 %
Epoch 1748 of 2000 took 0.097s
  training loss:		0.292350
  validation loss:		0.373401
  validation accuracy:		88.70 %
Epoch 1749 of 2000 took 0.097s
  training loss:		0.291720
  validation loss:		0.375808
  validation accuracy:		88.26 %
Epoch 1750 of 2000 took 0.097s
  training loss:		0.293795
  validation loss:		0.380085
  validation accuracy:		88.70 %
Epoch 1751 of 2000 took 0.096s
  training loss:		0.291450
  validation loss:		0.380043
  validation accuracy:		89.02 %
Epoch 1752 of 2000 took 0.097s
  training loss:		0.296780
  validation loss:		0.376447
  validation accuracy:		89.02 %
Epoch 1753 of 2000 took 0.096s
  training loss:		0.290659
  validation loss:		0.396593
  validation accuracy:		88.26 %
Epoch 1754 of 2000 took 0.096s
  training loss:		0.291257
  validation loss:		0.386879
  validation accuracy:		88.59 %
Epoch 1755 of 2000 took 0.097s
  training loss:		0.298646
  validation loss:		0.364649
  validation accuracy:		89.46 %
Epoch 1756 of 2000 took 0.097s
  training loss:		0.292626
  validation loss:		0.385503
  validation accuracy:		88.70 %
Epoch 1757 of 2000 took 0.096s
  training loss:		0.297263
  validation loss:		0.382273
  validation accuracy:		87.93 %
Epoch 1758 of 2000 took 0.097s
  training loss:		0.300914
  validation loss:		0.366234
  validation accuracy:		89.24 %
Epoch 1759 of 2000 took 0.098s
  training loss:		0.293699
  validation loss:		0.370709
  validation accuracy:		89.35 %
Epoch 1760 of 2000 took 0.097s
  training loss:		0.298634
  validation loss:		0.372224
  validation accuracy:		88.80 %
Epoch 1761 of 2000 took 0.104s
  training loss:		0.291649
  validation loss:		0.368408
  validation accuracy:		89.35 %
Epoch 1762 of 2000 took 0.165s
  training loss:		0.290261
  validation loss:		0.362504
  validation accuracy:		89.46 %
Epoch 1763 of 2000 took 0.139s
  training loss:		0.292484
  validation loss:		0.374753
  validation accuracy:		88.59 %
Epoch 1764 of 2000 took 0.096s
  training loss:		0.295073
  validation loss:		0.384443
  validation accuracy:		88.70 %
Epoch 1765 of 2000 took 0.097s
  training loss:		0.294703
  validation loss:		0.368866
  validation accuracy:		89.57 %
Epoch 1766 of 2000 took 0.102s
  training loss:		0.293749
  validation loss:		0.363776
  validation accuracy:		89.57 %
Epoch 1767 of 2000 took 0.106s
  training loss:		0.293612
  validation loss:		0.369931
  validation accuracy:		89.13 %
Epoch 1768 of 2000 took 0.104s
  training loss:		0.296895
  validation loss:		0.363190
  validation accuracy:		89.24 %
Epoch 1769 of 2000 took 0.099s
  training loss:		0.291370
  validation loss:		0.377485
  validation accuracy:		89.13 %
Epoch 1770 of 2000 took 0.099s
  training loss:		0.286780
  validation loss:		0.370989
  validation accuracy:		89.13 %
Epoch 1771 of 2000 took 0.099s
  training loss:		0.292542
  validation loss:		0.371929
  validation accuracy:		89.24 %
Epoch 1772 of 2000 took 0.099s
  training loss:		0.294262
  validation loss:		0.366526
  validation accuracy:		89.46 %
Epoch 1773 of 2000 took 0.099s
  training loss:		0.293487
  validation loss:		0.371610
  validation accuracy:		89.24 %
Epoch 1774 of 2000 took 0.099s
  training loss:		0.295829
  validation loss:		0.371835
  validation accuracy:		89.24 %
Epoch 1775 of 2000 took 0.099s
  training loss:		0.290543
  validation loss:		0.368686
  validation accuracy:		89.46 %
Epoch 1776 of 2000 took 0.098s
  training loss:		0.299060
  validation loss:		0.364876
  validation accuracy:		89.67 %
Epoch 1777 of 2000 took 0.096s
  training loss:		0.293696
  validation loss:		0.374541
  validation accuracy:		89.57 %
Epoch 1778 of 2000 took 0.096s
  training loss:		0.293007
  validation loss:		0.395889
  validation accuracy:		88.26 %
Epoch 1779 of 2000 took 0.103s
  training loss:		0.292263
  validation loss:		0.365373
  validation accuracy:		89.57 %
Epoch 1780 of 2000 took 0.098s
  training loss:		0.293864
  validation loss:		0.382688
  validation accuracy:		89.02 %
Epoch 1781 of 2000 took 0.096s
  training loss:		0.294200
  validation loss:		0.361179
  validation accuracy:		89.78 %
Epoch 1782 of 2000 took 0.100s
  training loss:		0.292461
  validation loss:		0.372887
  validation accuracy:		88.91 %
Epoch 1783 of 2000 took 0.100s
  training loss:		0.291868
  validation loss:		0.369995
  validation accuracy:		89.67 %
Epoch 1784 of 2000 took 0.098s
  training loss:		0.285707
  validation loss:		0.378248
  validation accuracy:		88.80 %
Epoch 1785 of 2000 took 0.097s
  training loss:		0.290750
  validation loss:		0.369341
  validation accuracy:		88.91 %
Epoch 1786 of 2000 took 0.097s
  training loss:		0.294689
  validation loss:		0.374598
  validation accuracy:		88.37 %
Epoch 1787 of 2000 took 0.097s
  training loss:		0.295320
  validation loss:		0.362264
  validation accuracy:		89.35 %
Epoch 1788 of 2000 took 0.098s
  training loss:		0.291693
  validation loss:		0.397634
  validation accuracy:		88.04 %
Epoch 1789 of 2000 took 0.097s
  training loss:		0.295120
  validation loss:		0.370112
  validation accuracy:		89.35 %
Epoch 1790 of 2000 took 0.097s
  training loss:		0.293276
  validation loss:		0.362531
  validation accuracy:		89.46 %
Epoch 1791 of 2000 took 0.097s
  training loss:		0.290442
  validation loss:		0.381744
  validation accuracy:		88.80 %
Epoch 1792 of 2000 took 0.097s
  training loss:		0.293970
  validation loss:		0.364371
  validation accuracy:		89.46 %
Epoch 1793 of 2000 took 0.097s
  training loss:		0.290805
  validation loss:		0.374762
  validation accuracy:		89.24 %
Epoch 1794 of 2000 took 0.097s
  training loss:		0.291530
  validation loss:		0.369079
  validation accuracy:		89.78 %
Epoch 1795 of 2000 took 0.097s
  training loss:		0.287717
  validation loss:		0.362712
  validation accuracy:		89.24 %
Epoch 1796 of 2000 took 0.097s
  training loss:		0.289123
  validation loss:		0.377861
  validation accuracy:		89.02 %
Epoch 1797 of 2000 took 0.097s
  training loss:		0.293150
  validation loss:		0.371629
  validation accuracy:		89.24 %
Epoch 1798 of 2000 took 0.097s
  training loss:		0.287298
  validation loss:		0.392096
  validation accuracy:		88.80 %
Epoch 1799 of 2000 took 0.097s
  training loss:		0.295841
  validation loss:		0.368339
  validation accuracy:		89.13 %
Epoch 1800 of 2000 took 0.097s
  training loss:		0.294990
  validation loss:		0.372328
  validation accuracy:		89.35 %
Epoch 1801 of 2000 took 0.097s
  training loss:		0.288008
  validation loss:		0.372065
  validation accuracy:		89.35 %
Epoch 1802 of 2000 took 0.097s
  training loss:		0.289270
  validation loss:		0.365989
  validation accuracy:		89.24 %
Epoch 1803 of 2000 took 0.097s
  training loss:		0.290852
  validation loss:		0.358621
  validation accuracy:		89.24 %
Epoch 1804 of 2000 took 0.097s
  training loss:		0.281024
  validation loss:		0.373353
  validation accuracy:		89.24 %
Epoch 1805 of 2000 took 0.097s
  training loss:		0.282120
  validation loss:		0.358392
  validation accuracy:		89.78 %
Epoch 1806 of 2000 took 0.097s
  training loss:		0.288836
  validation loss:		0.373444
  validation accuracy:		89.13 %
Epoch 1807 of 2000 took 0.097s
  training loss:		0.298751
  validation loss:		0.364678
  validation accuracy:		89.67 %
Epoch 1808 of 2000 took 0.097s
  training loss:		0.291259
  validation loss:		0.380214
  validation accuracy:		89.13 %
Epoch 1809 of 2000 took 0.097s
  training loss:		0.283460
  validation loss:		0.374043
  validation accuracy:		89.13 %
Epoch 1810 of 2000 took 0.097s
  training loss:		0.287756
  validation loss:		0.374676
  validation accuracy:		89.13 %
Epoch 1811 of 2000 took 0.097s
  training loss:		0.288777
  validation loss:		0.369443
  validation accuracy:		89.35 %
Epoch 1812 of 2000 took 0.097s
  training loss:		0.290358
  validation loss:		0.362499
  validation accuracy:		89.13 %
Epoch 1813 of 2000 took 0.097s
  training loss:		0.287354
  validation loss:		0.363377
  validation accuracy:		89.67 %
Epoch 1814 of 2000 took 0.097s
  training loss:		0.294111
  validation loss:		0.378068
  validation accuracy:		88.48 %
Epoch 1815 of 2000 took 0.097s
  training loss:		0.293625
  validation loss:		0.372813
  validation accuracy:		89.02 %
Epoch 1816 of 2000 took 0.097s
  training loss:		0.284664
  validation loss:		0.384674
  validation accuracy:		88.80 %
Epoch 1817 of 2000 took 0.097s
  training loss:		0.285358
  validation loss:		0.366468
  validation accuracy:		88.80 %
Epoch 1818 of 2000 took 0.097s
  training loss:		0.286052
  validation loss:		0.360115
  validation accuracy:		89.57 %
Epoch 1819 of 2000 took 0.098s
  training loss:		0.290544
  validation loss:		0.358147
  validation accuracy:		89.57 %
Epoch 1820 of 2000 took 0.097s
  training loss:		0.290600
  validation loss:		0.366317
  validation accuracy:		89.57 %
Epoch 1821 of 2000 took 0.097s
  training loss:		0.292730
  validation loss:		0.369122
  validation accuracy:		89.35 %
Epoch 1822 of 2000 took 0.097s
  training loss:		0.291873
  validation loss:		0.362546
  validation accuracy:		89.78 %
Epoch 1823 of 2000 took 0.097s
  training loss:		0.284967
  validation loss:		0.370831
  validation accuracy:		89.35 %
Epoch 1824 of 2000 took 0.097s
  training loss:		0.287303
  validation loss:		0.368004
  validation accuracy:		89.24 %
Epoch 1825 of 2000 took 0.097s
  training loss:		0.289291
  validation loss:		0.364859
  validation accuracy:		89.24 %
Epoch 1826 of 2000 took 0.097s
  training loss:		0.295123
  validation loss:		0.364700
  validation accuracy:		89.57 %
Epoch 1827 of 2000 took 0.097s
  training loss:		0.285114
  validation loss:		0.364565
  validation accuracy:		89.35 %
Epoch 1828 of 2000 took 0.097s
  training loss:		0.280633
  validation loss:		0.372774
  validation accuracy:		89.13 %
Epoch 1829 of 2000 took 0.097s
  training loss:		0.287312
  validation loss:		0.370447
  validation accuracy:		89.24 %
Epoch 1830 of 2000 took 0.097s
  training loss:		0.282265
  validation loss:		0.385490
  validation accuracy:		88.59 %
Epoch 1831 of 2000 took 0.097s
  training loss:		0.287693
  validation loss:		0.364404
  validation accuracy:		89.78 %
Epoch 1832 of 2000 took 0.097s
  training loss:		0.284710
  validation loss:		0.365450
  validation accuracy:		89.57 %
Epoch 1833 of 2000 took 0.097s
  training loss:		0.280730
  validation loss:		0.362422
  validation accuracy:		89.13 %
Epoch 1834 of 2000 took 0.097s
  training loss:		0.281375
  validation loss:		0.361182
  validation accuracy:		89.57 %
Epoch 1835 of 2000 took 0.097s
  training loss:		0.285981
  validation loss:		0.371782
  validation accuracy:		89.24 %
Epoch 1836 of 2000 took 0.097s
  training loss:		0.287053
  validation loss:		0.362399
  validation accuracy:		89.35 %
Epoch 1837 of 2000 took 0.097s
  training loss:		0.287225
  validation loss:		0.369157
  validation accuracy:		89.24 %
Epoch 1838 of 2000 took 0.097s
  training loss:		0.289554
  validation loss:		0.368587
  validation accuracy:		89.35 %
Epoch 1839 of 2000 took 0.097s
  training loss:		0.281344
  validation loss:		0.374651
  validation accuracy:		89.13 %
Epoch 1840 of 2000 took 0.097s
  training loss:		0.286750
  validation loss:		0.359822
  validation accuracy:		89.57 %
Epoch 1841 of 2000 took 0.097s
  training loss:		0.285998
  validation loss:		0.373555
  validation accuracy:		89.13 %
Epoch 1842 of 2000 took 0.097s
  training loss:		0.285863
  validation loss:		0.372657
  validation accuracy:		89.57 %
Epoch 1843 of 2000 took 0.097s
  training loss:		0.292069
  validation loss:		0.361792
  validation accuracy:		89.46 %
Epoch 1844 of 2000 took 0.097s
  training loss:		0.285873
  validation loss:		0.362316
  validation accuracy:		89.35 %
Epoch 1845 of 2000 took 0.097s
  training loss:		0.293528
  validation loss:		0.364224
  validation accuracy:		89.46 %
Epoch 1846 of 2000 took 0.097s
  training loss:		0.282132
  validation loss:		0.371829
  validation accuracy:		89.24 %
Epoch 1847 of 2000 took 0.097s
  training loss:		0.290018
  validation loss:		0.362090
  validation accuracy:		89.67 %
Epoch 1848 of 2000 took 0.097s
  training loss:		0.290433
  validation loss:		0.362130
  validation accuracy:		89.57 %
Epoch 1849 of 2000 took 0.097s
  training loss:		0.286173
  validation loss:		0.359667
  validation accuracy:		89.89 %
Epoch 1850 of 2000 took 0.098s
  training loss:		0.283094
  validation loss:		0.371672
  validation accuracy:		89.02 %
Epoch 1851 of 2000 took 0.097s
  training loss:		0.287522
  validation loss:		0.374271
  validation accuracy:		89.24 %
Epoch 1852 of 2000 took 0.097s
  training loss:		0.287736
  validation loss:		0.364532
  validation accuracy:		89.57 %
Epoch 1853 of 2000 took 0.097s
  training loss:		0.279485
  validation loss:		0.363898
  validation accuracy:		89.78 %
Epoch 1854 of 2000 took 0.097s
  training loss:		0.289376
  validation loss:		0.364217
  validation accuracy:		89.67 %
Epoch 1855 of 2000 took 0.097s
  training loss:		0.285703
  validation loss:		0.365564
  validation accuracy:		89.46 %
Epoch 1856 of 2000 took 0.097s
  training loss:		0.278922
  validation loss:		0.368467
  validation accuracy:		89.78 %
Epoch 1857 of 2000 took 0.097s
  training loss:		0.285995
  validation loss:		0.369700
  validation accuracy:		89.02 %
Epoch 1858 of 2000 took 0.097s
  training loss:		0.283725
  validation loss:		0.367979
  validation accuracy:		89.24 %
Epoch 1859 of 2000 took 0.097s
  training loss:		0.289316
  validation loss:		0.384927
  validation accuracy:		88.48 %
Epoch 1860 of 2000 took 0.097s
  training loss:		0.280433
  validation loss:		0.375281
  validation accuracy:		89.02 %
Epoch 1861 of 2000 took 0.097s
  training loss:		0.291595
  validation loss:		0.369575
  validation accuracy:		89.24 %
Epoch 1862 of 2000 took 0.097s
  training loss:		0.285323
  validation loss:		0.368266
  validation accuracy:		89.13 %
Epoch 1863 of 2000 took 0.097s
  training loss:		0.284011
  validation loss:		0.365170
  validation accuracy:		89.13 %
Epoch 1864 of 2000 took 0.097s
  training loss:		0.281128
  validation loss:		0.367899
  validation accuracy:		89.46 %
Epoch 1865 of 2000 took 0.097s
  training loss:		0.287684
  validation loss:		0.363637
  validation accuracy:		89.67 %
Epoch 1866 of 2000 took 0.097s
  training loss:		0.283081
  validation loss:		0.373337
  validation accuracy:		88.59 %
Epoch 1867 of 2000 took 0.097s
  training loss:		0.290959
  validation loss:		0.365368
  validation accuracy:		89.46 %
Epoch 1868 of 2000 took 0.097s
  training loss:		0.286124
  validation loss:		0.380901
  validation accuracy:		88.37 %
Epoch 1869 of 2000 took 0.097s
  training loss:		0.284667
  validation loss:		0.359559
  validation accuracy:		89.57 %
Epoch 1870 of 2000 took 0.097s
  training loss:		0.285471
  validation loss:		0.379123
  validation accuracy:		88.91 %
Epoch 1871 of 2000 took 0.097s
  training loss:		0.281706
  validation loss:		0.372136
  validation accuracy:		89.35 %
Epoch 1872 of 2000 took 0.097s
  training loss:		0.284468
  validation loss:		0.373050
  validation accuracy:		88.48 %
Epoch 1873 of 2000 took 0.097s
  training loss:		0.281940
  validation loss:		0.367591
  validation accuracy:		89.24 %
Epoch 1874 of 2000 took 0.097s
  training loss:		0.281256
  validation loss:		0.378537
  validation accuracy:		88.26 %
Epoch 1875 of 2000 took 0.097s
  training loss:		0.286857
  validation loss:		0.373087
  validation accuracy:		89.02 %
Epoch 1876 of 2000 took 0.097s
  training loss:		0.279395
  validation loss:		0.379299
  validation accuracy:		88.91 %
Epoch 1877 of 2000 took 0.097s
  training loss:		0.279960
  validation loss:		0.374674
  validation accuracy:		89.24 %
Epoch 1878 of 2000 took 0.097s
  training loss:		0.279682
  validation loss:		0.369709
  validation accuracy:		88.59 %
Epoch 1879 of 2000 took 0.097s
  training loss:		0.282120
  validation loss:		0.359740
  validation accuracy:		89.78 %
Epoch 1880 of 2000 took 0.097s
  training loss:		0.283288
  validation loss:		0.361220
  validation accuracy:		89.35 %
Epoch 1881 of 2000 took 0.097s
  training loss:		0.284219
  validation loss:		0.365118
  validation accuracy:		88.80 %
Epoch 1882 of 2000 took 0.098s
  training loss:		0.281377
  validation loss:		0.361342
  validation accuracy:		89.57 %
Epoch 1883 of 2000 took 0.097s
  training loss:		0.280847
  validation loss:		0.393251
  validation accuracy:		88.04 %
Epoch 1884 of 2000 took 0.097s
  training loss:		0.277265
  validation loss:		0.380151
  validation accuracy:		88.04 %
Epoch 1885 of 2000 took 0.097s
  training loss:		0.287726
  validation loss:		0.373823
  validation accuracy:		89.13 %
Epoch 1886 of 2000 took 0.097s
  training loss:		0.284771
  validation loss:		0.372943
  validation accuracy:		89.67 %
Epoch 1887 of 2000 took 0.097s
  training loss:		0.282741
  validation loss:		0.372992
  validation accuracy:		89.24 %
Epoch 1888 of 2000 took 0.097s
  training loss:		0.284630
  validation loss:		0.380189
  validation accuracy:		88.59 %
Epoch 1889 of 2000 took 0.097s
  training loss:		0.281432
  validation loss:		0.370606
  validation accuracy:		89.24 %
Epoch 1890 of 2000 took 0.097s
  training loss:		0.284198
  validation loss:		0.369597
  validation accuracy:		88.70 %
Epoch 1891 of 2000 took 0.097s
  training loss:		0.276934
  validation loss:		0.382009
  validation accuracy:		88.37 %
Epoch 1892 of 2000 took 0.097s
  training loss:		0.276901
  validation loss:		0.358848
  validation accuracy:		89.67 %
Epoch 1893 of 2000 took 0.097s
  training loss:		0.289358
  validation loss:		0.366764
  validation accuracy:		89.24 %
Epoch 1894 of 2000 took 0.097s
  training loss:		0.290915
  validation loss:		0.369863
  validation accuracy:		88.70 %
Epoch 1895 of 2000 took 0.097s
  training loss:		0.283398
  validation loss:		0.381452
  validation accuracy:		88.48 %
Epoch 1896 of 2000 took 0.097s
  training loss:		0.281630
  validation loss:		0.363635
  validation accuracy:		89.24 %
Epoch 1897 of 2000 took 0.097s
  training loss:		0.279764
  validation loss:		0.369461
  validation accuracy:		88.80 %
Epoch 1898 of 2000 took 0.097s
  training loss:		0.285839
  validation loss:		0.363400
  validation accuracy:		89.67 %
Epoch 1899 of 2000 took 0.097s
  training loss:		0.283122
  validation loss:		0.366412
  validation accuracy:		89.35 %
Epoch 1900 of 2000 took 0.097s
  training loss:		0.279213
  validation loss:		0.378911
  validation accuracy:		88.48 %
Epoch 1901 of 2000 took 0.097s
  training loss:		0.271591
  validation loss:		0.367747
  validation accuracy:		89.46 %
Epoch 1902 of 2000 took 0.097s
  training loss:		0.282651
  validation loss:		0.368738
  validation accuracy:		89.67 %
Epoch 1903 of 2000 took 0.097s
  training loss:		0.286315
  validation loss:		0.377785
  validation accuracy:		89.02 %
Epoch 1904 of 2000 took 0.097s
  training loss:		0.271710
  validation loss:		0.361766
  validation accuracy:		89.46 %
Epoch 1905 of 2000 took 0.097s
  training loss:		0.279857
  validation loss:		0.366127
  validation accuracy:		89.78 %
Epoch 1906 of 2000 took 0.097s
  training loss:		0.279769
  validation loss:		0.372508
  validation accuracy:		89.02 %
Epoch 1907 of 2000 took 0.097s
  training loss:		0.283113
  validation loss:		0.366300
  validation accuracy:		89.57 %
Epoch 1908 of 2000 took 0.097s
  training loss:		0.286287
  validation loss:		0.364296
  validation accuracy:		89.24 %
Epoch 1909 of 2000 took 0.097s
  training loss:		0.283729
  validation loss:		0.378402
  validation accuracy:		89.02 %
Epoch 1910 of 2000 took 0.097s
  training loss:		0.282934
  validation loss:		0.382856
  validation accuracy:		88.26 %
Epoch 1911 of 2000 took 0.097s
  training loss:		0.284003
  validation loss:		0.368230
  validation accuracy:		88.91 %
Epoch 1912 of 2000 took 0.097s
  training loss:		0.278760
  validation loss:		0.365896
  validation accuracy:		89.02 %
Epoch 1913 of 2000 took 0.098s
  training loss:		0.283696
  validation loss:		0.362414
  validation accuracy:		89.89 %
Epoch 1914 of 2000 took 0.097s
  training loss:		0.279708
  validation loss:		0.384269
  validation accuracy:		88.04 %
Epoch 1915 of 2000 took 0.097s
  training loss:		0.287619
  validation loss:		0.365940
  validation accuracy:		89.57 %
Epoch 1916 of 2000 took 0.097s
  training loss:		0.281183
  validation loss:		0.372330
  validation accuracy:		88.91 %
Epoch 1917 of 2000 took 0.097s
  training loss:		0.282509
  validation loss:		0.360715
  validation accuracy:		89.46 %
Epoch 1918 of 2000 took 0.097s
  training loss:		0.278727
  validation loss:		0.362972
  validation accuracy:		89.35 %
Epoch 1919 of 2000 took 0.097s
  training loss:		0.283831
  validation loss:		0.389019
  validation accuracy:		88.59 %
Epoch 1920 of 2000 took 0.097s
  training loss:		0.278709
  validation loss:		0.374578
  validation accuracy:		88.80 %
Epoch 1921 of 2000 took 0.097s
  training loss:		0.276405
  validation loss:		0.368808
  validation accuracy:		89.13 %
Epoch 1922 of 2000 took 0.097s
  training loss:		0.280871
  validation loss:		0.376828
  validation accuracy:		89.24 %
Epoch 1923 of 2000 took 0.097s
  training loss:		0.282085
  validation loss:		0.373570
  validation accuracy:		88.91 %
Epoch 1924 of 2000 took 0.097s
  training loss:		0.272308
  validation loss:		0.368862
  validation accuracy:		89.35 %
Epoch 1925 of 2000 took 0.097s
  training loss:		0.276210
  validation loss:		0.383785
  validation accuracy:		88.80 %
Epoch 1926 of 2000 took 0.097s
  training loss:		0.281902
  validation loss:		0.362497
  validation accuracy:		89.46 %
Epoch 1927 of 2000 took 0.097s
  training loss:		0.283918
  validation loss:		0.384758
  validation accuracy:		88.59 %
Epoch 1928 of 2000 took 0.097s
  training loss:		0.278073
  validation loss:		0.371894
  validation accuracy:		89.24 %
Epoch 1929 of 2000 took 0.097s
  training loss:		0.284485
  validation loss:		0.366564
  validation accuracy:		89.35 %
Epoch 1930 of 2000 took 0.097s
  training loss:		0.282161
  validation loss:		0.379681
  validation accuracy:		89.13 %
Epoch 1931 of 2000 took 0.097s
  training loss:		0.283763
  validation loss:		0.386124
  validation accuracy:		88.26 %
Epoch 1932 of 2000 took 0.097s
  training loss:		0.282952
  validation loss:		0.363582
  validation accuracy:		89.57 %
Epoch 1933 of 2000 took 0.097s
  training loss:		0.283278
  validation loss:		0.362753
  validation accuracy:		89.67 %
Epoch 1934 of 2000 took 0.097s
  training loss:		0.276196
  validation loss:		0.361581
  validation accuracy:		89.35 %
Epoch 1935 of 2000 took 0.097s
  training loss:		0.280777
  validation loss:		0.369594
  validation accuracy:		89.13 %
Epoch 1936 of 2000 took 0.097s
  training loss:		0.279133
  validation loss:		0.373147
  validation accuracy:		88.80 %
Epoch 1937 of 2000 took 0.097s
  training loss:		0.279636
  validation loss:		0.364308
  validation accuracy:		90.00 %
Epoch 1938 of 2000 took 0.097s
  training loss:		0.281492
  validation loss:		0.370985
  validation accuracy:		89.67 %
Epoch 1939 of 2000 took 0.097s
  training loss:		0.284477
  validation loss:		0.384516
  validation accuracy:		87.93 %
Epoch 1940 of 2000 took 0.097s
  training loss:		0.273872
  validation loss:		0.367976
  validation accuracy:		88.91 %
Epoch 1941 of 2000 took 0.097s
  training loss:		0.278016
  validation loss:		0.355722
  validation accuracy:		90.00 %
Epoch 1942 of 2000 took 0.097s
  training loss:		0.281259
  validation loss:		0.364667
  validation accuracy:		89.35 %
Epoch 1943 of 2000 took 0.097s
  training loss:		0.270998
  validation loss:		0.355533
  validation accuracy:		89.89 %
Epoch 1944 of 2000 took 0.098s
  training loss:		0.280901
  validation loss:		0.368302
  validation accuracy:		89.13 %
Epoch 1945 of 2000 took 0.097s
  training loss:		0.283875
  validation loss:		0.376019
  validation accuracy:		88.04 %
Epoch 1946 of 2000 took 0.097s
  training loss:		0.279295
  validation loss:		0.396383
  validation accuracy:		87.93 %
Epoch 1947 of 2000 took 0.097s
  training loss:		0.284161
  validation loss:		0.376865
  validation accuracy:		88.48 %
Epoch 1948 of 2000 took 0.097s
  training loss:		0.276238
  validation loss:		0.364740
  validation accuracy:		89.13 %
Epoch 1949 of 2000 took 0.097s
  training loss:		0.284760
  validation loss:		0.372851
  validation accuracy:		89.57 %
Epoch 1950 of 2000 took 0.097s
  training loss:		0.281951
  validation loss:		0.377912
  validation accuracy:		88.04 %
Epoch 1951 of 2000 took 0.097s
  training loss:		0.283787
  validation loss:		0.371512
  validation accuracy:		89.13 %
Epoch 1952 of 2000 took 0.097s
  training loss:		0.275243
  validation loss:		0.372641
  validation accuracy:		88.59 %
Epoch 1953 of 2000 took 0.097s
  training loss:		0.283703
  validation loss:		0.373270
  validation accuracy:		88.91 %
Epoch 1954 of 2000 took 0.097s
  training loss:		0.282179
  validation loss:		0.366911
  validation accuracy:		89.13 %
Epoch 1955 of 2000 took 0.097s
  training loss:		0.280235
  validation loss:		0.371145
  validation accuracy:		89.13 %
Epoch 1956 of 2000 took 0.097s
  training loss:		0.277094
  validation loss:		0.377489
  validation accuracy:		89.24 %
Epoch 1957 of 2000 took 0.097s
  training loss:		0.277111
  validation loss:		0.377486
  validation accuracy:		89.24 %
Epoch 1958 of 2000 took 0.097s
  training loss:		0.282733
  validation loss:		0.356939
  validation accuracy:		90.00 %
Epoch 1959 of 2000 took 0.097s
  training loss:		0.280679
  validation loss:		0.365108
  validation accuracy:		89.46 %
Epoch 1960 of 2000 took 0.097s
  training loss:		0.281924
  validation loss:		0.371553
  validation accuracy:		88.70 %
Epoch 1961 of 2000 took 0.097s
  training loss:		0.278557
  validation loss:		0.373342
  validation accuracy:		88.59 %
Epoch 1962 of 2000 took 0.097s
  training loss:		0.278164
  validation loss:		0.364770
  validation accuracy:		89.78 %
Epoch 1963 of 2000 took 0.097s
  training loss:		0.278533
  validation loss:		0.366591
  validation accuracy:		89.46 %
Epoch 1964 of 2000 took 0.097s
  training loss:		0.278402
  validation loss:		0.368829
  validation accuracy:		88.91 %
Epoch 1965 of 2000 took 0.097s
  training loss:		0.274100
  validation loss:		0.364789
  validation accuracy:		89.35 %
Epoch 1966 of 2000 took 0.097s
  training loss:		0.284161
  validation loss:		0.364464
  validation accuracy:		89.67 %
Epoch 1967 of 2000 took 0.097s
  training loss:		0.272629
  validation loss:		0.384028
  validation accuracy:		88.48 %
Epoch 1968 of 2000 took 0.097s
  training loss:		0.280928
  validation loss:		0.361603
  validation accuracy:		89.46 %
Epoch 1969 of 2000 took 0.097s
  training loss:		0.280661
  validation loss:		0.377128
  validation accuracy:		88.80 %
Epoch 1970 of 2000 took 0.097s
  training loss:		0.272527
  validation loss:		0.369014
  validation accuracy:		88.91 %
Epoch 1971 of 2000 took 0.097s
  training loss:		0.276133
  validation loss:		0.365181
  validation accuracy:		89.89 %
Epoch 1972 of 2000 took 0.097s
  training loss:		0.275487
  validation loss:		0.364807
  validation accuracy:		89.67 %
Epoch 1973 of 2000 took 0.097s
  training loss:		0.278505
  validation loss:		0.371078
  validation accuracy:		89.57 %
Epoch 1974 of 2000 took 0.097s
  training loss:		0.281313
  validation loss:		0.374350
  validation accuracy:		88.80 %
Epoch 1975 of 2000 took 0.098s
  training loss:		0.274238
  validation loss:		0.388259
  validation accuracy:		88.26 %
Epoch 1976 of 2000 took 0.097s
  training loss:		0.284329
  validation loss:		0.368718
  validation accuracy:		89.46 %
Epoch 1977 of 2000 took 0.097s
  training loss:		0.269742
  validation loss:		0.361978
  validation accuracy:		89.57 %
Epoch 1978 of 2000 took 0.097s
  training loss:		0.275313
  validation loss:		0.365823
  validation accuracy:		88.80 %
Epoch 1979 of 2000 took 0.097s
  training loss:		0.275486
  validation loss:		0.368724
  validation accuracy:		89.02 %
Epoch 1980 of 2000 took 0.097s
  training loss:		0.286504
  validation loss:		0.365147
  validation accuracy:		89.02 %
Epoch 1981 of 2000 took 0.097s
  training loss:		0.284143
  validation loss:		0.364119
  validation accuracy:		89.57 %
Epoch 1982 of 2000 took 0.097s
  training loss:		0.280280
  validation loss:		0.381095
  validation accuracy:		88.48 %
Epoch 1983 of 2000 took 0.097s
  training loss:		0.275223
  validation loss:		0.374654
  validation accuracy:		88.48 %
Epoch 1984 of 2000 took 0.097s
  training loss:		0.275912
  validation loss:		0.363167
  validation accuracy:		90.00 %
Epoch 1985 of 2000 took 0.097s
  training loss:		0.278947
  validation loss:		0.361325
  validation accuracy:		89.02 %
Epoch 1986 of 2000 took 0.097s
  training loss:		0.277370
  validation loss:		0.362964
  validation accuracy:		89.35 %
Epoch 1987 of 2000 took 0.097s
  training loss:		0.279054
  validation loss:		0.370763
  validation accuracy:		89.35 %
Epoch 1988 of 2000 took 0.097s
  training loss:		0.279850
  validation loss:		0.371749
  validation accuracy:		88.70 %
Epoch 1989 of 2000 took 0.097s
  training loss:		0.276750
  validation loss:		0.374818
  validation accuracy:		88.59 %
Epoch 1990 of 2000 took 0.097s
  training loss:		0.278539
  validation loss:		0.369295
  validation accuracy:		88.91 %
Epoch 1991 of 2000 took 0.097s
  training loss:		0.276875
  validation loss:		0.359788
  validation accuracy:		89.46 %
Epoch 1992 of 2000 took 0.097s
  training loss:		0.277282
  validation loss:		0.365165
  validation accuracy:		89.78 %
Epoch 1993 of 2000 took 0.097s
  training loss:		0.276986
  validation loss:		0.380557
  validation accuracy:		88.04 %
Epoch 1994 of 2000 took 0.097s
  training loss:		0.281599
  validation loss:		0.384513
  validation accuracy:		87.93 %
Epoch 1995 of 2000 took 0.097s
  training loss:		0.278482
  validation loss:		0.355633
  validation accuracy:		89.57 %
Epoch 1996 of 2000 took 0.097s
  training loss:		0.279935
  validation loss:		0.355361
  validation accuracy:		89.67 %
Epoch 1997 of 2000 took 0.097s
  training loss:		0.278076
  validation loss:		0.366646
  validation accuracy:		89.57 %
Epoch 1998 of 2000 took 0.097s
  training loss:		0.278234
  validation loss:		0.358073
  validation accuracy:		89.57 %
Epoch 1999 of 2000 took 0.097s
  training loss:		0.275639
  validation loss:		0.367144
  validation accuracy:		88.80 %
Epoch 2000 of 2000 took 0.097s
  training loss:		0.277049
  validation loss:		0.373986
  validation accuracy:		88.59 %
Final results:
  test loss:			0.723778
  test accuracy:		80.78 %
