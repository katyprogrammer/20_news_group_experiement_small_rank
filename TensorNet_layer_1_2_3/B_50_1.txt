Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(200, 150),b=(150,)
w=(150, 100),b=(100,)
w=(100, 50),b=(50,)
decomposing tensor W of shape (3, 200, 150)...
decomposing tensor B of shape (3, 150)...
Starting training...
Epoch 1 of 2000 took 0.099s
  training loss:		2.985752
  validation loss:		2.957444
  validation accuracy:		8.48 %
Epoch 2 of 2000 took 0.096s
  training loss:		2.946714
  validation loss:		2.898991
  validation accuracy:		11.96 %
Epoch 3 of 2000 took 0.099s
  training loss:		2.897590
  validation loss:		2.833127
  validation accuracy:		13.15 %
Epoch 4 of 2000 took 0.099s
  training loss:		2.842122
  validation loss:		2.762485
  validation accuracy:		13.37 %
Epoch 5 of 2000 took 0.099s
  training loss:		2.780051
  validation loss:		2.685321
  validation accuracy:		12.83 %
Epoch 6 of 2000 took 0.099s
  training loss:		2.714811
  validation loss:		2.603156
  validation accuracy:		12.83 %
Epoch 7 of 2000 took 0.099s
  training loss:		2.645636
  validation loss:		2.522415
  validation accuracy:		12.83 %
Epoch 8 of 2000 took 0.097s
  training loss:		2.574635
  validation loss:		2.446983
  validation accuracy:		12.83 %
Epoch 9 of 2000 took 0.096s
  training loss:		2.510543
  validation loss:		2.378978
  validation accuracy:		13.26 %
Epoch 10 of 2000 took 0.096s
  training loss:		2.448220
  validation loss:		2.321192
  validation accuracy:		13.91 %
Epoch 11 of 2000 took 0.095s
  training loss:		2.393807
  validation loss:		2.278040
  validation accuracy:		13.59 %
Epoch 12 of 2000 took 0.096s
  training loss:		2.354392
  validation loss:		2.251700
  validation accuracy:		13.15 %
Epoch 13 of 2000 took 0.096s
  training loss:		2.325087
  validation loss:		2.239511
  validation accuracy:		14.13 %
Epoch 14 of 2000 took 0.096s
  training loss:		2.306405
  validation loss:		2.232247
  validation accuracy:		13.48 %
Epoch 15 of 2000 took 0.096s
  training loss:		2.293177
  validation loss:		2.227093
  validation accuracy:		14.02 %
Epoch 16 of 2000 took 0.097s
  training loss:		2.282794
  validation loss:		2.219325
  validation accuracy:		13.80 %
Epoch 17 of 2000 took 0.097s
  training loss:		2.277319
  validation loss:		2.210958
  validation accuracy:		13.70 %
Epoch 18 of 2000 took 0.097s
  training loss:		2.272767
  validation loss:		2.205827
  validation accuracy:		13.48 %
Epoch 19 of 2000 took 0.097s
  training loss:		2.268112
  validation loss:		2.209019
  validation accuracy:		13.70 %
Epoch 20 of 2000 took 0.097s
  training loss:		2.264751
  validation loss:		2.205038
  validation accuracy:		15.43 %
Epoch 21 of 2000 took 0.097s
  training loss:		2.259018
  validation loss:		2.199567
  validation accuracy:		14.13 %
Epoch 22 of 2000 took 0.097s
  training loss:		2.257084
  validation loss:		2.189570
  validation accuracy:		15.11 %
Epoch 23 of 2000 took 0.097s
  training loss:		2.251738
  validation loss:		2.190172
  validation accuracy:		15.11 %
Epoch 24 of 2000 took 0.097s
  training loss:		2.248042
  validation loss:		2.191780
  validation accuracy:		16.30 %
Epoch 25 of 2000 took 0.097s
  training loss:		2.242373
  validation loss:		2.178723
  validation accuracy:		16.09 %
Epoch 26 of 2000 took 0.097s
  training loss:		2.238995
  validation loss:		2.173745
  validation accuracy:		15.11 %
Epoch 27 of 2000 took 0.096s
  training loss:		2.235837
  validation loss:		2.171307
  validation accuracy:		21.52 %
Epoch 28 of 2000 took 0.097s
  training loss:		2.226925
  validation loss:		2.160633
  validation accuracy:		17.83 %
Epoch 29 of 2000 took 0.097s
  training loss:		2.222431
  validation loss:		2.153651
  validation accuracy:		17.50 %
Epoch 30 of 2000 took 0.097s
  training loss:		2.214010
  validation loss:		2.150011
  validation accuracy:		21.20 %
Epoch 31 of 2000 took 0.097s
  training loss:		2.207362
  validation loss:		2.133855
  validation accuracy:		23.26 %
Epoch 32 of 2000 took 0.097s
  training loss:		2.200511
  validation loss:		2.136608
  validation accuracy:		22.17 %
Epoch 33 of 2000 took 0.097s
  training loss:		2.188083
  validation loss:		2.122635
  validation accuracy:		25.00 %
Epoch 34 of 2000 took 0.097s
  training loss:		2.179853
  validation loss:		2.100959
  validation accuracy:		28.15 %
Epoch 35 of 2000 took 0.097s
  training loss:		2.165792
  validation loss:		2.088750
  validation accuracy:		28.04 %
Epoch 36 of 2000 took 0.097s
  training loss:		2.151055
  validation loss:		2.075374
  validation accuracy:		28.48 %
Epoch 37 of 2000 took 0.097s
  training loss:		2.134930
  validation loss:		2.058763
  validation accuracy:		30.98 %
Epoch 38 of 2000 took 0.097s
  training loss:		2.117724
  validation loss:		2.033189
  validation accuracy:		32.28 %
Epoch 39 of 2000 took 0.097s
  training loss:		2.100612
  validation loss:		2.013637
  validation accuracy:		31.41 %
Epoch 40 of 2000 took 0.097s
  training loss:		2.077531
  validation loss:		1.994910
  validation accuracy:		34.67 %
Epoch 41 of 2000 took 0.097s
  training loss:		2.050824
  validation loss:		1.964097
  validation accuracy:		31.74 %
Epoch 42 of 2000 took 0.097s
  training loss:		2.028696
  validation loss:		1.935891
  validation accuracy:		34.46 %
Epoch 43 of 2000 took 0.097s
  training loss:		2.004611
  validation loss:		1.907898
  validation accuracy:		34.57 %
Epoch 44 of 2000 took 0.097s
  training loss:		1.973840
  validation loss:		1.881644
  validation accuracy:		35.33 %
Epoch 45 of 2000 took 0.097s
  training loss:		1.952619
  validation loss:		1.853737
  validation accuracy:		35.76 %
Epoch 46 of 2000 took 0.097s
  training loss:		1.918764
  validation loss:		1.829205
  validation accuracy:		38.59 %
Epoch 47 of 2000 took 0.097s
  training loss:		1.890437
  validation loss:		1.787292
  validation accuracy:		35.87 %
Epoch 48 of 2000 took 0.097s
  training loss:		1.865500
  validation loss:		1.758258
  validation accuracy:		39.67 %
Epoch 49 of 2000 took 0.097s
  training loss:		1.838397
  validation loss:		1.734799
  validation accuracy:		40.65 %
Epoch 50 of 2000 took 0.097s
  training loss:		1.809307
  validation loss:		1.710160
  validation accuracy:		42.83 %
Epoch 51 of 2000 took 0.097s
  training loss:		1.785373
  validation loss:		1.687911
  validation accuracy:		42.50 %
Epoch 52 of 2000 took 0.097s
  training loss:		1.764088
  validation loss:		1.657994
  validation accuracy:		42.39 %
Epoch 53 of 2000 took 0.097s
  training loss:		1.741238
  validation loss:		1.645156
  validation accuracy:		43.04 %
Epoch 54 of 2000 took 0.097s
  training loss:		1.725638
  validation loss:		1.623958
  validation accuracy:		45.22 %
Epoch 55 of 2000 took 0.097s
  training loss:		1.703766
  validation loss:		1.602672
  validation accuracy:		45.33 %
Epoch 56 of 2000 took 0.097s
  training loss:		1.682885
  validation loss:		1.576874
  validation accuracy:		46.63 %
Epoch 57 of 2000 took 0.097s
  training loss:		1.662551
  validation loss:		1.567256
  validation accuracy:		46.63 %
Epoch 58 of 2000 took 0.097s
  training loss:		1.647282
  validation loss:		1.553296
  validation accuracy:		46.74 %
Epoch 59 of 2000 took 0.097s
  training loss:		1.627289
  validation loss:		1.533175
  validation accuracy:		48.91 %
Epoch 60 of 2000 took 0.097s
  training loss:		1.612936
  validation loss:		1.524431
  validation accuracy:		47.28 %
Epoch 61 of 2000 took 0.097s
  training loss:		1.602273
  validation loss:		1.494598
  validation accuracy:		47.93 %
Epoch 62 of 2000 took 0.097s
  training loss:		1.575917
  validation loss:		1.487803
  validation accuracy:		49.78 %
Epoch 63 of 2000 took 0.097s
  training loss:		1.567534
  validation loss:		1.470184
  validation accuracy:		49.02 %
Epoch 64 of 2000 took 0.097s
  training loss:		1.552311
  validation loss:		1.473320
  validation accuracy:		50.11 %
Epoch 65 of 2000 took 0.097s
  training loss:		1.542032
  validation loss:		1.447274
  validation accuracy:		50.11 %
Epoch 66 of 2000 took 0.097s
  training loss:		1.519566
  validation loss:		1.430197
  validation accuracy:		50.33 %
Epoch 67 of 2000 took 0.097s
  training loss:		1.508248
  validation loss:		1.408063
  validation accuracy:		52.28 %
Epoch 68 of 2000 took 0.097s
  training loss:		1.495178
  validation loss:		1.397154
  validation accuracy:		51.09 %
Epoch 69 of 2000 took 0.097s
  training loss:		1.486420
  validation loss:		1.380922
  validation accuracy:		53.48 %
Epoch 70 of 2000 took 0.097s
  training loss:		1.465245
  validation loss:		1.381334
  validation accuracy:		54.78 %
Epoch 71 of 2000 took 0.097s
  training loss:		1.448498
  validation loss:		1.364015
  validation accuracy:		53.59 %
Epoch 72 of 2000 took 0.097s
  training loss:		1.431973
  validation loss:		1.338711
  validation accuracy:		54.89 %
Epoch 73 of 2000 took 0.097s
  training loss:		1.418396
  validation loss:		1.338318
  validation accuracy:		55.98 %
Epoch 74 of 2000 took 0.097s
  training loss:		1.405528
  validation loss:		1.307166
  validation accuracy:		56.41 %
Epoch 75 of 2000 took 0.097s
  training loss:		1.387802
  validation loss:		1.304982
  validation accuracy:		56.96 %
Epoch 76 of 2000 took 0.097s
  training loss:		1.374874
  validation loss:		1.285390
  validation accuracy:		57.28 %
Epoch 77 of 2000 took 0.097s
  training loss:		1.355596
  validation loss:		1.274139
  validation accuracy:		58.59 %
Epoch 78 of 2000 took 0.097s
  training loss:		1.341207
  validation loss:		1.250251
  validation accuracy:		58.48 %
Epoch 79 of 2000 took 0.097s
  training loss:		1.326570
  validation loss:		1.239654
  validation accuracy:		59.78 %
Epoch 80 of 2000 took 0.097s
  training loss:		1.309691
  validation loss:		1.223606
  validation accuracy:		60.54 %
Epoch 81 of 2000 took 0.097s
  training loss:		1.298458
  validation loss:		1.209202
  validation accuracy:		60.87 %
Epoch 82 of 2000 took 0.097s
  training loss:		1.281485
  validation loss:		1.199211
  validation accuracy:		61.52 %
Epoch 83 of 2000 took 0.097s
  training loss:		1.263928
  validation loss:		1.183971
  validation accuracy:		61.41 %
Epoch 84 of 2000 took 0.097s
  training loss:		1.245109
  validation loss:		1.168574
  validation accuracy:		62.39 %
Epoch 85 of 2000 took 0.097s
  training loss:		1.225929
  validation loss:		1.150709
  validation accuracy:		62.61 %
Epoch 86 of 2000 took 0.097s
  training loss:		1.210917
  validation loss:		1.146085
  validation accuracy:		62.50 %
Epoch 87 of 2000 took 0.097s
  training loss:		1.195431
  validation loss:		1.114995
  validation accuracy:		63.91 %
Epoch 88 of 2000 took 0.097s
  training loss:		1.169711
  validation loss:		1.086341
  validation accuracy:		64.35 %
Epoch 89 of 2000 took 0.097s
  training loss:		1.160845
  validation loss:		1.088869
  validation accuracy:		63.70 %
Epoch 90 of 2000 took 0.097s
  training loss:		1.139131
  validation loss:		1.087861
  validation accuracy:		64.78 %
Epoch 91 of 2000 took 0.097s
  training loss:		1.120456
  validation loss:		1.049814
  validation accuracy:		64.89 %
Epoch 92 of 2000 took 0.097s
  training loss:		1.106254
  validation loss:		1.029917
  validation accuracy:		65.87 %
Epoch 93 of 2000 took 0.097s
  training loss:		1.091629
  validation loss:		1.023223
  validation accuracy:		65.54 %
Epoch 94 of 2000 took 0.097s
  training loss:		1.068508
  validation loss:		1.022083
  validation accuracy:		65.22 %
Epoch 95 of 2000 took 0.097s
  training loss:		1.057085
  validation loss:		0.989783
  validation accuracy:		67.17 %
Epoch 96 of 2000 took 0.097s
  training loss:		1.039972
  validation loss:		0.965579
  validation accuracy:		68.15 %
Epoch 97 of 2000 took 0.097s
  training loss:		1.034339
  validation loss:		0.965358
  validation accuracy:		67.83 %
Epoch 98 of 2000 took 0.097s
  training loss:		1.014527
  validation loss:		0.936879
  validation accuracy:		68.04 %
Epoch 99 of 2000 took 0.097s
  training loss:		0.996277
  validation loss:		0.936601
  validation accuracy:		68.59 %
Epoch 100 of 2000 took 0.097s
  training loss:		0.984347
  validation loss:		0.919993
  validation accuracy:		69.02 %
Epoch 101 of 2000 took 0.100s
  training loss:		0.964361
  validation loss:		0.903818
  validation accuracy:		69.57 %
Epoch 102 of 2000 took 0.100s
  training loss:		0.967662
  validation loss:		0.892278
  validation accuracy:		69.89 %
Epoch 103 of 2000 took 0.100s
  training loss:		0.952225
  validation loss:		0.920064
  validation accuracy:		69.89 %
Epoch 104 of 2000 took 0.100s
  training loss:		0.935669
  validation loss:		0.872055
  validation accuracy:		70.43 %
Epoch 105 of 2000 took 0.100s
  training loss:		0.922244
  validation loss:		0.871863
  validation accuracy:		70.98 %
Epoch 106 of 2000 took 0.100s
  training loss:		0.921360
  validation loss:		0.898278
  validation accuracy:		71.09 %
Epoch 107 of 2000 took 0.100s
  training loss:		0.912601
  validation loss:		0.856679
  validation accuracy:		71.41 %
Epoch 108 of 2000 took 0.100s
  training loss:		0.897082
  validation loss:		0.832963
  validation accuracy:		72.28 %
Epoch 109 of 2000 took 0.098s
  training loss:		0.890818
  validation loss:		0.826188
  validation accuracy:		71.96 %
Epoch 110 of 2000 took 0.097s
  training loss:		0.890539
  validation loss:		0.819573
  validation accuracy:		72.39 %
Epoch 111 of 2000 took 0.097s
  training loss:		0.877947
  validation loss:		0.824541
  validation accuracy:		72.28 %
Epoch 112 of 2000 took 0.097s
  training loss:		0.878271
  validation loss:		0.793960
  validation accuracy:		72.72 %
Epoch 113 of 2000 took 0.097s
  training loss:		0.861075
  validation loss:		0.806178
  validation accuracy:		72.61 %
Epoch 114 of 2000 took 0.097s
  training loss:		0.854514
  validation loss:		0.807818
  validation accuracy:		73.15 %
Epoch 115 of 2000 took 0.097s
  training loss:		0.841987
  validation loss:		0.786514
  validation accuracy:		72.93 %
Epoch 116 of 2000 took 0.097s
  training loss:		0.842248
  validation loss:		0.789554
  validation accuracy:		73.37 %
Epoch 117 of 2000 took 0.097s
  training loss:		0.834624
  validation loss:		0.793157
  validation accuracy:		73.59 %
Epoch 118 of 2000 took 0.097s
  training loss:		0.831535
  validation loss:		0.794539
  validation accuracy:		73.59 %
Epoch 119 of 2000 took 0.097s
  training loss:		0.828475
  validation loss:		0.753134
  validation accuracy:		74.24 %
Epoch 120 of 2000 took 0.097s
  training loss:		0.811864
  validation loss:		0.752049
  validation accuracy:		73.91 %
Epoch 121 of 2000 took 0.097s
  training loss:		0.807598
  validation loss:		0.739920
  validation accuracy:		74.57 %
Epoch 122 of 2000 took 0.097s
  training loss:		0.803348
  validation loss:		0.730233
  validation accuracy:		74.57 %
Epoch 123 of 2000 took 0.097s
  training loss:		0.804687
  validation loss:		0.742570
  validation accuracy:		74.13 %
Epoch 124 of 2000 took 0.097s
  training loss:		0.795009
  validation loss:		0.783398
  validation accuracy:		74.57 %
Epoch 125 of 2000 took 0.097s
  training loss:		0.786236
  validation loss:		0.731806
  validation accuracy:		76.63 %
Epoch 126 of 2000 took 0.097s
  training loss:		0.784719
  validation loss:		0.715871
  validation accuracy:		75.54 %
Epoch 127 of 2000 took 0.097s
  training loss:		0.776112
  validation loss:		0.706640
  validation accuracy:		76.41 %
Epoch 128 of 2000 took 0.097s
  training loss:		0.766420
  validation loss:		0.703361
  validation accuracy:		75.43 %
Epoch 129 of 2000 took 0.097s
  training loss:		0.754979
  validation loss:		0.704593
  validation accuracy:		77.07 %
Epoch 130 of 2000 took 0.097s
  training loss:		0.754691
  validation loss:		0.697004
  validation accuracy:		76.96 %
Epoch 131 of 2000 took 0.097s
  training loss:		0.749357
  validation loss:		0.680778
  validation accuracy:		76.96 %
Epoch 132 of 2000 took 0.097s
  training loss:		0.742957
  validation loss:		0.712365
  validation accuracy:		75.98 %
Epoch 133 of 2000 took 0.097s
  training loss:		0.742468
  validation loss:		0.673542
  validation accuracy:		77.93 %
Epoch 134 of 2000 took 0.097s
  training loss:		0.731117
  validation loss:		0.668054
  validation accuracy:		77.50 %
Epoch 135 of 2000 took 0.097s
  training loss:		0.723749
  validation loss:		0.667361
  validation accuracy:		78.15 %
Epoch 136 of 2000 took 0.097s
  training loss:		0.723187
  validation loss:		0.661724
  validation accuracy:		78.15 %
Epoch 137 of 2000 took 0.097s
  training loss:		0.713141
  validation loss:		0.660380
  validation accuracy:		78.59 %
Epoch 138 of 2000 took 0.097s
  training loss:		0.707849
  validation loss:		0.649276
  validation accuracy:		78.37 %
Epoch 139 of 2000 took 0.097s
  training loss:		0.704448
  validation loss:		0.655363
  validation accuracy:		78.91 %
Epoch 140 of 2000 took 0.098s
  training loss:		0.708156
  validation loss:		0.637799
  validation accuracy:		78.91 %
Epoch 141 of 2000 took 0.097s
  training loss:		0.691827
  validation loss:		0.634243
  validation accuracy:		79.67 %
Epoch 142 of 2000 took 0.097s
  training loss:		0.690575
  validation loss:		0.633466
  validation accuracy:		79.78 %
Epoch 143 of 2000 took 0.097s
  training loss:		0.688729
  validation loss:		0.633876
  validation accuracy:		79.57 %
Epoch 144 of 2000 took 0.097s
  training loss:		0.686675
  validation loss:		0.628415
  validation accuracy:		79.67 %
Epoch 145 of 2000 took 0.097s
  training loss:		0.676198
  validation loss:		0.610205
  validation accuracy:		80.00 %
Epoch 146 of 2000 took 0.097s
  training loss:		0.670845
  validation loss:		0.633402
  validation accuracy:		79.24 %
Epoch 147 of 2000 took 0.097s
  training loss:		0.673397
  validation loss:		0.608634
  validation accuracy:		80.11 %
Epoch 148 of 2000 took 0.097s
  training loss:		0.654170
  validation loss:		0.594208
  validation accuracy:		80.65 %
Epoch 149 of 2000 took 0.097s
  training loss:		0.653937
  validation loss:		0.592374
  validation accuracy:		80.54 %
Epoch 150 of 2000 took 0.097s
  training loss:		0.646998
  validation loss:		0.609660
  validation accuracy:		80.11 %
Epoch 151 of 2000 took 0.097s
  training loss:		0.642971
  validation loss:		0.573647
  validation accuracy:		81.09 %
Epoch 152 of 2000 took 0.097s
  training loss:		0.637739
  validation loss:		0.589400
  validation accuracy:		80.54 %
Epoch 153 of 2000 took 0.097s
  training loss:		0.620465
  validation loss:		0.575687
  validation accuracy:		81.20 %
Epoch 154 of 2000 took 0.097s
  training loss:		0.621808
  validation loss:		0.564615
  validation accuracy:		81.85 %
Epoch 155 of 2000 took 0.097s
  training loss:		0.615816
  validation loss:		0.578887
  validation accuracy:		80.65 %
Epoch 156 of 2000 took 0.097s
  training loss:		0.617751
  validation loss:		0.552309
  validation accuracy:		81.96 %
Epoch 157 of 2000 took 0.097s
  training loss:		0.608733
  validation loss:		0.546123
  validation accuracy:		81.74 %
Epoch 158 of 2000 took 0.097s
  training loss:		0.605414
  validation loss:		0.546694
  validation accuracy:		81.52 %
Epoch 159 of 2000 took 0.097s
  training loss:		0.598493
  validation loss:		0.551384
  validation accuracy:		82.07 %
Epoch 160 of 2000 took 0.097s
  training loss:		0.589509
  validation loss:		0.526087
  validation accuracy:		82.61 %
Epoch 161 of 2000 took 0.097s
  training loss:		0.578897
  validation loss:		0.516781
  validation accuracy:		83.37 %
Epoch 162 of 2000 took 0.097s
  training loss:		0.577519
  validation loss:		0.530075
  validation accuracy:		82.72 %
Epoch 163 of 2000 took 0.097s
  training loss:		0.569244
  validation loss:		0.513161
  validation accuracy:		83.15 %
Epoch 164 of 2000 took 0.097s
  training loss:		0.558236
  validation loss:		0.537977
  validation accuracy:		82.50 %
Epoch 165 of 2000 took 0.097s
  training loss:		0.570614
  validation loss:		0.511545
  validation accuracy:		83.70 %
Epoch 166 of 2000 took 0.097s
  training loss:		0.551442
  validation loss:		0.503975
  validation accuracy:		84.13 %
Epoch 167 of 2000 took 0.097s
  training loss:		0.541147
  validation loss:		0.510481
  validation accuracy:		83.37 %
Epoch 168 of 2000 took 0.097s
  training loss:		0.539214
  validation loss:		0.488883
  validation accuracy:		84.02 %
Epoch 169 of 2000 took 0.097s
  training loss:		0.537424
  validation loss:		0.473868
  validation accuracy:		85.33 %
Epoch 170 of 2000 took 0.097s
  training loss:		0.530019
  validation loss:		0.479608
  validation accuracy:		84.78 %
Epoch 171 of 2000 took 0.098s
  training loss:		0.524644
  validation loss:		0.497647
  validation accuracy:		83.59 %
Epoch 172 of 2000 took 0.097s
  training loss:		0.522064
  validation loss:		0.474770
  validation accuracy:		84.57 %
Epoch 173 of 2000 took 0.097s
  training loss:		0.520953
  validation loss:		0.492174
  validation accuracy:		84.02 %
Epoch 174 of 2000 took 0.097s
  training loss:		0.509032
  validation loss:		0.488411
  validation accuracy:		83.91 %
Epoch 175 of 2000 took 0.097s
  training loss:		0.505453
  validation loss:		0.462555
  validation accuracy:		85.98 %
Epoch 176 of 2000 took 0.097s
  training loss:		0.497833
  validation loss:		0.498493
  validation accuracy:		83.59 %
Epoch 177 of 2000 took 0.097s
  training loss:		0.495048
  validation loss:		0.462283
  validation accuracy:		84.89 %
Epoch 178 of 2000 took 0.097s
  training loss:		0.483258
  validation loss:		0.446345
  validation accuracy:		86.30 %
Epoch 179 of 2000 took 0.097s
  training loss:		0.481948
  validation loss:		0.446914
  validation accuracy:		86.20 %
Epoch 180 of 2000 took 0.097s
  training loss:		0.483004
  validation loss:		0.442157
  validation accuracy:		86.30 %
Epoch 181 of 2000 took 0.097s
  training loss:		0.473778
  validation loss:		0.432844
  validation accuracy:		86.74 %
Epoch 182 of 2000 took 0.097s
  training loss:		0.475347
  validation loss:		0.434970
  validation accuracy:		86.41 %
Epoch 183 of 2000 took 0.097s
  training loss:		0.471781
  validation loss:		0.448458
  validation accuracy:		85.98 %
Epoch 184 of 2000 took 0.097s
  training loss:		0.472764
  validation loss:		0.447322
  validation accuracy:		85.76 %
Epoch 185 of 2000 took 0.097s
  training loss:		0.464870
  validation loss:		0.418594
  validation accuracy:		87.07 %
Epoch 186 of 2000 took 0.097s
  training loss:		0.462846
  validation loss:		0.436810
  validation accuracy:		85.98 %
Epoch 187 of 2000 took 0.097s
  training loss:		0.458990
  validation loss:		0.418902
  validation accuracy:		86.52 %
Epoch 188 of 2000 took 0.097s
  training loss:		0.458088
  validation loss:		0.420687
  validation accuracy:		86.96 %
Epoch 189 of 2000 took 0.097s
  training loss:		0.451802
  validation loss:		0.437316
  validation accuracy:		86.30 %
Epoch 190 of 2000 took 0.097s
  training loss:		0.452311
  validation loss:		0.428371
  validation accuracy:		86.85 %
Epoch 191 of 2000 took 0.097s
  training loss:		0.442131
  validation loss:		0.408414
  validation accuracy:		87.07 %
Epoch 192 of 2000 took 0.097s
  training loss:		0.444027
  validation loss:		0.399998
  validation accuracy:		87.72 %
Epoch 193 of 2000 took 0.097s
  training loss:		0.435111
  validation loss:		0.396948
  validation accuracy:		87.50 %
Epoch 194 of 2000 took 0.097s
  training loss:		0.435679
  validation loss:		0.417368
  validation accuracy:		86.85 %
Epoch 195 of 2000 took 0.097s
  training loss:		0.433975
  validation loss:		0.420210
  validation accuracy:		86.96 %
Epoch 196 of 2000 took 0.097s
  training loss:		0.435862
  validation loss:		0.399046
  validation accuracy:		87.28 %
Epoch 197 of 2000 took 0.097s
  training loss:		0.431252
  validation loss:		0.396320
  validation accuracy:		87.17 %
Epoch 198 of 2000 took 0.097s
  training loss:		0.424674
  validation loss:		0.385751
  validation accuracy:		87.61 %
Epoch 199 of 2000 took 0.097s
  training loss:		0.423370
  validation loss:		0.395041
  validation accuracy:		87.50 %
Epoch 200 of 2000 took 0.097s
  training loss:		0.416188
  validation loss:		0.392035
  validation accuracy:		87.39 %
Epoch 201 of 2000 took 0.097s
  training loss:		0.423464
  validation loss:		0.384165
  validation accuracy:		87.61 %
Epoch 202 of 2000 took 0.097s
  training loss:		0.415607
  validation loss:		0.388956
  validation accuracy:		87.72 %
Epoch 203 of 2000 took 0.097s
  training loss:		0.414516
  validation loss:		0.392374
  validation accuracy:		87.61 %
Epoch 204 of 2000 took 0.097s
  training loss:		0.417145
  validation loss:		0.380513
  validation accuracy:		87.83 %
Epoch 205 of 2000 took 0.097s
  training loss:		0.406423
  validation loss:		0.379536
  validation accuracy:		87.72 %
Epoch 206 of 2000 took 0.097s
  training loss:		0.402455
  validation loss:		0.376064
  validation accuracy:		87.83 %
Epoch 207 of 2000 took 0.097s
  training loss:		0.406272
  validation loss:		0.382048
  validation accuracy:		88.15 %
Epoch 208 of 2000 took 0.097s
  training loss:		0.395384
  validation loss:		0.387624
  validation accuracy:		87.61 %
Epoch 209 of 2000 took 0.097s
  training loss:		0.403942
  validation loss:		0.365331
  validation accuracy:		88.37 %
Epoch 210 of 2000 took 0.097s
  training loss:		0.395705
  validation loss:		0.387507
  validation accuracy:		87.83 %
Epoch 211 of 2000 took 0.097s
  training loss:		0.398335
  validation loss:		0.379732
  validation accuracy:		87.83 %
Epoch 212 of 2000 took 0.097s
  training loss:		0.394694
  validation loss:		0.371536
  validation accuracy:		88.26 %
Epoch 213 of 2000 took 0.097s
  training loss:		0.395832
  validation loss:		0.377626
  validation accuracy:		87.83 %
Epoch 214 of 2000 took 0.101s
  training loss:		0.395183
  validation loss:		0.369211
  validation accuracy:		88.37 %
Epoch 215 of 2000 took 0.100s
  training loss:		0.392347
  validation loss:		0.356318
  validation accuracy:		88.59 %
Epoch 216 of 2000 took 0.100s
  training loss:		0.380283
  validation loss:		0.358480
  validation accuracy:		88.70 %
Epoch 217 of 2000 took 0.100s
  training loss:		0.388055
  validation loss:		0.359288
  validation accuracy:		88.70 %
Epoch 218 of 2000 took 0.100s
  training loss:		0.381822
  validation loss:		0.353654
  validation accuracy:		89.13 %
Epoch 219 of 2000 took 0.100s
  training loss:		0.375307
  validation loss:		0.353807
  validation accuracy:		88.59 %
Epoch 220 of 2000 took 0.100s
  training loss:		0.383588
  validation loss:		0.347721
  validation accuracy:		89.35 %
Epoch 221 of 2000 took 0.100s
  training loss:		0.388082
  validation loss:		0.371912
  validation accuracy:		88.59 %
Epoch 222 of 2000 took 0.100s
  training loss:		0.371193
  validation loss:		0.349952
  validation accuracy:		89.13 %
Epoch 223 of 2000 took 0.099s
  training loss:		0.377896
  validation loss:		0.344492
  validation accuracy:		89.24 %
Epoch 224 of 2000 took 0.097s
  training loss:		0.379645
  validation loss:		0.360938
  validation accuracy:		88.37 %
Epoch 225 of 2000 took 0.097s
  training loss:		0.381287
  validation loss:		0.353934
  validation accuracy:		89.24 %
Epoch 226 of 2000 took 0.097s
  training loss:		0.370066
  validation loss:		0.374832
  validation accuracy:		88.70 %
Epoch 227 of 2000 took 0.097s
  training loss:		0.365097
  validation loss:		0.353411
  validation accuracy:		88.70 %
Epoch 228 of 2000 took 0.097s
  training loss:		0.374704
  validation loss:		0.361400
  validation accuracy:		88.37 %
Epoch 229 of 2000 took 0.097s
  training loss:		0.370177
  validation loss:		0.345818
  validation accuracy:		89.13 %
Epoch 230 of 2000 took 0.097s
  training loss:		0.368223
  validation loss:		0.364727
  validation accuracy:		88.04 %
Epoch 231 of 2000 took 0.097s
  training loss:		0.368900
  validation loss:		0.344666
  validation accuracy:		89.13 %
Epoch 232 of 2000 took 0.097s
  training loss:		0.366975
  validation loss:		0.349014
  validation accuracy:		88.48 %
Epoch 233 of 2000 took 0.097s
  training loss:		0.363894
  validation loss:		0.339745
  validation accuracy:		89.46 %
Epoch 234 of 2000 took 0.097s
  training loss:		0.365486
  validation loss:		0.343799
  validation accuracy:		89.35 %
Epoch 235 of 2000 took 0.097s
  training loss:		0.360509
  validation loss:		0.349289
  validation accuracy:		89.02 %
Epoch 236 of 2000 took 0.097s
  training loss:		0.360226
  validation loss:		0.374009
  validation accuracy:		88.26 %
Epoch 237 of 2000 took 0.097s
  training loss:		0.364666
  validation loss:		0.344271
  validation accuracy:		88.80 %
Epoch 238 of 2000 took 0.097s
  training loss:		0.352575
  validation loss:		0.331916
  validation accuracy:		89.78 %
Epoch 239 of 2000 took 0.097s
  training loss:		0.360783
  validation loss:		0.336812
  validation accuracy:		89.35 %
Epoch 240 of 2000 took 0.097s
  training loss:		0.353456
  validation loss:		0.366018
  validation accuracy:		88.04 %
Epoch 241 of 2000 took 0.097s
  training loss:		0.361248
  validation loss:		0.329913
  validation accuracy:		89.89 %
Epoch 242 of 2000 took 0.097s
  training loss:		0.353159
  validation loss:		0.336900
  validation accuracy:		89.57 %
Epoch 243 of 2000 took 0.097s
  training loss:		0.351055
  validation loss:		0.354625
  validation accuracy:		88.15 %
Epoch 244 of 2000 took 0.097s
  training loss:		0.351108
  validation loss:		0.343698
  validation accuracy:		88.59 %
Epoch 245 of 2000 took 0.097s
  training loss:		0.350308
  validation loss:		0.339144
  validation accuracy:		89.24 %
Epoch 246 of 2000 took 0.097s
  training loss:		0.347316
  validation loss:		0.335490
  validation accuracy:		89.46 %
Epoch 247 of 2000 took 0.097s
  training loss:		0.350899
  validation loss:		0.343003
  validation accuracy:		88.91 %
Epoch 248 of 2000 took 0.097s
  training loss:		0.342208
  validation loss:		0.343287
  validation accuracy:		88.59 %
Epoch 249 of 2000 took 0.097s
  training loss:		0.346027
  validation loss:		0.328998
  validation accuracy:		89.57 %
Epoch 250 of 2000 took 0.097s
  training loss:		0.344876
  validation loss:		0.347328
  validation accuracy:		88.37 %
Epoch 251 of 2000 took 0.097s
  training loss:		0.345653
  validation loss:		0.332906
  validation accuracy:		89.24 %
Epoch 252 of 2000 took 0.097s
  training loss:		0.351202
  validation loss:		0.324024
  validation accuracy:		90.22 %
Epoch 253 of 2000 took 0.097s
  training loss:		0.346157
  validation loss:		0.338681
  validation accuracy:		89.78 %
Epoch 254 of 2000 took 0.097s
  training loss:		0.346893
  validation loss:		0.319157
  validation accuracy:		90.22 %
Epoch 255 of 2000 took 0.097s
  training loss:		0.340487
  validation loss:		0.324852
  validation accuracy:		89.89 %
Epoch 256 of 2000 took 0.097s
  training loss:		0.329621
  validation loss:		0.326858
  validation accuracy:		89.78 %
Epoch 257 of 2000 took 0.097s
  training loss:		0.332174
  validation loss:		0.324508
  validation accuracy:		90.87 %
Epoch 258 of 2000 took 0.097s
  training loss:		0.335728
  validation loss:		0.336366
  validation accuracy:		89.57 %
Epoch 259 of 2000 took 0.097s
  training loss:		0.332323
  validation loss:		0.335283
  validation accuracy:		90.33 %
Epoch 260 of 2000 took 0.097s
  training loss:		0.334942
  validation loss:		0.317627
  validation accuracy:		90.76 %
Epoch 261 of 2000 took 0.097s
  training loss:		0.337011
  validation loss:		0.330431
  validation accuracy:		89.46 %
Epoch 262 of 2000 took 0.097s
  training loss:		0.331719
  validation loss:		0.320906
  validation accuracy:		90.43 %
Epoch 263 of 2000 took 0.097s
  training loss:		0.333797
  validation loss:		0.341535
  validation accuracy:		89.13 %
Epoch 264 of 2000 took 0.098s
  training loss:		0.335094
  validation loss:		0.320622
  validation accuracy:		90.43 %
Epoch 265 of 2000 took 0.097s
  training loss:		0.333913
  validation loss:		0.315207
  validation accuracy:		90.54 %
Epoch 266 of 2000 took 0.097s
  training loss:		0.324398
  validation loss:		0.335853
  validation accuracy:		89.35 %
Epoch 267 of 2000 took 0.097s
  training loss:		0.333674
  validation loss:		0.319865
  validation accuracy:		90.43 %
Epoch 268 of 2000 took 0.097s
  training loss:		0.334116
  validation loss:		0.340385
  validation accuracy:		88.70 %
Epoch 269 of 2000 took 0.097s
  training loss:		0.325842
  validation loss:		0.329778
  validation accuracy:		89.35 %
Epoch 270 of 2000 took 0.097s
  training loss:		0.325276
  validation loss:		0.341015
  validation accuracy:		88.80 %
Epoch 271 of 2000 took 0.097s
  training loss:		0.330734
  validation loss:		0.318561
  validation accuracy:		90.33 %
Epoch 272 of 2000 took 0.097s
  training loss:		0.327766
  validation loss:		0.308859
  validation accuracy:		91.09 %
Epoch 273 of 2000 took 0.097s
  training loss:		0.323460
  validation loss:		0.319020
  validation accuracy:		90.33 %
Epoch 274 of 2000 took 0.097s
  training loss:		0.320553
  validation loss:		0.319093
  validation accuracy:		90.22 %
Epoch 275 of 2000 took 0.097s
  training loss:		0.320484
  validation loss:		0.315218
  validation accuracy:		90.76 %
Epoch 276 of 2000 took 0.097s
  training loss:		0.329707
  validation loss:		0.323004
  validation accuracy:		90.33 %
Epoch 277 of 2000 took 0.097s
  training loss:		0.319443
  validation loss:		0.317508
  validation accuracy:		90.43 %
Epoch 278 of 2000 took 0.097s
  training loss:		0.323315
  validation loss:		0.322828
  validation accuracy:		89.89 %
Epoch 279 of 2000 took 0.097s
  training loss:		0.321694
  validation loss:		0.308564
  validation accuracy:		91.20 %
Epoch 280 of 2000 took 0.097s
  training loss:		0.319862
  validation loss:		0.318831
  validation accuracy:		90.76 %
Epoch 281 of 2000 took 0.097s
  training loss:		0.323882
  validation loss:		0.327790
  validation accuracy:		89.46 %
Epoch 282 of 2000 took 0.097s
  training loss:		0.326230
  validation loss:		0.321954
  validation accuracy:		89.89 %
Epoch 283 of 2000 took 0.097s
  training loss:		0.314773
  validation loss:		0.330550
  validation accuracy:		89.78 %
Epoch 284 of 2000 took 0.097s
  training loss:		0.321097
  validation loss:		0.337902
  validation accuracy:		88.80 %
Epoch 285 of 2000 took 0.097s
  training loss:		0.323771
  validation loss:		0.321825
  validation accuracy:		90.33 %
Epoch 286 of 2000 took 0.097s
  training loss:		0.312431
  validation loss:		0.324604
  validation accuracy:		90.43 %
Epoch 287 of 2000 took 0.097s
  training loss:		0.314761
  validation loss:		0.329989
  validation accuracy:		90.33 %
Epoch 288 of 2000 took 0.097s
  training loss:		0.319437
  validation loss:		0.323722
  validation accuracy:		89.67 %
Epoch 289 of 2000 took 0.097s
  training loss:		0.313206
  validation loss:		0.306747
  validation accuracy:		90.98 %
Epoch 290 of 2000 took 0.097s
  training loss:		0.314576
  validation loss:		0.352859
  validation accuracy:		87.93 %
Epoch 291 of 2000 took 0.097s
  training loss:		0.315659
  validation loss:		0.316038
  validation accuracy:		90.33 %
Epoch 292 of 2000 took 0.097s
  training loss:		0.312718
  validation loss:		0.314103
  validation accuracy:		90.76 %
Epoch 293 of 2000 took 0.097s
  training loss:		0.310929
  validation loss:		0.308620
  validation accuracy:		91.41 %
Epoch 294 of 2000 took 0.097s
  training loss:		0.313782
  validation loss:		0.331608
  validation accuracy:		89.02 %
Epoch 295 of 2000 took 0.097s
  training loss:		0.312524
  validation loss:		0.333499
  validation accuracy:		89.02 %
Epoch 296 of 2000 took 0.097s
  training loss:		0.310268
  validation loss:		0.312612
  validation accuracy:		90.65 %
Epoch 297 of 2000 took 0.097s
  training loss:		0.307871
  validation loss:		0.328161
  validation accuracy:		90.00 %
Epoch 298 of 2000 took 0.097s
  training loss:		0.307149
  validation loss:		0.317833
  validation accuracy:		90.11 %
Epoch 299 of 2000 took 0.097s
  training loss:		0.309758
  validation loss:		0.312312
  validation accuracy:		90.65 %
Epoch 300 of 2000 took 0.097s
  training loss:		0.305181
  validation loss:		0.315815
  validation accuracy:		90.54 %
Epoch 301 of 2000 took 0.097s
  training loss:		0.300491
  validation loss:		0.335927
  validation accuracy:		89.35 %
Epoch 302 of 2000 took 0.097s
  training loss:		0.304728
  validation loss:		0.320015
  validation accuracy:		90.33 %
Epoch 303 of 2000 took 0.097s
  training loss:		0.307405
  validation loss:		0.318876
  validation accuracy:		90.11 %
Epoch 304 of 2000 took 0.097s
  training loss:		0.306036
  validation loss:		0.307150
  validation accuracy:		90.98 %
Epoch 305 of 2000 took 0.097s
  training loss:		0.306277
  validation loss:		0.300803
  validation accuracy:		91.20 %
Epoch 306 of 2000 took 0.097s
  training loss:		0.310795
  validation loss:		0.302955
  validation accuracy:		91.20 %
Epoch 307 of 2000 took 0.097s
  training loss:		0.299650
  validation loss:		0.316924
  validation accuracy:		90.43 %
Epoch 308 of 2000 took 0.097s
  training loss:		0.304418
  validation loss:		0.314602
  validation accuracy:		90.65 %
Epoch 309 of 2000 took 0.097s
  training loss:		0.306275
  validation loss:		0.316886
  validation accuracy:		90.00 %
Epoch 310 of 2000 took 0.097s
  training loss:		0.295778
  validation loss:		0.314246
  validation accuracy:		90.65 %
Epoch 311 of 2000 took 0.097s
  training loss:		0.301775
  validation loss:		0.303599
  validation accuracy:		91.09 %
Epoch 312 of 2000 took 0.097s
  training loss:		0.305397
  validation loss:		0.328989
  validation accuracy:		89.89 %
Epoch 313 of 2000 took 0.097s
  training loss:		0.300348
  validation loss:		0.309273
  validation accuracy:		91.20 %
Epoch 314 of 2000 took 0.097s
  training loss:		0.300064
  validation loss:		0.327337
  validation accuracy:		89.57 %
Epoch 315 of 2000 took 0.097s
  training loss:		0.305586
  validation loss:		0.313005
  validation accuracy:		90.98 %
Epoch 316 of 2000 took 0.097s
  training loss:		0.293137
  validation loss:		0.318512
  validation accuracy:		90.43 %
Epoch 317 of 2000 took 0.097s
  training loss:		0.293672
  validation loss:		0.312806
  validation accuracy:		90.43 %
Epoch 318 of 2000 took 0.097s
  training loss:		0.297377
  validation loss:		0.318111
  validation accuracy:		90.87 %
Epoch 319 of 2000 took 0.097s
  training loss:		0.296883
  validation loss:		0.314843
  validation accuracy:		90.22 %
Epoch 320 of 2000 took 0.097s
  training loss:		0.300399
  validation loss:		0.321009
  validation accuracy:		90.22 %
Epoch 321 of 2000 took 0.097s
  training loss:		0.298472
  validation loss:		0.316402
  validation accuracy:		90.11 %
Epoch 322 of 2000 took 0.097s
  training loss:		0.288679
  validation loss:		0.336065
  validation accuracy:		89.67 %
Epoch 323 of 2000 took 0.097s
  training loss:		0.300523
  validation loss:		0.320112
  validation accuracy:		89.78 %
Epoch 324 of 2000 took 0.097s
  training loss:		0.295665
  validation loss:		0.320871
  validation accuracy:		89.89 %
Epoch 325 of 2000 took 0.097s
  training loss:		0.297286
  validation loss:		0.318392
  validation accuracy:		90.22 %
Epoch 326 of 2000 took 0.097s
  training loss:		0.293612
  validation loss:		0.316548
  validation accuracy:		91.09 %
Epoch 327 of 2000 took 0.097s
  training loss:		0.288358
  validation loss:		0.312831
  validation accuracy:		90.33 %
Epoch 328 of 2000 took 0.097s
  training loss:		0.291158
  validation loss:		0.302840
  validation accuracy:		91.30 %
Epoch 329 of 2000 took 0.097s
  training loss:		0.295175
  validation loss:		0.306829
  validation accuracy:		90.54 %
Epoch 330 of 2000 took 0.097s
  training loss:		0.288664
  validation loss:		0.314294
  validation accuracy:		90.76 %
Epoch 331 of 2000 took 0.097s
  training loss:		0.292386
  validation loss:		0.313257
  validation accuracy:		90.87 %
Epoch 332 of 2000 took 0.097s
  training loss:		0.293342
  validation loss:		0.303842
  validation accuracy:		90.98 %
Epoch 333 of 2000 took 0.097s
  training loss:		0.291609
  validation loss:		0.310005
  validation accuracy:		90.43 %
Epoch 334 of 2000 took 0.097s
  training loss:		0.291074
  validation loss:		0.318945
  validation accuracy:		90.98 %
Epoch 335 of 2000 took 0.097s
  training loss:		0.295560
  validation loss:		0.312690
  validation accuracy:		91.20 %
Epoch 336 of 2000 took 0.097s
  training loss:		0.286328
  validation loss:		0.326880
  validation accuracy:		90.00 %
Epoch 337 of 2000 took 0.097s
  training loss:		0.289525
  validation loss:		0.309077
  validation accuracy:		91.30 %
Epoch 338 of 2000 took 0.097s
  training loss:		0.290404
  validation loss:		0.313351
  validation accuracy:		91.09 %
Epoch 339 of 2000 took 0.097s
  training loss:		0.286140
  validation loss:		0.301303
  validation accuracy:		91.09 %
Epoch 340 of 2000 took 0.097s
  training loss:		0.293326
  validation loss:		0.313334
  validation accuracy:		90.87 %
Epoch 341 of 2000 took 0.097s
  training loss:		0.290505
  validation loss:		0.297379
  validation accuracy:		91.41 %
Epoch 342 of 2000 took 0.097s
  training loss:		0.287762
  validation loss:		0.310888
  validation accuracy:		90.76 %
Epoch 343 of 2000 took 0.097s
  training loss:		0.287934
  validation loss:		0.315690
  validation accuracy:		90.65 %
Epoch 344 of 2000 took 0.097s
  training loss:		0.285407
  validation loss:		0.322298
  validation accuracy:		89.78 %
Epoch 345 of 2000 took 0.097s
  training loss:		0.283056
  validation loss:		0.305011
  validation accuracy:		90.98 %
Epoch 346 of 2000 took 0.097s
  training loss:		0.281886
  validation loss:		0.303635
  validation accuracy:		91.41 %
Epoch 347 of 2000 took 0.097s
  training loss:		0.286479
  validation loss:		0.312218
  validation accuracy:		91.09 %
Epoch 348 of 2000 took 0.097s
  training loss:		0.290517
  validation loss:		0.314211
  validation accuracy:		90.87 %
Epoch 349 of 2000 took 0.097s
  training loss:		0.290141
  validation loss:		0.326541
  validation accuracy:		90.22 %
Epoch 350 of 2000 took 0.097s
  training loss:		0.282928
  validation loss:		0.318136
  validation accuracy:		91.09 %
Epoch 351 of 2000 took 0.097s
  training loss:		0.286207
  validation loss:		0.298847
  validation accuracy:		91.52 %
Epoch 352 of 2000 took 0.097s
  training loss:		0.282075
  validation loss:		0.320034
  validation accuracy:		90.54 %
Epoch 353 of 2000 took 0.097s
  training loss:		0.283966
  validation loss:		0.299701
  validation accuracy:		91.20 %
Epoch 354 of 2000 took 0.097s
  training loss:		0.286301
  validation loss:		0.318256
  validation accuracy:		90.33 %
Epoch 355 of 2000 took 0.097s
  training loss:		0.276958
  validation loss:		0.317863
  validation accuracy:		90.54 %
Epoch 356 of 2000 took 0.097s
  training loss:		0.287635
  validation loss:		0.307512
  validation accuracy:		91.20 %
Epoch 357 of 2000 took 0.097s
  training loss:		0.286109
  validation loss:		0.331938
  validation accuracy:		89.24 %
Epoch 358 of 2000 took 0.097s
  training loss:		0.286834
  validation loss:		0.309211
  validation accuracy:		90.98 %
Epoch 359 of 2000 took 0.097s
  training loss:		0.286045
  validation loss:		0.302146
  validation accuracy:		91.30 %
Epoch 360 of 2000 took 0.097s
  training loss:		0.276537
  validation loss:		0.313500
  validation accuracy:		90.43 %
Epoch 361 of 2000 took 0.097s
  training loss:		0.280463
  validation loss:		0.297164
  validation accuracy:		91.63 %
Epoch 362 of 2000 took 0.097s
  training loss:		0.278074
  validation loss:		0.303897
  validation accuracy:		91.52 %
Epoch 363 of 2000 took 0.097s
  training loss:		0.282699
  validation loss:		0.302746
  validation accuracy:		91.74 %
Epoch 364 of 2000 took 0.097s
  training loss:		0.278081
  validation loss:		0.321952
  validation accuracy:		90.00 %
Epoch 365 of 2000 took 0.097s
  training loss:		0.280567
  validation loss:		0.308046
  validation accuracy:		91.09 %
Epoch 366 of 2000 took 0.097s
  training loss:		0.278357
  validation loss:		0.314194
  validation accuracy:		90.54 %
Epoch 367 of 2000 took 0.097s
  training loss:		0.282476
  validation loss:		0.310604
  validation accuracy:		90.76 %
Epoch 368 of 2000 took 0.100s
  training loss:		0.275902
  validation loss:		0.305459
  validation accuracy:		91.41 %
Epoch 369 of 2000 took 0.097s
  training loss:		0.285050
  validation loss:		0.305203
  validation accuracy:		91.09 %
Epoch 370 of 2000 took 0.097s
  training loss:		0.272731
  validation loss:		0.299870
  validation accuracy:		91.41 %
Epoch 371 of 2000 took 0.097s
  training loss:		0.279611
  validation loss:		0.317119
  validation accuracy:		90.33 %
Epoch 372 of 2000 took 0.097s
  training loss:		0.274981
  validation loss:		0.302661
  validation accuracy:		91.09 %
Epoch 373 of 2000 took 0.097s
  training loss:		0.276623
  validation loss:		0.316269
  validation accuracy:		91.09 %
Epoch 374 of 2000 took 0.097s
  training loss:		0.270348
  validation loss:		0.322428
  validation accuracy:		89.89 %
Epoch 375 of 2000 took 0.097s
  training loss:		0.281267
  validation loss:		0.302497
  validation accuracy:		91.52 %
Epoch 376 of 2000 took 0.097s
  training loss:		0.278254
  validation loss:		0.308318
  validation accuracy:		90.76 %
Epoch 377 of 2000 took 0.097s
  training loss:		0.276021
  validation loss:		0.317832
  validation accuracy:		90.54 %
Epoch 378 of 2000 took 0.097s
  training loss:		0.274057
  validation loss:		0.299543
  validation accuracy:		91.30 %
Epoch 379 of 2000 took 0.097s
  training loss:		0.275529
  validation loss:		0.316962
  validation accuracy:		90.65 %
Epoch 380 of 2000 took 0.097s
  training loss:		0.275603
  validation loss:		0.332262
  validation accuracy:		89.57 %
Epoch 381 of 2000 took 0.097s
  training loss:		0.264175
  validation loss:		0.321580
  validation accuracy:		90.65 %
Epoch 382 of 2000 took 0.096s
  training loss:		0.278675
  validation loss:		0.323616
  validation accuracy:		90.43 %
Epoch 383 of 2000 took 0.097s
  training loss:		0.272172
  validation loss:		0.345882
  validation accuracy:		89.89 %
Epoch 384 of 2000 took 0.097s
  training loss:		0.273380
  validation loss:		0.299084
  validation accuracy:		91.30 %
Epoch 385 of 2000 took 0.097s
  training loss:		0.273983
  validation loss:		0.303753
  validation accuracy:		91.30 %
Epoch 386 of 2000 took 0.097s
  training loss:		0.272761
  validation loss:		0.294243
  validation accuracy:		91.63 %
Epoch 387 of 2000 took 0.097s
  training loss:		0.272621
  validation loss:		0.310078
  validation accuracy:		91.20 %
Epoch 388 of 2000 took 0.097s
  training loss:		0.272816
  validation loss:		0.305176
  validation accuracy:		91.20 %
Epoch 389 of 2000 took 0.097s
  training loss:		0.269747
  validation loss:		0.301514
  validation accuracy:		91.85 %
Epoch 390 of 2000 took 0.097s
  training loss:		0.272974
  validation loss:		0.309387
  validation accuracy:		91.09 %
Epoch 391 of 2000 took 0.097s
  training loss:		0.269462
  validation loss:		0.318675
  validation accuracy:		90.65 %
Epoch 392 of 2000 took 0.097s
  training loss:		0.271470
  validation loss:		0.331255
  validation accuracy:		90.33 %
Epoch 393 of 2000 took 0.097s
  training loss:		0.271629
  validation loss:		0.304108
  validation accuracy:		91.74 %
Epoch 394 of 2000 took 0.097s
  training loss:		0.276662
  validation loss:		0.322839
  validation accuracy:		90.22 %
Epoch 395 of 2000 took 0.097s
  training loss:		0.272833
  validation loss:		0.315327
  validation accuracy:		90.87 %
Epoch 396 of 2000 took 0.097s
  training loss:		0.266542
  validation loss:		0.309748
  validation accuracy:		90.98 %
Epoch 397 of 2000 took 0.097s
  training loss:		0.270209
  validation loss:		0.301084
  validation accuracy:		91.96 %
Epoch 398 of 2000 took 0.097s
  training loss:		0.266880
  validation loss:		0.305892
  validation accuracy:		91.09 %
Epoch 399 of 2000 took 0.097s
  training loss:		0.268088
  validation loss:		0.319275
  validation accuracy:		90.76 %
Epoch 400 of 2000 took 0.097s
  training loss:		0.264397
  validation loss:		0.301745
  validation accuracy:		91.74 %
Epoch 401 of 2000 took 0.097s
  training loss:		0.272472
  validation loss:		0.300882
  validation accuracy:		91.52 %
Epoch 402 of 2000 took 0.097s
  training loss:		0.260363
  validation loss:		0.309617
  validation accuracy:		91.09 %
Epoch 403 of 2000 took 0.097s
  training loss:		0.270076
  validation loss:		0.326699
  validation accuracy:		90.33 %
Epoch 404 of 2000 took 0.097s
  training loss:		0.258206
  validation loss:		0.314883
  validation accuracy:		90.87 %
Epoch 405 of 2000 took 0.097s
  training loss:		0.264420
  validation loss:		0.307113
  validation accuracy:		90.98 %
Epoch 406 of 2000 took 0.097s
  training loss:		0.265482
  validation loss:		0.312755
  validation accuracy:		91.09 %
Epoch 407 of 2000 took 0.097s
  training loss:		0.260259
  validation loss:		0.313383
  validation accuracy:		90.76 %
Epoch 408 of 2000 took 0.097s
  training loss:		0.270949
  validation loss:		0.301642
  validation accuracy:		91.74 %
Epoch 409 of 2000 took 0.097s
  training loss:		0.271598
  validation loss:		0.313714
  validation accuracy:		90.98 %
Epoch 410 of 2000 took 0.097s
  training loss:		0.271476
  validation loss:		0.317193
  validation accuracy:		90.76 %
Epoch 411 of 2000 took 0.097s
  training loss:		0.269423
  validation loss:		0.305155
  validation accuracy:		91.63 %
Epoch 412 of 2000 took 0.097s
  training loss:		0.270526
  validation loss:		0.321415
  validation accuracy:		90.33 %
Epoch 413 of 2000 took 0.097s
  training loss:		0.265547
  validation loss:		0.300109
  validation accuracy:		91.41 %
Epoch 414 of 2000 took 0.097s
  training loss:		0.263476
  validation loss:		0.325022
  validation accuracy:		90.65 %
Epoch 415 of 2000 took 0.097s
  training loss:		0.262825
  validation loss:		0.310158
  validation accuracy:		91.41 %
Epoch 416 of 2000 took 0.097s
  training loss:		0.265513
  validation loss:		0.299944
  validation accuracy:		91.41 %
Epoch 417 of 2000 took 0.097s
  training loss:		0.265696
  validation loss:		0.306395
  validation accuracy:		91.52 %
Epoch 418 of 2000 took 0.097s
  training loss:		0.268306
  validation loss:		0.311446
  validation accuracy:		90.98 %
Epoch 419 of 2000 took 0.097s
  training loss:		0.263676
  validation loss:		0.301243
  validation accuracy:		91.41 %
Epoch 420 of 2000 took 0.097s
  training loss:		0.261867
  validation loss:		0.297125
  validation accuracy:		92.07 %
Epoch 421 of 2000 took 0.097s
  training loss:		0.270602
  validation loss:		0.302193
  validation accuracy:		91.41 %
Epoch 422 of 2000 took 0.097s
  training loss:		0.259492
  validation loss:		0.298021
  validation accuracy:		91.74 %
Epoch 423 of 2000 took 0.097s
  training loss:		0.261896
  validation loss:		0.305941
  validation accuracy:		91.30 %
Epoch 424 of 2000 took 0.097s
  training loss:		0.259974
  validation loss:		0.300612
  validation accuracy:		91.52 %
Epoch 425 of 2000 took 0.097s
  training loss:		0.259508
  validation loss:		0.309073
  validation accuracy:		91.20 %
Epoch 426 of 2000 took 0.097s
  training loss:		0.259341
  validation loss:		0.308362
  validation accuracy:		91.63 %
Epoch 427 of 2000 took 0.097s
  training loss:		0.260194
  validation loss:		0.314862
  validation accuracy:		90.65 %
Epoch 428 of 2000 took 0.097s
  training loss:		0.259496
  validation loss:		0.310798
  validation accuracy:		91.20 %
Epoch 429 of 2000 took 0.097s
  training loss:		0.264780
  validation loss:		0.295565
  validation accuracy:		91.74 %
Epoch 430 of 2000 took 0.097s
  training loss:		0.262563
  validation loss:		0.301087
  validation accuracy:		91.63 %
Epoch 431 of 2000 took 0.097s
  training loss:		0.256203
  validation loss:		0.301116
  validation accuracy:		91.41 %
Epoch 432 of 2000 took 0.097s
  training loss:		0.259081
  validation loss:		0.296611
  validation accuracy:		91.63 %
Epoch 433 of 2000 took 0.097s
  training loss:		0.254910
  validation loss:		0.329096
  validation accuracy:		90.11 %
Epoch 434 of 2000 took 0.097s
  training loss:		0.256817
  validation loss:		0.307607
  validation accuracy:		91.20 %
Epoch 435 of 2000 took 0.097s
  training loss:		0.256319
  validation loss:		0.308379
  validation accuracy:		91.52 %
Epoch 436 of 2000 took 0.097s
  training loss:		0.260148
  validation loss:		0.304554
  validation accuracy:		91.74 %
Epoch 437 of 2000 took 0.097s
  training loss:		0.262849
  validation loss:		0.303558
  validation accuracy:		91.52 %
Epoch 438 of 2000 took 0.097s
  training loss:		0.256149
  validation loss:		0.326991
  validation accuracy:		90.43 %
Epoch 439 of 2000 took 0.097s
  training loss:		0.255711
  validation loss:		0.324393
  validation accuracy:		90.65 %
Epoch 440 of 2000 took 0.097s
  training loss:		0.257023
  validation loss:		0.328903
  validation accuracy:		90.76 %
Epoch 441 of 2000 took 0.097s
  training loss:		0.257952
  validation loss:		0.311861
  validation accuracy:		91.41 %
Epoch 442 of 2000 took 0.097s
  training loss:		0.258288
  validation loss:		0.313016
  validation accuracy:		91.41 %
Epoch 443 of 2000 took 0.097s
  training loss:		0.258406
  validation loss:		0.312306
  validation accuracy:		91.30 %
Epoch 444 of 2000 took 0.097s
  training loss:		0.255772
  validation loss:		0.309569
  validation accuracy:		91.30 %
Epoch 445 of 2000 took 0.097s
  training loss:		0.261174
  validation loss:		0.304959
  validation accuracy:		91.20 %
Epoch 446 of 2000 took 0.097s
  training loss:		0.256101
  validation loss:		0.311243
  validation accuracy:		91.20 %
Epoch 447 of 2000 took 0.097s
  training loss:		0.253992
  validation loss:		0.319788
  validation accuracy:		90.76 %
Epoch 448 of 2000 took 0.097s
  training loss:		0.257761
  validation loss:		0.300164
  validation accuracy:		91.85 %
Epoch 449 of 2000 took 0.097s
  training loss:		0.258398
  validation loss:		0.309386
  validation accuracy:		91.20 %
Epoch 450 of 2000 took 0.097s
  training loss:		0.258382
  validation loss:		0.303520
  validation accuracy:		91.52 %
Epoch 451 of 2000 took 0.097s
  training loss:		0.255731
  validation loss:		0.325896
  validation accuracy:		91.09 %
Epoch 452 of 2000 took 0.097s
  training loss:		0.252778
  validation loss:		0.321905
  validation accuracy:		90.87 %
Epoch 453 of 2000 took 0.097s
  training loss:		0.253973
  validation loss:		0.297111
  validation accuracy:		91.85 %
Epoch 454 of 2000 took 0.097s
  training loss:		0.258160
  validation loss:		0.310024
  validation accuracy:		91.09 %
Epoch 455 of 2000 took 0.097s
  training loss:		0.258470
  validation loss:		0.306749
  validation accuracy:		90.98 %
Epoch 456 of 2000 took 0.097s
  training loss:		0.248731
  validation loss:		0.304611
  validation accuracy:		91.30 %
Epoch 457 of 2000 took 0.097s
  training loss:		0.253908
  validation loss:		0.306951
  validation accuracy:		91.52 %
Epoch 458 of 2000 took 0.097s
  training loss:		0.252080
  validation loss:		0.306426
  validation accuracy:		91.41 %
Epoch 459 of 2000 took 0.097s
  training loss:		0.258393
  validation loss:		0.304480
  validation accuracy:		91.41 %
Epoch 460 of 2000 took 0.097s
  training loss:		0.254208
  validation loss:		0.321505
  validation accuracy:		90.54 %
Epoch 461 of 2000 took 0.097s
  training loss:		0.250837
  validation loss:		0.314831
  validation accuracy:		90.54 %
Epoch 462 of 2000 took 0.097s
  training loss:		0.250872
  validation loss:		0.302781
  validation accuracy:		91.20 %
Epoch 463 of 2000 took 0.097s
  training loss:		0.255893
  validation loss:		0.301017
  validation accuracy:		91.30 %
Epoch 464 of 2000 took 0.097s
  training loss:		0.253243
  validation loss:		0.300771
  validation accuracy:		91.41 %
Epoch 465 of 2000 took 0.097s
  training loss:		0.250273
  validation loss:		0.304312
  validation accuracy:		91.30 %
Epoch 466 of 2000 took 0.097s
  training loss:		0.247954
  validation loss:		0.304526
  validation accuracy:		91.41 %
Epoch 467 of 2000 took 0.097s
  training loss:		0.244907
  validation loss:		0.327644
  validation accuracy:		90.76 %
Epoch 468 of 2000 took 0.097s
  training loss:		0.263714
  validation loss:		0.303346
  validation accuracy:		91.52 %
Epoch 469 of 2000 took 0.097s
  training loss:		0.253794
  validation loss:		0.300123
  validation accuracy:		91.09 %
Epoch 470 of 2000 took 0.097s
  training loss:		0.251211
  validation loss:		0.312400
  validation accuracy:		91.20 %
Epoch 471 of 2000 took 0.099s
  training loss:		0.254708
  validation loss:		0.311218
  validation accuracy:		91.52 %
Epoch 472 of 2000 took 0.100s
  training loss:		0.254355
  validation loss:		0.310200
  validation accuracy:		90.98 %
Epoch 473 of 2000 took 0.100s
  training loss:		0.251284
  validation loss:		0.299140
  validation accuracy:		91.96 %
Epoch 474 of 2000 took 0.100s
  training loss:		0.248403
  validation loss:		0.308716
  validation accuracy:		91.09 %
Epoch 475 of 2000 took 0.100s
  training loss:		0.257383
  validation loss:		0.320702
  validation accuracy:		90.98 %
Epoch 476 of 2000 took 0.100s
  training loss:		0.249900
  validation loss:		0.304687
  validation accuracy:		91.30 %
Epoch 477 of 2000 took 0.100s
  training loss:		0.255941
  validation loss:		0.310296
  validation accuracy:		91.30 %
Epoch 478 of 2000 took 0.100s
  training loss:		0.251618
  validation loss:		0.314716
  validation accuracy:		91.20 %
Epoch 479 of 2000 took 0.100s
  training loss:		0.252202
  validation loss:		0.328927
  validation accuracy:		90.76 %
Epoch 480 of 2000 took 0.100s
  training loss:		0.246242
  validation loss:		0.311851
  validation accuracy:		91.30 %
Epoch 481 of 2000 took 0.100s
  training loss:		0.249480
  validation loss:		0.302790
  validation accuracy:		91.09 %
Epoch 482 of 2000 took 0.100s
  training loss:		0.246949
  validation loss:		0.304218
  validation accuracy:		91.30 %
Epoch 483 of 2000 took 0.100s
  training loss:		0.243898
  validation loss:		0.324311
  validation accuracy:		90.76 %
Epoch 484 of 2000 took 0.100s
  training loss:		0.250626
  validation loss:		0.309288
  validation accuracy:		91.20 %
Epoch 485 of 2000 took 0.100s
  training loss:		0.249635
  validation loss:		0.325772
  validation accuracy:		90.54 %
Epoch 486 of 2000 took 0.100s
  training loss:		0.248599
  validation loss:		0.306337
  validation accuracy:		91.41 %
Epoch 487 of 2000 took 0.100s
  training loss:		0.253563
  validation loss:		0.303580
  validation accuracy:		91.41 %
Epoch 488 of 2000 took 0.100s
  training loss:		0.246677
  validation loss:		0.306805
  validation accuracy:		91.41 %
Epoch 489 of 2000 took 0.100s
  training loss:		0.243689
  validation loss:		0.315886
  validation accuracy:		90.87 %
Epoch 490 of 2000 took 0.100s
  training loss:		0.247146
  validation loss:		0.312187
  validation accuracy:		91.52 %
Epoch 491 of 2000 took 0.100s
  training loss:		0.240612
  validation loss:		0.314598
  validation accuracy:		91.30 %
Epoch 492 of 2000 took 0.100s
  training loss:		0.248037
  validation loss:		0.312399
  validation accuracy:		90.76 %
Epoch 493 of 2000 took 0.100s
  training loss:		0.242206
  validation loss:		0.302344
  validation accuracy:		91.20 %
Epoch 494 of 2000 took 0.100s
  training loss:		0.250168
  validation loss:		0.308321
  validation accuracy:		90.98 %
Epoch 495 of 2000 took 0.100s
  training loss:		0.247224
  validation loss:		0.304242
  validation accuracy:		91.74 %
Epoch 496 of 2000 took 0.100s
  training loss:		0.250145
  validation loss:		0.302432
  validation accuracy:		91.96 %
Epoch 497 of 2000 took 0.100s
  training loss:		0.241832
  validation loss:		0.328914
  validation accuracy:		90.54 %
Epoch 498 of 2000 took 0.100s
  training loss:		0.250270
  validation loss:		0.303014
  validation accuracy:		92.07 %
Epoch 499 of 2000 took 0.100s
  training loss:		0.247224
  validation loss:		0.302658
  validation accuracy:		91.74 %
Epoch 500 of 2000 took 0.100s
  training loss:		0.245513
  validation loss:		0.310718
  validation accuracy:		91.41 %
Epoch 501 of 2000 took 0.100s
  training loss:		0.243028
  validation loss:		0.305315
  validation accuracy:		92.28 %
Epoch 502 of 2000 took 0.100s
  training loss:		0.250973
  validation loss:		0.310765
  validation accuracy:		91.63 %
Epoch 503 of 2000 took 0.100s
  training loss:		0.249576
  validation loss:		0.307016
  validation accuracy:		91.63 %
Epoch 504 of 2000 took 0.100s
  training loss:		0.240713
  validation loss:		0.314168
  validation accuracy:		91.30 %
Epoch 505 of 2000 took 0.100s
  training loss:		0.250988
  validation loss:		0.316926
  validation accuracy:		91.09 %
Epoch 506 of 2000 took 0.100s
  training loss:		0.246199
  validation loss:		0.308510
  validation accuracy:		92.17 %
Epoch 507 of 2000 took 0.100s
  training loss:		0.248052
  validation loss:		0.304283
  validation accuracy:		91.74 %
Epoch 508 of 2000 took 0.100s
  training loss:		0.245327
  validation loss:		0.315339
  validation accuracy:		91.41 %
Epoch 509 of 2000 took 0.100s
  training loss:		0.249763
  validation loss:		0.317499
  validation accuracy:		90.43 %
Epoch 510 of 2000 took 0.100s
  training loss:		0.245573
  validation loss:		0.298885
  validation accuracy:		92.28 %
Epoch 511 of 2000 took 0.098s
  training loss:		0.246437
  validation loss:		0.320377
  validation accuracy:		90.98 %
Epoch 512 of 2000 took 0.097s
  training loss:		0.241121
  validation loss:		0.309761
  validation accuracy:		91.41 %
Epoch 513 of 2000 took 0.097s
  training loss:		0.247941
  validation loss:		0.298234
  validation accuracy:		91.74 %
Epoch 514 of 2000 took 0.097s
  training loss:		0.240923
  validation loss:		0.299865
  validation accuracy:		92.07 %
Epoch 515 of 2000 took 0.097s
  training loss:		0.244650
  validation loss:		0.307128
  validation accuracy:		91.85 %
Epoch 516 of 2000 took 0.097s
  training loss:		0.241237
  validation loss:		0.310432
  validation accuracy:		91.63 %
Epoch 517 of 2000 took 0.097s
  training loss:		0.246821
  validation loss:		0.302594
  validation accuracy:		91.85 %
Epoch 518 of 2000 took 0.097s
  training loss:		0.247081
  validation loss:		0.303202
  validation accuracy:		91.52 %
Epoch 519 of 2000 took 0.097s
  training loss:		0.243510
  validation loss:		0.315773
  validation accuracy:		91.20 %
Epoch 520 of 2000 took 0.097s
  training loss:		0.236921
  validation loss:		0.324681
  validation accuracy:		90.76 %
Epoch 521 of 2000 took 0.097s
  training loss:		0.237200
  validation loss:		0.300843
  validation accuracy:		92.28 %
Epoch 522 of 2000 took 0.097s
  training loss:		0.238872
  validation loss:		0.306320
  validation accuracy:		91.09 %
Epoch 523 of 2000 took 0.097s
  training loss:		0.245002
  validation loss:		0.309419
  validation accuracy:		91.41 %
Epoch 524 of 2000 took 0.097s
  training loss:		0.242218
  validation loss:		0.309894
  validation accuracy:		91.52 %
Epoch 525 of 2000 took 0.097s
  training loss:		0.239584
  validation loss:		0.305232
  validation accuracy:		92.07 %
Epoch 526 of 2000 took 0.097s
  training loss:		0.239316
  validation loss:		0.313312
  validation accuracy:		91.96 %
Epoch 527 of 2000 took 0.097s
  training loss:		0.245804
  validation loss:		0.302204
  validation accuracy:		92.07 %
Epoch 528 of 2000 took 0.097s
  training loss:		0.237349
  validation loss:		0.301538
  validation accuracy:		91.63 %
Epoch 529 of 2000 took 0.097s
  training loss:		0.242828
  validation loss:		0.298919
  validation accuracy:		91.96 %
Epoch 530 of 2000 took 0.097s
  training loss:		0.240473
  validation loss:		0.305486
  validation accuracy:		91.96 %
Epoch 531 of 2000 took 0.097s
  training loss:		0.240724
  validation loss:		0.302757
  validation accuracy:		91.85 %
Epoch 532 of 2000 took 0.097s
  training loss:		0.244432
  validation loss:		0.312967
  validation accuracy:		91.09 %
Epoch 533 of 2000 took 0.097s
  training loss:		0.238393
  validation loss:		0.327481
  validation accuracy:		89.89 %
Epoch 534 of 2000 took 0.097s
  training loss:		0.240811
  validation loss:		0.314241
  validation accuracy:		90.65 %
Epoch 535 of 2000 took 0.097s
  training loss:		0.239562
  validation loss:		0.310073
  validation accuracy:		91.30 %
Epoch 536 of 2000 took 0.097s
  training loss:		0.236797
  validation loss:		0.316390
  validation accuracy:		90.65 %
Epoch 537 of 2000 took 0.097s
  training loss:		0.242920
  validation loss:		0.310801
  validation accuracy:		91.30 %
Epoch 538 of 2000 took 0.097s
  training loss:		0.237176
  validation loss:		0.321462
  validation accuracy:		90.11 %
Epoch 539 of 2000 took 0.097s
  training loss:		0.242213
  validation loss:		0.303892
  validation accuracy:		92.17 %
Epoch 540 of 2000 took 0.097s
  training loss:		0.235407
  validation loss:		0.301843
  validation accuracy:		91.85 %
Epoch 541 of 2000 took 0.097s
  training loss:		0.244079
  validation loss:		0.303886
  validation accuracy:		91.85 %
Epoch 542 of 2000 took 0.097s
  training loss:		0.243365
  validation loss:		0.314146
  validation accuracy:		91.41 %
Epoch 543 of 2000 took 0.097s
  training loss:		0.237225
  validation loss:		0.324467
  validation accuracy:		90.98 %
Epoch 544 of 2000 took 0.097s
  training loss:		0.239564
  validation loss:		0.300002
  validation accuracy:		91.85 %
Epoch 545 of 2000 took 0.097s
  training loss:		0.237376
  validation loss:		0.311271
  validation accuracy:		91.30 %
Epoch 546 of 2000 took 0.097s
  training loss:		0.233261
  validation loss:		0.302649
  validation accuracy:		91.41 %
Epoch 547 of 2000 took 0.097s
  training loss:		0.237596
  validation loss:		0.304572
  validation accuracy:		91.30 %
Epoch 548 of 2000 took 0.097s
  training loss:		0.233332
  validation loss:		0.316254
  validation accuracy:		90.33 %
Epoch 549 of 2000 took 0.097s
  training loss:		0.234864
  validation loss:		0.302574
  validation accuracy:		91.63 %
Epoch 550 of 2000 took 0.097s
  training loss:		0.237789
  validation loss:		0.315872
  validation accuracy:		90.98 %
Epoch 551 of 2000 took 0.097s
  training loss:		0.233130
  validation loss:		0.312356
  validation accuracy:		90.76 %
Epoch 552 of 2000 took 0.097s
  training loss:		0.237128
  validation loss:		0.309393
  validation accuracy:		91.30 %
Epoch 553 of 2000 took 0.097s
  training loss:		0.232420
  validation loss:		0.316985
  validation accuracy:		91.20 %
Epoch 554 of 2000 took 0.097s
  training loss:		0.235114
  validation loss:		0.308728
  validation accuracy:		91.52 %
Epoch 555 of 2000 took 0.097s
  training loss:		0.231896
  validation loss:		0.299335
  validation accuracy:		91.96 %
Epoch 556 of 2000 took 0.097s
  training loss:		0.232558
  validation loss:		0.324135
  validation accuracy:		91.09 %
Epoch 557 of 2000 took 0.097s
  training loss:		0.238805
  validation loss:		0.300290
  validation accuracy:		91.74 %
Epoch 558 of 2000 took 0.097s
  training loss:		0.231347
  validation loss:		0.308152
  validation accuracy:		91.96 %
Epoch 559 of 2000 took 0.097s
  training loss:		0.238725
  validation loss:		0.303844
  validation accuracy:		91.96 %
Epoch 560 of 2000 took 0.097s
  training loss:		0.239925
  validation loss:		0.304224
  validation accuracy:		91.96 %
Epoch 561 of 2000 took 0.097s
  training loss:		0.228711
  validation loss:		0.302900
  validation accuracy:		92.39 %
Epoch 562 of 2000 took 0.097s
  training loss:		0.237250
  validation loss:		0.303239
  validation accuracy:		92.28 %
Epoch 563 of 2000 took 0.097s
  training loss:		0.231706
  validation loss:		0.308703
  validation accuracy:		91.74 %
Epoch 564 of 2000 took 0.097s
  training loss:		0.238535
  validation loss:		0.306147
  validation accuracy:		91.20 %
Epoch 565 of 2000 took 0.097s
  training loss:		0.235909
  validation loss:		0.310312
  validation accuracy:		91.09 %
Epoch 566 of 2000 took 0.097s
  training loss:		0.232889
  validation loss:		0.337307
  validation accuracy:		90.43 %
Epoch 567 of 2000 took 0.097s
  training loss:		0.231598
  validation loss:		0.315419
  validation accuracy:		90.76 %
Epoch 568 of 2000 took 0.097s
  training loss:		0.237836
  validation loss:		0.315167
  validation accuracy:		91.52 %
Epoch 569 of 2000 took 0.097s
  training loss:		0.229770
  validation loss:		0.295812
  validation accuracy:		91.96 %
Epoch 570 of 2000 took 0.097s
  training loss:		0.232230
  validation loss:		0.326331
  validation accuracy:		90.54 %
Epoch 571 of 2000 took 0.097s
  training loss:		0.245154
  validation loss:		0.298979
  validation accuracy:		91.74 %
Epoch 572 of 2000 took 0.097s
  training loss:		0.235893
  validation loss:		0.310742
  validation accuracy:		91.63 %
Epoch 573 of 2000 took 0.097s
  training loss:		0.231644
  validation loss:		0.312124
  validation accuracy:		91.30 %
Epoch 574 of 2000 took 0.097s
  training loss:		0.228926
  validation loss:		0.310126
  validation accuracy:		91.52 %
Epoch 575 of 2000 took 0.097s
  training loss:		0.224095
  validation loss:		0.313960
  validation accuracy:		91.96 %
Epoch 576 of 2000 took 0.097s
  training loss:		0.233416
  validation loss:		0.299756
  validation accuracy:		92.39 %
Epoch 577 of 2000 took 0.097s
  training loss:		0.233215
  validation loss:		0.312910
  validation accuracy:		91.41 %
Epoch 578 of 2000 took 0.097s
  training loss:		0.225398
  validation loss:		0.315306
  validation accuracy:		91.20 %
Epoch 579 of 2000 took 0.097s
  training loss:		0.226167
  validation loss:		0.298268
  validation accuracy:		92.07 %
Epoch 580 of 2000 took 0.097s
  training loss:		0.229543
  validation loss:		0.308835
  validation accuracy:		91.85 %
Epoch 581 of 2000 took 0.097s
  training loss:		0.226475
  validation loss:		0.301906
  validation accuracy:		92.61 %
Epoch 582 of 2000 took 0.097s
  training loss:		0.231064
  validation loss:		0.309235
  validation accuracy:		91.96 %
Epoch 583 of 2000 took 0.097s
  training loss:		0.226923
  validation loss:		0.307817
  validation accuracy:		91.52 %
Epoch 584 of 2000 took 0.097s
  training loss:		0.233487
  validation loss:		0.325106
  validation accuracy:		90.76 %
Epoch 585 of 2000 took 0.097s
  training loss:		0.232206
  validation loss:		0.305265
  validation accuracy:		92.28 %
Epoch 586 of 2000 took 0.097s
  training loss:		0.238220
  validation loss:		0.337794
  validation accuracy:		90.00 %
Epoch 587 of 2000 took 0.097s
  training loss:		0.230632
  validation loss:		0.312373
  validation accuracy:		91.96 %
Epoch 588 of 2000 took 0.097s
  training loss:		0.230020
  validation loss:		0.304935
  validation accuracy:		92.17 %
Epoch 589 of 2000 took 0.097s
  training loss:		0.225187
  validation loss:		0.308533
  validation accuracy:		91.30 %
Epoch 590 of 2000 took 0.097s
  training loss:		0.231071
  validation loss:		0.302562
  validation accuracy:		91.96 %
Epoch 591 of 2000 took 0.097s
  training loss:		0.236068
  validation loss:		0.328104
  validation accuracy:		91.20 %
Epoch 592 of 2000 took 0.097s
  training loss:		0.236681
  validation loss:		0.312370
  validation accuracy:		91.85 %
Epoch 593 of 2000 took 0.097s
  training loss:		0.229813
  validation loss:		0.304441
  validation accuracy:		92.17 %
Epoch 594 of 2000 took 0.097s
  training loss:		0.235925
  validation loss:		0.311760
  validation accuracy:		91.85 %
Epoch 595 of 2000 took 0.097s
  training loss:		0.226869
  validation loss:		0.317732
  validation accuracy:		91.52 %
Epoch 596 of 2000 took 0.097s
  training loss:		0.224488
  validation loss:		0.312254
  validation accuracy:		91.52 %
Epoch 597 of 2000 took 0.097s
  training loss:		0.227939
  validation loss:		0.312207
  validation accuracy:		91.20 %
Epoch 598 of 2000 took 0.097s
  training loss:		0.224900
  validation loss:		0.302455
  validation accuracy:		92.50 %
Epoch 599 of 2000 took 0.097s
  training loss:		0.227122
  validation loss:		0.300460
  validation accuracy:		92.28 %
Epoch 600 of 2000 took 0.097s
  training loss:		0.228563
  validation loss:		0.308553
  validation accuracy:		91.09 %
Epoch 601 of 2000 took 0.097s
  training loss:		0.226692
  validation loss:		0.306273
  validation accuracy:		91.09 %
Epoch 602 of 2000 took 0.097s
  training loss:		0.231118
  validation loss:		0.306496
  validation accuracy:		91.52 %
Epoch 603 of 2000 took 0.097s
  training loss:		0.227003
  validation loss:		0.315010
  validation accuracy:		91.30 %
Epoch 604 of 2000 took 0.097s
  training loss:		0.228425
  validation loss:		0.314034
  validation accuracy:		91.63 %
Epoch 605 of 2000 took 0.097s
  training loss:		0.219102
  validation loss:		0.313564
  validation accuracy:		91.09 %
Epoch 606 of 2000 took 0.097s
  training loss:		0.225140
  validation loss:		0.308006
  validation accuracy:		91.96 %
Epoch 607 of 2000 took 0.097s
  training loss:		0.225329
  validation loss:		0.324005
  validation accuracy:		90.76 %
Epoch 608 of 2000 took 0.097s
  training loss:		0.226529
  validation loss:		0.305932
  validation accuracy:		91.63 %
Epoch 609 of 2000 took 0.097s
  training loss:		0.230049
  validation loss:		0.304937
  validation accuracy:		91.96 %
Epoch 610 of 2000 took 0.097s
  training loss:		0.224513
  validation loss:		0.305607
  validation accuracy:		91.41 %
Epoch 611 of 2000 took 0.097s
  training loss:		0.226163
  validation loss:		0.315192
  validation accuracy:		91.30 %
Epoch 612 of 2000 took 0.097s
  training loss:		0.222762
  validation loss:		0.309857
  validation accuracy:		91.30 %
Epoch 613 of 2000 took 0.097s
  training loss:		0.221365
  validation loss:		0.308934
  validation accuracy:		91.30 %
Epoch 614 of 2000 took 0.097s
  training loss:		0.222415
  validation loss:		0.306262
  validation accuracy:		91.52 %
Epoch 615 of 2000 took 0.097s
  training loss:		0.221820
  validation loss:		0.298297
  validation accuracy:		92.61 %
Epoch 616 of 2000 took 0.097s
  training loss:		0.220598
  validation loss:		0.302105
  validation accuracy:		91.63 %
Epoch 617 of 2000 took 0.097s
  training loss:		0.224978
  validation loss:		0.306756
  validation accuracy:		90.87 %
Epoch 618 of 2000 took 0.097s
  training loss:		0.224423
  validation loss:		0.302633
  validation accuracy:		92.28 %
Epoch 619 of 2000 took 0.097s
  training loss:		0.225958
  validation loss:		0.316355
  validation accuracy:		90.76 %
Epoch 620 of 2000 took 0.097s
  training loss:		0.228044
  validation loss:		0.308773
  validation accuracy:		91.85 %
Epoch 621 of 2000 took 0.097s
  training loss:		0.225124
  validation loss:		0.318775
  validation accuracy:		90.98 %
Epoch 622 of 2000 took 0.097s
  training loss:		0.222245
  validation loss:		0.304866
  validation accuracy:		92.17 %
Epoch 623 of 2000 took 0.097s
  training loss:		0.222992
  validation loss:		0.305852
  validation accuracy:		91.52 %
Epoch 624 of 2000 took 0.097s
  training loss:		0.219202
  validation loss:		0.299804
  validation accuracy:		92.93 %
Epoch 625 of 2000 took 0.097s
  training loss:		0.223526
  validation loss:		0.313107
  validation accuracy:		91.52 %
Epoch 626 of 2000 took 0.097s
  training loss:		0.223419
  validation loss:		0.308108
  validation accuracy:		91.30 %
Epoch 627 of 2000 took 0.097s
  training loss:		0.221981
  validation loss:		0.321391
  validation accuracy:		90.87 %
Epoch 628 of 2000 took 0.097s
  training loss:		0.223410
  validation loss:		0.311576
  validation accuracy:		91.63 %
Epoch 629 of 2000 took 0.097s
  training loss:		0.221990
  validation loss:		0.311356
  validation accuracy:		91.30 %
Epoch 630 of 2000 took 0.097s
  training loss:		0.225056
  validation loss:		0.306536
  validation accuracy:		92.39 %
Epoch 631 of 2000 took 0.097s
  training loss:		0.228045
  validation loss:		0.315076
  validation accuracy:		90.98 %
Epoch 632 of 2000 took 0.097s
  training loss:		0.220212
  validation loss:		0.299256
  validation accuracy:		92.39 %
Epoch 633 of 2000 took 0.097s
  training loss:		0.221797
  validation loss:		0.311402
  validation accuracy:		91.52 %
Epoch 634 of 2000 took 0.097s
  training loss:		0.219898
  validation loss:		0.323030
  validation accuracy:		91.20 %
Epoch 635 of 2000 took 0.097s
  training loss:		0.218696
  validation loss:		0.308551
  validation accuracy:		92.17 %
Epoch 636 of 2000 took 0.097s
  training loss:		0.221191
  validation loss:		0.322769
  validation accuracy:		90.65 %
Epoch 637 of 2000 took 0.097s
  training loss:		0.220020
  validation loss:		0.297825
  validation accuracy:		91.63 %
Epoch 638 of 2000 took 0.097s
  training loss:		0.222203
  validation loss:		0.314051
  validation accuracy:		91.63 %
Epoch 639 of 2000 took 0.097s
  training loss:		0.221491
  validation loss:		0.305017
  validation accuracy:		92.17 %
Epoch 640 of 2000 took 0.097s
  training loss:		0.223418
  validation loss:		0.303400
  validation accuracy:		91.85 %
Epoch 641 of 2000 took 0.097s
  training loss:		0.222182
  validation loss:		0.308495
  validation accuracy:		91.41 %
Epoch 642 of 2000 took 0.097s
  training loss:		0.219912
  validation loss:		0.306153
  validation accuracy:		91.30 %
Epoch 643 of 2000 took 0.097s
  training loss:		0.220947
  validation loss:		0.306127
  validation accuracy:		91.41 %
Epoch 644 of 2000 took 0.097s
  training loss:		0.223838
  validation loss:		0.304715
  validation accuracy:		92.61 %
Epoch 645 of 2000 took 0.097s
  training loss:		0.219181
  validation loss:		0.307664
  validation accuracy:		91.85 %
Epoch 646 of 2000 took 0.097s
  training loss:		0.221056
  validation loss:		0.299762
  validation accuracy:		92.17 %
Epoch 647 of 2000 took 0.097s
  training loss:		0.220247
  validation loss:		0.314897
  validation accuracy:		90.76 %
Epoch 648 of 2000 took 0.097s
  training loss:		0.214180
  validation loss:		0.306664
  validation accuracy:		91.41 %
Epoch 649 of 2000 took 0.097s
  training loss:		0.215979
  validation loss:		0.312565
  validation accuracy:		90.76 %
Epoch 650 of 2000 took 0.097s
  training loss:		0.223227
  validation loss:		0.319931
  validation accuracy:		91.20 %
Epoch 651 of 2000 took 0.097s
  training loss:		0.217061
  validation loss:		0.310726
  validation accuracy:		91.74 %
Epoch 652 of 2000 took 0.097s
  training loss:		0.220813
  validation loss:		0.308382
  validation accuracy:		92.61 %
Epoch 653 of 2000 took 0.097s
  training loss:		0.215649
  validation loss:		0.303834
  validation accuracy:		92.61 %
Epoch 654 of 2000 took 0.097s
  training loss:		0.221737
  validation loss:		0.322341
  validation accuracy:		91.20 %
Epoch 655 of 2000 took 0.097s
  training loss:		0.221993
  validation loss:		0.313187
  validation accuracy:		91.85 %
Epoch 656 of 2000 took 0.097s
  training loss:		0.217365
  validation loss:		0.302191
  validation accuracy:		92.17 %
Epoch 657 of 2000 took 0.097s
  training loss:		0.220620
  validation loss:		0.303501
  validation accuracy:		91.85 %
Epoch 658 of 2000 took 0.097s
  training loss:		0.220072
  validation loss:		0.306853
  validation accuracy:		92.28 %
Epoch 659 of 2000 took 0.097s
  training loss:		0.215279
  validation loss:		0.310021
  validation accuracy:		92.07 %
Epoch 660 of 2000 took 0.097s
  training loss:		0.209874
  validation loss:		0.308564
  validation accuracy:		91.85 %
Epoch 661 of 2000 took 0.097s
  training loss:		0.220333
  validation loss:		0.311103
  validation accuracy:		91.41 %
Epoch 662 of 2000 took 0.097s
  training loss:		0.213203
  validation loss:		0.303808
  validation accuracy:		91.63 %
Epoch 663 of 2000 took 0.097s
  training loss:		0.216970
  validation loss:		0.303126
  validation accuracy:		92.72 %
Epoch 664 of 2000 took 0.097s
  training loss:		0.218673
  validation loss:		0.311359
  validation accuracy:		91.74 %
Epoch 665 of 2000 took 0.097s
  training loss:		0.213863
  validation loss:		0.301140
  validation accuracy:		91.63 %
Epoch 666 of 2000 took 0.097s
  training loss:		0.214357
  validation loss:		0.310385
  validation accuracy:		91.74 %
Epoch 667 of 2000 took 0.097s
  training loss:		0.214525
  validation loss:		0.311163
  validation accuracy:		91.63 %
Epoch 668 of 2000 took 0.097s
  training loss:		0.214922
  validation loss:		0.302291
  validation accuracy:		92.39 %
Epoch 669 of 2000 took 0.097s
  training loss:		0.209459
  validation loss:		0.304833
  validation accuracy:		91.96 %
Epoch 670 of 2000 took 0.097s
  training loss:		0.213088
  validation loss:		0.316394
  validation accuracy:		91.09 %
Epoch 671 of 2000 took 0.097s
  training loss:		0.212181
  validation loss:		0.300626
  validation accuracy:		92.83 %
Epoch 672 of 2000 took 0.097s
  training loss:		0.217828
  validation loss:		0.314353
  validation accuracy:		91.41 %
Epoch 673 of 2000 took 0.097s
  training loss:		0.217382
  validation loss:		0.303741
  validation accuracy:		91.85 %
Epoch 674 of 2000 took 0.097s
  training loss:		0.218749
  validation loss:		0.318891
  validation accuracy:		91.41 %
Epoch 675 of 2000 took 0.097s
  training loss:		0.213715
  validation loss:		0.315153
  validation accuracy:		92.07 %
Epoch 676 of 2000 took 0.098s
  training loss:		0.215397
  validation loss:		0.318439
  validation accuracy:		92.07 %
Epoch 677 of 2000 took 0.100s
  training loss:		0.210169
  validation loss:		0.298929
  validation accuracy:		92.28 %
Epoch 678 of 2000 took 0.100s
  training loss:		0.214011
  validation loss:		0.312922
  validation accuracy:		91.85 %
Epoch 679 of 2000 took 0.100s
  training loss:		0.218060
  validation loss:		0.322583
  validation accuracy:		91.09 %
Epoch 680 of 2000 took 0.100s
  training loss:		0.215726
  validation loss:		0.314529
  validation accuracy:		92.39 %
Epoch 681 of 2000 took 0.100s
  training loss:		0.210630
  validation loss:		0.320940
  validation accuracy:		91.09 %
Epoch 682 of 2000 took 0.100s
  training loss:		0.211197
  validation loss:		0.315547
  validation accuracy:		92.39 %
Epoch 683 of 2000 took 0.100s
  training loss:		0.209482
  validation loss:		0.305729
  validation accuracy:		92.72 %
Epoch 684 of 2000 took 0.100s
  training loss:		0.217382
  validation loss:		0.304628
  validation accuracy:		92.39 %
Epoch 685 of 2000 took 0.100s
  training loss:		0.206775
  validation loss:		0.300023
  validation accuracy:		92.50 %
Epoch 686 of 2000 took 0.100s
  training loss:		0.208477
  validation loss:		0.303814
  validation accuracy:		92.39 %
Epoch 687 of 2000 took 0.100s
  training loss:		0.216692
  validation loss:		0.313020
  validation accuracy:		91.20 %
Epoch 688 of 2000 took 0.100s
  training loss:		0.209033
  validation loss:		0.307943
  validation accuracy:		92.61 %
Epoch 689 of 2000 took 0.100s
  training loss:		0.212207
  validation loss:		0.303189
  validation accuracy:		91.30 %
Epoch 690 of 2000 took 0.097s
  training loss:		0.219869
  validation loss:		0.310893
  validation accuracy:		92.39 %
Epoch 691 of 2000 took 0.097s
  training loss:		0.215811
  validation loss:		0.310800
  validation accuracy:		91.63 %
Epoch 692 of 2000 took 0.097s
  training loss:		0.215315
  validation loss:		0.299533
  validation accuracy:		91.96 %
Epoch 693 of 2000 took 0.097s
  training loss:		0.215998
  validation loss:		0.304653
  validation accuracy:		92.50 %
Epoch 694 of 2000 took 0.097s
  training loss:		0.208437
  validation loss:		0.308033
  validation accuracy:		91.74 %
Epoch 695 of 2000 took 0.097s
  training loss:		0.215511
  validation loss:		0.321568
  validation accuracy:		91.96 %
Epoch 696 of 2000 took 0.097s
  training loss:		0.215522
  validation loss:		0.313702
  validation accuracy:		92.39 %
Epoch 697 of 2000 took 0.097s
  training loss:		0.213089
  validation loss:		0.305495
  validation accuracy:		92.39 %
Epoch 698 of 2000 took 0.097s
  training loss:		0.207270
  validation loss:		0.323253
  validation accuracy:		91.74 %
Epoch 699 of 2000 took 0.097s
  training loss:		0.213941
  validation loss:		0.305116
  validation accuracy:		91.52 %
Epoch 700 of 2000 took 0.097s
  training loss:		0.209356
  validation loss:		0.325690
  validation accuracy:		90.76 %
Epoch 701 of 2000 took 0.097s
  training loss:		0.212043
  validation loss:		0.304672
  validation accuracy:		91.96 %
Epoch 702 of 2000 took 0.097s
  training loss:		0.216395
  validation loss:		0.303031
  validation accuracy:		92.07 %
Epoch 703 of 2000 took 0.097s
  training loss:		0.203824
  validation loss:		0.318419
  validation accuracy:		91.41 %
Epoch 704 of 2000 took 0.097s
  training loss:		0.206789
  validation loss:		0.326462
  validation accuracy:		91.30 %
Epoch 705 of 2000 took 0.097s
  training loss:		0.207816
  validation loss:		0.301573
  validation accuracy:		92.61 %
Epoch 706 of 2000 took 0.097s
  training loss:		0.213402
  validation loss:		0.316429
  validation accuracy:		92.39 %
Epoch 707 of 2000 took 0.097s
  training loss:		0.211476
  validation loss:		0.307425
  validation accuracy:		92.17 %
Epoch 708 of 2000 took 0.097s
  training loss:		0.204645
  validation loss:		0.305543
  validation accuracy:		92.39 %
Epoch 709 of 2000 took 0.097s
  training loss:		0.204990
  validation loss:		0.308056
  validation accuracy:		91.52 %
Epoch 710 of 2000 took 0.097s
  training loss:		0.202901
  validation loss:		0.318845
  validation accuracy:		91.52 %
Epoch 711 of 2000 took 0.097s
  training loss:		0.205652
  validation loss:		0.325562
  validation accuracy:		90.65 %
Epoch 712 of 2000 took 0.097s
  training loss:		0.203419
  validation loss:		0.312550
  validation accuracy:		91.63 %
Epoch 713 of 2000 took 0.097s
  training loss:		0.203752
  validation loss:		0.300502
  validation accuracy:		92.39 %
Epoch 714 of 2000 took 0.097s
  training loss:		0.210070
  validation loss:		0.329933
  validation accuracy:		90.87 %
Epoch 715 of 2000 took 0.097s
  training loss:		0.210105
  validation loss:		0.306157
  validation accuracy:		92.28 %
Epoch 716 of 2000 took 0.097s
  training loss:		0.204133
  validation loss:		0.305417
  validation accuracy:		92.61 %
Epoch 717 of 2000 took 0.097s
  training loss:		0.204407
  validation loss:		0.318055
  validation accuracy:		91.20 %
Epoch 718 of 2000 took 0.097s
  training loss:		0.209275
  validation loss:		0.325342
  validation accuracy:		90.87 %
Epoch 719 of 2000 took 0.097s
  training loss:		0.204106
  validation loss:		0.314869
  validation accuracy:		91.20 %
Epoch 720 of 2000 took 0.097s
  training loss:		0.204165
  validation loss:		0.314122
  validation accuracy:		91.85 %
Epoch 721 of 2000 took 0.097s
  training loss:		0.203068
  validation loss:		0.304064
  validation accuracy:		92.93 %
Epoch 722 of 2000 took 0.097s
  training loss:		0.201111
  validation loss:		0.306804
  validation accuracy:		91.63 %
Epoch 723 of 2000 took 0.097s
  training loss:		0.206545
  validation loss:		0.316963
  validation accuracy:		91.74 %
Epoch 724 of 2000 took 0.097s
  training loss:		0.207297
  validation loss:		0.322766
  validation accuracy:		91.52 %
Epoch 725 of 2000 took 0.097s
  training loss:		0.203236
  validation loss:		0.306434
  validation accuracy:		92.39 %
Epoch 726 of 2000 took 0.097s
  training loss:		0.207945
  validation loss:		0.307236
  validation accuracy:		91.30 %
Epoch 727 of 2000 took 0.097s
  training loss:		0.200484
  validation loss:		0.320827
  validation accuracy:		91.09 %
Epoch 728 of 2000 took 0.097s
  training loss:		0.199770
  validation loss:		0.310660
  validation accuracy:		91.96 %
Epoch 729 of 2000 took 0.097s
  training loss:		0.205309
  validation loss:		0.316478
  validation accuracy:		91.30 %
Epoch 730 of 2000 took 0.097s
  training loss:		0.204213
  validation loss:		0.312314
  validation accuracy:		91.74 %
Epoch 731 of 2000 took 0.097s
  training loss:		0.203880
  validation loss:		0.334794
  validation accuracy:		90.98 %
Epoch 732 of 2000 took 0.097s
  training loss:		0.201652
  validation loss:		0.314467
  validation accuracy:		91.74 %
Epoch 733 of 2000 took 0.097s
  training loss:		0.205832
  validation loss:		0.300988
  validation accuracy:		92.39 %
Epoch 734 of 2000 took 0.097s
  training loss:		0.199353
  validation loss:		0.309583
  validation accuracy:		91.52 %
Epoch 735 of 2000 took 0.097s
  training loss:		0.199355
  validation loss:		0.321061
  validation accuracy:		91.30 %
Epoch 736 of 2000 took 0.097s
  training loss:		0.201234
  validation loss:		0.310424
  validation accuracy:		91.74 %
Epoch 737 of 2000 took 0.097s
  training loss:		0.207733
  validation loss:		0.308404
  validation accuracy:		92.28 %
Epoch 738 of 2000 took 0.097s
  training loss:		0.206356
  validation loss:		0.321154
  validation accuracy:		90.87 %
Epoch 739 of 2000 took 0.097s
  training loss:		0.195681
  validation loss:		0.300820
  validation accuracy:		92.50 %
Epoch 740 of 2000 took 0.097s
  training loss:		0.202550
  validation loss:		0.307414
  validation accuracy:		91.96 %
Epoch 741 of 2000 took 0.097s
  training loss:		0.198896
  validation loss:		0.326725
  validation accuracy:		90.65 %
Epoch 742 of 2000 took 0.097s
  training loss:		0.200759
  validation loss:		0.305257
  validation accuracy:		91.96 %
Epoch 743 of 2000 took 0.097s
  training loss:		0.200125
  validation loss:		0.322360
  validation accuracy:		90.76 %
Epoch 744 of 2000 took 0.097s
  training loss:		0.200177
  validation loss:		0.308675
  validation accuracy:		92.07 %
Epoch 745 of 2000 took 0.097s
  training loss:		0.206181
  validation loss:		0.309674
  validation accuracy:		91.63 %
Epoch 746 of 2000 took 0.097s
  training loss:		0.200127
  validation loss:		0.311883
  validation accuracy:		91.85 %
Epoch 747 of 2000 took 0.097s
  training loss:		0.198817
  validation loss:		0.324015
  validation accuracy:		90.87 %
Epoch 748 of 2000 took 0.097s
  training loss:		0.202993
  validation loss:		0.316081
  validation accuracy:		91.85 %
Epoch 749 of 2000 took 0.097s
  training loss:		0.201883
  validation loss:		0.308415
  validation accuracy:		92.39 %
Epoch 750 of 2000 took 0.097s
  training loss:		0.203814
  validation loss:		0.304371
  validation accuracy:		91.96 %
Epoch 751 of 2000 took 0.097s
  training loss:		0.197125
  validation loss:		0.312991
  validation accuracy:		91.85 %
Epoch 752 of 2000 took 0.097s
  training loss:		0.197012
  validation loss:		0.306914
  validation accuracy:		92.17 %
Epoch 753 of 2000 took 0.097s
  training loss:		0.199292
  validation loss:		0.329711
  validation accuracy:		90.76 %
Epoch 754 of 2000 took 0.097s
  training loss:		0.201653
  validation loss:		0.324446
  validation accuracy:		91.30 %
Epoch 755 of 2000 took 0.097s
  training loss:		0.202601
  validation loss:		0.326045
  validation accuracy:		91.09 %
Epoch 756 of 2000 took 0.097s
  training loss:		0.199756
  validation loss:		0.318697
  validation accuracy:		92.50 %
Epoch 757 of 2000 took 0.097s
  training loss:		0.203336
  validation loss:		0.318174
  validation accuracy:		91.41 %
Epoch 758 of 2000 took 0.097s
  training loss:		0.195538
  validation loss:		0.319628
  validation accuracy:		91.52 %
Epoch 759 of 2000 took 0.097s
  training loss:		0.199104
  validation loss:		0.317356
  validation accuracy:		92.28 %
Epoch 760 of 2000 took 0.097s
  training loss:		0.201796
  validation loss:		0.307084
  validation accuracy:		91.74 %
Epoch 761 of 2000 took 0.097s
  training loss:		0.200555
  validation loss:		0.304484
  validation accuracy:		92.28 %
Epoch 762 of 2000 took 0.097s
  training loss:		0.204838
  validation loss:		0.313752
  validation accuracy:		91.74 %
Epoch 763 of 2000 took 0.097s
  training loss:		0.199246
  validation loss:		0.324327
  validation accuracy:		91.96 %
Epoch 764 of 2000 took 0.097s
  training loss:		0.198685
  validation loss:		0.302186
  validation accuracy:		92.07 %
Epoch 765 of 2000 took 0.097s
  training loss:		0.200590
  validation loss:		0.323461
  validation accuracy:		91.52 %
Epoch 766 of 2000 took 0.097s
  training loss:		0.193015
  validation loss:		0.312334
  validation accuracy:		91.41 %
Epoch 767 of 2000 took 0.097s
  training loss:		0.201484
  validation loss:		0.314391
  validation accuracy:		91.74 %
Epoch 768 of 2000 took 0.097s
  training loss:		0.193338
  validation loss:		0.313270
  validation accuracy:		91.63 %
Epoch 769 of 2000 took 0.097s
  training loss:		0.199011
  validation loss:		0.308530
  validation accuracy:		92.39 %
Epoch 770 of 2000 took 0.097s
  training loss:		0.200634
  validation loss:		0.319198
  validation accuracy:		91.96 %
Epoch 771 of 2000 took 0.097s
  training loss:		0.195348
  validation loss:		0.313766
  validation accuracy:		91.85 %
Epoch 772 of 2000 took 0.097s
  training loss:		0.198874
  validation loss:		0.318784
  validation accuracy:		91.85 %
Epoch 773 of 2000 took 0.097s
  training loss:		0.193813
  validation loss:		0.315855
  validation accuracy:		92.28 %
Epoch 774 of 2000 took 0.097s
  training loss:		0.199835
  validation loss:		0.315524
  validation accuracy:		91.63 %
Epoch 775 of 2000 took 0.097s
  training loss:		0.195280
  validation loss:		0.316772
  validation accuracy:		91.41 %
Epoch 776 of 2000 took 0.097s
  training loss:		0.196006
  validation loss:		0.323964
  validation accuracy:		91.63 %
Epoch 777 of 2000 took 0.097s
  training loss:		0.194543
  validation loss:		0.348949
  validation accuracy:		90.87 %
Epoch 778 of 2000 took 0.097s
  training loss:		0.198104
  validation loss:		0.310135
  validation accuracy:		92.39 %
Epoch 779 of 2000 took 0.097s
  training loss:		0.200086
  validation loss:		0.313399
  validation accuracy:		91.74 %
Epoch 780 of 2000 took 0.097s
  training loss:		0.197781
  validation loss:		0.317111
  validation accuracy:		92.28 %
Epoch 781 of 2000 took 0.097s
  training loss:		0.198470
  validation loss:		0.321351
  validation accuracy:		91.52 %
Epoch 782 of 2000 took 0.097s
  training loss:		0.194419
  validation loss:		0.322208
  validation accuracy:		91.85 %
Epoch 783 of 2000 took 0.097s
  training loss:		0.196292
  validation loss:		0.316293
  validation accuracy:		91.85 %
Epoch 784 of 2000 took 0.097s
  training loss:		0.195469
  validation loss:		0.305958
  validation accuracy:		92.28 %
Epoch 785 of 2000 took 0.097s
  training loss:		0.193476
  validation loss:		0.319828
  validation accuracy:		91.41 %
Epoch 786 of 2000 took 0.097s
  training loss:		0.195670
  validation loss:		0.306430
  validation accuracy:		92.50 %
Epoch 787 of 2000 took 0.097s
  training loss:		0.195592
  validation loss:		0.319158
  validation accuracy:		92.07 %
Epoch 788 of 2000 took 0.097s
  training loss:		0.197929
  validation loss:		0.305136
  validation accuracy:		91.96 %
Epoch 789 of 2000 took 0.097s
  training loss:		0.198107
  validation loss:		0.312850
  validation accuracy:		92.50 %
Epoch 790 of 2000 took 0.097s
  training loss:		0.198351
  validation loss:		0.320482
  validation accuracy:		91.96 %
Epoch 791 of 2000 took 0.097s
  training loss:		0.197874
  validation loss:		0.310989
  validation accuracy:		92.07 %
Epoch 792 of 2000 took 0.097s
  training loss:		0.195757
  validation loss:		0.323569
  validation accuracy:		91.41 %
Epoch 793 of 2000 took 0.097s
  training loss:		0.192818
  validation loss:		0.318481
  validation accuracy:		91.63 %
Epoch 794 of 2000 took 0.097s
  training loss:		0.191492
  validation loss:		0.320015
  validation accuracy:		91.96 %
Epoch 795 of 2000 took 0.097s
  training loss:		0.193115
  validation loss:		0.307897
  validation accuracy:		92.50 %
Epoch 796 of 2000 took 0.097s
  training loss:		0.194731
  validation loss:		0.311469
  validation accuracy:		92.07 %
Epoch 797 of 2000 took 0.097s
  training loss:		0.194682
  validation loss:		0.315540
  validation accuracy:		91.41 %
Epoch 798 of 2000 took 0.097s
  training loss:		0.190773
  validation loss:		0.308454
  validation accuracy:		92.07 %
Epoch 799 of 2000 took 0.097s
  training loss:		0.195826
  validation loss:		0.350740
  validation accuracy:		90.65 %
Epoch 800 of 2000 took 0.097s
  training loss:		0.197198
  validation loss:		0.311794
  validation accuracy:		91.52 %
Epoch 801 of 2000 took 0.097s
  training loss:		0.194970
  validation loss:		0.322328
  validation accuracy:		92.07 %
Epoch 802 of 2000 took 0.097s
  training loss:		0.193098
  validation loss:		0.311012
  validation accuracy:		92.50 %
Epoch 803 of 2000 took 0.097s
  training loss:		0.197372
  validation loss:		0.315386
  validation accuracy:		91.63 %
Epoch 804 of 2000 took 0.097s
  training loss:		0.193395
  validation loss:		0.322697
  validation accuracy:		92.28 %
Epoch 805 of 2000 took 0.097s
  training loss:		0.191603
  validation loss:		0.312422
  validation accuracy:		91.30 %
Epoch 806 of 2000 took 0.097s
  training loss:		0.191408
  validation loss:		0.326792
  validation accuracy:		91.20 %
Epoch 807 of 2000 took 0.097s
  training loss:		0.192677
  validation loss:		0.319017
  validation accuracy:		91.74 %
Epoch 808 of 2000 took 0.097s
  training loss:		0.185038
  validation loss:		0.324764
  validation accuracy:		91.74 %
Epoch 809 of 2000 took 0.097s
  training loss:		0.194633
  validation loss:		0.311675
  validation accuracy:		92.07 %
Epoch 810 of 2000 took 0.097s
  training loss:		0.190011
  validation loss:		0.317686
  validation accuracy:		91.96 %
Epoch 811 of 2000 took 0.097s
  training loss:		0.199291
  validation loss:		0.319864
  validation accuracy:		91.74 %
Epoch 812 of 2000 took 0.097s
  training loss:		0.186851
  validation loss:		0.326206
  validation accuracy:		91.41 %
Epoch 813 of 2000 took 0.097s
  training loss:		0.191522
  validation loss:		0.317277
  validation accuracy:		91.20 %
Epoch 814 of 2000 took 0.097s
  training loss:		0.189328
  validation loss:		0.323555
  validation accuracy:		91.74 %
Epoch 815 of 2000 took 0.097s
  training loss:		0.186114
  validation loss:		0.303993
  validation accuracy:		91.96 %
Epoch 816 of 2000 took 0.097s
  training loss:		0.192932
  validation loss:		0.312585
  validation accuracy:		91.96 %
Epoch 817 of 2000 took 0.097s
  training loss:		0.188208
  validation loss:		0.318221
  validation accuracy:		91.09 %
Epoch 818 of 2000 took 0.097s
  training loss:		0.193592
  validation loss:		0.336507
  validation accuracy:		91.30 %
Epoch 819 of 2000 took 0.097s
  training loss:		0.190209
  validation loss:		0.325424
  validation accuracy:		91.52 %
Epoch 820 of 2000 took 0.097s
  training loss:		0.191047
  validation loss:		0.315003
  validation accuracy:		91.96 %
Epoch 821 of 2000 took 0.097s
  training loss:		0.188254
  validation loss:		0.316242
  validation accuracy:		91.85 %
Epoch 822 of 2000 took 0.097s
  training loss:		0.189239
  validation loss:		0.322328
  validation accuracy:		91.09 %
Epoch 823 of 2000 took 0.097s
  training loss:		0.193560
  validation loss:		0.318626
  validation accuracy:		91.41 %
Epoch 824 of 2000 took 0.097s
  training loss:		0.189489
  validation loss:		0.314727
  validation accuracy:		92.17 %
Epoch 825 of 2000 took 0.097s
  training loss:		0.191587
  validation loss:		0.312011
  validation accuracy:		91.74 %
Epoch 826 of 2000 took 0.097s
  training loss:		0.191079
  validation loss:		0.307179
  validation accuracy:		92.07 %
Epoch 827 of 2000 took 0.097s
  training loss:		0.187725
  validation loss:		0.309903
  validation accuracy:		91.96 %
Epoch 828 of 2000 took 0.097s
  training loss:		0.186768
  validation loss:		0.318220
  validation accuracy:		91.74 %
Epoch 829 of 2000 took 0.097s
  training loss:		0.189996
  validation loss:		0.311061
  validation accuracy:		91.85 %
Epoch 830 of 2000 took 0.097s
  training loss:		0.184887
  validation loss:		0.323257
  validation accuracy:		91.52 %
Epoch 831 of 2000 took 0.099s
  training loss:		0.184060
  validation loss:		0.311988
  validation accuracy:		92.83 %
Epoch 832 of 2000 took 0.108s
  training loss:		0.192039
  validation loss:		0.315056
  validation accuracy:		91.74 %
Epoch 833 of 2000 took 0.115s
  training loss:		0.191828
  validation loss:		0.349977
  validation accuracy:		90.54 %
Epoch 834 of 2000 took 0.139s
  training loss:		0.192436
  validation loss:		0.314934
  validation accuracy:		91.74 %
Epoch 835 of 2000 took 0.106s
  training loss:		0.186660
  validation loss:		0.312479
  validation accuracy:		91.74 %
Epoch 836 of 2000 took 0.105s
  training loss:		0.190153
  validation loss:		0.336459
  validation accuracy:		91.30 %
Epoch 837 of 2000 took 0.106s
  training loss:		0.191739
  validation loss:		0.331945
  validation accuracy:		91.30 %
Epoch 838 of 2000 took 0.105s
  training loss:		0.185757
  validation loss:		0.309691
  validation accuracy:		92.17 %
Epoch 839 of 2000 took 0.102s
  training loss:		0.193024
  validation loss:		0.305741
  validation accuracy:		92.17 %
Epoch 840 of 2000 took 0.103s
  training loss:		0.189150
  validation loss:		0.328770
  validation accuracy:		91.74 %
Epoch 841 of 2000 took 0.101s
  training loss:		0.189051
  validation loss:		0.320063
  validation accuracy:		91.52 %
Epoch 842 of 2000 took 0.101s
  training loss:		0.190212
  validation loss:		0.323147
  validation accuracy:		91.30 %
Epoch 843 of 2000 took 0.101s
  training loss:		0.187957
  validation loss:		0.323445
  validation accuracy:		91.96 %
Epoch 844 of 2000 took 0.100s
  training loss:		0.188451
  validation loss:		0.324605
  validation accuracy:		90.98 %
Epoch 845 of 2000 took 0.101s
  training loss:		0.186884
  validation loss:		0.315440
  validation accuracy:		92.39 %
Epoch 846 of 2000 took 0.101s
  training loss:		0.185012
  validation loss:		0.307592
  validation accuracy:		91.85 %
Epoch 847 of 2000 took 0.101s
  training loss:		0.186566
  validation loss:		0.337079
  validation accuracy:		90.98 %
Epoch 848 of 2000 took 0.101s
  training loss:		0.189485
  validation loss:		0.323614
  validation accuracy:		91.63 %
Epoch 849 of 2000 took 0.100s
  training loss:		0.187838
  validation loss:		0.317016
  validation accuracy:		92.17 %
Epoch 850 of 2000 took 0.101s
  training loss:		0.184370
  validation loss:		0.322256
  validation accuracy:		92.07 %
Epoch 851 of 2000 took 0.101s
  training loss:		0.190861
  validation loss:		0.323680
  validation accuracy:		91.41 %
Epoch 852 of 2000 took 0.102s
  training loss:		0.182205
  validation loss:		0.322768
  validation accuracy:		91.41 %
Epoch 853 of 2000 took 0.101s
  training loss:		0.182436
  validation loss:		0.329702
  validation accuracy:		91.30 %
Epoch 854 of 2000 took 0.101s
  training loss:		0.182756
  validation loss:		0.313013
  validation accuracy:		91.96 %
Epoch 855 of 2000 took 0.101s
  training loss:		0.184164
  validation loss:		0.336289
  validation accuracy:		91.20 %
Epoch 856 of 2000 took 0.100s
  training loss:		0.179279
  validation loss:		0.325218
  validation accuracy:		91.20 %
Epoch 857 of 2000 took 0.101s
  training loss:		0.183496
  validation loss:		0.317817
  validation accuracy:		91.96 %
Epoch 858 of 2000 took 0.100s
  training loss:		0.182764
  validation loss:		0.320991
  validation accuracy:		91.85 %
Epoch 859 of 2000 took 0.101s
  training loss:		0.189757
  validation loss:		0.312318
  validation accuracy:		92.93 %
Epoch 860 of 2000 took 0.101s
  training loss:		0.178079
  validation loss:		0.321023
  validation accuracy:		91.63 %
Epoch 861 of 2000 took 0.101s
  training loss:		0.187366
  validation loss:		0.329068
  validation accuracy:		91.52 %
Epoch 862 of 2000 took 0.101s
  training loss:		0.181919
  validation loss:		0.331601
  validation accuracy:		91.41 %
Epoch 863 of 2000 took 0.101s
  training loss:		0.186918
  validation loss:		0.324808
  validation accuracy:		91.30 %
Epoch 864 of 2000 took 0.102s
  training loss:		0.184090
  validation loss:		0.339988
  validation accuracy:		91.74 %
Epoch 865 of 2000 took 0.101s
  training loss:		0.186646
  validation loss:		0.315846
  validation accuracy:		91.63 %
Epoch 866 of 2000 took 0.101s
  training loss:		0.183853
  validation loss:		0.331643
  validation accuracy:		91.41 %
Epoch 867 of 2000 took 0.101s
  training loss:		0.184538
  validation loss:		0.325618
  validation accuracy:		91.52 %
Epoch 868 of 2000 took 0.101s
  training loss:		0.185688
  validation loss:		0.322732
  validation accuracy:		91.41 %
Epoch 869 of 2000 took 0.100s
  training loss:		0.185587
  validation loss:		0.337106
  validation accuracy:		91.09 %
Epoch 870 of 2000 took 0.101s
  training loss:		0.187147
  validation loss:		0.313687
  validation accuracy:		92.17 %
Epoch 871 of 2000 took 0.101s
  training loss:		0.190819
  validation loss:		0.317084
  validation accuracy:		91.63 %
Epoch 872 of 2000 took 0.102s
  training loss:		0.180027
  validation loss:		0.317055
  validation accuracy:		92.07 %
Epoch 873 of 2000 took 0.101s
  training loss:		0.188033
  validation loss:		0.310918
  validation accuracy:		92.17 %
Epoch 874 of 2000 took 0.100s
  training loss:		0.179342
  validation loss:		0.325228
  validation accuracy:		91.74 %
Epoch 875 of 2000 took 0.100s
  training loss:		0.184665
  validation loss:		0.328654
  validation accuracy:		91.41 %
Epoch 876 of 2000 took 0.100s
  training loss:		0.182732
  validation loss:		0.318092
  validation accuracy:		92.07 %
Epoch 877 of 2000 took 0.100s
  training loss:		0.178908
  validation loss:		0.328418
  validation accuracy:		91.20 %
Epoch 878 of 2000 took 0.100s
  training loss:		0.185099
  validation loss:		0.331586
  validation accuracy:		91.09 %
Epoch 879 of 2000 took 0.099s
  training loss:		0.184982
  validation loss:		0.319131
  validation accuracy:		91.63 %
Epoch 880 of 2000 took 0.096s
  training loss:		0.177051
  validation loss:		0.318719
  validation accuracy:		92.17 %
Epoch 881 of 2000 took 0.099s
  training loss:		0.180466
  validation loss:		0.325972
  validation accuracy:		91.41 %
Epoch 882 of 2000 took 0.097s
  training loss:		0.183632
  validation loss:		0.324587
  validation accuracy:		92.28 %
Epoch 883 of 2000 took 0.103s
  training loss:		0.178225
  validation loss:		0.322407
  validation accuracy:		92.07 %
Epoch 884 of 2000 took 0.099s
  training loss:		0.178126
  validation loss:		0.313854
  validation accuracy:		92.28 %
Epoch 885 of 2000 took 0.096s
  training loss:		0.177722
  validation loss:		0.340243
  validation accuracy:		91.41 %
Epoch 886 of 2000 took 0.103s
  training loss:		0.180362
  validation loss:		0.331151
  validation accuracy:		91.30 %
Epoch 887 of 2000 took 0.099s
  training loss:		0.184154
  validation loss:		0.326976
  validation accuracy:		91.52 %
Epoch 888 of 2000 took 0.097s
  training loss:		0.182372
  validation loss:		0.328890
  validation accuracy:		91.96 %
Epoch 889 of 2000 took 0.097s
  training loss:		0.182760
  validation loss:		0.318968
  validation accuracy:		92.39 %
Epoch 890 of 2000 took 0.098s
  training loss:		0.185442
  validation loss:		0.321600
  validation accuracy:		91.74 %
Epoch 891 of 2000 took 0.103s
  training loss:		0.179573
  validation loss:		0.333667
  validation accuracy:		91.63 %
Epoch 892 of 2000 took 0.098s
  training loss:		0.179563
  validation loss:		0.320038
  validation accuracy:		92.17 %
Epoch 893 of 2000 took 0.097s
  training loss:		0.178742
  validation loss:		0.323035
  validation accuracy:		92.28 %
Epoch 894 of 2000 took 0.105s
  training loss:		0.181009
  validation loss:		0.319168
  validation accuracy:		91.74 %
Epoch 895 of 2000 took 0.096s
  training loss:		0.174858
  validation loss:		0.318616
  validation accuracy:		91.96 %
Epoch 896 of 2000 took 0.098s
  training loss:		0.181547
  validation loss:		0.348883
  validation accuracy:		91.41 %
Epoch 897 of 2000 took 0.096s
  training loss:		0.179240
  validation loss:		0.327098
  validation accuracy:		91.74 %
Epoch 898 of 2000 took 0.100s
  training loss:		0.177872
  validation loss:		0.326558
  validation accuracy:		91.74 %
Epoch 899 of 2000 took 0.101s
  training loss:		0.178725
  validation loss:		0.332968
  validation accuracy:		91.96 %
Epoch 900 of 2000 took 0.096s
  training loss:		0.180857
  validation loss:		0.346529
  validation accuracy:		91.63 %
Epoch 901 of 2000 took 0.103s
  training loss:		0.181561
  validation loss:		0.326435
  validation accuracy:		91.74 %
Epoch 902 of 2000 took 0.100s
  training loss:		0.178652
  validation loss:		0.326048
  validation accuracy:		92.28 %
Epoch 903 of 2000 took 0.099s
  training loss:		0.182410
  validation loss:		0.313669
  validation accuracy:		91.85 %
Epoch 904 of 2000 took 0.101s
  training loss:		0.176299
  validation loss:		0.319661
  validation accuracy:		92.50 %
Epoch 905 of 2000 took 0.096s
  training loss:		0.181914
  validation loss:		0.320965
  validation accuracy:		91.96 %
Epoch 906 of 2000 took 0.102s
  training loss:		0.179415
  validation loss:		0.332599
  validation accuracy:		91.85 %
Epoch 907 of 2000 took 0.097s
  training loss:		0.180828
  validation loss:		0.360180
  validation accuracy:		91.41 %
Epoch 908 of 2000 took 0.098s
  training loss:		0.183057
  validation loss:		0.335144
  validation accuracy:		91.96 %
Epoch 909 of 2000 took 0.100s
  training loss:		0.178596
  validation loss:		0.341822
  validation accuracy:		91.09 %
Epoch 910 of 2000 took 0.097s
  training loss:		0.176490
  validation loss:		0.337327
  validation accuracy:		92.28 %
Epoch 911 of 2000 took 0.102s
  training loss:		0.179149
  validation loss:		0.326633
  validation accuracy:		91.52 %
Epoch 912 of 2000 took 0.096s
  training loss:		0.181176
  validation loss:		0.327364
  validation accuracy:		91.20 %
Epoch 913 of 2000 took 0.101s
  training loss:		0.177471
  validation loss:		0.331910
  validation accuracy:		91.96 %
Epoch 914 of 2000 took 0.099s
  training loss:		0.180173
  validation loss:		0.344160
  validation accuracy:		91.30 %
Epoch 915 of 2000 took 0.098s
  training loss:		0.178277
  validation loss:		0.328715
  validation accuracy:		91.30 %
Epoch 916 of 2000 took 0.101s
  training loss:		0.182195
  validation loss:		0.343973
  validation accuracy:		90.98 %
Epoch 917 of 2000 took 0.097s
  training loss:		0.175610
  validation loss:		0.328287
  validation accuracy:		91.20 %
Epoch 918 of 2000 took 0.102s
  training loss:		0.177393
  validation loss:		0.321638
  validation accuracy:		92.28 %
Epoch 919 of 2000 took 0.096s
  training loss:		0.171593
  validation loss:		0.340528
  validation accuracy:		91.20 %
Epoch 920 of 2000 took 0.098s
  training loss:		0.175212
  validation loss:		0.343649
  validation accuracy:		90.87 %
Epoch 921 of 2000 took 0.099s
  training loss:		0.179589
  validation loss:		0.335481
  validation accuracy:		92.07 %
Epoch 922 of 2000 took 0.097s
  training loss:		0.171864
  validation loss:		0.332596
  validation accuracy:		91.96 %
Epoch 923 of 2000 took 0.104s
  training loss:		0.176069
  validation loss:		0.319839
  validation accuracy:		92.07 %
Epoch 924 of 2000 took 0.097s
  training loss:		0.173071
  validation loss:		0.321988
  validation accuracy:		91.74 %
Epoch 925 of 2000 took 0.097s
  training loss:		0.175810
  validation loss:		0.332162
  validation accuracy:		91.20 %
Epoch 926 of 2000 took 0.097s
  training loss:		0.178170
  validation loss:		0.326106
  validation accuracy:		92.28 %
Epoch 927 of 2000 took 0.097s
  training loss:		0.177576
  validation loss:		0.339130
  validation accuracy:		91.20 %
Epoch 928 of 2000 took 0.097s
  training loss:		0.175072
  validation loss:		0.337361
  validation accuracy:		91.20 %
Epoch 929 of 2000 took 0.097s
  training loss:		0.176242
  validation loss:		0.325392
  validation accuracy:		92.50 %
Epoch 930 of 2000 took 0.097s
  training loss:		0.178117
  validation loss:		0.336009
  validation accuracy:		91.41 %
Epoch 931 of 2000 took 0.097s
  training loss:		0.169477
  validation loss:		0.337216
  validation accuracy:		91.52 %
Epoch 932 of 2000 took 0.097s
  training loss:		0.175762
  validation loss:		0.322225
  validation accuracy:		91.74 %
Epoch 933 of 2000 took 0.097s
  training loss:		0.174967
  validation loss:		0.327216
  validation accuracy:		91.41 %
Epoch 934 of 2000 took 0.097s
  training loss:		0.175019
  validation loss:		0.347715
  validation accuracy:		90.76 %
Epoch 935 of 2000 took 0.097s
  training loss:		0.174755
  validation loss:		0.329656
  validation accuracy:		91.74 %
Epoch 936 of 2000 took 0.097s
  training loss:		0.168944
  validation loss:		0.321814
  validation accuracy:		91.85 %
Epoch 937 of 2000 took 0.097s
  training loss:		0.180180
  validation loss:		0.320766
  validation accuracy:		92.17 %
Epoch 938 of 2000 took 0.097s
  training loss:		0.178381
  validation loss:		0.351392
  validation accuracy:		90.87 %
Epoch 939 of 2000 took 0.097s
  training loss:		0.175278
  validation loss:		0.323796
  validation accuracy:		92.28 %
Epoch 940 of 2000 took 0.097s
  training loss:		0.176158
  validation loss:		0.332300
  validation accuracy:		91.63 %
Epoch 941 of 2000 took 0.097s
  training loss:		0.178209
  validation loss:		0.341009
  validation accuracy:		91.63 %
Epoch 942 of 2000 took 0.097s
  training loss:		0.174269
  validation loss:		0.332647
  validation accuracy:		91.30 %
Epoch 943 of 2000 took 0.097s
  training loss:		0.176384
  validation loss:		0.349921
  validation accuracy:		90.65 %
Epoch 944 of 2000 took 0.097s
  training loss:		0.172596
  validation loss:		0.331776
  validation accuracy:		92.07 %
Epoch 945 of 2000 took 0.097s
  training loss:		0.176058
  validation loss:		0.326218
  validation accuracy:		91.96 %
Epoch 946 of 2000 took 0.097s
  training loss:		0.172654
  validation loss:		0.322483
  validation accuracy:		92.07 %
Epoch 947 of 2000 took 0.097s
  training loss:		0.172981
  validation loss:		0.323505
  validation accuracy:		92.07 %
Epoch 948 of 2000 took 0.097s
  training loss:		0.173834
  validation loss:		0.335509
  validation accuracy:		92.28 %
Epoch 949 of 2000 took 0.097s
  training loss:		0.172623
  validation loss:		0.335227
  validation accuracy:		91.52 %
Epoch 950 of 2000 took 0.097s
  training loss:		0.172938
  validation loss:		0.337405
  validation accuracy:		92.07 %
Epoch 951 of 2000 took 0.097s
  training loss:		0.175913
  validation loss:		0.328092
  validation accuracy:		91.85 %
Epoch 952 of 2000 took 0.097s
  training loss:		0.174837
  validation loss:		0.333005
  validation accuracy:		92.17 %
Epoch 953 of 2000 took 0.097s
  training loss:		0.169457
  validation loss:		0.326120
  validation accuracy:		92.17 %
Epoch 954 of 2000 took 0.097s
  training loss:		0.174354
  validation loss:		0.328312
  validation accuracy:		91.96 %
Epoch 955 of 2000 took 0.097s
  training loss:		0.176006
  validation loss:		0.340827
  validation accuracy:		91.30 %
Epoch 956 of 2000 took 0.097s
  training loss:		0.174052
  validation loss:		0.323169
  validation accuracy:		92.17 %
Epoch 957 of 2000 took 0.097s
  training loss:		0.172371
  validation loss:		0.330922
  validation accuracy:		91.85 %
Epoch 958 of 2000 took 0.097s
  training loss:		0.174607
  validation loss:		0.335141
  validation accuracy:		91.85 %
Epoch 959 of 2000 took 0.097s
  training loss:		0.165906
  validation loss:		0.342387
  validation accuracy:		91.20 %
Epoch 960 of 2000 took 0.097s
  training loss:		0.169400
  validation loss:		0.339093
  validation accuracy:		91.63 %
Epoch 961 of 2000 took 0.097s
  training loss:		0.170373
  validation loss:		0.354918
  validation accuracy:		90.76 %
Epoch 962 of 2000 took 0.097s
  training loss:		0.171381
  validation loss:		0.349408
  validation accuracy:		90.87 %
Epoch 963 of 2000 took 0.097s
  training loss:		0.174449
  validation loss:		0.329872
  validation accuracy:		91.96 %
Epoch 964 of 2000 took 0.097s
  training loss:		0.170819
  validation loss:		0.343263
  validation accuracy:		91.30 %
Epoch 965 of 2000 took 0.097s
  training loss:		0.173653
  validation loss:		0.343659
  validation accuracy:		90.98 %
Epoch 966 of 2000 took 0.097s
  training loss:		0.172667
  validation loss:		0.343359
  validation accuracy:		90.87 %
Epoch 967 of 2000 took 0.097s
  training loss:		0.167087
  validation loss:		0.330931
  validation accuracy:		91.74 %
Epoch 968 of 2000 took 0.097s
  training loss:		0.165922
  validation loss:		0.336756
  validation accuracy:		92.17 %
Epoch 969 of 2000 took 0.097s
  training loss:		0.175947
  validation loss:		0.330639
  validation accuracy:		92.07 %
Epoch 970 of 2000 took 0.097s
  training loss:		0.173336
  validation loss:		0.335389
  validation accuracy:		91.41 %
Epoch 971 of 2000 took 0.097s
  training loss:		0.170448
  validation loss:		0.343538
  validation accuracy:		91.20 %
Epoch 972 of 2000 took 0.097s
  training loss:		0.173999
  validation loss:		0.334613
  validation accuracy:		91.63 %
Epoch 973 of 2000 took 0.097s
  training loss:		0.173980
  validation loss:		0.329371
  validation accuracy:		91.96 %
Epoch 974 of 2000 took 0.097s
  training loss:		0.172630
  validation loss:		0.346065
  validation accuracy:		91.41 %
Epoch 975 of 2000 took 0.097s
  training loss:		0.170061
  validation loss:		0.360891
  validation accuracy:		90.87 %
Epoch 976 of 2000 took 0.097s
  training loss:		0.171023
  validation loss:		0.347993
  validation accuracy:		91.09 %
Epoch 977 of 2000 took 0.097s
  training loss:		0.169224
  validation loss:		0.337161
  validation accuracy:		91.41 %
Epoch 978 of 2000 took 0.097s
  training loss:		0.174525
  validation loss:		0.331794
  validation accuracy:		91.30 %
Epoch 979 of 2000 took 0.097s
  training loss:		0.176927
  validation loss:		0.342920
  validation accuracy:		91.85 %
Epoch 980 of 2000 took 0.097s
  training loss:		0.170523
  validation loss:		0.334120
  validation accuracy:		91.63 %
Epoch 981 of 2000 took 0.097s
  training loss:		0.168016
  validation loss:		0.330069
  validation accuracy:		92.17 %
Epoch 982 of 2000 took 0.097s
  training loss:		0.168898
  validation loss:		0.336141
  validation accuracy:		91.74 %
Epoch 983 of 2000 took 0.097s
  training loss:		0.175118
  validation loss:		0.339862
  validation accuracy:		91.41 %
Epoch 984 of 2000 took 0.097s
  training loss:		0.171965
  validation loss:		0.347608
  validation accuracy:		91.09 %
Epoch 985 of 2000 took 0.097s
  training loss:		0.173470
  validation loss:		0.360377
  validation accuracy:		91.09 %
Epoch 986 of 2000 took 0.097s
  training loss:		0.172643
  validation loss:		0.344523
  validation accuracy:		91.52 %
Epoch 987 of 2000 took 0.097s
  training loss:		0.169939
  validation loss:		0.340974
  validation accuracy:		91.96 %
Epoch 988 of 2000 took 0.097s
  training loss:		0.172685
  validation loss:		0.327831
  validation accuracy:		92.28 %
Epoch 989 of 2000 took 0.097s
  training loss:		0.174072
  validation loss:		0.332995
  validation accuracy:		91.96 %
Epoch 990 of 2000 took 0.097s
  training loss:		0.168045
  validation loss:		0.333407
  validation accuracy:		91.85 %
Epoch 991 of 2000 took 0.097s
  training loss:		0.162960
  validation loss:		0.353106
  validation accuracy:		91.20 %
Epoch 992 of 2000 took 0.097s
  training loss:		0.170069
  validation loss:		0.342262
  validation accuracy:		91.20 %
Epoch 993 of 2000 took 0.097s
  training loss:		0.163949
  validation loss:		0.351141
  validation accuracy:		91.30 %
Epoch 994 of 2000 took 0.097s
  training loss:		0.169999
  validation loss:		0.357696
  validation accuracy:		91.09 %
Epoch 995 of 2000 took 0.097s
  training loss:		0.165515
  validation loss:		0.331497
  validation accuracy:		91.74 %
Epoch 996 of 2000 took 0.097s
  training loss:		0.171590
  validation loss:		0.344018
  validation accuracy:		91.52 %
Epoch 997 of 2000 took 0.097s
  training loss:		0.170654
  validation loss:		0.335549
  validation accuracy:		91.09 %
Epoch 998 of 2000 took 0.097s
  training loss:		0.169655
  validation loss:		0.330457
  validation accuracy:		91.96 %
Epoch 999 of 2000 took 0.097s
  training loss:		0.162844
  validation loss:		0.337627
  validation accuracy:		91.52 %
Epoch 1000 of 2000 took 0.097s
  training loss:		0.167160
  validation loss:		0.344749
  validation accuracy:		91.41 %
Epoch 1001 of 2000 took 0.097s
  training loss:		0.170116
  validation loss:		0.341108
  validation accuracy:		91.74 %
Epoch 1002 of 2000 took 0.097s
  training loss:		0.168539
  validation loss:		0.367247
  validation accuracy:		90.87 %
Epoch 1003 of 2000 took 0.097s
  training loss:		0.162567
  validation loss:		0.339955
  validation accuracy:		91.63 %
Epoch 1004 of 2000 took 0.097s
  training loss:		0.165828
  validation loss:		0.343966
  validation accuracy:		91.41 %
Epoch 1005 of 2000 took 0.097s
  training loss:		0.165713
  validation loss:		0.342039
  validation accuracy:		91.85 %
Epoch 1006 of 2000 took 0.097s
  training loss:		0.167955
  validation loss:		0.360393
  validation accuracy:		90.54 %
Epoch 1007 of 2000 took 0.097s
  training loss:		0.168456
  validation loss:		0.357812
  validation accuracy:		91.20 %
Epoch 1008 of 2000 took 0.097s
  training loss:		0.163580
  validation loss:		0.339019
  validation accuracy:		91.41 %
Epoch 1009 of 2000 took 0.097s
  training loss:		0.162009
  validation loss:		0.332934
  validation accuracy:		91.85 %
Epoch 1010 of 2000 took 0.097s
  training loss:		0.168421
  validation loss:		0.345329
  validation accuracy:		91.20 %
Epoch 1011 of 2000 took 0.097s
  training loss:		0.168768
  validation loss:		0.342653
  validation accuracy:		91.52 %
Epoch 1012 of 2000 took 0.097s
  training loss:		0.164951
  validation loss:		0.348314
  validation accuracy:		91.74 %
Epoch 1013 of 2000 took 0.097s
  training loss:		0.166705
  validation loss:		0.350716
  validation accuracy:		91.30 %
Epoch 1014 of 2000 took 0.097s
  training loss:		0.167754
  validation loss:		0.336539
  validation accuracy:		91.96 %
Epoch 1015 of 2000 took 0.097s
  training loss:		0.163817
  validation loss:		0.341746
  validation accuracy:		91.74 %
Epoch 1016 of 2000 took 0.097s
  training loss:		0.170399
  validation loss:		0.362972
  validation accuracy:		90.98 %
Epoch 1017 of 2000 took 0.097s
  training loss:		0.171468
  validation loss:		0.347043
  validation accuracy:		91.20 %
Epoch 1018 of 2000 took 0.097s
  training loss:		0.165804
  validation loss:		0.369422
  validation accuracy:		90.65 %
Epoch 1019 of 2000 took 0.097s
  training loss:		0.172005
  validation loss:		0.358931
  validation accuracy:		90.76 %
Epoch 1020 of 2000 took 0.097s
  training loss:		0.163763
  validation loss:		0.347388
  validation accuracy:		90.87 %
Epoch 1021 of 2000 took 0.097s
  training loss:		0.167573
  validation loss:		0.347238
  validation accuracy:		91.20 %
Epoch 1022 of 2000 took 0.097s
  training loss:		0.164201
  validation loss:		0.340392
  validation accuracy:		91.63 %
Epoch 1023 of 2000 took 0.097s
  training loss:		0.165782
  validation loss:		0.339230
  validation accuracy:		91.41 %
Epoch 1024 of 2000 took 0.097s
  training loss:		0.168016
  validation loss:		0.361552
  validation accuracy:		90.87 %
Epoch 1025 of 2000 took 0.097s
  training loss:		0.162170
  validation loss:		0.343288
  validation accuracy:		91.30 %
Epoch 1026 of 2000 took 0.097s
  training loss:		0.165733
  validation loss:		0.345398
  validation accuracy:		91.09 %
Epoch 1027 of 2000 took 0.097s
  training loss:		0.162757
  validation loss:		0.345771
  validation accuracy:		91.20 %
Epoch 1028 of 2000 took 0.097s
  training loss:		0.163631
  validation loss:		0.341879
  validation accuracy:		91.52 %
Epoch 1029 of 2000 took 0.097s
  training loss:		0.164013
  validation loss:		0.360207
  validation accuracy:		91.09 %
Epoch 1030 of 2000 took 0.097s
  training loss:		0.164082
  validation loss:		0.349690
  validation accuracy:		90.98 %
Epoch 1031 of 2000 took 0.097s
  training loss:		0.166557
  validation loss:		0.344181
  validation accuracy:		91.41 %
Epoch 1032 of 2000 took 0.097s
  training loss:		0.165426
  validation loss:		0.343941
  validation accuracy:		91.41 %
Epoch 1033 of 2000 took 0.097s
  training loss:		0.169257
  validation loss:		0.349745
  validation accuracy:		91.20 %
Epoch 1034 of 2000 took 0.097s
  training loss:		0.168994
  validation loss:		0.354503
  validation accuracy:		90.87 %
Epoch 1035 of 2000 took 0.097s
  training loss:		0.161439
  validation loss:		0.365116
  validation accuracy:		90.76 %
Epoch 1036 of 2000 took 0.097s
  training loss:		0.161049
  validation loss:		0.349929
  validation accuracy:		91.09 %
Epoch 1037 of 2000 took 0.097s
  training loss:		0.165054
  validation loss:		0.353108
  validation accuracy:		91.41 %
Epoch 1038 of 2000 took 0.097s
  training loss:		0.164344
  validation loss:		0.348185
  validation accuracy:		91.41 %
Epoch 1039 of 2000 took 0.097s
  training loss:		0.161271
  validation loss:		0.365774
  validation accuracy:		90.76 %
Epoch 1040 of 2000 took 0.097s
  training loss:		0.160524
  validation loss:		0.360506
  validation accuracy:		90.87 %
Epoch 1041 of 2000 took 0.097s
  training loss:		0.165409
  validation loss:		0.356583
  validation accuracy:		90.98 %
Epoch 1042 of 2000 took 0.097s
  training loss:		0.163009
  validation loss:		0.344359
  validation accuracy:		91.52 %
Epoch 1043 of 2000 took 0.097s
  training loss:		0.167472
  validation loss:		0.348421
  validation accuracy:		91.63 %
Epoch 1044 of 2000 took 0.097s
  training loss:		0.161969
  validation loss:		0.348076
  validation accuracy:		91.30 %
Epoch 1045 of 2000 took 0.097s
  training loss:		0.158052
  validation loss:		0.349453
  validation accuracy:		91.20 %
Epoch 1046 of 2000 took 0.097s
  training loss:		0.160355
  validation loss:		0.351154
  validation accuracy:		91.41 %
Epoch 1047 of 2000 took 0.097s
  training loss:		0.163140
  validation loss:		0.358087
  validation accuracy:		90.87 %
Epoch 1048 of 2000 took 0.097s
  training loss:		0.163941
  validation loss:		0.355971
  validation accuracy:		91.20 %
Epoch 1049 of 2000 took 0.097s
  training loss:		0.165162
  validation loss:		0.345118
  validation accuracy:		91.52 %
Epoch 1050 of 2000 took 0.097s
  training loss:		0.164923
  validation loss:		0.341984
  validation accuracy:		91.20 %
Epoch 1051 of 2000 took 0.097s
  training loss:		0.165965
  validation loss:		0.354049
  validation accuracy:		90.98 %
Epoch 1052 of 2000 took 0.097s
  training loss:		0.165160
  validation loss:		0.361100
  validation accuracy:		91.30 %
Epoch 1053 of 2000 took 0.097s
  training loss:		0.158918
  validation loss:		0.370960
  validation accuracy:		90.98 %
Epoch 1054 of 2000 took 0.097s
  training loss:		0.167970
  validation loss:		0.351598
  validation accuracy:		91.41 %
Epoch 1055 of 2000 took 0.097s
  training loss:		0.169615
  validation loss:		0.350963
  validation accuracy:		91.20 %
Epoch 1056 of 2000 took 0.097s
  training loss:		0.164255
  validation loss:		0.349008
  validation accuracy:		91.30 %
Epoch 1057 of 2000 took 0.097s
  training loss:		0.160717
  validation loss:		0.383526
  validation accuracy:		90.22 %
Epoch 1058 of 2000 took 0.097s
  training loss:		0.162438
  validation loss:		0.361178
  validation accuracy:		90.87 %
Epoch 1059 of 2000 took 0.097s
  training loss:		0.162696
  validation loss:		0.367959
  validation accuracy:		90.76 %
Epoch 1060 of 2000 took 0.097s
  training loss:		0.168476
  validation loss:		0.350028
  validation accuracy:		91.41 %
Epoch 1061 of 2000 took 0.097s
  training loss:		0.162127
  validation loss:		0.358974
  validation accuracy:		90.98 %
Epoch 1062 of 2000 took 0.097s
  training loss:		0.160189
  validation loss:		0.377909
  validation accuracy:		90.76 %
Epoch 1063 of 2000 took 0.097s
  training loss:		0.160473
  validation loss:		0.358990
  validation accuracy:		91.20 %
Epoch 1064 of 2000 took 0.097s
  training loss:		0.157205
  validation loss:		0.352488
  validation accuracy:		91.20 %
Epoch 1065 of 2000 took 0.097s
  training loss:		0.162665
  validation loss:		0.350192
  validation accuracy:		91.41 %
Epoch 1066 of 2000 took 0.097s
  training loss:		0.164426
  validation loss:		0.370269
  validation accuracy:		90.65 %
Epoch 1067 of 2000 took 0.097s
  training loss:		0.161966
  validation loss:		0.349246
  validation accuracy:		91.30 %
Epoch 1068 of 2000 took 0.097s
  training loss:		0.162570
  validation loss:		0.367994
  validation accuracy:		90.98 %
Epoch 1069 of 2000 took 0.097s
  training loss:		0.165993
  validation loss:		0.355744
  validation accuracy:		91.20 %
Epoch 1070 of 2000 took 0.097s
  training loss:		0.165307
  validation loss:		0.351122
  validation accuracy:		91.30 %
Epoch 1071 of 2000 took 0.097s
  training loss:		0.162151
  validation loss:		0.344874
  validation accuracy:		91.30 %
Epoch 1072 of 2000 took 0.097s
  training loss:		0.167630
  validation loss:		0.369250
  validation accuracy:		91.20 %
Epoch 1073 of 2000 took 0.097s
  training loss:		0.165638
  validation loss:		0.364589
  validation accuracy:		90.76 %
Epoch 1074 of 2000 took 0.097s
  training loss:		0.158930
  validation loss:		0.352063
  validation accuracy:		91.09 %
Epoch 1075 of 2000 took 0.097s
  training loss:		0.158233
  validation loss:		0.379774
  validation accuracy:		91.09 %
Epoch 1076 of 2000 took 0.097s
  training loss:		0.162307
  validation loss:		0.369067
  validation accuracy:		90.76 %
Epoch 1077 of 2000 took 0.097s
  training loss:		0.158487
  validation loss:		0.344889
  validation accuracy:		91.20 %
Epoch 1078 of 2000 took 0.097s
  training loss:		0.168999
  validation loss:		0.355009
  validation accuracy:		91.20 %
Epoch 1079 of 2000 took 0.097s
  training loss:		0.158462
  validation loss:		0.355113
  validation accuracy:		91.09 %
Epoch 1080 of 2000 took 0.097s
  training loss:		0.163275
  validation loss:		0.357758
  validation accuracy:		91.30 %
Epoch 1081 of 2000 took 0.097s
  training loss:		0.157680
  validation loss:		0.348205
  validation accuracy:		91.52 %
Epoch 1082 of 2000 took 0.097s
  training loss:		0.162319
  validation loss:		0.353967
  validation accuracy:		91.30 %
Epoch 1083 of 2000 took 0.097s
  training loss:		0.162680
  validation loss:		0.373054
  validation accuracy:		90.65 %
Epoch 1084 of 2000 took 0.097s
  training loss:		0.162917
  validation loss:		0.355543
  validation accuracy:		91.30 %
Epoch 1085 of 2000 took 0.097s
  training loss:		0.163170
  validation loss:		0.359230
  validation accuracy:		90.87 %
Epoch 1086 of 2000 took 0.097s
  training loss:		0.159832
  validation loss:		0.361994
  validation accuracy:		91.09 %
Epoch 1087 of 2000 took 0.097s
  training loss:		0.164004
  validation loss:		0.353076
  validation accuracy:		91.30 %
Epoch 1088 of 2000 took 0.097s
  training loss:		0.161429
  validation loss:		0.363599
  validation accuracy:		90.87 %
Epoch 1089 of 2000 took 0.097s
  training loss:		0.171082
  validation loss:		0.347717
  validation accuracy:		91.30 %
Epoch 1090 of 2000 took 0.097s
  training loss:		0.157662
  validation loss:		0.350400
  validation accuracy:		91.30 %
Epoch 1091 of 2000 took 0.097s
  training loss:		0.161311
  validation loss:		0.370471
  validation accuracy:		90.65 %
Epoch 1092 of 2000 took 0.097s
  training loss:		0.162769
  validation loss:		0.368416
  validation accuracy:		91.63 %
Epoch 1093 of 2000 took 0.097s
  training loss:		0.157408
  validation loss:		0.357858
  validation accuracy:		91.09 %
Epoch 1094 of 2000 took 0.097s
  training loss:		0.161633
  validation loss:		0.356861
  validation accuracy:		91.63 %
Epoch 1095 of 2000 took 0.097s
  training loss:		0.159420
  validation loss:		0.364580
  validation accuracy:		91.09 %
Epoch 1096 of 2000 took 0.097s
  training loss:		0.155176
  validation loss:		0.352158
  validation accuracy:		91.30 %
Epoch 1097 of 2000 took 0.097s
  training loss:		0.162499
  validation loss:		0.364203
  validation accuracy:		91.30 %
Epoch 1098 of 2000 took 0.097s
  training loss:		0.161605
  validation loss:		0.355794
  validation accuracy:		91.30 %
Epoch 1099 of 2000 took 0.097s
  training loss:		0.160012
  validation loss:		0.367995
  validation accuracy:		90.87 %
Epoch 1100 of 2000 took 0.097s
  training loss:		0.160353
  validation loss:		0.358662
  validation accuracy:		91.09 %
Epoch 1101 of 2000 took 0.097s
  training loss:		0.160039
  validation loss:		0.352762
  validation accuracy:		91.41 %
Epoch 1102 of 2000 took 0.097s
  training loss:		0.164245
  validation loss:		0.382529
  validation accuracy:		90.22 %
Epoch 1103 of 2000 took 0.097s
  training loss:		0.157648
  validation loss:		0.356861
  validation accuracy:		90.98 %
Epoch 1104 of 2000 took 0.097s
  training loss:		0.158577
  validation loss:		0.362427
  validation accuracy:		90.87 %
Epoch 1105 of 2000 took 0.097s
  training loss:		0.160603
  validation loss:		0.379904
  validation accuracy:		90.65 %
Epoch 1106 of 2000 took 0.097s
  training loss:		0.153995
  validation loss:		0.355665
  validation accuracy:		91.09 %
Epoch 1107 of 2000 took 0.097s
  training loss:		0.158563
  validation loss:		0.354881
  validation accuracy:		91.30 %
Epoch 1108 of 2000 took 0.097s
  training loss:		0.160192
  validation loss:		0.365582
  validation accuracy:		90.98 %
Epoch 1109 of 2000 took 0.097s
  training loss:		0.161906
  validation loss:		0.356025
  validation accuracy:		91.09 %
Epoch 1110 of 2000 took 0.097s
  training loss:		0.165385
  validation loss:		0.358199
  validation accuracy:		91.09 %
Epoch 1111 of 2000 took 0.097s
  training loss:		0.160225
  validation loss:		0.395963
  validation accuracy:		90.76 %
Epoch 1112 of 2000 took 0.097s
  training loss:		0.158119
  validation loss:		0.362278
  validation accuracy:		91.41 %
Epoch 1113 of 2000 took 0.097s
  training loss:		0.156026
  validation loss:		0.373897
  validation accuracy:		90.76 %
Epoch 1114 of 2000 took 0.097s
  training loss:		0.159365
  validation loss:		0.378206
  validation accuracy:		90.98 %
Epoch 1115 of 2000 took 0.097s
  training loss:		0.155023
  validation loss:		0.369113
  validation accuracy:		91.30 %
Epoch 1116 of 2000 took 0.097s
  training loss:		0.155611
  validation loss:		0.370884
  validation accuracy:		90.87 %
Epoch 1117 of 2000 took 0.097s
  training loss:		0.155575
  validation loss:		0.360543
  validation accuracy:		91.09 %
Epoch 1118 of 2000 took 0.097s
  training loss:		0.157426
  validation loss:		0.369257
  validation accuracy:		91.09 %
Epoch 1119 of 2000 took 0.097s
  training loss:		0.161521
  validation loss:		0.363216
  validation accuracy:		90.76 %
Epoch 1120 of 2000 took 0.097s
  training loss:		0.162791
  validation loss:		0.368836
  validation accuracy:		91.09 %
Epoch 1121 of 2000 took 0.097s
  training loss:		0.158582
  validation loss:		0.363574
  validation accuracy:		90.76 %
Epoch 1122 of 2000 took 0.097s
  training loss:		0.164883
  validation loss:		0.361678
  validation accuracy:		90.98 %
Epoch 1123 of 2000 took 0.097s
  training loss:		0.163801
  validation loss:		0.382504
  validation accuracy:		90.76 %
Epoch 1124 of 2000 took 0.097s
  training loss:		0.159298
  validation loss:		0.363481
  validation accuracy:		90.87 %
Epoch 1125 of 2000 took 0.097s
  training loss:		0.160439
  validation loss:		0.366325
  validation accuracy:		90.87 %
Epoch 1126 of 2000 took 0.097s
  training loss:		0.154210
  validation loss:		0.370723
  validation accuracy:		91.20 %
Epoch 1127 of 2000 took 0.097s
  training loss:		0.157688
  validation loss:		0.369951
  validation accuracy:		91.52 %
Epoch 1128 of 2000 took 0.097s
  training loss:		0.168953
  validation loss:		0.367013
  validation accuracy:		91.09 %
Epoch 1129 of 2000 took 0.097s
  training loss:		0.155854
  validation loss:		0.356061
  validation accuracy:		91.41 %
Epoch 1130 of 2000 took 0.097s
  training loss:		0.159633
  validation loss:		0.360862
  validation accuracy:		91.20 %
Epoch 1131 of 2000 took 0.097s
  training loss:		0.161693
  validation loss:		0.367162
  validation accuracy:		90.98 %
Epoch 1132 of 2000 took 0.097s
  training loss:		0.157870
  validation loss:		0.361487
  validation accuracy:		90.98 %
Epoch 1133 of 2000 took 0.097s
  training loss:		0.157629
  validation loss:		0.367566
  validation accuracy:		90.65 %
Epoch 1134 of 2000 took 0.097s
  training loss:		0.163342
  validation loss:		0.364359
  validation accuracy:		90.98 %
Epoch 1135 of 2000 took 0.097s
  training loss:		0.159170
  validation loss:		0.361364
  validation accuracy:		91.09 %
Epoch 1136 of 2000 took 0.097s
  training loss:		0.160527
  validation loss:		0.372499
  validation accuracy:		91.41 %
Epoch 1137 of 2000 took 0.097s
  training loss:		0.159219
  validation loss:		0.364828
  validation accuracy:		90.65 %
Epoch 1138 of 2000 took 0.097s
  training loss:		0.157213
  validation loss:		0.378256
  validation accuracy:		90.98 %
Epoch 1139 of 2000 took 0.097s
  training loss:		0.163735
  validation loss:		0.374500
  validation accuracy:		90.98 %
Epoch 1140 of 2000 took 0.097s
  training loss:		0.160363
  validation loss:		0.376158
  validation accuracy:		91.20 %
Epoch 1141 of 2000 took 0.097s
  training loss:		0.158004
  validation loss:		0.370994
  validation accuracy:		90.98 %
Epoch 1142 of 2000 took 0.097s
  training loss:		0.157096
  validation loss:		0.373012
  validation accuracy:		90.76 %
Epoch 1143 of 2000 took 0.097s
  training loss:		0.155263
  validation loss:		0.390970
  validation accuracy:		90.76 %
Epoch 1144 of 2000 took 0.097s
  training loss:		0.156078
  validation loss:		0.356692
  validation accuracy:		91.20 %
Epoch 1145 of 2000 took 0.097s
  training loss:		0.155194
  validation loss:		0.375803
  validation accuracy:		90.76 %
Epoch 1146 of 2000 took 0.097s
  training loss:		0.153030
  validation loss:		0.371416
  validation accuracy:		90.76 %
Epoch 1147 of 2000 took 0.097s
  training loss:		0.158910
  validation loss:		0.369787
  validation accuracy:		90.87 %
Epoch 1148 of 2000 took 0.097s
  training loss:		0.160900
  validation loss:		0.374140
  validation accuracy:		91.09 %
Epoch 1149 of 2000 took 0.097s
  training loss:		0.163805
  validation loss:		0.378793
  validation accuracy:		90.87 %
Epoch 1150 of 2000 took 0.097s
  training loss:		0.160183
  validation loss:		0.359049
  validation accuracy:		91.09 %
Epoch 1151 of 2000 took 0.097s
  training loss:		0.155273
  validation loss:		0.359975
  validation accuracy:		91.20 %
Epoch 1152 of 2000 took 0.097s
  training loss:		0.151801
  validation loss:		0.388308
  validation accuracy:		90.65 %
Epoch 1153 of 2000 took 0.097s
  training loss:		0.160814
  validation loss:		0.378490
  validation accuracy:		90.98 %
Epoch 1154 of 2000 took 0.097s
  training loss:		0.158233
  validation loss:		0.371092
  validation accuracy:		91.30 %
Epoch 1155 of 2000 took 0.097s
  training loss:		0.156149
  validation loss:		0.364878
  validation accuracy:		91.30 %
Epoch 1156 of 2000 took 0.097s
  training loss:		0.155737
  validation loss:		0.370117
  validation accuracy:		90.98 %
Epoch 1157 of 2000 took 0.097s
  training loss:		0.160044
  validation loss:		0.385400
  validation accuracy:		90.65 %
Epoch 1158 of 2000 took 0.097s
  training loss:		0.155015
  validation loss:		0.372126
  validation accuracy:		91.20 %
Epoch 1159 of 2000 took 0.097s
  training loss:		0.154456
  validation loss:		0.373674
  validation accuracy:		91.09 %
Epoch 1160 of 2000 took 0.097s
  training loss:		0.157196
  validation loss:		0.368407
  validation accuracy:		90.98 %
Epoch 1161 of 2000 took 0.097s
  training loss:		0.159014
  validation loss:		0.375774
  validation accuracy:		90.87 %
Epoch 1162 of 2000 took 0.097s
  training loss:		0.157649
  validation loss:		0.364988
  validation accuracy:		91.30 %
Epoch 1163 of 2000 took 0.097s
  training loss:		0.150046
  validation loss:		0.369998
  validation accuracy:		90.65 %
Epoch 1164 of 2000 took 0.097s
  training loss:		0.164076
  validation loss:		0.374338
  validation accuracy:		90.65 %
Epoch 1165 of 2000 took 0.097s
  training loss:		0.152222
  validation loss:		0.372489
  validation accuracy:		90.87 %
Epoch 1166 of 2000 took 0.097s
  training loss:		0.151170
  validation loss:		0.384281
  validation accuracy:		90.87 %
Epoch 1167 of 2000 took 0.097s
  training loss:		0.157478
  validation loss:		0.372691
  validation accuracy:		91.09 %
Epoch 1168 of 2000 took 0.099s
  training loss:		0.156856
  validation loss:		0.382710
  validation accuracy:		90.98 %
Epoch 1169 of 2000 took 0.100s
  training loss:		0.156812
  validation loss:		0.367265
  validation accuracy:		91.09 %
Epoch 1170 of 2000 took 0.100s
  training loss:		0.156625
  validation loss:		0.372864
  validation accuracy:		90.87 %
Epoch 1171 of 2000 took 0.100s
  training loss:		0.160798
  validation loss:		0.394427
  validation accuracy:		90.54 %
Epoch 1172 of 2000 took 0.100s
  training loss:		0.152802
  validation loss:		0.367322
  validation accuracy:		90.87 %
Epoch 1173 of 2000 took 0.100s
  training loss:		0.156749
  validation loss:		0.367437
  validation accuracy:		91.09 %
Epoch 1174 of 2000 took 0.100s
  training loss:		0.157811
  validation loss:		0.367850
  validation accuracy:		90.87 %
Epoch 1175 of 2000 took 0.100s
  training loss:		0.155022
  validation loss:		0.368267
  validation accuracy:		90.87 %
Epoch 1176 of 2000 took 0.100s
  training loss:		0.155251
  validation loss:		0.372112
  validation accuracy:		90.87 %
Epoch 1177 of 2000 took 0.100s
  training loss:		0.155481
  validation loss:		0.385075
  validation accuracy:		90.98 %
Epoch 1178 of 2000 took 0.100s
  training loss:		0.156483
  validation loss:		0.378202
  validation accuracy:		90.87 %
Epoch 1179 of 2000 took 0.100s
  training loss:		0.154626
  validation loss:		0.380552
  validation accuracy:		90.87 %
Epoch 1180 of 2000 took 0.100s
  training loss:		0.157610
  validation loss:		0.410303
  validation accuracy:		90.11 %
Epoch 1181 of 2000 took 0.100s
  training loss:		0.156745
  validation loss:		0.376589
  validation accuracy:		90.98 %
Epoch 1182 of 2000 took 0.100s
  training loss:		0.151489
  validation loss:		0.377805
  validation accuracy:		91.30 %
Epoch 1183 of 2000 took 0.100s
  training loss:		0.157352
  validation loss:		0.395371
  validation accuracy:		90.76 %
Epoch 1184 of 2000 took 0.100s
  training loss:		0.156949
  validation loss:		0.363525
  validation accuracy:		90.98 %
Epoch 1185 of 2000 took 0.100s
  training loss:		0.162450
  validation loss:		0.374002
  validation accuracy:		90.98 %
Epoch 1186 of 2000 took 0.100s
  training loss:		0.156566
  validation loss:		0.384815
  validation accuracy:		90.76 %
Epoch 1187 of 2000 took 0.100s
  training loss:		0.154800
  validation loss:		0.387689
  validation accuracy:		90.76 %
Epoch 1188 of 2000 took 0.100s
  training loss:		0.158859
  validation loss:		0.387124
  validation accuracy:		90.87 %
Epoch 1189 of 2000 took 0.100s
  training loss:		0.158819
  validation loss:		0.374259
  validation accuracy:		90.87 %
Epoch 1190 of 2000 took 0.100s
  training loss:		0.157409
  validation loss:		0.365677
  validation accuracy:		91.30 %
Epoch 1191 of 2000 took 0.100s
  training loss:		0.153860
  validation loss:		0.401181
  validation accuracy:		90.43 %
Epoch 1192 of 2000 took 0.100s
  training loss:		0.148207
  validation loss:		0.389938
  validation accuracy:		90.65 %
Epoch 1193 of 2000 took 0.100s
  training loss:		0.158174
  validation loss:		0.406853
  validation accuracy:		90.22 %
Epoch 1194 of 2000 took 0.100s
  training loss:		0.163953
  validation loss:		0.387243
  validation accuracy:		90.65 %
Epoch 1195 of 2000 took 0.100s
  training loss:		0.157682
  validation loss:		0.386716
  validation accuracy:		90.87 %
Epoch 1196 of 2000 took 0.100s
  training loss:		0.160625
  validation loss:		0.372322
  validation accuracy:		91.09 %
Epoch 1197 of 2000 took 0.100s
  training loss:		0.157574
  validation loss:		0.384052
  validation accuracy:		90.87 %
Epoch 1198 of 2000 took 0.101s
  training loss:		0.154029
  validation loss:		0.372532
  validation accuracy:		90.98 %
Epoch 1199 of 2000 took 0.100s
  training loss:		0.157334
  validation loss:		0.386750
  validation accuracy:		90.87 %
Epoch 1200 of 2000 took 0.100s
  training loss:		0.149995
  validation loss:		0.373562
  validation accuracy:		90.87 %
Epoch 1201 of 2000 took 0.100s
  training loss:		0.160087
  validation loss:		0.400108
  validation accuracy:		90.54 %
Epoch 1202 of 2000 took 0.100s
  training loss:		0.154475
  validation loss:		0.376780
  validation accuracy:		90.87 %
Epoch 1203 of 2000 took 0.100s
  training loss:		0.153866
  validation loss:		0.374965
  validation accuracy:		90.76 %
Epoch 1204 of 2000 took 0.100s
  training loss:		0.149790
  validation loss:		0.393701
  validation accuracy:		90.65 %
Epoch 1205 of 2000 took 0.100s
  training loss:		0.154911
  validation loss:		0.380735
  validation accuracy:		90.87 %
Epoch 1206 of 2000 took 0.100s
  training loss:		0.151061
  validation loss:		0.385198
  validation accuracy:		90.76 %
Epoch 1207 of 2000 took 0.100s
  training loss:		0.162955
  validation loss:		0.386887
  validation accuracy:		90.76 %
Epoch 1208 of 2000 took 0.098s
  training loss:		0.153903
  validation loss:		0.385931
  validation accuracy:		90.65 %
Epoch 1209 of 2000 took 0.097s
  training loss:		0.152152
  validation loss:		0.379082
  validation accuracy:		91.09 %
Epoch 1210 of 2000 took 0.097s
  training loss:		0.152051
  validation loss:		0.377926
  validation accuracy:		91.52 %
Epoch 1211 of 2000 took 0.097s
  training loss:		0.152245
  validation loss:		0.377683
  validation accuracy:		90.87 %
Epoch 1212 of 2000 took 0.097s
  training loss:		0.160300
  validation loss:		0.387205
  validation accuracy:		90.87 %
Epoch 1213 of 2000 took 0.097s
  training loss:		0.156604
  validation loss:		0.374211
  validation accuracy:		90.98 %
Epoch 1214 of 2000 took 0.097s
  training loss:		0.150808
  validation loss:		0.401029
  validation accuracy:		90.43 %
Epoch 1215 of 2000 took 0.097s
  training loss:		0.155547
  validation loss:		0.375239
  validation accuracy:		90.98 %
Epoch 1216 of 2000 took 0.097s
  training loss:		0.149680
  validation loss:		0.388316
  validation accuracy:		90.76 %
Epoch 1217 of 2000 took 0.097s
  training loss:		0.151387
  validation loss:		0.407097
  validation accuracy:		90.54 %
Epoch 1218 of 2000 took 0.098s
  training loss:		0.153992
  validation loss:		0.387374
  validation accuracy:		90.65 %
Epoch 1219 of 2000 took 0.097s
  training loss:		0.153916
  validation loss:		0.383541
  validation accuracy:		90.76 %
Epoch 1220 of 2000 took 0.097s
  training loss:		0.154910
  validation loss:		0.391018
  validation accuracy:		90.76 %
Epoch 1221 of 2000 took 0.097s
  training loss:		0.162136
  validation loss:		0.379178
  validation accuracy:		90.87 %
Epoch 1222 of 2000 took 0.097s
  training loss:		0.152641
  validation loss:		0.381510
  validation accuracy:		90.87 %
Epoch 1223 of 2000 took 0.097s
  training loss:		0.152776
  validation loss:		0.373087
  validation accuracy:		90.98 %
Epoch 1224 of 2000 took 0.097s
  training loss:		0.152668
  validation loss:		0.377240
  validation accuracy:		90.98 %
Epoch 1225 of 2000 took 0.097s
  training loss:		0.150278
  validation loss:		0.395668
  validation accuracy:		90.76 %
Epoch 1226 of 2000 took 0.097s
  training loss:		0.158802
  validation loss:		0.391335
  validation accuracy:		90.65 %
Epoch 1227 of 2000 took 0.097s
  training loss:		0.154078
  validation loss:		0.376296
  validation accuracy:		90.76 %
Epoch 1228 of 2000 took 0.097s
  training loss:		0.156180
  validation loss:		0.378083
  validation accuracy:		90.98 %
Epoch 1229 of 2000 took 0.097s
  training loss:		0.155819
  validation loss:		0.389216
  validation accuracy:		90.54 %
Epoch 1230 of 2000 took 0.097s
  training loss:		0.156885
  validation loss:		0.394318
  validation accuracy:		90.43 %
Epoch 1231 of 2000 took 0.097s
  training loss:		0.161337
  validation loss:		0.402746
  validation accuracy:		90.33 %
Epoch 1232 of 2000 took 0.097s
  training loss:		0.152756
  validation loss:		0.387516
  validation accuracy:		90.76 %
Epoch 1233 of 2000 took 0.097s
  training loss:		0.153187
  validation loss:		0.387264
  validation accuracy:		91.20 %
Epoch 1234 of 2000 took 0.097s
  training loss:		0.159576
  validation loss:		0.377892
  validation accuracy:		90.65 %
Epoch 1235 of 2000 took 0.097s
  training loss:		0.155806
  validation loss:		0.380537
  validation accuracy:		90.76 %
Epoch 1236 of 2000 took 0.097s
  training loss:		0.150075
  validation loss:		0.388255
  validation accuracy:		91.09 %
Epoch 1237 of 2000 took 0.097s
  training loss:		0.150764
  validation loss:		0.393496
  validation accuracy:		90.76 %
Epoch 1238 of 2000 took 0.097s
  training loss:		0.149307
  validation loss:		0.391170
  validation accuracy:		90.76 %
Epoch 1239 of 2000 took 0.097s
  training loss:		0.148923
  validation loss:		0.385226
  validation accuracy:		90.87 %
Epoch 1240 of 2000 took 0.097s
  training loss:		0.146990
  validation loss:		0.375545
  validation accuracy:		91.20 %
Epoch 1241 of 2000 took 0.097s
  training loss:		0.159348
  validation loss:		0.390083
  validation accuracy:		90.65 %
Epoch 1242 of 2000 took 0.097s
  training loss:		0.149234
  validation loss:		0.381711
  validation accuracy:		90.87 %
Epoch 1243 of 2000 took 0.097s
  training loss:		0.156965
  validation loss:		0.378715
  validation accuracy:		91.09 %
Epoch 1244 of 2000 took 0.097s
  training loss:		0.147694
  validation loss:		0.408483
  validation accuracy:		90.76 %
Epoch 1245 of 2000 took 0.097s
  training loss:		0.160546
  validation loss:		0.388689
  validation accuracy:		90.87 %
Epoch 1246 of 2000 took 0.097s
  training loss:		0.155198
  validation loss:		0.383868
  validation accuracy:		90.98 %
Epoch 1247 of 2000 took 0.097s
  training loss:		0.153878
  validation loss:		0.394037
  validation accuracy:		90.76 %
Epoch 1248 of 2000 took 0.097s
  training loss:		0.159556
  validation loss:		0.390383
  validation accuracy:		90.76 %
Epoch 1249 of 2000 took 0.097s
  training loss:		0.148675
  validation loss:		0.391139
  validation accuracy:		90.65 %
Epoch 1250 of 2000 took 0.097s
  training loss:		0.154592
  validation loss:		0.394215
  validation accuracy:		90.76 %
Epoch 1251 of 2000 took 0.097s
  training loss:		0.156635
  validation loss:		0.380577
  validation accuracy:		90.87 %
Epoch 1252 of 2000 took 0.097s
  training loss:		0.150438
  validation loss:		0.399082
  validation accuracy:		90.33 %
Epoch 1253 of 2000 took 0.097s
  training loss:		0.153273
  validation loss:		0.382614
  validation accuracy:		90.76 %
Epoch 1254 of 2000 took 0.097s
  training loss:		0.148484
  validation loss:		0.371528
  validation accuracy:		91.09 %
Epoch 1255 of 2000 took 0.097s
  training loss:		0.149534
  validation loss:		0.406318
  validation accuracy:		90.43 %
Epoch 1256 of 2000 took 0.097s
  training loss:		0.152542
  validation loss:		0.386516
  validation accuracy:		90.98 %
Epoch 1257 of 2000 took 0.097s
  training loss:		0.157920
  validation loss:		0.404510
  validation accuracy:		90.22 %
Epoch 1258 of 2000 took 0.097s
  training loss:		0.154758
  validation loss:		0.416994
  validation accuracy:		90.22 %
Epoch 1259 of 2000 took 0.097s
  training loss:		0.160680
  validation loss:		0.382747
  validation accuracy:		90.76 %
Epoch 1260 of 2000 took 0.097s
  training loss:		0.152180
  validation loss:		0.384815
  validation accuracy:		90.98 %
Epoch 1261 of 2000 took 0.097s
  training loss:		0.151454
  validation loss:		0.385876
  validation accuracy:		90.98 %
Epoch 1262 of 2000 took 0.097s
  training loss:		0.158914
  validation loss:		0.404236
  validation accuracy:		90.43 %
Epoch 1263 of 2000 took 0.097s
  training loss:		0.150031
  validation loss:		0.408299
  validation accuracy:		90.54 %
Epoch 1264 of 2000 took 0.097s
  training loss:		0.151732
  validation loss:		0.388941
  validation accuracy:		90.87 %
Epoch 1265 of 2000 took 0.097s
  training loss:		0.150722
  validation loss:		0.400542
  validation accuracy:		90.65 %
Epoch 1266 of 2000 took 0.097s
  training loss:		0.148077
  validation loss:		0.385835
  validation accuracy:		90.76 %
Epoch 1267 of 2000 took 0.097s
  training loss:		0.150967
  validation loss:		0.386705
  validation accuracy:		90.54 %
Epoch 1268 of 2000 took 0.097s
  training loss:		0.152044
  validation loss:		0.396142
  validation accuracy:		90.65 %
Epoch 1269 of 2000 took 0.097s
  training loss:		0.151330
  validation loss:		0.402220
  validation accuracy:		90.54 %
Epoch 1270 of 2000 took 0.097s
  training loss:		0.148027
  validation loss:		0.396981
  validation accuracy:		90.76 %
Epoch 1271 of 2000 took 0.097s
  training loss:		0.158704
  validation loss:		0.413093
  validation accuracy:		90.65 %
Epoch 1272 of 2000 took 0.097s
  training loss:		0.152348
  validation loss:		0.420646
  validation accuracy:		90.65 %
Epoch 1273 of 2000 took 0.097s
  training loss:		0.155288
  validation loss:		0.411107
  validation accuracy:		90.11 %
Epoch 1274 of 2000 took 0.097s
  training loss:		0.155455
  validation loss:		0.398816
  validation accuracy:		90.87 %
Epoch 1275 of 2000 took 0.097s
  training loss:		0.160042
  validation loss:		0.399936
  validation accuracy:		90.54 %
Epoch 1276 of 2000 took 0.097s
  training loss:		0.152468
  validation loss:		0.399208
  validation accuracy:		90.54 %
Epoch 1277 of 2000 took 0.097s
  training loss:		0.155083
  validation loss:		0.388761
  validation accuracy:		90.65 %
Epoch 1278 of 2000 took 0.097s
  training loss:		0.161517
  validation loss:		0.399057
  validation accuracy:		90.54 %
Epoch 1279 of 2000 took 0.097s
  training loss:		0.150873
  validation loss:		0.393839
  validation accuracy:		90.65 %
Epoch 1280 of 2000 took 0.097s
  training loss:		0.153140
  validation loss:		0.389673
  validation accuracy:		90.76 %
Epoch 1281 of 2000 took 0.097s
  training loss:		0.150578
  validation loss:		0.394676
  validation accuracy:		90.87 %
Epoch 1282 of 2000 took 0.097s
  training loss:		0.152077
  validation loss:		0.399954
  validation accuracy:		90.76 %
Epoch 1283 of 2000 took 0.097s
  training loss:		0.156009
  validation loss:		0.405649
  validation accuracy:		90.33 %
Epoch 1284 of 2000 took 0.097s
  training loss:		0.156421
  validation loss:		0.410125
  validation accuracy:		90.33 %
Epoch 1285 of 2000 took 0.097s
  training loss:		0.154273
  validation loss:		0.392107
  validation accuracy:		90.98 %
Epoch 1286 of 2000 took 0.097s
  training loss:		0.152335
  validation loss:		0.421471
  validation accuracy:		90.11 %
Epoch 1287 of 2000 took 0.097s
  training loss:		0.151406
  validation loss:		0.398153
  validation accuracy:		90.98 %
Epoch 1288 of 2000 took 0.097s
  training loss:		0.149878
  validation loss:		0.405458
  validation accuracy:		90.65 %
Epoch 1289 of 2000 took 0.097s
  training loss:		0.143340
  validation loss:		0.392646
  validation accuracy:		90.87 %
Epoch 1290 of 2000 took 0.097s
  training loss:		0.151997
  validation loss:		0.411456
  validation accuracy:		90.65 %
Epoch 1291 of 2000 took 0.097s
  training loss:		0.153912
  validation loss:		0.411628
  validation accuracy:		90.65 %
Epoch 1292 of 2000 took 0.097s
  training loss:		0.149963
  validation loss:		0.413728
  validation accuracy:		90.11 %
Epoch 1293 of 2000 took 0.097s
  training loss:		0.144066
  validation loss:		0.399496
  validation accuracy:		90.65 %
Epoch 1294 of 2000 took 0.097s
  training loss:		0.151839
  validation loss:		0.401430
  validation accuracy:		90.87 %
Epoch 1295 of 2000 took 0.097s
  training loss:		0.156724
  validation loss:		0.414327
  validation accuracy:		90.22 %
Epoch 1296 of 2000 took 0.097s
  training loss:		0.152346
  validation loss:		0.391566
  validation accuracy:		90.76 %
Epoch 1297 of 2000 took 0.097s
  training loss:		0.152363
  validation loss:		0.391976
  validation accuracy:		91.20 %
Epoch 1298 of 2000 took 0.097s
  training loss:		0.151727
  validation loss:		0.390656
  validation accuracy:		90.98 %
Epoch 1299 of 2000 took 0.097s
  training loss:		0.151294
  validation loss:		0.404578
  validation accuracy:		90.43 %
Epoch 1300 of 2000 took 0.097s
  training loss:		0.161754
  validation loss:		0.427744
  validation accuracy:		90.11 %
Epoch 1301 of 2000 took 0.097s
  training loss:		0.147550
  validation loss:		0.422434
  validation accuracy:		90.11 %
Epoch 1302 of 2000 took 0.097s
  training loss:		0.151365
  validation loss:		0.406596
  validation accuracy:		90.87 %
Epoch 1303 of 2000 took 0.097s
  training loss:		0.155137
  validation loss:		0.416498
  validation accuracy:		90.22 %
Epoch 1304 of 2000 took 0.097s
  training loss:		0.149617
  validation loss:		0.407193
  validation accuracy:		90.43 %
Epoch 1305 of 2000 took 0.097s
  training loss:		0.151078
  validation loss:		0.397373
  validation accuracy:		90.87 %
Epoch 1306 of 2000 took 0.097s
  training loss:		0.152369
  validation loss:		0.390028
  validation accuracy:		90.87 %
Epoch 1307 of 2000 took 0.097s
  training loss:		0.152682
  validation loss:		0.400251
  validation accuracy:		90.33 %
Epoch 1308 of 2000 took 0.097s
  training loss:		0.150982
  validation loss:		0.389220
  validation accuracy:		90.54 %
Epoch 1309 of 2000 took 0.097s
  training loss:		0.152594
  validation loss:		0.401377
  validation accuracy:		90.65 %
Epoch 1310 of 2000 took 0.097s
  training loss:		0.151488
  validation loss:		0.413032
  validation accuracy:		90.54 %
Epoch 1311 of 2000 took 0.097s
  training loss:		0.151725
  validation loss:		0.398121
  validation accuracy:		90.65 %
Epoch 1312 of 2000 took 0.097s
  training loss:		0.147974
  validation loss:		0.402888
  validation accuracy:		90.54 %
Epoch 1313 of 2000 took 0.097s
  training loss:		0.152197
  validation loss:		0.402064
  validation accuracy:		90.54 %
Epoch 1314 of 2000 took 0.097s
  training loss:		0.150291
  validation loss:		0.404705
  validation accuracy:		90.76 %
Epoch 1315 of 2000 took 0.097s
  training loss:		0.155653
  validation loss:		0.404339
  validation accuracy:		90.76 %
Epoch 1316 of 2000 took 0.097s
  training loss:		0.146235
  validation loss:		0.418519
  validation accuracy:		90.22 %
Epoch 1317 of 2000 took 0.097s
  training loss:		0.158461
  validation loss:		0.432246
  validation accuracy:		90.11 %
Epoch 1318 of 2000 took 0.097s
  training loss:		0.154425
  validation loss:		0.400256
  validation accuracy:		90.65 %
Epoch 1319 of 2000 took 0.097s
  training loss:		0.155103
  validation loss:		0.402974
  validation accuracy:		90.54 %
Epoch 1320 of 2000 took 0.097s
  training loss:		0.153785
  validation loss:		0.415363
  validation accuracy:		90.76 %
Epoch 1321 of 2000 took 0.097s
  training loss:		0.149281
  validation loss:		0.399283
  validation accuracy:		90.76 %
Epoch 1322 of 2000 took 0.098s
  training loss:		0.148447
  validation loss:		0.389324
  validation accuracy:		90.98 %
Epoch 1323 of 2000 took 0.102s
  training loss:		0.147894
  validation loss:		0.419971
  validation accuracy:		90.22 %
Epoch 1324 of 2000 took 0.110s
  training loss:		0.157318
  validation loss:		0.414658
  validation accuracy:		90.87 %
Epoch 1325 of 2000 took 0.135s
  training loss:		0.160136
  validation loss:		0.396780
  validation accuracy:		90.76 %
Epoch 1326 of 2000 took 0.097s
  training loss:		0.151455
  validation loss:		0.404814
  validation accuracy:		90.76 %
Epoch 1327 of 2000 took 0.098s
  training loss:		0.149091
  validation loss:		0.402470
  validation accuracy:		90.65 %
Epoch 1328 of 2000 took 0.100s
  training loss:		0.154083
  validation loss:		0.419273
  validation accuracy:		90.33 %
Epoch 1329 of 2000 took 0.100s
  training loss:		0.146782
  validation loss:		0.390334
  validation accuracy:		90.65 %
Epoch 1330 of 2000 took 0.098s
  training loss:		0.146788
  validation loss:		0.421448
  validation accuracy:		90.54 %
Epoch 1331 of 2000 took 0.097s
  training loss:		0.154442
  validation loss:		0.396941
  validation accuracy:		90.65 %
Epoch 1332 of 2000 took 0.097s
  training loss:		0.147269
  validation loss:		0.397897
  validation accuracy:		90.76 %
Epoch 1333 of 2000 took 0.097s
  training loss:		0.153468
  validation loss:		0.400832
  validation accuracy:		90.76 %
Epoch 1334 of 2000 took 0.096s
  training loss:		0.153801
  validation loss:		0.402890
  validation accuracy:		90.33 %
Epoch 1335 of 2000 took 0.096s
  training loss:		0.151110
  validation loss:		0.416320
  validation accuracy:		90.87 %
Epoch 1336 of 2000 took 0.096s
  training loss:		0.147652
  validation loss:		0.427863
  validation accuracy:		90.22 %
Epoch 1337 of 2000 took 0.096s
  training loss:		0.147141
  validation loss:		0.410317
  validation accuracy:		90.54 %
Epoch 1338 of 2000 took 0.096s
  training loss:		0.154317
  validation loss:		0.410694
  validation accuracy:		91.09 %
Epoch 1339 of 2000 took 0.096s
  training loss:		0.162673
  validation loss:		0.392410
  validation accuracy:		90.76 %
Epoch 1340 of 2000 took 0.096s
  training loss:		0.150870
  validation loss:		0.412093
  validation accuracy:		90.54 %
Epoch 1341 of 2000 took 0.097s
  training loss:		0.156069
  validation loss:		0.411184
  validation accuracy:		90.54 %
Epoch 1342 of 2000 took 0.096s
  training loss:		0.153552
  validation loss:		0.403889
  validation accuracy:		90.76 %
Epoch 1343 of 2000 took 0.097s
  training loss:		0.150486
  validation loss:		0.424544
  validation accuracy:		90.22 %
Epoch 1344 of 2000 took 0.097s
  training loss:		0.150557
  validation loss:		0.396196
  validation accuracy:		90.43 %
Epoch 1345 of 2000 took 0.096s
  training loss:		0.153196
  validation loss:		0.407841
  validation accuracy:		90.76 %
Epoch 1346 of 2000 took 0.097s
  training loss:		0.157849
  validation loss:		0.413341
  validation accuracy:		90.65 %
Epoch 1347 of 2000 took 0.096s
  training loss:		0.144795
  validation loss:		0.399533
  validation accuracy:		90.87 %
Epoch 1348 of 2000 took 0.097s
  training loss:		0.154884
  validation loss:		0.400748
  validation accuracy:		90.65 %
Epoch 1349 of 2000 took 0.096s
  training loss:		0.152904
  validation loss:		0.393488
  validation accuracy:		90.87 %
Epoch 1350 of 2000 took 0.096s
  training loss:		0.153044
  validation loss:		0.427624
  validation accuracy:		90.33 %
Epoch 1351 of 2000 took 0.096s
  training loss:		0.153263
  validation loss:		0.401209
  validation accuracy:		90.65 %
Epoch 1352 of 2000 took 0.097s
  training loss:		0.152541
  validation loss:		0.419688
  validation accuracy:		90.33 %
Epoch 1353 of 2000 took 0.097s
  training loss:		0.145099
  validation loss:		0.394604
  validation accuracy:		90.76 %
Epoch 1354 of 2000 took 0.096s
  training loss:		0.145102
  validation loss:		0.406777
  validation accuracy:		90.54 %
Epoch 1355 of 2000 took 0.097s
  training loss:		0.149667
  validation loss:		0.422473
  validation accuracy:		90.11 %
Epoch 1356 of 2000 took 0.096s
  training loss:		0.146740
  validation loss:		0.419515
  validation accuracy:		90.22 %
Epoch 1357 of 2000 took 0.096s
  training loss:		0.149381
  validation loss:		0.423553
  validation accuracy:		90.11 %
Epoch 1358 of 2000 took 0.097s
  training loss:		0.154191
  validation loss:		0.436683
  validation accuracy:		90.00 %
Epoch 1359 of 2000 took 0.097s
  training loss:		0.143541
  validation loss:		0.416968
  validation accuracy:		90.22 %
Epoch 1360 of 2000 took 0.096s
  training loss:		0.159112
  validation loss:		0.449537
  validation accuracy:		89.46 %
Epoch 1361 of 2000 took 0.097s
  training loss:		0.153241
  validation loss:		0.414823
  validation accuracy:		90.54 %
Epoch 1362 of 2000 took 0.097s
  training loss:		0.148613
  validation loss:		0.425227
  validation accuracy:		90.22 %
Epoch 1363 of 2000 took 0.096s
  training loss:		0.151732
  validation loss:		0.432924
  validation accuracy:		90.00 %
Epoch 1364 of 2000 took 0.098s
  training loss:		0.151252
  validation loss:		0.401695
  validation accuracy:		90.87 %
Epoch 1365 of 2000 took 0.140s
  training loss:		0.146567
  validation loss:		0.409011
  validation accuracy:		90.33 %
Epoch 1366 of 2000 took 0.165s
  training loss:		0.145630
  validation loss:		0.409434
  validation accuracy:		90.76 %
Epoch 1367 of 2000 took 0.164s
  training loss:		0.152576
  validation loss:		0.427813
  validation accuracy:		90.22 %
Epoch 1368 of 2000 took 0.164s
  training loss:		0.150829
  validation loss:		0.401711
  validation accuracy:		90.65 %
Epoch 1369 of 2000 took 0.164s
  training loss:		0.145788
  validation loss:		0.396442
  validation accuracy:		90.65 %
Epoch 1370 of 2000 took 0.164s
  training loss:		0.152627
  validation loss:		0.429845
  validation accuracy:		90.33 %
Epoch 1371 of 2000 took 0.164s
  training loss:		0.164391
  validation loss:		0.417123
  validation accuracy:		90.22 %
Epoch 1372 of 2000 took 0.165s
  training loss:		0.149120
  validation loss:		0.413922
  validation accuracy:		90.65 %
Epoch 1373 of 2000 took 0.165s
  training loss:		0.147077
  validation loss:		0.449497
  validation accuracy:		89.78 %
Epoch 1374 of 2000 took 0.164s
  training loss:		0.147886
  validation loss:		0.413120
  validation accuracy:		90.76 %
Epoch 1375 of 2000 took 0.164s
  training loss:		0.151621
  validation loss:		0.401441
  validation accuracy:		90.22 %
Epoch 1376 of 2000 took 0.162s
  training loss:		0.148167
  validation loss:		0.429773
  validation accuracy:		90.22 %
Epoch 1377 of 2000 took 0.164s
  training loss:		0.146473
  validation loss:		0.442739
  validation accuracy:		90.11 %
Epoch 1378 of 2000 took 0.164s
  training loss:		0.150377
  validation loss:		0.405314
  validation accuracy:		90.54 %
Epoch 1379 of 2000 took 0.164s
  training loss:		0.139893
  validation loss:		0.407320
  validation accuracy:		90.76 %
Epoch 1380 of 2000 took 0.164s
  training loss:		0.153134
  validation loss:		0.421673
  validation accuracy:		90.33 %
Epoch 1381 of 2000 took 0.164s
  training loss:		0.150515
  validation loss:		0.408348
  validation accuracy:		90.87 %
Epoch 1382 of 2000 took 0.164s
  training loss:		0.147988
  validation loss:		0.405745
  validation accuracy:		90.87 %
Epoch 1383 of 2000 took 0.164s
  training loss:		0.151544
  validation loss:		0.409356
  validation accuracy:		90.43 %
Epoch 1384 of 2000 took 0.164s
  training loss:		0.148105
  validation loss:		0.429932
  validation accuracy:		90.22 %
Epoch 1385 of 2000 took 0.164s
  training loss:		0.153812
  validation loss:		0.411984
  validation accuracy:		90.22 %
Epoch 1386 of 2000 took 0.164s
  training loss:		0.155770
  validation loss:		0.414977
  validation accuracy:		90.33 %
Epoch 1387 of 2000 took 0.164s
  training loss:		0.147131
  validation loss:		0.423642
  validation accuracy:		90.11 %
Epoch 1388 of 2000 took 0.162s
  training loss:		0.145933
  validation loss:		0.409866
  validation accuracy:		90.65 %
Epoch 1389 of 2000 took 0.164s
  training loss:		0.145505
  validation loss:		0.413425
  validation accuracy:		90.65 %
Epoch 1390 of 2000 took 0.164s
  training loss:		0.149186
  validation loss:		0.433677
  validation accuracy:		90.00 %
Epoch 1391 of 2000 took 0.165s
  training loss:		0.154427
  validation loss:		0.417586
  validation accuracy:		90.43 %
Epoch 1392 of 2000 took 0.165s
  training loss:		0.147816
  validation loss:		0.415582
  validation accuracy:		90.76 %
Epoch 1393 of 2000 took 0.190s
  training loss:		0.152979
  validation loss:		0.405892
  validation accuracy:		90.54 %
Epoch 1394 of 2000 took 0.232s
  training loss:		0.146366
  validation loss:		0.406598
  validation accuracy:		90.33 %
Epoch 1395 of 2000 took 0.164s
  training loss:		0.141657
  validation loss:		0.427821
  validation accuracy:		90.43 %
Epoch 1396 of 2000 took 0.161s
  training loss:		0.147424
  validation loss:		0.414041
  validation accuracy:		90.87 %
Epoch 1397 of 2000 took 0.164s
  training loss:		0.150910
  validation loss:		0.432913
  validation accuracy:		90.00 %
Epoch 1398 of 2000 took 0.164s
  training loss:		0.152002
  validation loss:		0.448920
  validation accuracy:		89.78 %
Epoch 1399 of 2000 took 0.172s
  training loss:		0.149865
  validation loss:		0.412902
  validation accuracy:		90.98 %
Epoch 1400 of 2000 took 0.326s
  training loss:		0.153421
  validation loss:		0.407710
  validation accuracy:		90.43 %
Epoch 1401 of 2000 took 0.217s
  training loss:		0.143907
  validation loss:		0.425952
  validation accuracy:		90.11 %
Epoch 1402 of 2000 took 0.166s
  training loss:		0.150111
  validation loss:		0.405800
  validation accuracy:		90.76 %
Epoch 1403 of 2000 took 0.166s
  training loss:		0.148071
  validation loss:		0.431794
  validation accuracy:		90.22 %
Epoch 1404 of 2000 took 0.224s
  training loss:		0.148928
  validation loss:		0.442753
  validation accuracy:		89.89 %
Epoch 1405 of 2000 took 0.164s
  training loss:		0.153617
  validation loss:		0.442112
  validation accuracy:		90.00 %
Epoch 1406 of 2000 took 0.162s
  training loss:		0.147763
  validation loss:		0.422871
  validation accuracy:		90.43 %
Epoch 1407 of 2000 took 0.165s
  training loss:		0.153873
  validation loss:		0.409988
  validation accuracy:		90.76 %
Epoch 1408 of 2000 took 0.165s
  training loss:		0.154404
  validation loss:		0.413527
  validation accuracy:		90.43 %
Epoch 1409 of 2000 took 0.165s
  training loss:		0.149629
  validation loss:		0.417981
  validation accuracy:		90.54 %
Epoch 1410 of 2000 took 0.165s
  training loss:		0.149119
  validation loss:		0.403476
  validation accuracy:		90.65 %
Epoch 1411 of 2000 took 0.165s
  training loss:		0.143012
  validation loss:		0.417288
  validation accuracy:		90.43 %
Epoch 1412 of 2000 took 0.165s
  training loss:		0.142113
  validation loss:		0.429322
  validation accuracy:		90.76 %
Epoch 1413 of 2000 took 0.165s
  training loss:		0.156133
  validation loss:		0.407757
  validation accuracy:		90.65 %
Epoch 1414 of 2000 took 0.165s
  training loss:		0.152118
  validation loss:		0.446804
  validation accuracy:		90.11 %
Epoch 1415 of 2000 took 0.165s
  training loss:		0.145605
  validation loss:		0.421333
  validation accuracy:		90.54 %
Epoch 1416 of 2000 took 0.165s
  training loss:		0.151970
  validation loss:		0.440473
  validation accuracy:		89.89 %
Epoch 1417 of 2000 took 0.181s
  training loss:		0.145664
  validation loss:		0.410103
  validation accuracy:		90.76 %
Epoch 1418 of 2000 took 0.165s
  training loss:		0.157245
  validation loss:		0.409110
  validation accuracy:		90.54 %
Epoch 1419 of 2000 took 0.165s
  training loss:		0.146369
  validation loss:		0.432716
  validation accuracy:		90.11 %
Epoch 1420 of 2000 took 0.165s
  training loss:		0.147757
  validation loss:		0.423668
  validation accuracy:		90.54 %
Epoch 1421 of 2000 took 0.165s
  training loss:		0.150811
  validation loss:		0.412369
  validation accuracy:		90.54 %
Epoch 1422 of 2000 took 0.165s
  training loss:		0.146632
  validation loss:		0.416033
  validation accuracy:		90.33 %
Epoch 1423 of 2000 took 0.165s
  training loss:		0.146185
  validation loss:		0.417570
  validation accuracy:		90.43 %
Epoch 1424 of 2000 took 0.165s
  training loss:		0.147149
  validation loss:		0.413569
  validation accuracy:		90.76 %
Epoch 1425 of 2000 took 0.165s
  training loss:		0.153772
  validation loss:		0.441930
  validation accuracy:		90.00 %
Epoch 1426 of 2000 took 0.165s
  training loss:		0.151122
  validation loss:		0.416154
  validation accuracy:		90.54 %
Epoch 1427 of 2000 took 0.165s
  training loss:		0.148572
  validation loss:		0.410218
  validation accuracy:		90.54 %
Epoch 1428 of 2000 took 0.165s
  training loss:		0.149284
  validation loss:		0.427605
  validation accuracy:		90.33 %
Epoch 1429 of 2000 took 0.225s
  training loss:		0.148833
  validation loss:		0.428228
  validation accuracy:		90.22 %
Epoch 1430 of 2000 took 0.263s
  training loss:		0.151836
  validation loss:		0.421047
  validation accuracy:		90.54 %
Epoch 1431 of 2000 took 0.187s
  training loss:		0.149373
  validation loss:		0.409480
  validation accuracy:		90.76 %
Epoch 1432 of 2000 took 0.246s
  training loss:		0.149839
  validation loss:		0.426916
  validation accuracy:		90.98 %
Epoch 1433 of 2000 took 0.165s
  training loss:		0.147479
  validation loss:		0.428471
  validation accuracy:		90.33 %
Epoch 1434 of 2000 took 0.166s
  training loss:		0.148138
  validation loss:		0.430344
  validation accuracy:		90.22 %
Epoch 1435 of 2000 took 0.170s
  training loss:		0.149548
  validation loss:		0.416988
  validation accuracy:		90.65 %
Epoch 1436 of 2000 took 0.170s
  training loss:		0.146248
  validation loss:		0.440297
  validation accuracy:		89.67 %
Epoch 1437 of 2000 took 0.167s
  training loss:		0.146322
  validation loss:		0.412924
  validation accuracy:		90.33 %
Epoch 1438 of 2000 took 0.279s
  training loss:		0.143633
  validation loss:		0.422454
  validation accuracy:		90.76 %
Epoch 1439 of 2000 took 0.169s
  training loss:		0.151339
  validation loss:		0.424969
  validation accuracy:		90.43 %
Epoch 1440 of 2000 took 0.213s
  training loss:		0.147413
  validation loss:		0.408202
  validation accuracy:		90.65 %
Epoch 1441 of 2000 took 0.168s
  training loss:		0.148895
  validation loss:		0.444901
  validation accuracy:		90.00 %
Epoch 1442 of 2000 took 0.170s
  training loss:		0.154804
  validation loss:		0.428183
  validation accuracy:		90.22 %
Epoch 1443 of 2000 took 0.170s
  training loss:		0.152200
  validation loss:		0.416016
  validation accuracy:		90.65 %
Epoch 1444 of 2000 took 0.166s
  training loss:		0.144148
  validation loss:		0.419178
  validation accuracy:		90.43 %
Epoch 1445 of 2000 took 0.170s
  training loss:		0.154006
  validation loss:		0.434664
  validation accuracy:		90.11 %
Epoch 1446 of 2000 took 0.170s
  training loss:		0.154653
  validation loss:		0.433553
  validation accuracy:		90.22 %
Epoch 1447 of 2000 took 0.166s
  training loss:		0.144650
  validation loss:		0.441139
  validation accuracy:		90.00 %
Epoch 1448 of 2000 took 0.168s
  training loss:		0.145999
  validation loss:		0.429538
  validation accuracy:		90.11 %
Epoch 1449 of 2000 took 0.166s
  training loss:		0.152722
  validation loss:		0.414253
  validation accuracy:		90.33 %
Epoch 1450 of 2000 took 0.165s
  training loss:		0.144530
  validation loss:		0.414943
  validation accuracy:		90.33 %
Epoch 1451 of 2000 took 0.169s
  training loss:		0.149490
  validation loss:		0.425660
  validation accuracy:		90.33 %
Epoch 1452 of 2000 took 0.166s
  training loss:		0.148749
  validation loss:		0.416676
  validation accuracy:		90.43 %
Epoch 1453 of 2000 took 0.166s
  training loss:		0.143610
  validation loss:		0.419810
  validation accuracy:		90.33 %
Epoch 1454 of 2000 took 0.168s
  training loss:		0.146567
  validation loss:		0.423627
  validation accuracy:		90.11 %
Epoch 1455 of 2000 took 0.171s
  training loss:		0.146477
  validation loss:		0.415531
  validation accuracy:		90.65 %
Epoch 1456 of 2000 took 0.166s
  training loss:		0.144258
  validation loss:		0.433528
  validation accuracy:		90.11 %
Epoch 1457 of 2000 took 0.166s
  training loss:		0.145291
  validation loss:		0.427751
  validation accuracy:		90.33 %
Epoch 1458 of 2000 took 0.167s
  training loss:		0.152324
  validation loss:		0.411846
  validation accuracy:		90.43 %
Epoch 1459 of 2000 took 0.166s
  training loss:		0.149940
  validation loss:		0.427093
  validation accuracy:		90.65 %
Epoch 1460 of 2000 took 0.168s
  training loss:		0.145226
  validation loss:		0.411314
  validation accuracy:		90.76 %
Epoch 1461 of 2000 took 0.169s
  training loss:		0.149215
  validation loss:		0.445820
  validation accuracy:		90.11 %
Epoch 1462 of 2000 took 0.168s
  training loss:		0.143918
  validation loss:		0.413348
  validation accuracy:		90.76 %
Epoch 1463 of 2000 took 0.171s
  training loss:		0.143791
  validation loss:		0.417913
  validation accuracy:		90.65 %
Epoch 1464 of 2000 took 0.230s
  training loss:		0.143202
  validation loss:		0.422273
  validation accuracy:		90.11 %
Epoch 1465 of 2000 took 0.169s
  training loss:		0.148568
  validation loss:		0.446790
  validation accuracy:		89.89 %
Epoch 1466 of 2000 took 0.166s
  training loss:		0.147059
  validation loss:		0.442691
  validation accuracy:		90.11 %
Epoch 1467 of 2000 took 0.167s
  training loss:		0.143805
  validation loss:		0.443346
  validation accuracy:		90.11 %
Epoch 1468 of 2000 took 0.167s
  training loss:		0.149643
  validation loss:		0.410937
  validation accuracy:		90.54 %
Epoch 1469 of 2000 took 0.171s
  training loss:		0.146646
  validation loss:		0.432051
  validation accuracy:		90.22 %
Epoch 1470 of 2000 took 0.171s
  training loss:		0.147824
  validation loss:		0.429171
  validation accuracy:		90.22 %
Epoch 1471 of 2000 took 0.167s
  training loss:		0.148216
  validation loss:		0.486904
  validation accuracy:		89.35 %
Epoch 1472 of 2000 took 0.167s
  training loss:		0.148244
  validation loss:		0.432619
  validation accuracy:		90.22 %
Epoch 1473 of 2000 took 0.171s
  training loss:		0.141642
  validation loss:		0.429900
  validation accuracy:		90.33 %
Epoch 1474 of 2000 took 0.271s
  training loss:		0.152723
  validation loss:		0.427857
  validation accuracy:		90.43 %
Epoch 1475 of 2000 took 0.188s
  training loss:		0.147289
  validation loss:		0.435112
  validation accuracy:		90.00 %
Epoch 1476 of 2000 took 0.325s
  training loss:		0.157745
  validation loss:		0.429987
  validation accuracy:		89.89 %
Epoch 1477 of 2000 took 0.241s
  training loss:		0.153000
  validation loss:		0.435715
  validation accuracy:		90.11 %
Epoch 1478 of 2000 took 0.170s
  training loss:		0.144592
  validation loss:		0.459228
  validation accuracy:		90.00 %
Epoch 1479 of 2000 took 0.173s
  training loss:		0.145637
  validation loss:		0.434608
  validation accuracy:		89.89 %
Epoch 1480 of 2000 took 0.171s
  training loss:		0.147516
  validation loss:		0.443990
  validation accuracy:		89.78 %
Epoch 1481 of 2000 took 0.166s
  training loss:		0.146846
  validation loss:		0.414832
  validation accuracy:		90.22 %
Epoch 1482 of 2000 took 0.168s
  training loss:		0.151500
  validation loss:		0.442557
  validation accuracy:		90.11 %
Epoch 1483 of 2000 took 0.166s
  training loss:		0.151911
  validation loss:		0.432936
  validation accuracy:		90.33 %
Epoch 1484 of 2000 took 0.168s
  training loss:		0.149933
  validation loss:		0.439213
  validation accuracy:		90.11 %
Epoch 1485 of 2000 took 0.169s
  training loss:		0.150365
  validation loss:		0.463437
  validation accuracy:		89.89 %
Epoch 1486 of 2000 took 0.167s
  training loss:		0.145024
  validation loss:		0.455095
  validation accuracy:		89.78 %
Epoch 1487 of 2000 took 0.166s
  training loss:		0.143365
  validation loss:		0.423485
  validation accuracy:		90.43 %
Epoch 1488 of 2000 took 0.183s
  training loss:		0.146789
  validation loss:		0.452412
  validation accuracy:		90.00 %
Epoch 1489 of 2000 took 0.219s
  training loss:		0.144880
  validation loss:		0.455220
  validation accuracy:		89.78 %
Epoch 1490 of 2000 took 0.197s
  training loss:		0.142052
  validation loss:		0.440614
  validation accuracy:		90.54 %
Epoch 1491 of 2000 took 0.166s
  training loss:		0.151684
  validation loss:		0.474091
  validation accuracy:		89.46 %
Epoch 1492 of 2000 took 0.171s
  training loss:		0.148283
  validation loss:		0.441806
  validation accuracy:		89.89 %
Epoch 1493 of 2000 took 0.168s
  training loss:		0.143544
  validation loss:		0.446637
  validation accuracy:		90.11 %
Epoch 1494 of 2000 took 0.166s
  training loss:		0.152100
  validation loss:		0.440709
  validation accuracy:		90.22 %
Epoch 1495 of 2000 took 0.171s
  training loss:		0.150785
  validation loss:		0.436513
  validation accuracy:		90.98 %
Epoch 1496 of 2000 took 0.171s
  training loss:		0.153450
  validation loss:		0.416842
  validation accuracy:		90.65 %
Epoch 1497 of 2000 took 0.167s
  training loss:		0.150294
  validation loss:		0.422060
  validation accuracy:		90.54 %
Epoch 1498 of 2000 took 0.167s
  training loss:		0.143931
  validation loss:		0.451114
  validation accuracy:		90.00 %
Epoch 1499 of 2000 took 0.166s
  training loss:		0.145657
  validation loss:		0.447795
  validation accuracy:		90.11 %
Epoch 1500 of 2000 took 0.171s
  training loss:		0.143963
  validation loss:		0.434797
  validation accuracy:		90.22 %
Epoch 1501 of 2000 took 0.168s
  training loss:		0.146774
  validation loss:		0.431913
  validation accuracy:		90.43 %
Epoch 1502 of 2000 took 0.166s
  training loss:		0.147190
  validation loss:		0.424570
  validation accuracy:		90.98 %
Epoch 1503 of 2000 took 0.172s
  training loss:		0.144423
  validation loss:		0.426441
  validation accuracy:		90.43 %
Epoch 1504 of 2000 took 0.169s
  training loss:		0.142471
  validation loss:		0.421437
  validation accuracy:		90.98 %
Epoch 1505 of 2000 took 0.167s
  training loss:		0.147712
  validation loss:		0.438741
  validation accuracy:		90.00 %
Epoch 1506 of 2000 took 0.170s
  training loss:		0.151021
  validation loss:		0.439190
  validation accuracy:		89.78 %
Epoch 1507 of 2000 took 0.167s
  training loss:		0.145856
  validation loss:		0.439495
  validation accuracy:		90.33 %
Epoch 1508 of 2000 took 0.170s
  training loss:		0.144200
  validation loss:		0.423091
  validation accuracy:		90.65 %
Epoch 1509 of 2000 took 0.166s
  training loss:		0.138618
  validation loss:		0.418123
  validation accuracy:		90.54 %
Epoch 1510 of 2000 took 0.167s
  training loss:		0.147840
  validation loss:		0.430977
  validation accuracy:		90.22 %
Epoch 1511 of 2000 took 0.169s
  training loss:		0.151879
  validation loss:		0.434609
  validation accuracy:		90.33 %
Epoch 1512 of 2000 took 0.169s
  training loss:		0.155593
  validation loss:		0.432032
  validation accuracy:		90.98 %
Epoch 1513 of 2000 took 0.112s
  training loss:		0.149936
  validation loss:		0.425709
  validation accuracy:		90.33 %
Epoch 1514 of 2000 took 0.103s
  training loss:		0.150517
  validation loss:		0.437916
  validation accuracy:		89.89 %
Epoch 1515 of 2000 took 0.100s
  training loss:		0.154452
  validation loss:		0.422712
  validation accuracy:		90.65 %
Epoch 1516 of 2000 took 0.108s
  training loss:		0.146563
  validation loss:		0.471939
  validation accuracy:		89.24 %
Epoch 1517 of 2000 took 0.108s
  training loss:		0.144359
  validation loss:		0.441809
  validation accuracy:		90.43 %
Epoch 1518 of 2000 took 0.107s
  training loss:		0.149010
  validation loss:		0.453105
  validation accuracy:		89.78 %
Epoch 1519 of 2000 took 0.106s
  training loss:		0.153131
  validation loss:		0.473241
  validation accuracy:		90.98 %
Epoch 1520 of 2000 took 0.100s
  training loss:		0.155304
  validation loss:		0.422123
  validation accuracy:		90.98 %
Epoch 1521 of 2000 took 0.100s
  training loss:		0.148664
  validation loss:		0.442256
  validation accuracy:		90.22 %
Epoch 1522 of 2000 took 0.101s
  training loss:		0.145004
  validation loss:		0.447880
  validation accuracy:		89.89 %
Epoch 1523 of 2000 took 0.100s
  training loss:		0.156799
  validation loss:		0.436802
  validation accuracy:		90.22 %
Epoch 1524 of 2000 took 0.102s
  training loss:		0.140012
  validation loss:		0.452968
  validation accuracy:		89.89 %
Epoch 1525 of 2000 took 0.100s
  training loss:		0.149768
  validation loss:		0.443163
  validation accuracy:		89.89 %
Epoch 1526 of 2000 took 0.101s
  training loss:		0.149529
  validation loss:		0.441489
  validation accuracy:		90.00 %
Epoch 1527 of 2000 took 0.101s
  training loss:		0.147323
  validation loss:		0.447326
  validation accuracy:		90.00 %
Epoch 1528 of 2000 took 0.100s
  training loss:		0.144055
  validation loss:		0.428468
  validation accuracy:		90.87 %
Epoch 1529 of 2000 took 0.101s
  training loss:		0.147385
  validation loss:		0.449910
  validation accuracy:		90.00 %
Epoch 1530 of 2000 took 0.104s
  training loss:		0.145375
  validation loss:		0.433878
  validation accuracy:		90.43 %
Epoch 1531 of 2000 took 0.102s
  training loss:		0.146342
  validation loss:		0.447414
  validation accuracy:		90.22 %
Epoch 1532 of 2000 took 0.101s
  training loss:		0.144352
  validation loss:		0.428698
  validation accuracy:		90.43 %
Epoch 1533 of 2000 took 0.103s
  training loss:		0.150818
  validation loss:		0.465067
  validation accuracy:		89.78 %
Epoch 1534 of 2000 took 0.103s
  training loss:		0.144407
  validation loss:		0.445032
  validation accuracy:		90.11 %
Epoch 1535 of 2000 took 0.103s
  training loss:		0.141755
  validation loss:		0.434997
  validation accuracy:		90.43 %
Epoch 1536 of 2000 took 0.103s
  training loss:		0.147470
  validation loss:		0.445705
  validation accuracy:		90.33 %
Epoch 1537 of 2000 took 0.103s
  training loss:		0.144992
  validation loss:		0.451483
  validation accuracy:		90.22 %
Epoch 1538 of 2000 took 0.106s
  training loss:		0.152396
  validation loss:		0.453148
  validation accuracy:		90.33 %
Epoch 1539 of 2000 took 0.103s
  training loss:		0.146275
  validation loss:		0.438963
  validation accuracy:		90.33 %
Epoch 1540 of 2000 took 0.103s
  training loss:		0.143026
  validation loss:		0.446142
  validation accuracy:		90.43 %
Epoch 1541 of 2000 took 0.103s
  training loss:		0.151336
  validation loss:		0.440800
  validation accuracy:		90.11 %
Epoch 1542 of 2000 took 0.103s
  training loss:		0.144178
  validation loss:		0.446227
  validation accuracy:		89.78 %
Epoch 1543 of 2000 took 0.103s
  training loss:		0.144069
  validation loss:		0.431757
  validation accuracy:		90.11 %
Epoch 1544 of 2000 took 0.103s
  training loss:		0.146178
  validation loss:		0.430212
  validation accuracy:		90.87 %
Epoch 1545 of 2000 took 0.103s
  training loss:		0.141680
  validation loss:		0.455819
  validation accuracy:		90.11 %
Epoch 1546 of 2000 took 0.103s
  training loss:		0.139932
  validation loss:		0.434461
  validation accuracy:		90.22 %
Epoch 1547 of 2000 took 0.103s
  training loss:		0.137807
  validation loss:		0.464187
  validation accuracy:		89.78 %
Epoch 1548 of 2000 took 0.103s
  training loss:		0.155642
  validation loss:		0.445906
  validation accuracy:		90.65 %
Epoch 1549 of 2000 took 0.103s
  training loss:		0.146930
  validation loss:		0.430581
  validation accuracy:		90.11 %
Epoch 1550 of 2000 took 0.103s
  training loss:		0.141480
  validation loss:		0.436349
  validation accuracy:		90.43 %
Epoch 1551 of 2000 took 0.103s
  training loss:		0.143101
  validation loss:		0.443712
  validation accuracy:		90.22 %
Epoch 1552 of 2000 took 0.103s
  training loss:		0.145881
  validation loss:		0.461899
  validation accuracy:		89.89 %
Epoch 1553 of 2000 took 0.103s
  training loss:		0.146410
  validation loss:		0.435480
  validation accuracy:		90.65 %
Epoch 1554 of 2000 took 0.104s
  training loss:		0.139315
  validation loss:		0.430325
  validation accuracy:		90.22 %
Epoch 1555 of 2000 took 0.103s
  training loss:		0.143557
  validation loss:		0.468746
  validation accuracy:		89.78 %
Epoch 1556 of 2000 took 0.103s
  training loss:		0.151120
  validation loss:		0.430250
  validation accuracy:		90.22 %
Epoch 1557 of 2000 took 0.103s
  training loss:		0.142083
  validation loss:		0.441285
  validation accuracy:		90.22 %
Epoch 1558 of 2000 took 0.106s
  training loss:		0.149738
  validation loss:		0.437256
  validation accuracy:		90.43 %
Epoch 1559 of 2000 took 0.103s
  training loss:		0.142673
  validation loss:		0.453380
  validation accuracy:		90.11 %
Epoch 1560 of 2000 took 0.103s
  training loss:		0.140195
  validation loss:		0.434296
  validation accuracy:		90.43 %
Epoch 1561 of 2000 took 0.103s
  training loss:		0.152531
  validation loss:		0.427924
  validation accuracy:		90.54 %
Epoch 1562 of 2000 took 0.103s
  training loss:		0.151313
  validation loss:		0.430109
  validation accuracy:		90.33 %
Epoch 1563 of 2000 took 0.103s
  training loss:		0.145568
  validation loss:		0.438030
  validation accuracy:		90.65 %
Epoch 1564 of 2000 took 0.103s
  training loss:		0.148108
  validation loss:		0.439747
  validation accuracy:		91.09 %
Epoch 1565 of 2000 took 0.103s
  training loss:		0.143824
  validation loss:		0.432855
  validation accuracy:		90.54 %
Epoch 1566 of 2000 took 0.103s
  training loss:		0.139050
  validation loss:		0.460273
  validation accuracy:		89.78 %
Epoch 1567 of 2000 took 0.103s
  training loss:		0.150001
  validation loss:		0.454662
  validation accuracy:		89.67 %
Epoch 1568 of 2000 took 0.103s
  training loss:		0.142369
  validation loss:		0.448009
  validation accuracy:		89.89 %
Epoch 1569 of 2000 took 0.103s
  training loss:		0.142542
  validation loss:		0.450123
  validation accuracy:		90.11 %
Epoch 1570 of 2000 took 0.103s
  training loss:		0.145818
  validation loss:		0.435706
  validation accuracy:		90.43 %
Epoch 1571 of 2000 took 0.103s
  training loss:		0.143067
  validation loss:		0.444327
  validation accuracy:		90.11 %
Epoch 1572 of 2000 took 0.103s
  training loss:		0.144413
  validation loss:		0.429211
  validation accuracy:		90.76 %
Epoch 1573 of 2000 took 0.103s
  training loss:		0.148161
  validation loss:		0.439048
  validation accuracy:		90.54 %
Epoch 1574 of 2000 took 0.103s
  training loss:		0.155861
  validation loss:		0.455885
  validation accuracy:		90.00 %
Epoch 1575 of 2000 took 0.103s
  training loss:		0.142667
  validation loss:		0.495578
  validation accuracy:		89.02 %
Epoch 1576 of 2000 took 0.103s
  training loss:		0.148563
  validation loss:		0.481912
  validation accuracy:		90.11 %
Epoch 1577 of 2000 took 0.103s
  training loss:		0.151581
  validation loss:		0.440383
  validation accuracy:		90.22 %
Epoch 1578 of 2000 took 0.103s
  training loss:		0.148110
  validation loss:		0.443064
  validation accuracy:		90.54 %
Epoch 1579 of 2000 took 0.103s
  training loss:		0.149579
  validation loss:		0.440054
  validation accuracy:		90.11 %
Epoch 1580 of 2000 took 0.103s
  training loss:		0.149416
  validation loss:		0.438320
  validation accuracy:		90.22 %
Epoch 1581 of 2000 took 0.106s
  training loss:		0.149356
  validation loss:		0.445531
  validation accuracy:		89.89 %
Epoch 1582 of 2000 took 0.103s
  training loss:		0.147292
  validation loss:		0.440903
  validation accuracy:		90.22 %
Epoch 1583 of 2000 took 0.103s
  training loss:		0.140511
  validation loss:		0.441745
  validation accuracy:		90.54 %
Epoch 1584 of 2000 took 0.103s
  training loss:		0.139966
  validation loss:		0.429597
  validation accuracy:		90.76 %
Epoch 1585 of 2000 took 0.103s
  training loss:		0.147322
  validation loss:		0.461401
  validation accuracy:		89.78 %
Epoch 1586 of 2000 took 0.103s
  training loss:		0.146185
  validation loss:		0.451000
  validation accuracy:		90.11 %
Epoch 1587 of 2000 took 0.103s
  training loss:		0.147246
  validation loss:		0.448289
  validation accuracy:		90.54 %
Epoch 1588 of 2000 took 0.103s
  training loss:		0.141443
  validation loss:		0.474999
  validation accuracy:		89.78 %
Epoch 1589 of 2000 took 0.103s
  training loss:		0.143919
  validation loss:		0.454751
  validation accuracy:		89.89 %
Epoch 1590 of 2000 took 0.103s
  training loss:		0.151712
  validation loss:		0.435642
  validation accuracy:		90.22 %
Epoch 1591 of 2000 took 0.103s
  training loss:		0.146797
  validation loss:		0.435707
  validation accuracy:		90.87 %
Epoch 1592 of 2000 took 0.103s
  training loss:		0.145303
  validation loss:		0.474995
  validation accuracy:		89.78 %
Epoch 1593 of 2000 took 0.103s
  training loss:		0.142816
  validation loss:		0.452848
  validation accuracy:		90.54 %
Epoch 1594 of 2000 took 0.103s
  training loss:		0.154152
  validation loss:		0.434474
  validation accuracy:		91.20 %
Epoch 1595 of 2000 took 0.104s
  training loss:		0.140435
  validation loss:		0.466317
  validation accuracy:		89.67 %
Epoch 1596 of 2000 took 0.103s
  training loss:		0.141528
  validation loss:		0.462839
  validation accuracy:		89.89 %
Epoch 1597 of 2000 took 0.103s
  training loss:		0.145309
  validation loss:		0.471701
  validation accuracy:		89.67 %
Epoch 1598 of 2000 took 0.103s
  training loss:		0.145572
  validation loss:		0.439138
  validation accuracy:		90.22 %
Epoch 1599 of 2000 took 0.103s
  training loss:		0.142526
  validation loss:		0.445206
  validation accuracy:		90.11 %
Epoch 1600 of 2000 took 0.103s
  training loss:		0.143127
  validation loss:		0.455264
  validation accuracy:		90.11 %
Epoch 1601 of 2000 took 0.103s
  training loss:		0.143138
  validation loss:		0.459189
  validation accuracy:		90.00 %
Epoch 1602 of 2000 took 0.103s
  training loss:		0.149569
  validation loss:		0.444590
  validation accuracy:		90.76 %
Epoch 1603 of 2000 took 0.103s
  training loss:		0.147221
  validation loss:		0.449638
  validation accuracy:		89.89 %
Epoch 1604 of 2000 took 0.103s
  training loss:		0.141203
  validation loss:		0.444648
  validation accuracy:		90.00 %
Epoch 1605 of 2000 took 0.103s
  training loss:		0.149378
  validation loss:		0.460963
  validation accuracy:		89.67 %
Epoch 1606 of 2000 took 0.104s
  training loss:		0.148005
  validation loss:		0.480803
  validation accuracy:		89.35 %
Epoch 1607 of 2000 took 0.108s
  training loss:		0.143747
  validation loss:		0.448238
  validation accuracy:		90.11 %
Epoch 1608 of 2000 took 0.103s
  training loss:		0.142460
  validation loss:		0.450048
  validation accuracy:		90.11 %
Epoch 1609 of 2000 took 0.103s
  training loss:		0.146176
  validation loss:		0.450460
  validation accuracy:		90.33 %
Epoch 1610 of 2000 took 0.104s
  training loss:		0.144260
  validation loss:		0.484944
  validation accuracy:		89.78 %
Epoch 1611 of 2000 took 0.104s
  training loss:		0.147545
  validation loss:		0.440601
  validation accuracy:		90.76 %
Epoch 1612 of 2000 took 0.104s
  training loss:		0.149450
  validation loss:		0.442182
  validation accuracy:		90.33 %
Epoch 1613 of 2000 took 0.104s
  training loss:		0.146729
  validation loss:		0.470790
  validation accuracy:		90.33 %
Epoch 1614 of 2000 took 0.104s
  training loss:		0.154679
  validation loss:		0.439544
  validation accuracy:		90.22 %
Epoch 1615 of 2000 took 0.104s
  training loss:		0.141647
  validation loss:		0.444937
  validation accuracy:		90.00 %
Epoch 1616 of 2000 took 0.104s
  training loss:		0.142683
  validation loss:		0.469145
  validation accuracy:		89.46 %
Epoch 1617 of 2000 took 0.104s
  training loss:		0.150152
  validation loss:		0.470905
  validation accuracy:		89.57 %
Epoch 1618 of 2000 took 0.104s
  training loss:		0.145688
  validation loss:		0.485346
  validation accuracy:		89.46 %
Epoch 1619 of 2000 took 0.104s
  training loss:		0.151490
  validation loss:		0.441757
  validation accuracy:		90.76 %
Epoch 1620 of 2000 took 0.104s
  training loss:		0.154102
  validation loss:		0.431438
  validation accuracy:		90.98 %
Epoch 1621 of 2000 took 0.104s
  training loss:		0.152533
  validation loss:		0.445587
  validation accuracy:		90.33 %
Epoch 1622 of 2000 took 0.103s
  training loss:		0.142237
  validation loss:		0.447603
  validation accuracy:		90.00 %
Epoch 1623 of 2000 took 0.104s
  training loss:		0.141674
  validation loss:		0.439472
  validation accuracy:		90.65 %
Epoch 1624 of 2000 took 0.105s
  training loss:		0.148830
  validation loss:		0.471601
  validation accuracy:		90.22 %
Epoch 1625 of 2000 took 0.104s
  training loss:		0.141337
  validation loss:		0.464744
  validation accuracy:		90.33 %
Epoch 1626 of 2000 took 0.104s
  training loss:		0.145944
  validation loss:		0.450129
  validation accuracy:		89.89 %
Epoch 1627 of 2000 took 0.104s
  training loss:		0.140240
  validation loss:		0.465888
  validation accuracy:		89.89 %
Epoch 1628 of 2000 took 0.104s
  training loss:		0.147240
  validation loss:		0.444254
  validation accuracy:		90.22 %
Epoch 1629 of 2000 took 0.104s
  training loss:		0.141164
  validation loss:		0.459281
  validation accuracy:		89.78 %
Epoch 1630 of 2000 took 0.104s
  training loss:		0.147889
  validation loss:		0.444759
  validation accuracy:		90.33 %
Epoch 1631 of 2000 took 0.104s
  training loss:		0.143162
  validation loss:		0.434861
  validation accuracy:		90.54 %
Epoch 1632 of 2000 took 0.103s
  training loss:		0.143713
  validation loss:		0.457730
  validation accuracy:		90.11 %
Epoch 1633 of 2000 took 0.104s
  training loss:		0.145743
  validation loss:		0.461204
  validation accuracy:		89.78 %
Epoch 1634 of 2000 took 0.106s
  training loss:		0.142549
  validation loss:		0.456033
  validation accuracy:		90.33 %
Epoch 1635 of 2000 took 0.104s
  training loss:		0.146738
  validation loss:		0.459887
  validation accuracy:		90.11 %
Epoch 1636 of 2000 took 0.104s
  training loss:		0.140527
  validation loss:		0.448557
  validation accuracy:		90.33 %
Epoch 1637 of 2000 took 0.104s
  training loss:		0.140560
  validation loss:		0.457215
  validation accuracy:		90.54 %
Epoch 1638 of 2000 took 0.104s
  training loss:		0.145404
  validation loss:		0.456866
  validation accuracy:		90.65 %
Epoch 1639 of 2000 took 0.104s
  training loss:		0.144772
  validation loss:		0.459865
  validation accuracy:		90.43 %
Epoch 1640 of 2000 took 0.104s
  training loss:		0.145216
  validation loss:		0.452166
  validation accuracy:		90.54 %
Epoch 1641 of 2000 took 0.104s
  training loss:		0.141416
  validation loss:		0.458449
  validation accuracy:		90.43 %
Epoch 1642 of 2000 took 0.104s
  training loss:		0.145731
  validation loss:		0.455165
  validation accuracy:		89.78 %
Epoch 1643 of 2000 took 0.104s
  training loss:		0.147431
  validation loss:		0.451209
  validation accuracy:		90.11 %
Epoch 1644 of 2000 took 0.104s
  training loss:		0.143912
  validation loss:		0.469435
  validation accuracy:		89.78 %
Epoch 1645 of 2000 took 0.104s
  training loss:		0.144897
  validation loss:		0.447059
  validation accuracy:		90.65 %
Epoch 1646 of 2000 took 0.104s
  training loss:		0.149638
  validation loss:		0.472375
  validation accuracy:		89.24 %
Epoch 1647 of 2000 took 0.104s
  training loss:		0.140750
  validation loss:		0.456987
  validation accuracy:		89.78 %
Epoch 1648 of 2000 took 0.104s
  training loss:		0.138576
  validation loss:		0.462371
  validation accuracy:		90.00 %
Epoch 1649 of 2000 took 0.104s
  training loss:		0.143063
  validation loss:		0.450825
  validation accuracy:		90.33 %
Epoch 1650 of 2000 took 0.104s
  training loss:		0.144794
  validation loss:		0.441529
  validation accuracy:		90.76 %
Epoch 1651 of 2000 took 0.105s
  training loss:		0.140686
  validation loss:		0.460126
  validation accuracy:		90.11 %
Epoch 1652 of 2000 took 0.104s
  training loss:		0.144099
  validation loss:		0.448826
  validation accuracy:		90.43 %
Epoch 1653 of 2000 took 0.105s
  training loss:		0.144727
  validation loss:		0.467789
  validation accuracy:		89.67 %
Epoch 1654 of 2000 took 0.104s
  training loss:		0.144885
  validation loss:		0.449906
  validation accuracy:		90.33 %
Epoch 1655 of 2000 took 0.104s
  training loss:		0.145064
  validation loss:		0.461418
  validation accuracy:		90.00 %
Epoch 1656 of 2000 took 0.104s
  training loss:		0.146503
  validation loss:		0.482953
  validation accuracy:		89.57 %
Epoch 1657 of 2000 took 0.104s
  training loss:		0.151099
  validation loss:		0.452674
  validation accuracy:		89.89 %
Epoch 1658 of 2000 took 0.104s
  training loss:		0.151026
  validation loss:		0.456711
  validation accuracy:		90.87 %
Epoch 1659 of 2000 took 0.104s
  training loss:		0.146474
  validation loss:		0.452326
  validation accuracy:		90.65 %
Epoch 1660 of 2000 took 0.104s
  training loss:		0.141582
  validation loss:		0.466578
  validation accuracy:		89.57 %
Epoch 1661 of 2000 took 0.104s
  training loss:		0.151013
  validation loss:		0.439266
  validation accuracy:		90.65 %
Epoch 1662 of 2000 took 0.104s
  training loss:		0.141725
  validation loss:		0.465725
  validation accuracy:		89.89 %
Epoch 1663 of 2000 took 0.104s
  training loss:		0.144980
  validation loss:		0.459764
  validation accuracy:		89.89 %
Epoch 1664 of 2000 took 0.105s
  training loss:		0.148557
  validation loss:		0.466774
  validation accuracy:		89.89 %
Epoch 1665 of 2000 took 0.104s
  training loss:		0.143158
  validation loss:		0.479456
  validation accuracy:		89.57 %
Epoch 1666 of 2000 took 0.104s
  training loss:		0.139006
  validation loss:		0.456873
  validation accuracy:		90.33 %
Epoch 1667 of 2000 took 0.104s
  training loss:		0.145879
  validation loss:		0.451844
  validation accuracy:		90.87 %
Epoch 1668 of 2000 took 0.103s
  training loss:		0.144053
  validation loss:		0.443560
  validation accuracy:		90.87 %
Epoch 1669 of 2000 took 0.104s
  training loss:		0.144367
  validation loss:		0.453089
  validation accuracy:		89.78 %
Epoch 1670 of 2000 took 0.106s
  training loss:		0.140209
  validation loss:		0.479435
  validation accuracy:		89.46 %
Epoch 1671 of 2000 took 0.107s
  training loss:		0.141481
  validation loss:		0.466730
  validation accuracy:		90.33 %
Epoch 1672 of 2000 took 0.107s
  training loss:		0.139305
  validation loss:		0.451127
  validation accuracy:		90.76 %
Epoch 1673 of 2000 took 0.107s
  training loss:		0.142908
  validation loss:		0.470997
  validation accuracy:		89.67 %
Epoch 1674 of 2000 took 0.107s
  training loss:		0.146741
  validation loss:		0.476794
  validation accuracy:		90.33 %
Epoch 1675 of 2000 took 0.107s
  training loss:		0.144183
  validation loss:		0.497458
  validation accuracy:		89.24 %
Epoch 1676 of 2000 took 0.107s
  training loss:		0.141789
  validation loss:		0.456071
  validation accuracy:		90.33 %
Epoch 1677 of 2000 took 0.107s
  training loss:		0.144683
  validation loss:		0.449355
  validation accuracy:		90.11 %
Epoch 1678 of 2000 took 0.107s
  training loss:		0.148119
  validation loss:		0.461211
  validation accuracy:		90.22 %
Epoch 1679 of 2000 took 0.107s
  training loss:		0.145813
  validation loss:		0.446959
  validation accuracy:		90.11 %
Epoch 1680 of 2000 took 0.107s
  training loss:		0.143249
  validation loss:		0.460834
  validation accuracy:		90.33 %
Epoch 1681 of 2000 took 0.108s
  training loss:		0.143114
  validation loss:		0.447886
  validation accuracy:		90.11 %
Epoch 1682 of 2000 took 0.104s
  training loss:		0.142014
  validation loss:		0.487021
  validation accuracy:		89.57 %
Epoch 1683 of 2000 took 0.104s
  training loss:		0.144709
  validation loss:		0.481087
  validation accuracy:		90.22 %
Epoch 1684 of 2000 took 0.104s
  training loss:		0.146764
  validation loss:		0.456297
  validation accuracy:		89.78 %
Epoch 1685 of 2000 took 0.104s
  training loss:		0.143890
  validation loss:		0.478245
  validation accuracy:		90.11 %
Epoch 1686 of 2000 took 0.104s
  training loss:		0.147806
  validation loss:		0.452745
  validation accuracy:		90.22 %
Epoch 1687 of 2000 took 0.104s
  training loss:		0.140615
  validation loss:		0.465207
  validation accuracy:		89.89 %
Epoch 1688 of 2000 took 0.104s
  training loss:		0.143616
  validation loss:		0.470980
  validation accuracy:		89.67 %
Epoch 1689 of 2000 took 0.104s
  training loss:		0.145734
  validation loss:		0.454876
  validation accuracy:		89.67 %
Epoch 1690 of 2000 took 0.104s
  training loss:		0.144751
  validation loss:		0.459118
  validation accuracy:		90.33 %
Epoch 1691 of 2000 took 0.104s
  training loss:		0.139715
  validation loss:		0.467714
  validation accuracy:		90.11 %
Epoch 1692 of 2000 took 0.104s
  training loss:		0.150839
  validation loss:		0.463143
  validation accuracy:		90.22 %
Epoch 1693 of 2000 took 0.104s
  training loss:		0.145337
  validation loss:		0.469709
  validation accuracy:		90.11 %
Epoch 1694 of 2000 took 0.104s
  training loss:		0.142566
  validation loss:		0.479382
  validation accuracy:		89.89 %
Epoch 1695 of 2000 took 0.104s
  training loss:		0.144340
  validation loss:		0.471243
  validation accuracy:		89.78 %
Epoch 1696 of 2000 took 0.104s
  training loss:		0.140924
  validation loss:		0.455892
  validation accuracy:		90.87 %
Epoch 1697 of 2000 took 0.105s
  training loss:		0.144716
  validation loss:		0.466189
  validation accuracy:		90.43 %
Epoch 1698 of 2000 took 0.104s
  training loss:		0.141845
  validation loss:		0.452906
  validation accuracy:		90.65 %
Epoch 1699 of 2000 took 0.104s
  training loss:		0.142580
  validation loss:		0.462374
  validation accuracy:		89.78 %
Epoch 1700 of 2000 took 0.104s
  training loss:		0.137924
  validation loss:		0.512069
  validation accuracy:		89.35 %
Epoch 1701 of 2000 took 0.104s
  training loss:		0.142978
  validation loss:		0.451198
  validation accuracy:		90.54 %
Epoch 1702 of 2000 took 0.104s
  training loss:		0.150825
  validation loss:		0.493938
  validation accuracy:		89.78 %
Epoch 1703 of 2000 took 0.104s
  training loss:		0.147788
  validation loss:		0.475938
  validation accuracy:		89.67 %
Epoch 1704 of 2000 took 0.103s
  training loss:		0.148202
  validation loss:		0.491048
  validation accuracy:		90.22 %
Epoch 1705 of 2000 took 0.103s
  training loss:		0.151586
  validation loss:		0.477964
  validation accuracy:		89.35 %
Epoch 1706 of 2000 took 0.104s
  training loss:		0.145851
  validation loss:		0.495296
  validation accuracy:		89.78 %
Epoch 1707 of 2000 took 0.104s
  training loss:		0.142473
  validation loss:		0.450806
  validation accuracy:		90.98 %
Epoch 1708 of 2000 took 0.104s
  training loss:		0.137802
  validation loss:		0.453951
  validation accuracy:		90.76 %
Epoch 1709 of 2000 took 0.104s
  training loss:		0.143338
  validation loss:		0.457606
  validation accuracy:		90.33 %
Epoch 1710 of 2000 took 0.105s
  training loss:		0.142769
  validation loss:		0.485133
  validation accuracy:		89.35 %
Epoch 1711 of 2000 took 0.104s
  training loss:		0.140945
  validation loss:		0.459079
  validation accuracy:		90.76 %
Epoch 1712 of 2000 took 0.104s
  training loss:		0.141428
  validation loss:		0.466738
  validation accuracy:		90.00 %
Epoch 1713 of 2000 took 0.104s
  training loss:		0.141635
  validation loss:		0.478266
  validation accuracy:		89.67 %
Epoch 1714 of 2000 took 0.104s
  training loss:		0.148100
  validation loss:		0.459194
  validation accuracy:		90.33 %
Epoch 1715 of 2000 took 0.104s
  training loss:		0.140879
  validation loss:		0.492765
  validation accuracy:		89.78 %
Epoch 1716 of 2000 took 0.104s
  training loss:		0.145575
  validation loss:		0.454413
  validation accuracy:		90.54 %
Epoch 1717 of 2000 took 0.104s
  training loss:		0.145675
  validation loss:		0.453342
  validation accuracy:		90.33 %
Epoch 1718 of 2000 took 0.104s
  training loss:		0.146430
  validation loss:		0.480542
  validation accuracy:		89.89 %
Epoch 1719 of 2000 took 0.104s
  training loss:		0.143861
  validation loss:		0.469761
  validation accuracy:		90.33 %
Epoch 1720 of 2000 took 0.104s
  training loss:		0.142523
  validation loss:		0.480089
  validation accuracy:		90.22 %
Epoch 1721 of 2000 took 0.104s
  training loss:		0.142930
  validation loss:		0.490699
  validation accuracy:		89.57 %
Epoch 1722 of 2000 took 0.103s
  training loss:		0.142589
  validation loss:		0.461578
  validation accuracy:		90.11 %
Epoch 1723 of 2000 took 0.104s
  training loss:		0.152386
  validation loss:		0.460910
  validation accuracy:		89.78 %
Epoch 1724 of 2000 took 0.104s
  training loss:		0.145022
  validation loss:		0.484186
  validation accuracy:		89.46 %
Epoch 1725 of 2000 took 0.104s
  training loss:		0.139801
  validation loss:		0.470557
  validation accuracy:		90.00 %
Epoch 1726 of 2000 took 0.103s
  training loss:		0.140857
  validation loss:		0.467292
  validation accuracy:		89.89 %
Epoch 1727 of 2000 took 0.105s
  training loss:		0.139484
  validation loss:		0.452361
  validation accuracy:		90.65 %
Epoch 1728 of 2000 took 0.104s
  training loss:		0.145387
  validation loss:		0.471456
  validation accuracy:		89.89 %
Epoch 1729 of 2000 took 0.104s
  training loss:		0.138047
  validation loss:		0.467790
  validation accuracy:		89.78 %
Epoch 1730 of 2000 took 0.104s
  training loss:		0.143303
  validation loss:		0.455624
  validation accuracy:		90.98 %
Epoch 1731 of 2000 took 0.104s
  training loss:		0.148795
  validation loss:		0.457204
  validation accuracy:		90.87 %
Epoch 1732 of 2000 took 0.104s
  training loss:		0.143936
  validation loss:		0.457066
  validation accuracy:		90.43 %
Epoch 1733 of 2000 took 0.104s
  training loss:		0.142887
  validation loss:		0.494218
  validation accuracy:		90.11 %
Epoch 1734 of 2000 took 0.104s
  training loss:		0.141098
  validation loss:		0.469656
  validation accuracy:		89.78 %
Epoch 1735 of 2000 took 0.104s
  training loss:		0.145343
  validation loss:		0.460915
  validation accuracy:		90.00 %
Epoch 1736 of 2000 took 0.104s
  training loss:		0.137258
  validation loss:		0.484543
  validation accuracy:		90.00 %
Epoch 1737 of 2000 took 0.104s
  training loss:		0.143498
  validation loss:		0.462507
  validation accuracy:		90.00 %
Epoch 1738 of 2000 took 0.104s
  training loss:		0.138251
  validation loss:		0.462812
  validation accuracy:		90.11 %
Epoch 1739 of 2000 took 0.104s
  training loss:		0.140627
  validation loss:		0.457626
  validation accuracy:		90.22 %
Epoch 1740 of 2000 took 0.104s
  training loss:		0.147821
  validation loss:		0.488416
  validation accuracy:		89.24 %
Epoch 1741 of 2000 took 0.104s
  training loss:		0.146799
  validation loss:		0.487845
  validation accuracy:		89.35 %
Epoch 1742 of 2000 took 0.104s
  training loss:		0.149599
  validation loss:		0.461390
  validation accuracy:		89.89 %
Epoch 1743 of 2000 took 0.104s
  training loss:		0.158352
  validation loss:		0.456665
  validation accuracy:		90.54 %
Epoch 1744 of 2000 took 0.104s
  training loss:		0.140644
  validation loss:		0.475535
  validation accuracy:		89.78 %
Epoch 1745 of 2000 took 0.104s
  training loss:		0.147972
  validation loss:		0.459755
  validation accuracy:		90.54 %
Epoch 1746 of 2000 took 0.103s
  training loss:		0.133151
  validation loss:		0.490153
  validation accuracy:		89.46 %
Epoch 1747 of 2000 took 0.105s
  training loss:		0.150570
  validation loss:		0.459817
  validation accuracy:		90.43 %
Epoch 1748 of 2000 took 0.104s
  training loss:		0.139529
  validation loss:		0.474442
  validation accuracy:		90.11 %
Epoch 1749 of 2000 took 0.104s
  training loss:		0.148970
  validation loss:		0.464710
  validation accuracy:		90.65 %
Epoch 1750 of 2000 took 0.104s
  training loss:		0.149029
  validation loss:		0.455740
  validation accuracy:		90.65 %
Epoch 1751 of 2000 took 0.103s
  training loss:		0.145155
  validation loss:		0.472353
  validation accuracy:		89.78 %
Epoch 1752 of 2000 took 0.104s
  training loss:		0.137180
  validation loss:		0.477343
  validation accuracy:		89.67 %
Epoch 1753 of 2000 took 0.104s
  training loss:		0.148691
  validation loss:		0.464934
  validation accuracy:		90.65 %
Epoch 1754 of 2000 took 0.106s
  training loss:		0.147227
  validation loss:		0.480853
  validation accuracy:		89.78 %
Epoch 1755 of 2000 took 0.104s
  training loss:		0.142733
  validation loss:		0.500624
  validation accuracy:		89.24 %
Epoch 1756 of 2000 took 0.104s
  training loss:		0.143061
  validation loss:		0.486251
  validation accuracy:		89.78 %
Epoch 1757 of 2000 took 0.104s
  training loss:		0.143600
  validation loss:		0.451056
  validation accuracy:		90.54 %
Epoch 1758 of 2000 took 0.104s
  training loss:		0.141470
  validation loss:		0.469087
  validation accuracy:		89.89 %
Epoch 1759 of 2000 took 0.104s
  training loss:		0.141052
  validation loss:		0.471809
  validation accuracy:		89.89 %
Epoch 1760 of 2000 took 0.104s
  training loss:		0.146405
  validation loss:		0.483828
  validation accuracy:		89.78 %
Epoch 1761 of 2000 took 0.104s
  training loss:		0.139043
  validation loss:		0.496654
  validation accuracy:		89.78 %
Epoch 1762 of 2000 took 0.104s
  training loss:		0.148561
  validation loss:		0.475263
  validation accuracy:		90.00 %
Epoch 1763 of 2000 took 0.104s
  training loss:		0.145633
  validation loss:		0.470518
  validation accuracy:		89.78 %
Epoch 1764 of 2000 took 0.104s
  training loss:		0.141382
  validation loss:		0.465220
  validation accuracy:		90.33 %
Epoch 1765 of 2000 took 0.104s
  training loss:		0.146003
  validation loss:		0.459720
  validation accuracy:		90.22 %
Epoch 1766 of 2000 took 0.104s
  training loss:		0.141997
  validation loss:		0.463874
  validation accuracy:		90.33 %
Epoch 1767 of 2000 took 0.104s
  training loss:		0.139307
  validation loss:		0.506977
  validation accuracy:		89.24 %
Epoch 1768 of 2000 took 0.104s
  training loss:		0.144191
  validation loss:		0.495711
  validation accuracy:		89.78 %
Epoch 1769 of 2000 took 0.104s
  training loss:		0.136281
  validation loss:		0.465303
  validation accuracy:		90.00 %
Epoch 1770 of 2000 took 0.104s
  training loss:		0.147885
  validation loss:		0.470567
  validation accuracy:		90.11 %
Epoch 1771 of 2000 took 0.101s
  training loss:		0.145306
  validation loss:		0.482943
  validation accuracy:		89.57 %
Epoch 1772 of 2000 took 0.097s
  training loss:		0.143029
  validation loss:		0.461776
  validation accuracy:		90.76 %
Epoch 1773 of 2000 took 0.097s
  training loss:		0.159910
  validation loss:		0.474232
  validation accuracy:		90.43 %
Epoch 1774 of 2000 took 0.097s
  training loss:		0.148367
  validation loss:		0.476790
  validation accuracy:		89.89 %
Epoch 1775 of 2000 took 0.096s
  training loss:		0.142191
  validation loss:		0.489488
  validation accuracy:		90.11 %
Epoch 1776 of 2000 took 0.096s
  training loss:		0.145648
  validation loss:		0.457723
  validation accuracy:		90.54 %
Epoch 1777 of 2000 took 0.096s
  training loss:		0.143523
  validation loss:		0.493034
  validation accuracy:		89.46 %
Epoch 1778 of 2000 took 0.096s
  training loss:		0.140927
  validation loss:		0.468185
  validation accuracy:		90.22 %
Epoch 1779 of 2000 took 0.100s
  training loss:		0.142095
  validation loss:		0.464021
  validation accuracy:		90.54 %
Epoch 1780 of 2000 took 0.098s
  training loss:		0.135702
  validation loss:		0.477559
  validation accuracy:		89.78 %
Epoch 1781 of 2000 took 0.097s
  training loss:		0.146182
  validation loss:		0.467353
  validation accuracy:		90.54 %
Epoch 1782 of 2000 took 0.103s
  training loss:		0.141160
  validation loss:		0.471369
  validation accuracy:		90.33 %
Epoch 1783 of 2000 took 0.096s
  training loss:		0.145255
  validation loss:		0.459276
  validation accuracy:		90.65 %
Epoch 1784 of 2000 took 0.097s
  training loss:		0.145321
  validation loss:		0.473226
  validation accuracy:		90.43 %
Epoch 1785 of 2000 took 0.096s
  training loss:		0.140162
  validation loss:		0.480629
  validation accuracy:		89.89 %
Epoch 1786 of 2000 took 0.098s
  training loss:		0.137510
  validation loss:		0.453844
  validation accuracy:		90.87 %
Epoch 1787 of 2000 took 0.101s
  training loss:		0.146719
  validation loss:		0.468309
  validation accuracy:		90.22 %
Epoch 1788 of 2000 took 0.096s
  training loss:		0.140642
  validation loss:		0.464305
  validation accuracy:		90.43 %
Epoch 1789 of 2000 took 0.097s
  training loss:		0.143376
  validation loss:		0.460862
  validation accuracy:		89.89 %
Epoch 1790 of 2000 took 0.103s
  training loss:		0.142537
  validation loss:		0.475512
  validation accuracy:		90.00 %
Epoch 1791 of 2000 took 0.096s
  training loss:		0.143883
  validation loss:		0.470169
  validation accuracy:		89.89 %
Epoch 1792 of 2000 took 0.097s
  training loss:		0.142778
  validation loss:		0.490845
  validation accuracy:		89.78 %
Epoch 1793 of 2000 took 0.096s
  training loss:		0.142943
  validation loss:		0.489818
  validation accuracy:		89.89 %
Epoch 1794 of 2000 took 0.100s
  training loss:		0.152439
  validation loss:		0.486498
  validation accuracy:		90.11 %
Epoch 1795 of 2000 took 0.099s
  training loss:		0.144268
  validation loss:		0.476054
  validation accuracy:		90.00 %
Epoch 1796 of 2000 took 0.096s
  training loss:		0.148483
  validation loss:		0.476504
  validation accuracy:		90.00 %
Epoch 1797 of 2000 took 0.099s
  training loss:		0.141394
  validation loss:		0.484299
  validation accuracy:		89.78 %
Epoch 1798 of 2000 took 0.100s
  training loss:		0.142215
  validation loss:		0.468016
  validation accuracy:		90.65 %
Epoch 1799 of 2000 took 0.097s
  training loss:		0.142967
  validation loss:		0.484756
  validation accuracy:		89.57 %
Epoch 1800 of 2000 took 0.097s
  training loss:		0.148764
  validation loss:		0.481142
  validation accuracy:		89.67 %
Epoch 1801 of 2000 took 0.096s
  training loss:		0.143842
  validation loss:		0.462104
  validation accuracy:		90.87 %
Epoch 1802 of 2000 took 0.100s
  training loss:		0.149583
  validation loss:		0.462436
  validation accuracy:		90.43 %
Epoch 1803 of 2000 took 0.097s
  training loss:		0.145504
  validation loss:		0.472960
  validation accuracy:		90.11 %
Epoch 1804 of 2000 took 0.097s
  training loss:		0.139799
  validation loss:		0.486958
  validation accuracy:		89.57 %
Epoch 1805 of 2000 took 0.097s
  training loss:		0.141364
  validation loss:		0.487805
  validation accuracy:		89.78 %
Epoch 1806 of 2000 took 0.096s
  training loss:		0.145280
  validation loss:		0.479347
  validation accuracy:		89.67 %
Epoch 1807 of 2000 took 0.096s
  training loss:		0.145466
  validation loss:		0.487075
  validation accuracy:		89.67 %
Epoch 1808 of 2000 took 0.097s
  training loss:		0.149297
  validation loss:		0.488147
  validation accuracy:		89.46 %
Epoch 1809 of 2000 took 0.097s
  training loss:		0.145149
  validation loss:		0.476738
  validation accuracy:		89.78 %
Epoch 1810 of 2000 took 0.096s
  training loss:		0.144121
  validation loss:		0.466892
  validation accuracy:		90.43 %
Epoch 1811 of 2000 took 0.096s
  training loss:		0.138113
  validation loss:		0.472715
  validation accuracy:		90.11 %
Epoch 1812 of 2000 took 0.098s
  training loss:		0.144530
  validation loss:		0.463407
  validation accuracy:		90.65 %
Epoch 1813 of 2000 took 0.097s
  training loss:		0.146449
  validation loss:		0.486365
  validation accuracy:		90.22 %
Epoch 1814 of 2000 took 0.097s
  training loss:		0.143941
  validation loss:		0.482313
  validation accuracy:		90.43 %
Epoch 1815 of 2000 took 0.096s
  training loss:		0.139381
  validation loss:		0.465656
  validation accuracy:		90.11 %
Epoch 1816 of 2000 took 0.097s
  training loss:		0.140745
  validation loss:		0.470337
  validation accuracy:		90.00 %
Epoch 1817 of 2000 took 0.097s
  training loss:		0.138380
  validation loss:		0.473793
  validation accuracy:		89.67 %
Epoch 1818 of 2000 took 0.097s
  training loss:		0.153520
  validation loss:		0.473711
  validation accuracy:		89.67 %
Epoch 1819 of 2000 took 0.096s
  training loss:		0.137466
  validation loss:		0.465000
  validation accuracy:		90.76 %
Epoch 1820 of 2000 took 0.097s
  training loss:		0.147756
  validation loss:		0.487427
  validation accuracy:		89.35 %
Epoch 1821 of 2000 took 0.096s
  training loss:		0.143881
  validation loss:		0.478406
  validation accuracy:		89.67 %
Epoch 1822 of 2000 took 0.096s
  training loss:		0.139223
  validation loss:		0.483493
  validation accuracy:		89.35 %
Epoch 1823 of 2000 took 0.097s
  training loss:		0.137129
  validation loss:		0.458327
  validation accuracy:		90.87 %
Epoch 1824 of 2000 took 0.097s
  training loss:		0.143464
  validation loss:		0.468195
  validation accuracy:		90.65 %
Epoch 1825 of 2000 took 0.096s
  training loss:		0.140255
  validation loss:		0.484252
  validation accuracy:		90.33 %
Epoch 1826 of 2000 took 0.096s
  training loss:		0.138286
  validation loss:		0.507089
  validation accuracy:		90.00 %
Epoch 1827 of 2000 took 0.098s
  training loss:		0.146394
  validation loss:		0.474905
  validation accuracy:		89.89 %
Epoch 1828 of 2000 took 0.096s
  training loss:		0.139148
  validation loss:		0.483583
  validation accuracy:		90.00 %
Epoch 1829 of 2000 took 0.097s
  training loss:		0.142867
  validation loss:		0.487741
  validation accuracy:		90.00 %
Epoch 1830 of 2000 took 0.097s
  training loss:		0.141029
  validation loss:		0.497919
  validation accuracy:		89.35 %
Epoch 1831 of 2000 took 0.097s
  training loss:		0.142061
  validation loss:		0.468204
  validation accuracy:		90.43 %
Epoch 1832 of 2000 took 0.096s
  training loss:		0.139574
  validation loss:		0.477682
  validation accuracy:		90.00 %
Epoch 1833 of 2000 took 0.097s
  training loss:		0.139508
  validation loss:		0.464428
  validation accuracy:		90.65 %
Epoch 1834 of 2000 took 0.096s
  training loss:		0.147008
  validation loss:		0.482903
  validation accuracy:		89.46 %
Epoch 1835 of 2000 took 0.096s
  training loss:		0.138955
  validation loss:		0.464153
  validation accuracy:		90.22 %
Epoch 1836 of 2000 took 0.096s
  training loss:		0.140653
  validation loss:		0.485460
  validation accuracy:		90.00 %
Epoch 1837 of 2000 took 0.096s
  training loss:		0.144085
  validation loss:		0.485010
  validation accuracy:		90.76 %
Epoch 1838 of 2000 took 0.096s
  training loss:		0.152612
  validation loss:		0.471804
  validation accuracy:		90.00 %
Epoch 1839 of 2000 took 0.096s
  training loss:		0.144387
  validation loss:		0.499307
  validation accuracy:		89.57 %
Epoch 1840 of 2000 took 0.098s
  training loss:		0.143106
  validation loss:		0.473912
  validation accuracy:		90.43 %
Epoch 1841 of 2000 took 0.096s
  training loss:		0.145292
  validation loss:		0.464608
  validation accuracy:		90.11 %
Epoch 1842 of 2000 took 0.096s
  training loss:		0.137905
  validation loss:		0.474464
  validation accuracy:		90.11 %
Epoch 1843 of 2000 took 0.097s
  training loss:		0.141915
  validation loss:		0.478504
  validation accuracy:		89.67 %
Epoch 1844 of 2000 took 0.096s
  training loss:		0.137518
  validation loss:		0.469612
  validation accuracy:		90.76 %
Epoch 1845 of 2000 took 0.097s
  training loss:		0.139459
  validation loss:		0.495950
  validation accuracy:		89.24 %
Epoch 1846 of 2000 took 0.096s
  training loss:		0.145431
  validation loss:		0.483277
  validation accuracy:		90.54 %
Epoch 1847 of 2000 took 0.096s
  training loss:		0.138957
  validation loss:		0.511599
  validation accuracy:		89.67 %
Epoch 1848 of 2000 took 0.097s
  training loss:		0.154216
  validation loss:		0.468234
  validation accuracy:		90.87 %
Epoch 1849 of 2000 took 0.096s
  training loss:		0.132516
  validation loss:		0.493473
  validation accuracy:		89.57 %
Epoch 1850 of 2000 took 0.097s
  training loss:		0.146132
  validation loss:		0.477829
  validation accuracy:		90.43 %
Epoch 1851 of 2000 took 0.096s
  training loss:		0.143930
  validation loss:		0.471880
  validation accuracy:		90.76 %
Epoch 1852 of 2000 took 0.098s
  training loss:		0.138831
  validation loss:		0.495089
  validation accuracy:		89.78 %
Epoch 1853 of 2000 took 0.097s
  training loss:		0.139746
  validation loss:		0.472424
  validation accuracy:		90.00 %
Epoch 1854 of 2000 took 0.097s
  training loss:		0.142309
  validation loss:		0.491381
  validation accuracy:		90.54 %
Epoch 1855 of 2000 took 0.097s
  training loss:		0.142115
  validation loss:		0.485833
  validation accuracy:		89.78 %
Epoch 1856 of 2000 took 0.096s
  training loss:		0.144524
  validation loss:		0.492963
  validation accuracy:		90.11 %
Epoch 1857 of 2000 took 0.096s
  training loss:		0.139326
  validation loss:		0.482837
  validation accuracy:		90.00 %
Epoch 1858 of 2000 took 0.096s
  training loss:		0.137645
  validation loss:		0.486847
  validation accuracy:		90.00 %
Epoch 1859 of 2000 took 0.096s
  training loss:		0.137341
  validation loss:		0.463568
  validation accuracy:		90.22 %
Epoch 1860 of 2000 took 0.097s
  training loss:		0.146530
  validation loss:		0.483341
  validation accuracy:		90.22 %
Epoch 1861 of 2000 took 0.097s
  training loss:		0.141518
  validation loss:		0.469627
  validation accuracy:		90.11 %
Epoch 1862 of 2000 took 0.098s
  training loss:		0.142635
  validation loss:		0.502707
  validation accuracy:		90.00 %
Epoch 1863 of 2000 took 0.096s
  training loss:		0.135138
  validation loss:		0.475555
  validation accuracy:		90.33 %
Epoch 1864 of 2000 took 0.097s
  training loss:		0.140094
  validation loss:		0.491939
  validation accuracy:		89.67 %
Epoch 1865 of 2000 took 0.096s
  training loss:		0.145961
  validation loss:		0.476350
  validation accuracy:		90.11 %
Epoch 1866 of 2000 took 0.096s
  training loss:		0.142266
  validation loss:		0.471397
  validation accuracy:		90.00 %
Epoch 1867 of 2000 took 0.096s
  training loss:		0.143565
  validation loss:		0.473719
  validation accuracy:		90.76 %
Epoch 1868 of 2000 took 0.096s
  training loss:		0.147823
  validation loss:		0.480613
  validation accuracy:		89.89 %
Epoch 1869 of 2000 took 0.096s
  training loss:		0.154900
  validation loss:		0.507268
  validation accuracy:		89.78 %
Epoch 1870 of 2000 took 0.096s
  training loss:		0.147720
  validation loss:		0.472867
  validation accuracy:		90.33 %
Epoch 1871 of 2000 took 0.096s
  training loss:		0.140386
  validation loss:		0.489170
  validation accuracy:		90.00 %
Epoch 1872 of 2000 took 0.096s
  training loss:		0.141010
  validation loss:		0.464049
  validation accuracy:		90.87 %
Epoch 1873 of 2000 took 0.098s
  training loss:		0.143579
  validation loss:		0.495263
  validation accuracy:		90.22 %
Epoch 1874 of 2000 took 0.096s
  training loss:		0.141366
  validation loss:		0.471606
  validation accuracy:		90.98 %
Epoch 1875 of 2000 took 0.097s
  training loss:		0.147317
  validation loss:		0.492244
  validation accuracy:		89.89 %
Epoch 1876 of 2000 took 0.097s
  training loss:		0.141418
  validation loss:		0.493130
  validation accuracy:		89.57 %
Epoch 1877 of 2000 took 0.096s
  training loss:		0.140645
  validation loss:		0.520011
  validation accuracy:		89.35 %
Epoch 1878 of 2000 took 0.096s
  training loss:		0.137902
  validation loss:		0.485150
  validation accuracy:		89.89 %
Epoch 1879 of 2000 took 0.096s
  training loss:		0.140682
  validation loss:		0.465333
  validation accuracy:		90.00 %
Epoch 1880 of 2000 took 0.096s
  training loss:		0.144320
  validation loss:		0.476766
  validation accuracy:		90.43 %
Epoch 1881 of 2000 took 0.097s
  training loss:		0.144370
  validation loss:		0.479231
  validation accuracy:		90.22 %
Epoch 1882 of 2000 took 0.096s
  training loss:		0.144419
  validation loss:		0.483096
  validation accuracy:		89.89 %
Epoch 1883 of 2000 took 0.098s
  training loss:		0.144550
  validation loss:		0.472692
  validation accuracy:		89.89 %
Epoch 1884 of 2000 took 0.097s
  training loss:		0.140526
  validation loss:		0.467595
  validation accuracy:		90.11 %
Epoch 1885 of 2000 took 0.097s
  training loss:		0.139849
  validation loss:		0.510777
  validation accuracy:		89.78 %
Epoch 1886 of 2000 took 0.097s
  training loss:		0.145590
  validation loss:		0.474004
  validation accuracy:		89.78 %
Epoch 1887 of 2000 took 0.096s
  training loss:		0.139115
  validation loss:		0.480792
  validation accuracy:		90.00 %
Epoch 1888 of 2000 took 0.096s
  training loss:		0.138212
  validation loss:		0.493489
  validation accuracy:		89.57 %
Epoch 1889 of 2000 took 0.096s
  training loss:		0.144185
  validation loss:		0.475431
  validation accuracy:		89.78 %
Epoch 1890 of 2000 took 0.096s
  training loss:		0.147630
  validation loss:		0.471541
  validation accuracy:		90.54 %
Epoch 1891 of 2000 took 0.097s
  training loss:		0.143403
  validation loss:		0.484211
  validation accuracy:		90.11 %
Epoch 1892 of 2000 took 0.097s
  training loss:		0.137286
  validation loss:		0.489152
  validation accuracy:		89.46 %
Epoch 1893 of 2000 took 0.099s
  training loss:		0.139754
  validation loss:		0.481767
  validation accuracy:		89.78 %
Epoch 1894 of 2000 took 0.097s
  training loss:		0.148277
  validation loss:		0.489994
  validation accuracy:		90.00 %
Epoch 1895 of 2000 took 0.097s
  training loss:		0.143199
  validation loss:		0.488401
  validation accuracy:		89.57 %
Epoch 1896 of 2000 took 0.096s
  training loss:		0.145412
  validation loss:		0.477238
  validation accuracy:		90.22 %
Epoch 1897 of 2000 took 0.096s
  training loss:		0.142476
  validation loss:		0.473357
  validation accuracy:		90.00 %
Epoch 1898 of 2000 took 0.096s
  training loss:		0.135736
  validation loss:		0.486189
  validation accuracy:		89.78 %
Epoch 1899 of 2000 took 0.096s
  training loss:		0.142819
  validation loss:		0.484381
  validation accuracy:		89.57 %
Epoch 1900 of 2000 took 0.096s
  training loss:		0.141929
  validation loss:		0.541614
  validation accuracy:		88.91 %
Epoch 1901 of 2000 took 0.096s
  training loss:		0.142243
  validation loss:		0.485728
  validation accuracy:		89.67 %
Epoch 1902 of 2000 took 0.096s
  training loss:		0.143865
  validation loss:		0.491186
  validation accuracy:		89.78 %
Epoch 1903 of 2000 took 0.096s
  training loss:		0.142481
  validation loss:		0.492784
  validation accuracy:		89.57 %
Epoch 1904 of 2000 took 0.098s
  training loss:		0.150428
  validation loss:		0.501827
  validation accuracy:		89.78 %
Epoch 1905 of 2000 took 0.097s
  training loss:		0.142666
  validation loss:		0.510102
  validation accuracy:		89.67 %
Epoch 1906 of 2000 took 0.096s
  training loss:		0.134401
  validation loss:		0.489721
  validation accuracy:		89.57 %
Epoch 1907 of 2000 took 0.097s
  training loss:		0.142120
  validation loss:		0.535750
  validation accuracy:		89.02 %
Epoch 1908 of 2000 took 0.096s
  training loss:		0.139811
  validation loss:		0.496813
  validation accuracy:		90.00 %
Epoch 1909 of 2000 took 0.096s
  training loss:		0.137703
  validation loss:		0.489763
  validation accuracy:		90.11 %
Epoch 1910 of 2000 took 0.096s
  training loss:		0.146366
  validation loss:		0.508474
  validation accuracy:		89.46 %
Epoch 1911 of 2000 took 0.096s
  training loss:		0.142010
  validation loss:		0.480138
  validation accuracy:		89.67 %
Epoch 1912 of 2000 took 0.096s
  training loss:		0.139445
  validation loss:		0.495225
  validation accuracy:		89.57 %
Epoch 1913 of 2000 took 0.096s
  training loss:		0.143506
  validation loss:		0.500269
  validation accuracy:		89.67 %
Epoch 1914 of 2000 took 0.098s
  training loss:		0.141435
  validation loss:		0.484321
  validation accuracy:		90.43 %
Epoch 1915 of 2000 took 0.097s
  training loss:		0.150130
  validation loss:		0.510498
  validation accuracy:		89.35 %
Epoch 1916 of 2000 took 0.096s
  training loss:		0.139164
  validation loss:		0.479247
  validation accuracy:		90.00 %
Epoch 1917 of 2000 took 0.096s
  training loss:		0.135937
  validation loss:		0.497232
  validation accuracy:		89.57 %
Epoch 1918 of 2000 took 0.096s
  training loss:		0.141896
  validation loss:		0.505435
  validation accuracy:		89.35 %
Epoch 1919 of 2000 took 0.096s
  training loss:		0.141520
  validation loss:		0.504331
  validation accuracy:		89.35 %
Epoch 1920 of 2000 took 0.096s
  training loss:		0.138225
  validation loss:		0.501867
  validation accuracy:		90.33 %
Epoch 1921 of 2000 took 0.096s
  training loss:		0.147203
  validation loss:		0.484669
  validation accuracy:		90.00 %
Epoch 1922 of 2000 took 0.096s
  training loss:		0.141386
  validation loss:		0.491904
  validation accuracy:		89.78 %
Epoch 1923 of 2000 took 0.096s
  training loss:		0.139425
  validation loss:		0.472695
  validation accuracy:		90.33 %
Epoch 1924 of 2000 took 0.099s
  training loss:		0.143812
  validation loss:		0.505886
  validation accuracy:		89.24 %
Epoch 1925 of 2000 took 0.097s
  training loss:		0.147575
  validation loss:		0.498034
  validation accuracy:		89.78 %
Epoch 1926 of 2000 took 0.097s
  training loss:		0.137209
  validation loss:		0.487836
  validation accuracy:		89.67 %
Epoch 1927 of 2000 took 0.096s
  training loss:		0.137021
  validation loss:		0.488776
  validation accuracy:		90.76 %
Epoch 1928 of 2000 took 0.097s
  training loss:		0.147296
  validation loss:		0.469368
  validation accuracy:		90.76 %
Epoch 1929 of 2000 took 0.096s
  training loss:		0.140957
  validation loss:		0.485428
  validation accuracy:		90.22 %
Epoch 1930 of 2000 took 0.096s
  training loss:		0.139845
  validation loss:		0.501397
  validation accuracy:		89.89 %
Epoch 1931 of 2000 took 0.096s
  training loss:		0.140266
  validation loss:		0.497860
  validation accuracy:		90.54 %
Epoch 1932 of 2000 took 0.099s
  training loss:		0.140190
  validation loss:		0.484913
  validation accuracy:		89.89 %
Epoch 1933 of 2000 took 0.100s
  training loss:		0.143893
  validation loss:		0.472786
  validation accuracy:		90.65 %
Epoch 1934 of 2000 took 0.099s
  training loss:		0.143736
  validation loss:		0.472509
  validation accuracy:		90.98 %
Epoch 1935 of 2000 took 0.101s
  training loss:		0.145083
  validation loss:		0.492516
  validation accuracy:		89.67 %
Epoch 1936 of 2000 took 0.100s
  training loss:		0.142902
  validation loss:		0.487641
  validation accuracy:		89.78 %
Epoch 1937 of 2000 took 0.100s
  training loss:		0.146728
  validation loss:		0.491857
  validation accuracy:		89.89 %
Epoch 1938 of 2000 took 0.100s
  training loss:		0.140683
  validation loss:		0.465815
  validation accuracy:		90.43 %
Epoch 1939 of 2000 took 0.099s
  training loss:		0.136930
  validation loss:		0.495734
  validation accuracy:		89.57 %
Epoch 1940 of 2000 took 0.099s
  training loss:		0.140402
  validation loss:		0.476827
  validation accuracy:		89.78 %
Epoch 1941 of 2000 took 0.099s
  training loss:		0.139390
  validation loss:		0.511631
  validation accuracy:		89.46 %
Epoch 1942 of 2000 took 0.100s
  training loss:		0.142002
  validation loss:		0.487780
  validation accuracy:		89.57 %
Epoch 1943 of 2000 took 0.099s
  training loss:		0.132983
  validation loss:		0.489264
  validation accuracy:		90.43 %
Epoch 1944 of 2000 took 0.099s
  training loss:		0.140739
  validation loss:		0.499203
  validation accuracy:		90.65 %
Epoch 1945 of 2000 took 0.101s
  training loss:		0.138129
  validation loss:		0.481533
  validation accuracy:		89.78 %
Epoch 1946 of 2000 took 0.100s
  training loss:		0.141699
  validation loss:		0.477512
  validation accuracy:		90.33 %
Epoch 1947 of 2000 took 0.099s
  training loss:		0.138345
  validation loss:		0.490697
  validation accuracy:		90.33 %
Epoch 1948 of 2000 took 0.097s
  training loss:		0.145377
  validation loss:		0.502750
  validation accuracy:		89.57 %
Epoch 1949 of 2000 took 0.096s
  training loss:		0.143901
  validation loss:		0.506620
  validation accuracy:		89.89 %
Epoch 1950 of 2000 took 0.097s
  training loss:		0.137536
  validation loss:		0.531231
  validation accuracy:		88.91 %
Epoch 1951 of 2000 took 0.097s
  training loss:		0.146686
  validation loss:		0.496155
  validation accuracy:		90.22 %
Epoch 1952 of 2000 took 0.096s
  training loss:		0.140898
  validation loss:		0.499519
  validation accuracy:		89.89 %
Epoch 1953 of 2000 took 0.096s
  training loss:		0.142342
  validation loss:		0.479367
  validation accuracy:		90.22 %
Epoch 1954 of 2000 took 0.097s
  training loss:		0.143219
  validation loss:		0.494052
  validation accuracy:		90.11 %
Epoch 1955 of 2000 took 0.098s
  training loss:		0.140582
  validation loss:		0.502650
  validation accuracy:		89.67 %
Epoch 1956 of 2000 took 0.096s
  training loss:		0.135181
  validation loss:		0.479895
  validation accuracy:		90.22 %
Epoch 1957 of 2000 took 0.096s
  training loss:		0.135870
  validation loss:		0.491838
  validation accuracy:		90.22 %
Epoch 1958 of 2000 took 0.097s
  training loss:		0.137104
  validation loss:		0.484698
  validation accuracy:		89.89 %
Epoch 1959 of 2000 took 0.096s
  training loss:		0.135281
  validation loss:		0.519591
  validation accuracy:		89.35 %
Epoch 1960 of 2000 took 0.096s
  training loss:		0.142217
  validation loss:		0.539068
  validation accuracy:		89.35 %
Epoch 1961 of 2000 took 0.096s
  training loss:		0.144470
  validation loss:		0.485401
  validation accuracy:		90.54 %
Epoch 1962 of 2000 took 0.096s
  training loss:		0.140270
  validation loss:		0.500255
  validation accuracy:		90.33 %
Epoch 1963 of 2000 took 0.096s
  training loss:		0.141269
  validation loss:		0.509326
  validation accuracy:		89.35 %
Epoch 1964 of 2000 took 0.096s
  training loss:		0.136360
  validation loss:		0.491787
  validation accuracy:		89.89 %
Epoch 1965 of 2000 took 0.098s
  training loss:		0.140845
  validation loss:		0.509151
  validation accuracy:		89.67 %
Epoch 1966 of 2000 took 0.097s
  training loss:		0.136604
  validation loss:		0.495591
  validation accuracy:		90.43 %
Epoch 1967 of 2000 took 0.097s
  training loss:		0.143091
  validation loss:		0.495097
  validation accuracy:		89.89 %
Epoch 1968 of 2000 took 0.096s
  training loss:		0.147117
  validation loss:		0.506915
  validation accuracy:		90.43 %
Epoch 1969 of 2000 took 0.097s
  training loss:		0.142297
  validation loss:		0.476287
  validation accuracy:		90.11 %
Epoch 1970 of 2000 took 0.096s
  training loss:		0.140769
  validation loss:		0.499047
  validation accuracy:		90.22 %
Epoch 1971 of 2000 took 0.096s
  training loss:		0.139206
  validation loss:		0.521347
  validation accuracy:		89.89 %
Epoch 1972 of 2000 took 0.096s
  training loss:		0.147753
  validation loss:		0.500803
  validation accuracy:		89.57 %
Epoch 1973 of 2000 took 0.097s
  training loss:		0.131655
  validation loss:		0.500082
  validation accuracy:		90.11 %
Epoch 1974 of 2000 took 0.097s
  training loss:		0.147191
  validation loss:		0.477389
  validation accuracy:		90.54 %
Epoch 1975 of 2000 took 0.097s
  training loss:		0.139384
  validation loss:		0.486065
  validation accuracy:		90.33 %
Epoch 1976 of 2000 took 0.098s
  training loss:		0.144509
  validation loss:		0.504074
  validation accuracy:		89.67 %
Epoch 1977 of 2000 took 0.097s
  training loss:		0.138265
  validation loss:		0.496911
  validation accuracy:		90.00 %
Epoch 1978 of 2000 took 0.097s
  training loss:		0.148478
  validation loss:		0.499340
  validation accuracy:		89.57 %
Epoch 1979 of 2000 took 0.096s
  training loss:		0.136497
  validation loss:		0.496767
  validation accuracy:		89.46 %
Epoch 1980 of 2000 took 0.096s
  training loss:		0.141890
  validation loss:		0.490625
  validation accuracy:		90.11 %
Epoch 1981 of 2000 took 0.096s
  training loss:		0.135685
  validation loss:		0.506487
  validation accuracy:		89.57 %
Epoch 1982 of 2000 took 0.096s
  training loss:		0.144253
  validation loss:		0.497343
  validation accuracy:		90.00 %
Epoch 1983 of 2000 took 0.096s
  training loss:		0.138680
  validation loss:		0.470449
  validation accuracy:		90.87 %
Epoch 1984 of 2000 took 0.096s
  training loss:		0.144323
  validation loss:		0.496917
  validation accuracy:		90.11 %
Epoch 1985 of 2000 took 0.096s
  training loss:		0.135409
  validation loss:		0.489014
  validation accuracy:		89.89 %
Epoch 1986 of 2000 took 0.099s
  training loss:		0.144836
  validation loss:		0.494099
  validation accuracy:		90.11 %
Epoch 1987 of 2000 took 0.096s
  training loss:		0.141458
  validation loss:		0.482294
  validation accuracy:		90.43 %
Epoch 1988 of 2000 took 0.097s
  training loss:		0.137501
  validation loss:		0.517283
  validation accuracy:		89.24 %
Epoch 1989 of 2000 took 0.097s
  training loss:		0.139241
  validation loss:		0.500577
  validation accuracy:		90.00 %
Epoch 1990 of 2000 took 0.096s
  training loss:		0.143678
  validation loss:		0.489041
  validation accuracy:		89.89 %
Epoch 1991 of 2000 took 0.096s
  training loss:		0.135227
  validation loss:		0.482218
  validation accuracy:		91.09 %
Epoch 1992 of 2000 took 0.096s
  training loss:		0.136310
  validation loss:		0.503288
  validation accuracy:		90.11 %
Epoch 1993 of 2000 took 0.096s
  training loss:		0.136375
  validation loss:		0.512711
  validation accuracy:		89.78 %
Epoch 1994 of 2000 took 0.096s
  training loss:		0.139522
  validation loss:		0.496161
  validation accuracy:		90.11 %
Epoch 1995 of 2000 took 0.096s
  training loss:		0.137548
  validation loss:		0.482328
  validation accuracy:		90.43 %
Epoch 1996 of 2000 took 0.098s
  training loss:		0.138428
  validation loss:		0.507521
  validation accuracy:		89.46 %
Epoch 1997 of 2000 took 0.096s
  training loss:		0.135462
  validation loss:		0.506159
  validation accuracy:		89.57 %
Epoch 1998 of 2000 took 0.097s
  training loss:		0.141770
  validation loss:		0.486650
  validation accuracy:		90.33 %
Epoch 1999 of 2000 took 0.096s
  training loss:		0.137277
  validation loss:		0.521121
  validation accuracy:		89.57 %
Epoch 2000 of 2000 took 0.096s
  training loss:		0.137595
  validation loss:		0.499371
  validation accuracy:		89.57 %
Final results:
  test loss:			1.109589
  test accuracy:		81.18 %
