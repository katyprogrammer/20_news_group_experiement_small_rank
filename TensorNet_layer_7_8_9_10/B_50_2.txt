Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
decomposing tensor W of shape (4, 50, 50)...
decomposing tensor B of shape (4, 50)...
Starting training...
Epoch 1 of 2000 took 0.101s
  training loss:		3.033256
  validation loss:		2.916740
  validation accuracy:		11.85 %
Epoch 2 of 2000 took 0.096s
  training loss:		2.860544
  validation loss:		2.706288
  validation accuracy:		12.28 %
Epoch 3 of 2000 took 0.099s
  training loss:		2.734449
  validation loss:		2.550425
  validation accuracy:		12.83 %
Epoch 4 of 2000 took 0.099s
  training loss:		2.628271
  validation loss:		2.439338
  validation accuracy:		13.59 %
Epoch 5 of 2000 took 0.099s
  training loss:		2.538095
  validation loss:		2.362399
  validation accuracy:		13.70 %
Epoch 6 of 2000 took 0.099s
  training loss:		2.441468
  validation loss:		2.299993
  validation accuracy:		12.07 %
Epoch 7 of 2000 took 0.099s
  training loss:		2.363174
  validation loss:		2.260871
  validation accuracy:		16.41 %
Epoch 8 of 2000 took 0.099s
  training loss:		2.310566
  validation loss:		2.232030
  validation accuracy:		22.28 %
Epoch 9 of 2000 took 0.099s
  training loss:		2.283286
  validation loss:		2.215392
  validation accuracy:		23.80 %
Epoch 10 of 2000 took 0.096s
  training loss:		2.267060
  validation loss:		2.217068
  validation accuracy:		20.00 %
Epoch 11 of 2000 took 0.096s
  training loss:		2.255112
  validation loss:		2.200396
  validation accuracy:		23.80 %
Epoch 12 of 2000 took 0.096s
  training loss:		2.244381
  validation loss:		2.188452
  validation accuracy:		23.59 %
Epoch 13 of 2000 took 0.096s
  training loss:		2.235851
  validation loss:		2.176969
  validation accuracy:		24.67 %
Epoch 14 of 2000 took 0.096s
  training loss:		2.227233
  validation loss:		2.179117
  validation accuracy:		24.89 %
Epoch 15 of 2000 took 0.096s
  training loss:		2.217317
  validation loss:		2.167211
  validation accuracy:		31.41 %
Epoch 16 of 2000 took 0.096s
  training loss:		2.206083
  validation loss:		2.144394
  validation accuracy:		31.63 %
Epoch 17 of 2000 took 0.096s
  training loss:		2.195593
  validation loss:		2.140158
  validation accuracy:		31.09 %
Epoch 18 of 2000 took 0.096s
  training loss:		2.187354
  validation loss:		2.121993
  validation accuracy:		32.39 %
Epoch 19 of 2000 took 0.096s
  training loss:		2.171736
  validation loss:		2.113492
  validation accuracy:		36.96 %
Epoch 20 of 2000 took 0.097s
  training loss:		2.159136
  validation loss:		2.097930
  validation accuracy:		35.00 %
Epoch 21 of 2000 took 0.097s
  training loss:		2.144355
  validation loss:		2.077155
  validation accuracy:		39.67 %
Epoch 22 of 2000 took 0.097s
  training loss:		2.126222
  validation loss:		2.066871
  validation accuracy:		38.04 %
Epoch 23 of 2000 took 0.097s
  training loss:		2.106072
  validation loss:		2.043747
  validation accuracy:		40.65 %
Epoch 24 of 2000 took 0.097s
  training loss:		2.083794
  validation loss:		2.022901
  validation accuracy:		39.13 %
Epoch 25 of 2000 took 0.097s
  training loss:		2.060469
  validation loss:		1.996708
  validation accuracy:		39.78 %
Epoch 26 of 2000 took 0.097s
  training loss:		2.034066
  validation loss:		1.962527
  validation accuracy:		40.22 %
Epoch 27 of 2000 took 0.097s
  training loss:		2.001784
  validation loss:		1.933846
  validation accuracy:		45.11 %
Epoch 28 of 2000 took 0.097s
  training loss:		1.965235
  validation loss:		1.894225
  validation accuracy:		43.26 %
Epoch 29 of 2000 took 0.097s
  training loss:		1.930160
  validation loss:		1.853782
  validation accuracy:		46.74 %
Epoch 30 of 2000 took 0.097s
  training loss:		1.886684
  validation loss:		1.819218
  validation accuracy:		45.65 %
Epoch 31 of 2000 took 0.097s
  training loss:		1.847437
  validation loss:		1.775670
  validation accuracy:		47.28 %
Epoch 32 of 2000 took 0.097s
  training loss:		1.805052
  validation loss:		1.735214
  validation accuracy:		47.07 %
Epoch 33 of 2000 took 0.097s
  training loss:		1.763292
  validation loss:		1.698897
  validation accuracy:		49.35 %
Epoch 34 of 2000 took 0.097s
  training loss:		1.717078
  validation loss:		1.640996
  validation accuracy:		51.63 %
Epoch 35 of 2000 took 0.097s
  training loss:		1.673480
  validation loss:		1.611543
  validation accuracy:		52.28 %
Epoch 36 of 2000 took 0.097s
  training loss:		1.628982
  validation loss:		1.557457
  validation accuracy:		52.61 %
Epoch 37 of 2000 took 0.097s
  training loss:		1.588923
  validation loss:		1.527807
  validation accuracy:		54.89 %
Epoch 38 of 2000 took 0.097s
  training loss:		1.547396
  validation loss:		1.483012
  validation accuracy:		56.20 %
Epoch 39 of 2000 took 0.097s
  training loss:		1.504810
  validation loss:		1.439307
  validation accuracy:		57.39 %
Epoch 40 of 2000 took 0.097s
  training loss:		1.468784
  validation loss:		1.426348
  validation accuracy:		58.59 %
Epoch 41 of 2000 took 0.097s
  training loss:		1.428829
  validation loss:		1.380460
  validation accuracy:		59.46 %
Epoch 42 of 2000 took 0.097s
  training loss:		1.392668
  validation loss:		1.343845
  validation accuracy:		60.00 %
Epoch 43 of 2000 took 0.097s
  training loss:		1.352639
  validation loss:		1.294800
  validation accuracy:		61.41 %
Epoch 44 of 2000 took 0.097s
  training loss:		1.316359
  validation loss:		1.276367
  validation accuracy:		62.93 %
Epoch 45 of 2000 took 0.098s
  training loss:		1.278105
  validation loss:		1.238023
  validation accuracy:		62.93 %
Epoch 46 of 2000 took 0.097s
  training loss:		1.238496
  validation loss:		1.204853
  validation accuracy:		62.72 %
Epoch 47 of 2000 took 0.097s
  training loss:		1.204439
  validation loss:		1.168974
  validation accuracy:		64.24 %
Epoch 48 of 2000 took 0.097s
  training loss:		1.173109
  validation loss:		1.129019
  validation accuracy:		65.54 %
Epoch 49 of 2000 took 0.097s
  training loss:		1.129143
  validation loss:		1.106087
  validation accuracy:		67.28 %
Epoch 50 of 2000 took 0.097s
  training loss:		1.097172
  validation loss:		1.058310
  validation accuracy:		68.15 %
Epoch 51 of 2000 took 0.098s
  training loss:		1.059124
  validation loss:		1.038292
  validation accuracy:		68.59 %
Epoch 52 of 2000 took 0.097s
  training loss:		1.026788
  validation loss:		1.006360
  validation accuracy:		69.67 %
Epoch 53 of 2000 took 0.097s
  training loss:		0.992864
  validation loss:		0.963929
  validation accuracy:		71.30 %
Epoch 54 of 2000 took 0.097s
  training loss:		0.960200
  validation loss:		0.947022
  validation accuracy:		71.52 %
Epoch 55 of 2000 took 0.097s
  training loss:		0.934479
  validation loss:		0.918419
  validation accuracy:		73.80 %
Epoch 56 of 2000 took 0.097s
  training loss:		0.906157
  validation loss:		0.912076
  validation accuracy:		73.70 %
Epoch 57 of 2000 took 0.097s
  training loss:		0.878497
  validation loss:		0.868570
  validation accuracy:		75.54 %
Epoch 58 of 2000 took 0.097s
  training loss:		0.849793
  validation loss:		0.834963
  validation accuracy:		74.78 %
Epoch 59 of 2000 took 0.097s
  training loss:		0.830760
  validation loss:		0.829467
  validation accuracy:		75.87 %
Epoch 60 of 2000 took 0.097s
  training loss:		0.813130
  validation loss:		0.789353
  validation accuracy:		77.28 %
Epoch 61 of 2000 took 0.097s
  training loss:		0.794452
  validation loss:		0.809050
  validation accuracy:		76.96 %
Epoch 62 of 2000 took 0.097s
  training loss:		0.775472
  validation loss:		0.792381
  validation accuracy:		76.96 %
Epoch 63 of 2000 took 0.097s
  training loss:		0.760003
  validation loss:		0.744443
  validation accuracy:		77.93 %
Epoch 64 of 2000 took 0.097s
  training loss:		0.749278
  validation loss:		0.731878
  validation accuracy:		78.04 %
Epoch 65 of 2000 took 0.097s
  training loss:		0.733499
  validation loss:		0.725425
  validation accuracy:		79.02 %
Epoch 66 of 2000 took 0.097s
  training loss:		0.720884
  validation loss:		0.737295
  validation accuracy:		78.80 %
Epoch 67 of 2000 took 0.097s
  training loss:		0.702524
  validation loss:		0.691762
  validation accuracy:		79.57 %
Epoch 68 of 2000 took 0.097s
  training loss:		0.686924
  validation loss:		0.672152
  validation accuracy:		79.89 %
Epoch 69 of 2000 took 0.097s
  training loss:		0.674360
  validation loss:		0.690647
  validation accuracy:		79.46 %
Epoch 70 of 2000 took 0.097s
  training loss:		0.666922
  validation loss:		0.657956
  validation accuracy:		80.76 %
Epoch 71 of 2000 took 0.097s
  training loss:		0.652729
  validation loss:		0.639756
  validation accuracy:		81.30 %
Epoch 72 of 2000 took 0.097s
  training loss:		0.650412
  validation loss:		0.632961
  validation accuracy:		81.63 %
Epoch 73 of 2000 took 0.097s
  training loss:		0.631930
  validation loss:		0.638997
  validation accuracy:		82.07 %
Epoch 74 of 2000 took 0.097s
  training loss:		0.627073
  validation loss:		0.610987
  validation accuracy:		82.39 %
Epoch 75 of 2000 took 0.097s
  training loss:		0.611308
  validation loss:		0.614021
  validation accuracy:		81.85 %
Epoch 76 of 2000 took 0.097s
  training loss:		0.606350
  validation loss:		0.596385
  validation accuracy:		82.93 %
Epoch 77 of 2000 took 0.097s
  training loss:		0.596682
  validation loss:		0.589311
  validation accuracy:		83.26 %
Epoch 78 of 2000 took 0.097s
  training loss:		0.593052
  validation loss:		0.592932
  validation accuracy:		82.93 %
Epoch 79 of 2000 took 0.097s
  training loss:		0.579975
  validation loss:		0.575345
  validation accuracy:		83.80 %
Epoch 80 of 2000 took 0.097s
  training loss:		0.574037
  validation loss:		0.593914
  validation accuracy:		83.26 %
Epoch 81 of 2000 took 0.097s
  training loss:		0.566817
  validation loss:		0.561292
  validation accuracy:		83.80 %
Epoch 82 of 2000 took 0.098s
  training loss:		0.562105
  validation loss:		0.546201
  validation accuracy:		84.78 %
Epoch 83 of 2000 took 0.097s
  training loss:		0.547023
  validation loss:		0.543841
  validation accuracy:		84.67 %
Epoch 84 of 2000 took 0.097s
  training loss:		0.543365
  validation loss:		0.528659
  validation accuracy:		85.43 %
Epoch 85 of 2000 took 0.097s
  training loss:		0.534960
  validation loss:		0.537722
  validation accuracy:		84.78 %
Epoch 86 of 2000 took 0.097s
  training loss:		0.521235
  validation loss:		0.514270
  validation accuracy:		86.09 %
Epoch 87 of 2000 took 0.097s
  training loss:		0.524310
  validation loss:		0.511204
  validation accuracy:		86.20 %
Epoch 88 of 2000 took 0.097s
  training loss:		0.509706
  validation loss:		0.530933
  validation accuracy:		85.87 %
Epoch 89 of 2000 took 0.097s
  training loss:		0.501395
  validation loss:		0.522397
  validation accuracy:		86.20 %
Epoch 90 of 2000 took 0.097s
  training loss:		0.501200
  validation loss:		0.502756
  validation accuracy:		86.52 %
Epoch 91 of 2000 took 0.097s
  training loss:		0.489029
  validation loss:		0.480283
  validation accuracy:		86.20 %
Epoch 92 of 2000 took 0.097s
  training loss:		0.486788
  validation loss:		0.497121
  validation accuracy:		85.65 %
Epoch 93 of 2000 took 0.097s
  training loss:		0.482957
  validation loss:		0.490161
  validation accuracy:		86.30 %
Epoch 94 of 2000 took 0.097s
  training loss:		0.477361
  validation loss:		0.466709
  validation accuracy:		85.54 %
Epoch 95 of 2000 took 0.097s
  training loss:		0.475841
  validation loss:		0.472762
  validation accuracy:		86.20 %
Epoch 96 of 2000 took 0.097s
  training loss:		0.462397
  validation loss:		0.466733
  validation accuracy:		86.30 %
Epoch 97 of 2000 took 0.097s
  training loss:		0.456940
  validation loss:		0.452405
  validation accuracy:		86.85 %
Epoch 98 of 2000 took 0.097s
  training loss:		0.456090
  validation loss:		0.448905
  validation accuracy:		86.74 %
Epoch 99 of 2000 took 0.097s
  training loss:		0.444385
  validation loss:		0.446204
  validation accuracy:		86.63 %
Epoch 100 of 2000 took 0.097s
  training loss:		0.445304
  validation loss:		0.437500
  validation accuracy:		86.41 %
Epoch 101 of 2000 took 0.097s
  training loss:		0.446388
  validation loss:		0.438921
  validation accuracy:		86.20 %
Epoch 102 of 2000 took 0.097s
  training loss:		0.439908
  validation loss:		0.435033
  validation accuracy:		86.41 %
Epoch 103 of 2000 took 0.097s
  training loss:		0.439449
  validation loss:		0.432977
  validation accuracy:		86.85 %
Epoch 104 of 2000 took 0.097s
  training loss:		0.435734
  validation loss:		0.418142
  validation accuracy:		87.07 %
Epoch 105 of 2000 took 0.097s
  training loss:		0.431600
  validation loss:		0.449922
  validation accuracy:		86.63 %
Epoch 106 of 2000 took 0.097s
  training loss:		0.425290
  validation loss:		0.414052
  validation accuracy:		86.85 %
Epoch 107 of 2000 took 0.097s
  training loss:		0.415323
  validation loss:		0.421221
  validation accuracy:		87.17 %
Epoch 108 of 2000 took 0.097s
  training loss:		0.407794
  validation loss:		0.439473
  validation accuracy:		86.74 %
Epoch 109 of 2000 took 0.097s
  training loss:		0.408105
  validation loss:		0.426148
  validation accuracy:		87.50 %
Epoch 110 of 2000 took 0.097s
  training loss:		0.407427
  validation loss:		0.428775
  validation accuracy:		86.96 %
Epoch 111 of 2000 took 0.098s
  training loss:		0.405525
  validation loss:		0.405173
  validation accuracy:		87.50 %
Epoch 112 of 2000 took 0.097s
  training loss:		0.390969
  validation loss:		0.405267
  validation accuracy:		87.61 %
Epoch 113 of 2000 took 0.098s
  training loss:		0.393980
  validation loss:		0.408509
  validation accuracy:		87.61 %
Epoch 114 of 2000 took 0.097s
  training loss:		0.390111
  validation loss:		0.417062
  validation accuracy:		87.28 %
Epoch 115 of 2000 took 0.097s
  training loss:		0.391224
  validation loss:		0.404389
  validation accuracy:		87.61 %
Epoch 116 of 2000 took 0.097s
  training loss:		0.378506
  validation loss:		0.420380
  validation accuracy:		87.28 %
Epoch 117 of 2000 took 0.097s
  training loss:		0.378827
  validation loss:		0.394607
  validation accuracy:		87.83 %
Epoch 118 of 2000 took 0.097s
  training loss:		0.374771
  validation loss:		0.381979
  validation accuracy:		88.15 %
Epoch 119 of 2000 took 0.097s
  training loss:		0.374399
  validation loss:		0.390737
  validation accuracy:		87.07 %
Epoch 120 of 2000 took 0.097s
  training loss:		0.374989
  validation loss:		0.378938
  validation accuracy:		88.37 %
Epoch 121 of 2000 took 0.097s
  training loss:		0.369540
  validation loss:		0.388815
  validation accuracy:		87.61 %
Epoch 122 of 2000 took 0.097s
  training loss:		0.363693
  validation loss:		0.388151
  validation accuracy:		88.37 %
Epoch 123 of 2000 took 0.097s
  training loss:		0.358771
  validation loss:		0.386355
  validation accuracy:		87.93 %
Epoch 124 of 2000 took 0.097s
  training loss:		0.358254
  validation loss:		0.384877
  validation accuracy:		88.04 %
Epoch 125 of 2000 took 0.097s
  training loss:		0.360115
  validation loss:		0.379101
  validation accuracy:		88.15 %
Epoch 126 of 2000 took 0.097s
  training loss:		0.355528
  validation loss:		0.376272
  validation accuracy:		88.26 %
Epoch 127 of 2000 took 0.097s
  training loss:		0.357649
  validation loss:		0.381426
  validation accuracy:		88.04 %
Epoch 128 of 2000 took 0.097s
  training loss:		0.348747
  validation loss:		0.368712
  validation accuracy:		88.04 %
Epoch 129 of 2000 took 0.097s
  training loss:		0.354148
  validation loss:		0.381586
  validation accuracy:		88.04 %
Epoch 130 of 2000 took 0.097s
  training loss:		0.343322
  validation loss:		0.370250
  validation accuracy:		87.93 %
Epoch 131 of 2000 took 0.097s
  training loss:		0.344129
  validation loss:		0.360674
  validation accuracy:		88.59 %
Epoch 132 of 2000 took 0.097s
  training loss:		0.337727
  validation loss:		0.377028
  validation accuracy:		88.48 %
Epoch 133 of 2000 took 0.102s
  training loss:		0.329587
  validation loss:		0.358242
  validation accuracy:		88.26 %
Epoch 134 of 2000 took 0.098s
  training loss:		0.332679
  validation loss:		0.355140
  validation accuracy:		88.48 %
Epoch 135 of 2000 took 0.097s
  training loss:		0.337818
  validation loss:		0.366341
  validation accuracy:		88.59 %
Epoch 136 of 2000 took 0.097s
  training loss:		0.325575
  validation loss:		0.354620
  validation accuracy:		88.91 %
Epoch 137 of 2000 took 0.097s
  training loss:		0.327117
  validation loss:		0.365165
  validation accuracy:		88.48 %
Epoch 138 of 2000 took 0.097s
  training loss:		0.327418
  validation loss:		0.398276
  validation accuracy:		87.50 %
Epoch 139 of 2000 took 0.097s
  training loss:		0.324181
  validation loss:		0.355062
  validation accuracy:		89.02 %
Epoch 140 of 2000 took 0.097s
  training loss:		0.321679
  validation loss:		0.346959
  validation accuracy:		88.59 %
Epoch 141 of 2000 took 0.097s
  training loss:		0.319810
  validation loss:		0.346898
  validation accuracy:		89.35 %
Epoch 142 of 2000 took 0.097s
  training loss:		0.316692
  validation loss:		0.342376
  validation accuracy:		89.24 %
Epoch 143 of 2000 took 0.097s
  training loss:		0.308331
  validation loss:		0.342063
  validation accuracy:		89.02 %
Epoch 144 of 2000 took 0.098s
  training loss:		0.311499
  validation loss:		0.353883
  validation accuracy:		88.59 %
Epoch 145 of 2000 took 0.097s
  training loss:		0.307688
  validation loss:		0.344895
  validation accuracy:		89.24 %
Epoch 146 of 2000 took 0.097s
  training loss:		0.305092
  validation loss:		0.356063
  validation accuracy:		88.91 %
Epoch 147 of 2000 took 0.097s
  training loss:		0.310331
  validation loss:		0.336291
  validation accuracy:		89.35 %
Epoch 148 of 2000 took 0.097s
  training loss:		0.305384
  validation loss:		0.336884
  validation accuracy:		89.57 %
Epoch 149 of 2000 took 0.097s
  training loss:		0.291188
  validation loss:		0.332184
  validation accuracy:		88.91 %
Epoch 150 of 2000 took 0.097s
  training loss:		0.306817
  validation loss:		0.335828
  validation accuracy:		89.24 %
Epoch 151 of 2000 took 0.097s
  training loss:		0.293411
  validation loss:		0.337416
  validation accuracy:		89.13 %
Epoch 152 of 2000 took 0.097s
  training loss:		0.297561
  validation loss:		0.355013
  validation accuracy:		88.80 %
Epoch 153 of 2000 took 0.097s
  training loss:		0.297210
  validation loss:		0.343757
  validation accuracy:		88.91 %
Epoch 154 of 2000 took 0.097s
  training loss:		0.295542
  validation loss:		0.342219
  validation accuracy:		88.80 %
Epoch 155 of 2000 took 0.097s
  training loss:		0.290279
  validation loss:		0.340294
  validation accuracy:		88.80 %
Epoch 156 of 2000 took 0.097s
  training loss:		0.290728
  validation loss:		0.343789
  validation accuracy:		88.59 %
Epoch 157 of 2000 took 0.097s
  training loss:		0.289631
  validation loss:		0.329401
  validation accuracy:		89.35 %
Epoch 158 of 2000 took 0.097s
  training loss:		0.285962
  validation loss:		0.336925
  validation accuracy:		88.37 %
Epoch 159 of 2000 took 0.097s
  training loss:		0.285238
  validation loss:		0.335862
  validation accuracy:		89.02 %
Epoch 160 of 2000 took 0.097s
  training loss:		0.291377
  validation loss:		0.328466
  validation accuracy:		89.46 %
Epoch 161 of 2000 took 0.097s
  training loss:		0.281732
  validation loss:		0.338715
  validation accuracy:		89.89 %
Epoch 162 of 2000 took 0.097s
  training loss:		0.279645
  validation loss:		0.328024
  validation accuracy:		89.35 %
Epoch 163 of 2000 took 0.097s
  training loss:		0.284060
  validation loss:		0.350328
  validation accuracy:		88.70 %
Epoch 164 of 2000 took 0.097s
  training loss:		0.285438
  validation loss:		0.328348
  validation accuracy:		90.11 %
Epoch 165 of 2000 took 0.097s
  training loss:		0.277067
  validation loss:		0.342261
  validation accuracy:		88.80 %
Epoch 166 of 2000 took 0.097s
  training loss:		0.282319
  validation loss:		0.334471
  validation accuracy:		89.78 %
Epoch 167 of 2000 took 0.097s
  training loss:		0.274696
  validation loss:		0.342009
  validation accuracy:		88.59 %
Epoch 168 of 2000 took 0.097s
  training loss:		0.277769
  validation loss:		0.332506
  validation accuracy:		89.46 %
Epoch 169 of 2000 took 0.097s
  training loss:		0.279778
  validation loss:		0.328280
  validation accuracy:		89.02 %
Epoch 170 of 2000 took 0.097s
  training loss:		0.272978
  validation loss:		0.324874
  validation accuracy:		89.57 %
Epoch 171 of 2000 took 0.097s
  training loss:		0.272682
  validation loss:		0.326843
  validation accuracy:		89.46 %
Epoch 172 of 2000 took 0.097s
  training loss:		0.271814
  validation loss:		0.332485
  validation accuracy:		89.57 %
Epoch 173 of 2000 took 0.097s
  training loss:		0.264845
  validation loss:		0.327561
  validation accuracy:		89.24 %
Epoch 174 of 2000 took 0.097s
  training loss:		0.272513
  validation loss:		0.310295
  validation accuracy:		90.00 %
Epoch 175 of 2000 took 0.098s
  training loss:		0.265263
  validation loss:		0.320631
  validation accuracy:		90.00 %
Epoch 176 of 2000 took 0.097s
  training loss:		0.268153
  validation loss:		0.319675
  validation accuracy:		89.89 %
Epoch 177 of 2000 took 0.097s
  training loss:		0.272999
  validation loss:		0.322117
  validation accuracy:		89.35 %
Epoch 178 of 2000 took 0.097s
  training loss:		0.263620
  validation loss:		0.328292
  validation accuracy:		89.46 %
Epoch 179 of 2000 took 0.097s
  training loss:		0.261109
  validation loss:		0.312001
  validation accuracy:		89.89 %
Epoch 180 of 2000 took 0.097s
  training loss:		0.259376
  validation loss:		0.314863
  validation accuracy:		89.46 %
Epoch 181 of 2000 took 0.097s
  training loss:		0.260182
  validation loss:		0.317515
  validation accuracy:		89.78 %
Epoch 182 of 2000 took 0.097s
  training loss:		0.258424
  validation loss:		0.336341
  validation accuracy:		89.57 %
Epoch 183 of 2000 took 0.097s
  training loss:		0.267762
  validation loss:		0.312825
  validation accuracy:		90.00 %
Epoch 184 of 2000 took 0.097s
  training loss:		0.263075
  validation loss:		0.318613
  validation accuracy:		89.35 %
Epoch 185 of 2000 took 0.097s
  training loss:		0.258276
  validation loss:		0.317880
  validation accuracy:		90.11 %
Epoch 186 of 2000 took 0.097s
  training loss:		0.262958
  validation loss:		0.312414
  validation accuracy:		89.89 %
Epoch 187 of 2000 took 0.097s
  training loss:		0.255640
  validation loss:		0.317835
  validation accuracy:		90.33 %
Epoch 188 of 2000 took 0.097s
  training loss:		0.252856
  validation loss:		0.317436
  validation accuracy:		90.22 %
Epoch 189 of 2000 took 0.097s
  training loss:		0.259489
  validation loss:		0.325932
  validation accuracy:		89.24 %
Epoch 190 of 2000 took 0.097s
  training loss:		0.257884
  validation loss:		0.310496
  validation accuracy:		89.89 %
Epoch 191 of 2000 took 0.097s
  training loss:		0.260632
  validation loss:		0.306444
  validation accuracy:		89.67 %
Epoch 192 of 2000 took 0.097s
  training loss:		0.250157
  validation loss:		0.313856
  validation accuracy:		90.76 %
Epoch 193 of 2000 took 0.097s
  training loss:		0.256046
  validation loss:		0.310264
  validation accuracy:		90.11 %
Epoch 194 of 2000 took 0.097s
  training loss:		0.251384
  validation loss:		0.317140
  validation accuracy:		90.33 %
Epoch 195 of 2000 took 0.097s
  training loss:		0.246349
  validation loss:		0.322507
  validation accuracy:		89.46 %
Epoch 196 of 2000 took 0.097s
  training loss:		0.253614
  validation loss:		0.311178
  validation accuracy:		89.89 %
Epoch 197 of 2000 took 0.097s
  training loss:		0.243997
  validation loss:		0.333281
  validation accuracy:		89.67 %
Epoch 198 of 2000 took 0.097s
  training loss:		0.252426
  validation loss:		0.332459
  validation accuracy:		89.35 %
Epoch 199 of 2000 took 0.097s
  training loss:		0.251246
  validation loss:		0.311104
  validation accuracy:		89.89 %
Epoch 200 of 2000 took 0.097s
  training loss:		0.245863
  validation loss:		0.306334
  validation accuracy:		90.22 %
Epoch 201 of 2000 took 0.097s
  training loss:		0.243273
  validation loss:		0.308280
  validation accuracy:		90.33 %
Epoch 202 of 2000 took 0.097s
  training loss:		0.248689
  validation loss:		0.311288
  validation accuracy:		90.87 %
Epoch 203 of 2000 took 0.097s
  training loss:		0.245114
  validation loss:		0.322509
  validation accuracy:		89.24 %
Epoch 204 of 2000 took 0.097s
  training loss:		0.243132
  validation loss:		0.318194
  validation accuracy:		89.89 %
Epoch 205 of 2000 took 0.097s
  training loss:		0.242106
  validation loss:		0.313691
  validation accuracy:		90.11 %
Epoch 206 of 2000 took 0.098s
  training loss:		0.238510
  validation loss:		0.316787
  validation accuracy:		89.78 %
Epoch 207 of 2000 took 0.097s
  training loss:		0.242953
  validation loss:		0.315843
  validation accuracy:		90.11 %
Epoch 208 of 2000 took 0.097s
  training loss:		0.239709
  validation loss:		0.330283
  validation accuracy:		90.11 %
Epoch 209 of 2000 took 0.097s
  training loss:		0.249030
  validation loss:		0.317666
  validation accuracy:		90.54 %
Epoch 210 of 2000 took 0.097s
  training loss:		0.240797
  validation loss:		0.312480
  validation accuracy:		90.00 %
Epoch 211 of 2000 took 0.097s
  training loss:		0.248125
  validation loss:		0.309943
  validation accuracy:		90.11 %
Epoch 212 of 2000 took 0.097s
  training loss:		0.246514
  validation loss:		0.313876
  validation accuracy:		89.89 %
Epoch 213 of 2000 took 0.097s
  training loss:		0.234482
  validation loss:		0.298767
  validation accuracy:		90.54 %
Epoch 214 of 2000 took 0.097s
  training loss:		0.237869
  validation loss:		0.298566
  validation accuracy:		90.43 %
Epoch 215 of 2000 took 0.097s
  training loss:		0.239400
  validation loss:		0.304247
  validation accuracy:		90.54 %
Epoch 216 of 2000 took 0.097s
  training loss:		0.234623
  validation loss:		0.324059
  validation accuracy:		89.57 %
Epoch 217 of 2000 took 0.097s
  training loss:		0.238786
  validation loss:		0.304302
  validation accuracy:		90.33 %
Epoch 218 of 2000 took 0.097s
  training loss:		0.237806
  validation loss:		0.330222
  validation accuracy:		89.78 %
Epoch 219 of 2000 took 0.097s
  training loss:		0.237448
  validation loss:		0.300494
  validation accuracy:		90.76 %
Epoch 220 of 2000 took 0.097s
  training loss:		0.229432
  validation loss:		0.301990
  validation accuracy:		90.87 %
Epoch 221 of 2000 took 0.097s
  training loss:		0.234476
  validation loss:		0.324841
  validation accuracy:		90.11 %
Epoch 222 of 2000 took 0.097s
  training loss:		0.238433
  validation loss:		0.303503
  validation accuracy:		90.65 %
Epoch 223 of 2000 took 0.097s
  training loss:		0.230601
  validation loss:		0.313254
  validation accuracy:		90.11 %
Epoch 224 of 2000 took 0.097s
  training loss:		0.229593
  validation loss:		0.308192
  validation accuracy:		90.54 %
Epoch 225 of 2000 took 0.097s
  training loss:		0.231890
  validation loss:		0.316338
  validation accuracy:		90.33 %
Epoch 226 of 2000 took 0.097s
  training loss:		0.230181
  validation loss:		0.315211
  validation accuracy:		90.43 %
Epoch 227 of 2000 took 0.097s
  training loss:		0.228121
  validation loss:		0.326044
  validation accuracy:		89.89 %
Epoch 228 of 2000 took 0.097s
  training loss:		0.235436
  validation loss:		0.309540
  validation accuracy:		90.22 %
Epoch 229 of 2000 took 0.097s
  training loss:		0.233287
  validation loss:		0.298504
  validation accuracy:		90.87 %
Epoch 230 of 2000 took 0.097s
  training loss:		0.232392
  validation loss:		0.310289
  validation accuracy:		90.11 %
Epoch 231 of 2000 took 0.097s
  training loss:		0.225805
  validation loss:		0.309980
  validation accuracy:		89.67 %
Epoch 232 of 2000 took 0.097s
  training loss:		0.230129
  validation loss:		0.321763
  validation accuracy:		90.33 %
Epoch 233 of 2000 took 0.097s
  training loss:		0.225307
  validation loss:		0.327295
  validation accuracy:		89.46 %
Epoch 234 of 2000 took 0.097s
  training loss:		0.222589
  validation loss:		0.297965
  validation accuracy:		90.43 %
Epoch 235 of 2000 took 0.097s
  training loss:		0.219910
  validation loss:		0.309568
  validation accuracy:		90.43 %
Epoch 236 of 2000 took 0.097s
  training loss:		0.221210
  validation loss:		0.332099
  validation accuracy:		89.46 %
Epoch 237 of 2000 took 0.098s
  training loss:		0.231282
  validation loss:		0.310088
  validation accuracy:		90.43 %
Epoch 238 of 2000 took 0.097s
  training loss:		0.220166
  validation loss:		0.320513
  validation accuracy:		89.78 %
Epoch 239 of 2000 took 0.097s
  training loss:		0.222374
  validation loss:		0.308104
  validation accuracy:		90.43 %
Epoch 240 of 2000 took 0.097s
  training loss:		0.221469
  validation loss:		0.306449
  validation accuracy:		90.11 %
Epoch 241 of 2000 took 0.097s
  training loss:		0.223453
  validation loss:		0.297131
  validation accuracy:		90.33 %
Epoch 242 of 2000 took 0.097s
  training loss:		0.226700
  validation loss:		0.324700
  validation accuracy:		89.89 %
Epoch 243 of 2000 took 0.097s
  training loss:		0.222366
  validation loss:		0.315454
  validation accuracy:		90.00 %
Epoch 244 of 2000 took 0.097s
  training loss:		0.228458
  validation loss:		0.306302
  validation accuracy:		90.11 %
Epoch 245 of 2000 took 0.097s
  training loss:		0.230717
  validation loss:		0.324649
  validation accuracy:		89.78 %
Epoch 246 of 2000 took 0.097s
  training loss:		0.225546
  validation loss:		0.296939
  validation accuracy:		90.76 %
Epoch 247 of 2000 took 0.097s
  training loss:		0.222040
  validation loss:		0.323165
  validation accuracy:		90.11 %
Epoch 248 of 2000 took 0.097s
  training loss:		0.224243
  validation loss:		0.306327
  validation accuracy:		90.33 %
Epoch 249 of 2000 took 0.097s
  training loss:		0.226333
  validation loss:		0.306035
  validation accuracy:		90.54 %
Epoch 250 of 2000 took 0.097s
  training loss:		0.220203
  validation loss:		0.321382
  validation accuracy:		89.89 %
Epoch 251 of 2000 took 0.097s
  training loss:		0.217032
  validation loss:		0.312623
  validation accuracy:		90.43 %
Epoch 252 of 2000 took 0.097s
  training loss:		0.217847
  validation loss:		0.308363
  validation accuracy:		90.54 %
Epoch 253 of 2000 took 0.097s
  training loss:		0.215216
  validation loss:		0.329355
  validation accuracy:		89.67 %
Epoch 254 of 2000 took 0.097s
  training loss:		0.218825
  validation loss:		0.298769
  validation accuracy:		90.65 %
Epoch 255 of 2000 took 0.097s
  training loss:		0.218329
  validation loss:		0.305464
  validation accuracy:		90.43 %
Epoch 256 of 2000 took 0.097s
  training loss:		0.224041
  validation loss:		0.343808
  validation accuracy:		89.13 %
Epoch 257 of 2000 took 0.097s
  training loss:		0.223632
  validation loss:		0.300548
  validation accuracy:		90.11 %
Epoch 258 of 2000 took 0.097s
  training loss:		0.219437
  validation loss:		0.303436
  validation accuracy:		90.54 %
Epoch 259 of 2000 took 0.097s
  training loss:		0.214160
  validation loss:		0.300328
  validation accuracy:		90.76 %
Epoch 260 of 2000 took 0.097s
  training loss:		0.211401
  validation loss:		0.322127
  validation accuracy:		90.22 %
Epoch 261 of 2000 took 0.097s
  training loss:		0.219708
  validation loss:		0.318588
  validation accuracy:		90.11 %
Epoch 262 of 2000 took 0.097s
  training loss:		0.214783
  validation loss:		0.303290
  validation accuracy:		90.43 %
Epoch 263 of 2000 took 0.097s
  training loss:		0.211919
  validation loss:		0.341023
  validation accuracy:		89.78 %
Epoch 264 of 2000 took 0.097s
  training loss:		0.217272
  validation loss:		0.327159
  validation accuracy:		89.78 %
Epoch 265 of 2000 took 0.097s
  training loss:		0.215428
  validation loss:		0.313486
  validation accuracy:		90.43 %
Epoch 266 of 2000 took 0.097s
  training loss:		0.208368
  validation loss:		0.312385
  validation accuracy:		90.76 %
Epoch 267 of 2000 took 0.097s
  training loss:		0.206446
  validation loss:		0.313209
  validation accuracy:		90.65 %
Epoch 268 of 2000 took 0.098s
  training loss:		0.216759
  validation loss:		0.306919
  validation accuracy:		90.33 %
Epoch 269 of 2000 took 0.097s
  training loss:		0.215181
  validation loss:		0.310390
  validation accuracy:		90.22 %
Epoch 270 of 2000 took 0.098s
  training loss:		0.216147
  validation loss:		0.304779
  validation accuracy:		90.22 %
Epoch 271 of 2000 took 0.097s
  training loss:		0.210803
  validation loss:		0.328830
  validation accuracy:		89.89 %
Epoch 272 of 2000 took 0.097s
  training loss:		0.211205
  validation loss:		0.310651
  validation accuracy:		90.22 %
Epoch 273 of 2000 took 0.097s
  training loss:		0.212782
  validation loss:		0.300564
  validation accuracy:		90.54 %
Epoch 274 of 2000 took 0.097s
  training loss:		0.211384
  validation loss:		0.310422
  validation accuracy:		90.54 %
Epoch 275 of 2000 took 0.099s
  training loss:		0.217437
  validation loss:		0.312482
  validation accuracy:		90.43 %
Epoch 276 of 2000 took 0.101s
  training loss:		0.212291
  validation loss:		0.316589
  validation accuracy:		90.43 %
Epoch 277 of 2000 took 0.100s
  training loss:		0.215073
  validation loss:		0.323986
  validation accuracy:		89.67 %
Epoch 278 of 2000 took 0.100s
  training loss:		0.212280
  validation loss:		0.309614
  validation accuracy:		90.65 %
Epoch 279 of 2000 took 0.100s
  training loss:		0.215218
  validation loss:		0.301754
  validation accuracy:		91.20 %
Epoch 280 of 2000 took 0.100s
  training loss:		0.206965
  validation loss:		0.308874
  validation accuracy:		90.33 %
Epoch 281 of 2000 took 0.100s
  training loss:		0.209903
  validation loss:		0.317795
  validation accuracy:		90.65 %
Epoch 282 of 2000 took 0.100s
  training loss:		0.204549
  validation loss:		0.314483
  validation accuracy:		90.76 %
Epoch 283 of 2000 took 0.100s
  training loss:		0.210176
  validation loss:		0.310824
  validation accuracy:		90.65 %
Epoch 284 of 2000 took 0.100s
  training loss:		0.210412
  validation loss:		0.325761
  validation accuracy:		90.00 %
Epoch 285 of 2000 took 0.100s
  training loss:		0.216132
  validation loss:		0.307097
  validation accuracy:		90.33 %
Epoch 286 of 2000 took 0.100s
  training loss:		0.203007
  validation loss:		0.306628
  validation accuracy:		90.43 %
Epoch 287 of 2000 took 0.100s
  training loss:		0.207116
  validation loss:		0.319202
  validation accuracy:		90.33 %
Epoch 288 of 2000 took 0.100s
  training loss:		0.208099
  validation loss:		0.310785
  validation accuracy:		90.76 %
Epoch 289 of 2000 took 0.100s
  training loss:		0.202019
  validation loss:		0.312290
  validation accuracy:		90.43 %
Epoch 290 of 2000 took 0.100s
  training loss:		0.204214
  validation loss:		0.317451
  validation accuracy:		90.43 %
Epoch 291 of 2000 took 0.100s
  training loss:		0.201907
  validation loss:		0.309236
  validation accuracy:		90.65 %
Epoch 292 of 2000 took 0.100s
  training loss:		0.202948
  validation loss:		0.314160
  validation accuracy:		90.43 %
Epoch 293 of 2000 took 0.100s
  training loss:		0.197298
  validation loss:		0.303746
  validation accuracy:		90.87 %
Epoch 294 of 2000 took 0.100s
  training loss:		0.205372
  validation loss:		0.325945
  validation accuracy:		89.89 %
Epoch 295 of 2000 took 0.100s
  training loss:		0.209579
  validation loss:		0.306825
  validation accuracy:		90.87 %
Epoch 296 of 2000 took 0.100s
  training loss:		0.205266
  validation loss:		0.315271
  validation accuracy:		90.98 %
Epoch 297 of 2000 took 0.102s
  training loss:		0.207309
  validation loss:		0.311252
  validation accuracy:		90.54 %
Epoch 298 of 2000 took 0.105s
  training loss:		0.198190
  validation loss:		0.310573
  validation accuracy:		90.54 %
Epoch 299 of 2000 took 0.110s
  training loss:		0.205568
  validation loss:		0.304956
  validation accuracy:		90.43 %
Epoch 300 of 2000 took 0.106s
  training loss:		0.203137
  validation loss:		0.306530
  validation accuracy:		90.54 %
Epoch 301 of 2000 took 0.104s
  training loss:		0.210449
  validation loss:		0.312358
  validation accuracy:		90.33 %
Epoch 302 of 2000 took 0.104s
  training loss:		0.203013
  validation loss:		0.321245
  validation accuracy:		90.43 %
Epoch 303 of 2000 took 0.096s
  training loss:		0.206375
  validation loss:		0.306713
  validation accuracy:		90.87 %
Epoch 304 of 2000 took 0.096s
  training loss:		0.201204
  validation loss:		0.306877
  validation accuracy:		90.65 %
Epoch 305 of 2000 took 0.096s
  training loss:		0.203907
  validation loss:		0.302589
  validation accuracy:		90.54 %
Epoch 306 of 2000 took 0.096s
  training loss:		0.205747
  validation loss:		0.334418
  validation accuracy:		90.22 %
Epoch 307 of 2000 took 0.096s
  training loss:		0.203839
  validation loss:		0.312775
  validation accuracy:		90.33 %
Epoch 308 of 2000 took 0.095s
  training loss:		0.202670
  validation loss:		0.308603
  validation accuracy:		90.43 %
Epoch 309 of 2000 took 0.095s
  training loss:		0.195193
  validation loss:		0.319313
  validation accuracy:		90.43 %
Epoch 310 of 2000 took 0.096s
  training loss:		0.201005
  validation loss:		0.310704
  validation accuracy:		90.54 %
Epoch 311 of 2000 took 0.095s
  training loss:		0.198533
  validation loss:		0.310208
  validation accuracy:		90.65 %
Epoch 312 of 2000 took 0.096s
  training loss:		0.197328
  validation loss:		0.312544
  validation accuracy:		90.33 %
Epoch 313 of 2000 took 0.096s
  training loss:		0.201378
  validation loss:		0.315634
  validation accuracy:		90.43 %
Epoch 314 of 2000 took 0.096s
  training loss:		0.205294
  validation loss:		0.324349
  validation accuracy:		90.54 %
Epoch 315 of 2000 took 0.095s
  training loss:		0.203960
  validation loss:		0.317853
  validation accuracy:		89.89 %
Epoch 316 of 2000 took 0.093s
  training loss:		0.197143
  validation loss:		0.317408
  validation accuracy:		89.89 %
Epoch 317 of 2000 took 0.093s
  training loss:		0.201724
  validation loss:		0.318427
  validation accuracy:		90.65 %
Epoch 318 of 2000 took 0.093s
  training loss:		0.201386
  validation loss:		0.306283
  validation accuracy:		90.33 %
Epoch 319 of 2000 took 0.093s
  training loss:		0.203445
  validation loss:		0.316027
  validation accuracy:		90.54 %
Epoch 320 of 2000 took 0.093s
  training loss:		0.197566
  validation loss:		0.332933
  validation accuracy:		90.11 %
Epoch 321 of 2000 took 0.093s
  training loss:		0.201079
  validation loss:		0.315486
  validation accuracy:		90.87 %
Epoch 322 of 2000 took 0.093s
  training loss:		0.192372
  validation loss:		0.326893
  validation accuracy:		90.33 %
Epoch 323 of 2000 took 0.092s
  training loss:		0.189489
  validation loss:		0.309056
  validation accuracy:		90.43 %
Epoch 324 of 2000 took 0.093s
  training loss:		0.202782
  validation loss:		0.306615
  validation accuracy:		90.54 %
Epoch 325 of 2000 took 0.093s
  training loss:		0.194545
  validation loss:		0.301485
  validation accuracy:		91.09 %
Epoch 326 of 2000 took 0.107s
  training loss:		0.192271
  validation loss:		0.309092
  validation accuracy:		90.76 %
Epoch 327 of 2000 took 0.111s
  training loss:		0.197440
  validation loss:		0.318795
  validation accuracy:		89.67 %
Epoch 328 of 2000 took 0.106s
  training loss:		0.204508
  validation loss:		0.317615
  validation accuracy:		90.43 %
Epoch 329 of 2000 took 0.105s
  training loss:		0.193853
  validation loss:		0.333926
  validation accuracy:		89.78 %
Epoch 330 of 2000 took 0.105s
  training loss:		0.196032
  validation loss:		0.326024
  validation accuracy:		90.54 %
Epoch 331 of 2000 took 0.105s
  training loss:		0.196277
  validation loss:		0.307623
  validation accuracy:		90.65 %
Epoch 332 of 2000 took 0.110s
  training loss:		0.196587
  validation loss:		0.311804
  validation accuracy:		90.54 %
Epoch 333 of 2000 took 0.105s
  training loss:		0.189339
  validation loss:		0.314700
  validation accuracy:		90.76 %
Epoch 334 of 2000 took 0.106s
  training loss:		0.197357
  validation loss:		0.304801
  validation accuracy:		90.54 %
Epoch 335 of 2000 took 0.111s
  training loss:		0.194789
  validation loss:		0.316180
  validation accuracy:		90.22 %
Epoch 336 of 2000 took 0.104s
  training loss:		0.197889
  validation loss:		0.331518
  validation accuracy:		89.57 %
Epoch 337 of 2000 took 0.106s
  training loss:		0.196817
  validation loss:		0.313395
  validation accuracy:		90.65 %
Epoch 338 of 2000 took 0.104s
  training loss:		0.190426
  validation loss:		0.313501
  validation accuracy:		90.54 %
Epoch 339 of 2000 took 0.108s
  training loss:		0.190072
  validation loss:		0.308132
  validation accuracy:		90.65 %
Epoch 340 of 2000 took 0.107s
  training loss:		0.195805
  validation loss:		0.328659
  validation accuracy:		90.00 %
Epoch 341 of 2000 took 0.103s
  training loss:		0.192846
  validation loss:		0.319689
  validation accuracy:		90.33 %
Epoch 342 of 2000 took 0.109s
  training loss:		0.196048
  validation loss:		0.307860
  validation accuracy:		90.43 %
Epoch 343 of 2000 took 0.107s
  training loss:		0.194970
  validation loss:		0.322067
  validation accuracy:		90.76 %
Epoch 344 of 2000 took 0.105s
  training loss:		0.190244
  validation loss:		0.327220
  validation accuracy:		90.22 %
Epoch 345 of 2000 took 0.105s
  training loss:		0.187354
  validation loss:		0.313116
  validation accuracy:		90.22 %
Epoch 346 of 2000 took 0.105s
  training loss:		0.186276
  validation loss:		0.325156
  validation accuracy:		90.87 %
Epoch 347 of 2000 took 0.110s
  training loss:		0.196897
  validation loss:		0.326055
  validation accuracy:		90.65 %
Epoch 348 of 2000 took 0.105s
  training loss:		0.195196
  validation loss:		0.329049
  validation accuracy:		90.22 %
Epoch 349 of 2000 took 0.105s
  training loss:		0.191540
  validation loss:		0.319439
  validation accuracy:		90.54 %
Epoch 350 of 2000 took 0.111s
  training loss:		0.194874
  validation loss:		0.316669
  validation accuracy:		90.11 %
Epoch 351 of 2000 took 0.104s
  training loss:		0.187345
  validation loss:		0.318459
  validation accuracy:		90.22 %
Epoch 352 of 2000 took 0.106s
  training loss:		0.194416
  validation loss:		0.311787
  validation accuracy:		90.87 %
Epoch 353 of 2000 took 0.104s
  training loss:		0.187163
  validation loss:		0.314200
  validation accuracy:		90.65 %
Epoch 354 of 2000 took 0.108s
  training loss:		0.186002
  validation loss:		0.315937
  validation accuracy:		90.54 %
Epoch 355 of 2000 took 0.108s
  training loss:		0.193325
  validation loss:		0.314216
  validation accuracy:		90.76 %
Epoch 356 of 2000 took 0.104s
  training loss:		0.190247
  validation loss:		0.338376
  validation accuracy:		90.43 %
Epoch 357 of 2000 took 0.108s
  training loss:		0.200848
  validation loss:		0.316311
  validation accuracy:		90.43 %
Epoch 358 of 2000 took 0.108s
  training loss:		0.194862
  validation loss:		0.319737
  validation accuracy:		90.00 %
Epoch 359 of 2000 took 0.104s
  training loss:		0.182963
  validation loss:		0.313863
  validation accuracy:		90.87 %
Epoch 360 of 2000 took 0.105s
  training loss:		0.186979
  validation loss:		0.324104
  validation accuracy:		90.43 %
Epoch 361 of 2000 took 0.104s
  training loss:		0.193649
  validation loss:		0.315882
  validation accuracy:		90.87 %
Epoch 362 of 2000 took 0.110s
  training loss:		0.187342
  validation loss:		0.318064
  validation accuracy:		90.54 %
Epoch 363 of 2000 took 0.105s
  training loss:		0.187287
  validation loss:		0.316062
  validation accuracy:		90.43 %
Epoch 364 of 2000 took 0.105s
  training loss:		0.190445
  validation loss:		0.329385
  validation accuracy:		90.54 %
Epoch 365 of 2000 took 0.111s
  training loss:		0.188889
  validation loss:		0.327010
  validation accuracy:		90.54 %
Epoch 366 of 2000 took 0.104s
  training loss:		0.186531
  validation loss:		0.322259
  validation accuracy:		90.65 %
Epoch 367 of 2000 took 0.106s
  training loss:		0.192221
  validation loss:		0.325385
  validation accuracy:		90.43 %
Epoch 368 of 2000 took 0.104s
  training loss:		0.187163
  validation loss:		0.311255
  validation accuracy:		90.65 %
Epoch 369 of 2000 took 0.107s
  training loss:		0.185817
  validation loss:		0.313149
  validation accuracy:		90.65 %
Epoch 370 of 2000 took 0.110s
  training loss:		0.186581
  validation loss:		0.318699
  validation accuracy:		90.43 %
Epoch 371 of 2000 took 0.103s
  training loss:		0.186140
  validation loss:		0.319687
  validation accuracy:		90.54 %
Epoch 372 of 2000 took 0.106s
  training loss:		0.197573
  validation loss:		0.332492
  validation accuracy:		90.43 %
Epoch 373 of 2000 took 0.110s
  training loss:		0.188500
  validation loss:		0.309190
  validation accuracy:		91.09 %
Epoch 374 of 2000 took 0.104s
  training loss:		0.188896
  validation loss:		0.326415
  validation accuracy:		90.76 %
Epoch 375 of 2000 took 0.106s
  training loss:		0.179615
  validation loss:		0.311570
  validation accuracy:		90.65 %
Epoch 376 of 2000 took 0.103s
  training loss:		0.187260
  validation loss:		0.335143
  validation accuracy:		90.11 %
Epoch 377 of 2000 took 0.110s
  training loss:		0.188579
  validation loss:		0.323302
  validation accuracy:		89.89 %
Epoch 378 of 2000 took 0.106s
  training loss:		0.183154
  validation loss:		0.311214
  validation accuracy:		90.76 %
Epoch 379 of 2000 took 0.104s
  training loss:		0.182644
  validation loss:		0.312308
  validation accuracy:		90.76 %
Epoch 380 of 2000 took 0.111s
  training loss:		0.187783
  validation loss:		0.329936
  validation accuracy:		90.43 %
Epoch 381 of 2000 took 0.104s
  training loss:		0.185234
  validation loss:		0.312764
  validation accuracy:		90.65 %
Epoch 382 of 2000 took 0.105s
  training loss:		0.183072
  validation loss:		0.316796
  validation accuracy:		90.11 %
Epoch 383 of 2000 took 0.104s
  training loss:		0.182179
  validation loss:		0.315375
  validation accuracy:		90.65 %
Epoch 384 of 2000 took 0.106s
  training loss:		0.180322
  validation loss:		0.321580
  validation accuracy:		90.76 %
Epoch 385 of 2000 took 0.110s
  training loss:		0.176025
  validation loss:		0.352592
  validation accuracy:		90.11 %
Epoch 386 of 2000 took 0.104s
  training loss:		0.187151
  validation loss:		0.309189
  validation accuracy:		90.65 %
Epoch 387 of 2000 took 0.106s
  training loss:		0.187965
  validation loss:		0.330047
  validation accuracy:		90.33 %
Epoch 388 of 2000 took 0.110s
  training loss:		0.190324
  validation loss:		0.313671
  validation accuracy:		90.54 %
Epoch 389 of 2000 took 0.104s
  training loss:		0.186088
  validation loss:		0.343169
  validation accuracy:		90.33 %
Epoch 390 of 2000 took 0.106s
  training loss:		0.187407
  validation loss:		0.310362
  validation accuracy:		91.30 %
Epoch 391 of 2000 took 0.104s
  training loss:		0.178863
  validation loss:		0.310336
  validation accuracy:		90.87 %
Epoch 392 of 2000 took 0.110s
  training loss:		0.177609
  validation loss:		0.330543
  validation accuracy:		90.43 %
Epoch 393 of 2000 took 0.106s
  training loss:		0.176644
  validation loss:		0.316420
  validation accuracy:		90.65 %
Epoch 394 of 2000 took 0.100s
  training loss:		0.179223
  validation loss:		0.327630
  validation accuracy:		90.65 %
Epoch 395 of 2000 took 0.108s
  training loss:		0.180904
  validation loss:		0.324318
  validation accuracy:		90.00 %
Epoch 396 of 2000 took 0.102s
  training loss:		0.178912
  validation loss:		0.322938
  validation accuracy:		90.65 %
Epoch 397 of 2000 took 0.102s
  training loss:		0.185283
  validation loss:		0.341247
  validation accuracy:		90.22 %
Epoch 398 of 2000 took 0.101s
  training loss:		0.180677
  validation loss:		0.321697
  validation accuracy:		90.43 %
Epoch 399 of 2000 took 0.103s
  training loss:		0.178367
  validation loss:		0.353465
  validation accuracy:		89.35 %
Epoch 400 of 2000 took 0.107s
  training loss:		0.183694
  validation loss:		0.324684
  validation accuracy:		90.65 %
Epoch 401 of 2000 took 0.101s
  training loss:		0.175216
  validation loss:		0.341506
  validation accuracy:		90.54 %
Epoch 402 of 2000 took 0.103s
  training loss:		0.180241
  validation loss:		0.312971
  validation accuracy:		91.30 %
Epoch 403 of 2000 took 0.104s
  training loss:		0.189019
  validation loss:		0.346715
  validation accuracy:		90.11 %
Epoch 404 of 2000 took 0.101s
  training loss:		0.179958
  validation loss:		0.327062
  validation accuracy:		90.22 %
Epoch 405 of 2000 took 0.106s
  training loss:		0.176922
  validation loss:		0.321933
  validation accuracy:		90.76 %
Epoch 406 of 2000 took 0.100s
  training loss:		0.181183
  validation loss:		0.323491
  validation accuracy:		90.65 %
Epoch 407 of 2000 took 0.105s
  training loss:		0.178003
  validation loss:		0.320831
  validation accuracy:		90.76 %
Epoch 408 of 2000 took 0.101s
  training loss:		0.176552
  validation loss:		0.330221
  validation accuracy:		89.78 %
Epoch 409 of 2000 took 0.102s
  training loss:		0.180262
  validation loss:		0.318121
  validation accuracy:		90.98 %
Epoch 410 of 2000 took 0.104s
  training loss:		0.183699
  validation loss:		0.335155
  validation accuracy:		90.54 %
Epoch 411 of 2000 took 0.101s
  training loss:		0.179799
  validation loss:		0.319105
  validation accuracy:		90.98 %
Epoch 412 of 2000 took 0.106s
  training loss:		0.181144
  validation loss:		0.338874
  validation accuracy:		90.65 %
Epoch 413 of 2000 took 0.100s
  training loss:		0.178637
  validation loss:		0.322311
  validation accuracy:		90.54 %
Epoch 414 of 2000 took 0.105s
  training loss:		0.180918
  validation loss:		0.323582
  validation accuracy:		90.54 %
Epoch 415 of 2000 took 0.102s
  training loss:		0.176021
  validation loss:		0.333418
  validation accuracy:		90.43 %
Epoch 416 of 2000 took 0.102s
  training loss:		0.180572
  validation loss:		0.345900
  validation accuracy:		89.78 %
Epoch 417 of 2000 took 0.104s
  training loss:		0.177406
  validation loss:		0.346111
  validation accuracy:		90.22 %
Epoch 418 of 2000 took 0.101s
  training loss:		0.182205
  validation loss:		0.330454
  validation accuracy:		90.54 %
Epoch 419 of 2000 took 0.106s
  training loss:		0.182408
  validation loss:		0.324555
  validation accuracy:		90.22 %
Epoch 420 of 2000 took 0.100s
  training loss:		0.171609
  validation loss:		0.315515
  validation accuracy:		90.87 %
Epoch 421 of 2000 took 0.105s
  training loss:		0.175600
  validation loss:		0.325499
  validation accuracy:		90.43 %
Epoch 422 of 2000 took 0.102s
  training loss:		0.183226
  validation loss:		0.334022
  validation accuracy:		90.22 %
Epoch 423 of 2000 took 0.102s
  training loss:		0.174391
  validation loss:		0.323295
  validation accuracy:		90.87 %
Epoch 424 of 2000 took 0.104s
  training loss:		0.177780
  validation loss:		0.320877
  validation accuracy:		91.09 %
Epoch 425 of 2000 took 0.101s
  training loss:		0.177462
  validation loss:		0.334573
  validation accuracy:		90.54 %
Epoch 426 of 2000 took 0.106s
  training loss:		0.184224
  validation loss:		0.327451
  validation accuracy:		90.33 %
Epoch 427 of 2000 took 0.100s
  training loss:		0.174113
  validation loss:		0.323029
  validation accuracy:		90.54 %
Epoch 428 of 2000 took 0.105s
  training loss:		0.175577
  validation loss:		0.332024
  validation accuracy:		90.33 %
Epoch 429 of 2000 took 0.105s
  training loss:		0.168726
  validation loss:		0.321591
  validation accuracy:		91.09 %
Epoch 430 of 2000 took 0.101s
  training loss:		0.177413
  validation loss:		0.332906
  validation accuracy:		90.65 %
Epoch 431 of 2000 took 0.102s
  training loss:		0.173553
  validation loss:		0.317179
  validation accuracy:		90.54 %
Epoch 432 of 2000 took 0.101s
  training loss:		0.173868
  validation loss:		0.335789
  validation accuracy:		90.00 %
Epoch 433 of 2000 took 0.110s
  training loss:		0.169286
  validation loss:		0.337547
  validation accuracy:		90.87 %
Epoch 434 of 2000 took 0.105s
  training loss:		0.174134
  validation loss:		0.320063
  validation accuracy:		90.98 %
Epoch 435 of 2000 took 0.104s
  training loss:		0.177094
  validation loss:		0.335804
  validation accuracy:		89.78 %
Epoch 436 of 2000 took 0.112s
  training loss:		0.184415
  validation loss:		0.321573
  validation accuracy:		90.76 %
Epoch 437 of 2000 took 0.104s
  training loss:		0.172913
  validation loss:		0.326966
  validation accuracy:		90.98 %
Epoch 438 of 2000 took 0.106s
  training loss:		0.170848
  validation loss:		0.330815
  validation accuracy:		90.11 %
Epoch 439 of 2000 took 0.104s
  training loss:		0.172925
  validation loss:		0.326165
  validation accuracy:		91.09 %
Epoch 440 of 2000 took 0.107s
  training loss:		0.168322
  validation loss:		0.325374
  validation accuracy:		90.54 %
Epoch 441 of 2000 took 0.110s
  training loss:		0.173983
  validation loss:		0.327459
  validation accuracy:		90.87 %
Epoch 442 of 2000 took 0.104s
  training loss:		0.179463
  validation loss:		0.321326
  validation accuracy:		90.98 %
Epoch 443 of 2000 took 0.107s
  training loss:		0.170911
  validation loss:		0.320520
  validation accuracy:		90.33 %
Epoch 444 of 2000 took 0.110s
  training loss:		0.170439
  validation loss:		0.328828
  validation accuracy:		90.54 %
Epoch 445 of 2000 took 0.104s
  training loss:		0.177769
  validation loss:		0.347257
  validation accuracy:		90.43 %
Epoch 446 of 2000 took 0.106s
  training loss:		0.183853
  validation loss:		0.330605
  validation accuracy:		90.54 %
Epoch 447 of 2000 took 0.104s
  training loss:		0.172712
  validation loss:		0.327764
  validation accuracy:		90.54 %
Epoch 448 of 2000 took 0.110s
  training loss:		0.171094
  validation loss:		0.327410
  validation accuracy:		90.00 %
Epoch 449 of 2000 took 0.106s
  training loss:		0.176501
  validation loss:		0.324934
  validation accuracy:		90.33 %
Epoch 450 of 2000 took 0.109s
  training loss:		0.169900
  validation loss:		0.328996
  validation accuracy:		90.65 %
Epoch 451 of 2000 took 0.112s
  training loss:		0.173905
  validation loss:		0.328601
  validation accuracy:		90.54 %
Epoch 452 of 2000 took 0.104s
  training loss:		0.170439
  validation loss:		0.343641
  validation accuracy:		90.22 %
Epoch 453 of 2000 took 0.106s
  training loss:		0.169376
  validation loss:		0.330470
  validation accuracy:		90.76 %
Epoch 454 of 2000 took 0.104s
  training loss:		0.167751
  validation loss:		0.335144
  validation accuracy:		90.76 %
Epoch 455 of 2000 took 0.106s
  training loss:		0.174574
  validation loss:		0.320566
  validation accuracy:		91.20 %
Epoch 456 of 2000 took 0.109s
  training loss:		0.171773
  validation loss:		0.334898
  validation accuracy:		90.33 %
Epoch 457 of 2000 took 0.103s
  training loss:		0.172822
  validation loss:		0.321651
  validation accuracy:		90.87 %
Epoch 458 of 2000 took 0.106s
  training loss:		0.168691
  validation loss:		0.334324
  validation accuracy:		90.76 %
Epoch 459 of 2000 took 0.110s
  training loss:		0.172608
  validation loss:		0.336180
  validation accuracy:		90.00 %
Epoch 460 of 2000 took 0.107s
  training loss:		0.170099
  validation loss:		0.339245
  validation accuracy:		90.76 %
Epoch 461 of 2000 took 0.105s
  training loss:		0.174701
  validation loss:		0.331155
  validation accuracy:		90.54 %
Epoch 462 of 2000 took 0.103s
  training loss:		0.174565
  validation loss:		0.319532
  validation accuracy:		90.76 %
Epoch 463 of 2000 took 0.110s
  training loss:		0.172782
  validation loss:		0.343796
  validation accuracy:		90.76 %
Epoch 464 of 2000 took 0.106s
  training loss:		0.169293
  validation loss:		0.325519
  validation accuracy:		90.43 %
Epoch 465 of 2000 took 0.104s
  training loss:		0.167779
  validation loss:		0.326295
  validation accuracy:		90.87 %
Epoch 466 of 2000 took 0.110s
  training loss:		0.169044
  validation loss:		0.347375
  validation accuracy:		90.11 %
Epoch 467 of 2000 took 0.105s
  training loss:		0.170663
  validation loss:		0.325417
  validation accuracy:		90.65 %
Epoch 468 of 2000 took 0.105s
  training loss:		0.171989
  validation loss:		0.335903
  validation accuracy:		90.76 %
Epoch 469 of 2000 took 0.104s
  training loss:		0.173552
  validation loss:		0.335700
  validation accuracy:		90.00 %
Epoch 470 of 2000 took 0.105s
  training loss:		0.167264
  validation loss:		0.333446
  validation accuracy:		90.11 %
Epoch 471 of 2000 took 0.106s
  training loss:		0.167447
  validation loss:		0.336918
  validation accuracy:		90.11 %
Epoch 472 of 2000 took 0.101s
  training loss:		0.174176
  validation loss:		0.324771
  validation accuracy:		91.20 %
Epoch 473 of 2000 took 0.102s
  training loss:		0.162877
  validation loss:		0.327939
  validation accuracy:		90.33 %
Epoch 474 of 2000 took 0.110s
  training loss:		0.168540
  validation loss:		0.339923
  validation accuracy:		90.22 %
Epoch 475 of 2000 took 0.100s
  training loss:		0.165607
  validation loss:		0.357986
  validation accuracy:		90.00 %
Epoch 476 of 2000 took 0.102s
  training loss:		0.170784
  validation loss:		0.327676
  validation accuracy:		90.65 %
Epoch 477 of 2000 took 0.100s
  training loss:		0.166649
  validation loss:		0.340689
  validation accuracy:		91.09 %
Epoch 478 of 2000 took 0.106s
  training loss:		0.165643
  validation loss:		0.355463
  validation accuracy:		89.67 %
Epoch 479 of 2000 took 0.103s
  training loss:		0.163678
  validation loss:		0.343400
  validation accuracy:		89.78 %
Epoch 480 of 2000 took 0.100s
  training loss:		0.165230
  validation loss:		0.343820
  validation accuracy:		90.33 %
Epoch 481 of 2000 took 0.106s
  training loss:		0.169916
  validation loss:		0.364792
  validation accuracy:		89.89 %
Epoch 482 of 2000 took 0.102s
  training loss:		0.169498
  validation loss:		0.339452
  validation accuracy:		90.65 %
Epoch 483 of 2000 took 0.101s
  training loss:		0.170171
  validation loss:		0.348362
  validation accuracy:		90.87 %
Epoch 484 of 2000 took 0.101s
  training loss:		0.161202
  validation loss:		0.325117
  validation accuracy:		90.76 %
Epoch 485 of 2000 took 0.101s
  training loss:		0.170376
  validation loss:		0.335667
  validation accuracy:		90.98 %
Epoch 486 of 2000 took 0.106s
  training loss:		0.168054
  validation loss:		0.341023
  validation accuracy:		90.76 %
Epoch 487 of 2000 took 0.101s
  training loss:		0.167644
  validation loss:		0.329559
  validation accuracy:		90.87 %
Epoch 488 of 2000 took 0.102s
  training loss:		0.171480
  validation loss:		0.328299
  validation accuracy:		90.65 %
Epoch 489 of 2000 took 0.107s
  training loss:		0.161702
  validation loss:		0.333875
  validation accuracy:		90.54 %
Epoch 490 of 2000 took 0.100s
  training loss:		0.164943
  validation loss:		0.332105
  validation accuracy:		90.76 %
Epoch 491 of 2000 took 0.102s
  training loss:		0.165547
  validation loss:		0.350685
  validation accuracy:		90.00 %
Epoch 492 of 2000 took 0.100s
  training loss:		0.163025
  validation loss:		0.334620
  validation accuracy:		90.54 %
Epoch 493 of 2000 took 0.104s
  training loss:		0.166865
  validation loss:		0.329270
  validation accuracy:		91.20 %
Epoch 494 of 2000 took 0.105s
  training loss:		0.160203
  validation loss:		0.324264
  validation accuracy:		90.87 %
Epoch 495 of 2000 took 0.100s
  training loss:		0.160332
  validation loss:		0.325374
  validation accuracy:		90.43 %
Epoch 496 of 2000 took 0.107s
  training loss:		0.164552
  validation loss:		0.325282
  validation accuracy:		90.98 %
Epoch 497 of 2000 took 0.105s
  training loss:		0.168566
  validation loss:		0.349316
  validation accuracy:		90.00 %
Epoch 498 of 2000 took 0.101s
  training loss:		0.161417
  validation loss:		0.330568
  validation accuracy:		90.87 %
Epoch 499 of 2000 took 0.102s
  training loss:		0.165687
  validation loss:		0.338181
  validation accuracy:		90.98 %
Epoch 500 of 2000 took 0.101s
  training loss:		0.171143
  validation loss:		0.337098
  validation accuracy:		90.54 %
Epoch 501 of 2000 took 0.107s
  training loss:		0.165157
  validation loss:		0.333294
  validation accuracy:		90.76 %
Epoch 502 of 2000 took 0.102s
  training loss:		0.177251
  validation loss:		0.340269
  validation accuracy:		90.54 %
Epoch 503 of 2000 took 0.101s
  training loss:		0.160223
  validation loss:		0.340992
  validation accuracy:		90.00 %
Epoch 504 of 2000 took 0.108s
  training loss:		0.167992
  validation loss:		0.344656
  validation accuracy:		89.89 %
Epoch 505 of 2000 took 0.101s
  training loss:		0.166506
  validation loss:		0.361714
  validation accuracy:		90.11 %
Epoch 506 of 2000 took 0.103s
  training loss:		0.157713
  validation loss:		0.349698
  validation accuracy:		90.76 %
Epoch 507 of 2000 took 0.100s
  training loss:		0.161244
  validation loss:		0.342516
  validation accuracy:		90.65 %
Epoch 508 of 2000 took 0.103s
  training loss:		0.162644
  validation loss:		0.325787
  validation accuracy:		90.54 %
Epoch 509 of 2000 took 0.106s
  training loss:		0.159469
  validation loss:		0.343075
  validation accuracy:		90.22 %
Epoch 510 of 2000 took 0.100s
  training loss:		0.158878
  validation loss:		0.324609
  validation accuracy:		90.65 %
Epoch 511 of 2000 took 0.103s
  training loss:		0.170426
  validation loss:		0.348643
  validation accuracy:		90.65 %
Epoch 512 of 2000 took 0.106s
  training loss:		0.162636
  validation loss:		0.355993
  validation accuracy:		90.65 %
Epoch 513 of 2000 took 0.100s
  training loss:		0.161032
  validation loss:		0.343145
  validation accuracy:		90.43 %
Epoch 514 of 2000 took 0.102s
  training loss:		0.165149
  validation loss:		0.329127
  validation accuracy:		90.54 %
Epoch 515 of 2000 took 0.100s
  training loss:		0.164792
  validation loss:		0.331149
  validation accuracy:		90.65 %
Epoch 516 of 2000 took 0.106s
  training loss:		0.164298
  validation loss:		0.327354
  validation accuracy:		90.22 %
Epoch 517 of 2000 took 0.103s
  training loss:		0.158860
  validation loss:		0.343775
  validation accuracy:		90.00 %
Epoch 518 of 2000 took 0.100s
  training loss:		0.163014
  validation loss:		0.334992
  validation accuracy:		90.54 %
Epoch 519 of 2000 took 0.107s
  training loss:		0.161046
  validation loss:		0.340417
  validation accuracy:		90.33 %
Epoch 520 of 2000 took 0.102s
  training loss:		0.161749
  validation loss:		0.354856
  validation accuracy:		89.89 %
Epoch 521 of 2000 took 0.101s
  training loss:		0.159285
  validation loss:		0.339645
  validation accuracy:		90.22 %
Epoch 522 of 2000 took 0.101s
  training loss:		0.163300
  validation loss:		0.347844
  validation accuracy:		89.67 %
Epoch 523 of 2000 took 0.102s
  training loss:		0.158723
  validation loss:		0.334625
  validation accuracy:		89.89 %
Epoch 524 of 2000 took 0.106s
  training loss:		0.164369
  validation loss:		0.336416
  validation accuracy:		90.76 %
Epoch 525 of 2000 took 0.101s
  training loss:		0.157905
  validation loss:		0.349155
  validation accuracy:		90.54 %
Epoch 526 of 2000 took 0.102s
  training loss:		0.161382
  validation loss:		0.337062
  validation accuracy:		90.54 %
Epoch 527 of 2000 took 0.108s
  training loss:		0.158170
  validation loss:		0.348813
  validation accuracy:		91.20 %
Epoch 528 of 2000 took 0.100s
  training loss:		0.161335
  validation loss:		0.345398
  validation accuracy:		90.11 %
Epoch 529 of 2000 took 0.103s
  training loss:		0.161326
  validation loss:		0.341960
  validation accuracy:		90.43 %
Epoch 530 of 2000 took 0.100s
  training loss:		0.168241
  validation loss:		0.357043
  validation accuracy:		90.76 %
Epoch 531 of 2000 took 0.109s
  training loss:		0.160152
  validation loss:		0.344158
  validation accuracy:		90.33 %
Epoch 532 of 2000 took 0.103s
  training loss:		0.157424
  validation loss:		0.334857
  validation accuracy:		90.33 %
Epoch 533 of 2000 took 0.100s
  training loss:		0.158704
  validation loss:		0.331433
  validation accuracy:		90.54 %
Epoch 534 of 2000 took 0.106s
  training loss:		0.165810
  validation loss:		0.338460
  validation accuracy:		90.22 %
Epoch 535 of 2000 took 0.103s
  training loss:		0.162467
  validation loss:		0.332968
  validation accuracy:		90.87 %
Epoch 536 of 2000 took 0.101s
  training loss:		0.163616
  validation loss:		0.344837
  validation accuracy:		90.65 %
Epoch 537 of 2000 took 0.101s
  training loss:		0.155326
  validation loss:		0.354966
  validation accuracy:		90.00 %
Epoch 538 of 2000 took 0.102s
  training loss:		0.161285
  validation loss:		0.341685
  validation accuracy:		90.43 %
Epoch 539 of 2000 took 0.106s
  training loss:		0.160306
  validation loss:		0.349201
  validation accuracy:		90.43 %
Epoch 540 of 2000 took 0.102s
  training loss:		0.153531
  validation loss:		0.340390
  validation accuracy:		91.09 %
Epoch 541 of 2000 took 0.101s
  training loss:		0.160480
  validation loss:		0.342131
  validation accuracy:		89.89 %
Epoch 542 of 2000 took 0.108s
  training loss:		0.157257
  validation loss:		0.352386
  validation accuracy:		90.43 %
Epoch 543 of 2000 took 0.100s
  training loss:		0.162134
  validation loss:		0.345258
  validation accuracy:		90.11 %
Epoch 544 of 2000 took 0.102s
  training loss:		0.155176
  validation loss:		0.353756
  validation accuracy:		89.78 %
Epoch 545 of 2000 took 0.101s
  training loss:		0.155411
  validation loss:		0.346006
  validation accuracy:		90.65 %
Epoch 546 of 2000 took 0.107s
  training loss:		0.166829
  validation loss:		0.333146
  validation accuracy:		90.54 %
Epoch 547 of 2000 took 0.109s
  training loss:		0.156609
  validation loss:		0.341093
  validation accuracy:		90.43 %
Epoch 548 of 2000 took 0.104s
  training loss:		0.156823
  validation loss:		0.342308
  validation accuracy:		90.87 %
Epoch 549 of 2000 took 0.107s
  training loss:		0.150944
  validation loss:		0.346906
  validation accuracy:		90.98 %
Epoch 550 of 2000 took 0.108s
  training loss:		0.158150
  validation loss:		0.349672
  validation accuracy:		89.89 %
Epoch 551 of 2000 took 0.104s
  training loss:		0.170468
  validation loss:		0.348943
  validation accuracy:		90.11 %
Epoch 552 of 2000 took 0.105s
  training loss:		0.155888
  validation loss:		0.357943
  validation accuracy:		90.65 %
Epoch 553 of 2000 took 0.104s
  training loss:		0.154637
  validation loss:		0.332164
  validation accuracy:		90.00 %
Epoch 554 of 2000 took 0.110s
  training loss:		0.151892
  validation loss:		0.347666
  validation accuracy:		90.65 %
Epoch 555 of 2000 took 0.105s
  training loss:		0.147655
  validation loss:		0.334611
  validation accuracy:		90.76 %
Epoch 556 of 2000 took 0.104s
  training loss:		0.155425
  validation loss:		0.342565
  validation accuracy:		90.43 %
Epoch 557 of 2000 took 0.111s
  training loss:		0.156281
  validation loss:		0.353125
  validation accuracy:		89.89 %
Epoch 558 of 2000 took 0.104s
  training loss:		0.155856
  validation loss:		0.366164
  validation accuracy:		90.11 %
Epoch 559 of 2000 took 0.106s
  training loss:		0.157691
  validation loss:		0.365372
  validation accuracy:		90.11 %
Epoch 560 of 2000 took 0.104s
  training loss:		0.171703
  validation loss:		0.338778
  validation accuracy:		90.33 %
Epoch 561 of 2000 took 0.106s
  training loss:		0.156953
  validation loss:		0.336321
  validation accuracy:		90.33 %
Epoch 562 of 2000 took 0.109s
  training loss:		0.153049
  validation loss:		0.335469
  validation accuracy:		90.54 %
Epoch 563 of 2000 took 0.103s
  training loss:		0.153599
  validation loss:		0.347187
  validation accuracy:		90.43 %
Epoch 564 of 2000 took 0.106s
  training loss:		0.152211
  validation loss:		0.353252
  validation accuracy:		91.20 %
Epoch 565 of 2000 took 0.110s
  training loss:		0.149133
  validation loss:		0.352009
  validation accuracy:		90.22 %
Epoch 566 of 2000 took 0.104s
  training loss:		0.164115
  validation loss:		0.341981
  validation accuracy:		91.09 %
Epoch 567 of 2000 took 0.106s
  training loss:		0.158450
  validation loss:		0.361322
  validation accuracy:		89.78 %
Epoch 568 of 2000 took 0.103s
  training loss:		0.153695
  validation loss:		0.334545
  validation accuracy:		90.22 %
Epoch 569 of 2000 took 0.110s
  training loss:		0.154772
  validation loss:		0.355207
  validation accuracy:		90.98 %
Epoch 570 of 2000 took 0.106s
  training loss:		0.149635
  validation loss:		0.354755
  validation accuracy:		90.76 %
Epoch 571 of 2000 took 0.103s
  training loss:		0.151371
  validation loss:		0.349109
  validation accuracy:		90.87 %
Epoch 572 of 2000 took 0.111s
  training loss:		0.152588
  validation loss:		0.357169
  validation accuracy:		90.76 %
Epoch 573 of 2000 took 0.105s
  training loss:		0.150993
  validation loss:		0.352674
  validation accuracy:		90.65 %
Epoch 574 of 2000 took 0.105s
  training loss:		0.161789
  validation loss:		0.353613
  validation accuracy:		90.22 %
Epoch 575 of 2000 took 0.104s
  training loss:		0.153653
  validation loss:		0.334352
  validation accuracy:		90.76 %
Epoch 576 of 2000 took 0.105s
  training loss:		0.155770
  validation loss:		0.347236
  validation accuracy:		90.22 %
Epoch 577 of 2000 took 0.109s
  training loss:		0.155650
  validation loss:		0.346141
  validation accuracy:		90.33 %
Epoch 578 of 2000 took 0.104s
  training loss:		0.152749
  validation loss:		0.363959
  validation accuracy:		90.33 %
Epoch 579 of 2000 took 0.105s
  training loss:		0.149969
  validation loss:		0.336960
  validation accuracy:		90.43 %
Epoch 580 of 2000 took 0.111s
  training loss:		0.157256
  validation loss:		0.348266
  validation accuracy:		90.87 %
Epoch 581 of 2000 took 0.104s
  training loss:		0.154132
  validation loss:		0.339223
  validation accuracy:		90.98 %
Epoch 582 of 2000 took 0.106s
  training loss:		0.148688
  validation loss:		0.338848
  validation accuracy:		90.11 %
Epoch 583 of 2000 took 0.106s
  training loss:		0.149062
  validation loss:		0.338441
  validation accuracy:		90.65 %
Epoch 584 of 2000 took 0.112s
  training loss:		0.148015
  validation loss:		0.348138
  validation accuracy:		90.22 %
Epoch 585 of 2000 took 0.114s
  training loss:		0.149872
  validation loss:		0.349368
  validation accuracy:		90.98 %
Epoch 586 of 2000 took 0.107s
  training loss:		0.149268
  validation loss:		0.340971
  validation accuracy:		90.11 %
Epoch 587 of 2000 took 0.112s
  training loss:		0.151212
  validation loss:		0.363313
  validation accuracy:		90.65 %
Epoch 588 of 2000 took 0.110s
  training loss:		0.149507
  validation loss:		0.341001
  validation accuracy:		90.65 %
Epoch 589 of 2000 took 0.108s
  training loss:		0.143847
  validation loss:		0.342371
  validation accuracy:		90.65 %
Epoch 590 of 2000 took 0.108s
  training loss:		0.149852
  validation loss:		0.359745
  validation accuracy:		90.22 %
Epoch 591 of 2000 took 0.108s
  training loss:		0.156678
  validation loss:		0.334776
  validation accuracy:		90.54 %
Epoch 592 of 2000 took 0.113s
  training loss:		0.152394
  validation loss:		0.352473
  validation accuracy:		90.43 %
Epoch 593 of 2000 took 0.108s
  training loss:		0.145775
  validation loss:		0.356163
  validation accuracy:		90.43 %
Epoch 594 of 2000 took 0.108s
  training loss:		0.152065
  validation loss:		0.343095
  validation accuracy:		90.22 %
Epoch 595 of 2000 took 0.114s
  training loss:		0.144687
  validation loss:		0.364470
  validation accuracy:		90.22 %
Epoch 596 of 2000 took 0.107s
  training loss:		0.155554
  validation loss:		0.366496
  validation accuracy:		90.43 %
Epoch 597 of 2000 took 0.109s
  training loss:		0.142709
  validation loss:		0.348565
  validation accuracy:		90.65 %
Epoch 598 of 2000 took 0.107s
  training loss:		0.147285
  validation loss:		0.356683
  validation accuracy:		90.98 %
Epoch 599 of 2000 took 0.110s
  training loss:		0.144168
  validation loss:		0.355509
  validation accuracy:		89.67 %
Epoch 600 of 2000 took 0.112s
  training loss:		0.146533
  validation loss:		0.345808
  validation accuracy:		90.54 %
Epoch 601 of 2000 took 0.107s
  training loss:		0.148623
  validation loss:		0.355136
  validation accuracy:		90.00 %
Epoch 602 of 2000 took 0.110s
  training loss:		0.148513
  validation loss:		0.354448
  validation accuracy:		90.87 %
Epoch 603 of 2000 took 0.112s
  training loss:		0.146093
  validation loss:		0.342885
  validation accuracy:		90.54 %
Epoch 604 of 2000 took 0.107s
  training loss:		0.149602
  validation loss:		0.343715
  validation accuracy:		90.54 %
Epoch 605 of 2000 took 0.109s
  training loss:		0.152011
  validation loss:		0.361824
  validation accuracy:		90.98 %
Epoch 606 of 2000 took 0.107s
  training loss:		0.148425
  validation loss:		0.345816
  validation accuracy:		90.54 %
Epoch 607 of 2000 took 0.113s
  training loss:		0.145414
  validation loss:		0.342510
  validation accuracy:		90.33 %
Epoch 608 of 2000 took 0.109s
  training loss:		0.144562
  validation loss:		0.345506
  validation accuracy:		90.00 %
Epoch 609 of 2000 took 0.107s
  training loss:		0.147915
  validation loss:		0.354481
  validation accuracy:		89.78 %
Epoch 610 of 2000 took 0.114s
  training loss:		0.142395
  validation loss:		0.368435
  validation accuracy:		90.43 %
Epoch 611 of 2000 took 0.108s
  training loss:		0.146239
  validation loss:		0.351700
  validation accuracy:		89.89 %
Epoch 612 of 2000 took 0.109s
  training loss:		0.155455
  validation loss:		0.351878
  validation accuracy:		90.33 %
Epoch 613 of 2000 took 0.107s
  training loss:		0.147773
  validation loss:		0.373987
  validation accuracy:		89.78 %
Epoch 614 of 2000 took 0.109s
  training loss:		0.156640
  validation loss:		0.369774
  validation accuracy:		90.54 %
Epoch 615 of 2000 took 0.113s
  training loss:		0.148127
  validation loss:		0.355820
  validation accuracy:		90.00 %
Epoch 616 of 2000 took 0.107s
  training loss:		0.145710
  validation loss:		0.355159
  validation accuracy:		90.43 %
Epoch 617 of 2000 took 0.109s
  training loss:		0.147216
  validation loss:		0.365781
  validation accuracy:		91.20 %
Epoch 618 of 2000 took 0.114s
  training loss:		0.146053
  validation loss:		0.370713
  validation accuracy:		90.11 %
Epoch 619 of 2000 took 0.107s
  training loss:		0.145842
  validation loss:		0.344154
  validation accuracy:		90.87 %
Epoch 620 of 2000 took 0.106s
  training loss:		0.141174
  validation loss:		0.369138
  validation accuracy:		89.89 %
Epoch 621 of 2000 took 0.103s
  training loss:		0.144965
  validation loss:		0.367650
  validation accuracy:		89.46 %
Epoch 622 of 2000 took 0.110s
  training loss:		0.140650
  validation loss:		0.372878
  validation accuracy:		89.78 %
Epoch 623 of 2000 took 0.106s
  training loss:		0.146712
  validation loss:		0.356956
  validation accuracy:		91.41 %
Epoch 624 of 2000 took 0.103s
  training loss:		0.147834
  validation loss:		0.348991
  validation accuracy:		90.33 %
Epoch 625 of 2000 took 0.110s
  training loss:		0.139266
  validation loss:		0.367043
  validation accuracy:		89.89 %
Epoch 626 of 2000 took 0.106s
  training loss:		0.138449
  validation loss:		0.364975
  validation accuracy:		90.11 %
Epoch 627 of 2000 took 0.105s
  training loss:		0.148385
  validation loss:		0.354529
  validation accuracy:		89.78 %
Epoch 628 of 2000 took 0.104s
  training loss:		0.141012
  validation loss:		0.359648
  validation accuracy:		90.22 %
Epoch 629 of 2000 took 0.105s
  training loss:		0.144329
  validation loss:		0.347235
  validation accuracy:		90.65 %
Epoch 630 of 2000 took 0.110s
  training loss:		0.145601
  validation loss:		0.365917
  validation accuracy:		90.65 %
Epoch 631 of 2000 took 0.104s
  training loss:		0.142940
  validation loss:		0.358206
  validation accuracy:		89.78 %
Epoch 632 of 2000 took 0.105s
  training loss:		0.145900
  validation loss:		0.371890
  validation accuracy:		89.35 %
Epoch 633 of 2000 took 0.111s
  training loss:		0.138882
  validation loss:		0.346956
  validation accuracy:		90.22 %
Epoch 634 of 2000 took 0.103s
  training loss:		0.144762
  validation loss:		0.367929
  validation accuracy:		90.54 %
Epoch 635 of 2000 took 0.106s
  training loss:		0.140356
  validation loss:		0.359839
  validation accuracy:		89.78 %
Epoch 636 of 2000 took 0.103s
  training loss:		0.143311
  validation loss:		0.350309
  validation accuracy:		89.67 %
Epoch 637 of 2000 took 0.108s
  training loss:		0.153337
  validation loss:		0.372810
  validation accuracy:		90.00 %
Epoch 638 of 2000 took 0.108s
  training loss:		0.149381
  validation loss:		0.352444
  validation accuracy:		89.78 %
Epoch 639 of 2000 took 0.103s
  training loss:		0.145531
  validation loss:		0.370579
  validation accuracy:		90.76 %
Epoch 640 of 2000 took 0.109s
  training loss:		0.141769
  validation loss:		0.373395
  validation accuracy:		90.43 %
Epoch 641 of 2000 took 0.106s
  training loss:		0.146010
  validation loss:		0.372142
  validation accuracy:		90.65 %
Epoch 642 of 2000 took 0.101s
  training loss:		0.142576
  validation loss:		0.357406
  validation accuracy:		90.54 %
Epoch 643 of 2000 took 0.102s
  training loss:		0.145289
  validation loss:		0.364127
  validation accuracy:		89.78 %
Epoch 644 of 2000 took 0.101s
  training loss:		0.143103
  validation loss:		0.357793
  validation accuracy:		90.00 %
Epoch 645 of 2000 took 0.106s
  training loss:		0.139683
  validation loss:		0.355693
  validation accuracy:		90.76 %
Epoch 646 of 2000 took 0.102s
  training loss:		0.143232
  validation loss:		0.367702
  validation accuracy:		89.13 %
Epoch 647 of 2000 took 0.101s
  training loss:		0.143660
  validation loss:		0.360497
  validation accuracy:		89.89 %
Epoch 648 of 2000 took 0.108s
  training loss:		0.146296
  validation loss:		0.363033
  validation accuracy:		90.33 %
Epoch 649 of 2000 took 0.100s
  training loss:		0.148247
  validation loss:		0.361363
  validation accuracy:		90.00 %
Epoch 650 of 2000 took 0.102s
  training loss:		0.141851
  validation loss:		0.358537
  validation accuracy:		90.33 %
Epoch 651 of 2000 took 0.100s
  training loss:		0.139913
  validation loss:		0.361024
  validation accuracy:		90.22 %
Epoch 652 of 2000 took 0.103s
  training loss:		0.141455
  validation loss:		0.373474
  validation accuracy:		90.54 %
Epoch 653 of 2000 took 0.106s
  training loss:		0.137750
  validation loss:		0.362727
  validation accuracy:		90.54 %
Epoch 654 of 2000 took 0.100s
  training loss:		0.137443
  validation loss:		0.358411
  validation accuracy:		90.54 %
Epoch 655 of 2000 took 0.104s
  training loss:		0.147442
  validation loss:		0.352941
  validation accuracy:		90.54 %
Epoch 656 of 2000 took 0.105s
  training loss:		0.134280
  validation loss:		0.361971
  validation accuracy:		90.33 %
Epoch 657 of 2000 took 0.101s
  training loss:		0.131346
  validation loss:		0.375526
  validation accuracy:		90.00 %
Epoch 658 of 2000 took 0.102s
  training loss:		0.140160
  validation loss:		0.367998
  validation accuracy:		90.65 %
Epoch 659 of 2000 took 0.100s
  training loss:		0.140719
  validation loss:		0.383844
  validation accuracy:		90.54 %
Epoch 660 of 2000 took 0.107s
  training loss:		0.140508
  validation loss:		0.362294
  validation accuracy:		90.22 %
Epoch 661 of 2000 took 0.102s
  training loss:		0.137419
  validation loss:		0.379678
  validation accuracy:		90.76 %
Epoch 662 of 2000 took 0.101s
  training loss:		0.144631
  validation loss:		0.356126
  validation accuracy:		90.22 %
Epoch 663 of 2000 took 0.108s
  training loss:		0.136729
  validation loss:		0.358969
  validation accuracy:		90.87 %
Epoch 664 of 2000 took 0.101s
  training loss:		0.133556
  validation loss:		0.358061
  validation accuracy:		90.22 %
Epoch 665 of 2000 took 0.102s
  training loss:		0.134735
  validation loss:		0.360268
  validation accuracy:		90.54 %
Epoch 666 of 2000 took 0.100s
  training loss:		0.136457
  validation loss:		0.364828
  validation accuracy:		90.65 %
Epoch 667 of 2000 took 0.103s
  training loss:		0.134694
  validation loss:		0.367431
  validation accuracy:		90.43 %
Epoch 668 of 2000 took 0.106s
  training loss:		0.136753
  validation loss:		0.359499
  validation accuracy:		90.98 %
Epoch 669 of 2000 took 0.100s
  training loss:		0.134411
  validation loss:		0.359656
  validation accuracy:		90.65 %
Epoch 670 of 2000 took 0.103s
  training loss:		0.138646
  validation loss:		0.403226
  validation accuracy:		90.65 %
Epoch 671 of 2000 took 0.107s
  training loss:		0.139433
  validation loss:		0.368794
  validation accuracy:		90.65 %
Epoch 672 of 2000 took 0.103s
  training loss:		0.133975
  validation loss:		0.361009
  validation accuracy:		90.22 %
Epoch 673 of 2000 took 0.103s
  training loss:		0.142384
  validation loss:		0.362286
  validation accuracy:		90.33 %
Epoch 674 of 2000 took 0.100s
  training loss:		0.146436
  validation loss:		0.380962
  validation accuracy:		90.98 %
Epoch 675 of 2000 took 0.106s
  training loss:		0.135124
  validation loss:		0.366995
  validation accuracy:		89.89 %
Epoch 676 of 2000 took 0.103s
  training loss:		0.137371
  validation loss:		0.367418
  validation accuracy:		90.98 %
Epoch 677 of 2000 took 0.100s
  training loss:		0.137822
  validation loss:		0.368429
  validation accuracy:		89.67 %
Epoch 678 of 2000 took 0.107s
  training loss:		0.135728
  validation loss:		0.369269
  validation accuracy:		91.09 %
Epoch 679 of 2000 took 0.102s
  training loss:		0.139853
  validation loss:		0.378941
  validation accuracy:		90.33 %
Epoch 680 of 2000 took 0.101s
  training loss:		0.129274
  validation loss:		0.359207
  validation accuracy:		90.65 %
Epoch 681 of 2000 took 0.101s
  training loss:		0.129624
  validation loss:		0.371721
  validation accuracy:		90.65 %
Epoch 682 of 2000 took 0.102s
  training loss:		0.138839
  validation loss:		0.360881
  validation accuracy:		90.00 %
Epoch 683 of 2000 took 0.106s
  training loss:		0.134419
  validation loss:		0.385405
  validation accuracy:		90.22 %
Epoch 684 of 2000 took 0.101s
  training loss:		0.138755
  validation loss:		0.355731
  validation accuracy:		90.54 %
Epoch 685 of 2000 took 0.102s
  training loss:		0.133233
  validation loss:		0.374343
  validation accuracy:		90.11 %
Epoch 686 of 2000 took 0.107s
  training loss:		0.140107
  validation loss:		0.364545
  validation accuracy:		90.22 %
Epoch 687 of 2000 took 0.100s
  training loss:		0.142146
  validation loss:		0.372870
  validation accuracy:		90.22 %
Epoch 688 of 2000 took 0.102s
  training loss:		0.136159
  validation loss:		0.379463
  validation accuracy:		90.76 %
Epoch 689 of 2000 took 0.100s
  training loss:		0.140227
  validation loss:		0.378364
  validation accuracy:		90.33 %
Epoch 690 of 2000 took 0.105s
  training loss:		0.136619
  validation loss:		0.354610
  validation accuracy:		90.33 %
Epoch 691 of 2000 took 0.103s
  training loss:		0.138611
  validation loss:		0.365943
  validation accuracy:		90.43 %
Epoch 692 of 2000 took 0.100s
  training loss:		0.132488
  validation loss:		0.363018
  validation accuracy:		90.11 %
Epoch 693 of 2000 took 0.105s
  training loss:		0.136029
  validation loss:		0.380435
  validation accuracy:		90.76 %
Epoch 694 of 2000 took 0.104s
  training loss:		0.137629
  validation loss:		0.420391
  validation accuracy:		89.13 %
Epoch 695 of 2000 took 0.101s
  training loss:		0.135337
  validation loss:		0.386847
  validation accuracy:		90.11 %
Epoch 696 of 2000 took 0.102s
  training loss:		0.136083
  validation loss:		0.372326
  validation accuracy:		90.00 %
Epoch 697 of 2000 took 0.101s
  training loss:		0.132578
  validation loss:		0.383705
  validation accuracy:		90.00 %
Epoch 698 of 2000 took 0.106s
  training loss:		0.131726
  validation loss:		0.366486
  validation accuracy:		90.43 %
Epoch 699 of 2000 took 0.102s
  training loss:		0.130880
  validation loss:		0.381574
  validation accuracy:		89.78 %
Epoch 700 of 2000 took 0.102s
  training loss:		0.135760
  validation loss:		0.381482
  validation accuracy:		89.78 %
Epoch 701 of 2000 took 0.108s
  training loss:		0.136123
  validation loss:		0.377951
  validation accuracy:		90.87 %
Epoch 702 of 2000 took 0.100s
  training loss:		0.135221
  validation loss:		0.375306
  validation accuracy:		89.78 %
Epoch 703 of 2000 took 0.102s
  training loss:		0.132221
  validation loss:		0.377924
  validation accuracy:		90.33 %
Epoch 704 of 2000 took 0.100s
  training loss:		0.131601
  validation loss:		0.371067
  validation accuracy:		90.33 %
Epoch 705 of 2000 took 0.104s
  training loss:		0.131192
  validation loss:		0.399613
  validation accuracy:		90.22 %
Epoch 706 of 2000 took 0.105s
  training loss:		0.136611
  validation loss:		0.385452
  validation accuracy:		90.43 %
Epoch 707 of 2000 took 0.100s
  training loss:		0.133617
  validation loss:		0.358783
  validation accuracy:		90.22 %
Epoch 708 of 2000 took 0.104s
  training loss:		0.138041
  validation loss:		0.377357
  validation accuracy:		89.78 %
Epoch 709 of 2000 took 0.105s
  training loss:		0.124923
  validation loss:		0.381248
  validation accuracy:		89.78 %
Epoch 710 of 2000 took 0.101s
  training loss:		0.128484
  validation loss:		0.384634
  validation accuracy:		91.09 %
Epoch 711 of 2000 took 0.102s
  training loss:		0.131452
  validation loss:		0.361031
  validation accuracy:		90.76 %
Epoch 712 of 2000 took 0.100s
  training loss:		0.137163
  validation loss:		0.383840
  validation accuracy:		90.54 %
Epoch 713 of 2000 took 0.107s
  training loss:		0.129238
  validation loss:		0.362573
  validation accuracy:		91.20 %
Epoch 714 of 2000 took 0.102s
  training loss:		0.131668
  validation loss:		0.394742
  validation accuracy:		90.00 %
Epoch 715 of 2000 took 0.101s
  training loss:		0.136530
  validation loss:		0.379997
  validation accuracy:		90.00 %
Epoch 716 of 2000 took 0.108s
  training loss:		0.138980
  validation loss:		0.391088
  validation accuracy:		89.67 %
Epoch 717 of 2000 took 0.101s
  training loss:		0.132099
  validation loss:		0.370621
  validation accuracy:		90.76 %
Epoch 718 of 2000 took 0.102s
  training loss:		0.132993
  validation loss:		0.379481
  validation accuracy:		90.00 %
Epoch 719 of 2000 took 0.100s
  training loss:		0.131848
  validation loss:		0.372126
  validation accuracy:		90.54 %
Epoch 720 of 2000 took 0.103s
  training loss:		0.131635
  validation loss:		0.365139
  validation accuracy:		90.22 %
Epoch 721 of 2000 took 0.106s
  training loss:		0.130414
  validation loss:		0.376723
  validation accuracy:		90.76 %
Epoch 722 of 2000 took 0.100s
  training loss:		0.129146
  validation loss:		0.370838
  validation accuracy:		90.00 %
Epoch 723 of 2000 took 0.103s
  training loss:		0.124330
  validation loss:		0.371635
  validation accuracy:		91.20 %
Epoch 724 of 2000 took 0.107s
  training loss:		0.132074
  validation loss:		0.371781
  validation accuracy:		89.89 %
Epoch 725 of 2000 took 0.100s
  training loss:		0.134220
  validation loss:		0.363118
  validation accuracy:		90.76 %
Epoch 726 of 2000 took 0.102s
  training loss:		0.132609
  validation loss:		0.388622
  validation accuracy:		90.00 %
Epoch 727 of 2000 took 0.100s
  training loss:		0.128360
  validation loss:		0.380420
  validation accuracy:		90.22 %
Epoch 728 of 2000 took 0.107s
  training loss:		0.130925
  validation loss:		0.365445
  validation accuracy:		90.22 %
Epoch 729 of 2000 took 0.103s
  training loss:		0.129985
  validation loss:		0.392555
  validation accuracy:		89.78 %
Epoch 730 of 2000 took 0.100s
  training loss:		0.128980
  validation loss:		0.367948
  validation accuracy:		90.65 %
Epoch 731 of 2000 took 0.108s
  training loss:		0.125718
  validation loss:		0.394468
  validation accuracy:		89.46 %
Epoch 732 of 2000 took 0.102s
  training loss:		0.137034
  validation loss:		0.388419
  validation accuracy:		89.57 %
Epoch 733 of 2000 took 0.102s
  training loss:		0.129570
  validation loss:		0.393132
  validation accuracy:		90.54 %
Epoch 734 of 2000 took 0.101s
  training loss:		0.126782
  validation loss:		0.395010
  validation accuracy:		90.43 %
Epoch 735 of 2000 took 0.104s
  training loss:		0.127904
  validation loss:		0.370672
  validation accuracy:		90.11 %
Epoch 736 of 2000 took 0.110s
  training loss:		0.126614
  validation loss:		0.374325
  validation accuracy:		90.22 %
Epoch 737 of 2000 took 0.104s
  training loss:		0.127204
  validation loss:		0.362542
  validation accuracy:		91.09 %
Epoch 738 of 2000 took 0.108s
  training loss:		0.141793
  validation loss:		0.364448
  validation accuracy:		91.30 %
Epoch 739 of 2000 took 0.114s
  training loss:		0.125801
  validation loss:		0.367129
  validation accuracy:		90.54 %
Epoch 740 of 2000 took 0.107s
  training loss:		0.122119
  validation loss:		0.383237
  validation accuracy:		90.11 %
Epoch 741 of 2000 took 0.109s
  training loss:		0.131251
  validation loss:		0.372000
  validation accuracy:		90.11 %
Epoch 742 of 2000 took 0.107s
  training loss:		0.130026
  validation loss:		0.378037
  validation accuracy:		90.00 %
Epoch 743 of 2000 took 0.112s
  training loss:		0.127299
  validation loss:		0.368615
  validation accuracy:		90.76 %
Epoch 744 of 2000 took 0.110s
  training loss:		0.128315
  validation loss:		0.368942
  validation accuracy:		90.65 %
Epoch 745 of 2000 took 0.107s
  training loss:		0.128819
  validation loss:		0.386487
  validation accuracy:		89.89 %
Epoch 746 of 2000 took 0.113s
  training loss:		0.119961
  validation loss:		0.366992
  validation accuracy:		90.22 %
Epoch 747 of 2000 took 0.110s
  training loss:		0.135799
  validation loss:		0.376028
  validation accuracy:		90.76 %
Epoch 748 of 2000 took 0.108s
  training loss:		0.131790
  validation loss:		0.367300
  validation accuracy:		90.43 %
Epoch 749 of 2000 took 0.108s
  training loss:		0.125835
  validation loss:		0.366634
  validation accuracy:		90.33 %
Epoch 750 of 2000 took 0.109s
  training loss:		0.120574
  validation loss:		0.370529
  validation accuracy:		91.20 %
Epoch 751 of 2000 took 0.113s
  training loss:		0.125256
  validation loss:		0.408442
  validation accuracy:		90.43 %
Epoch 752 of 2000 took 0.108s
  training loss:		0.126458
  validation loss:		0.368848
  validation accuracy:		90.43 %
Epoch 753 of 2000 took 0.109s
  training loss:		0.128299
  validation loss:		0.372766
  validation accuracy:		90.43 %
Epoch 754 of 2000 took 0.114s
  training loss:		0.121886
  validation loss:		0.374726
  validation accuracy:		90.33 %
Epoch 755 of 2000 took 0.107s
  training loss:		0.118616
  validation loss:		0.395701
  validation accuracy:		90.76 %
Epoch 756 of 2000 took 0.109s
  training loss:		0.124895
  validation loss:		0.366011
  validation accuracy:		90.98 %
Epoch 757 of 2000 took 0.107s
  training loss:		0.126695
  validation loss:		0.373529
  validation accuracy:		90.65 %
Epoch 758 of 2000 took 0.111s
  training loss:		0.127350
  validation loss:		0.371036
  validation accuracy:		90.54 %
Epoch 759 of 2000 took 0.111s
  training loss:		0.122689
  validation loss:		0.379827
  validation accuracy:		90.00 %
Epoch 760 of 2000 took 0.107s
  training loss:		0.128450
  validation loss:		0.394004
  validation accuracy:		90.22 %
Epoch 761 of 2000 took 0.112s
  training loss:		0.127512
  validation loss:		0.381697
  validation accuracy:		90.54 %
Epoch 762 of 2000 took 0.111s
  training loss:		0.127841
  validation loss:		0.380597
  validation accuracy:		91.20 %
Epoch 763 of 2000 took 0.108s
  training loss:		0.124044
  validation loss:		0.367160
  validation accuracy:		91.09 %
Epoch 764 of 2000 took 0.108s
  training loss:		0.118727
  validation loss:		0.379702
  validation accuracy:		90.43 %
Epoch 765 of 2000 took 0.108s
  training loss:		0.122278
  validation loss:		0.395796
  validation accuracy:		89.67 %
Epoch 766 of 2000 took 0.113s
  training loss:		0.119366
  validation loss:		0.368168
  validation accuracy:		90.76 %
Epoch 767 of 2000 took 0.108s
  training loss:		0.127422
  validation loss:		0.444204
  validation accuracy:		89.57 %
Epoch 768 of 2000 took 0.108s
  training loss:		0.132175
  validation loss:		0.382762
  validation accuracy:		91.20 %
Epoch 769 of 2000 took 0.115s
  training loss:		0.121756
  validation loss:		0.420309
  validation accuracy:		89.78 %
Epoch 770 of 2000 took 0.107s
  training loss:		0.124306
  validation loss:		0.382043
  validation accuracy:		90.65 %
Epoch 771 of 2000 took 0.109s
  training loss:		0.122639
  validation loss:		0.373366
  validation accuracy:		90.76 %
Epoch 772 of 2000 took 0.104s
  training loss:		0.120186
  validation loss:		0.383020
  validation accuracy:		90.54 %
Epoch 773 of 2000 took 0.107s
  training loss:		0.119388
  validation loss:		0.373293
  validation accuracy:		90.98 %
Epoch 774 of 2000 took 0.108s
  training loss:		0.125006
  validation loss:		0.379672
  validation accuracy:		90.76 %
Epoch 775 of 2000 took 0.100s
  training loss:		0.117880
  validation loss:		0.381775
  validation accuracy:		90.22 %
Epoch 776 of 2000 took 0.104s
  training loss:		0.129402
  validation loss:		0.372497
  validation accuracy:		90.98 %
Epoch 777 of 2000 took 0.105s
  training loss:		0.119654
  validation loss:		0.393995
  validation accuracy:		90.43 %
Epoch 778 of 2000 took 0.101s
  training loss:		0.121538
  validation loss:		0.378012
  validation accuracy:		90.54 %
Epoch 779 of 2000 took 0.102s
  training loss:		0.121435
  validation loss:		0.375436
  validation accuracy:		90.98 %
Epoch 780 of 2000 took 0.100s
  training loss:		0.116292
  validation loss:		0.396566
  validation accuracy:		90.22 %
Epoch 781 of 2000 took 0.107s
  training loss:		0.118915
  validation loss:		0.404741
  validation accuracy:		90.22 %
Epoch 782 of 2000 took 0.102s
  training loss:		0.128711
  validation loss:		0.381819
  validation accuracy:		90.00 %
Epoch 783 of 2000 took 0.101s
  training loss:		0.121322
  validation loss:		0.392566
  validation accuracy:		90.33 %
Epoch 784 of 2000 took 0.106s
  training loss:		0.119563
  validation loss:		0.395368
  validation accuracy:		90.54 %
Epoch 785 of 2000 took 0.100s
  training loss:		0.122636
  validation loss:		0.408202
  validation accuracy:		90.43 %
Epoch 786 of 2000 took 0.105s
  training loss:		0.120070
  validation loss:		0.390074
  validation accuracy:		90.00 %
Epoch 787 of 2000 took 0.101s
  training loss:		0.113213
  validation loss:		0.392294
  validation accuracy:		90.11 %
Epoch 788 of 2000 took 0.102s
  training loss:		0.124388
  validation loss:		0.385796
  validation accuracy:		90.11 %
Epoch 789 of 2000 took 0.104s
  training loss:		0.113075
  validation loss:		0.391808
  validation accuracy:		90.76 %
Epoch 790 of 2000 took 0.101s
  training loss:		0.118855
  validation loss:		0.391402
  validation accuracy:		90.43 %
Epoch 791 of 2000 took 0.106s
  training loss:		0.119087
  validation loss:		0.402391
  validation accuracy:		90.33 %
Epoch 792 of 2000 took 0.100s
  training loss:		0.120148
  validation loss:		0.395681
  validation accuracy:		90.54 %
Epoch 793 of 2000 took 0.104s
  training loss:		0.120406
  validation loss:		0.391525
  validation accuracy:		90.54 %
Epoch 794 of 2000 took 0.101s
  training loss:		0.125297
  validation loss:		0.398335
  validation accuracy:		90.33 %
Epoch 795 of 2000 took 0.102s
  training loss:		0.118772
  validation loss:		0.390675
  validation accuracy:		90.22 %
Epoch 796 of 2000 took 0.104s
  training loss:		0.117262
  validation loss:		0.395800
  validation accuracy:		90.65 %
Epoch 797 of 2000 took 0.101s
  training loss:		0.117406
  validation loss:		0.398974
  validation accuracy:		90.11 %
Epoch 798 of 2000 took 0.106s
  training loss:		0.125082
  validation loss:		0.372995
  validation accuracy:		90.76 %
Epoch 799 of 2000 took 0.100s
  training loss:		0.115428
  validation loss:		0.390712
  validation accuracy:		90.00 %
Epoch 800 of 2000 took 0.104s
  training loss:		0.122263
  validation loss:		0.391508
  validation accuracy:		90.87 %
Epoch 801 of 2000 took 0.101s
  training loss:		0.115610
  validation loss:		0.385365
  validation accuracy:		90.00 %
Epoch 802 of 2000 took 0.102s
  training loss:		0.117724
  validation loss:		0.391568
  validation accuracy:		90.98 %
Epoch 803 of 2000 took 0.104s
  training loss:		0.119690
  validation loss:		0.424868
  validation accuracy:		89.89 %
Epoch 804 of 2000 took 0.101s
  training loss:		0.117678
  validation loss:		0.396021
  validation accuracy:		90.33 %
Epoch 805 of 2000 took 0.106s
  training loss:		0.108608
  validation loss:		0.380564
  validation accuracy:		90.33 %
Epoch 806 of 2000 took 0.100s
  training loss:		0.122014
  validation loss:		0.396306
  validation accuracy:		90.33 %
Epoch 807 of 2000 took 0.104s
  training loss:		0.117722
  validation loss:		0.381673
  validation accuracy:		90.54 %
Epoch 808 of 2000 took 0.102s
  training loss:		0.114526
  validation loss:		0.425583
  validation accuracy:		90.43 %
Epoch 809 of 2000 took 0.102s
  training loss:		0.118948
  validation loss:		0.388663
  validation accuracy:		90.65 %
Epoch 810 of 2000 took 0.108s
  training loss:		0.120573
  validation loss:		0.383686
  validation accuracy:		90.43 %
Epoch 811 of 2000 took 0.104s
  training loss:		0.118661
  validation loss:		0.412033
  validation accuracy:		90.43 %
Epoch 812 of 2000 took 0.106s
  training loss:		0.119834
  validation loss:		0.382461
  validation accuracy:		90.22 %
Epoch 813 of 2000 took 0.107s
  training loss:		0.112980
  validation loss:		0.392426
  validation accuracy:		90.43 %
Epoch 814 of 2000 took 0.109s
  training loss:		0.111364
  validation loss:		0.398305
  validation accuracy:		89.78 %
Epoch 815 of 2000 took 0.106s
  training loss:		0.121140
  validation loss:		0.400230
  validation accuracy:		90.33 %
Epoch 816 of 2000 took 0.103s
  training loss:		0.121282
  validation loss:		0.379902
  validation accuracy:		90.87 %
Epoch 817 of 2000 took 0.110s
  training loss:		0.109151
  validation loss:		0.393858
  validation accuracy:		89.78 %
Epoch 818 of 2000 took 0.106s
  training loss:		0.115563
  validation loss:		0.384544
  validation accuracy:		90.43 %
Epoch 819 of 2000 took 0.105s
  training loss:		0.112172
  validation loss:		0.405862
  validation accuracy:		90.43 %
Epoch 820 of 2000 took 0.104s
  training loss:		0.114655
  validation loss:		0.417684
  validation accuracy:		90.33 %
Epoch 821 of 2000 took 0.105s
  training loss:		0.116053
  validation loss:		0.383946
  validation accuracy:		90.98 %
Epoch 822 of 2000 took 0.109s
  training loss:		0.116949
  validation loss:		0.423985
  validation accuracy:		90.33 %
Epoch 823 of 2000 took 0.105s
  training loss:		0.115919
  validation loss:		0.375348
  validation accuracy:		90.87 %
Epoch 824 of 2000 took 0.105s
  training loss:		0.113933
  validation loss:		0.415174
  validation accuracy:		90.11 %
Epoch 825 of 2000 took 0.111s
  training loss:		0.119123
  validation loss:		0.383288
  validation accuracy:		90.65 %
Epoch 826 of 2000 took 0.104s
  training loss:		0.117981
  validation loss:		0.407804
  validation accuracy:		89.78 %
Epoch 827 of 2000 took 0.106s
  training loss:		0.117794
  validation loss:		0.384838
  validation accuracy:		90.76 %
Epoch 828 of 2000 took 0.103s
  training loss:		0.121759
  validation loss:		0.383879
  validation accuracy:		90.76 %
Epoch 829 of 2000 took 0.108s
  training loss:		0.115880
  validation loss:		0.393150
  validation accuracy:		90.33 %
Epoch 830 of 2000 took 0.108s
  training loss:		0.111896
  validation loss:		0.393374
  validation accuracy:		90.76 %
Epoch 831 of 2000 took 0.103s
  training loss:		0.115157
  validation loss:		0.400084
  validation accuracy:		89.89 %
Epoch 832 of 2000 took 0.108s
  training loss:		0.117908
  validation loss:		0.383267
  validation accuracy:		90.87 %
Epoch 833 of 2000 took 0.108s
  training loss:		0.119730
  validation loss:		0.410488
  validation accuracy:		90.33 %
Epoch 834 of 2000 took 0.104s
  training loss:		0.116631
  validation loss:		0.394381
  validation accuracy:		90.00 %
Epoch 835 of 2000 took 0.105s
  training loss:		0.118163
  validation loss:		0.397439
  validation accuracy:		90.98 %
Epoch 836 of 2000 took 0.104s
  training loss:		0.116403
  validation loss:		0.407726
  validation accuracy:		90.43 %
Epoch 837 of 2000 took 0.110s
  training loss:		0.116786
  validation loss:		0.393192
  validation accuracy:		90.11 %
Epoch 838 of 2000 took 0.105s
  training loss:		0.117551
  validation loss:		0.390791
  validation accuracy:		90.87 %
Epoch 839 of 2000 took 0.104s
  training loss:		0.115768
  validation loss:		0.397040
  validation accuracy:		90.22 %
Epoch 840 of 2000 took 0.111s
  training loss:		0.117151
  validation loss:		0.399912
  validation accuracy:		90.22 %
Epoch 841 of 2000 took 0.104s
  training loss:		0.112436
  validation loss:		0.405916
  validation accuracy:		89.57 %
Epoch 842 of 2000 took 0.106s
  training loss:		0.114424
  validation loss:		0.414930
  validation accuracy:		89.89 %
Epoch 843 of 2000 took 0.103s
  training loss:		0.113482
  validation loss:		0.411339
  validation accuracy:		90.33 %
Epoch 844 of 2000 took 0.107s
  training loss:		0.118714
  validation loss:		0.397872
  validation accuracy:		90.54 %
Epoch 845 of 2000 took 0.109s
  training loss:		0.108753
  validation loss:		0.401827
  validation accuracy:		90.54 %
Epoch 846 of 2000 took 0.103s
  training loss:		0.108658
  validation loss:		0.408780
  validation accuracy:		89.13 %
Epoch 847 of 2000 took 0.107s
  training loss:		0.119364
  validation loss:		0.408933
  validation accuracy:		89.78 %
Epoch 848 of 2000 took 0.107s
  training loss:		0.110948
  validation loss:		0.419486
  validation accuracy:		90.22 %
Epoch 849 of 2000 took 0.101s
  training loss:		0.112045
  validation loss:		0.396833
  validation accuracy:		90.87 %
Epoch 850 of 2000 took 0.102s
  training loss:		0.116260
  validation loss:		0.381986
  validation accuracy:		90.43 %
Epoch 851 of 2000 took 0.101s
  training loss:		0.110546
  validation loss:		0.414687
  validation accuracy:		89.57 %
Epoch 852 of 2000 took 0.107s
  training loss:		0.116988
  validation loss:		0.392093
  validation accuracy:		90.43 %
Epoch 853 of 2000 took 0.102s
  training loss:		0.113965
  validation loss:		0.389805
  validation accuracy:		90.65 %
Epoch 854 of 2000 took 0.100s
  training loss:		0.111735
  validation loss:		0.403748
  validation accuracy:		90.11 %
Epoch 855 of 2000 took 0.108s
  training loss:		0.113141
  validation loss:		0.404403
  validation accuracy:		90.33 %
Epoch 856 of 2000 took 0.101s
  training loss:		0.113007
  validation loss:		0.399137
  validation accuracy:		90.76 %
Epoch 857 of 2000 took 0.102s
  training loss:		0.115199
  validation loss:		0.392388
  validation accuracy:		90.76 %
Epoch 858 of 2000 took 0.100s
  training loss:		0.109256
  validation loss:		0.403514
  validation accuracy:		90.11 %
Epoch 859 of 2000 took 0.103s
  training loss:		0.114272
  validation loss:		0.381803
  validation accuracy:		90.87 %
Epoch 860 of 2000 took 0.106s
  training loss:		0.109193
  validation loss:		0.397474
  validation accuracy:		90.76 %
Epoch 861 of 2000 took 0.100s
  training loss:		0.113224
  validation loss:		0.431850
  validation accuracy:		90.11 %
Epoch 862 of 2000 took 0.102s
  training loss:		0.113159
  validation loss:		0.395981
  validation accuracy:		90.54 %
Epoch 863 of 2000 took 0.107s
  training loss:		0.109119
  validation loss:		0.406745
  validation accuracy:		90.76 %
Epoch 864 of 2000 took 0.100s
  training loss:		0.110562
  validation loss:		0.396074
  validation accuracy:		90.00 %
Epoch 865 of 2000 took 0.103s
  training loss:		0.107488
  validation loss:		0.418239
  validation accuracy:		90.54 %
Epoch 866 of 2000 took 0.100s
  training loss:		0.112882
  validation loss:		0.410830
  validation accuracy:		89.78 %
Epoch 867 of 2000 took 0.106s
  training loss:		0.109418
  validation loss:		0.409567
  validation accuracy:		90.33 %
Epoch 868 of 2000 took 0.103s
  training loss:		0.103424
  validation loss:		0.394854
  validation accuracy:		90.98 %
Epoch 869 of 2000 took 0.100s
  training loss:		0.111531
  validation loss:		0.401499
  validation accuracy:		90.33 %
Epoch 870 of 2000 took 0.106s
  training loss:		0.115380
  validation loss:		0.405909
  validation accuracy:		89.67 %
Epoch 871 of 2000 took 0.103s
  training loss:		0.108880
  validation loss:		0.403202
  validation accuracy:		90.54 %
Epoch 872 of 2000 took 0.101s
  training loss:		0.104553
  validation loss:		0.416261
  validation accuracy:		90.22 %
Epoch 873 of 2000 took 0.101s
  training loss:		0.113747
  validation loss:		0.397969
  validation accuracy:		91.09 %
Epoch 874 of 2000 took 0.102s
  training loss:		0.111799
  validation loss:		0.437519
  validation accuracy:		89.67 %
Epoch 875 of 2000 took 0.106s
  training loss:		0.106078
  validation loss:		0.394988
  validation accuracy:		90.76 %
Epoch 876 of 2000 took 0.101s
  training loss:		0.106010
  validation loss:		0.400077
  validation accuracy:		90.33 %
Epoch 877 of 2000 took 0.102s
  training loss:		0.112405
  validation loss:		0.448540
  validation accuracy:		89.24 %
Epoch 878 of 2000 took 0.108s
  training loss:		0.105051
  validation loss:		0.414220
  validation accuracy:		90.65 %
Epoch 879 of 2000 took 0.100s
  training loss:		0.105108
  validation loss:		0.419200
  validation accuracy:		90.22 %
Epoch 880 of 2000 took 0.102s
  training loss:		0.105587
  validation loss:		0.416170
  validation accuracy:		89.89 %
Epoch 881 of 2000 took 0.100s
  training loss:		0.108690
  validation loss:		0.413555
  validation accuracy:		90.54 %
Epoch 882 of 2000 took 0.104s
  training loss:		0.109346
  validation loss:		0.411401
  validation accuracy:		90.22 %
Epoch 883 of 2000 took 0.104s
  training loss:		0.102028
  validation loss:		0.402545
  validation accuracy:		90.65 %
Epoch 884 of 2000 took 0.100s
  training loss:		0.106369
  validation loss:		0.407769
  validation accuracy:		90.43 %
Epoch 885 of 2000 took 0.105s
  training loss:		0.110001
  validation loss:		0.429648
  validation accuracy:		89.57 %
Epoch 886 of 2000 took 0.104s
  training loss:		0.113403
  validation loss:		0.423090
  validation accuracy:		90.54 %
Epoch 887 of 2000 took 0.101s
  training loss:		0.103825
  validation loss:		0.407795
  validation accuracy:		90.54 %
Epoch 888 of 2000 took 0.102s
  training loss:		0.102908
  validation loss:		0.409500
  validation accuracy:		90.65 %
Epoch 889 of 2000 took 0.101s
  training loss:		0.105175
  validation loss:		0.421148
  validation accuracy:		89.67 %
Epoch 890 of 2000 took 0.107s
  training loss:		0.112959
  validation loss:		0.413692
  validation accuracy:		90.11 %
Epoch 891 of 2000 took 0.102s
  training loss:		0.107091
  validation loss:		0.399197
  validation accuracy:		90.76 %
Epoch 892 of 2000 took 0.101s
  training loss:		0.105873
  validation loss:		0.424543
  validation accuracy:		89.57 %
Epoch 893 of 2000 took 0.108s
  training loss:		0.103952
  validation loss:		0.414945
  validation accuracy:		89.89 %
Epoch 894 of 2000 took 0.100s
  training loss:		0.106898
  validation loss:		0.403897
  validation accuracy:		90.54 %
Epoch 895 of 2000 took 0.102s
  training loss:		0.105503
  validation loss:		0.409629
  validation accuracy:		90.76 %
Epoch 896 of 2000 took 0.100s
  training loss:		0.118688
  validation loss:		0.427649
  validation accuracy:		90.11 %
Epoch 897 of 2000 took 0.103s
  training loss:		0.107571
  validation loss:		0.421006
  validation accuracy:		90.11 %
Epoch 898 of 2000 took 0.106s
  training loss:		0.105436
  validation loss:		0.419151
  validation accuracy:		90.00 %
Epoch 899 of 2000 took 0.100s
  training loss:		0.105796
  validation loss:		0.433539
  validation accuracy:		89.78 %
Epoch 900 of 2000 took 0.103s
  training loss:		0.107823
  validation loss:		0.427669
  validation accuracy:		89.89 %
Epoch 901 of 2000 took 0.106s
  training loss:		0.104000
  validation loss:		0.427815
  validation accuracy:		90.33 %
Epoch 902 of 2000 took 0.100s
  training loss:		0.103225
  validation loss:		0.437538
  validation accuracy:		90.11 %
Epoch 903 of 2000 took 0.103s
  training loss:		0.107097
  validation loss:		0.444253
  validation accuracy:		89.89 %
Epoch 904 of 2000 took 0.100s
  training loss:		0.104115
  validation loss:		0.410832
  validation accuracy:		90.54 %
Epoch 905 of 2000 took 0.107s
  training loss:		0.102261
  validation loss:		0.413390
  validation accuracy:		90.43 %
Epoch 906 of 2000 took 0.102s
  training loss:		0.114589
  validation loss:		0.422986
  validation accuracy:		90.11 %
Epoch 907 of 2000 took 0.101s
  training loss:		0.102551
  validation loss:		0.403760
  validation accuracy:		90.76 %
Epoch 908 of 2000 took 0.108s
  training loss:		0.106451
  validation loss:		0.431410
  validation accuracy:		89.46 %
Epoch 909 of 2000 took 0.101s
  training loss:		0.100933
  validation loss:		0.440801
  validation accuracy:		89.02 %
Epoch 910 of 2000 took 0.102s
  training loss:		0.107741
  validation loss:		0.420051
  validation accuracy:		90.11 %
Epoch 911 of 2000 took 0.100s
  training loss:		0.104368
  validation loss:		0.426321
  validation accuracy:		90.11 %
Epoch 912 of 2000 took 0.103s
  training loss:		0.102779
  validation loss:		0.402518
  validation accuracy:		90.33 %
Epoch 913 of 2000 took 0.106s
  training loss:		0.108997
  validation loss:		0.413704
  validation accuracy:		90.22 %
Epoch 914 of 2000 took 0.100s
  training loss:		0.109023
  validation loss:		0.421405
  validation accuracy:		89.67 %
Epoch 915 of 2000 took 0.103s
  training loss:		0.102178
  validation loss:		0.421346
  validation accuracy:		89.78 %
Epoch 916 of 2000 took 0.107s
  training loss:		0.100520
  validation loss:		0.406717
  validation accuracy:		90.76 %
Epoch 917 of 2000 took 0.100s
  training loss:		0.102421
  validation loss:		0.421839
  validation accuracy:		90.65 %
Epoch 918 of 2000 took 0.103s
  training loss:		0.103783
  validation loss:		0.423341
  validation accuracy:		90.43 %
Epoch 919 of 2000 took 0.100s
  training loss:		0.097443
  validation loss:		0.432214
  validation accuracy:		89.46 %
Epoch 920 of 2000 took 0.107s
  training loss:		0.107327
  validation loss:		0.424291
  validation accuracy:		90.22 %
Epoch 921 of 2000 took 0.103s
  training loss:		0.099041
  validation loss:		0.450871
  validation accuracy:		90.11 %
Epoch 922 of 2000 took 0.100s
  training loss:		0.102475
  validation loss:		0.411383
  validation accuracy:		90.22 %
Epoch 923 of 2000 took 0.107s
  training loss:		0.099528
  validation loss:		0.441376
  validation accuracy:		90.00 %
Epoch 924 of 2000 took 0.102s
  training loss:		0.102052
  validation loss:		0.414600
  validation accuracy:		90.11 %
Epoch 925 of 2000 took 0.102s
  training loss:		0.102977
  validation loss:		0.400845
  validation accuracy:		91.20 %
Epoch 926 of 2000 took 0.103s
  training loss:		0.104926
  validation loss:		0.420767
  validation accuracy:		90.22 %
Epoch 927 of 2000 took 0.105s
  training loss:		0.102386
  validation loss:		0.422859
  validation accuracy:		89.78 %
Epoch 928 of 2000 took 0.110s
  training loss:		0.105800
  validation loss:		0.435719
  validation accuracy:		90.22 %
Epoch 929 of 2000 took 0.104s
  training loss:		0.104604
  validation loss:		0.423331
  validation accuracy:		90.11 %
Epoch 930 of 2000 took 0.105s
  training loss:		0.105643
  validation loss:		0.442725
  validation accuracy:		89.67 %
Epoch 931 of 2000 took 0.111s
  training loss:		0.098943
  validation loss:		0.424534
  validation accuracy:		90.33 %
Epoch 932 of 2000 took 0.104s
  training loss:		0.102884
  validation loss:		0.435381
  validation accuracy:		90.11 %
Epoch 933 of 2000 took 0.106s
  training loss:		0.096060
  validation loss:		0.447036
  validation accuracy:		90.11 %
Epoch 934 of 2000 took 0.103s
  training loss:		0.100990
  validation loss:		0.433838
  validation accuracy:		89.89 %
Epoch 935 of 2000 took 0.109s
  training loss:		0.101696
  validation loss:		0.434173
  validation accuracy:		90.54 %
Epoch 936 of 2000 took 0.107s
  training loss:		0.101920
  validation loss:		0.425366
  validation accuracy:		90.76 %
Epoch 937 of 2000 took 0.103s
  training loss:		0.102372
  validation loss:		0.425021
  validation accuracy:		89.46 %
Epoch 938 of 2000 took 0.110s
  training loss:		0.101082
  validation loss:		0.425906
  validation accuracy:		90.43 %
Epoch 939 of 2000 took 0.106s
  training loss:		0.099821
  validation loss:		0.474614
  validation accuracy:		90.22 %
Epoch 940 of 2000 took 0.105s
  training loss:		0.104044
  validation loss:		0.434051
  validation accuracy:		90.76 %
Epoch 941 of 2000 took 0.105s
  training loss:		0.099368
  validation loss:		0.450317
  validation accuracy:		90.65 %
Epoch 942 of 2000 took 0.105s
  training loss:		0.097730
  validation loss:		0.448893
  validation accuracy:		90.00 %
Epoch 943 of 2000 took 0.110s
  training loss:		0.102297
  validation loss:		0.423508
  validation accuracy:		90.33 %
Epoch 944 of 2000 took 0.105s
  training loss:		0.108868
  validation loss:		0.477604
  validation accuracy:		89.89 %
Epoch 945 of 2000 took 0.105s
  training loss:		0.103779
  validation loss:		0.422345
  validation accuracy:		90.00 %
Epoch 946 of 2000 took 0.111s
  training loss:		0.102274
  validation loss:		0.422854
  validation accuracy:		90.76 %
Epoch 947 of 2000 took 0.104s
  training loss:		0.095272
  validation loss:		0.439940
  validation accuracy:		90.22 %
Epoch 948 of 2000 took 0.106s
  training loss:		0.103802
  validation loss:		0.445547
  validation accuracy:		90.22 %
Epoch 949 of 2000 took 0.103s
  training loss:		0.098820
  validation loss:		0.462165
  validation accuracy:		90.11 %
Epoch 950 of 2000 took 0.108s
  training loss:		0.109580
  validation loss:		0.442644
  validation accuracy:		90.54 %
Epoch 951 of 2000 took 0.108s
  training loss:		0.106962
  validation loss:		0.439809
  validation accuracy:		90.11 %
Epoch 952 of 2000 took 0.103s
  training loss:		0.097251
  validation loss:		0.445110
  validation accuracy:		90.33 %
Epoch 953 of 2000 took 0.108s
  training loss:		0.094452
  validation loss:		0.448037
  validation accuracy:		90.43 %
Epoch 954 of 2000 took 0.108s
  training loss:		0.119087
  validation loss:		0.446436
  validation accuracy:		90.33 %
Epoch 955 of 2000 took 0.104s
  training loss:		0.095443
  validation loss:		0.450474
  validation accuracy:		90.22 %
Epoch 956 of 2000 took 0.105s
  training loss:		0.098639
  validation loss:		0.432861
  validation accuracy:		89.67 %
Epoch 957 of 2000 took 0.104s
  training loss:		0.098281
  validation loss:		0.424994
  validation accuracy:		90.65 %
Epoch 958 of 2000 took 0.110s
  training loss:		0.101178
  validation loss:		0.435874
  validation accuracy:		90.22 %
Epoch 959 of 2000 took 0.105s
  training loss:		0.095257
  validation loss:		0.443777
  validation accuracy:		89.78 %
Epoch 960 of 2000 took 0.105s
  training loss:		0.108717
  validation loss:		0.478347
  validation accuracy:		89.13 %
Epoch 961 of 2000 took 0.112s
  training loss:		0.100611
  validation loss:		0.461720
  validation accuracy:		89.67 %
Epoch 962 of 2000 took 0.104s
  training loss:		0.108942
  validation loss:		0.447164
  validation accuracy:		90.65 %
Epoch 963 of 2000 took 0.106s
  training loss:		0.092674
  validation loss:		0.450272
  validation accuracy:		90.22 %
Epoch 964 of 2000 took 0.104s
  training loss:		0.100860
  validation loss:		0.463535
  validation accuracy:		89.78 %
Epoch 965 of 2000 took 0.102s
  training loss:		0.098434
  validation loss:		0.427102
  validation accuracy:		90.76 %
Epoch 966 of 2000 took 0.106s
  training loss:		0.095477
  validation loss:		0.447022
  validation accuracy:		90.54 %
Epoch 967 of 2000 took 0.102s
  training loss:		0.104309
  validation loss:		0.447357
  validation accuracy:		90.11 %
Epoch 968 of 2000 took 0.104s
  training loss:		0.106695
  validation loss:		0.464288
  validation accuracy:		90.00 %
Epoch 969 of 2000 took 0.108s
  training loss:		0.098753
  validation loss:		0.468016
  validation accuracy:		89.35 %
Epoch 970 of 2000 took 0.102s
  training loss:		0.102411
  validation loss:		0.438219
  validation accuracy:		89.67 %
Epoch 971 of 2000 took 0.104s
  training loss:		0.100797
  validation loss:		0.435429
  validation accuracy:		90.22 %
Epoch 972 of 2000 took 0.102s
  training loss:		0.095277
  validation loss:		0.464615
  validation accuracy:		90.22 %
Epoch 973 of 2000 took 0.107s
  training loss:		0.099371
  validation loss:		0.434357
  validation accuracy:		90.11 %
Epoch 974 of 2000 took 0.104s
  training loss:		0.094256
  validation loss:		0.461041
  validation accuracy:		90.22 %
Epoch 975 of 2000 took 0.102s
  training loss:		0.096344
  validation loss:		0.441035
  validation accuracy:		89.78 %
Epoch 976 of 2000 took 0.108s
  training loss:		0.096744
  validation loss:		0.445973
  validation accuracy:		90.11 %
Epoch 977 of 2000 took 0.104s
  training loss:		0.097332
  validation loss:		0.471299
  validation accuracy:		90.11 %
Epoch 978 of 2000 took 0.103s
  training loss:		0.097603
  validation loss:		0.475546
  validation accuracy:		89.67 %
Epoch 979 of 2000 took 0.103s
  training loss:		0.099270
  validation loss:		0.446233
  validation accuracy:		89.89 %
Epoch 980 of 2000 took 0.103s
  training loss:		0.116967
  validation loss:		0.439715
  validation accuracy:		90.87 %
Epoch 981 of 2000 took 0.107s
  training loss:		0.093942
  validation loss:		0.447643
  validation accuracy:		90.65 %
Epoch 982 of 2000 took 0.103s
  training loss:		0.094540
  validation loss:		0.469082
  validation accuracy:		89.89 %
Epoch 983 of 2000 took 0.103s
  training loss:		0.098786
  validation loss:		0.452584
  validation accuracy:		90.87 %
Epoch 984 of 2000 took 0.109s
  training loss:		0.091984
  validation loss:		0.460331
  validation accuracy:		90.33 %
Epoch 985 of 2000 took 0.102s
  training loss:		0.098410
  validation loss:		0.434024
  validation accuracy:		90.33 %
Epoch 986 of 2000 took 0.104s
  training loss:		0.095419
  validation loss:		0.456911
  validation accuracy:		89.89 %
Epoch 987 of 2000 took 0.102s
  training loss:		0.097651
  validation loss:		0.443336
  validation accuracy:		90.43 %
Epoch 988 of 2000 took 0.105s
  training loss:		0.097676
  validation loss:		0.455937
  validation accuracy:		89.57 %
Epoch 989 of 2000 took 0.106s
  training loss:		0.100448
  validation loss:		0.460489
  validation accuracy:		90.00 %
Epoch 990 of 2000 took 0.103s
  training loss:		0.091965
  validation loss:		0.448959
  validation accuracy:		90.98 %
Epoch 991 of 2000 took 0.104s
  training loss:		0.100304
  validation loss:		0.459676
  validation accuracy:		89.89 %
Epoch 992 of 2000 took 0.107s
  training loss:		0.098259
  validation loss:		0.451959
  validation accuracy:		90.22 %
Epoch 993 of 2000 took 0.102s
  training loss:		0.096223
  validation loss:		0.475587
  validation accuracy:		90.11 %
Epoch 994 of 2000 took 0.103s
  training loss:		0.098644
  validation loss:		0.477495
  validation accuracy:		90.11 %
Epoch 995 of 2000 took 0.102s
  training loss:		0.101885
  validation loss:		0.465036
  validation accuracy:		90.33 %
Epoch 996 of 2000 took 0.107s
  training loss:		0.089948
  validation loss:		0.449770
  validation accuracy:		90.00 %
Epoch 997 of 2000 took 0.104s
  training loss:		0.097428
  validation loss:		0.471714
  validation accuracy:		90.54 %
Epoch 998 of 2000 took 0.102s
  training loss:		0.094303
  validation loss:		0.501704
  validation accuracy:		89.02 %
Epoch 999 of 2000 took 0.108s
  training loss:		0.111568
  validation loss:		0.447866
  validation accuracy:		90.33 %
Epoch 1000 of 2000 took 0.104s
  training loss:		0.101554
  validation loss:		0.484058
  validation accuracy:		89.78 %
Epoch 1001 of 2000 took 0.103s
  training loss:		0.099098
  validation loss:		0.484110
  validation accuracy:		89.67 %
Epoch 1002 of 2000 took 0.102s
  training loss:		0.096419
  validation loss:		0.465645
  validation accuracy:		90.22 %
Epoch 1003 of 2000 took 0.100s
  training loss:		0.099341
  validation loss:		0.437161
  validation accuracy:		90.43 %
Epoch 1004 of 2000 took 0.103s
  training loss:		0.091925
  validation loss:		0.474820
  validation accuracy:		90.11 %
Epoch 1005 of 2000 took 0.097s
  training loss:		0.095467
  validation loss:		0.450627
  validation accuracy:		89.89 %
Epoch 1006 of 2000 took 0.097s
  training loss:		0.094368
  validation loss:		0.468276
  validation accuracy:		90.87 %
Epoch 1007 of 2000 took 0.103s
  training loss:		0.093549
  validation loss:		0.459425
  validation accuracy:		90.22 %
Epoch 1008 of 2000 took 0.096s
  training loss:		0.093287
  validation loss:		0.446420
  validation accuracy:		90.76 %
Epoch 1009 of 2000 took 0.097s
  training loss:		0.096915
  validation loss:		0.441589
  validation accuracy:		90.98 %
Epoch 1010 of 2000 took 0.096s
  training loss:		0.101446
  validation loss:		0.468602
  validation accuracy:		90.65 %
Epoch 1011 of 2000 took 0.098s
  training loss:		0.096503
  validation loss:		0.458742
  validation accuracy:		89.67 %
Epoch 1012 of 2000 took 0.100s
  training loss:		0.096365
  validation loss:		0.442087
  validation accuracy:		90.87 %
Epoch 1013 of 2000 took 0.096s
  training loss:		0.093477
  validation loss:		0.454574
  validation accuracy:		89.78 %
Epoch 1014 of 2000 took 0.097s
  training loss:		0.090360
  validation loss:		0.458123
  validation accuracy:		90.54 %
Epoch 1015 of 2000 took 0.102s
  training loss:		0.085569
  validation loss:		0.470286
  validation accuracy:		90.00 %
Epoch 1016 of 2000 took 0.096s
  training loss:		0.096247
  validation loss:		0.471532
  validation accuracy:		90.22 %
Epoch 1017 of 2000 took 0.097s
  training loss:		0.097474
  validation loss:		0.482257
  validation accuracy:		89.67 %
Epoch 1018 of 2000 took 0.096s
  training loss:		0.098356
  validation loss:		0.462774
  validation accuracy:		89.67 %
Epoch 1019 of 2000 took 0.101s
  training loss:		0.094006
  validation loss:		0.460357
  validation accuracy:		90.22 %
Epoch 1020 of 2000 took 0.098s
  training loss:		0.089163
  validation loss:		0.475770
  validation accuracy:		90.33 %
Epoch 1021 of 2000 took 0.096s
  training loss:		0.100132
  validation loss:		0.473172
  validation accuracy:		90.76 %
Epoch 1022 of 2000 took 0.101s
  training loss:		0.094437
  validation loss:		0.463587
  validation accuracy:		90.11 %
Epoch 1023 of 2000 took 0.098s
  training loss:		0.094745
  validation loss:		0.457208
  validation accuracy:		90.76 %
Epoch 1024 of 2000 took 0.096s
  training loss:		0.106567
  validation loss:		0.468861
  validation accuracy:		90.43 %
Epoch 1025 of 2000 took 0.097s
  training loss:		0.090927
  validation loss:		0.455251
  validation accuracy:		90.76 %
Epoch 1026 of 2000 took 0.097s
  training loss:		0.091169
  validation loss:		0.455986
  validation accuracy:		90.76 %
Epoch 1027 of 2000 took 0.101s
  training loss:		0.089290
  validation loss:		0.466923
  validation accuracy:		89.46 %
Epoch 1028 of 2000 took 0.097s
  training loss:		0.093058
  validation loss:		0.465669
  validation accuracy:		90.65 %
Epoch 1029 of 2000 took 0.096s
  training loss:		0.097393
  validation loss:		0.500008
  validation accuracy:		90.11 %
Epoch 1030 of 2000 took 0.103s
  training loss:		0.104548
  validation loss:		0.498194
  validation accuracy:		90.00 %
Epoch 1031 of 2000 took 0.096s
  training loss:		0.102397
  validation loss:		0.457204
  validation accuracy:		90.11 %
Epoch 1032 of 2000 took 0.097s
  training loss:		0.093780
  validation loss:		0.485802
  validation accuracy:		90.11 %
Epoch 1033 of 2000 took 0.096s
  training loss:		0.092553
  validation loss:		0.465944
  validation accuracy:		91.09 %
Epoch 1034 of 2000 took 0.097s
  training loss:		0.093659
  validation loss:		0.465479
  validation accuracy:		90.22 %
Epoch 1035 of 2000 took 0.101s
  training loss:		0.090568
  validation loss:		0.467742
  validation accuracy:		89.78 %
Epoch 1036 of 2000 took 0.096s
  training loss:		0.096435
  validation loss:		0.481240
  validation accuracy:		89.89 %
Epoch 1037 of 2000 took 0.097s
  training loss:		0.090637
  validation loss:		0.466326
  validation accuracy:		90.43 %
Epoch 1038 of 2000 took 0.102s
  training loss:		0.087977
  validation loss:		0.461445
  validation accuracy:		90.00 %
Epoch 1039 of 2000 took 0.096s
  training loss:		0.091199
  validation loss:		0.480122
  validation accuracy:		89.89 %
Epoch 1040 of 2000 took 0.097s
  training loss:		0.092000
  validation loss:		0.487502
  validation accuracy:		89.57 %
Epoch 1041 of 2000 took 0.099s
  training loss:		0.093017
  validation loss:		0.468294
  validation accuracy:		90.33 %
Epoch 1042 of 2000 took 0.100s
  training loss:		0.095124
  validation loss:		0.479821
  validation accuracy:		89.78 %
Epoch 1043 of 2000 took 0.098s
  training loss:		0.088729
  validation loss:		0.481282
  validation accuracy:		89.35 %
Epoch 1044 of 2000 took 0.096s
  training loss:		0.091648
  validation loss:		0.476856
  validation accuracy:		90.00 %
Epoch 1045 of 2000 took 0.100s
  training loss:		0.089830
  validation loss:		0.467511
  validation accuracy:		90.76 %
Epoch 1046 of 2000 took 0.099s
  training loss:		0.102744
  validation loss:		0.479342
  validation accuracy:		90.33 %
Epoch 1047 of 2000 took 0.097s
  training loss:		0.093776
  validation loss:		0.467978
  validation accuracy:		90.98 %
Epoch 1048 of 2000 took 0.097s
  training loss:		0.087510
  validation loss:		0.488921
  validation accuracy:		89.78 %
Epoch 1049 of 2000 took 0.096s
  training loss:		0.089235
  validation loss:		0.495186
  validation accuracy:		89.89 %
Epoch 1050 of 2000 took 0.101s
  training loss:		0.084081
  validation loss:		0.488073
  validation accuracy:		90.00 %
Epoch 1051 of 2000 took 0.097s
  training loss:		0.092292
  validation loss:		0.496028
  validation accuracy:		89.89 %
Epoch 1052 of 2000 took 0.097s
  training loss:		0.114129
  validation loss:		0.483466
  validation accuracy:		90.54 %
Epoch 1053 of 2000 took 0.103s
  training loss:		0.086231
  validation loss:		0.493574
  validation accuracy:		90.00 %
Epoch 1054 of 2000 took 0.096s
  training loss:		0.088971
  validation loss:		0.456806
  validation accuracy:		90.65 %
Epoch 1055 of 2000 took 0.097s
  training loss:		0.088452
  validation loss:		0.501908
  validation accuracy:		89.35 %
Epoch 1056 of 2000 took 0.096s
  training loss:		0.092363
  validation loss:		0.487820
  validation accuracy:		89.67 %
Epoch 1057 of 2000 took 0.098s
  training loss:		0.089207
  validation loss:		0.498686
  validation accuracy:		89.78 %
Epoch 1058 of 2000 took 0.101s
  training loss:		0.085683
  validation loss:		0.455181
  validation accuracy:		90.11 %
Epoch 1059 of 2000 took 0.096s
  training loss:		0.088532
  validation loss:		0.498270
  validation accuracy:		89.46 %
Epoch 1060 of 2000 took 0.097s
  training loss:		0.088431
  validation loss:		0.518557
  validation accuracy:		89.89 %
Epoch 1061 of 2000 took 0.102s
  training loss:		0.091670
  validation loss:		0.478590
  validation accuracy:		90.11 %
Epoch 1062 of 2000 took 0.096s
  training loss:		0.096703
  validation loss:		0.476936
  validation accuracy:		90.00 %
Epoch 1063 of 2000 took 0.097s
  training loss:		0.091852
  validation loss:		0.492524
  validation accuracy:		90.43 %
Epoch 1064 of 2000 took 0.096s
  training loss:		0.090396
  validation loss:		0.480635
  validation accuracy:		89.78 %
Epoch 1065 of 2000 took 0.100s
  training loss:		0.092061
  validation loss:		0.482132
  validation accuracy:		90.43 %
Epoch 1066 of 2000 took 0.098s
  training loss:		0.086486
  validation loss:		0.491483
  validation accuracy:		90.76 %
Epoch 1067 of 2000 took 0.096s
  training loss:		0.090191
  validation loss:		0.517519
  validation accuracy:		90.33 %
Epoch 1068 of 2000 took 0.100s
  training loss:		0.088497
  validation loss:		0.494436
  validation accuracy:		90.43 %
Epoch 1069 of 2000 took 0.099s
  training loss:		0.086275
  validation loss:		0.488110
  validation accuracy:		90.11 %
Epoch 1070 of 2000 took 0.097s
  training loss:		0.101774
  validation loss:		0.500156
  validation accuracy:		89.57 %
Epoch 1071 of 2000 took 0.097s
  training loss:		0.089477
  validation loss:		0.496657
  validation accuracy:		90.87 %
Epoch 1072 of 2000 took 0.096s
  training loss:		0.084224
  validation loss:		0.502183
  validation accuracy:		90.54 %
Epoch 1073 of 2000 took 0.101s
  training loss:		0.085400
  validation loss:		0.512736
  validation accuracy:		89.57 %
Epoch 1074 of 2000 took 0.097s
  training loss:		0.093813
  validation loss:		0.561300
  validation accuracy:		89.57 %
Epoch 1075 of 2000 took 0.096s
  training loss:		0.092156
  validation loss:		0.494471
  validation accuracy:		90.65 %
Epoch 1076 of 2000 took 0.102s
  training loss:		0.088899
  validation loss:		0.493165
  validation accuracy:		90.33 %
Epoch 1077 of 2000 took 0.097s
  training loss:		0.089425
  validation loss:		0.505403
  validation accuracy:		89.89 %
Epoch 1078 of 2000 took 0.097s
  training loss:		0.090236
  validation loss:		0.501878
  validation accuracy:		90.11 %
Epoch 1079 of 2000 took 0.096s
  training loss:		0.096765
  validation loss:		0.539458
  validation accuracy:		90.11 %
Epoch 1080 of 2000 took 0.097s
  training loss:		0.088236
  validation loss:		0.503497
  validation accuracy:		89.35 %
Epoch 1081 of 2000 took 0.101s
  training loss:		0.083875
  validation loss:		0.534021
  validation accuracy:		89.57 %
Epoch 1082 of 2000 took 0.096s
  training loss:		0.082826
  validation loss:		0.495412
  validation accuracy:		89.89 %
Epoch 1083 of 2000 took 0.097s
  training loss:		0.098504
  validation loss:		0.491291
  validation accuracy:		90.22 %
Epoch 1084 of 2000 took 0.103s
  training loss:		0.082038
  validation loss:		0.514822
  validation accuracy:		90.11 %
Epoch 1085 of 2000 took 0.096s
  training loss:		0.087085
  validation loss:		0.486581
  validation accuracy:		90.54 %
Epoch 1086 of 2000 took 0.097s
  training loss:		0.085936
  validation loss:		0.506444
  validation accuracy:		89.89 %
Epoch 1087 of 2000 took 0.096s
  training loss:		0.092803
  validation loss:		0.519777
  validation accuracy:		89.67 %
Epoch 1088 of 2000 took 0.099s
  training loss:		0.091361
  validation loss:		0.485582
  validation accuracy:		90.22 %
Epoch 1089 of 2000 took 0.099s
  training loss:		0.089104
  validation loss:		0.512159
  validation accuracy:		89.78 %
Epoch 1090 of 2000 took 0.097s
  training loss:		0.090780
  validation loss:		0.502833
  validation accuracy:		90.22 %
Epoch 1091 of 2000 took 0.097s
  training loss:		0.088617
  validation loss:		0.507321
  validation accuracy:		89.89 %
Epoch 1092 of 2000 took 0.097s
  training loss:		0.088721
  validation loss:		0.493851
  validation accuracy:		90.33 %
Epoch 1093 of 2000 took 0.097s
  training loss:		0.096447
  validation loss:		0.505510
  validation accuracy:		89.78 %
Epoch 1094 of 2000 took 0.097s
  training loss:		0.088802
  validation loss:		0.497729
  validation accuracy:		90.33 %
Epoch 1095 of 2000 took 0.097s
  training loss:		0.085028
  validation loss:		0.532053
  validation accuracy:		89.35 %
Epoch 1096 of 2000 took 0.097s
  training loss:		0.087771
  validation loss:		0.529707
  validation accuracy:		89.46 %
Epoch 1097 of 2000 took 0.097s
  training loss:		0.091198
  validation loss:		0.472629
  validation accuracy:		90.00 %
Epoch 1098 of 2000 took 0.097s
  training loss:		0.092171
  validation loss:		0.502367
  validation accuracy:		90.65 %
Epoch 1099 of 2000 took 0.097s
  training loss:		0.089561
  validation loss:		0.508595
  validation accuracy:		90.33 %
Epoch 1100 of 2000 took 0.097s
  training loss:		0.081927
  validation loss:		0.508971
  validation accuracy:		90.43 %
Epoch 1101 of 2000 took 0.097s
  training loss:		0.084948
  validation loss:		0.469581
  validation accuracy:		90.43 %
Epoch 1102 of 2000 took 0.097s
  training loss:		0.093199
  validation loss:		0.497478
  validation accuracy:		89.78 %
Epoch 1103 of 2000 took 0.097s
  training loss:		0.097313
  validation loss:		0.494373
  validation accuracy:		89.78 %
Epoch 1104 of 2000 took 0.097s
  training loss:		0.085328
  validation loss:		0.507305
  validation accuracy:		89.89 %
Epoch 1105 of 2000 took 0.097s
  training loss:		0.084381
  validation loss:		0.505243
  validation accuracy:		89.13 %
Epoch 1106 of 2000 took 0.097s
  training loss:		0.089416
  validation loss:		0.536251
  validation accuracy:		90.00 %
Epoch 1107 of 2000 took 0.097s
  training loss:		0.089679
  validation loss:		0.495864
  validation accuracy:		90.00 %
Epoch 1108 of 2000 took 0.097s
  training loss:		0.084710
  validation loss:		0.485663
  validation accuracy:		90.65 %
Epoch 1109 of 2000 took 0.097s
  training loss:		0.085917
  validation loss:		0.521143
  validation accuracy:		90.00 %
Epoch 1110 of 2000 took 0.097s
  training loss:		0.085052
  validation loss:		0.523299
  validation accuracy:		90.33 %
Epoch 1111 of 2000 took 0.097s
  training loss:		0.082561
  validation loss:		0.507284
  validation accuracy:		89.67 %
Epoch 1112 of 2000 took 0.098s
  training loss:		0.092581
  validation loss:		0.488979
  validation accuracy:		90.65 %
Epoch 1113 of 2000 took 0.097s
  training loss:		0.099402
  validation loss:		0.550017
  validation accuracy:		88.70 %
Epoch 1114 of 2000 took 0.097s
  training loss:		0.086719
  validation loss:		0.518183
  validation accuracy:		90.00 %
Epoch 1115 of 2000 took 0.097s
  training loss:		0.081041
  validation loss:		0.511839
  validation accuracy:		90.22 %
Epoch 1116 of 2000 took 0.097s
  training loss:		0.087867
  validation loss:		0.540020
  validation accuracy:		89.57 %
Epoch 1117 of 2000 took 0.097s
  training loss:		0.080320
  validation loss:		0.526367
  validation accuracy:		89.57 %
Epoch 1118 of 2000 took 0.097s
  training loss:		0.080877
  validation loss:		0.527412
  validation accuracy:		89.89 %
Epoch 1119 of 2000 took 0.097s
  training loss:		0.085597
  validation loss:		0.545645
  validation accuracy:		89.89 %
Epoch 1120 of 2000 took 0.097s
  training loss:		0.082000
  validation loss:		0.513070
  validation accuracy:		90.11 %
Epoch 1121 of 2000 took 0.097s
  training loss:		0.083957
  validation loss:		0.508811
  validation accuracy:		90.11 %
Epoch 1122 of 2000 took 0.097s
  training loss:		0.094927
  validation loss:		0.543831
  validation accuracy:		89.78 %
Epoch 1123 of 2000 took 0.097s
  training loss:		0.090395
  validation loss:		0.537302
  validation accuracy:		89.35 %
Epoch 1124 of 2000 took 0.097s
  training loss:		0.087486
  validation loss:		0.523752
  validation accuracy:		90.11 %
Epoch 1125 of 2000 took 0.097s
  training loss:		0.099669
  validation loss:		0.512413
  validation accuracy:		89.57 %
Epoch 1126 of 2000 took 0.097s
  training loss:		0.080797
  validation loss:		0.531343
  validation accuracy:		89.67 %
Epoch 1127 of 2000 took 0.097s
  training loss:		0.083738
  validation loss:		0.539647
  validation accuracy:		89.57 %
Epoch 1128 of 2000 took 0.097s
  training loss:		0.087743
  validation loss:		0.509089
  validation accuracy:		90.00 %
Epoch 1129 of 2000 took 0.097s
  training loss:		0.091655
  validation loss:		0.536157
  validation accuracy:		90.33 %
Epoch 1130 of 2000 took 0.097s
  training loss:		0.095044
  validation loss:		0.517590
  validation accuracy:		90.54 %
Epoch 1131 of 2000 took 0.097s
  training loss:		0.086752
  validation loss:		0.505874
  validation accuracy:		90.22 %
Epoch 1132 of 2000 took 0.097s
  training loss:		0.084577
  validation loss:		0.519328
  validation accuracy:		89.46 %
Epoch 1133 of 2000 took 0.097s
  training loss:		0.083525
  validation loss:		0.526049
  validation accuracy:		90.33 %
Epoch 1134 of 2000 took 0.097s
  training loss:		0.085969
  validation loss:		0.521082
  validation accuracy:		89.13 %
Epoch 1135 of 2000 took 0.097s
  training loss:		0.085354
  validation loss:		0.527263
  validation accuracy:		90.11 %
Epoch 1136 of 2000 took 0.097s
  training loss:		0.083631
  validation loss:		0.514381
  validation accuracy:		90.11 %
Epoch 1137 of 2000 took 0.097s
  training loss:		0.087490
  validation loss:		0.518945
  validation accuracy:		90.11 %
Epoch 1138 of 2000 took 0.097s
  training loss:		0.087960
  validation loss:		0.515152
  validation accuracy:		90.65 %
Epoch 1139 of 2000 took 0.097s
  training loss:		0.090594
  validation loss:		0.583320
  validation accuracy:		89.57 %
Epoch 1140 of 2000 took 0.097s
  training loss:		0.085944
  validation loss:		0.544845
  validation accuracy:		90.00 %
Epoch 1141 of 2000 took 0.097s
  training loss:		0.085826
  validation loss:		0.529681
  validation accuracy:		89.24 %
Epoch 1142 of 2000 took 0.097s
  training loss:		0.089977
  validation loss:		0.527859
  validation accuracy:		89.78 %
Epoch 1143 of 2000 took 0.098s
  training loss:		0.087699
  validation loss:		0.535148
  validation accuracy:		89.13 %
Epoch 1144 of 2000 took 0.097s
  training loss:		0.089372
  validation loss:		0.515280
  validation accuracy:		90.33 %
Epoch 1145 of 2000 took 0.097s
  training loss:		0.097809
  validation loss:		0.507066
  validation accuracy:		90.65 %
Epoch 1146 of 2000 took 0.097s
  training loss:		0.089505
  validation loss:		0.543036
  validation accuracy:		89.89 %
Epoch 1147 of 2000 took 0.097s
  training loss:		0.083262
  validation loss:		0.549517
  validation accuracy:		90.00 %
Epoch 1148 of 2000 took 0.097s
  training loss:		0.093255
  validation loss:		0.598746
  validation accuracy:		89.35 %
Epoch 1149 of 2000 took 0.097s
  training loss:		0.090704
  validation loss:		0.536715
  validation accuracy:		89.89 %
Epoch 1150 of 2000 took 0.097s
  training loss:		0.086381
  validation loss:		0.574459
  validation accuracy:		89.78 %
Epoch 1151 of 2000 took 0.097s
  training loss:		0.085514
  validation loss:		0.546602
  validation accuracy:		89.78 %
Epoch 1152 of 2000 took 0.097s
  training loss:		0.095389
  validation loss:		0.539592
  validation accuracy:		89.89 %
Epoch 1153 of 2000 took 0.097s
  training loss:		0.083642
  validation loss:		0.537995
  validation accuracy:		90.00 %
Epoch 1154 of 2000 took 0.097s
  training loss:		0.081658
  validation loss:		0.567487
  validation accuracy:		88.37 %
Epoch 1155 of 2000 took 0.097s
  training loss:		0.086163
  validation loss:		0.518655
  validation accuracy:		90.65 %
Epoch 1156 of 2000 took 0.097s
  training loss:		0.094344
  validation loss:		0.543851
  validation accuracy:		89.89 %
Epoch 1157 of 2000 took 0.102s
  training loss:		0.091755
  validation loss:		0.542018
  validation accuracy:		88.70 %
Epoch 1158 of 2000 took 0.103s
  training loss:		0.087048
  validation loss:		0.541955
  validation accuracy:		90.43 %
Epoch 1159 of 2000 took 0.102s
  training loss:		0.089880
  validation loss:		0.545857
  validation accuracy:		89.57 %
Epoch 1160 of 2000 took 0.100s
  training loss:		0.089472
  validation loss:		0.550843
  validation accuracy:		89.35 %
Epoch 1161 of 2000 took 0.100s
  training loss:		0.087776
  validation loss:		0.536035
  validation accuracy:		88.80 %
Epoch 1162 of 2000 took 0.100s
  training loss:		0.100899
  validation loss:		0.527014
  validation accuracy:		90.11 %
Epoch 1163 of 2000 took 0.100s
  training loss:		0.077576
  validation loss:		0.554648
  validation accuracy:		89.57 %
Epoch 1164 of 2000 took 0.100s
  training loss:		0.082911
  validation loss:		0.535054
  validation accuracy:		89.57 %
Epoch 1165 of 2000 took 0.100s
  training loss:		0.082268
  validation loss:		0.517949
  validation accuracy:		90.33 %
Epoch 1166 of 2000 took 0.100s
  training loss:		0.075599
  validation loss:		0.535655
  validation accuracy:		89.78 %
Epoch 1167 of 2000 took 0.101s
  training loss:		0.079475
  validation loss:		0.545768
  validation accuracy:		89.78 %
Epoch 1168 of 2000 took 0.103s
  training loss:		0.081404
  validation loss:		0.526866
  validation accuracy:		90.54 %
Epoch 1169 of 2000 took 0.104s
  training loss:		0.080554
  validation loss:		0.553871
  validation accuracy:		89.35 %
Epoch 1170 of 2000 took 0.103s
  training loss:		0.093098
  validation loss:		0.556867
  validation accuracy:		89.78 %
Epoch 1171 of 2000 took 0.104s
  training loss:		0.078954
  validation loss:		0.613187
  validation accuracy:		88.80 %
Epoch 1172 of 2000 took 0.103s
  training loss:		0.092325
  validation loss:		0.529441
  validation accuracy:		89.89 %
Epoch 1173 of 2000 took 0.104s
  training loss:		0.081405
  validation loss:		0.598066
  validation accuracy:		89.46 %
Epoch 1174 of 2000 took 0.103s
  training loss:		0.081462
  validation loss:		0.535587
  validation accuracy:		89.57 %
Epoch 1175 of 2000 took 0.103s
  training loss:		0.118654
  validation loss:		0.540297
  validation accuracy:		89.46 %
Epoch 1176 of 2000 took 0.103s
  training loss:		0.095530
  validation loss:		0.536167
  validation accuracy:		90.00 %
Epoch 1177 of 2000 took 0.103s
  training loss:		0.080803
  validation loss:		0.566988
  validation accuracy:		89.13 %
Epoch 1178 of 2000 took 0.102s
  training loss:		0.084176
  validation loss:		0.532670
  validation accuracy:		90.22 %
Epoch 1179 of 2000 took 0.100s
  training loss:		0.079068
  validation loss:		0.624980
  validation accuracy:		88.80 %
Epoch 1180 of 2000 took 0.100s
  training loss:		0.101927
  validation loss:		0.545392
  validation accuracy:		89.35 %
Epoch 1181 of 2000 took 0.100s
  training loss:		0.076508
  validation loss:		0.558328
  validation accuracy:		89.24 %
Epoch 1182 of 2000 took 0.100s
  training loss:		0.082017
  validation loss:		0.542040
  validation accuracy:		90.00 %
Epoch 1183 of 2000 took 0.100s
  training loss:		0.082348
  validation loss:		0.552775
  validation accuracy:		89.57 %
Epoch 1184 of 2000 took 0.100s
  training loss:		0.089141
  validation loss:		0.563049
  validation accuracy:		89.78 %
Epoch 1185 of 2000 took 0.100s
  training loss:		0.086988
  validation loss:		0.552733
  validation accuracy:		89.24 %
Epoch 1186 of 2000 took 0.101s
  training loss:		0.085173
  validation loss:		0.548418
  validation accuracy:		90.33 %
Epoch 1187 of 2000 took 0.100s
  training loss:		0.078318
  validation loss:		0.576009
  validation accuracy:		89.35 %
Epoch 1188 of 2000 took 0.100s
  training loss:		0.081067
  validation loss:		0.560089
  validation accuracy:		89.24 %
Epoch 1189 of 2000 took 0.100s
  training loss:		0.088862
  validation loss:		0.548871
  validation accuracy:		90.11 %
Epoch 1190 of 2000 took 0.100s
  training loss:		0.085741
  validation loss:		0.588244
  validation accuracy:		89.35 %
Epoch 1191 of 2000 took 0.100s
  training loss:		0.104476
  validation loss:		0.538927
  validation accuracy:		89.78 %
Epoch 1192 of 2000 took 0.100s
  training loss:		0.078173
  validation loss:		0.530134
  validation accuracy:		90.65 %
Epoch 1193 of 2000 took 0.100s
  training loss:		0.081445
  validation loss:		0.555051
  validation accuracy:		90.11 %
Epoch 1194 of 2000 took 0.100s
  training loss:		0.095391
  validation loss:		0.555931
  validation accuracy:		89.89 %
Epoch 1195 of 2000 took 0.100s
  training loss:		0.084826
  validation loss:		0.558548
  validation accuracy:		90.11 %
Epoch 1196 of 2000 took 0.100s
  training loss:		0.076339
  validation loss:		0.611435
  validation accuracy:		89.13 %
Epoch 1197 of 2000 took 0.100s
  training loss:		0.080641
  validation loss:		0.547221
  validation accuracy:		90.11 %
Epoch 1198 of 2000 took 0.100s
  training loss:		0.079640
  validation loss:		0.566440
  validation accuracy:		89.89 %
Epoch 1199 of 2000 took 0.100s
  training loss:		0.080172
  validation loss:		0.576819
  validation accuracy:		89.78 %
Epoch 1200 of 2000 took 0.100s
  training loss:		0.078059
  validation loss:		0.558396
  validation accuracy:		90.22 %
Epoch 1201 of 2000 took 0.100s
  training loss:		0.080603
  validation loss:		0.560099
  validation accuracy:		89.57 %
Epoch 1202 of 2000 took 0.100s
  training loss:		0.084133
  validation loss:		0.572832
  validation accuracy:		89.67 %
Epoch 1203 of 2000 took 0.101s
  training loss:		0.085282
  validation loss:		0.544020
  validation accuracy:		90.00 %
Epoch 1204 of 2000 took 0.100s
  training loss:		0.084092
  validation loss:		0.564737
  validation accuracy:		89.35 %
Epoch 1205 of 2000 took 0.100s
  training loss:		0.076820
  validation loss:		0.575452
  validation accuracy:		89.57 %
Epoch 1206 of 2000 took 0.100s
  training loss:		0.077061
  validation loss:		0.578145
  validation accuracy:		89.67 %
Epoch 1207 of 2000 took 0.098s
  training loss:		0.083964
  validation loss:		0.564056
  validation accuracy:		89.02 %
Epoch 1208 of 2000 took 0.097s
  training loss:		0.077415
  validation loss:		0.553773
  validation accuracy:		89.89 %
Epoch 1209 of 2000 took 0.097s
  training loss:		0.093367
  validation loss:		0.644664
  validation accuracy:		88.80 %
Epoch 1210 of 2000 took 0.097s
  training loss:		0.085298
  validation loss:		0.583426
  validation accuracy:		90.00 %
Epoch 1211 of 2000 took 0.097s
  training loss:		0.082402
  validation loss:		0.581195
  validation accuracy:		88.48 %
Epoch 1212 of 2000 took 0.097s
  training loss:		0.087727
  validation loss:		0.585780
  validation accuracy:		89.24 %
Epoch 1213 of 2000 took 0.097s
  training loss:		0.077589
  validation loss:		0.558592
  validation accuracy:		89.89 %
Epoch 1214 of 2000 took 0.097s
  training loss:		0.087885
  validation loss:		0.570712
  validation accuracy:		90.00 %
Epoch 1215 of 2000 took 0.097s
  training loss:		0.083939
  validation loss:		0.573377
  validation accuracy:		89.57 %
Epoch 1216 of 2000 took 0.097s
  training loss:		0.071426
  validation loss:		0.570988
  validation accuracy:		89.78 %
Epoch 1217 of 2000 took 0.097s
  training loss:		0.083831
  validation loss:		0.562166
  validation accuracy:		89.67 %
Epoch 1218 of 2000 took 0.097s
  training loss:		0.084079
  validation loss:		0.563656
  validation accuracy:		89.13 %
Epoch 1219 of 2000 took 0.097s
  training loss:		0.075211
  validation loss:		0.565643
  validation accuracy:		89.67 %
Epoch 1220 of 2000 took 0.097s
  training loss:		0.079116
  validation loss:		0.559820
  validation accuracy:		90.22 %
Epoch 1221 of 2000 took 0.097s
  training loss:		0.089675
  validation loss:		0.613675
  validation accuracy:		88.91 %
Epoch 1222 of 2000 took 0.097s
  training loss:		0.093860
  validation loss:		0.561264
  validation accuracy:		89.67 %
Epoch 1223 of 2000 took 0.097s
  training loss:		0.083652
  validation loss:		0.559523
  validation accuracy:		90.00 %
Epoch 1224 of 2000 took 0.097s
  training loss:		0.079121
  validation loss:		0.552477
  validation accuracy:		90.11 %
Epoch 1225 of 2000 took 0.097s
  training loss:		0.078785
  validation loss:		0.602438
  validation accuracy:		89.57 %
Epoch 1226 of 2000 took 0.097s
  training loss:		0.075285
  validation loss:		0.569691
  validation accuracy:		89.46 %
Epoch 1227 of 2000 took 0.097s
  training loss:		0.072549
  validation loss:		0.599717
  validation accuracy:		89.46 %
Epoch 1228 of 2000 took 0.097s
  training loss:		0.081873
  validation loss:		0.570650
  validation accuracy:		90.43 %
Epoch 1229 of 2000 took 0.097s
  training loss:		0.081521
  validation loss:		0.544962
  validation accuracy:		90.33 %
Epoch 1230 of 2000 took 0.097s
  training loss:		0.083078
  validation loss:		0.594362
  validation accuracy:		89.57 %
Epoch 1231 of 2000 took 0.097s
  training loss:		0.086024
  validation loss:		0.600242
  validation accuracy:		89.89 %
Epoch 1232 of 2000 took 0.097s
  training loss:		0.081489
  validation loss:		0.597236
  validation accuracy:		89.46 %
Epoch 1233 of 2000 took 0.097s
  training loss:		0.088732
  validation loss:		0.541681
  validation accuracy:		90.33 %
Epoch 1234 of 2000 took 0.098s
  training loss:		0.076915
  validation loss:		0.572092
  validation accuracy:		89.89 %
Epoch 1235 of 2000 took 0.097s
  training loss:		0.091923
  validation loss:		0.569712
  validation accuracy:		89.78 %
Epoch 1236 of 2000 took 0.097s
  training loss:		0.108307
  validation loss:		0.585496
  validation accuracy:		90.00 %
Epoch 1237 of 2000 took 0.097s
  training loss:		0.078021
  validation loss:		0.553535
  validation accuracy:		90.11 %
Epoch 1238 of 2000 took 0.097s
  training loss:		0.081611
  validation loss:		0.566264
  validation accuracy:		89.24 %
Epoch 1239 of 2000 took 0.097s
  training loss:		0.103381
  validation loss:		0.574718
  validation accuracy:		89.89 %
Epoch 1240 of 2000 took 0.097s
  training loss:		0.087082
  validation loss:		0.554284
  validation accuracy:		89.67 %
Epoch 1241 of 2000 took 0.097s
  training loss:		0.078594
  validation loss:		0.596031
  validation accuracy:		89.35 %
Epoch 1242 of 2000 took 0.097s
  training loss:		0.087735
  validation loss:		0.586135
  validation accuracy:		89.78 %
Epoch 1243 of 2000 took 0.097s
  training loss:		0.087541
  validation loss:		0.575006
  validation accuracy:		88.70 %
Epoch 1244 of 2000 took 0.097s
  training loss:		0.097872
  validation loss:		0.619952
  validation accuracy:		88.80 %
Epoch 1245 of 2000 took 0.097s
  training loss:		0.078189
  validation loss:		0.574037
  validation accuracy:		89.78 %
Epoch 1246 of 2000 took 0.097s
  training loss:		0.077471
  validation loss:		0.572227
  validation accuracy:		90.22 %
Epoch 1247 of 2000 took 0.097s
  training loss:		0.074726
  validation loss:		0.577687
  validation accuracy:		90.11 %
Epoch 1248 of 2000 took 0.097s
  training loss:		0.088730
  validation loss:		0.610803
  validation accuracy:		88.48 %
Epoch 1249 of 2000 took 0.097s
  training loss:		0.084264
  validation loss:		0.595384
  validation accuracy:		89.35 %
Epoch 1250 of 2000 took 0.097s
  training loss:		0.077151
  validation loss:		0.562102
  validation accuracy:		90.00 %
Epoch 1251 of 2000 took 0.097s
  training loss:		0.085987
  validation loss:		0.572113
  validation accuracy:		90.33 %
Epoch 1252 of 2000 took 0.097s
  training loss:		0.084875
  validation loss:		0.580134
  validation accuracy:		89.78 %
Epoch 1253 of 2000 took 0.097s
  training loss:		0.084217
  validation loss:		0.605214
  validation accuracy:		89.46 %
Epoch 1254 of 2000 took 0.097s
  training loss:		0.081788
  validation loss:		0.576297
  validation accuracy:		89.57 %
Epoch 1255 of 2000 took 0.097s
  training loss:		0.116091
  validation loss:		0.581827
  validation accuracy:		88.91 %
Epoch 1256 of 2000 took 0.097s
  training loss:		0.077786
  validation loss:		0.585285
  validation accuracy:		89.67 %
Epoch 1257 of 2000 took 0.097s
  training loss:		0.076708
  validation loss:		0.564649
  validation accuracy:		90.33 %
Epoch 1258 of 2000 took 0.097s
  training loss:		0.076341
  validation loss:		0.577021
  validation accuracy:		88.80 %
Epoch 1259 of 2000 took 0.097s
  training loss:		0.082883
  validation loss:		0.583701
  validation accuracy:		88.91 %
Epoch 1260 of 2000 took 0.097s
  training loss:		0.075831
  validation loss:		0.595129
  validation accuracy:		89.57 %
Epoch 1261 of 2000 took 0.097s
  training loss:		0.090980
  validation loss:		0.601280
  validation accuracy:		89.67 %
Epoch 1262 of 2000 took 0.097s
  training loss:		0.081197
  validation loss:		0.604230
  validation accuracy:		89.02 %
Epoch 1263 of 2000 took 0.097s
  training loss:		0.075065
  validation loss:		0.597437
  validation accuracy:		89.35 %
Epoch 1264 of 2000 took 0.097s
  training loss:		0.069177
  validation loss:		0.569625
  validation accuracy:		89.89 %
Epoch 1265 of 2000 took 0.098s
  training loss:		0.090398
  validation loss:		0.589851
  validation accuracy:		89.89 %
Epoch 1266 of 2000 took 0.097s
  training loss:		0.087705
  validation loss:		0.569029
  validation accuracy:		90.00 %
Epoch 1267 of 2000 took 0.097s
  training loss:		0.086697
  validation loss:		0.588788
  validation accuracy:		89.46 %
Epoch 1268 of 2000 took 0.097s
  training loss:		0.081584
  validation loss:		0.587212
  validation accuracy:		89.67 %
Epoch 1269 of 2000 took 0.097s
  training loss:		0.082185
  validation loss:		0.620503
  validation accuracy:		89.46 %
Epoch 1270 of 2000 took 0.097s
  training loss:		0.071312
  validation loss:		0.567557
  validation accuracy:		90.11 %
Epoch 1271 of 2000 took 0.097s
  training loss:		0.085473
  validation loss:		0.589573
  validation accuracy:		89.78 %
Epoch 1272 of 2000 took 0.097s
  training loss:		0.074437
  validation loss:		0.594258
  validation accuracy:		89.35 %
Epoch 1273 of 2000 took 0.097s
  training loss:		0.078701
  validation loss:		0.610421
  validation accuracy:		89.35 %
Epoch 1274 of 2000 took 0.097s
  training loss:		0.079662
  validation loss:		0.628900
  validation accuracy:		89.24 %
Epoch 1275 of 2000 took 0.097s
  training loss:		0.081781
  validation loss:		0.599295
  validation accuracy:		90.00 %
Epoch 1276 of 2000 took 0.097s
  training loss:		0.078685
  validation loss:		0.630763
  validation accuracy:		89.35 %
Epoch 1277 of 2000 took 0.097s
  training loss:		0.070358
  validation loss:		0.615883
  validation accuracy:		89.13 %
Epoch 1278 of 2000 took 0.097s
  training loss:		0.087894
  validation loss:		0.662043
  validation accuracy:		88.80 %
Epoch 1279 of 2000 took 0.097s
  training loss:		0.090569
  validation loss:		0.660303
  validation accuracy:		89.78 %
Epoch 1280 of 2000 took 0.097s
  training loss:		0.085093
  validation loss:		0.615313
  validation accuracy:		89.35 %
Epoch 1281 of 2000 took 0.097s
  training loss:		0.088242
  validation loss:		0.585088
  validation accuracy:		89.67 %
Epoch 1282 of 2000 took 0.097s
  training loss:		0.078400
  validation loss:		0.584580
  validation accuracy:		89.89 %
Epoch 1283 of 2000 took 0.097s
  training loss:		0.086463
  validation loss:		0.560773
  validation accuracy:		90.11 %
Epoch 1284 of 2000 took 0.097s
  training loss:		0.079998
  validation loss:		0.611312
  validation accuracy:		89.02 %
Epoch 1285 of 2000 took 0.097s
  training loss:		0.077034
  validation loss:		0.602141
  validation accuracy:		89.46 %
Epoch 1286 of 2000 took 0.097s
  training loss:		0.081884
  validation loss:		0.648476
  validation accuracy:		89.46 %
Epoch 1287 of 2000 took 0.097s
  training loss:		0.092879
  validation loss:		0.588804
  validation accuracy:		89.89 %
Epoch 1288 of 2000 took 0.097s
  training loss:		0.072601
  validation loss:		0.599277
  validation accuracy:		89.46 %
Epoch 1289 of 2000 took 0.098s
  training loss:		0.068441
  validation loss:		0.591604
  validation accuracy:		89.46 %
Epoch 1290 of 2000 took 0.097s
  training loss:		0.082428
  validation loss:		0.603111
  validation accuracy:		89.57 %
Epoch 1291 of 2000 took 0.097s
  training loss:		0.110050
  validation loss:		0.593357
  validation accuracy:		89.35 %
Epoch 1292 of 2000 took 0.097s
  training loss:		0.084712
  validation loss:		0.605107
  validation accuracy:		89.89 %
Epoch 1293 of 2000 took 0.097s
  training loss:		0.076318
  validation loss:		0.584844
  validation accuracy:		89.46 %
Epoch 1294 of 2000 took 0.097s
  training loss:		0.079511
  validation loss:		0.625045
  validation accuracy:		89.46 %
Epoch 1295 of 2000 took 0.097s
  training loss:		0.079635
  validation loss:		0.618513
  validation accuracy:		89.89 %
Epoch 1296 of 2000 took 0.098s
  training loss:		0.080526
  validation loss:		0.573141
  validation accuracy:		89.67 %
Epoch 1297 of 2000 took 0.097s
  training loss:		0.074968
  validation loss:		0.625511
  validation accuracy:		89.57 %
Epoch 1298 of 2000 took 0.097s
  training loss:		0.077006
  validation loss:		0.680086
  validation accuracy:		88.04 %
Epoch 1299 of 2000 took 0.097s
  training loss:		0.090225
  validation loss:		0.614293
  validation accuracy:		89.78 %
Epoch 1300 of 2000 took 0.097s
  training loss:		0.076953
  validation loss:		0.635126
  validation accuracy:		90.00 %
Epoch 1301 of 2000 took 0.097s
  training loss:		0.069984
  validation loss:		0.615254
  validation accuracy:		89.78 %
Epoch 1302 of 2000 took 0.097s
  training loss:		0.082703
  validation loss:		0.618587
  validation accuracy:		89.35 %
Epoch 1303 of 2000 took 0.097s
  training loss:		0.080919
  validation loss:		0.589134
  validation accuracy:		90.22 %
Epoch 1304 of 2000 took 0.097s
  training loss:		0.081989
  validation loss:		0.613844
  validation accuracy:		88.80 %
Epoch 1305 of 2000 took 0.097s
  training loss:		0.108776
  validation loss:		0.639661
  validation accuracy:		89.67 %
Epoch 1306 of 2000 took 0.097s
  training loss:		0.084142
  validation loss:		0.594162
  validation accuracy:		90.00 %
Epoch 1307 of 2000 took 0.097s
  training loss:		0.077942
  validation loss:		0.615415
  validation accuracy:		89.78 %
Epoch 1308 of 2000 took 0.097s
  training loss:		0.079642
  validation loss:		0.588938
  validation accuracy:		90.22 %
Epoch 1309 of 2000 took 0.098s
  training loss:		0.070970
  validation loss:		0.617874
  validation accuracy:		89.57 %
Epoch 1310 of 2000 took 0.105s
  training loss:		0.076309
  validation loss:		0.597354
  validation accuracy:		89.24 %
Epoch 1311 of 2000 took 0.110s
  training loss:		0.073689
  validation loss:		0.598968
  validation accuracy:		90.00 %
Epoch 1312 of 2000 took 0.114s
  training loss:		0.072627
  validation loss:		0.596949
  validation accuracy:		90.33 %
Epoch 1313 of 2000 took 0.145s
  training loss:		0.075889
  validation loss:		0.640781
  validation accuracy:		89.02 %
Epoch 1314 of 2000 took 0.104s
  training loss:		0.085483
  validation loss:		0.660312
  validation accuracy:		89.24 %
Epoch 1315 of 2000 took 0.103s
  training loss:		0.078315
  validation loss:		0.622199
  validation accuracy:		90.11 %
Epoch 1316 of 2000 took 0.105s
  training loss:		0.069953
  validation loss:		0.581885
  validation accuracy:		90.00 %
Epoch 1317 of 2000 took 0.106s
  training loss:		0.063823
  validation loss:		0.612132
  validation accuracy:		89.67 %
Epoch 1318 of 2000 took 0.102s
  training loss:		0.072337
  validation loss:		0.600308
  validation accuracy:		89.89 %
Epoch 1319 of 2000 took 0.105s
  training loss:		0.071596
  validation loss:		0.612336
  validation accuracy:		89.78 %
Epoch 1320 of 2000 took 0.102s
  training loss:		0.075609
  validation loss:		0.604564
  validation accuracy:		89.57 %
Epoch 1321 of 2000 took 0.101s
  training loss:		0.083285
  validation loss:		0.601752
  validation accuracy:		89.35 %
Epoch 1322 of 2000 took 0.101s
  training loss:		0.066313
  validation loss:		0.614475
  validation accuracy:		89.46 %
Epoch 1323 of 2000 took 0.101s
  training loss:		0.070859
  validation loss:		0.651289
  validation accuracy:		89.35 %
Epoch 1324 of 2000 took 0.101s
  training loss:		0.106620
  validation loss:		0.608367
  validation accuracy:		90.11 %
Epoch 1325 of 2000 took 0.102s
  training loss:		0.094806
  validation loss:		0.599819
  validation accuracy:		89.89 %
Epoch 1326 of 2000 took 0.102s
  training loss:		0.079369
  validation loss:		0.609223
  validation accuracy:		89.67 %
Epoch 1327 of 2000 took 0.101s
  training loss:		0.073772
  validation loss:		0.647940
  validation accuracy:		88.15 %
Epoch 1328 of 2000 took 0.101s
  training loss:		0.090058
  validation loss:		0.641539
  validation accuracy:		89.13 %
Epoch 1329 of 2000 took 0.102s
  training loss:		0.071245
  validation loss:		0.619274
  validation accuracy:		90.22 %
Epoch 1330 of 2000 took 0.101s
  training loss:		0.080186
  validation loss:		0.594826
  validation accuracy:		90.11 %
Epoch 1331 of 2000 took 0.102s
  training loss:		0.077452
  validation loss:		0.637052
  validation accuracy:		88.91 %
Epoch 1332 of 2000 took 0.102s
  training loss:		0.077622
  validation loss:		0.624475
  validation accuracy:		89.35 %
Epoch 1333 of 2000 took 0.102s
  training loss:		0.088694
  validation loss:		0.622100
  validation accuracy:		89.67 %
Epoch 1334 of 2000 took 0.101s
  training loss:		0.069444
  validation loss:		0.603395
  validation accuracy:		89.78 %
Epoch 1335 of 2000 took 0.101s
  training loss:		0.084004
  validation loss:		0.625416
  validation accuracy:		89.35 %
Epoch 1336 of 2000 took 0.102s
  training loss:		0.075380
  validation loss:		0.691972
  validation accuracy:		88.80 %
Epoch 1337 of 2000 took 0.100s
  training loss:		0.078804
  validation loss:		0.664658
  validation accuracy:		89.46 %
Epoch 1338 of 2000 took 0.102s
  training loss:		0.071894
  validation loss:		0.611336
  validation accuracy:		89.89 %
Epoch 1339 of 2000 took 0.102s
  training loss:		0.074997
  validation loss:		0.665658
  validation accuracy:		88.37 %
Epoch 1340 of 2000 took 0.102s
  training loss:		0.083971
  validation loss:		0.628412
  validation accuracy:		89.67 %
Epoch 1341 of 2000 took 0.101s
  training loss:		0.073759
  validation loss:		0.641403
  validation accuracy:		88.48 %
Epoch 1342 of 2000 took 0.101s
  training loss:		0.080868
  validation loss:		0.667914
  validation accuracy:		88.70 %
Epoch 1343 of 2000 took 0.102s
  training loss:		0.080314
  validation loss:		0.627147
  validation accuracy:		89.89 %
Epoch 1344 of 2000 took 0.101s
  training loss:		0.069212
  validation loss:		0.629399
  validation accuracy:		89.46 %
Epoch 1345 of 2000 took 0.101s
  training loss:		0.070814
  validation loss:		0.605936
  validation accuracy:		89.89 %
Epoch 1346 of 2000 took 0.102s
  training loss:		0.068458
  validation loss:		0.641380
  validation accuracy:		89.35 %
Epoch 1347 of 2000 took 0.101s
  training loss:		0.077337
  validation loss:		0.625975
  validation accuracy:		89.24 %
Epoch 1348 of 2000 took 0.101s
  training loss:		0.069442
  validation loss:		0.633537
  validation accuracy:		88.70 %
Epoch 1349 of 2000 took 0.102s
  training loss:		0.075373
  validation loss:		0.625760
  validation accuracy:		89.89 %
Epoch 1350 of 2000 took 0.101s
  training loss:		0.073623
  validation loss:		0.635684
  validation accuracy:		89.57 %
Epoch 1351 of 2000 took 0.102s
  training loss:		0.074730
  validation loss:		0.601836
  validation accuracy:		90.00 %
Epoch 1352 of 2000 took 0.104s
  training loss:		0.077865
  validation loss:		0.645013
  validation accuracy:		89.13 %
Epoch 1353 of 2000 took 0.102s
  training loss:		0.071181
  validation loss:		0.666102
  validation accuracy:		89.35 %
Epoch 1354 of 2000 took 0.101s
  training loss:		0.088692
  validation loss:		0.619288
  validation accuracy:		90.00 %
Epoch 1355 of 2000 took 0.102s
  training loss:		0.070715
  validation loss:		0.662128
  validation accuracy:		89.13 %
Epoch 1356 of 2000 took 0.101s
  training loss:		0.073152
  validation loss:		0.635409
  validation accuracy:		89.57 %
Epoch 1357 of 2000 took 0.101s
  training loss:		0.085851
  validation loss:		0.665219
  validation accuracy:		89.02 %
Epoch 1358 of 2000 took 0.101s
  training loss:		0.067795
  validation loss:		0.684931
  validation accuracy:		89.02 %
Epoch 1359 of 2000 took 0.101s
  training loss:		0.071612
  validation loss:		0.631901
  validation accuracy:		89.24 %
Epoch 1360 of 2000 took 0.101s
  training loss:		0.071566
  validation loss:		0.664335
  validation accuracy:		89.24 %
Epoch 1361 of 2000 took 0.101s
  training loss:		0.083003
  validation loss:		0.607582
  validation accuracy:		89.46 %
Epoch 1362 of 2000 took 0.101s
  training loss:		0.080756
  validation loss:		0.631169
  validation accuracy:		89.67 %
Epoch 1363 of 2000 took 0.101s
  training loss:		0.080562
  validation loss:		0.640505
  validation accuracy:		89.78 %
Epoch 1364 of 2000 took 0.101s
  training loss:		0.073905
  validation loss:		0.631054
  validation accuracy:		89.67 %
Epoch 1365 of 2000 took 0.101s
  training loss:		0.083668
  validation loss:		0.645400
  validation accuracy:		89.46 %
Epoch 1366 of 2000 took 0.101s
  training loss:		0.078289
  validation loss:		0.627019
  validation accuracy:		89.24 %
Epoch 1367 of 2000 took 0.099s
  training loss:		0.080333
  validation loss:		0.642393
  validation accuracy:		89.57 %
Epoch 1368 of 2000 took 0.095s
  training loss:		0.065739
  validation loss:		0.692158
  validation accuracy:		88.59 %
Epoch 1369 of 2000 took 0.103s
  training loss:		0.069842
  validation loss:		0.621237
  validation accuracy:		89.24 %
Epoch 1370 of 2000 took 0.096s
  training loss:		0.086319
  validation loss:		0.727062
  validation accuracy:		88.59 %
Epoch 1371 of 2000 took 0.097s
  training loss:		0.073242
  validation loss:		0.620441
  validation accuracy:		89.89 %
Epoch 1372 of 2000 took 0.096s
  training loss:		0.069652
  validation loss:		0.655269
  validation accuracy:		89.13 %
Epoch 1373 of 2000 took 0.097s
  training loss:		0.065521
  validation loss:		0.645009
  validation accuracy:		89.46 %
Epoch 1374 of 2000 took 0.100s
  training loss:		0.072171
  validation loss:		0.640569
  validation accuracy:		89.02 %
Epoch 1375 of 2000 took 0.096s
  training loss:		0.076487
  validation loss:		0.641736
  validation accuracy:		89.35 %
Epoch 1376 of 2000 took 0.097s
  training loss:		0.078650
  validation loss:		0.639238
  validation accuracy:		89.24 %
Epoch 1377 of 2000 took 0.102s
  training loss:		0.074262
  validation loss:		0.725878
  validation accuracy:		88.37 %
Epoch 1378 of 2000 took 0.096s
  training loss:		0.111549
  validation loss:		0.665443
  validation accuracy:		89.02 %
Epoch 1379 of 2000 took 0.097s
  training loss:		0.066831
  validation loss:		0.615701
  validation accuracy:		89.24 %
Epoch 1380 of 2000 took 0.097s
  training loss:		0.074085
  validation loss:		0.679092
  validation accuracy:		89.24 %
Epoch 1381 of 2000 took 0.100s
  training loss:		0.071011
  validation loss:		0.645149
  validation accuracy:		89.35 %
Epoch 1382 of 2000 took 0.100s
  training loss:		0.076159
  validation loss:		0.628598
  validation accuracy:		89.35 %
Epoch 1383 of 2000 took 0.096s
  training loss:		0.073609
  validation loss:		0.648644
  validation accuracy:		89.35 %
Epoch 1384 of 2000 took 0.098s
  training loss:		0.073322
  validation loss:		0.651271
  validation accuracy:		89.13 %
Epoch 1385 of 2000 took 0.101s
  training loss:		0.063666
  validation loss:		0.654569
  validation accuracy:		89.24 %
Epoch 1386 of 2000 took 0.096s
  training loss:		0.086268
  validation loss:		0.676583
  validation accuracy:		89.35 %
Epoch 1387 of 2000 took 0.097s
  training loss:		0.088753
  validation loss:		0.664383
  validation accuracy:		89.46 %
Epoch 1388 of 2000 took 0.096s
  training loss:		0.134306
  validation loss:		0.675615
  validation accuracy:		88.48 %
Epoch 1389 of 2000 took 0.101s
  training loss:		0.077504
  validation loss:		0.643197
  validation accuracy:		90.11 %
Epoch 1390 of 2000 took 0.098s
  training loss:		0.072733
  validation loss:		0.650102
  validation accuracy:		89.67 %
Epoch 1391 of 2000 took 0.096s
  training loss:		0.066503
  validation loss:		0.637800
  validation accuracy:		89.67 %
Epoch 1392 of 2000 took 0.102s
  training loss:		0.063905
  validation loss:		0.687796
  validation accuracy:		89.78 %
Epoch 1393 of 2000 took 0.097s
  training loss:		0.068109
  validation loss:		0.644441
  validation accuracy:		89.24 %
Epoch 1394 of 2000 took 0.097s
  training loss:		0.085458
  validation loss:		0.663304
  validation accuracy:		89.13 %
Epoch 1395 of 2000 took 0.096s
  training loss:		0.067704
  validation loss:		0.677080
  validation accuracy:		89.13 %
Epoch 1396 of 2000 took 0.097s
  training loss:		0.066941
  validation loss:		0.676241
  validation accuracy:		88.26 %
Epoch 1397 of 2000 took 0.100s
  training loss:		0.083105
  validation loss:		0.639724
  validation accuracy:		89.24 %
Epoch 1398 of 2000 took 0.097s
  training loss:		0.073926
  validation loss:		0.612439
  validation accuracy:		90.33 %
Epoch 1399 of 2000 took 0.097s
  training loss:		0.085598
  validation loss:		0.643057
  validation accuracy:		89.78 %
Epoch 1400 of 2000 took 0.103s
  training loss:		0.084372
  validation loss:		0.670570
  validation accuracy:		90.11 %
Epoch 1401 of 2000 took 0.096s
  training loss:		0.621817
  validation loss:		3.986820
  validation accuracy:		70.54 %
Epoch 1402 of 2000 took 0.097s
  training loss:		1.805104
  validation loss:		0.627835
  validation accuracy:		88.91 %
Epoch 1403 of 2000 took 0.096s
  training loss:		0.213572
  validation loss:		0.592549
  validation accuracy:		89.46 %
Epoch 1404 of 2000 took 0.098s
  training loss:		0.133964
  validation loss:		0.543536
  validation accuracy:		90.33 %
Epoch 1405 of 2000 took 0.099s
  training loss:		0.109467
  validation loss:		0.603330
  validation accuracy:		89.02 %
Epoch 1406 of 2000 took 0.096s
  training loss:		0.133540
  validation loss:		0.571726
  validation accuracy:		90.22 %
Epoch 1407 of 2000 took 0.098s
  training loss:		0.104622
  validation loss:		0.582496
  validation accuracy:		90.22 %
Epoch 1408 of 2000 took 0.101s
  training loss:		0.089125
  validation loss:		0.531575
  validation accuracy:		90.87 %
Epoch 1409 of 2000 took 0.096s
  training loss:		0.093450
  validation loss:		0.548697
  validation accuracy:		90.65 %
Epoch 1410 of 2000 took 0.097s
  training loss:		0.082769
  validation loss:		0.560236
  validation accuracy:		89.13 %
Epoch 1411 of 2000 took 0.096s
  training loss:		0.105571
  validation loss:		0.556318
  validation accuracy:		90.33 %
Epoch 1412 of 2000 took 0.101s
  training loss:		0.081902
  validation loss:		0.526712
  validation accuracy:		91.09 %
Epoch 1413 of 2000 took 0.097s
  training loss:		0.082216
  validation loss:		0.564872
  validation accuracy:		90.33 %
Epoch 1414 of 2000 took 0.096s
  training loss:		0.087453
  validation loss:		0.550789
  validation accuracy:		90.43 %
Epoch 1415 of 2000 took 0.102s
  training loss:		0.077038
  validation loss:		0.576723
  validation accuracy:		89.89 %
Epoch 1416 of 2000 took 0.097s
  training loss:		0.097879
  validation loss:		0.544041
  validation accuracy:		90.65 %
Epoch 1417 of 2000 took 0.097s
  training loss:		0.077673
  validation loss:		0.528832
  validation accuracy:		90.00 %
Epoch 1418 of 2000 took 0.097s
  training loss:		0.078036
  validation loss:		0.533353
  validation accuracy:		90.54 %
Epoch 1419 of 2000 took 0.097s
  training loss:		0.084041
  validation loss:		0.543286
  validation accuracy:		90.76 %
Epoch 1420 of 2000 took 0.100s
  training loss:		0.078387
  validation loss:		0.570895
  validation accuracy:		90.33 %
Epoch 1421 of 2000 took 0.097s
  training loss:		0.076076
  validation loss:		0.565335
  validation accuracy:		90.43 %
Epoch 1422 of 2000 took 0.097s
  training loss:		0.086873
  validation loss:		0.598594
  validation accuracy:		89.13 %
Epoch 1423 of 2000 took 0.103s
  training loss:		0.094406
  validation loss:		0.601923
  validation accuracy:		89.57 %
Epoch 1424 of 2000 took 0.099s
  training loss:		0.087725
  validation loss:		0.587421
  validation accuracy:		90.00 %
Epoch 1425 of 2000 took 0.097s
  training loss:		0.076919
  validation loss:		0.534414
  validation accuracy:		90.54 %
Epoch 1426 of 2000 took 0.096s
  training loss:		0.072288
  validation loss:		0.567326
  validation accuracy:		90.00 %
Epoch 1427 of 2000 took 0.098s
  training loss:		0.072890
  validation loss:		0.557211
  validation accuracy:		90.22 %
Epoch 1428 of 2000 took 0.100s
  training loss:		0.075207
  validation loss:		0.544573
  validation accuracy:		90.33 %
Epoch 1429 of 2000 took 0.096s
  training loss:		0.079183
  validation loss:		0.587163
  validation accuracy:		88.91 %
Epoch 1430 of 2000 took 0.098s
  training loss:		0.080633
  validation loss:		0.552159
  validation accuracy:		90.11 %
Epoch 1431 of 2000 took 0.101s
  training loss:		0.073971
  validation loss:		0.594219
  validation accuracy:		90.43 %
Epoch 1432 of 2000 took 0.096s
  training loss:		0.078933
  validation loss:		0.561854
  validation accuracy:		89.89 %
Epoch 1433 of 2000 took 0.097s
  training loss:		0.072082
  validation loss:		0.550080
  validation accuracy:		90.33 %
Epoch 1434 of 2000 took 0.096s
  training loss:		0.067412
  validation loss:		0.573300
  validation accuracy:		90.22 %
Epoch 1435 of 2000 took 0.101s
  training loss:		0.068932
  validation loss:		0.586310
  validation accuracy:		89.67 %
Epoch 1436 of 2000 took 0.098s
  training loss:		0.072649
  validation loss:		0.564854
  validation accuracy:		89.78 %
Epoch 1437 of 2000 took 0.096s
  training loss:		0.071724
  validation loss:		0.564871
  validation accuracy:		89.78 %
Epoch 1438 of 2000 took 0.102s
  training loss:		0.081902
  validation loss:		0.549411
  validation accuracy:		90.87 %
Epoch 1439 of 2000 took 0.097s
  training loss:		0.072130
  validation loss:		0.556356
  validation accuracy:		90.11 %
Epoch 1440 of 2000 took 0.097s
  training loss:		0.068623
  validation loss:		0.554621
  validation accuracy:		90.22 %
Epoch 1441 of 2000 took 0.097s
  training loss:		0.076264
  validation loss:		0.590521
  validation accuracy:		89.89 %
Epoch 1442 of 2000 took 0.097s
  training loss:		0.068626
  validation loss:		0.570668
  validation accuracy:		89.89 %
Epoch 1443 of 2000 took 0.100s
  training loss:		0.074265
  validation loss:		0.573666
  validation accuracy:		90.00 %
Epoch 1444 of 2000 took 0.097s
  training loss:		0.071656
  validation loss:		0.557575
  validation accuracy:		90.76 %
Epoch 1445 of 2000 took 0.097s
  training loss:		0.071169
  validation loss:		0.565725
  validation accuracy:		89.78 %
Epoch 1446 of 2000 took 0.103s
  training loss:		0.067682
  validation loss:		0.591977
  validation accuracy:		89.46 %
Epoch 1447 of 2000 took 0.096s
  training loss:		0.076514
  validation loss:		0.584620
  validation accuracy:		89.89 %
Epoch 1448 of 2000 took 0.097s
  training loss:		0.070783
  validation loss:		0.570287
  validation accuracy:		89.78 %
Epoch 1449 of 2000 took 0.096s
  training loss:		0.068739
  validation loss:		0.552629
  validation accuracy:		89.78 %
Epoch 1450 of 2000 took 0.098s
  training loss:		0.064104
  validation loss:		0.573012
  validation accuracy:		89.89 %
Epoch 1451 of 2000 took 0.101s
  training loss:		0.065931
  validation loss:		0.609050
  validation accuracy:		89.67 %
Epoch 1452 of 2000 took 0.096s
  training loss:		0.069626
  validation loss:		0.576795
  validation accuracy:		90.11 %
Epoch 1453 of 2000 took 0.097s
  training loss:		0.066410
  validation loss:		0.564523
  validation accuracy:		89.67 %
Epoch 1454 of 2000 took 0.101s
  training loss:		0.065131
  validation loss:		0.607427
  validation accuracy:		88.80 %
Epoch 1455 of 2000 took 0.096s
  training loss:		0.068278
  validation loss:		0.592863
  validation accuracy:		89.46 %
Epoch 1456 of 2000 took 0.097s
  training loss:		0.073745
  validation loss:		0.651341
  validation accuracy:		88.80 %
Epoch 1457 of 2000 took 0.096s
  training loss:		0.074276
  validation loss:		0.581407
  validation accuracy:		89.89 %
Epoch 1458 of 2000 took 0.101s
  training loss:		0.074377
  validation loss:		0.594898
  validation accuracy:		90.22 %
Epoch 1459 of 2000 took 0.098s
  training loss:		0.069302
  validation loss:		0.591301
  validation accuracy:		89.67 %
Epoch 1460 of 2000 took 0.096s
  training loss:		0.076893
  validation loss:		0.576543
  validation accuracy:		89.78 %
Epoch 1461 of 2000 took 0.101s
  training loss:		0.076771
  validation loss:		0.637419
  validation accuracy:		89.24 %
Epoch 1462 of 2000 took 0.098s
  training loss:		0.069707
  validation loss:		0.567620
  validation accuracy:		90.33 %
Epoch 1463 of 2000 took 0.097s
  training loss:		0.066317
  validation loss:		0.585779
  validation accuracy:		89.57 %
Epoch 1464 of 2000 took 0.097s
  training loss:		0.067805
  validation loss:		0.608413
  validation accuracy:		89.57 %
Epoch 1465 of 2000 took 0.097s
  training loss:		0.068651
  validation loss:		0.607868
  validation accuracy:		89.24 %
Epoch 1466 of 2000 took 0.100s
  training loss:		0.062634
  validation loss:		0.592653
  validation accuracy:		89.78 %
Epoch 1467 of 2000 took 0.097s
  training loss:		0.064297
  validation loss:		0.582659
  validation accuracy:		89.78 %
Epoch 1468 of 2000 took 0.097s
  training loss:		0.067070
  validation loss:		0.612453
  validation accuracy:		89.35 %
Epoch 1469 of 2000 took 0.103s
  training loss:		0.088445
  validation loss:		0.640660
  validation accuracy:		89.24 %
Epoch 1470 of 2000 took 0.096s
  training loss:		0.069940
  validation loss:		0.572017
  validation accuracy:		89.78 %
Epoch 1471 of 2000 took 0.097s
  training loss:		0.066206
  validation loss:		0.578583
  validation accuracy:		89.78 %
Epoch 1472 of 2000 took 0.096s
  training loss:		0.068783
  validation loss:		0.632969
  validation accuracy:		88.59 %
Epoch 1473 of 2000 took 0.098s
  training loss:		0.067254
  validation loss:		0.578526
  validation accuracy:		90.11 %
Epoch 1474 of 2000 took 0.100s
  training loss:		0.064092
  validation loss:		0.598183
  validation accuracy:		89.46 %
Epoch 1475 of 2000 took 0.096s
  training loss:		0.069787
  validation loss:		0.636790
  validation accuracy:		88.48 %
Epoch 1476 of 2000 took 0.097s
  training loss:		0.065940
  validation loss:		0.591639
  validation accuracy:		89.35 %
Epoch 1477 of 2000 took 0.102s
  training loss:		0.074255
  validation loss:		0.595657
  validation accuracy:		90.11 %
Epoch 1478 of 2000 took 0.096s
  training loss:		0.064962
  validation loss:		0.637361
  validation accuracy:		90.00 %
Epoch 1479 of 2000 took 0.097s
  training loss:		0.061100
  validation loss:		0.596830
  validation accuracy:		89.35 %
Epoch 1480 of 2000 took 0.096s
  training loss:		0.069332
  validation loss:		0.622998
  validation accuracy:		89.35 %
Epoch 1481 of 2000 took 0.100s
  training loss:		0.064594
  validation loss:		0.611376
  validation accuracy:		89.46 %
Epoch 1482 of 2000 took 0.098s
  training loss:		0.073992
  validation loss:		0.623939
  validation accuracy:		90.11 %
Epoch 1483 of 2000 took 0.096s
  training loss:		0.066959
  validation loss:		0.651918
  validation accuracy:		88.80 %
Epoch 1484 of 2000 took 0.100s
  training loss:		0.066118
  validation loss:		0.628606
  validation accuracy:		89.67 %
Epoch 1485 of 2000 took 0.098s
  training loss:		0.066796
  validation loss:		0.628648
  validation accuracy:		89.02 %
Epoch 1486 of 2000 took 0.096s
  training loss:		0.065564
  validation loss:		0.671496
  validation accuracy:		89.02 %
Epoch 1487 of 2000 took 0.097s
  training loss:		0.075782
  validation loss:		0.616636
  validation accuracy:		89.89 %
Epoch 1488 of 2000 took 0.097s
  training loss:		0.070535
  validation loss:		0.613729
  validation accuracy:		89.35 %
Epoch 1489 of 2000 took 0.101s
  training loss:		0.064013
  validation loss:		0.640519
  validation accuracy:		89.35 %
Epoch 1490 of 2000 took 0.097s
  training loss:		0.069986
  validation loss:		0.603651
  validation accuracy:		88.91 %
Epoch 1491 of 2000 took 0.096s
  training loss:		0.069071
  validation loss:		0.656750
  validation accuracy:		88.91 %
Epoch 1492 of 2000 took 0.103s
  training loss:		0.070665
  validation loss:		0.670652
  validation accuracy:		88.70 %
Epoch 1493 of 2000 took 0.096s
  training loss:		0.080335
  validation loss:		0.616399
  validation accuracy:		89.46 %
Epoch 1494 of 2000 took 0.097s
  training loss:		0.070816
  validation loss:		0.610909
  validation accuracy:		89.57 %
Epoch 1495 of 2000 took 0.096s
  training loss:		0.062782
  validation loss:		0.622307
  validation accuracy:		89.24 %
Epoch 1496 of 2000 took 0.098s
  training loss:		0.173647
  validation loss:		0.610390
  validation accuracy:		90.54 %
Epoch 1497 of 2000 took 0.101s
  training loss:		0.067814
  validation loss:		0.621914
  validation accuracy:		89.67 %
Epoch 1498 of 2000 took 0.096s
  training loss:		0.068643
  validation loss:		0.617557
  validation accuracy:		89.78 %
Epoch 1499 of 2000 took 0.097s
  training loss:		0.061672
  validation loss:		0.608066
  validation accuracy:		89.67 %
Epoch 1500 of 2000 took 0.102s
  training loss:		0.065806
  validation loss:		0.588089
  validation accuracy:		89.46 %
Epoch 1501 of 2000 took 0.096s
  training loss:		0.071690
  validation loss:		0.649144
  validation accuracy:		88.80 %
Epoch 1502 of 2000 took 0.097s
  training loss:		0.066740
  validation loss:		0.609790
  validation accuracy:		90.11 %
Epoch 1503 of 2000 took 0.096s
  training loss:		0.061501
  validation loss:		0.634118
  validation accuracy:		89.46 %
Epoch 1504 of 2000 took 0.100s
  training loss:		0.062374
  validation loss:		0.650779
  validation accuracy:		88.91 %
Epoch 1505 of 2000 took 0.098s
  training loss:		0.061481
  validation loss:		0.609308
  validation accuracy:		89.35 %
Epoch 1506 of 2000 took 0.096s
  training loss:		0.079076
  validation loss:		0.628470
  validation accuracy:		90.00 %
Epoch 1507 of 2000 took 0.100s
  training loss:		0.070033
  validation loss:		0.615066
  validation accuracy:		90.00 %
Epoch 1508 of 2000 took 0.099s
  training loss:		0.069499
  validation loss:		0.642854
  validation accuracy:		89.35 %
Epoch 1509 of 2000 took 0.097s
  training loss:		0.064077
  validation loss:		0.649446
  validation accuracy:		90.11 %
Epoch 1510 of 2000 took 0.097s
  training loss:		0.061985
  validation loss:		0.620943
  validation accuracy:		90.22 %
Epoch 1511 of 2000 took 0.096s
  training loss:		0.061441
  validation loss:		0.644276
  validation accuracy:		89.67 %
Epoch 1512 of 2000 took 0.101s
  training loss:		0.072984
  validation loss:		0.643100
  validation accuracy:		88.91 %
Epoch 1513 of 2000 took 0.097s
  training loss:		0.059022
  validation loss:		0.634446
  validation accuracy:		89.35 %
Epoch 1514 of 2000 took 0.096s
  training loss:		0.068535
  validation loss:		0.636362
  validation accuracy:		90.11 %
Epoch 1515 of 2000 took 0.102s
  training loss:		0.072830
  validation loss:		0.679184
  validation accuracy:		88.70 %
Epoch 1516 of 2000 took 0.096s
  training loss:		0.067080
  validation loss:		0.641704
  validation accuracy:		89.46 %
Epoch 1517 of 2000 took 0.097s
  training loss:		0.066312
  validation loss:		0.628018
  validation accuracy:		90.22 %
Epoch 1518 of 2000 took 0.096s
  training loss:		0.064626
  validation loss:		0.624801
  validation accuracy:		89.35 %
Epoch 1519 of 2000 took 0.097s
  training loss:		0.069307
  validation loss:		0.632339
  validation accuracy:		89.67 %
Epoch 1520 of 2000 took 0.100s
  training loss:		0.067508
  validation loss:		0.710406
  validation accuracy:		88.80 %
Epoch 1521 of 2000 took 0.096s
  training loss:		0.091520
  validation loss:		0.753472
  validation accuracy:		87.83 %
Epoch 1522 of 2000 took 0.097s
  training loss:		0.083133
  validation loss:		0.638640
  validation accuracy:		89.02 %
Epoch 1523 of 2000 took 0.103s
  training loss:		0.067924
  validation loss:		0.622985
  validation accuracy:		88.80 %
Epoch 1524 of 2000 took 0.096s
  training loss:		0.068661
  validation loss:		0.637654
  validation accuracy:		89.57 %
Epoch 1525 of 2000 took 0.097s
  training loss:		0.066717
  validation loss:		0.651577
  validation accuracy:		89.57 %
Epoch 1526 of 2000 took 0.096s
  training loss:		0.069402
  validation loss:		0.694982
  validation accuracy:		89.35 %
Epoch 1527 of 2000 took 0.099s
  training loss:		0.066831
  validation loss:		0.639455
  validation accuracy:		89.67 %
Epoch 1528 of 2000 took 0.099s
  training loss:		0.065144
  validation loss:		0.645274
  validation accuracy:		89.35 %
Epoch 1529 of 2000 took 0.096s
  training loss:		0.078449
  validation loss:		0.694462
  validation accuracy:		88.70 %
Epoch 1530 of 2000 took 0.099s
  training loss:		0.067185
  validation loss:		0.663954
  validation accuracy:		89.13 %
Epoch 1531 of 2000 took 0.100s
  training loss:		0.065828
  validation loss:		0.674503
  validation accuracy:		89.46 %
Epoch 1532 of 2000 took 0.096s
  training loss:		0.069495
  validation loss:		0.638222
  validation accuracy:		89.89 %
Epoch 1533 of 2000 took 0.097s
  training loss:		0.065626
  validation loss:		0.670938
  validation accuracy:		89.24 %
Epoch 1534 of 2000 took 0.096s
  training loss:		0.064664
  validation loss:		0.654815
  validation accuracy:		89.67 %
Epoch 1535 of 2000 took 0.101s
  training loss:		0.058465
  validation loss:		0.687642
  validation accuracy:		88.70 %
Epoch 1536 of 2000 took 0.098s
  training loss:		0.071205
  validation loss:		0.646842
  validation accuracy:		89.35 %
Epoch 1537 of 2000 took 0.096s
  training loss:		0.068996
  validation loss:		0.686604
  validation accuracy:		89.46 %
Epoch 1538 of 2000 took 0.102s
  training loss:		0.068296
  validation loss:		0.650646
  validation accuracy:		89.57 %
Epoch 1539 of 2000 took 0.097s
  training loss:		0.072722
  validation loss:		0.650709
  validation accuracy:		89.57 %
Epoch 1540 of 2000 took 0.097s
  training loss:		0.069046
  validation loss:		0.706200
  validation accuracy:		88.15 %
Epoch 1541 of 2000 took 0.096s
  training loss:		0.061490
  validation loss:		0.660611
  validation accuracy:		89.02 %
Epoch 1542 of 2000 took 0.097s
  training loss:		0.061102
  validation loss:		0.693454
  validation accuracy:		89.02 %
Epoch 1543 of 2000 took 0.100s
  training loss:		0.058875
  validation loss:		0.678448
  validation accuracy:		88.48 %
Epoch 1544 of 2000 took 0.097s
  training loss:		0.071028
  validation loss:		0.667660
  validation accuracy:		89.46 %
Epoch 1545 of 2000 took 0.097s
  training loss:		0.075039
  validation loss:		0.649492
  validation accuracy:		89.35 %
Epoch 1546 of 2000 took 0.103s
  training loss:		0.060447
  validation loss:		0.673348
  validation accuracy:		89.35 %
Epoch 1547 of 2000 took 0.096s
  training loss:		0.059899
  validation loss:		0.634137
  validation accuracy:		89.57 %
Epoch 1548 of 2000 took 0.097s
  training loss:		0.060070
  validation loss:		0.646927
  validation accuracy:		89.78 %
Epoch 1549 of 2000 took 0.096s
  training loss:		0.067353
  validation loss:		0.645371
  validation accuracy:		89.35 %
Epoch 1550 of 2000 took 0.098s
  training loss:		0.064445
  validation loss:		0.644245
  validation accuracy:		89.46 %
Epoch 1551 of 2000 took 0.100s
  training loss:		0.061692
  validation loss:		0.718519
  validation accuracy:		89.02 %
Epoch 1552 of 2000 took 0.096s
  training loss:		0.067765
  validation loss:		0.659276
  validation accuracy:		89.57 %
Epoch 1553 of 2000 took 0.098s
  training loss:		0.065201
  validation loss:		0.688134
  validation accuracy:		89.24 %
Epoch 1554 of 2000 took 0.098s
  training loss:		0.070333
  validation loss:		0.676671
  validation accuracy:		89.67 %
Epoch 1555 of 2000 took 0.096s
  training loss:		0.072769
  validation loss:		0.691577
  validation accuracy:		89.02 %
Epoch 1556 of 2000 took 0.100s
  training loss:		0.071399
  validation loss:		0.669998
  validation accuracy:		89.02 %
Epoch 1557 of 2000 took 0.096s
  training loss:		0.064152
  validation loss:		0.670245
  validation accuracy:		88.70 %
Epoch 1558 of 2000 took 0.099s
  training loss:		0.060940
  validation loss:		0.664610
  validation accuracy:		89.13 %
Epoch 1559 of 2000 took 0.097s
  training loss:		0.062439
  validation loss:		0.709273
  validation accuracy:		89.46 %
Epoch 1560 of 2000 took 0.097s
  training loss:		0.064581
  validation loss:		0.701337
  validation accuracy:		89.67 %
Epoch 1561 of 2000 took 0.099s
  training loss:		0.073436
  validation loss:		0.666508
  validation accuracy:		89.35 %
Epoch 1562 of 2000 took 0.096s
  training loss:		0.063124
  validation loss:		0.689652
  validation accuracy:		88.80 %
Epoch 1563 of 2000 took 0.100s
  training loss:		0.063174
  validation loss:		0.704928
  validation accuracy:		89.13 %
Epoch 1564 of 2000 took 0.096s
  training loss:		0.075117
  validation loss:		0.713526
  validation accuracy:		88.91 %
Epoch 1565 of 2000 took 0.098s
  training loss:		0.069306
  validation loss:		0.698022
  validation accuracy:		89.13 %
Epoch 1566 of 2000 took 0.098s
  training loss:		0.065476
  validation loss:		0.726280
  validation accuracy:		88.91 %
Epoch 1567 of 2000 took 0.097s
  training loss:		0.072928
  validation loss:		0.692596
  validation accuracy:		89.02 %
Epoch 1568 of 2000 took 0.100s
  training loss:		0.061374
  validation loss:		0.675887
  validation accuracy:		89.24 %
Epoch 1569 of 2000 took 0.096s
  training loss:		0.063129
  validation loss:		0.716957
  validation accuracy:		89.24 %
Epoch 1570 of 2000 took 0.100s
  training loss:		0.069471
  validation loss:		0.690525
  validation accuracy:		89.46 %
Epoch 1571 of 2000 took 0.097s
  training loss:		0.071769
  validation loss:		0.711420
  validation accuracy:		89.24 %
Epoch 1572 of 2000 took 0.097s
  training loss:		0.069079
  validation loss:		0.675863
  validation accuracy:		89.35 %
Epoch 1573 of 2000 took 0.099s
  training loss:		0.059641
  validation loss:		0.691555
  validation accuracy:		89.24 %
Epoch 1574 of 2000 took 0.096s
  training loss:		0.072415
  validation loss:		0.671282
  validation accuracy:		88.70 %
Epoch 1575 of 2000 took 0.100s
  training loss:		0.096365
  validation loss:		0.987515
  validation accuracy:		86.85 %
Epoch 1576 of 2000 took 0.096s
  training loss:		0.137918
  validation loss:		0.698796
  validation accuracy:		89.35 %
Epoch 1577 of 2000 took 0.098s
  training loss:		0.068630
  validation loss:		0.665786
  validation accuracy:		88.80 %
Epoch 1578 of 2000 took 0.097s
  training loss:		0.065636
  validation loss:		0.639994
  validation accuracy:		90.00 %
Epoch 1579 of 2000 took 0.097s
  training loss:		0.061686
  validation loss:		0.704265
  validation accuracy:		89.35 %
Epoch 1580 of 2000 took 0.103s
  training loss:		0.066123
  validation loss:		0.656088
  validation accuracy:		89.13 %
Epoch 1581 of 2000 took 0.096s
  training loss:		0.062665
  validation loss:		0.684848
  validation accuracy:		89.78 %
Epoch 1582 of 2000 took 0.097s
  training loss:		0.055224
  validation loss:		0.707957
  validation accuracy:		88.91 %
Epoch 1583 of 2000 took 0.096s
  training loss:		0.060100
  validation loss:		0.670152
  validation accuracy:		89.13 %
Epoch 1584 of 2000 took 0.098s
  training loss:		0.063375
  validation loss:		0.709261
  validation accuracy:		88.48 %
Epoch 1585 of 2000 took 0.100s
  training loss:		0.071575
  validation loss:		0.709805
  validation accuracy:		88.91 %
Epoch 1586 of 2000 took 0.096s
  training loss:		0.056166
  validation loss:		0.706776
  validation accuracy:		88.80 %
Epoch 1587 of 2000 took 0.098s
  training loss:		0.069131
  validation loss:		0.725041
  validation accuracy:		89.13 %
Epoch 1588 of 2000 took 0.101s
  training loss:		0.067917
  validation loss:		0.669579
  validation accuracy:		89.35 %
Epoch 1589 of 2000 took 0.096s
  training loss:		0.065322
  validation loss:		0.718739
  validation accuracy:		89.35 %
Epoch 1590 of 2000 took 0.097s
  training loss:		0.059440
  validation loss:		0.682085
  validation accuracy:		89.57 %
Epoch 1591 of 2000 took 0.096s
  training loss:		0.056799
  validation loss:		0.678417
  validation accuracy:		89.24 %
Epoch 1592 of 2000 took 0.101s
  training loss:		0.068432
  validation loss:		0.723904
  validation accuracy:		88.37 %
Epoch 1593 of 2000 took 0.098s
  training loss:		0.059130
  validation loss:		0.711557
  validation accuracy:		88.26 %
Epoch 1594 of 2000 took 0.096s
  training loss:		0.057389
  validation loss:		0.715648
  validation accuracy:		88.80 %
Epoch 1595 of 2000 took 0.102s
  training loss:		0.066013
  validation loss:		0.701034
  validation accuracy:		89.02 %
Epoch 1596 of 2000 took 0.097s
  training loss:		0.077338
  validation loss:		0.707140
  validation accuracy:		89.46 %
Epoch 1597 of 2000 took 0.097s
  training loss:		0.060470
  validation loss:		0.760126
  validation accuracy:		89.46 %
Epoch 1598 of 2000 took 0.097s
  training loss:		0.066134
  validation loss:		0.703973
  validation accuracy:		89.46 %
Epoch 1599 of 2000 took 0.097s
  training loss:		0.064605
  validation loss:		0.719599
  validation accuracy:		89.46 %
Epoch 1600 of 2000 took 0.100s
  training loss:		0.065465
  validation loss:		0.701799
  validation accuracy:		89.35 %
Epoch 1601 of 2000 took 0.097s
  training loss:		0.057397
  validation loss:		0.731447
  validation accuracy:		89.24 %
Epoch 1602 of 2000 took 0.097s
  training loss:		0.058949
  validation loss:		0.681996
  validation accuracy:		89.67 %
Epoch 1603 of 2000 took 0.103s
  training loss:		0.057185
  validation loss:		0.689118
  validation accuracy:		89.78 %
Epoch 1604 of 2000 took 0.096s
  training loss:		0.067932
  validation loss:		0.752138
  validation accuracy:		89.57 %
Epoch 1605 of 2000 took 0.097s
  training loss:		0.073175
  validation loss:		0.817651
  validation accuracy:		88.26 %
Epoch 1606 of 2000 took 0.096s
  training loss:		0.080760
  validation loss:		0.737729
  validation accuracy:		89.46 %
Epoch 1607 of 2000 took 0.098s
  training loss:		0.064960
  validation loss:		0.703410
  validation accuracy:		89.46 %
Epoch 1608 of 2000 took 0.100s
  training loss:		0.062041
  validation loss:		0.701069
  validation accuracy:		89.02 %
Epoch 1609 of 2000 took 0.096s
  training loss:		0.056896
  validation loss:		0.727046
  validation accuracy:		89.57 %
Epoch 1610 of 2000 took 0.097s
  training loss:		0.071919
  validation loss:		0.739650
  validation accuracy:		89.13 %
Epoch 1611 of 2000 took 0.101s
  training loss:		0.059113
  validation loss:		0.752670
  validation accuracy:		88.70 %
Epoch 1612 of 2000 took 0.096s
  training loss:		0.062830
  validation loss:		0.705013
  validation accuracy:		89.46 %
Epoch 1613 of 2000 took 0.097s
  training loss:		0.058962
  validation loss:		0.757517
  validation accuracy:		89.02 %
Epoch 1614 of 2000 took 0.097s
  training loss:		0.058320
  validation loss:		0.740251
  validation accuracy:		88.70 %
Epoch 1615 of 2000 took 0.101s
  training loss:		0.074172
  validation loss:		0.747396
  validation accuracy:		89.24 %
Epoch 1616 of 2000 took 0.098s
  training loss:		0.070695
  validation loss:		0.760706
  validation accuracy:		89.02 %
Epoch 1617 of 2000 took 0.096s
  training loss:		0.104160
  validation loss:		0.760884
  validation accuracy:		87.72 %
Epoch 1618 of 2000 took 0.102s
  training loss:		0.064753
  validation loss:		0.707061
  validation accuracy:		88.80 %
Epoch 1619 of 2000 took 0.097s
  training loss:		0.070062
  validation loss:		0.696878
  validation accuracy:		89.46 %
Epoch 1620 of 2000 took 0.097s
  training loss:		0.058758
  validation loss:		0.733287
  validation accuracy:		88.80 %
Epoch 1621 of 2000 took 0.097s
  training loss:		0.077764
  validation loss:		0.711677
  validation accuracy:		88.91 %
Epoch 1622 of 2000 took 0.097s
  training loss:		0.073452
  validation loss:		0.743688
  validation accuracy:		89.02 %
Epoch 1623 of 2000 took 0.100s
  training loss:		0.072353
  validation loss:		0.745226
  validation accuracy:		88.37 %
Epoch 1624 of 2000 took 0.097s
  training loss:		0.066416
  validation loss:		0.725948
  validation accuracy:		89.78 %
Epoch 1625 of 2000 took 0.097s
  training loss:		0.069535
  validation loss:		0.910642
  validation accuracy:		86.74 %
Epoch 1626 of 2000 took 0.103s
  training loss:		0.182383
  validation loss:		0.721454
  validation accuracy:		88.80 %
Epoch 1627 of 2000 took 0.096s
  training loss:		0.070899
  validation loss:		0.753743
  validation accuracy:		88.59 %
Epoch 1628 of 2000 took 0.097s
  training loss:		0.072283
  validation loss:		0.735882
  validation accuracy:		89.24 %
Epoch 1629 of 2000 took 0.096s
  training loss:		0.068178
  validation loss:		0.742020
  validation accuracy:		89.02 %
Epoch 1630 of 2000 took 0.098s
  training loss:		0.078142
  validation loss:		0.761092
  validation accuracy:		88.91 %
Epoch 1631 of 2000 took 0.101s
  training loss:		0.067339
  validation loss:		0.718202
  validation accuracy:		88.80 %
Epoch 1632 of 2000 took 0.096s
  training loss:		0.059687
  validation loss:		0.682485
  validation accuracy:		89.24 %
Epoch 1633 of 2000 took 0.097s
  training loss:		0.052779
  validation loss:		0.742288
  validation accuracy:		88.48 %
Epoch 1634 of 2000 took 0.102s
  training loss:		0.057947
  validation loss:		0.726021
  validation accuracy:		89.13 %
Epoch 1635 of 2000 took 0.096s
  training loss:		0.058611
  validation loss:		0.696701
  validation accuracy:		88.91 %
Epoch 1636 of 2000 took 0.097s
  training loss:		0.056880
  validation loss:		0.740732
  validation accuracy:		88.26 %
Epoch 1637 of 2000 took 0.096s
  training loss:		0.062065
  validation loss:		0.757060
  validation accuracy:		88.59 %
Epoch 1638 of 2000 took 0.100s
  training loss:		0.061044
  validation loss:		0.741008
  validation accuracy:		88.80 %
Epoch 1639 of 2000 took 0.098s
  training loss:		0.056835
  validation loss:		0.711651
  validation accuracy:		89.78 %
Epoch 1640 of 2000 took 0.096s
  training loss:		0.089681
  validation loss:		0.701681
  validation accuracy:		89.46 %
Epoch 1641 of 2000 took 0.100s
  training loss:		0.066422
  validation loss:		0.722507
  validation accuracy:		88.91 %
Epoch 1642 of 2000 took 0.099s
  training loss:		0.059537
  validation loss:		0.731942
  validation accuracy:		88.91 %
Epoch 1643 of 2000 took 0.097s
  training loss:		0.057802
  validation loss:		0.753908
  validation accuracy:		89.02 %
Epoch 1644 of 2000 took 0.097s
  training loss:		0.071674
  validation loss:		0.732142
  validation accuracy:		89.67 %
Epoch 1645 of 2000 took 0.096s
  training loss:		0.067322
  validation loss:		0.721978
  validation accuracy:		89.35 %
Epoch 1646 of 2000 took 0.101s
  training loss:		0.075587
  validation loss:		0.716978
  validation accuracy:		89.78 %
Epoch 1647 of 2000 took 0.097s
  training loss:		0.067296
  validation loss:		0.694757
  validation accuracy:		89.57 %
Epoch 1648 of 2000 took 0.096s
  training loss:		0.066135
  validation loss:		0.744011
  validation accuracy:		89.67 %
Epoch 1649 of 2000 took 0.103s
  training loss:		0.062557
  validation loss:		0.720270
  validation accuracy:		89.46 %
Epoch 1650 of 2000 took 0.096s
  training loss:		0.073203
  validation loss:		0.745671
  validation accuracy:		89.57 %
Epoch 1651 of 2000 took 0.097s
  training loss:		0.076845
  validation loss:		0.717766
  validation accuracy:		89.46 %
Epoch 1652 of 2000 took 0.096s
  training loss:		0.057949
  validation loss:		0.752396
  validation accuracy:		89.24 %
Epoch 1653 of 2000 took 0.098s
  training loss:		0.060484
  validation loss:		0.726187
  validation accuracy:		88.48 %
Epoch 1654 of 2000 took 0.101s
  training loss:		0.078181
  validation loss:		0.712179
  validation accuracy:		89.57 %
Epoch 1655 of 2000 took 0.096s
  training loss:		0.052529
  validation loss:		0.727769
  validation accuracy:		89.13 %
Epoch 1656 of 2000 took 0.097s
  training loss:		0.073797
  validation loss:		0.718638
  validation accuracy:		89.24 %
Epoch 1657 of 2000 took 0.137s
  training loss:		0.059310
  validation loss:		0.773767
  validation accuracy:		89.46 %
Epoch 1658 of 2000 took 0.107s
  training loss:		0.060192
  validation loss:		0.792309
  validation accuracy:		88.70 %
Epoch 1659 of 2000 took 0.098s
  training loss:		0.075624
  validation loss:		0.735520
  validation accuracy:		89.24 %
Epoch 1660 of 2000 took 0.097s
  training loss:		0.055504
  validation loss:		0.769522
  validation accuracy:		88.59 %
Epoch 1661 of 2000 took 0.101s
  training loss:		0.081289
  validation loss:		0.778813
  validation accuracy:		88.48 %
Epoch 1662 of 2000 took 0.100s
  training loss:		0.082934
  validation loss:		0.732350
  validation accuracy:		89.13 %
Epoch 1663 of 2000 took 0.097s
  training loss:		0.062863
  validation loss:		0.721156
  validation accuracy:		89.57 %
Epoch 1664 of 2000 took 0.101s
  training loss:		0.054683
  validation loss:		0.748770
  validation accuracy:		89.13 %
Epoch 1665 of 2000 took 0.100s
  training loss:		0.061077
  validation loss:		0.732134
  validation accuracy:		88.70 %
Epoch 1666 of 2000 took 0.097s
  training loss:		0.066993
  validation loss:		0.728812
  validation accuracy:		89.46 %
Epoch 1667 of 2000 took 0.097s
  training loss:		0.071925
  validation loss:		0.749996
  validation accuracy:		89.78 %
Epoch 1668 of 2000 took 0.096s
  training loss:		0.067826
  validation loss:		0.780374
  validation accuracy:		89.46 %
Epoch 1669 of 2000 took 0.101s
  training loss:		0.056252
  validation loss:		0.741749
  validation accuracy:		89.78 %
Epoch 1670 of 2000 took 0.098s
  training loss:		0.060314
  validation loss:		0.725549
  validation accuracy:		89.46 %
Epoch 1671 of 2000 took 0.096s
  training loss:		0.073507
  validation loss:		0.753245
  validation accuracy:		88.80 %
Epoch 1672 of 2000 took 0.102s
  training loss:		0.078702
  validation loss:		0.762456
  validation accuracy:		89.57 %
Epoch 1673 of 2000 took 0.097s
  training loss:		0.059069
  validation loss:		0.753849
  validation accuracy:		89.46 %
Epoch 1674 of 2000 took 0.097s
  training loss:		0.152351
  validation loss:		0.804479
  validation accuracy:		88.80 %
Epoch 1675 of 2000 took 0.097s
  training loss:		0.086385
  validation loss:		0.766373
  validation accuracy:		89.46 %
Epoch 1676 of 2000 took 0.097s
  training loss:		0.060092
  validation loss:		0.750337
  validation accuracy:		89.46 %
Epoch 1677 of 2000 took 0.100s
  training loss:		0.063045
  validation loss:		0.779677
  validation accuracy:		89.24 %
Epoch 1678 of 2000 took 0.097s
  training loss:		0.069673
  validation loss:		0.741179
  validation accuracy:		89.24 %
Epoch 1679 of 2000 took 0.097s
  training loss:		0.059088
  validation loss:		0.797878
  validation accuracy:		88.59 %
Epoch 1680 of 2000 took 0.103s
  training loss:		0.059004
  validation loss:		0.731313
  validation accuracy:		89.35 %
Epoch 1681 of 2000 took 0.096s
  training loss:		0.057655
  validation loss:		0.733823
  validation accuracy:		89.35 %
Epoch 1682 of 2000 took 0.097s
  training loss:		0.056757
  validation loss:		0.768674
  validation accuracy:		89.35 %
Epoch 1683 of 2000 took 0.096s
  training loss:		0.078242
  validation loss:		0.754379
  validation accuracy:		88.70 %
Epoch 1684 of 2000 took 0.098s
  training loss:		0.060415
  validation loss:		0.806717
  validation accuracy:		88.80 %
Epoch 1685 of 2000 took 0.100s
  training loss:		0.058022
  validation loss:		0.754177
  validation accuracy:		89.35 %
Epoch 1686 of 2000 took 0.096s
  training loss:		0.064586
  validation loss:		0.839530
  validation accuracy:		88.15 %
Epoch 1687 of 2000 took 0.098s
  training loss:		0.073364
  validation loss:		0.779415
  validation accuracy:		89.02 %
Epoch 1688 of 2000 took 0.101s
  training loss:		0.073796
  validation loss:		0.782079
  validation accuracy:		89.35 %
Epoch 1689 of 2000 took 0.096s
  training loss:		0.060178
  validation loss:		0.818559
  validation accuracy:		88.15 %
Epoch 1690 of 2000 took 0.097s
  training loss:		0.076281
  validation loss:		0.811374
  validation accuracy:		88.59 %
Epoch 1691 of 2000 took 0.096s
  training loss:		0.071020
  validation loss:		0.772930
  validation accuracy:		88.91 %
Epoch 1692 of 2000 took 0.101s
  training loss:		0.059175
  validation loss:		0.764355
  validation accuracy:		89.46 %
Epoch 1693 of 2000 took 0.098s
  training loss:		0.058533
  validation loss:		0.778265
  validation accuracy:		88.70 %
Epoch 1694 of 2000 took 0.096s
  training loss:		0.071758
  validation loss:		0.777540
  validation accuracy:		89.02 %
Epoch 1695 of 2000 took 0.102s
  training loss:		0.055201
  validation loss:		0.786137
  validation accuracy:		89.13 %
Epoch 1696 of 2000 took 0.098s
  training loss:		0.055982
  validation loss:		0.762181
  validation accuracy:		89.57 %
Epoch 1697 of 2000 took 0.097s
  training loss:		0.071747
  validation loss:		0.734696
  validation accuracy:		89.46 %
Epoch 1698 of 2000 took 0.099s
  training loss:		0.055193
  validation loss:		0.800351
  validation accuracy:		89.02 %
Epoch 1699 of 2000 took 0.167s
  training loss:		0.068263
  validation loss:		0.755864
  validation accuracy:		89.13 %
Epoch 1700 of 2000 took 0.169s
  training loss:		0.054960
  validation loss:		0.746344
  validation accuracy:		89.02 %
Epoch 1701 of 2000 took 0.165s
  training loss:		0.058257
  validation loss:		0.775384
  validation accuracy:		88.80 %
Epoch 1702 of 2000 took 0.165s
  training loss:		0.085603
  validation loss:		0.809695
  validation accuracy:		89.02 %
Epoch 1703 of 2000 took 0.170s
  training loss:		0.127840
  validation loss:		0.771501
  validation accuracy:		89.13 %
Epoch 1704 of 2000 took 0.164s
  training loss:		0.064302
  validation loss:		0.802437
  validation accuracy:		88.59 %
Epoch 1705 of 2000 took 0.166s
  training loss:		0.062447
  validation loss:		0.773423
  validation accuracy:		89.46 %
Epoch 1706 of 2000 took 0.164s
  training loss:		0.059533
  validation loss:		0.749113
  validation accuracy:		88.80 %
Epoch 1707 of 2000 took 0.169s
  training loss:		0.062376
  validation loss:		0.801633
  validation accuracy:		89.13 %
Epoch 1708 of 2000 took 0.166s
  training loss:		0.098349
  validation loss:		0.745546
  validation accuracy:		88.70 %
Epoch 1709 of 2000 took 0.164s
  training loss:		0.068083
  validation loss:		0.813627
  validation accuracy:		89.02 %
Epoch 1710 of 2000 took 0.170s
  training loss:		0.070137
  validation loss:		0.732897
  validation accuracy:		89.35 %
Epoch 1711 of 2000 took 0.165s
  training loss:		0.060181
  validation loss:		0.770121
  validation accuracy:		89.35 %
Epoch 1712 of 2000 took 0.166s
  training loss:		0.053207
  validation loss:		0.766195
  validation accuracy:		89.02 %
Epoch 1713 of 2000 took 0.164s
  training loss:		0.056917
  validation loss:		0.779715
  validation accuracy:		89.35 %
Epoch 1714 of 2000 took 0.167s
  training loss:		0.055026
  validation loss:		0.753030
  validation accuracy:		89.24 %
Epoch 1715 of 2000 took 0.169s
  training loss:		0.052654
  validation loss:		0.794221
  validation accuracy:		88.59 %
Epoch 1716 of 2000 took 0.164s
  training loss:		0.067750
  validation loss:		0.831443
  validation accuracy:		88.80 %
Epoch 1717 of 2000 took 0.167s
  training loss:		0.056935
  validation loss:		0.793312
  validation accuracy:		89.35 %
Epoch 1718 of 2000 took 0.168s
  training loss:		0.056977
  validation loss:		0.754861
  validation accuracy:		88.91 %
Epoch 1719 of 2000 took 0.165s
  training loss:		0.056093
  validation loss:		0.774553
  validation accuracy:		88.70 %
Epoch 1720 of 2000 took 0.165s
  training loss:		0.064020
  validation loss:		0.767780
  validation accuracy:		88.91 %
Epoch 1721 of 2000 took 0.164s
  training loss:		0.065152
  validation loss:		0.806094
  validation accuracy:		88.91 %
Epoch 1722 of 2000 took 0.167s
  training loss:		0.064264
  validation loss:		0.852918
  validation accuracy:		88.70 %
Epoch 1723 of 2000 took 0.165s
  training loss:		0.049464
  validation loss:		0.785878
  validation accuracy:		88.80 %
Epoch 1724 of 2000 took 0.165s
  training loss:		0.052337
  validation loss:		0.778036
  validation accuracy:		89.89 %
Epoch 1725 of 2000 took 0.170s
  training loss:		0.064886
  validation loss:		0.819902
  validation accuracy:		89.02 %
Epoch 1726 of 2000 took 0.164s
  training loss:		0.054727
  validation loss:		0.792178
  validation accuracy:		88.70 %
Epoch 1727 of 2000 took 0.166s
  training loss:		0.057058
  validation loss:		0.780013
  validation accuracy:		89.35 %
Epoch 1728 of 2000 took 0.164s
  training loss:		0.058813
  validation loss:		0.728184
  validation accuracy:		89.24 %
Epoch 1729 of 2000 took 0.168s
  training loss:		0.104834
  validation loss:		0.786034
  validation accuracy:		89.13 %
Epoch 1730 of 2000 took 0.166s
  training loss:		0.143691
  validation loss:		0.818910
  validation accuracy:		88.59 %
Epoch 1731 of 2000 took 0.161s
  training loss:		0.063664
  validation loss:		0.805583
  validation accuracy:		89.13 %
Epoch 1732 of 2000 took 0.163s
  training loss:		0.066398
  validation loss:		0.757207
  validation accuracy:		89.35 %
Epoch 1733 of 2000 took 0.166s
  training loss:		0.069836
  validation loss:		0.784274
  validation accuracy:		90.00 %
Epoch 1734 of 2000 took 0.165s
  training loss:		0.066604
  validation loss:		0.777275
  validation accuracy:		89.67 %
Epoch 1735 of 2000 took 0.165s
  training loss:		0.074220
  validation loss:		0.907048
  validation accuracy:		88.15 %
Epoch 1736 of 2000 took 0.165s
  training loss:		0.068483
  validation loss:		0.833534
  validation accuracy:		88.70 %
Epoch 1737 of 2000 took 0.169s
  training loss:		0.071794
  validation loss:		0.785929
  validation accuracy:		89.46 %
Epoch 1738 of 2000 took 0.164s
  training loss:		0.058154
  validation loss:		0.789404
  validation accuracy:		88.91 %
Epoch 1739 of 2000 took 0.163s
  training loss:		0.057247
  validation loss:		0.772600
  validation accuracy:		89.02 %
Epoch 1740 of 2000 took 0.167s
  training loss:		0.063104
  validation loss:		0.877049
  validation accuracy:		88.48 %
Epoch 1741 of 2000 took 0.164s
  training loss:		0.068665
  validation loss:		0.918357
  validation accuracy:		88.04 %
Epoch 1742 of 2000 took 0.166s
  training loss:		0.073813
  validation loss:		0.762018
  validation accuracy:		89.46 %
Epoch 1743 of 2000 took 0.164s
  training loss:		0.061450
  validation loss:		0.805368
  validation accuracy:		89.24 %
Epoch 1744 of 2000 took 0.169s
  training loss:		0.053213
  validation loss:		0.805533
  validation accuracy:		89.13 %
Epoch 1745 of 2000 took 0.166s
  training loss:		0.056006
  validation loss:		0.783979
  validation accuracy:		89.57 %
Epoch 1746 of 2000 took 0.164s
  training loss:		0.073452
  validation loss:		0.934454
  validation accuracy:		85.22 %
Epoch 1747 of 2000 took 0.170s
  training loss:		0.095329
  validation loss:		0.815482
  validation accuracy:		88.80 %
Epoch 1748 of 2000 took 0.164s
  training loss:		0.068711
  validation loss:		0.762282
  validation accuracy:		89.35 %
Epoch 1749 of 2000 took 0.165s
  training loss:		0.056002
  validation loss:		0.877685
  validation accuracy:		88.80 %
Epoch 1750 of 2000 took 0.164s
  training loss:		0.068737
  validation loss:		0.801974
  validation accuracy:		88.80 %
Epoch 1751 of 2000 took 0.166s
  training loss:		0.052431
  validation loss:		0.787913
  validation accuracy:		89.02 %
Epoch 1752 of 2000 took 0.168s
  training loss:		0.047293
  validation loss:		0.781910
  validation accuracy:		89.67 %
Epoch 1753 of 2000 took 0.164s
  training loss:		0.048376
  validation loss:		0.798154
  validation accuracy:		89.67 %
Epoch 1754 of 2000 took 0.165s
  training loss:		0.059166
  validation loss:		0.862107
  validation accuracy:		87.93 %
Epoch 1755 of 2000 took 0.168s
  training loss:		0.076695
  validation loss:		0.821271
  validation accuracy:		89.24 %
Epoch 1756 of 2000 took 0.165s
  training loss:		0.061154
  validation loss:		0.793802
  validation accuracy:		89.13 %
Epoch 1757 of 2000 took 0.165s
  training loss:		0.079126
  validation loss:		0.795340
  validation accuracy:		89.13 %
Epoch 1758 of 2000 took 0.165s
  training loss:		0.076726
  validation loss:		0.768307
  validation accuracy:		89.13 %
Epoch 1759 of 2000 took 0.169s
  training loss:		0.066281
  validation loss:		0.833947
  validation accuracy:		89.02 %
Epoch 1760 of 2000 took 0.166s
  training loss:		0.052588
  validation loss:		0.789159
  validation accuracy:		89.02 %
Epoch 1761 of 2000 took 0.165s
  training loss:		0.058424
  validation loss:		0.813805
  validation accuracy:		89.57 %
Epoch 1762 of 2000 took 0.170s
  training loss:		0.047571
  validation loss:		0.796810
  validation accuracy:		89.02 %
Epoch 1763 of 2000 took 0.164s
  training loss:		0.051951
  validation loss:		0.815731
  validation accuracy:		88.59 %
Epoch 1764 of 2000 took 0.165s
  training loss:		0.058276
  validation loss:		0.798736
  validation accuracy:		89.78 %
Epoch 1765 of 2000 took 0.164s
  training loss:		0.074304
  validation loss:		0.801035
  validation accuracy:		88.70 %
Epoch 1766 of 2000 took 0.168s
  training loss:		0.059539
  validation loss:		0.816689
  validation accuracy:		88.80 %
Epoch 1767 of 2000 took 0.167s
  training loss:		0.054825
  validation loss:		0.795513
  validation accuracy:		89.57 %
Epoch 1768 of 2000 took 0.164s
  training loss:		0.059840
  validation loss:		0.818224
  validation accuracy:		89.02 %
Epoch 1769 of 2000 took 0.169s
  training loss:		0.050248
  validation loss:		0.790777
  validation accuracy:		89.46 %
Epoch 1770 of 2000 took 0.166s
  training loss:		0.100315
  validation loss:		0.878961
  validation accuracy:		87.93 %
Epoch 1771 of 2000 took 0.165s
  training loss:		0.065695
  validation loss:		0.804721
  validation accuracy:		89.35 %
Epoch 1772 of 2000 took 0.165s
  training loss:		0.055248
  validation loss:		0.884697
  validation accuracy:		87.93 %
Epoch 1773 of 2000 took 0.165s
  training loss:		0.073307
  validation loss:		0.825022
  validation accuracy:		88.70 %
Epoch 1774 of 2000 took 0.169s
  training loss:		0.059674
  validation loss:		0.780013
  validation accuracy:		88.70 %
Epoch 1775 of 2000 took 0.164s
  training loss:		0.105008
  validation loss:		0.810522
  validation accuracy:		90.11 %
Epoch 1776 of 2000 took 0.163s
  training loss:		0.097172
  validation loss:		0.823760
  validation accuracy:		88.91 %
Epoch 1777 of 2000 took 0.170s
  training loss:		0.080585
  validation loss:		0.817132
  validation accuracy:		89.46 %
Epoch 1778 of 2000 took 0.164s
  training loss:		0.054991
  validation loss:		0.810800
  validation accuracy:		90.00 %
Epoch 1779 of 2000 took 0.166s
  training loss:		0.067707
  validation loss:		0.903162
  validation accuracy:		88.15 %
Epoch 1780 of 2000 took 0.164s
  training loss:		0.059534
  validation loss:		0.855286
  validation accuracy:		87.72 %
Epoch 1781 of 2000 took 0.169s
  training loss:		0.092766
  validation loss:		0.804371
  validation accuracy:		88.26 %
Epoch 1782 of 2000 took 0.166s
  training loss:		0.059093
  validation loss:		0.807108
  validation accuracy:		89.13 %
Epoch 1783 of 2000 took 0.164s
  training loss:		0.058052
  validation loss:		0.838792
  validation accuracy:		89.57 %
Epoch 1784 of 2000 took 0.170s
  training loss:		0.080415
  validation loss:		0.790782
  validation accuracy:		89.24 %
Epoch 1785 of 2000 took 0.165s
  training loss:		0.078978
  validation loss:		0.879413
  validation accuracy:		88.48 %
Epoch 1786 of 2000 took 0.165s
  training loss:		0.062573
  validation loss:		0.836185
  validation accuracy:		89.24 %
Epoch 1787 of 2000 took 0.164s
  training loss:		0.059681
  validation loss:		0.788960
  validation accuracy:		89.46 %
Epoch 1788 of 2000 took 0.166s
  training loss:		0.050160
  validation loss:		0.796223
  validation accuracy:		88.91 %
Epoch 1789 of 2000 took 0.168s
  training loss:		0.057128
  validation loss:		0.779186
  validation accuracy:		88.70 %
Epoch 1790 of 2000 took 0.164s
  training loss:		0.065067
  validation loss:		0.872936
  validation accuracy:		88.26 %
Epoch 1791 of 2000 took 0.165s
  training loss:		0.050625
  validation loss:		0.825538
  validation accuracy:		89.13 %
Epoch 1792 of 2000 took 0.168s
  training loss:		0.051900
  validation loss:		0.821180
  validation accuracy:		89.13 %
Epoch 1793 of 2000 took 0.165s
  training loss:		0.063892
  validation loss:		0.789589
  validation accuracy:		88.70 %
Epoch 1794 of 2000 took 0.165s
  training loss:		0.055123
  validation loss:		0.835162
  validation accuracy:		88.91 %
Epoch 1795 of 2000 took 0.165s
  training loss:		0.115616
  validation loss:		0.807850
  validation accuracy:		89.57 %
Epoch 1796 of 2000 took 0.169s
  training loss:		0.065040
  validation loss:		0.826575
  validation accuracy:		88.70 %
Epoch 1797 of 2000 took 0.165s
  training loss:		0.072339
  validation loss:		0.902889
  validation accuracy:		87.72 %
Epoch 1798 of 2000 took 0.165s
  training loss:		0.054879
  validation loss:		0.819158
  validation accuracy:		89.02 %
Epoch 1799 of 2000 took 0.170s
  training loss:		0.050865
  validation loss:		0.848602
  validation accuracy:		88.70 %
Epoch 1800 of 2000 took 0.164s
  training loss:		0.048717
  validation loss:		0.823330
  validation accuracy:		88.80 %
Epoch 1801 of 2000 took 0.166s
  training loss:		0.087313
  validation loss:		1.190713
  validation accuracy:		86.96 %
Epoch 1802 of 2000 took 0.164s
  training loss:		0.173822
  validation loss:		0.916453
  validation accuracy:		88.04 %
Epoch 1803 of 2000 took 0.168s
  training loss:		0.082597
  validation loss:		0.862516
  validation accuracy:		89.02 %
Epoch 1804 of 2000 took 0.167s
  training loss:		0.067843
  validation loss:		0.813786
  validation accuracy:		89.67 %
Epoch 1805 of 2000 took 0.164s
  training loss:		0.050643
  validation loss:		0.820014
  validation accuracy:		89.13 %
Epoch 1806 of 2000 took 0.169s
  training loss:		0.052576
  validation loss:		0.781868
  validation accuracy:		88.91 %
Epoch 1807 of 2000 took 0.166s
  training loss:		0.059695
  validation loss:		0.812057
  validation accuracy:		88.91 %
Epoch 1808 of 2000 took 0.165s
  training loss:		0.127632
  validation loss:		0.788089
  validation accuracy:		89.78 %
Epoch 1809 of 2000 took 0.165s
  training loss:		0.055043
  validation loss:		0.789379
  validation accuracy:		89.67 %
Epoch 1810 of 2000 took 0.166s
  training loss:		0.060951
  validation loss:		0.805086
  validation accuracy:		89.57 %
Epoch 1811 of 2000 took 0.169s
  training loss:		0.062640
  validation loss:		0.794672
  validation accuracy:		89.46 %
Epoch 1812 of 2000 took 0.165s
  training loss:		0.065369
  validation loss:		0.865667
  validation accuracy:		89.35 %
Epoch 1813 of 2000 took 0.166s
  training loss:		0.061510
  validation loss:		0.939680
  validation accuracy:		88.37 %
Epoch 1814 of 2000 took 0.169s
  training loss:		0.098428
  validation loss:		0.788284
  validation accuracy:		89.13 %
Epoch 1815 of 2000 took 0.164s
  training loss:		0.060718
  validation loss:		0.810538
  validation accuracy:		89.13 %
Epoch 1816 of 2000 took 0.165s
  training loss:		0.055667
  validation loss:		0.856335
  validation accuracy:		87.17 %
Epoch 1817 of 2000 took 0.162s
  training loss:		0.111417
  validation loss:		0.821732
  validation accuracy:		89.35 %
Epoch 1818 of 2000 took 0.169s
  training loss:		0.053599
  validation loss:		0.787228
  validation accuracy:		89.35 %
Epoch 1819 of 2000 took 0.166s
  training loss:		0.055977
  validation loss:		0.825923
  validation accuracy:		88.80 %
Epoch 1820 of 2000 took 0.164s
  training loss:		0.070235
  validation loss:		0.787729
  validation accuracy:		89.35 %
Epoch 1821 of 2000 took 0.170s
  training loss:		0.057275
  validation loss:		0.788093
  validation accuracy:		89.67 %
Epoch 1822 of 2000 took 0.165s
  training loss:		0.056377
  validation loss:		0.773223
  validation accuracy:		89.13 %
Epoch 1823 of 2000 took 0.165s
  training loss:		0.054275
  validation loss:		0.806712
  validation accuracy:		89.13 %
Epoch 1824 of 2000 took 0.164s
  training loss:		0.052743
  validation loss:		0.816392
  validation accuracy:		89.24 %
Epoch 1825 of 2000 took 0.166s
  training loss:		0.060621
  validation loss:		0.821412
  validation accuracy:		89.78 %
Epoch 1826 of 2000 took 0.168s
  training loss:		0.063668
  validation loss:		0.824698
  validation accuracy:		88.91 %
Epoch 1827 of 2000 took 0.164s
  training loss:		0.049454
  validation loss:		0.811952
  validation accuracy:		89.13 %
Epoch 1828 of 2000 took 0.167s
  training loss:		0.056665
  validation loss:		0.826526
  validation accuracy:		88.91 %
Epoch 1829 of 2000 took 0.168s
  training loss:		0.054481
  validation loss:		0.850265
  validation accuracy:		88.80 %
Epoch 1830 of 2000 took 0.165s
  training loss:		0.067428
  validation loss:		0.847984
  validation accuracy:		88.91 %
Epoch 1831 of 2000 took 0.165s
  training loss:		0.058148
  validation loss:		0.773315
  validation accuracy:		89.35 %
Epoch 1832 of 2000 took 0.165s
  training loss:		0.062880
  validation loss:		0.809529
  validation accuracy:		89.67 %
Epoch 1833 of 2000 took 0.169s
  training loss:		0.053792
  validation loss:		0.801001
  validation accuracy:		88.91 %
Epoch 1834 of 2000 took 0.163s
  training loss:		0.053307
  validation loss:		0.891430
  validation accuracy:		89.13 %
Epoch 1835 of 2000 took 0.165s
  training loss:		0.058238
  validation loss:		0.820065
  validation accuracy:		88.80 %
Epoch 1836 of 2000 took 0.170s
  training loss:		0.050203
  validation loss:		0.801485
  validation accuracy:		89.02 %
Epoch 1837 of 2000 took 0.164s
  training loss:		0.059518
  validation loss:		0.854241
  validation accuracy:		88.91 %
Epoch 1838 of 2000 took 0.166s
  training loss:		0.051146
  validation loss:		0.838428
  validation accuracy:		89.02 %
Epoch 1839 of 2000 took 0.164s
  training loss:		0.050064
  validation loss:		0.814129
  validation accuracy:		88.80 %
Epoch 1840 of 2000 took 0.168s
  training loss:		0.048882
  validation loss:		0.827884
  validation accuracy:		88.48 %
Epoch 1841 of 2000 took 0.167s
  training loss:		0.051600
  validation loss:		0.847891
  validation accuracy:		89.13 %
Epoch 1842 of 2000 took 0.164s
  training loss:		0.046658
  validation loss:		0.838843
  validation accuracy:		88.48 %
Epoch 1843 of 2000 took 0.169s
  training loss:		0.054618
  validation loss:		0.869893
  validation accuracy:		88.37 %
Epoch 1844 of 2000 took 0.166s
  training loss:		0.051624
  validation loss:		0.869174
  validation accuracy:		88.91 %
Epoch 1845 of 2000 took 0.165s
  training loss:		0.055460
  validation loss:		0.845885
  validation accuracy:		88.91 %
Epoch 1846 of 2000 took 0.165s
  training loss:		0.047278
  validation loss:		0.912068
  validation accuracy:		88.70 %
Epoch 1847 of 2000 took 0.166s
  training loss:		0.054939
  validation loss:		0.861831
  validation accuracy:		88.70 %
Epoch 1848 of 2000 took 0.169s
  training loss:		0.052810
  validation loss:		0.903073
  validation accuracy:		88.26 %
Epoch 1849 of 2000 took 0.164s
  training loss:		0.056723
  validation loss:		0.871967
  validation accuracy:		89.13 %
Epoch 1850 of 2000 took 0.164s
  training loss:		0.047233
  validation loss:		0.846375
  validation accuracy:		88.59 %
Epoch 1851 of 2000 took 0.169s
  training loss:		0.059473
  validation loss:		0.880033
  validation accuracy:		88.91 %
Epoch 1852 of 2000 took 0.164s
  training loss:		0.124328
  validation loss:		0.953890
  validation accuracy:		87.39 %
Epoch 1853 of 2000 took 0.166s
  training loss:		0.071504
  validation loss:		0.869566
  validation accuracy:		88.80 %
Epoch 1854 of 2000 took 0.164s
  training loss:		0.050656
  validation loss:		0.855991
  validation accuracy:		88.37 %
Epoch 1855 of 2000 took 0.169s
  training loss:		0.061682
  validation loss:		0.864080
  validation accuracy:		89.02 %
Epoch 1856 of 2000 took 0.166s
  training loss:		0.047474
  validation loss:		0.849782
  validation accuracy:		89.24 %
Epoch 1857 of 2000 took 0.165s
  training loss:		0.048209
  validation loss:		0.868660
  validation accuracy:		88.91 %
Epoch 1858 of 2000 took 0.170s
  training loss:		0.051302
  validation loss:		0.871352
  validation accuracy:		89.24 %
Epoch 1859 of 2000 took 0.164s
  training loss:		0.062503
  validation loss:		0.841878
  validation accuracy:		88.80 %
Epoch 1860 of 2000 took 0.165s
  training loss:		0.070308
  validation loss:		0.946840
  validation accuracy:		88.04 %
Epoch 1861 of 2000 took 0.165s
  training loss:		0.064270
  validation loss:		0.813386
  validation accuracy:		89.67 %
Epoch 1862 of 2000 took 0.166s
  training loss:		0.065045
  validation loss:		0.901874
  validation accuracy:		89.02 %
Epoch 1863 of 2000 took 0.169s
  training loss:		0.052428
  validation loss:		0.799552
  validation accuracy:		89.24 %
Epoch 1864 of 2000 took 0.164s
  training loss:		0.073569
  validation loss:		0.868271
  validation accuracy:		88.91 %
Epoch 1865 of 2000 took 0.166s
  training loss:		0.064506
  validation loss:		0.858322
  validation accuracy:		88.48 %
Epoch 1866 of 2000 took 0.169s
  training loss:		0.062869
  validation loss:		0.840152
  validation accuracy:		89.57 %
Epoch 1867 of 2000 took 0.162s
  training loss:		0.052342
  validation loss:		0.833035
  validation accuracy:		88.59 %
Epoch 1868 of 2000 took 0.166s
  training loss:		0.057554
  validation loss:		0.855017
  validation accuracy:		88.48 %
Epoch 1869 of 2000 took 0.164s
  training loss:		0.044499
  validation loss:		0.862595
  validation accuracy:		89.13 %
Epoch 1870 of 2000 took 0.153s
  training loss:		0.063524
  validation loss:		0.812442
  validation accuracy:		88.70 %
Epoch 1871 of 2000 took 0.098s
  training loss:		0.061638
  validation loss:		0.847892
  validation accuracy:		88.59 %
Epoch 1872 of 2000 took 0.096s
  training loss:		0.048821
  validation loss:		0.853943
  validation accuracy:		89.46 %
Epoch 1873 of 2000 took 0.105s
  training loss:		0.051636
  validation loss:		0.825369
  validation accuracy:		88.80 %
Epoch 1874 of 2000 took 0.099s
  training loss:		0.054043
  validation loss:		0.859978
  validation accuracy:		88.70 %
Epoch 1875 of 2000 took 0.098s
  training loss:		0.049491
  validation loss:		0.955433
  validation accuracy:		88.26 %
Epoch 1876 of 2000 took 0.098s
  training loss:		0.062720
  validation loss:		0.892420
  validation accuracy:		88.59 %
Epoch 1877 of 2000 took 0.097s
  training loss:		0.101461
  validation loss:		1.340136
  validation accuracy:		85.98 %
Epoch 1878 of 2000 took 0.100s
  training loss:		0.273353
  validation loss:		0.890961
  validation accuracy:		88.70 %
Epoch 1879 of 2000 took 0.097s
  training loss:		0.089473
  validation loss:		0.861387
  validation accuracy:		89.35 %
Epoch 1880 of 2000 took 0.097s
  training loss:		0.067540
  validation loss:		0.958253
  validation accuracy:		87.93 %
Epoch 1881 of 2000 took 0.103s
  training loss:		0.065888
  validation loss:		0.812449
  validation accuracy:		89.57 %
Epoch 1882 of 2000 took 0.096s
  training loss:		0.059226
  validation loss:		0.836066
  validation accuracy:		89.35 %
Epoch 1883 of 2000 took 0.097s
  training loss:		0.053247
  validation loss:		0.776065
  validation accuracy:		89.67 %
Epoch 1884 of 2000 took 0.096s
  training loss:		0.069500
  validation loss:		0.831931
  validation accuracy:		88.80 %
Epoch 1885 of 2000 took 0.098s
  training loss:		0.084397
  validation loss:		0.837217
  validation accuracy:		88.48 %
Epoch 1886 of 2000 took 0.100s
  training loss:		0.050621
  validation loss:		0.845122
  validation accuracy:		89.46 %
Epoch 1887 of 2000 took 0.097s
  training loss:		0.055323
  validation loss:		0.838492
  validation accuracy:		89.13 %
Epoch 1888 of 2000 took 0.098s
  training loss:		0.053785
  validation loss:		0.873447
  validation accuracy:		89.02 %
Epoch 1889 of 2000 took 0.101s
  training loss:		0.043544
  validation loss:		0.842628
  validation accuracy:		89.24 %
Epoch 1890 of 2000 took 0.096s
  training loss:		0.049278
  validation loss:		0.893115
  validation accuracy:		88.48 %
Epoch 1891 of 2000 took 0.097s
  training loss:		0.057458
  validation loss:		0.857646
  validation accuracy:		88.80 %
Epoch 1892 of 2000 took 0.096s
  training loss:		0.058211
  validation loss:		0.854847
  validation accuracy:		89.24 %
Epoch 1893 of 2000 took 0.101s
  training loss:		0.053289
  validation loss:		0.856534
  validation accuracy:		88.91 %
Epoch 1894 of 2000 took 0.098s
  training loss:		0.060301
  validation loss:		0.873580
  validation accuracy:		88.37 %
Epoch 1895 of 2000 took 0.096s
  training loss:		0.049848
  validation loss:		0.848011
  validation accuracy:		88.15 %
Epoch 1896 of 2000 took 0.101s
  training loss:		0.058136
  validation loss:		0.856448
  validation accuracy:		88.91 %
Epoch 1897 of 2000 took 0.098s
  training loss:		0.057098
  validation loss:		0.870578
  validation accuracy:		88.80 %
Epoch 1898 of 2000 took 0.097s
  training loss:		0.051574
  validation loss:		0.849118
  validation accuracy:		88.48 %
Epoch 1899 of 2000 took 0.097s
  training loss:		0.056548
  validation loss:		0.850261
  validation accuracy:		88.80 %
Epoch 1900 of 2000 took 0.097s
  training loss:		0.057285
  validation loss:		0.895953
  validation accuracy:		88.37 %
Epoch 1901 of 2000 took 0.101s
  training loss:		0.051270
  validation loss:		0.872392
  validation accuracy:		88.59 %
Epoch 1902 of 2000 took 0.097s
  training loss:		0.062716
  validation loss:		0.855619
  validation accuracy:		88.80 %
Epoch 1903 of 2000 took 0.097s
  training loss:		0.091919
  validation loss:		0.885357
  validation accuracy:		88.59 %
Epoch 1904 of 2000 took 0.103s
  training loss:		0.063179
  validation loss:		0.818371
  validation accuracy:		88.80 %
Epoch 1905 of 2000 took 0.096s
  training loss:		0.054502
  validation loss:		0.857629
  validation accuracy:		88.80 %
Epoch 1906 of 2000 took 0.097s
  training loss:		0.050591
  validation loss:		0.903470
  validation accuracy:		89.02 %
Epoch 1907 of 2000 took 0.096s
  training loss:		0.069662
  validation loss:		0.871248
  validation accuracy:		88.48 %
Epoch 1908 of 2000 took 0.098s
  training loss:		0.056296
  validation loss:		0.837618
  validation accuracy:		89.46 %
Epoch 1909 of 2000 took 0.100s
  training loss:		0.053232
  validation loss:		0.845330
  validation accuracy:		88.59 %
Epoch 1910 of 2000 took 0.096s
  training loss:		0.051559
  validation loss:		0.844213
  validation accuracy:		88.48 %
Epoch 1911 of 2000 took 0.097s
  training loss:		0.270637
  validation loss:		0.875794
  validation accuracy:		88.70 %
Epoch 1912 of 2000 took 0.102s
  training loss:		0.071484
  validation loss:		0.919883
  validation accuracy:		88.04 %
Epoch 1913 of 2000 took 0.096s
  training loss:		0.060225
  validation loss:		0.853235
  validation accuracy:		89.67 %
Epoch 1914 of 2000 took 0.097s
  training loss:		0.054881
  validation loss:		0.825572
  validation accuracy:		89.46 %
Epoch 1915 of 2000 took 0.096s
  training loss:		0.057207
  validation loss:		0.887743
  validation accuracy:		88.70 %
Epoch 1916 of 2000 took 0.103s
  training loss:		0.070577
  validation loss:		0.861402
  validation accuracy:		88.80 %
Epoch 1917 of 2000 took 0.098s
  training loss:		0.056151
  validation loss:		0.864870
  validation accuracy:		89.13 %
Epoch 1918 of 2000 took 0.096s
  training loss:		0.098078
  validation loss:		0.871125
  validation accuracy:		89.46 %
Epoch 1919 of 2000 took 0.100s
  training loss:		0.062487
  validation loss:		0.933263
  validation accuracy:		88.59 %
Epoch 1920 of 2000 took 0.098s
  training loss:		0.065241
  validation loss:		0.901519
  validation accuracy:		89.78 %
Epoch 1921 of 2000 took 0.096s
  training loss:		0.049621
  validation loss:		0.850541
  validation accuracy:		88.15 %
Epoch 1922 of 2000 took 0.097s
  training loss:		0.053560
  validation loss:		0.819712
  validation accuracy:		88.91 %
Epoch 1923 of 2000 took 0.096s
  training loss:		0.115310
  validation loss:		0.944687
  validation accuracy:		88.59 %
Epoch 1924 of 2000 took 0.101s
  training loss:		0.060112
  validation loss:		0.821985
  validation accuracy:		88.80 %
Epoch 1925 of 2000 took 0.097s
  training loss:		0.047234
  validation loss:		0.887413
  validation accuracy:		89.35 %
Epoch 1926 of 2000 took 0.096s
  training loss:		0.044811
  validation loss:		0.878198
  validation accuracy:		89.46 %
Epoch 1927 of 2000 took 0.103s
  training loss:		0.065763
  validation loss:		0.866089
  validation accuracy:		89.35 %
Epoch 1928 of 2000 took 0.096s
  training loss:		0.046248
  validation loss:		0.934784
  validation accuracy:		87.93 %
Epoch 1929 of 2000 took 0.097s
  training loss:		0.062524
  validation loss:		0.855725
  validation accuracy:		87.72 %
Epoch 1930 of 2000 took 0.096s
  training loss:		0.070229
  validation loss:		0.907298
  validation accuracy:		88.80 %
Epoch 1931 of 2000 took 0.098s
  training loss:		0.068458
  validation loss:		0.862295
  validation accuracy:		88.80 %
Epoch 1932 of 2000 took 0.101s
  training loss:		0.083639
  validation loss:		0.882037
  validation accuracy:		89.24 %
Epoch 1933 of 2000 took 0.096s
  training loss:		0.049802
  validation loss:		0.890807
  validation accuracy:		88.26 %
Epoch 1934 of 2000 took 0.097s
  training loss:		0.049323
  validation loss:		0.894765
  validation accuracy:		89.02 %
Epoch 1935 of 2000 took 0.099s
  training loss:		0.088613
  validation loss:		0.861105
  validation accuracy:		89.13 %
Epoch 1936 of 2000 took 0.096s
  training loss:		0.053656
  validation loss:		0.834673
  validation accuracy:		89.02 %
Epoch 1937 of 2000 took 0.100s
  training loss:		0.046744
  validation loss:		0.848075
  validation accuracy:		88.80 %
Epoch 1938 of 2000 took 0.096s
  training loss:		0.065620
  validation loss:		0.965489
  validation accuracy:		88.37 %
Epoch 1939 of 2000 took 0.098s
  training loss:		0.101332
  validation loss:		0.895789
  validation accuracy:		88.37 %
Epoch 1940 of 2000 took 0.097s
  training loss:		0.050090
  validation loss:		0.889212
  validation accuracy:		88.59 %
Epoch 1941 of 2000 took 0.097s
  training loss:		0.047909
  validation loss:		0.873945
  validation accuracy:		88.37 %
Epoch 1942 of 2000 took 0.099s
  training loss:		0.089313
  validation loss:		0.876368
  validation accuracy:		88.59 %
Epoch 1943 of 2000 took 0.096s
  training loss:		0.052685
  validation loss:		0.886240
  validation accuracy:		89.35 %
Epoch 1944 of 2000 took 0.100s
  training loss:		0.052238
  validation loss:		0.875915
  validation accuracy:		89.24 %
Epoch 1945 of 2000 took 0.096s
  training loss:		0.047814
  validation loss:		0.880142
  validation accuracy:		88.59 %
Epoch 1946 of 2000 took 0.097s
  training loss:		0.046794
  validation loss:		0.861436
  validation accuracy:		88.91 %
Epoch 1947 of 2000 took 0.099s
  training loss:		0.050041
  validation loss:		0.869733
  validation accuracy:		89.13 %
Epoch 1948 of 2000 took 0.096s
  training loss:		0.068344
  validation loss:		0.837480
  validation accuracy:		89.02 %
Epoch 1949 of 2000 took 0.100s
  training loss:		0.055283
  validation loss:		0.887847
  validation accuracy:		89.02 %
Epoch 1950 of 2000 took 0.096s
  training loss:		0.053134
  validation loss:		0.917211
  validation accuracy:		89.13 %
Epoch 1951 of 2000 took 0.099s
  training loss:		0.054081
  validation loss:		0.908280
  validation accuracy:		88.80 %
Epoch 1952 of 2000 took 0.097s
  training loss:		0.052560
  validation loss:		0.918421
  validation accuracy:		87.72 %
Epoch 1953 of 2000 took 0.097s
  training loss:		0.061291
  validation loss:		0.933502
  validation accuracy:		89.02 %
Epoch 1954 of 2000 took 0.099s
  training loss:		0.052500
  validation loss:		0.886116
  validation accuracy:		89.24 %
Epoch 1955 of 2000 took 0.096s
  training loss:		0.056058
  validation loss:		0.858839
  validation accuracy:		88.91 %
Epoch 1956 of 2000 took 0.100s
  training loss:		0.046034
  validation loss:		0.853036
  validation accuracy:		88.48 %
Epoch 1957 of 2000 took 0.096s
  training loss:		0.045821
  validation loss:		0.893747
  validation accuracy:		89.02 %
Epoch 1958 of 2000 took 0.098s
  training loss:		0.056315
  validation loss:		0.866838
  validation accuracy:		88.70 %
Epoch 1959 of 2000 took 0.098s
  training loss:		0.067538
  validation loss:		0.870021
  validation accuracy:		88.70 %
Epoch 1960 of 2000 took 0.097s
  training loss:		0.050187
  validation loss:		0.882352
  validation accuracy:		88.70 %
Epoch 1961 of 2000 took 0.103s
  training loss:		0.054078
  validation loss:		0.985426
  validation accuracy:		88.15 %
Epoch 1962 of 2000 took 0.096s
  training loss:		0.078149
  validation loss:		0.933505
  validation accuracy:		88.37 %
Epoch 1963 of 2000 took 0.097s
  training loss:		0.048651
  validation loss:		0.938183
  validation accuracy:		88.59 %
Epoch 1964 of 2000 took 0.096s
  training loss:		0.062197
  validation loss:		0.880538
  validation accuracy:		89.13 %
Epoch 1965 of 2000 took 0.098s
  training loss:		0.045516
  validation loss:		0.872908
  validation accuracy:		89.13 %
Epoch 1966 of 2000 took 0.100s
  training loss:		0.043815
  validation loss:		0.992221
  validation accuracy:		88.04 %
Epoch 1967 of 2000 took 0.096s
  training loss:		0.052563
  validation loss:		0.886805
  validation accuracy:		88.26 %
Epoch 1968 of 2000 took 0.098s
  training loss:		0.059726
  validation loss:		0.918087
  validation accuracy:		88.37 %
Epoch 1969 of 2000 took 0.101s
  training loss:		0.046900
  validation loss:		0.917302
  validation accuracy:		88.37 %
Epoch 1970 of 2000 took 0.096s
  training loss:		0.046410
  validation loss:		0.908653
  validation accuracy:		89.35 %
Epoch 1971 of 2000 took 0.097s
  training loss:		0.048132
  validation loss:		0.875811
  validation accuracy:		88.70 %
Epoch 1972 of 2000 took 0.096s
  training loss:		0.059825
  validation loss:		0.887498
  validation accuracy:		88.59 %
Epoch 1973 of 2000 took 0.101s
  training loss:		0.043912
  validation loss:		0.920521
  validation accuracy:		88.70 %
Epoch 1974 of 2000 took 0.098s
  training loss:		0.050659
  validation loss:		1.030504
  validation accuracy:		87.93 %
Epoch 1975 of 2000 took 0.096s
  training loss:		0.288529
  validation loss:		1.634532
  validation accuracy:		86.63 %
Epoch 1976 of 2000 took 0.101s
  training loss:		0.266882
  validation loss:		0.923898
  validation accuracy:		89.13 %
Epoch 1977 of 2000 took 0.097s
  training loss:		0.061105
  validation loss:		0.919500
  validation accuracy:		88.91 %
Epoch 1978 of 2000 took 0.097s
  training loss:		0.057110
  validation loss:		0.851865
  validation accuracy:		89.02 %
Epoch 1979 of 2000 took 0.097s
  training loss:		0.082257
  validation loss:		0.856634
  validation accuracy:		89.02 %
Epoch 1980 of 2000 took 0.097s
  training loss:		0.061179
  validation loss:		0.876009
  validation accuracy:		88.91 %
Epoch 1981 of 2000 took 0.100s
  training loss:		0.058139
  validation loss:		0.893269
  validation accuracy:		89.35 %
Epoch 1982 of 2000 took 0.097s
  training loss:		0.056840
  validation loss:		0.875623
  validation accuracy:		88.37 %
Epoch 1983 of 2000 took 0.097s
  training loss:		0.052062
  validation loss:		0.847972
  validation accuracy:		89.35 %
Epoch 1984 of 2000 took 0.103s
  training loss:		0.051045
  validation loss:		0.931879
  validation accuracy:		87.93 %
Epoch 1985 of 2000 took 0.096s
  training loss:		0.053385
  validation loss:		0.930171
  validation accuracy:		89.24 %
Epoch 1986 of 2000 took 0.097s
  training loss:		0.058825
  validation loss:		0.962861
  validation accuracy:		88.37 %
Epoch 1987 of 2000 took 0.096s
  training loss:		0.051668
  validation loss:		0.854988
  validation accuracy:		89.13 %
Epoch 1988 of 2000 took 0.098s
  training loss:		0.054931
  validation loss:		0.893514
  validation accuracy:		88.59 %
Epoch 1989 of 2000 took 0.101s
  training loss:		0.047286
  validation loss:		0.860644
  validation accuracy:		88.59 %
Epoch 1990 of 2000 took 0.096s
  training loss:		0.047781
  validation loss:		0.873595
  validation accuracy:		89.02 %
Epoch 1991 of 2000 took 0.097s
  training loss:		0.063169
  validation loss:		0.962878
  validation accuracy:		88.15 %
Epoch 1992 of 2000 took 0.102s
  training loss:		0.056469
  validation loss:		0.907249
  validation accuracy:		88.80 %
Epoch 1993 of 2000 took 0.096s
  training loss:		0.066398
  validation loss:		0.906003
  validation accuracy:		89.57 %
Epoch 1994 of 2000 took 0.097s
  training loss:		0.081105
  validation loss:		0.928554
  validation accuracy:		89.02 %
Epoch 1995 of 2000 took 0.096s
  training loss:		0.052751
  validation loss:		0.888306
  validation accuracy:		88.48 %
Epoch 1996 of 2000 took 0.100s
  training loss:		0.050210
  validation loss:		0.933538
  validation accuracy:		89.24 %
Epoch 1997 of 2000 took 0.098s
  training loss:		0.054210
  validation loss:		0.889677
  validation accuracy:		89.02 %
Epoch 1998 of 2000 took 0.096s
  training loss:		0.048312
  validation loss:		0.887365
  validation accuracy:		88.37 %
Epoch 1999 of 2000 took 0.100s
  training loss:		0.050101
  validation loss:		0.889464
  validation accuracy:		88.26 %
Epoch 2000 of 2000 took 0.099s
  training loss:		0.055567
  validation loss:		0.886107
  validation accuracy:		88.70 %
Final results:
  test loss:			1.916841
  test accuracy:		81.58 %
