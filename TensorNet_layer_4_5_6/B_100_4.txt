Loading data...
#train = 4423, #test = 3677, #valid = 1101
Building model and compiling functions...
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
w=(50, 50),b=(50,)
decomposing tensor W of shape (3, 50, 50)...
decomposing tensor B of shape (3, 50)...
Starting training...
Epoch 1 of 2000 took 0.101s
  training loss:		3.009927
  validation loss:		2.977003
  validation accuracy:		3.37 %
Epoch 2 of 2000 took 0.096s
  training loss:		2.905616
  validation loss:		2.874399
  validation accuracy:		2.07 %
Epoch 3 of 2000 took 0.099s
  training loss:		2.788623
  validation loss:		2.758600
  validation accuracy:		4.89 %
Epoch 4 of 2000 took 0.099s
  training loss:		2.661392
  validation loss:		2.622270
  validation accuracy:		12.83 %
Epoch 5 of 2000 took 0.099s
  training loss:		2.535223
  validation loss:		2.468064
  validation accuracy:		12.83 %
Epoch 6 of 2000 took 0.097s
  training loss:		2.413383
  validation loss:		2.330933
  validation accuracy:		13.70 %
Epoch 7 of 2000 took 0.096s
  training loss:		2.329182
  validation loss:		2.245665
  validation accuracy:		19.13 %
Epoch 8 of 2000 took 0.096s
  training loss:		2.289702
  validation loss:		2.208779
  validation accuracy:		17.07 %
Epoch 9 of 2000 took 0.096s
  training loss:		2.267508
  validation loss:		2.195946
  validation accuracy:		24.24 %
Epoch 10 of 2000 took 0.096s
  training loss:		2.253371
  validation loss:		2.190486
  validation accuracy:		23.15 %
Epoch 11 of 2000 took 0.096s
  training loss:		2.241387
  validation loss:		2.176321
  validation accuracy:		24.78 %
Epoch 12 of 2000 took 0.096s
  training loss:		2.232328
  validation loss:		2.164079
  validation accuracy:		27.61 %
Epoch 13 of 2000 took 0.096s
  training loss:		2.219563
  validation loss:		2.150457
  validation accuracy:		22.72 %
Epoch 14 of 2000 took 0.096s
  training loss:		2.209832
  validation loss:		2.141631
  validation accuracy:		27.83 %
Epoch 15 of 2000 took 0.096s
  training loss:		2.196391
  validation loss:		2.130411
  validation accuracy:		30.65 %
Epoch 16 of 2000 took 0.096s
  training loss:		2.180527
  validation loss:		2.111214
  validation accuracy:		30.54 %
Epoch 17 of 2000 took 0.097s
  training loss:		2.166953
  validation loss:		2.089623
  validation accuracy:		33.26 %
Epoch 18 of 2000 took 0.096s
  training loss:		2.150991
  validation loss:		2.079247
  validation accuracy:		32.39 %
Epoch 19 of 2000 took 0.096s
  training loss:		2.132669
  validation loss:		2.051235
  validation accuracy:		35.22 %
Epoch 20 of 2000 took 0.096s
  training loss:		2.110034
  validation loss:		2.018677
  validation accuracy:		36.09 %
Epoch 21 of 2000 took 0.096s
  training loss:		2.087312
  validation loss:		1.994078
  validation accuracy:		36.74 %
Epoch 22 of 2000 took 0.096s
  training loss:		2.058093
  validation loss:		1.972940
  validation accuracy:		36.63 %
Epoch 23 of 2000 took 0.096s
  training loss:		2.030255
  validation loss:		1.935892
  validation accuracy:		37.61 %
Epoch 24 of 2000 took 0.097s
  training loss:		1.998751
  validation loss:		1.894994
  validation accuracy:		39.67 %
Epoch 25 of 2000 took 0.097s
  training loss:		1.961751
  validation loss:		1.857336
  validation accuracy:		41.63 %
Epoch 26 of 2000 took 0.097s
  training loss:		1.923689
  validation loss:		1.811778
  validation accuracy:		41.63 %
Epoch 27 of 2000 took 0.097s
  training loss:		1.884033
  validation loss:		1.772224
  validation accuracy:		45.00 %
Epoch 28 of 2000 took 0.097s
  training loss:		1.842231
  validation loss:		1.730763
  validation accuracy:		44.24 %
Epoch 29 of 2000 took 0.097s
  training loss:		1.796435
  validation loss:		1.678219
  validation accuracy:		45.76 %
Epoch 30 of 2000 took 0.097s
  training loss:		1.747466
  validation loss:		1.633973
  validation accuracy:		47.17 %
Epoch 31 of 2000 took 0.097s
  training loss:		1.701302
  validation loss:		1.593400
  validation accuracy:		45.98 %
Epoch 32 of 2000 took 0.097s
  training loss:		1.659586
  validation loss:		1.553038
  validation accuracy:		48.04 %
Epoch 33 of 2000 took 0.097s
  training loss:		1.616629
  validation loss:		1.512311
  validation accuracy:		48.91 %
Epoch 34 of 2000 took 0.097s
  training loss:		1.571756
  validation loss:		1.465727
  validation accuracy:		49.57 %
Epoch 35 of 2000 took 0.097s
  training loss:		1.527342
  validation loss:		1.440724
  validation accuracy:		49.46 %
Epoch 36 of 2000 took 0.097s
  training loss:		1.495404
  validation loss:		1.400792
  validation accuracy:		49.24 %
Epoch 37 of 2000 took 0.101s
  training loss:		1.458236
  validation loss:		1.358391
  validation accuracy:		51.96 %
Epoch 38 of 2000 took 0.097s
  training loss:		1.419244
  validation loss:		1.335685
  validation accuracy:		52.07 %
Epoch 39 of 2000 took 0.097s
  training loss:		1.382310
  validation loss:		1.300475
  validation accuracy:		52.83 %
Epoch 40 of 2000 took 0.097s
  training loss:		1.357905
  validation loss:		1.290090
  validation accuracy:		54.02 %
Epoch 41 of 2000 took 0.097s
  training loss:		1.333734
  validation loss:		1.254535
  validation accuracy:		56.09 %
Epoch 42 of 2000 took 0.097s
  training loss:		1.288014
  validation loss:		1.227045
  validation accuracy:		55.54 %
Epoch 43 of 2000 took 0.097s
  training loss:		1.271300
  validation loss:		1.187302
  validation accuracy:		58.04 %
Epoch 44 of 2000 took 0.097s
  training loss:		1.233913
  validation loss:		1.172250
  validation accuracy:		60.65 %
Epoch 45 of 2000 took 0.097s
  training loss:		1.216482
  validation loss:		1.150243
  validation accuracy:		59.46 %
Epoch 46 of 2000 took 0.097s
  training loss:		1.185703
  validation loss:		1.120435
  validation accuracy:		60.43 %
Epoch 47 of 2000 took 0.097s
  training loss:		1.146747
  validation loss:		1.091979
  validation accuracy:		62.72 %
Epoch 48 of 2000 took 0.098s
  training loss:		1.130055
  validation loss:		1.120101
  validation accuracy:		59.67 %
Epoch 49 of 2000 took 0.097s
  training loss:		1.124706
  validation loss:		1.042322
  validation accuracy:		64.78 %
Epoch 50 of 2000 took 0.097s
  training loss:		1.084734
  validation loss:		1.053085
  validation accuracy:		63.59 %
Epoch 51 of 2000 took 0.097s
  training loss:		1.055365
  validation loss:		1.006706
  validation accuracy:		67.17 %
Epoch 52 of 2000 took 0.097s
  training loss:		1.022609
  validation loss:		0.993559
  validation accuracy:		66.85 %
Epoch 53 of 2000 took 0.097s
  training loss:		1.005723
  validation loss:		1.008187
  validation accuracy:		64.24 %
Epoch 54 of 2000 took 0.097s
  training loss:		0.996318
  validation loss:		0.940132
  validation accuracy:		69.57 %
Epoch 55 of 2000 took 0.097s
  training loss:		0.979519
  validation loss:		1.044884
  validation accuracy:		64.24 %
Epoch 56 of 2000 took 0.097s
  training loss:		1.078838
  validation loss:		1.135756
  validation accuracy:		59.13 %
Epoch 57 of 2000 took 0.097s
  training loss:		0.970385
  validation loss:		0.905438
  validation accuracy:		69.57 %
Epoch 58 of 2000 took 0.097s
  training loss:		0.928883
  validation loss:		0.887706
  validation accuracy:		72.17 %
Epoch 59 of 2000 took 0.097s
  training loss:		0.887553
  validation loss:		0.859911
  validation accuracy:		72.28 %
Epoch 60 of 2000 took 0.097s
  training loss:		0.911337
  validation loss:		1.022822
  validation accuracy:		64.24 %
Epoch 61 of 2000 took 0.097s
  training loss:		0.929116
  validation loss:		0.881983
  validation accuracy:		70.76 %
Epoch 62 of 2000 took 0.098s
  training loss:		0.883923
  validation loss:		0.843949
  validation accuracy:		72.39 %
Epoch 63 of 2000 took 0.097s
  training loss:		1.016982
  validation loss:		1.149708
  validation accuracy:		57.93 %
Epoch 64 of 2000 took 0.097s
  training loss:		0.956789
  validation loss:		0.872057
  validation accuracy:		70.54 %
Epoch 65 of 2000 took 0.097s
  training loss:		0.837204
  validation loss:		0.790668
  validation accuracy:		75.54 %
Epoch 66 of 2000 took 0.097s
  training loss:		0.820384
  validation loss:		0.772040
  validation accuracy:		76.63 %
Epoch 67 of 2000 took 0.097s
  training loss:		0.795124
  validation loss:		0.758939
  validation accuracy:		77.28 %
Epoch 68 of 2000 took 0.097s
  training loss:		0.789470
  validation loss:		0.757550
  validation accuracy:		77.07 %
Epoch 69 of 2000 took 0.097s
  training loss:		0.774262
  validation loss:		0.749195
  validation accuracy:		76.74 %
Epoch 70 of 2000 took 0.097s
  training loss:		0.761406
  validation loss:		0.743694
  validation accuracy:		77.61 %
Epoch 71 of 2000 took 0.097s
  training loss:		0.760276
  validation loss:		0.734083
  validation accuracy:		77.83 %
Epoch 72 of 2000 took 0.097s
  training loss:		0.759823
  validation loss:		0.753293
  validation accuracy:		75.65 %
Epoch 73 of 2000 took 0.097s
  training loss:		0.737853
  validation loss:		0.720514
  validation accuracy:		77.39 %
Epoch 74 of 2000 took 0.097s
  training loss:		0.743865
  validation loss:		0.726343
  validation accuracy:		77.39 %
Epoch 75 of 2000 took 0.097s
  training loss:		0.731293
  validation loss:		0.750393
  validation accuracy:		76.20 %
Epoch 76 of 2000 took 0.097s
  training loss:		0.712269
  validation loss:		0.698699
  validation accuracy:		79.13 %
Epoch 77 of 2000 took 0.097s
  training loss:		0.818775
  validation loss:		0.836584
  validation accuracy:		71.30 %
Epoch 78 of 2000 took 0.097s
  training loss:		0.732489
  validation loss:		0.723650
  validation accuracy:		77.61 %
Epoch 79 of 2000 took 0.098s
  training loss:		0.695395
  validation loss:		0.688538
  validation accuracy:		79.13 %
Epoch 80 of 2000 took 0.097s
  training loss:		0.678498
  validation loss:		0.693586
  validation accuracy:		78.80 %
Epoch 81 of 2000 took 0.097s
  training loss:		0.946458
  validation loss:		0.818962
  validation accuracy:		72.83 %
Epoch 82 of 2000 took 0.097s
  training loss:		0.717097
  validation loss:		0.694870
  validation accuracy:		78.59 %
Epoch 83 of 2000 took 0.097s
  training loss:		0.664287
  validation loss:		0.650435
  validation accuracy:		80.98 %
Epoch 84 of 2000 took 0.097s
  training loss:		0.648806
  validation loss:		0.641525
  validation accuracy:		81.09 %
Epoch 85 of 2000 took 0.097s
  training loss:		0.658723
  validation loss:		0.644743
  validation accuracy:		81.20 %
Epoch 86 of 2000 took 0.097s
  training loss:		0.649132
  validation loss:		0.636010
  validation accuracy:		80.87 %
Epoch 87 of 2000 took 0.097s
  training loss:		0.637010
  validation loss:		0.643157
  validation accuracy:		80.54 %
Epoch 88 of 2000 took 0.097s
  training loss:		0.644335
  validation loss:		0.615250
  validation accuracy:		81.74 %
Epoch 89 of 2000 took 0.097s
  training loss:		0.620698
  validation loss:		0.614341
  validation accuracy:		81.85 %
Epoch 90 of 2000 took 0.097s
  training loss:		0.625154
  validation loss:		0.635121
  validation accuracy:		80.43 %
Epoch 91 of 2000 took 0.097s
  training loss:		0.615198
  validation loss:		0.609162
  validation accuracy:		82.39 %
Epoch 92 of 2000 took 0.097s
  training loss:		0.598792
  validation loss:		0.597751
  validation accuracy:		82.50 %
Epoch 93 of 2000 took 0.097s
  training loss:		0.594691
  validation loss:		0.593945
  validation accuracy:		82.39 %
Epoch 94 of 2000 took 0.097s
  training loss:		0.590875
  validation loss:		0.601157
  validation accuracy:		81.96 %
Epoch 95 of 2000 took 0.097s
  training loss:		0.590116
  validation loss:		0.589703
  validation accuracy:		82.83 %
Epoch 96 of 2000 took 0.097s
  training loss:		0.574821
  validation loss:		0.590377
  validation accuracy:		81.52 %
Epoch 97 of 2000 took 0.097s
  training loss:		0.584193
  validation loss:		0.593459
  validation accuracy:		82.39 %
Epoch 98 of 2000 took 0.097s
  training loss:		0.589652
  validation loss:		0.616960
  validation accuracy:		80.43 %
Epoch 99 of 2000 took 0.101s
  training loss:		0.592688
  validation loss:		0.601139
  validation accuracy:		82.28 %
Epoch 100 of 2000 took 0.097s
  training loss:		0.563559
  validation loss:		0.588584
  validation accuracy:		83.37 %
Epoch 101 of 2000 took 0.097s
  training loss:		0.543905
  validation loss:		0.556036
  validation accuracy:		83.26 %
Epoch 102 of 2000 took 0.097s
  training loss:		0.545518
  validation loss:		0.554972
  validation accuracy:		84.02 %
Epoch 103 of 2000 took 0.097s
  training loss:		0.533087
  validation loss:		0.568398
  validation accuracy:		83.70 %
Epoch 104 of 2000 took 0.097s
  training loss:		0.525853
  validation loss:		0.544463
  validation accuracy:		83.48 %
Epoch 105 of 2000 took 0.097s
  training loss:		0.520314
  validation loss:		0.541953
  validation accuracy:		84.24 %
Epoch 106 of 2000 took 0.097s
  training loss:		0.513459
  validation loss:		0.531237
  validation accuracy:		84.02 %
Epoch 107 of 2000 took 0.097s
  training loss:		0.506448
  validation loss:		0.522592
  validation accuracy:		84.24 %
Epoch 108 of 2000 took 0.097s
  training loss:		0.504642
  validation loss:		0.519932
  validation accuracy:		84.78 %
Epoch 109 of 2000 took 0.097s
  training loss:		0.501544
  validation loss:		0.521453
  validation accuracy:		85.11 %
Epoch 110 of 2000 took 0.098s
  training loss:		0.493133
  validation loss:		0.516074
  validation accuracy:		85.33 %
Epoch 111 of 2000 took 0.097s
  training loss:		0.490331
  validation loss:		0.501516
  validation accuracy:		84.89 %
Epoch 112 of 2000 took 0.097s
  training loss:		0.485247
  validation loss:		0.516653
  validation accuracy:		85.00 %
Epoch 113 of 2000 took 0.097s
  training loss:		0.478779
  validation loss:		0.517310
  validation accuracy:		85.33 %
Epoch 114 of 2000 took 0.097s
  training loss:		0.485560
  validation loss:		0.519018
  validation accuracy:		85.43 %
Epoch 115 of 2000 took 0.097s
  training loss:		0.473063
  validation loss:		0.510671
  validation accuracy:		84.13 %
Epoch 116 of 2000 took 0.097s
  training loss:		0.465621
  validation loss:		0.487968
  validation accuracy:		85.11 %
Epoch 117 of 2000 took 0.097s
  training loss:		0.453707
  validation loss:		0.487556
  validation accuracy:		85.33 %
Epoch 118 of 2000 took 0.097s
  training loss:		0.464391
  validation loss:		0.495763
  validation accuracy:		85.65 %
Epoch 119 of 2000 took 0.097s
  training loss:		0.464217
  validation loss:		0.520735
  validation accuracy:		85.33 %
Epoch 120 of 2000 took 0.097s
  training loss:		0.457888
  validation loss:		0.488549
  validation accuracy:		85.43 %
Epoch 121 of 2000 took 0.097s
  training loss:		0.449205
  validation loss:		0.489993
  validation accuracy:		85.43 %
Epoch 122 of 2000 took 0.097s
  training loss:		0.453981
  validation loss:		0.477734
  validation accuracy:		85.54 %
Epoch 123 of 2000 took 0.097s
  training loss:		0.441542
  validation loss:		0.481493
  validation accuracy:		85.65 %
Epoch 124 of 2000 took 0.097s
  training loss:		0.430388
  validation loss:		0.476044
  validation accuracy:		85.65 %
Epoch 125 of 2000 took 0.097s
  training loss:		0.441902
  validation loss:		0.469372
  validation accuracy:		85.98 %
Epoch 126 of 2000 took 0.098s
  training loss:		0.433742
  validation loss:		0.459657
  validation accuracy:		85.98 %
Epoch 127 of 2000 took 0.097s
  training loss:		0.430658
  validation loss:		0.477353
  validation accuracy:		85.11 %
Epoch 128 of 2000 took 0.097s
  training loss:		0.430246
  validation loss:		0.472134
  validation accuracy:		85.11 %
Epoch 129 of 2000 took 0.097s
  training loss:		0.421385
  validation loss:		0.464986
  validation accuracy:		85.87 %
Epoch 130 of 2000 took 0.097s
  training loss:		0.419257
  validation loss:		0.467600
  validation accuracy:		85.98 %
Epoch 131 of 2000 took 0.097s
  training loss:		0.432635
  validation loss:		0.466028
  validation accuracy:		85.65 %
Epoch 132 of 2000 took 0.097s
  training loss:		0.427468
  validation loss:		0.450743
  validation accuracy:		86.20 %
Epoch 133 of 2000 took 0.097s
  training loss:		0.434235
  validation loss:		0.472873
  validation accuracy:		84.89 %
Epoch 134 of 2000 took 0.097s
  training loss:		0.419594
  validation loss:		0.447553
  validation accuracy:		86.09 %
Epoch 135 of 2000 took 0.097s
  training loss:		0.407901
  validation loss:		0.449745
  validation accuracy:		86.41 %
Epoch 136 of 2000 took 0.097s
  training loss:		0.410683
  validation loss:		0.445347
  validation accuracy:		86.20 %
Epoch 137 of 2000 took 0.097s
  training loss:		0.405372
  validation loss:		0.444314
  validation accuracy:		86.20 %
Epoch 138 of 2000 took 0.097s
  training loss:		0.405103
  validation loss:		0.466253
  validation accuracy:		86.52 %
Epoch 139 of 2000 took 0.097s
  training loss:		0.399537
  validation loss:		0.437808
  validation accuracy:		86.52 %
Epoch 140 of 2000 took 0.097s
  training loss:		0.396860
  validation loss:		0.432140
  validation accuracy:		86.74 %
Epoch 141 of 2000 took 0.098s
  training loss:		0.394910
  validation loss:		0.444011
  validation accuracy:		86.74 %
Epoch 142 of 2000 took 0.097s
  training loss:		0.412734
  validation loss:		0.452830
  validation accuracy:		85.43 %
Epoch 143 of 2000 took 0.097s
  training loss:		0.398266
  validation loss:		0.431037
  validation accuracy:		86.30 %
Epoch 144 of 2000 took 0.097s
  training loss:		0.390117
  validation loss:		0.449238
  validation accuracy:		86.52 %
Epoch 145 of 2000 took 0.097s
  training loss:		0.397972
  validation loss:		0.456790
  validation accuracy:		86.63 %
Epoch 146 of 2000 took 0.097s
  training loss:		0.395440
  validation loss:		0.428626
  validation accuracy:		86.96 %
Epoch 147 of 2000 took 0.097s
  training loss:		0.383821
  validation loss:		0.427752
  validation accuracy:		87.07 %
Epoch 148 of 2000 took 0.097s
  training loss:		0.391923
  validation loss:		0.434737
  validation accuracy:		86.20 %
Epoch 149 of 2000 took 0.097s
  training loss:		0.384920
  validation loss:		0.422839
  validation accuracy:		86.63 %
Epoch 150 of 2000 took 0.097s
  training loss:		0.387860
  validation loss:		0.425920
  validation accuracy:		86.96 %
Epoch 151 of 2000 took 0.097s
  training loss:		0.377843
  validation loss:		0.426229
  validation accuracy:		87.07 %
Epoch 152 of 2000 took 0.097s
  training loss:		0.382468
  validation loss:		0.443335
  validation accuracy:		86.85 %
Epoch 153 of 2000 took 0.097s
  training loss:		0.378801
  validation loss:		0.418087
  validation accuracy:		86.85 %
Epoch 154 of 2000 took 0.097s
  training loss:		0.377489
  validation loss:		0.424343
  validation accuracy:		87.17 %
Epoch 155 of 2000 took 0.097s
  training loss:		0.372192
  validation loss:		0.473171
  validation accuracy:		85.87 %
Epoch 156 of 2000 took 0.097s
  training loss:		0.384491
  validation loss:		0.415743
  validation accuracy:		87.61 %
Epoch 157 of 2000 took 0.097s
  training loss:		0.376380
  validation loss:		0.421794
  validation accuracy:		87.39 %
Epoch 158 of 2000 took 0.097s
  training loss:		0.373874
  validation loss:		0.431754
  validation accuracy:		86.96 %
Epoch 159 of 2000 took 0.097s
  training loss:		0.378374
  validation loss:		0.427367
  validation accuracy:		87.50 %
Epoch 160 of 2000 took 0.097s
  training loss:		0.369700
  validation loss:		0.432720
  validation accuracy:		87.17 %
Epoch 161 of 2000 took 0.097s
  training loss:		0.381759
  validation loss:		0.413734
  validation accuracy:		87.39 %
Epoch 162 of 2000 took 0.097s
  training loss:		0.367029
  validation loss:		0.405921
  validation accuracy:		87.50 %
Epoch 163 of 2000 took 0.097s
  training loss:		0.368797
  validation loss:		0.416451
  validation accuracy:		87.61 %
Epoch 164 of 2000 took 0.097s
  training loss:		0.369856
  validation loss:		0.413771
  validation accuracy:		87.50 %
Epoch 165 of 2000 took 0.097s
  training loss:		0.361223
  validation loss:		0.439191
  validation accuracy:		86.85 %
Epoch 166 of 2000 took 0.097s
  training loss:		0.361125
  validation loss:		0.419503
  validation accuracy:		87.72 %
Epoch 167 of 2000 took 0.097s
  training loss:		0.367270
  validation loss:		0.409553
  validation accuracy:		88.04 %
Epoch 168 of 2000 took 0.097s
  training loss:		0.358540
  validation loss:		0.404513
  validation accuracy:		87.72 %
Epoch 169 of 2000 took 0.097s
  training loss:		0.361961
  validation loss:		0.450083
  validation accuracy:		86.30 %
Epoch 170 of 2000 took 0.097s
  training loss:		0.366846
  validation loss:		0.413106
  validation accuracy:		87.17 %
Epoch 171 of 2000 took 0.097s
  training loss:		0.349926
  validation loss:		0.422422
  validation accuracy:		87.17 %
Epoch 172 of 2000 took 0.098s
  training loss:		0.355754
  validation loss:		0.414348
  validation accuracy:		87.72 %
Epoch 173 of 2000 took 0.097s
  training loss:		0.363014
  validation loss:		0.438526
  validation accuracy:		87.17 %
Epoch 174 of 2000 took 0.097s
  training loss:		0.362726
  validation loss:		0.421724
  validation accuracy:		87.83 %
Epoch 175 of 2000 took 0.097s
  training loss:		0.349077
  validation loss:		0.417574
  validation accuracy:		87.17 %
Epoch 176 of 2000 took 0.097s
  training loss:		0.350649
  validation loss:		0.405551
  validation accuracy:		88.26 %
Epoch 177 of 2000 took 0.097s
  training loss:		0.353487
  validation loss:		0.406951
  validation accuracy:		87.50 %
Epoch 178 of 2000 took 0.097s
  training loss:		0.350398
  validation loss:		0.459543
  validation accuracy:		85.98 %
Epoch 179 of 2000 took 0.101s
  training loss:		0.353683
  validation loss:		0.414209
  validation accuracy:		88.15 %
Epoch 180 of 2000 took 0.097s
  training loss:		0.344196
  validation loss:		0.415357
  validation accuracy:		87.61 %
Epoch 181 of 2000 took 0.097s
  training loss:		0.339267
  validation loss:		0.406528
  validation accuracy:		87.93 %
Epoch 182 of 2000 took 0.097s
  training loss:		0.340457
  validation loss:		0.413483
  validation accuracy:		87.93 %
Epoch 183 of 2000 took 0.097s
  training loss:		0.341234
  validation loss:		0.393295
  validation accuracy:		87.93 %
Epoch 184 of 2000 took 0.097s
  training loss:		0.355617
  validation loss:		0.414186
  validation accuracy:		87.61 %
Epoch 185 of 2000 took 0.097s
  training loss:		0.341665
  validation loss:		0.394492
  validation accuracy:		87.83 %
Epoch 186 of 2000 took 0.097s
  training loss:		0.344902
  validation loss:		0.398794
  validation accuracy:		87.93 %
Epoch 187 of 2000 took 0.097s
  training loss:		0.346218
  validation loss:		0.407089
  validation accuracy:		87.83 %
Epoch 188 of 2000 took 0.097s
  training loss:		0.344581
  validation loss:		0.394197
  validation accuracy:		87.39 %
Epoch 189 of 2000 took 0.100s
  training loss:		0.335080
  validation loss:		0.397925
  validation accuracy:		88.37 %
Epoch 190 of 2000 took 0.100s
  training loss:		0.338835
  validation loss:		0.397882
  validation accuracy:		88.26 %
Epoch 191 of 2000 took 0.100s
  training loss:		0.341239
  validation loss:		0.437617
  validation accuracy:		87.61 %
Epoch 192 of 2000 took 0.100s
  training loss:		0.342364
  validation loss:		0.395230
  validation accuracy:		88.37 %
Epoch 193 of 2000 took 0.100s
  training loss:		0.342502
  validation loss:		0.427351
  validation accuracy:		87.28 %
Epoch 194 of 2000 took 0.100s
  training loss:		0.345114
  validation loss:		0.387461
  validation accuracy:		88.04 %
Epoch 195 of 2000 took 0.100s
  training loss:		0.329340
  validation loss:		0.392113
  validation accuracy:		87.93 %
Epoch 196 of 2000 took 0.100s
  training loss:		0.334670
  validation loss:		0.394132
  validation accuracy:		88.04 %
Epoch 197 of 2000 took 0.100s
  training loss:		0.332725
  validation loss:		0.396650
  validation accuracy:		88.15 %
Epoch 198 of 2000 took 0.100s
  training loss:		0.337860
  validation loss:		0.443734
  validation accuracy:		86.41 %
Epoch 199 of 2000 took 0.100s
  training loss:		0.335229
  validation loss:		0.396670
  validation accuracy:		88.15 %
Epoch 200 of 2000 took 0.100s
  training loss:		0.329907
  validation loss:		0.386546
  validation accuracy:		88.37 %
Epoch 201 of 2000 took 0.100s
  training loss:		0.333721
  validation loss:		0.402622
  validation accuracy:		87.72 %
Epoch 202 of 2000 took 0.101s
  training loss:		0.334168
  validation loss:		0.398548
  validation accuracy:		87.83 %
Epoch 203 of 2000 took 0.100s
  training loss:		0.336576
  validation loss:		0.403250
  validation accuracy:		88.15 %
Epoch 204 of 2000 took 0.100s
  training loss:		0.329792
  validation loss:		0.422485
  validation accuracy:		87.28 %
Epoch 205 of 2000 took 0.100s
  training loss:		0.343643
  validation loss:		0.416216
  validation accuracy:		86.96 %
Epoch 206 of 2000 took 0.100s
  training loss:		0.329596
  validation loss:		0.398762
  validation accuracy:		88.59 %
Epoch 207 of 2000 took 0.100s
  training loss:		0.325088
  validation loss:		0.398202
  validation accuracy:		87.72 %
Epoch 208 of 2000 took 0.100s
  training loss:		0.326076
  validation loss:		0.413416
  validation accuracy:		87.61 %
Epoch 209 of 2000 took 0.100s
  training loss:		0.327694
  validation loss:		0.385634
  validation accuracy:		88.15 %
Epoch 210 of 2000 took 0.100s
  training loss:		0.326451
  validation loss:		0.388051
  validation accuracy:		88.26 %
Epoch 211 of 2000 took 0.100s
  training loss:		0.319556
  validation loss:		0.387306
  validation accuracy:		88.48 %
Epoch 212 of 2000 took 0.100s
  training loss:		0.324992
  validation loss:		0.388479
  validation accuracy:		88.26 %
Epoch 213 of 2000 took 0.100s
  training loss:		0.331779
  validation loss:		0.390040
  validation accuracy:		88.48 %
Epoch 214 of 2000 took 0.100s
  training loss:		0.318633
  validation loss:		0.391447
  validation accuracy:		88.15 %
Epoch 215 of 2000 took 0.100s
  training loss:		0.325037
  validation loss:		0.404119
  validation accuracy:		87.72 %
Epoch 216 of 2000 took 0.100s
  training loss:		0.329795
  validation loss:		0.397279
  validation accuracy:		87.72 %
Epoch 217 of 2000 took 0.100s
  training loss:		0.319000
  validation loss:		0.402673
  validation accuracy:		87.83 %
Epoch 218 of 2000 took 0.100s
  training loss:		0.324944
  validation loss:		0.386300
  validation accuracy:		88.15 %
Epoch 219 of 2000 took 0.100s
  training loss:		0.327160
  validation loss:		0.398318
  validation accuracy:		88.15 %
Epoch 220 of 2000 took 0.100s
  training loss:		0.325112
  validation loss:		0.385014
  validation accuracy:		88.26 %
Epoch 221 of 2000 took 0.100s
  training loss:		0.320340
  validation loss:		0.385541
  validation accuracy:		88.37 %
Epoch 222 of 2000 took 0.100s
  training loss:		0.322026
  validation loss:		0.395229
  validation accuracy:		88.04 %
Epoch 223 of 2000 took 0.100s
  training loss:		0.318572
  validation loss:		0.390633
  validation accuracy:		88.04 %
Epoch 224 of 2000 took 0.100s
  training loss:		0.314709
  validation loss:		0.392894
  validation accuracy:		88.70 %
Epoch 225 of 2000 took 0.100s
  training loss:		0.311816
  validation loss:		0.379850
  validation accuracy:		88.59 %
Epoch 226 of 2000 took 0.100s
  training loss:		0.317478
  validation loss:		0.410074
  validation accuracy:		87.39 %
Epoch 227 of 2000 took 0.100s
  training loss:		0.322258
  validation loss:		0.409213
  validation accuracy:		87.61 %
Epoch 228 of 2000 took 0.100s
  training loss:		0.319138
  validation loss:		0.396992
  validation accuracy:		87.50 %
Epoch 229 of 2000 took 0.097s
  training loss:		0.317173
  validation loss:		0.379991
  validation accuracy:		88.15 %
Epoch 230 of 2000 took 0.097s
  training loss:		0.319195
  validation loss:		0.405698
  validation accuracy:		88.15 %
Epoch 231 of 2000 took 0.097s
  training loss:		0.322253
  validation loss:		0.383914
  validation accuracy:		88.04 %
Epoch 232 of 2000 took 0.098s
  training loss:		0.322286
  validation loss:		0.392370
  validation accuracy:		88.70 %
Epoch 233 of 2000 took 0.098s
  training loss:		0.314783
  validation loss:		0.398407
  validation accuracy:		87.83 %
Epoch 234 of 2000 took 0.097s
  training loss:		0.307504
  validation loss:		0.390288
  validation accuracy:		88.04 %
Epoch 235 of 2000 took 0.097s
  training loss:		0.316239
  validation loss:		0.389505
  validation accuracy:		88.04 %
Epoch 236 of 2000 took 0.097s
  training loss:		0.310553
  validation loss:		0.394976
  validation accuracy:		88.04 %
Epoch 237 of 2000 took 0.097s
  training loss:		0.320571
  validation loss:		0.378366
  validation accuracy:		88.37 %
Epoch 238 of 2000 took 0.097s
  training loss:		0.310802
  validation loss:		0.385977
  validation accuracy:		88.37 %
Epoch 239 of 2000 took 0.097s
  training loss:		0.311148
  validation loss:		0.382157
  validation accuracy:		87.93 %
Epoch 240 of 2000 took 0.097s
  training loss:		0.311171
  validation loss:		0.405000
  validation accuracy:		87.61 %
Epoch 241 of 2000 took 0.097s
  training loss:		0.304656
  validation loss:		0.377617
  validation accuracy:		87.83 %
Epoch 242 of 2000 took 0.097s
  training loss:		0.314547
  validation loss:		0.381773
  validation accuracy:		88.48 %
Epoch 243 of 2000 took 0.097s
  training loss:		0.309907
  validation loss:		0.394726
  validation accuracy:		88.04 %
Epoch 244 of 2000 took 0.097s
  training loss:		0.314723
  validation loss:		0.397082
  validation accuracy:		87.61 %
Epoch 245 of 2000 took 0.097s
  training loss:		0.315770
  validation loss:		0.385651
  validation accuracy:		88.37 %
Epoch 246 of 2000 took 0.097s
  training loss:		0.306243
  validation loss:		0.400787
  validation accuracy:		88.15 %
Epoch 247 of 2000 took 0.097s
  training loss:		0.310683
  validation loss:		0.409470
  validation accuracy:		87.83 %
Epoch 248 of 2000 took 0.097s
  training loss:		0.312053
  validation loss:		0.401184
  validation accuracy:		87.83 %
Epoch 249 of 2000 took 0.097s
  training loss:		0.304950
  validation loss:		0.376352
  validation accuracy:		88.80 %
Epoch 250 of 2000 took 0.101s
  training loss:		0.305843
  validation loss:		0.380516
  validation accuracy:		89.02 %
Epoch 251 of 2000 took 0.098s
  training loss:		0.305355
  validation loss:		0.383724
  validation accuracy:		88.59 %
Epoch 252 of 2000 took 0.097s
  training loss:		0.303599
  validation loss:		0.378470
  validation accuracy:		88.26 %
Epoch 253 of 2000 took 0.097s
  training loss:		0.304459
  validation loss:		0.408311
  validation accuracy:		87.93 %
Epoch 254 of 2000 took 0.097s
  training loss:		0.310478
  validation loss:		0.393953
  validation accuracy:		88.26 %
Epoch 255 of 2000 took 0.097s
  training loss:		0.314833
  validation loss:		0.374761
  validation accuracy:		88.37 %
Epoch 256 of 2000 took 0.097s
  training loss:		0.303320
  validation loss:		0.398358
  validation accuracy:		87.93 %
Epoch 257 of 2000 took 0.097s
  training loss:		0.311189
  validation loss:		0.382562
  validation accuracy:		88.37 %
Epoch 258 of 2000 took 0.097s
  training loss:		0.295951
  validation loss:		0.376766
  validation accuracy:		88.80 %
Epoch 259 of 2000 took 0.097s
  training loss:		0.295461
  validation loss:		0.401010
  validation accuracy:		88.26 %
Epoch 260 of 2000 took 0.097s
  training loss:		0.301800
  validation loss:		0.378583
  validation accuracy:		88.91 %
Epoch 261 of 2000 took 0.097s
  training loss:		0.303635
  validation loss:		0.381899
  validation accuracy:		88.48 %
Epoch 262 of 2000 took 0.097s
  training loss:		0.294628
  validation loss:		0.390867
  validation accuracy:		88.04 %
Epoch 263 of 2000 took 0.097s
  training loss:		0.296586
  validation loss:		0.375045
  validation accuracy:		88.26 %
Epoch 264 of 2000 took 0.098s
  training loss:		0.293013
  validation loss:		0.374908
  validation accuracy:		89.13 %
Epoch 265 of 2000 took 0.097s
  training loss:		0.304833
  validation loss:		0.388705
  validation accuracy:		88.48 %
Epoch 266 of 2000 took 0.097s
  training loss:		0.296296
  validation loss:		0.375470
  validation accuracy:		88.91 %
Epoch 267 of 2000 took 0.097s
  training loss:		0.295835
  validation loss:		0.368748
  validation accuracy:		89.02 %
Epoch 268 of 2000 took 0.097s
  training loss:		0.295370
  validation loss:		0.375365
  validation accuracy:		88.80 %
Epoch 269 of 2000 took 0.097s
  training loss:		0.296548
  validation loss:		0.378331
  validation accuracy:		88.70 %
Epoch 270 of 2000 took 0.097s
  training loss:		0.299199
  validation loss:		0.365788
  validation accuracy:		88.80 %
Epoch 271 of 2000 took 0.097s
  training loss:		0.294100
  validation loss:		0.380206
  validation accuracy:		88.37 %
Epoch 272 of 2000 took 0.097s
  training loss:		0.296208
  validation loss:		0.372266
  validation accuracy:		89.13 %
Epoch 273 of 2000 took 0.097s
  training loss:		0.299843
  validation loss:		0.367900
  validation accuracy:		89.02 %
Epoch 274 of 2000 took 0.097s
  training loss:		0.291054
  validation loss:		0.365912
  validation accuracy:		88.91 %
Epoch 275 of 2000 took 0.097s
  training loss:		0.301548
  validation loss:		0.376677
  validation accuracy:		88.91 %
Epoch 276 of 2000 took 0.097s
  training loss:		0.292498
  validation loss:		0.361649
  validation accuracy:		89.46 %
Epoch 277 of 2000 took 0.097s
  training loss:		0.296164
  validation loss:		0.368510
  validation accuracy:		88.70 %
Epoch 278 of 2000 took 0.097s
  training loss:		0.293739
  validation loss:		0.374139
  validation accuracy:		88.80 %
Epoch 279 of 2000 took 0.097s
  training loss:		0.299422
  validation loss:		0.378240
  validation accuracy:		88.48 %
Epoch 280 of 2000 took 0.097s
  training loss:		0.291322
  validation loss:		0.374472
  validation accuracy:		88.59 %
Epoch 281 of 2000 took 0.097s
  training loss:		0.296030
  validation loss:		0.365561
  validation accuracy:		88.80 %
Epoch 282 of 2000 took 0.097s
  training loss:		0.291589
  validation loss:		0.366335
  validation accuracy:		89.13 %
Epoch 283 of 2000 took 0.097s
  training loss:		0.283042
  validation loss:		0.365293
  validation accuracy:		89.46 %
Epoch 284 of 2000 took 0.097s
  training loss:		0.285451
  validation loss:		0.382730
  validation accuracy:		88.70 %
Epoch 285 of 2000 took 0.097s
  training loss:		0.299016
  validation loss:		0.362850
  validation accuracy:		89.02 %
Epoch 286 of 2000 took 0.097s
  training loss:		0.290414
  validation loss:		0.365840
  validation accuracy:		89.13 %
Epoch 287 of 2000 took 0.097s
  training loss:		0.285074
  validation loss:		0.360822
  validation accuracy:		89.02 %
Epoch 288 of 2000 took 0.097s
  training loss:		0.284514
  validation loss:		0.367143
  validation accuracy:		88.91 %
Epoch 289 of 2000 took 0.097s
  training loss:		0.290385
  validation loss:		0.373395
  validation accuracy:		89.02 %
Epoch 290 of 2000 took 0.097s
  training loss:		0.286647
  validation loss:		0.382746
  validation accuracy:		88.70 %
Epoch 291 of 2000 took 0.097s
  training loss:		0.283530
  validation loss:		0.369423
  validation accuracy:		89.13 %
Epoch 292 of 2000 took 0.097s
  training loss:		0.282827
  validation loss:		0.358208
  validation accuracy:		89.67 %
Epoch 293 of 2000 took 0.097s
  training loss:		0.282707
  validation loss:		0.372074
  validation accuracy:		89.13 %
Epoch 294 of 2000 took 0.097s
  training loss:		0.282877
  validation loss:		0.375780
  validation accuracy:		89.24 %
Epoch 295 of 2000 took 0.098s
  training loss:		0.281551
  validation loss:		0.393078
  validation accuracy:		88.70 %
Epoch 296 of 2000 took 0.097s
  training loss:		0.286841
  validation loss:		0.385656
  validation accuracy:		88.80 %
Epoch 297 of 2000 took 0.097s
  training loss:		0.284246
  validation loss:		0.357909
  validation accuracy:		89.57 %
Epoch 298 of 2000 took 0.097s
  training loss:		0.286366
  validation loss:		0.374162
  validation accuracy:		88.70 %
Epoch 299 of 2000 took 0.097s
  training loss:		0.284953
  validation loss:		0.357138
  validation accuracy:		89.57 %
Epoch 300 of 2000 took 0.097s
  training loss:		0.284923
  validation loss:		0.363015
  validation accuracy:		89.46 %
Epoch 301 of 2000 took 0.097s
  training loss:		0.279034
  validation loss:		0.358702
  validation accuracy:		89.67 %
Epoch 302 of 2000 took 0.097s
  training loss:		0.285286
  validation loss:		0.373236
  validation accuracy:		88.91 %
Epoch 303 of 2000 took 0.097s
  training loss:		0.283712
  validation loss:		0.361713
  validation accuracy:		89.24 %
Epoch 304 of 2000 took 0.097s
  training loss:		0.281141
  validation loss:		0.362937
  validation accuracy:		89.46 %
Epoch 305 of 2000 took 0.097s
  training loss:		0.269978
  validation loss:		0.366402
  validation accuracy:		89.24 %
Epoch 306 of 2000 took 0.097s
  training loss:		0.277270
  validation loss:		0.374832
  validation accuracy:		88.80 %
Epoch 307 of 2000 took 0.097s
  training loss:		0.280508
  validation loss:		0.369304
  validation accuracy:		89.35 %
Epoch 308 of 2000 took 0.097s
  training loss:		0.270598
  validation loss:		0.363855
  validation accuracy:		89.89 %
Epoch 309 of 2000 took 0.097s
  training loss:		0.276438
  validation loss:		0.358171
  validation accuracy:		89.57 %
Epoch 310 of 2000 took 0.097s
  training loss:		0.280149
  validation loss:		0.364509
  validation accuracy:		88.59 %
Epoch 311 of 2000 took 0.097s
  training loss:		0.279933
  validation loss:		0.358311
  validation accuracy:		89.46 %
Epoch 312 of 2000 took 0.102s
  training loss:		0.278535
  validation loss:		0.355327
  validation accuracy:		89.67 %
Epoch 313 of 2000 took 0.103s
  training loss:		0.273570
  validation loss:		0.366600
  validation accuracy:		89.35 %
Epoch 314 of 2000 took 0.103s
  training loss:		0.270594
  validation loss:		0.359701
  validation accuracy:		89.46 %
Epoch 315 of 2000 took 0.108s
  training loss:		0.265276
  validation loss:		0.364203
  validation accuracy:		89.13 %
Epoch 316 of 2000 took 0.104s
  training loss:		0.275168
  validation loss:		0.359269
  validation accuracy:		89.13 %
Epoch 317 of 2000 took 0.103s
  training loss:		0.272274
  validation loss:		0.392341
  validation accuracy:		89.13 %
Epoch 318 of 2000 took 0.104s
  training loss:		0.275447
  validation loss:		0.365271
  validation accuracy:		89.35 %
Epoch 319 of 2000 took 0.103s
  training loss:		0.273301
  validation loss:		0.362134
  validation accuracy:		89.35 %
Epoch 320 of 2000 took 0.103s
  training loss:		0.271332
  validation loss:		0.363876
  validation accuracy:		89.35 %
Epoch 321 of 2000 took 0.103s
  training loss:		0.265216
  validation loss:		0.366811
  validation accuracy:		89.57 %
Epoch 322 of 2000 took 0.103s
  training loss:		0.262480
  validation loss:		0.359116
  validation accuracy:		89.57 %
Epoch 323 of 2000 took 0.103s
  training loss:		0.270786
  validation loss:		0.347856
  validation accuracy:		89.89 %
Epoch 324 of 2000 took 0.103s
  training loss:		0.267812
  validation loss:		0.359114
  validation accuracy:		89.78 %
Epoch 325 of 2000 took 0.104s
  training loss:		0.260674
  validation loss:		0.355346
  validation accuracy:		89.67 %
Epoch 326 of 2000 took 0.103s
  training loss:		0.268811
  validation loss:		0.353774
  validation accuracy:		89.78 %
Epoch 327 of 2000 took 0.103s
  training loss:		0.264527
  validation loss:		0.363657
  validation accuracy:		89.57 %
Epoch 328 of 2000 took 0.103s
  training loss:		0.262512
  validation loss:		0.352705
  validation accuracy:		90.11 %
Epoch 329 of 2000 took 0.103s
  training loss:		0.268061
  validation loss:		0.358843
  validation accuracy:		89.57 %
Epoch 330 of 2000 took 0.104s
  training loss:		0.274426
  validation loss:		0.355633
  validation accuracy:		89.67 %
Epoch 331 of 2000 took 0.103s
  training loss:		0.268517
  validation loss:		0.361193
  validation accuracy:		89.67 %
Epoch 332 of 2000 took 0.103s
  training loss:		0.265900
  validation loss:		0.376093
  validation accuracy:		89.46 %
Epoch 333 of 2000 took 0.103s
  training loss:		0.267487
  validation loss:		0.351113
  validation accuracy:		89.35 %
Epoch 334 of 2000 took 0.104s
  training loss:		0.267667
  validation loss:		0.361034
  validation accuracy:		89.57 %
Epoch 335 of 2000 took 0.103s
  training loss:		0.262220
  validation loss:		0.364604
  validation accuracy:		89.57 %
Epoch 336 of 2000 took 0.103s
  training loss:		0.261951
  validation loss:		0.358628
  validation accuracy:		90.00 %
Epoch 337 of 2000 took 0.103s
  training loss:		0.267080
  validation loss:		0.378343
  validation accuracy:		89.24 %
Epoch 338 of 2000 took 0.103s
  training loss:		0.258186
  validation loss:		0.385983
  validation accuracy:		89.13 %
Epoch 339 of 2000 took 0.103s
  training loss:		0.266052
  validation loss:		0.351466
  validation accuracy:		89.57 %
Epoch 340 of 2000 took 0.103s
  training loss:		0.263714
  validation loss:		0.362308
  validation accuracy:		89.57 %
Epoch 341 of 2000 took 0.103s
  training loss:		0.253253
  validation loss:		0.359537
  validation accuracy:		89.57 %
Epoch 342 of 2000 took 0.103s
  training loss:		0.258064
  validation loss:		0.355386
  validation accuracy:		89.89 %
Epoch 343 of 2000 took 0.103s
  training loss:		0.259110
  validation loss:		0.356892
  validation accuracy:		89.67 %
Epoch 344 of 2000 took 0.103s
  training loss:		0.250875
  validation loss:		0.376930
  validation accuracy:		89.13 %
Epoch 345 of 2000 took 0.103s
  training loss:		0.258692
  validation loss:		0.359640
  validation accuracy:		89.67 %
Epoch 346 of 2000 took 0.103s
  training loss:		0.264151
  validation loss:		0.355079
  validation accuracy:		89.78 %
Epoch 347 of 2000 took 0.104s
  training loss:		0.259230
  validation loss:		0.348787
  validation accuracy:		89.89 %
Epoch 348 of 2000 took 0.103s
  training loss:		0.252235
  validation loss:		0.342074
  validation accuracy:		89.89 %
Epoch 349 of 2000 took 0.103s
  training loss:		0.246683
  validation loss:		0.359423
  validation accuracy:		89.89 %
Epoch 350 of 2000 took 0.104s
  training loss:		0.260451
  validation loss:		0.348921
  validation accuracy:		89.57 %
Epoch 351 of 2000 took 0.104s
  training loss:		0.256051
  validation loss:		0.355887
  validation accuracy:		89.89 %
Epoch 352 of 2000 took 0.104s
  training loss:		0.252090
  validation loss:		0.366448
  validation accuracy:		89.57 %
Epoch 353 of 2000 took 0.103s
  training loss:		0.246969
  validation loss:		0.350295
  validation accuracy:		89.35 %
Epoch 354 of 2000 took 0.104s
  training loss:		0.248169
  validation loss:		0.347935
  validation accuracy:		89.89 %
Epoch 355 of 2000 took 0.103s
  training loss:		0.254082
  validation loss:		0.343051
  validation accuracy:		90.00 %
Epoch 356 of 2000 took 0.103s
  training loss:		0.242137
  validation loss:		0.340641
  validation accuracy:		90.11 %
Epoch 357 of 2000 took 0.103s
  training loss:		0.250131
  validation loss:		0.341559
  validation accuracy:		90.33 %
Epoch 358 of 2000 took 0.103s
  training loss:		0.244625
  validation loss:		0.349716
  validation accuracy:		89.57 %
Epoch 359 of 2000 took 0.103s
  training loss:		0.249083
  validation loss:		0.341377
  validation accuracy:		90.65 %
Epoch 360 of 2000 took 0.103s
  training loss:		0.244379
  validation loss:		0.336706
  validation accuracy:		90.33 %
Epoch 361 of 2000 took 0.103s
  training loss:		0.243161
  validation loss:		0.341197
  validation accuracy:		90.11 %
Epoch 362 of 2000 took 0.103s
  training loss:		0.247447
  validation loss:		0.341765
  validation accuracy:		90.22 %
Epoch 363 of 2000 took 0.103s
  training loss:		0.241908
  validation loss:		0.351955
  validation accuracy:		90.11 %
Epoch 364 of 2000 took 0.103s
  training loss:		0.241043
  validation loss:		0.337205
  validation accuracy:		90.43 %
Epoch 365 of 2000 took 0.103s
  training loss:		0.239677
  validation loss:		0.343603
  validation accuracy:		90.33 %
Epoch 366 of 2000 took 0.104s
  training loss:		0.242014
  validation loss:		0.337475
  validation accuracy:		90.11 %
Epoch 367 of 2000 took 0.103s
  training loss:		0.240394
  validation loss:		0.350893
  validation accuracy:		89.78 %
Epoch 368 of 2000 took 0.103s
  training loss:		0.243901
  validation loss:		0.345222
  validation accuracy:		90.00 %
Epoch 369 of 2000 took 0.103s
  training loss:		0.232980
  validation loss:		0.355652
  validation accuracy:		89.89 %
Epoch 370 of 2000 took 0.108s
  training loss:		0.244400
  validation loss:		0.342533
  validation accuracy:		90.11 %
Epoch 371 of 2000 took 0.104s
  training loss:		0.236216
  validation loss:		0.350603
  validation accuracy:		90.22 %
Epoch 372 of 2000 took 0.103s
  training loss:		0.239160
  validation loss:		0.343423
  validation accuracy:		90.22 %
Epoch 373 of 2000 took 0.103s
  training loss:		0.238617
  validation loss:		0.340750
  validation accuracy:		90.43 %
Epoch 374 of 2000 took 0.103s
  training loss:		0.238787
  validation loss:		0.348047
  validation accuracy:		90.00 %
Epoch 375 of 2000 took 0.103s
  training loss:		0.237633
  validation loss:		0.335004
  validation accuracy:		90.87 %
Epoch 376 of 2000 took 0.103s
  training loss:		0.236399
  validation loss:		0.342002
  validation accuracy:		90.11 %
Epoch 377 of 2000 took 0.103s
  training loss:		0.236527
  validation loss:		0.344815
  validation accuracy:		90.00 %
Epoch 378 of 2000 took 0.103s
  training loss:		0.235074
  validation loss:		0.341383
  validation accuracy:		90.22 %
Epoch 379 of 2000 took 0.103s
  training loss:		0.231958
  validation loss:		0.335861
  validation accuracy:		90.54 %
Epoch 380 of 2000 took 0.103s
  training loss:		0.235114
  validation loss:		0.339278
  validation accuracy:		90.33 %
Epoch 381 of 2000 took 0.103s
  training loss:		0.230261
  validation loss:		0.336809
  validation accuracy:		90.54 %
Epoch 382 of 2000 took 0.103s
  training loss:		0.231620
  validation loss:		0.347081
  validation accuracy:		90.11 %
Epoch 383 of 2000 took 0.104s
  training loss:		0.240316
  validation loss:		0.333778
  validation accuracy:		90.76 %
Epoch 384 of 2000 took 0.103s
  training loss:		0.229775
  validation loss:		0.339498
  validation accuracy:		90.33 %
Epoch 385 of 2000 took 0.104s
  training loss:		0.231856
  validation loss:		0.337412
  validation accuracy:		90.76 %
Epoch 386 of 2000 took 0.104s
  training loss:		0.227581
  validation loss:		0.335564
  validation accuracy:		90.43 %
Epoch 387 of 2000 took 0.103s
  training loss:		0.232848
  validation loss:		0.344436
  validation accuracy:		90.33 %
Epoch 388 of 2000 took 0.104s
  training loss:		0.235661
  validation loss:		0.342762
  validation accuracy:		90.33 %
Epoch 389 of 2000 took 0.107s
  training loss:		0.226765
  validation loss:		0.348068
  validation accuracy:		90.43 %
Epoch 390 of 2000 took 0.107s
  training loss:		0.230017
  validation loss:		0.341169
  validation accuracy:		90.65 %
Epoch 391 of 2000 took 0.107s
  training loss:		0.224538
  validation loss:		0.337411
  validation accuracy:		90.22 %
Epoch 392 of 2000 took 0.107s
  training loss:		0.224905
  validation loss:		0.347204
  validation accuracy:		89.89 %
Epoch 393 of 2000 took 0.107s
  training loss:		0.225135
  validation loss:		0.339168
  validation accuracy:		90.54 %
Epoch 394 of 2000 took 0.107s
  training loss:		0.229671
  validation loss:		0.338861
  validation accuracy:		90.22 %
Epoch 395 of 2000 took 0.107s
  training loss:		0.222358
  validation loss:		0.333385
  validation accuracy:		90.54 %
Epoch 396 of 2000 took 0.107s
  training loss:		0.223343
  validation loss:		0.354916
  validation accuracy:		89.89 %
Epoch 397 of 2000 took 0.107s
  training loss:		0.220116
  validation loss:		0.333211
  validation accuracy:		90.54 %
Epoch 398 of 2000 took 0.107s
  training loss:		0.224524
  validation loss:		0.338482
  validation accuracy:		90.43 %
Epoch 399 of 2000 took 0.107s
  training loss:		0.226338
  validation loss:		0.333570
  validation accuracy:		90.43 %
Epoch 400 of 2000 took 0.107s
  training loss:		0.222483
  validation loss:		0.332323
  validation accuracy:		90.98 %
Epoch 401 of 2000 took 0.107s
  training loss:		0.214948
  validation loss:		0.334847
  validation accuracy:		91.20 %
Epoch 402 of 2000 took 0.107s
  training loss:		0.220060
  validation loss:		0.343337
  validation accuracy:		90.00 %
Epoch 403 of 2000 took 0.107s
  training loss:		0.227513
  validation loss:		0.331029
  validation accuracy:		90.98 %
Epoch 404 of 2000 took 0.107s
  training loss:		0.217764
  validation loss:		0.341240
  validation accuracy:		90.54 %
Epoch 405 of 2000 took 0.107s
  training loss:		0.223338
  validation loss:		0.336944
  validation accuracy:		90.54 %
Epoch 406 of 2000 took 0.107s
  training loss:		0.219147
  validation loss:		0.332318
  validation accuracy:		90.65 %
Epoch 407 of 2000 took 0.107s
  training loss:		0.214245
  validation loss:		0.328455
  validation accuracy:		91.09 %
Epoch 408 of 2000 took 0.107s
  training loss:		0.212595
  validation loss:		0.339783
  validation accuracy:		90.54 %
Epoch 409 of 2000 took 0.107s
  training loss:		0.217248
  validation loss:		0.350210
  validation accuracy:		90.54 %
Epoch 410 of 2000 took 0.107s
  training loss:		0.220088
  validation loss:		0.333733
  validation accuracy:		90.76 %
Epoch 411 of 2000 took 0.107s
  training loss:		0.214214
  validation loss:		0.348012
  validation accuracy:		90.33 %
Epoch 412 of 2000 took 0.107s
  training loss:		0.209314
  validation loss:		0.345715
  validation accuracy:		90.33 %
Epoch 413 of 2000 took 0.107s
  training loss:		0.214438
  validation loss:		0.328716
  validation accuracy:		90.33 %
Epoch 414 of 2000 took 0.107s
  training loss:		0.209394
  validation loss:		0.332066
  validation accuracy:		91.41 %
Epoch 415 of 2000 took 0.107s
  training loss:		0.210900
  validation loss:		0.328191
  validation accuracy:		91.20 %
Epoch 416 of 2000 took 0.107s
  training loss:		0.204617
  validation loss:		0.325405
  validation accuracy:		91.09 %
Epoch 417 of 2000 took 0.107s
  training loss:		0.209072
  validation loss:		0.346001
  validation accuracy:		90.87 %
Epoch 418 of 2000 took 0.107s
  training loss:		0.210078
  validation loss:		0.329191
  validation accuracy:		90.98 %
Epoch 419 of 2000 took 0.112s
  training loss:		0.207106
  validation loss:		0.331101
  validation accuracy:		91.30 %
Epoch 420 of 2000 took 0.107s
  training loss:		0.208622
  validation loss:		0.334857
  validation accuracy:		91.41 %
Epoch 421 of 2000 took 0.107s
  training loss:		0.204347
  validation loss:		0.346698
  validation accuracy:		90.65 %
Epoch 422 of 2000 took 0.107s
  training loss:		0.207825
  validation loss:		0.330824
  validation accuracy:		90.98 %
Epoch 423 of 2000 took 0.107s
  training loss:		0.207328
  validation loss:		0.321451
  validation accuracy:		90.76 %
Epoch 424 of 2000 took 0.107s
  training loss:		0.207607
  validation loss:		0.323543
  validation accuracy:		90.54 %
Epoch 425 of 2000 took 0.107s
  training loss:		0.198397
  validation loss:		0.326617
  validation accuracy:		91.30 %
Epoch 426 of 2000 took 0.106s
  training loss:		0.200727
  validation loss:		0.330224
  validation accuracy:		91.41 %
Epoch 427 of 2000 took 0.100s
  training loss:		0.203421
  validation loss:		0.323883
  validation accuracy:		91.41 %
Epoch 428 of 2000 took 0.100s
  training loss:		0.201778
  validation loss:		0.353127
  validation accuracy:		90.65 %
Epoch 429 of 2000 took 0.100s
  training loss:		0.199889
  validation loss:		0.335626
  validation accuracy:		91.20 %
Epoch 430 of 2000 took 0.100s
  training loss:		0.202357
  validation loss:		0.342923
  validation accuracy:		90.65 %
Epoch 431 of 2000 took 0.100s
  training loss:		0.204151
  validation loss:		0.321494
  validation accuracy:		91.20 %
Epoch 432 of 2000 took 0.100s
  training loss:		0.202244
  validation loss:		0.331963
  validation accuracy:		91.63 %
Epoch 433 of 2000 took 0.100s
  training loss:		0.201673
  validation loss:		0.335677
  validation accuracy:		90.98 %
Epoch 434 of 2000 took 0.100s
  training loss:		0.202232
  validation loss:		0.325027
  validation accuracy:		91.30 %
Epoch 435 of 2000 took 0.100s
  training loss:		0.201549
  validation loss:		0.330105
  validation accuracy:		91.30 %
Epoch 436 of 2000 took 0.100s
  training loss:		0.190935
  validation loss:		0.349070
  validation accuracy:		91.09 %
Epoch 437 of 2000 took 0.100s
  training loss:		0.193874
  validation loss:		0.330050
  validation accuracy:		91.41 %
Epoch 438 of 2000 took 0.100s
  training loss:		0.195887
  validation loss:		0.324920
  validation accuracy:		91.52 %
Epoch 439 of 2000 took 0.100s
  training loss:		0.194725
  validation loss:		0.320106
  validation accuracy:		91.20 %
Epoch 440 of 2000 took 0.101s
  training loss:		0.200771
  validation loss:		0.335742
  validation accuracy:		90.98 %
Epoch 441 of 2000 took 0.100s
  training loss:		0.192578
  validation loss:		0.339741
  validation accuracy:		90.87 %
Epoch 442 of 2000 took 0.100s
  training loss:		0.195457
  validation loss:		0.327033
  validation accuracy:		90.33 %
Epoch 443 of 2000 took 0.100s
  training loss:		0.188477
  validation loss:		0.336882
  validation accuracy:		91.20 %
Epoch 444 of 2000 took 0.100s
  training loss:		0.193340
  validation loss:		0.323373
  validation accuracy:		91.20 %
Epoch 445 of 2000 took 0.100s
  training loss:		0.187137
  validation loss:		0.333700
  validation accuracy:		91.30 %
Epoch 446 of 2000 took 0.100s
  training loss:		0.189969
  validation loss:		0.328250
  validation accuracy:		91.74 %
Epoch 447 of 2000 took 0.100s
  training loss:		0.193451
  validation loss:		0.319210
  validation accuracy:		91.85 %
Epoch 448 of 2000 took 0.100s
  training loss:		0.190460
  validation loss:		0.340452
  validation accuracy:		91.41 %
Epoch 449 of 2000 took 0.100s
  training loss:		0.191333
  validation loss:		0.318215
  validation accuracy:		91.41 %
Epoch 450 of 2000 took 0.100s
  training loss:		0.188369
  validation loss:		0.330133
  validation accuracy:		91.30 %
Epoch 451 of 2000 took 0.100s
  training loss:		0.185634
  validation loss:		0.335072
  validation accuracy:		91.20 %
Epoch 452 of 2000 took 0.100s
  training loss:		0.186372
  validation loss:		0.320020
  validation accuracy:		91.63 %
Epoch 453 of 2000 took 0.100s
  training loss:		0.182028
  validation loss:		0.328559
  validation accuracy:		91.09 %
Epoch 454 of 2000 took 0.100s
  training loss:		0.183302
  validation loss:		0.322661
  validation accuracy:		91.20 %
Epoch 455 of 2000 took 0.100s
  training loss:		0.180206
  validation loss:		0.320290
  validation accuracy:		91.41 %
Epoch 456 of 2000 took 0.100s
  training loss:		0.181749
  validation loss:		0.330864
  validation accuracy:		91.20 %
Epoch 457 of 2000 took 0.100s
  training loss:		0.181900
  validation loss:		0.316358
  validation accuracy:		91.30 %
Epoch 458 of 2000 took 0.100s
  training loss:		0.180154
  validation loss:		0.320036
  validation accuracy:		91.52 %
Epoch 459 of 2000 took 0.100s
  training loss:		0.180743
  validation loss:		0.329036
  validation accuracy:		90.76 %
Epoch 460 of 2000 took 0.100s
  training loss:		0.185157
  validation loss:		0.325432
  validation accuracy:		91.96 %
Epoch 461 of 2000 took 0.100s
  training loss:		0.184163
  validation loss:		0.316417
  validation accuracy:		91.52 %
Epoch 462 of 2000 took 0.100s
  training loss:		0.179859
  validation loss:		0.330577
  validation accuracy:		91.74 %
Epoch 463 of 2000 took 0.100s
  training loss:		0.182976
  validation loss:		0.322681
  validation accuracy:		91.85 %
Epoch 464 of 2000 took 0.104s
  training loss:		0.181871
  validation loss:		0.325875
  validation accuracy:		91.52 %
Epoch 465 of 2000 took 0.100s
  training loss:		0.179227
  validation loss:		0.320085
  validation accuracy:		91.63 %
Epoch 466 of 2000 took 0.097s
  training loss:		0.176803
  validation loss:		0.315651
  validation accuracy:		91.52 %
Epoch 467 of 2000 took 0.097s
  training loss:		0.179080
  validation loss:		0.331297
  validation accuracy:		91.74 %
Epoch 468 of 2000 took 0.097s
  training loss:		0.177351
  validation loss:		0.313385
  validation accuracy:		91.30 %
Epoch 469 of 2000 took 0.097s
  training loss:		0.180473
  validation loss:		0.326189
  validation accuracy:		91.63 %
Epoch 470 of 2000 took 0.097s
  training loss:		0.178195
  validation loss:		0.327756
  validation accuracy:		91.52 %
Epoch 471 of 2000 took 0.098s
  training loss:		0.174890
  validation loss:		0.316031
  validation accuracy:		91.41 %
Epoch 472 of 2000 took 0.097s
  training loss:		0.180406
  validation loss:		0.323602
  validation accuracy:		91.52 %
Epoch 473 of 2000 took 0.097s
  training loss:		0.176448
  validation loss:		0.316118
  validation accuracy:		91.85 %
Epoch 474 of 2000 took 0.097s
  training loss:		0.169993
  validation loss:		0.315099
  validation accuracy:		91.52 %
Epoch 475 of 2000 took 0.097s
  training loss:		0.172490
  validation loss:		0.327846
  validation accuracy:		91.41 %
Epoch 476 of 2000 took 0.097s
  training loss:		0.174361
  validation loss:		0.324635
  validation accuracy:		91.85 %
Epoch 477 of 2000 took 0.097s
  training loss:		0.173200
  validation loss:		0.325253
  validation accuracy:		91.63 %
Epoch 478 of 2000 took 0.097s
  training loss:		0.176388
  validation loss:		0.318002
  validation accuracy:		92.17 %
Epoch 479 of 2000 took 0.097s
  training loss:		0.172392
  validation loss:		0.322668
  validation accuracy:		92.17 %
Epoch 480 of 2000 took 0.097s
  training loss:		0.174763
  validation loss:		0.323436
  validation accuracy:		91.30 %
Epoch 481 of 2000 took 0.097s
  training loss:		0.169876
  validation loss:		0.321129
  validation accuracy:		91.85 %
Epoch 482 of 2000 took 0.097s
  training loss:		0.175864
  validation loss:		0.319532
  validation accuracy:		91.85 %
Epoch 483 of 2000 took 0.097s
  training loss:		0.169252
  validation loss:		0.324400
  validation accuracy:		91.74 %
Epoch 484 of 2000 took 0.097s
  training loss:		0.169857
  validation loss:		0.323109
  validation accuracy:		91.41 %
Epoch 485 of 2000 took 0.097s
  training loss:		0.166968
  validation loss:		0.316694
  validation accuracy:		91.63 %
Epoch 486 of 2000 took 0.097s
  training loss:		0.166991
  validation loss:		0.311516
  validation accuracy:		92.07 %
Epoch 487 of 2000 took 0.097s
  training loss:		0.172440
  validation loss:		0.318165
  validation accuracy:		91.74 %
Epoch 488 of 2000 took 0.097s
  training loss:		0.171187
  validation loss:		0.320343
  validation accuracy:		91.52 %
Epoch 489 of 2000 took 0.097s
  training loss:		0.165523
  validation loss:		0.318192
  validation accuracy:		91.85 %
Epoch 490 of 2000 took 0.097s
  training loss:		0.163215
  validation loss:		0.315990
  validation accuracy:		92.28 %
Epoch 491 of 2000 took 0.097s
  training loss:		0.168084
  validation loss:		0.318509
  validation accuracy:		91.63 %
Epoch 492 of 2000 took 0.097s
  training loss:		0.163718
  validation loss:		0.324136
  validation accuracy:		91.74 %
Epoch 493 of 2000 took 0.097s
  training loss:		0.166255
  validation loss:		0.314659
  validation accuracy:		92.07 %
Epoch 494 of 2000 took 0.097s
  training loss:		0.164863
  validation loss:		0.319820
  validation accuracy:		92.50 %
Epoch 495 of 2000 took 0.097s
  training loss:		0.165317
  validation loss:		0.317360
  validation accuracy:		91.41 %
Epoch 496 of 2000 took 0.097s
  training loss:		0.164082
  validation loss:		0.317316
  validation accuracy:		91.96 %
Epoch 497 of 2000 took 0.097s
  training loss:		0.164021
  validation loss:		0.325698
  validation accuracy:		91.74 %
Epoch 498 of 2000 took 0.097s
  training loss:		0.163774
  validation loss:		0.318994
  validation accuracy:		92.28 %
Epoch 499 of 2000 took 0.097s
  training loss:		0.162880
  validation loss:		0.323335
  validation accuracy:		91.74 %
Epoch 500 of 2000 took 0.097s
  training loss:		0.161973
  validation loss:		0.325104
  validation accuracy:		91.85 %
Epoch 501 of 2000 took 0.097s
  training loss:		0.159543
  validation loss:		0.329933
  validation accuracy:		91.74 %
Epoch 502 of 2000 took 0.098s
  training loss:		0.161308
  validation loss:		0.315915
  validation accuracy:		92.07 %
Epoch 503 of 2000 took 0.097s
  training loss:		0.150900
  validation loss:		0.320456
  validation accuracy:		92.39 %
Epoch 504 of 2000 took 0.100s
  training loss:		0.163998
  validation loss:		0.336266
  validation accuracy:		91.41 %
Epoch 505 of 2000 took 0.097s
  training loss:		0.160428
  validation loss:		0.317521
  validation accuracy:		92.39 %
Epoch 506 of 2000 took 0.097s
  training loss:		0.157059
  validation loss:		0.324025
  validation accuracy:		92.17 %
Epoch 507 of 2000 took 0.103s
  training loss:		0.160428
  validation loss:		0.322048
  validation accuracy:		92.28 %
Epoch 508 of 2000 took 0.100s
  training loss:		0.159333
  validation loss:		0.320210
  validation accuracy:		91.74 %
Epoch 509 of 2000 took 0.100s
  training loss:		0.160914
  validation loss:		0.326190
  validation accuracy:		91.96 %
Epoch 510 of 2000 took 0.100s
  training loss:		0.154484
  validation loss:		0.331799
  validation accuracy:		91.85 %
Epoch 511 of 2000 took 0.100s
  training loss:		0.155124
  validation loss:		0.323428
  validation accuracy:		91.85 %
Epoch 512 of 2000 took 0.100s
  training loss:		0.151109
  validation loss:		0.317794
  validation accuracy:		92.39 %
Epoch 513 of 2000 took 0.100s
  training loss:		0.154298
  validation loss:		0.318344
  validation accuracy:		92.28 %
Epoch 514 of 2000 took 0.100s
  training loss:		0.155378
  validation loss:		0.319066
  validation accuracy:		91.96 %
Epoch 515 of 2000 took 0.100s
  training loss:		0.153809
  validation loss:		0.317939
  validation accuracy:		92.28 %
Epoch 516 of 2000 took 0.100s
  training loss:		0.154175
  validation loss:		0.319612
  validation accuracy:		91.74 %
Epoch 517 of 2000 took 0.100s
  training loss:		0.155668
  validation loss:		0.323475
  validation accuracy:		91.85 %
Epoch 518 of 2000 took 0.100s
  training loss:		0.150889
  validation loss:		0.318918
  validation accuracy:		91.74 %
Epoch 519 of 2000 took 0.100s
  training loss:		0.152664
  validation loss:		0.329476
  validation accuracy:		92.07 %
Epoch 520 of 2000 took 0.100s
  training loss:		0.153952
  validation loss:		0.330197
  validation accuracy:		91.74 %
Epoch 521 of 2000 took 0.100s
  training loss:		0.150244
  validation loss:		0.322757
  validation accuracy:		92.72 %
Epoch 522 of 2000 took 0.100s
  training loss:		0.151223
  validation loss:		0.330265
  validation accuracy:		91.96 %
Epoch 523 of 2000 took 0.100s
  training loss:		0.151870
  validation loss:		0.314582
  validation accuracy:		92.39 %
Epoch 524 of 2000 took 0.100s
  training loss:		0.151277
  validation loss:		0.326113
  validation accuracy:		91.41 %
Epoch 525 of 2000 took 0.100s
  training loss:		0.148842
  validation loss:		0.317959
  validation accuracy:		91.85 %
Epoch 526 of 2000 took 0.100s
  training loss:		0.148092
  validation loss:		0.316507
  validation accuracy:		92.28 %
Epoch 527 of 2000 took 0.100s
  training loss:		0.145746
  validation loss:		0.319806
  validation accuracy:		92.39 %
Epoch 528 of 2000 took 0.100s
  training loss:		0.150195
  validation loss:		0.320065
  validation accuracy:		92.17 %
Epoch 529 of 2000 took 0.100s
  training loss:		0.146294
  validation loss:		0.330812
  validation accuracy:		92.07 %
Epoch 530 of 2000 took 0.100s
  training loss:		0.149222
  validation loss:		0.322325
  validation accuracy:		91.96 %
Epoch 531 of 2000 took 0.100s
  training loss:		0.151706
  validation loss:		0.326182
  validation accuracy:		91.74 %
Epoch 532 of 2000 took 0.101s
  training loss:		0.143716
  validation loss:		0.318420
  validation accuracy:		92.83 %
Epoch 533 of 2000 took 0.100s
  training loss:		0.150277
  validation loss:		0.323180
  validation accuracy:		92.07 %
Epoch 534 of 2000 took 0.100s
  training loss:		0.145577
  validation loss:		0.323368
  validation accuracy:		92.72 %
Epoch 535 of 2000 took 0.100s
  training loss:		0.145461
  validation loss:		0.329444
  validation accuracy:		91.52 %
Epoch 536 of 2000 took 0.100s
  training loss:		0.141353
  validation loss:		0.334345
  validation accuracy:		91.52 %
Epoch 537 of 2000 took 0.102s
  training loss:		0.142069
  validation loss:		0.336170
  validation accuracy:		91.09 %
Epoch 538 of 2000 took 0.107s
  training loss:		0.145397
  validation loss:		0.344011
  validation accuracy:		91.20 %
Epoch 539 of 2000 took 0.112s
  training loss:		0.146884
  validation loss:		0.323505
  validation accuracy:		92.07 %
Epoch 540 of 2000 took 0.143s
  training loss:		0.142877
  validation loss:		0.328821
  validation accuracy:		92.07 %
Epoch 541 of 2000 took 0.108s
  training loss:		0.144440
  validation loss:		0.317982
  validation accuracy:		91.63 %
Epoch 542 of 2000 took 0.102s
  training loss:		0.139935
  validation loss:		0.340516
  validation accuracy:		91.74 %
Epoch 543 of 2000 took 0.105s
  training loss:		0.142621
  validation loss:		0.320631
  validation accuracy:		92.17 %
Epoch 544 of 2000 took 0.098s
  training loss:		0.143399
  validation loss:		0.319298
  validation accuracy:		91.96 %
Epoch 545 of 2000 took 0.096s
  training loss:		0.142499
  validation loss:		0.315669
  validation accuracy:		92.72 %
Epoch 546 of 2000 took 0.103s
  training loss:		0.144048
  validation loss:		0.315767
  validation accuracy:		92.39 %
Epoch 547 of 2000 took 0.098s
  training loss:		0.138759
  validation loss:		0.316659
  validation accuracy:		92.93 %
Epoch 548 of 2000 took 0.097s
  training loss:		0.141435
  validation loss:		0.322769
  validation accuracy:		92.39 %
Epoch 549 of 2000 took 0.104s
  training loss:		0.137021
  validation loss:		0.327006
  validation accuracy:		91.63 %
Epoch 550 of 2000 took 0.097s
  training loss:		0.140838
  validation loss:		0.328995
  validation accuracy:		92.07 %
Epoch 551 of 2000 took 0.097s
  training loss:		0.138439
  validation loss:		0.328260
  validation accuracy:		91.85 %
Epoch 552 of 2000 took 0.097s
  training loss:		0.134520
  validation loss:		0.317638
  validation accuracy:		92.83 %
Epoch 553 of 2000 took 0.098s
  training loss:		0.142466
  validation loss:		0.319792
  validation accuracy:		91.85 %
Epoch 554 of 2000 took 0.102s
  training loss:		0.139075
  validation loss:		0.316703
  validation accuracy:		92.17 %
Epoch 555 of 2000 took 0.097s
  training loss:		0.139717
  validation loss:		0.328836
  validation accuracy:		92.07 %
Epoch 556 of 2000 took 0.097s
  training loss:		0.137553
  validation loss:		0.328115
  validation accuracy:		92.07 %
Epoch 557 of 2000 took 0.104s
  training loss:		0.138782
  validation loss:		0.315519
  validation accuracy:		92.17 %
Epoch 558 of 2000 took 0.097s
  training loss:		0.135237
  validation loss:		0.315060
  validation accuracy:		92.50 %
Epoch 559 of 2000 took 0.098s
  training loss:		0.139164
  validation loss:		0.324528
  validation accuracy:		92.07 %
Epoch 560 of 2000 took 0.096s
  training loss:		0.133638
  validation loss:		0.320069
  validation accuracy:		92.93 %
Epoch 561 of 2000 took 0.100s
  training loss:		0.140614
  validation loss:		0.330805
  validation accuracy:		92.17 %
Epoch 562 of 2000 took 0.100s
  training loss:		0.134347
  validation loss:		0.324205
  validation accuracy:		92.83 %
Epoch 563 of 2000 took 0.096s
  training loss:		0.135133
  validation loss:		0.340769
  validation accuracy:		91.41 %
Epoch 564 of 2000 took 0.100s
  training loss:		0.136350
  validation loss:		0.319816
  validation accuracy:		92.93 %
Epoch 565 of 2000 took 0.101s
  training loss:		0.140205
  validation loss:		0.324431
  validation accuracy:		92.50 %
Epoch 566 of 2000 took 0.097s
  training loss:		0.134148
  validation loss:		0.321609
  validation accuracy:		92.39 %
Epoch 567 of 2000 took 0.097s
  training loss:		0.134247
  validation loss:		0.324199
  validation accuracy:		92.28 %
Epoch 568 of 2000 took 0.096s
  training loss:		0.133497
  validation loss:		0.342197
  validation accuracy:		91.52 %
Epoch 569 of 2000 took 0.103s
  training loss:		0.129824
  validation loss:		0.321658
  validation accuracy:		92.39 %
Epoch 570 of 2000 took 0.098s
  training loss:		0.134354
  validation loss:		0.326574
  validation accuracy:		92.39 %
Epoch 571 of 2000 took 0.097s
  training loss:		0.129814
  validation loss:		0.328550
  validation accuracy:		92.28 %
Epoch 572 of 2000 took 0.104s
  training loss:		0.132047
  validation loss:		0.328193
  validation accuracy:		92.07 %
Epoch 573 of 2000 took 0.097s
  training loss:		0.132051
  validation loss:		0.325910
  validation accuracy:		92.17 %
Epoch 574 of 2000 took 0.098s
  training loss:		0.134341
  validation loss:		0.318312
  validation accuracy:		92.39 %
Epoch 575 of 2000 took 0.097s
  training loss:		0.134352
  validation loss:		0.324397
  validation accuracy:		92.39 %
Epoch 576 of 2000 took 0.098s
  training loss:		0.130425
  validation loss:		0.322629
  validation accuracy:		92.28 %
Epoch 577 of 2000 took 0.111s
  training loss:		0.130658
  validation loss:		0.330226
  validation accuracy:		92.39 %
Epoch 578 of 2000 took 0.097s
  training loss:		0.126237
  validation loss:		0.322281
  validation accuracy:		92.17 %
Epoch 579 of 2000 took 0.121s
  training loss:		0.129505
  validation loss:		0.327249
  validation accuracy:		92.17 %
Epoch 580 of 2000 took 0.167s
  training loss:		0.127567
  validation loss:		0.318962
  validation accuracy:		92.83 %
Epoch 581 of 2000 took 0.167s
  training loss:		0.125451
  validation loss:		0.322940
  validation accuracy:		93.04 %
Epoch 582 of 2000 took 0.166s
  training loss:		0.126817
  validation loss:		0.321714
  validation accuracy:		92.17 %
Epoch 583 of 2000 took 0.166s
  training loss:		0.132733
  validation loss:		0.323407
  validation accuracy:		92.61 %
Epoch 584 of 2000 took 0.167s
  training loss:		0.126148
  validation loss:		0.323192
  validation accuracy:		92.72 %
Epoch 585 of 2000 took 0.167s
  training loss:		0.126181
  validation loss:		0.319136
  validation accuracy:		92.83 %
Epoch 586 of 2000 took 0.166s
  training loss:		0.127750
  validation loss:		0.323401
  validation accuracy:		92.28 %
Epoch 587 of 2000 took 0.167s
  training loss:		0.124342
  validation loss:		0.329791
  validation accuracy:		91.85 %
Epoch 588 of 2000 took 0.167s
  training loss:		0.126329
  validation loss:		0.326351
  validation accuracy:		92.28 %
Epoch 589 of 2000 took 0.166s
  training loss:		0.127796
  validation loss:		0.327955
  validation accuracy:		92.83 %
Epoch 590 of 2000 took 0.098s
  training loss:		0.125936
  validation loss:		0.333323
  validation accuracy:		92.50 %
Epoch 591 of 2000 took 0.097s
  training loss:		0.125306
  validation loss:		0.336456
  validation accuracy:		92.28 %
Epoch 592 of 2000 took 0.102s
  training loss:		0.124390
  validation loss:		0.325243
  validation accuracy:		91.85 %
Epoch 593 of 2000 took 0.106s
  training loss:		0.129116
  validation loss:		0.320490
  validation accuracy:		92.17 %
Epoch 594 of 2000 took 0.111s
  training loss:		0.125567
  validation loss:		0.330689
  validation accuracy:		92.39 %
Epoch 595 of 2000 took 0.101s
  training loss:		0.125928
  validation loss:		0.324146
  validation accuracy:		92.61 %
Epoch 596 of 2000 took 0.101s
  training loss:		0.120868
  validation loss:		0.328790
  validation accuracy:		91.63 %
Epoch 597 of 2000 took 0.103s
  training loss:		0.114956
  validation loss:		0.341054
  validation accuracy:		92.61 %
Epoch 598 of 2000 took 0.104s
  training loss:		0.125679
  validation loss:		0.328031
  validation accuracy:		92.83 %
Epoch 599 of 2000 took 0.104s
  training loss:		0.123465
  validation loss:		0.324884
  validation accuracy:		91.74 %
Epoch 600 of 2000 took 0.107s
  training loss:		0.119112
  validation loss:		0.334694
  validation accuracy:		91.96 %
Epoch 601 of 2000 took 0.103s
  training loss:		0.123292
  validation loss:		0.342092
  validation accuracy:		92.07 %
Epoch 602 of 2000 took 0.101s
  training loss:		0.124630
  validation loss:		0.329517
  validation accuracy:		92.61 %
Epoch 603 of 2000 took 0.101s
  training loss:		0.126006
  validation loss:		0.326636
  validation accuracy:		92.83 %
Epoch 604 of 2000 took 0.101s
  training loss:		0.118861
  validation loss:		0.329767
  validation accuracy:		92.72 %
Epoch 605 of 2000 took 0.107s
  training loss:		0.120855
  validation loss:		0.330391
  validation accuracy:		92.17 %
Epoch 606 of 2000 took 0.107s
  training loss:		0.124209
  validation loss:		0.330365
  validation accuracy:		92.39 %
Epoch 607 of 2000 took 0.104s
  training loss:		0.120598
  validation loss:		0.337114
  validation accuracy:		91.74 %
Epoch 608 of 2000 took 0.105s
  training loss:		0.122077
  validation loss:		0.332004
  validation accuracy:		92.17 %
Epoch 609 of 2000 took 0.106s
  training loss:		0.119220
  validation loss:		0.324743
  validation accuracy:		92.07 %
Epoch 610 of 2000 took 0.106s
  training loss:		0.121581
  validation loss:		0.322218
  validation accuracy:		92.17 %
Epoch 611 of 2000 took 0.106s
  training loss:		0.118440
  validation loss:		0.341012
  validation accuracy:		91.85 %
Epoch 612 of 2000 took 0.106s
  training loss:		0.117939
  validation loss:		0.352096
  validation accuracy:		91.74 %
Epoch 613 of 2000 took 0.106s
  training loss:		0.121076
  validation loss:		0.328533
  validation accuracy:		91.74 %
Epoch 614 of 2000 took 0.107s
  training loss:		0.117701
  validation loss:		0.327805
  validation accuracy:		92.50 %
Epoch 615 of 2000 took 0.106s
  training loss:		0.114769
  validation loss:		0.333747
  validation accuracy:		92.61 %
Epoch 616 of 2000 took 0.106s
  training loss:		0.119960
  validation loss:		0.341302
  validation accuracy:		92.17 %
Epoch 617 of 2000 took 0.105s
  training loss:		0.118794
  validation loss:		0.331136
  validation accuracy:		91.96 %
Epoch 618 of 2000 took 0.106s
  training loss:		0.113481
  validation loss:		0.330524
  validation accuracy:		91.85 %
Epoch 619 of 2000 took 0.106s
  training loss:		0.116978
  validation loss:		0.332662
  validation accuracy:		91.74 %
Epoch 620 of 2000 took 0.106s
  training loss:		0.117424
  validation loss:		0.325710
  validation accuracy:		92.17 %
Epoch 621 of 2000 took 0.106s
  training loss:		0.117731
  validation loss:		0.331629
  validation accuracy:		92.17 %
Epoch 622 of 2000 took 0.106s
  training loss:		0.115608
  validation loss:		0.346728
  validation accuracy:		92.61 %
Epoch 623 of 2000 took 0.106s
  training loss:		0.117128
  validation loss:		0.338298
  validation accuracy:		91.52 %
Epoch 624 of 2000 took 0.106s
  training loss:		0.122996
  validation loss:		0.334899
  validation accuracy:		92.61 %
Epoch 625 of 2000 took 0.106s
  training loss:		0.116287
  validation loss:		0.334961
  validation accuracy:		92.61 %
Epoch 626 of 2000 took 0.106s
  training loss:		0.113530
  validation loss:		0.342657
  validation accuracy:		91.85 %
Epoch 627 of 2000 took 0.106s
  training loss:		0.114018
  validation loss:		0.331309
  validation accuracy:		92.07 %
Epoch 628 of 2000 took 0.106s
  training loss:		0.111017
  validation loss:		0.337703
  validation accuracy:		91.96 %
Epoch 629 of 2000 took 0.106s
  training loss:		0.117226
  validation loss:		0.334149
  validation accuracy:		92.93 %
Epoch 630 of 2000 took 0.106s
  training loss:		0.114877
  validation loss:		0.331587
  validation accuracy:		91.85 %
Epoch 631 of 2000 took 0.106s
  training loss:		0.112341
  validation loss:		0.349269
  validation accuracy:		91.52 %
Epoch 632 of 2000 took 0.106s
  training loss:		0.117161
  validation loss:		0.338520
  validation accuracy:		92.72 %
Epoch 633 of 2000 took 0.106s
  training loss:		0.111559
  validation loss:		0.345267
  validation accuracy:		91.96 %
Epoch 634 of 2000 took 0.106s
  training loss:		0.115684
  validation loss:		0.341155
  validation accuracy:		92.50 %
Epoch 635 of 2000 took 0.106s
  training loss:		0.116003
  validation loss:		0.335159
  validation accuracy:		92.28 %
Epoch 636 of 2000 took 0.106s
  training loss:		0.112849
  validation loss:		0.345035
  validation accuracy:		92.28 %
Epoch 637 of 2000 took 0.106s
  training loss:		0.109667
  validation loss:		0.334321
  validation accuracy:		92.83 %
Epoch 638 of 2000 took 0.106s
  training loss:		0.111339
  validation loss:		0.336976
  validation accuracy:		91.96 %
Epoch 639 of 2000 took 0.106s
  training loss:		0.112527
  validation loss:		0.331217
  validation accuracy:		92.17 %
Epoch 640 of 2000 took 0.111s
  training loss:		0.111054
  validation loss:		0.344839
  validation accuracy:		92.39 %
Epoch 641 of 2000 took 0.107s
  training loss:		0.109470
  validation loss:		0.344808
  validation accuracy:		91.74 %
Epoch 642 of 2000 took 0.107s
  training loss:		0.109975
  validation loss:		0.338624
  validation accuracy:		92.28 %
Epoch 643 of 2000 took 0.106s
  training loss:		0.106963
  validation loss:		0.341540
  validation accuracy:		92.17 %
Epoch 644 of 2000 took 0.106s
  training loss:		0.111248
  validation loss:		0.332063
  validation accuracy:		92.07 %
Epoch 645 of 2000 took 0.106s
  training loss:		0.114031
  validation loss:		0.346097
  validation accuracy:		91.96 %
Epoch 646 of 2000 took 0.106s
  training loss:		0.111306
  validation loss:		0.345959
  validation accuracy:		92.28 %
Epoch 647 of 2000 took 0.106s
  training loss:		0.111105
  validation loss:		0.343416
  validation accuracy:		92.83 %
Epoch 648 of 2000 took 0.106s
  training loss:		0.107634
  validation loss:		0.341711
  validation accuracy:		92.61 %
Epoch 649 of 2000 took 0.106s
  training loss:		0.110373
  validation loss:		0.337886
  validation accuracy:		92.72 %
Epoch 650 of 2000 took 0.106s
  training loss:		0.104912
  validation loss:		0.340263
  validation accuracy:		92.07 %
Epoch 651 of 2000 took 0.106s
  training loss:		0.102395
  validation loss:		0.344895
  validation accuracy:		92.17 %
Epoch 652 of 2000 took 0.106s
  training loss:		0.108419
  validation loss:		0.345502
  validation accuracy:		92.39 %
Epoch 653 of 2000 took 0.106s
  training loss:		0.106443
  validation loss:		0.356447
  validation accuracy:		91.41 %
Epoch 654 of 2000 took 0.106s
  training loss:		0.106620
  validation loss:		0.341775
  validation accuracy:		92.50 %
Epoch 655 of 2000 took 0.106s
  training loss:		0.109250
  validation loss:		0.345625
  validation accuracy:		91.85 %
Epoch 656 of 2000 took 0.106s
  training loss:		0.108060
  validation loss:		0.336101
  validation accuracy:		93.04 %
Epoch 657 of 2000 took 0.106s
  training loss:		0.105001
  validation loss:		0.359039
  validation accuracy:		92.17 %
Epoch 658 of 2000 took 0.106s
  training loss:		0.109287
  validation loss:		0.345474
  validation accuracy:		92.50 %
Epoch 659 of 2000 took 0.106s
  training loss:		0.108225
  validation loss:		0.339387
  validation accuracy:		91.74 %
Epoch 660 of 2000 took 0.106s
  training loss:		0.106552
  validation loss:		0.344352
  validation accuracy:		91.74 %
Epoch 661 of 2000 took 0.106s
  training loss:		0.105775
  validation loss:		0.340286
  validation accuracy:		91.96 %
Epoch 662 of 2000 took 0.105s
  training loss:		0.105727
  validation loss:		0.342268
  validation accuracy:		92.28 %
Epoch 663 of 2000 took 0.106s
  training loss:		0.105691
  validation loss:		0.346073
  validation accuracy:		92.17 %
Epoch 664 of 2000 took 0.106s
  training loss:		0.101494
  validation loss:		0.342248
  validation accuracy:		91.96 %
Epoch 665 of 2000 took 0.106s
  training loss:		0.099522
  validation loss:		0.350880
  validation accuracy:		91.85 %
Epoch 666 of 2000 took 0.106s
  training loss:		0.109554
  validation loss:		0.351384
  validation accuracy:		92.28 %
Epoch 667 of 2000 took 0.106s
  training loss:		0.104559
  validation loss:		0.340455
  validation accuracy:		92.39 %
Epoch 668 of 2000 took 0.106s
  training loss:		0.108960
  validation loss:		0.355883
  validation accuracy:		92.28 %
Epoch 669 of 2000 took 0.106s
  training loss:		0.102843
  validation loss:		0.352549
  validation accuracy:		92.61 %
Epoch 670 of 2000 took 0.106s
  training loss:		0.102991
  validation loss:		0.358737
  validation accuracy:		92.07 %
Epoch 671 of 2000 took 0.107s
  training loss:		0.105952
  validation loss:		0.345263
  validation accuracy:		92.61 %
Epoch 672 of 2000 took 0.106s
  training loss:		0.103169
  validation loss:		0.345660
  validation accuracy:		92.39 %
Epoch 673 of 2000 took 0.106s
  training loss:		0.102980
  validation loss:		0.354937
  validation accuracy:		92.28 %
Epoch 674 of 2000 took 0.106s
  training loss:		0.110165
  validation loss:		0.354270
  validation accuracy:		91.96 %
Epoch 675 of 2000 took 0.108s
  training loss:		0.104145
  validation loss:		0.352545
  validation accuracy:		92.17 %
Epoch 676 of 2000 took 0.109s
  training loss:		0.104921
  validation loss:		0.350460
  validation accuracy:		91.85 %
Epoch 677 of 2000 took 0.106s
  training loss:		0.104363
  validation loss:		0.356132
  validation accuracy:		92.72 %
Epoch 678 of 2000 took 0.106s
  training loss:		0.101865
  validation loss:		0.363563
  validation accuracy:		92.28 %
Epoch 679 of 2000 took 0.106s
  training loss:		0.100161
  validation loss:		0.357738
  validation accuracy:		91.85 %
Epoch 680 of 2000 took 0.106s
  training loss:		0.102309
  validation loss:		0.352931
  validation accuracy:		91.96 %
Epoch 681 of 2000 took 0.106s
  training loss:		0.101826
  validation loss:		0.351437
  validation accuracy:		92.07 %
Epoch 682 of 2000 took 0.106s
  training loss:		0.103126
  validation loss:		0.368089
  validation accuracy:		92.28 %
Epoch 683 of 2000 took 0.106s
  training loss:		0.101212
  validation loss:		0.345264
  validation accuracy:		92.17 %
Epoch 684 of 2000 took 0.106s
  training loss:		0.103210
  validation loss:		0.353155
  validation accuracy:		91.74 %
Epoch 685 of 2000 took 0.106s
  training loss:		0.102015
  validation loss:		0.356637
  validation accuracy:		92.61 %
Epoch 686 of 2000 took 0.106s
  training loss:		0.097679
  validation loss:		0.353666
  validation accuracy:		92.28 %
Epoch 687 of 2000 took 0.106s
  training loss:		0.097460
  validation loss:		0.354021
  validation accuracy:		91.74 %
Epoch 688 of 2000 took 0.106s
  training loss:		0.096969
  validation loss:		0.350868
  validation accuracy:		91.74 %
Epoch 689 of 2000 took 0.106s
  training loss:		0.099158
  validation loss:		0.356128
  validation accuracy:		92.17 %
Epoch 690 of 2000 took 0.106s
  training loss:		0.096649
  validation loss:		0.352002
  validation accuracy:		91.96 %
Epoch 691 of 2000 took 0.106s
  training loss:		0.098481
  validation loss:		0.351558
  validation accuracy:		91.85 %
Epoch 692 of 2000 took 0.106s
  training loss:		0.097618
  validation loss:		0.353954
  validation accuracy:		91.85 %
Epoch 693 of 2000 took 0.106s
  training loss:		0.097550
  validation loss:		0.360268
  validation accuracy:		91.30 %
Epoch 694 of 2000 took 0.106s
  training loss:		0.102277
  validation loss:		0.356841
  validation accuracy:		92.28 %
Epoch 695 of 2000 took 0.106s
  training loss:		0.095005
  validation loss:		0.358220
  validation accuracy:		92.39 %
Epoch 696 of 2000 took 0.111s
  training loss:		0.099427
  validation loss:		0.357599
  validation accuracy:		91.63 %
Epoch 697 of 2000 took 0.107s
  training loss:		0.102457
  validation loss:		0.357087
  validation accuracy:		91.52 %
Epoch 698 of 2000 took 0.106s
  training loss:		0.097377
  validation loss:		0.355187
  validation accuracy:		91.74 %
Epoch 699 of 2000 took 0.107s
  training loss:		0.097109
  validation loss:		0.365615
  validation accuracy:		92.07 %
Epoch 700 of 2000 took 0.106s
  training loss:		0.096423
  validation loss:		0.375791
  validation accuracy:		91.96 %
Epoch 701 of 2000 took 0.106s
  training loss:		0.098253
  validation loss:		0.370937
  validation accuracy:		91.96 %
Epoch 702 of 2000 took 0.106s
  training loss:		0.097316
  validation loss:		0.360561
  validation accuracy:		92.61 %
Epoch 703 of 2000 took 0.106s
  training loss:		0.097365
  validation loss:		0.350830
  validation accuracy:		91.85 %
Epoch 704 of 2000 took 0.106s
  training loss:		0.096633
  validation loss:		0.363741
  validation accuracy:		91.85 %
Epoch 705 of 2000 took 0.106s
  training loss:		0.094643
  validation loss:		0.360835
  validation accuracy:		91.85 %
Epoch 706 of 2000 took 0.106s
  training loss:		0.098629
  validation loss:		0.369025
  validation accuracy:		91.74 %
Epoch 707 of 2000 took 0.106s
  training loss:		0.095588
  validation loss:		0.364045
  validation accuracy:		92.50 %
Epoch 708 of 2000 took 0.106s
  training loss:		0.091488
  validation loss:		0.371194
  validation accuracy:		92.50 %
Epoch 709 of 2000 took 0.106s
  training loss:		0.093804
  validation loss:		0.389769
  validation accuracy:		92.17 %
Epoch 710 of 2000 took 0.106s
  training loss:		0.094275
  validation loss:		0.372884
  validation accuracy:		92.50 %
Epoch 711 of 2000 took 0.106s
  training loss:		0.089763
  validation loss:		0.359399
  validation accuracy:		91.85 %
Epoch 712 of 2000 took 0.106s
  training loss:		0.091424
  validation loss:		0.366575
  validation accuracy:		91.30 %
Epoch 713 of 2000 took 0.106s
  training loss:		0.092950
  validation loss:		0.362489
  validation accuracy:		92.17 %
Epoch 714 of 2000 took 0.106s
  training loss:		0.096927
  validation loss:		0.368631
  validation accuracy:		92.72 %
Epoch 715 of 2000 took 0.106s
  training loss:		0.094624
  validation loss:		0.388300
  validation accuracy:		91.30 %
Epoch 716 of 2000 took 0.106s
  training loss:		0.093608
  validation loss:		0.352971
  validation accuracy:		91.96 %
Epoch 717 of 2000 took 0.106s
  training loss:		0.092317
  validation loss:		0.362589
  validation accuracy:		92.07 %
Epoch 718 of 2000 took 0.106s
  training loss:		0.093076
  validation loss:		0.366248
  validation accuracy:		91.52 %
Epoch 719 of 2000 took 0.106s
  training loss:		0.094934
  validation loss:		0.357645
  validation accuracy:		92.17 %
Epoch 720 of 2000 took 0.106s
  training loss:		0.096584
  validation loss:		0.360451
  validation accuracy:		91.74 %
Epoch 721 of 2000 took 0.106s
  training loss:		0.092435
  validation loss:		0.361874
  validation accuracy:		91.74 %
Epoch 722 of 2000 took 0.106s
  training loss:		0.096605
  validation loss:		0.362343
  validation accuracy:		91.85 %
Epoch 723 of 2000 took 0.106s
  training loss:		0.095179
  validation loss:		0.371449
  validation accuracy:		91.41 %
Epoch 724 of 2000 took 0.106s
  training loss:		0.091510
  validation loss:		0.378174
  validation accuracy:		92.17 %
Epoch 725 of 2000 took 0.106s
  training loss:		0.094542
  validation loss:		0.368235
  validation accuracy:		92.17 %
Epoch 726 of 2000 took 0.106s
  training loss:		0.089330
  validation loss:		0.367387
  validation accuracy:		92.39 %
Epoch 727 of 2000 took 0.106s
  training loss:		0.093298
  validation loss:		0.361605
  validation accuracy:		92.61 %
Epoch 728 of 2000 took 0.107s
  training loss:		0.090382
  validation loss:		0.361001
  validation accuracy:		91.74 %
Epoch 729 of 2000 took 0.106s
  training loss:		0.091568
  validation loss:		0.368501
  validation accuracy:		92.17 %
Epoch 730 of 2000 took 0.106s
  training loss:		0.089016
  validation loss:		0.379691
  validation accuracy:		92.28 %
Epoch 731 of 2000 took 0.106s
  training loss:		0.094796
  validation loss:		0.369978
  validation accuracy:		91.74 %
Epoch 732 of 2000 took 0.106s
  training loss:		0.089689
  validation loss:		0.369996
  validation accuracy:		92.28 %
Epoch 733 of 2000 took 0.106s
  training loss:		0.091812
  validation loss:		0.372196
  validation accuracy:		91.74 %
Epoch 734 of 2000 took 0.106s
  training loss:		0.087883
  validation loss:		0.381147
  validation accuracy:		92.17 %
Epoch 735 of 2000 took 0.110s
  training loss:		0.088872
  validation loss:		0.379790
  validation accuracy:		91.96 %
Epoch 736 of 2000 took 0.107s
  training loss:		0.089520
  validation loss:		0.385140
  validation accuracy:		91.52 %
Epoch 737 of 2000 took 0.106s
  training loss:		0.085297
  validation loss:		0.387268
  validation accuracy:		91.74 %
Epoch 738 of 2000 took 0.106s
  training loss:		0.091612
  validation loss:		0.371430
  validation accuracy:		91.74 %
Epoch 739 of 2000 took 0.106s
  training loss:		0.089856
  validation loss:		0.371607
  validation accuracy:		91.85 %
Epoch 740 of 2000 took 0.106s
  training loss:		0.090103
  validation loss:		0.375880
  validation accuracy:		92.39 %
Epoch 741 of 2000 took 0.106s
  training loss:		0.090081
  validation loss:		0.371521
  validation accuracy:		91.74 %
Epoch 742 of 2000 took 0.106s
  training loss:		0.086725
  validation loss:		0.379027
  validation accuracy:		91.63 %
Epoch 743 of 2000 took 0.106s
  training loss:		0.084717
  validation loss:		0.379893
  validation accuracy:		91.85 %
Epoch 744 of 2000 took 0.106s
  training loss:		0.086556
  validation loss:		0.381649
  validation accuracy:		91.63 %
Epoch 745 of 2000 took 0.106s
  training loss:		0.087432
  validation loss:		0.369371
  validation accuracy:		91.74 %
Epoch 746 of 2000 took 0.106s
  training loss:		0.085574
  validation loss:		0.381530
  validation accuracy:		92.07 %
Epoch 747 of 2000 took 0.106s
  training loss:		0.091071
  validation loss:		0.393605
  validation accuracy:		91.41 %
Epoch 748 of 2000 took 0.106s
  training loss:		0.087918
  validation loss:		0.382046
  validation accuracy:		92.17 %
Epoch 749 of 2000 took 0.106s
  training loss:		0.085321
  validation loss:		0.377474
  validation accuracy:		92.39 %
Epoch 750 of 2000 took 0.106s
  training loss:		0.087197
  validation loss:		0.382892
  validation accuracy:		92.39 %
Epoch 751 of 2000 took 0.106s
  training loss:		0.093158
  validation loss:		0.381829
  validation accuracy:		91.63 %
Epoch 752 of 2000 took 0.106s
  training loss:		0.084110
  validation loss:		0.379046
  validation accuracy:		92.28 %
Epoch 753 of 2000 took 0.106s
  training loss:		0.086155
  validation loss:		0.406424
  validation accuracy:		91.41 %
Epoch 754 of 2000 took 0.106s
  training loss:		0.089497
  validation loss:		0.399663
  validation accuracy:		91.20 %
Epoch 755 of 2000 took 0.106s
  training loss:		0.093521
  validation loss:		0.391325
  validation accuracy:		92.28 %
Epoch 756 of 2000 took 0.107s
  training loss:		0.086292
  validation loss:		0.390806
  validation accuracy:		91.74 %
Epoch 757 of 2000 took 0.106s
  training loss:		0.086753
  validation loss:		0.381020
  validation accuracy:		91.96 %
Epoch 758 of 2000 took 0.106s
  training loss:		0.088720
  validation loss:		0.375622
  validation accuracy:		92.07 %
Epoch 759 of 2000 took 0.106s
  training loss:		0.085789
  validation loss:		0.373173
  validation accuracy:		92.17 %
Epoch 760 of 2000 took 0.106s
  training loss:		0.088161
  validation loss:		0.381383
  validation accuracy:		91.74 %
Epoch 761 of 2000 took 0.106s
  training loss:		0.086223
  validation loss:		0.384009
  validation accuracy:		91.96 %
Epoch 762 of 2000 took 0.106s
  training loss:		0.086291
  validation loss:		0.389485
  validation accuracy:		91.74 %
Epoch 763 of 2000 took 0.112s
  training loss:		0.083409
  validation loss:		0.391897
  validation accuracy:		91.74 %
Epoch 764 of 2000 took 0.106s
  training loss:		0.088874
  validation loss:		0.390283
  validation accuracy:		91.74 %
Epoch 765 of 2000 took 0.106s
  training loss:		0.081905
  validation loss:		0.386331
  validation accuracy:		91.96 %
Epoch 766 of 2000 took 0.106s
  training loss:		0.087925
  validation loss:		0.386928
  validation accuracy:		92.17 %
Epoch 767 of 2000 took 0.106s
  training loss:		0.082868
  validation loss:		0.413901
  validation accuracy:		91.41 %
Epoch 768 of 2000 took 0.106s
  training loss:		0.082177
  validation loss:		0.388547
  validation accuracy:		91.63 %
Epoch 769 of 2000 took 0.106s
  training loss:		0.081553
  validation loss:		0.392336
  validation accuracy:		91.96 %
Epoch 770 of 2000 took 0.106s
  training loss:		0.086055
  validation loss:		0.409115
  validation accuracy:		91.96 %
Epoch 771 of 2000 took 0.106s
  training loss:		0.084353
  validation loss:		0.393081
  validation accuracy:		91.52 %
Epoch 772 of 2000 took 0.106s
  training loss:		0.083417
  validation loss:		0.396515
  validation accuracy:		92.07 %
Epoch 773 of 2000 took 0.106s
  training loss:		0.082692
  validation loss:		0.396295
  validation accuracy:		91.52 %
Epoch 774 of 2000 took 0.106s
  training loss:		0.081664
  validation loss:		0.408936
  validation accuracy:		91.74 %
Epoch 775 of 2000 took 0.106s
  training loss:		0.081459
  validation loss:		0.397660
  validation accuracy:		91.52 %
Epoch 776 of 2000 took 0.106s
  training loss:		0.084258
  validation loss:		0.396344
  validation accuracy:		91.63 %
Epoch 777 of 2000 took 0.106s
  training loss:		0.077644
  validation loss:		0.393083
  validation accuracy:		91.96 %
Epoch 778 of 2000 took 0.106s
  training loss:		0.080482
  validation loss:		0.397848
  validation accuracy:		91.20 %
Epoch 779 of 2000 took 0.106s
  training loss:		0.084840
  validation loss:		0.394402
  validation accuracy:		91.63 %
Epoch 780 of 2000 took 0.106s
  training loss:		0.079768
  validation loss:		0.394594
  validation accuracy:		91.74 %
Epoch 781 of 2000 took 0.102s
  training loss:		0.080070
  validation loss:		0.396160
  validation accuracy:		92.39 %
Epoch 782 of 2000 took 0.117s
  training loss:		0.080269
  validation loss:		0.418130
  validation accuracy:		92.07 %
Epoch 783 of 2000 took 0.139s
  training loss:		0.081814
  validation loss:		0.386583
  validation accuracy:		91.63 %
Epoch 784 of 2000 took 0.115s
  training loss:		0.083536
  validation loss:		0.416459
  validation accuracy:		91.85 %
Epoch 785 of 2000 took 0.103s
  training loss:		0.078371
  validation loss:		0.392105
  validation accuracy:		92.07 %
Epoch 786 of 2000 took 0.104s
  training loss:		0.076457
  validation loss:		0.394693
  validation accuracy:		91.74 %
Epoch 787 of 2000 took 0.100s
  training loss:		0.085055
  validation loss:		0.393952
  validation accuracy:		92.07 %
Epoch 788 of 2000 took 0.104s
  training loss:		0.077763
  validation loss:		0.400988
  validation accuracy:		92.17 %
Epoch 789 of 2000 took 0.103s
  training loss:		0.081318
  validation loss:		0.398656
  validation accuracy:		92.39 %
Epoch 790 of 2000 took 0.101s
  training loss:		0.085354
  validation loss:		0.392877
  validation accuracy:		92.39 %
Epoch 791 of 2000 took 0.101s
  training loss:		0.080420
  validation loss:		0.400279
  validation accuracy:		92.07 %
Epoch 792 of 2000 took 0.101s
  training loss:		0.077784
  validation loss:		0.405629
  validation accuracy:		91.85 %
Epoch 793 of 2000 took 0.100s
  training loss:		0.077409
  validation loss:		0.419614
  validation accuracy:		91.30 %
Epoch 794 of 2000 took 0.101s
  training loss:		0.078068
  validation loss:		0.396760
  validation accuracy:		91.74 %
Epoch 795 of 2000 took 0.111s
  training loss:		0.081405
  validation loss:		0.407490
  validation accuracy:		91.41 %
Epoch 796 of 2000 took 0.101s
  training loss:		0.081154
  validation loss:		0.394357
  validation accuracy:		91.96 %
Epoch 797 of 2000 took 0.101s
  training loss:		0.078444
  validation loss:		0.417876
  validation accuracy:		91.52 %
Epoch 798 of 2000 took 0.101s
  training loss:		0.079025
  validation loss:		0.410512
  validation accuracy:		91.63 %
Epoch 799 of 2000 took 0.102s
  training loss:		0.079758
  validation loss:		0.398582
  validation accuracy:		92.17 %
Epoch 800 of 2000 took 0.100s
  training loss:		0.075024
  validation loss:		0.398342
  validation accuracy:		91.96 %
Epoch 801 of 2000 took 0.101s
  training loss:		0.079377
  validation loss:		0.416608
  validation accuracy:		92.28 %
Epoch 802 of 2000 took 0.101s
  training loss:		0.081187
  validation loss:		0.413677
  validation accuracy:		91.30 %
Epoch 803 of 2000 took 0.101s
  training loss:		0.075502
  validation loss:		0.411533
  validation accuracy:		91.85 %
Epoch 804 of 2000 took 0.101s
  training loss:		0.076367
  validation loss:		0.407465
  validation accuracy:		91.74 %
Epoch 805 of 2000 took 0.105s
  training loss:		0.076832
  validation loss:		0.409301
  validation accuracy:		92.07 %
Epoch 806 of 2000 took 0.102s
  training loss:		0.075487
  validation loss:		0.403650
  validation accuracy:		91.74 %
Epoch 807 of 2000 took 0.100s
  training loss:		0.076416
  validation loss:		0.418451
  validation accuracy:		91.52 %
Epoch 808 of 2000 took 0.101s
  training loss:		0.077071
  validation loss:		0.402274
  validation accuracy:		92.07 %
Epoch 809 of 2000 took 0.101s
  training loss:		0.077566
  validation loss:		0.416782
  validation accuracy:		91.96 %
Epoch 810 of 2000 took 0.101s
  training loss:		0.076074
  validation loss:		0.405727
  validation accuracy:		91.85 %
Epoch 811 of 2000 took 0.101s
  training loss:		0.075993
  validation loss:		0.423774
  validation accuracy:		91.41 %
Epoch 812 of 2000 took 0.101s
  training loss:		0.075279
  validation loss:		0.397973
  validation accuracy:		91.96 %
Epoch 813 of 2000 took 0.101s
  training loss:		0.074690
  validation loss:		0.450107
  validation accuracy:		91.30 %
Epoch 814 of 2000 took 0.101s
  training loss:		0.079706
  validation loss:		0.429091
  validation accuracy:		91.63 %
Epoch 815 of 2000 took 0.105s
  training loss:		0.081488
  validation loss:		0.417885
  validation accuracy:		92.07 %
Epoch 816 of 2000 took 0.102s
  training loss:		0.078494
  validation loss:		0.421887
  validation accuracy:		91.41 %
Epoch 817 of 2000 took 0.101s
  training loss:		0.077233
  validation loss:		0.423596
  validation accuracy:		91.85 %
Epoch 818 of 2000 took 0.101s
  training loss:		0.078593
  validation loss:		0.417866
  validation accuracy:		91.85 %
Epoch 819 of 2000 took 0.102s
  training loss:		0.076019
  validation loss:		0.404647
  validation accuracy:		91.85 %
Epoch 820 of 2000 took 0.101s
  training loss:		0.077521
  validation loss:		0.413872
  validation accuracy:		91.96 %
Epoch 821 of 2000 took 0.102s
  training loss:		0.075978
  validation loss:		0.432968
  validation accuracy:		91.96 %
Epoch 822 of 2000 took 0.102s
  training loss:		0.079060
  validation loss:		0.418889
  validation accuracy:		91.96 %
Epoch 823 of 2000 took 0.145s
  training loss:		0.067003
  validation loss:		0.408578
  validation accuracy:		92.17 %
Epoch 824 of 2000 took 0.163s
  training loss:		0.072530
  validation loss:		0.412034
  validation accuracy:		91.63 %
Epoch 825 of 2000 took 0.132s
  training loss:		0.073506
  validation loss:		0.418731
  validation accuracy:		91.74 %
Epoch 826 of 2000 took 0.159s
  training loss:		0.073093
  validation loss:		0.421878
  validation accuracy:		91.85 %
Epoch 827 of 2000 took 0.108s
  training loss:		0.070417
  validation loss:		0.414391
  validation accuracy:		92.17 %
Epoch 828 of 2000 took 0.107s
  training loss:		0.070648
  validation loss:		0.422426
  validation accuracy:		91.63 %
Epoch 829 of 2000 took 0.134s
  training loss:		0.071390
  validation loss:		0.417677
  validation accuracy:		91.74 %
Epoch 830 of 2000 took 0.168s
  training loss:		0.069633
  validation loss:		0.419196
  validation accuracy:		91.63 %
Epoch 831 of 2000 took 0.173s
  training loss:		0.075946
  validation loss:		0.420867
  validation accuracy:		91.74 %
Epoch 832 of 2000 took 0.170s
  training loss:		0.071553
  validation loss:		0.418646
  validation accuracy:		91.85 %
Epoch 833 of 2000 took 0.166s
  training loss:		0.069526
  validation loss:		0.429075
  validation accuracy:		91.96 %
Epoch 834 of 2000 took 0.166s
  training loss:		0.072037
  validation loss:		0.441676
  validation accuracy:		91.63 %
Epoch 835 of 2000 took 0.170s
  training loss:		0.070651
  validation loss:		0.430640
  validation accuracy:		91.41 %
Epoch 836 of 2000 took 0.167s
  training loss:		0.075954
  validation loss:		0.434135
  validation accuracy:		91.52 %
Epoch 837 of 2000 took 0.182s
  training loss:		0.072700
  validation loss:		0.431155
  validation accuracy:		91.96 %
Epoch 838 of 2000 took 0.165s
  training loss:		0.069552
  validation loss:		0.425769
  validation accuracy:		92.07 %
Epoch 839 of 2000 took 0.165s
  training loss:		0.072807
  validation loss:		0.432372
  validation accuracy:		92.07 %
Epoch 840 of 2000 took 0.169s
  training loss:		0.069872
  validation loss:		0.435587
  validation accuracy:		91.74 %
Epoch 841 of 2000 took 0.166s
  training loss:		0.073315
  validation loss:		0.418893
  validation accuracy:		91.96 %
Epoch 842 of 2000 took 0.171s
  training loss:		0.070364
  validation loss:		0.413699
  validation accuracy:		91.85 %
Epoch 843 of 2000 took 0.171s
  training loss:		0.068241
  validation loss:		0.428576
  validation accuracy:		91.96 %
Epoch 844 of 2000 took 0.166s
  training loss:		0.076902
  validation loss:		0.432718
  validation accuracy:		91.63 %
Epoch 845 of 2000 took 0.171s
  training loss:		0.069462
  validation loss:		0.433633
  validation accuracy:		91.85 %
Epoch 846 of 2000 took 0.166s
  training loss:		0.066323
  validation loss:		0.443264
  validation accuracy:		91.41 %
Epoch 847 of 2000 took 0.172s
  training loss:		0.069200
  validation loss:		0.428499
  validation accuracy:		91.85 %
Epoch 848 of 2000 took 0.166s
  training loss:		0.066337
  validation loss:		0.449253
  validation accuracy:		91.85 %
Epoch 849 of 2000 took 0.166s
  training loss:		0.070373
  validation loss:		0.429333
  validation accuracy:		92.07 %
Epoch 850 of 2000 took 0.171s
  training loss:		0.069713
  validation loss:		0.439260
  validation accuracy:		91.74 %
Epoch 851 of 2000 took 0.170s
  training loss:		0.067827
  validation loss:		0.447221
  validation accuracy:		91.85 %
Epoch 852 of 2000 took 0.172s
  training loss:		0.070983
  validation loss:		0.442667
  validation accuracy:		91.52 %
Epoch 853 of 2000 took 0.166s
  training loss:		0.074446
  validation loss:		0.434533
  validation accuracy:		91.52 %
Epoch 854 of 2000 took 0.165s
  training loss:		0.074170
  validation loss:		0.465885
  validation accuracy:		91.30 %
Epoch 855 of 2000 took 0.170s
  training loss:		0.072751
  validation loss:		0.450606
  validation accuracy:		91.96 %
Epoch 856 of 2000 took 0.165s
  training loss:		0.072981
  validation loss:		0.430363
  validation accuracy:		91.96 %
Epoch 857 of 2000 took 0.170s
  training loss:		0.070473
  validation loss:		0.447260
  validation accuracy:		91.09 %
Epoch 858 of 2000 took 0.165s
  training loss:		0.071795
  validation loss:		0.433763
  validation accuracy:		91.74 %
Epoch 859 of 2000 took 0.165s
  training loss:		0.068627
  validation loss:		0.431172
  validation accuracy:		91.63 %
Epoch 860 of 2000 took 0.170s
  training loss:		0.073651
  validation loss:		0.451533
  validation accuracy:		91.52 %
Epoch 861 of 2000 took 0.165s
  training loss:		0.068580
  validation loss:		0.444071
  validation accuracy:		91.96 %
Epoch 862 of 2000 took 0.169s
  training loss:		0.065541
  validation loss:		0.439949
  validation accuracy:		91.85 %
Epoch 863 of 2000 took 0.170s
  training loss:		0.069169
  validation loss:		0.439122
  validation accuracy:		91.85 %
Epoch 864 of 2000 took 0.165s
  training loss:		0.066902
  validation loss:		0.448375
  validation accuracy:		91.74 %
Epoch 865 of 2000 took 0.169s
  training loss:		0.065154
  validation loss:		0.442797
  validation accuracy:		92.17 %
Epoch 866 of 2000 took 0.165s
  training loss:		0.064788
  validation loss:		0.441132
  validation accuracy:		91.85 %
Epoch 867 of 2000 took 0.169s
  training loss:		0.067632
  validation loss:		0.442849
  validation accuracy:		91.41 %
Epoch 868 of 2000 took 0.166s
  training loss:		0.066900
  validation loss:		0.436492
  validation accuracy:		92.07 %
Epoch 869 of 2000 took 0.165s
  training loss:		0.066020
  validation loss:		0.438070
  validation accuracy:		91.63 %
Epoch 870 of 2000 took 0.169s
  training loss:		0.066317
  validation loss:		0.435060
  validation accuracy:		91.85 %
Epoch 871 of 2000 took 0.165s
  training loss:		0.064839
  validation loss:		0.485994
  validation accuracy:		90.76 %
Epoch 872 of 2000 took 0.169s
  training loss:		0.069605
  validation loss:		0.433996
  validation accuracy:		91.63 %
Epoch 873 of 2000 took 0.165s
  training loss:		0.066296
  validation loss:		0.439635
  validation accuracy:		91.52 %
Epoch 874 of 2000 took 0.166s
  training loss:		0.064204
  validation loss:		0.451097
  validation accuracy:		92.07 %
Epoch 875 of 2000 took 0.168s
  training loss:		0.067432
  validation loss:		0.430577
  validation accuracy:		91.52 %
Epoch 876 of 2000 took 0.166s
  training loss:		0.065113
  validation loss:		0.461803
  validation accuracy:		91.74 %
Epoch 877 of 2000 took 0.168s
  training loss:		0.066442
  validation loss:		0.452068
  validation accuracy:		91.52 %
Epoch 878 of 2000 took 0.166s
  training loss:		0.065275
  validation loss:		0.460931
  validation accuracy:		91.85 %
Epoch 879 of 2000 took 0.166s
  training loss:		0.062369
  validation loss:		0.459868
  validation accuracy:		91.74 %
Epoch 880 of 2000 took 0.168s
  training loss:		0.064051
  validation loss:		0.444655
  validation accuracy:		91.74 %
Epoch 881 of 2000 took 0.167s
  training loss:		0.062234
  validation loss:		0.446965
  validation accuracy:		91.52 %
Epoch 882 of 2000 took 0.172s
  training loss:		0.065750
  validation loss:		0.494470
  validation accuracy:		91.41 %
Epoch 883 of 2000 took 0.166s
  training loss:		0.066600
  validation loss:		0.452797
  validation accuracy:		91.74 %
Epoch 884 of 2000 took 0.167s
  training loss:		0.066639
  validation loss:		0.445559
  validation accuracy:		91.63 %
Epoch 885 of 2000 took 0.167s
  training loss:		0.063134
  validation loss:		0.446696
  validation accuracy:		91.63 %
Epoch 886 of 2000 took 0.167s
  training loss:		0.066852
  validation loss:		0.455041
  validation accuracy:		91.74 %
Epoch 887 of 2000 took 0.166s
  training loss:		0.059654
  validation loss:		0.467924
  validation accuracy:		91.52 %
Epoch 888 of 2000 took 0.166s
  training loss:		0.061845
  validation loss:		0.460888
  validation accuracy:		91.85 %
Epoch 889 of 2000 took 0.168s
  training loss:		0.060201
  validation loss:		0.473240
  validation accuracy:		91.41 %
Epoch 890 of 2000 took 0.166s
  training loss:		0.063775
  validation loss:		0.459005
  validation accuracy:		91.96 %
Epoch 891 of 2000 took 0.168s
  training loss:		0.060932
  validation loss:		0.472089
  validation accuracy:		91.52 %
Epoch 892 of 2000 took 0.166s
  training loss:		0.062481
  validation loss:		0.467207
  validation accuracy:		91.63 %
Epoch 893 of 2000 took 0.165s
  training loss:		0.066174
  validation loss:		0.462741
  validation accuracy:		91.85 %
Epoch 894 of 2000 took 0.168s
  training loss:		0.065330
  validation loss:		0.451727
  validation accuracy:		91.85 %
Epoch 895 of 2000 took 0.166s
  training loss:		0.060889
  validation loss:		0.472831
  validation accuracy:		91.52 %
Epoch 896 of 2000 took 0.169s
  training loss:		0.067193
  validation loss:		0.467708
  validation accuracy:		91.74 %
Epoch 897 of 2000 took 0.165s
  training loss:		0.063542
  validation loss:		0.479309
  validation accuracy:		91.52 %
Epoch 898 of 2000 took 0.166s
  training loss:		0.064580
  validation loss:		0.466123
  validation accuracy:		91.74 %
Epoch 899 of 2000 took 0.168s
  training loss:		0.064256
  validation loss:		0.481438
  validation accuracy:		91.85 %
Epoch 900 of 2000 took 0.166s
  training loss:		0.061960
  validation loss:		0.467845
  validation accuracy:		91.52 %
Epoch 901 of 2000 took 0.169s
  training loss:		0.060240
  validation loss:		0.468864
  validation accuracy:		92.07 %
Epoch 902 of 2000 took 0.165s
  training loss:		0.064352
  validation loss:		0.457566
  validation accuracy:		92.07 %
Epoch 903 of 2000 took 0.165s
  training loss:		0.059863
  validation loss:		0.465787
  validation accuracy:		91.63 %
Epoch 904 of 2000 took 0.169s
  training loss:		0.059333
  validation loss:		0.480994
  validation accuracy:		91.41 %
Epoch 905 of 2000 took 0.166s
  training loss:		0.057584
  validation loss:		0.482432
  validation accuracy:		91.41 %
Epoch 906 of 2000 took 0.170s
  training loss:		0.073254
  validation loss:		0.468394
  validation accuracy:		91.96 %
Epoch 907 of 2000 took 0.165s
  training loss:		0.060880
  validation loss:		0.475465
  validation accuracy:		91.63 %
Epoch 908 of 2000 took 0.165s
  training loss:		0.064252
  validation loss:		0.493856
  validation accuracy:		91.63 %
Epoch 909 of 2000 took 0.169s
  training loss:		0.062112
  validation loss:		0.477329
  validation accuracy:		92.07 %
Epoch 910 of 2000 took 0.165s
  training loss:		0.059895
  validation loss:		0.476601
  validation accuracy:		91.41 %
Epoch 911 of 2000 took 0.170s
  training loss:		0.063005
  validation loss:		0.485564
  validation accuracy:		91.63 %
Epoch 912 of 2000 took 0.170s
  training loss:		0.066301
  validation loss:		0.467551
  validation accuracy:		91.41 %
Epoch 913 of 2000 took 0.165s
  training loss:		0.059523
  validation loss:		0.469456
  validation accuracy:		91.63 %
Epoch 914 of 2000 took 0.169s
  training loss:		0.061677
  validation loss:		0.465376
  validation accuracy:		91.52 %
Epoch 915 of 2000 took 0.165s
  training loss:		0.063955
  validation loss:		0.480717
  validation accuracy:		91.74 %
Epoch 916 of 2000 took 0.170s
  training loss:		0.060296
  validation loss:		0.482583
  validation accuracy:		91.74 %
Epoch 917 of 2000 took 0.165s
  training loss:		0.059871
  validation loss:		0.485650
  validation accuracy:		91.74 %
Epoch 918 of 2000 took 0.165s
  training loss:		0.058492
  validation loss:		0.479588
  validation accuracy:		91.74 %
Epoch 919 of 2000 took 0.170s
  training loss:		0.055117
  validation loss:		0.483581
  validation accuracy:		91.74 %
Epoch 920 of 2000 took 0.165s
  training loss:		0.056711
  validation loss:		0.481523
  validation accuracy:		91.30 %
Epoch 921 of 2000 took 0.170s
  training loss:		0.057751
  validation loss:		0.473090
  validation accuracy:		91.41 %
Epoch 922 of 2000 took 0.165s
  training loss:		0.057361
  validation loss:		0.483745
  validation accuracy:		91.74 %
Epoch 923 of 2000 took 0.165s
  training loss:		0.061302
  validation loss:		0.482029
  validation accuracy:		91.30 %
Epoch 924 of 2000 took 0.170s
  training loss:		0.059064
  validation loss:		0.477206
  validation accuracy:		91.96 %
Epoch 925 of 2000 took 0.164s
  training loss:		0.071441
  validation loss:		0.496394
  validation accuracy:		91.52 %
Epoch 926 of 2000 took 0.170s
  training loss:		0.057887
  validation loss:		0.475309
  validation accuracy:		91.41 %
Epoch 927 of 2000 took 0.165s
  training loss:		0.058385
  validation loss:		0.476794
  validation accuracy:		91.96 %
Epoch 928 of 2000 took 0.164s
  training loss:		0.060359
  validation loss:		0.501184
  validation accuracy:		91.30 %
Epoch 929 of 2000 took 0.170s
  training loss:		0.056329
  validation loss:		0.509324
  validation accuracy:		91.41 %
Epoch 930 of 2000 took 0.165s
  training loss:		0.062106
  validation loss:		0.490666
  validation accuracy:		91.52 %
Epoch 931 of 2000 took 0.170s
  training loss:		0.059950
  validation loss:		0.473727
  validation accuracy:		91.41 %
Epoch 932 of 2000 took 0.165s
  training loss:		0.059949
  validation loss:		0.511316
  validation accuracy:		90.98 %
Epoch 933 of 2000 took 0.164s
  training loss:		0.057175
  validation loss:		0.493369
  validation accuracy:		91.41 %
Epoch 934 of 2000 took 0.170s
  training loss:		0.071058
  validation loss:		0.495460
  validation accuracy:		91.20 %
Epoch 935 of 2000 took 0.165s
  training loss:		0.063526
  validation loss:		0.492853
  validation accuracy:		91.30 %
Epoch 936 of 2000 took 0.170s
  training loss:		0.058142
  validation loss:		0.483348
  validation accuracy:		91.30 %
Epoch 937 of 2000 took 0.165s
  training loss:		0.060477
  validation loss:		0.493302
  validation accuracy:		91.52 %
Epoch 938 of 2000 took 0.165s
  training loss:		0.056563
  validation loss:		0.490339
  validation accuracy:		91.41 %
Epoch 939 of 2000 took 0.170s
  training loss:		0.057197
  validation loss:		0.486769
  validation accuracy:		91.41 %
Epoch 940 of 2000 took 0.165s
  training loss:		0.059912
  validation loss:		0.487451
  validation accuracy:		91.63 %
Epoch 941 of 2000 took 0.169s
  training loss:		0.059308
  validation loss:		0.501392
  validation accuracy:		91.96 %
Epoch 942 of 2000 took 0.165s
  training loss:		0.057812
  validation loss:		0.491015
  validation accuracy:		91.41 %
Epoch 943 of 2000 took 0.165s
  training loss:		0.058487
  validation loss:		0.498382
  validation accuracy:		91.41 %
Epoch 944 of 2000 took 0.169s
  training loss:		0.054772
  validation loss:		0.481501
  validation accuracy:		91.74 %
Epoch 945 of 2000 took 0.165s
  training loss:		0.058312
  validation loss:		0.497806
  validation accuracy:		92.07 %
Epoch 946 of 2000 took 0.169s
  training loss:		0.053059
  validation loss:		0.509030
  validation accuracy:		91.41 %
Epoch 947 of 2000 took 0.165s
  training loss:		0.057441
  validation loss:		0.491178
  validation accuracy:		91.85 %
Epoch 948 of 2000 took 0.165s
  training loss:		0.055807
  validation loss:		0.503021
  validation accuracy:		91.85 %
Epoch 949 of 2000 took 0.169s
  training loss:		0.054158
  validation loss:		0.491543
  validation accuracy:		91.85 %
Epoch 950 of 2000 took 0.165s
  training loss:		0.058424
  validation loss:		0.484525
  validation accuracy:		91.63 %
Epoch 951 of 2000 took 0.169s
  training loss:		0.054454
  validation loss:		0.501675
  validation accuracy:		91.41 %
Epoch 952 of 2000 took 0.165s
  training loss:		0.058933
  validation loss:		0.506515
  validation accuracy:		91.52 %
Epoch 953 of 2000 took 0.165s
  training loss:		0.052499
  validation loss:		0.525100
  validation accuracy:		91.96 %
Epoch 954 of 2000 took 0.169s
  training loss:		0.054991
  validation loss:		0.530898
  validation accuracy:		91.20 %
Epoch 955 of 2000 took 0.165s
  training loss:		0.056903
  validation loss:		0.494722
  validation accuracy:		91.85 %
Epoch 956 of 2000 took 0.169s
  training loss:		0.053951
  validation loss:		0.491966
  validation accuracy:		91.41 %
Epoch 957 of 2000 took 0.165s
  training loss:		0.051272
  validation loss:		0.521276
  validation accuracy:		90.76 %
Epoch 958 of 2000 took 0.165s
  training loss:		0.054112
  validation loss:		0.502781
  validation accuracy:		91.85 %
Epoch 959 of 2000 took 0.169s
  training loss:		0.053170
  validation loss:		0.500231
  validation accuracy:		91.30 %
Epoch 960 of 2000 took 0.170s
  training loss:		0.052929
  validation loss:		0.504538
  validation accuracy:		91.63 %
Epoch 961 of 2000 took 0.169s
  training loss:		0.051255
  validation loss:		0.517732
  validation accuracy:		91.52 %
Epoch 962 of 2000 took 0.165s
  training loss:		0.060890
  validation loss:		0.505779
  validation accuracy:		91.52 %
Epoch 963 of 2000 took 0.166s
  training loss:		0.052788
  validation loss:		0.505970
  validation accuracy:		92.17 %
Epoch 964 of 2000 took 0.168s
  training loss:		0.052473
  validation loss:		0.509582
  validation accuracy:		91.96 %
Epoch 965 of 2000 took 0.166s
  training loss:		0.054155
  validation loss:		0.523878
  validation accuracy:		90.87 %
Epoch 966 of 2000 took 0.168s
  training loss:		0.053345
  validation loss:		0.518381
  validation accuracy:		90.98 %
Epoch 967 of 2000 took 0.165s
  training loss:		0.051773
  validation loss:		0.530730
  validation accuracy:		91.52 %
Epoch 968 of 2000 took 0.166s
  training loss:		0.055046
  validation loss:		0.522794
  validation accuracy:		91.41 %
Epoch 969 of 2000 took 0.168s
  training loss:		0.050643
  validation loss:		0.513878
  validation accuracy:		91.52 %
Epoch 970 of 2000 took 0.167s
  training loss:		0.058008
  validation loss:		0.524682
  validation accuracy:		91.30 %
Epoch 971 of 2000 took 0.167s
  training loss:		0.050562
  validation loss:		0.521501
  validation accuracy:		91.41 %
Epoch 972 of 2000 took 0.165s
  training loss:		0.049651
  validation loss:		0.509344
  validation accuracy:		91.85 %
Epoch 973 of 2000 took 0.167s
  training loss:		0.050206
  validation loss:		0.523776
  validation accuracy:		91.09 %
Epoch 974 of 2000 took 0.167s
  training loss:		0.049086
  validation loss:		0.515627
  validation accuracy:		91.30 %
Epoch 975 of 2000 took 0.167s
  training loss:		0.050803
  validation loss:		0.524491
  validation accuracy:		91.63 %
Epoch 976 of 2000 took 0.167s
  training loss:		0.053475
  validation loss:		0.539200
  validation accuracy:		90.76 %
Epoch 977 of 2000 took 0.166s
  training loss:		0.062716
  validation loss:		0.528170
  validation accuracy:		91.63 %
Epoch 978 of 2000 took 0.167s
  training loss:		0.051741
  validation loss:		0.519350
  validation accuracy:		90.87 %
Epoch 979 of 2000 took 0.167s
  training loss:		0.051335
  validation loss:		0.527238
  validation accuracy:		90.76 %
Epoch 980 of 2000 took 0.168s
  training loss:		0.052474
  validation loss:		0.509082
  validation accuracy:		91.09 %
Epoch 981 of 2000 took 0.166s
  training loss:		0.062738
  validation loss:		0.656514
  validation accuracy:		89.67 %
Epoch 982 of 2000 took 0.165s
  training loss:		0.127103
  validation loss:		0.521006
  validation accuracy:		91.52 %
Epoch 983 of 2000 took 0.168s
  training loss:		0.052409
  validation loss:		0.513005
  validation accuracy:		91.85 %
Epoch 984 of 2000 took 0.166s
  training loss:		0.050968
  validation loss:		0.533108
  validation accuracy:		91.09 %
Epoch 985 of 2000 took 0.168s
  training loss:		0.055884
  validation loss:		0.514740
  validation accuracy:		91.30 %
Epoch 986 of 2000 took 0.165s
  training loss:		0.048715
  validation loss:		0.508174
  validation accuracy:		91.41 %
Epoch 987 of 2000 took 0.166s
  training loss:		0.047181
  validation loss:		0.521752
  validation accuracy:		91.74 %
Epoch 988 of 2000 took 0.169s
  training loss:		0.053729
  validation loss:		0.523496
  validation accuracy:		91.52 %
Epoch 989 of 2000 took 0.166s
  training loss:		0.057362
  validation loss:		0.524676
  validation accuracy:		91.74 %
Epoch 990 of 2000 took 0.169s
  training loss:		0.052333
  validation loss:		0.512751
  validation accuracy:		91.74 %
Epoch 991 of 2000 took 0.165s
  training loss:		0.047452
  validation loss:		0.535140
  validation accuracy:		91.41 %
Epoch 992 of 2000 took 0.165s
  training loss:		0.054080
  validation loss:		0.523604
  validation accuracy:		91.30 %
Epoch 993 of 2000 took 0.169s
  training loss:		0.047254
  validation loss:		0.548804
  validation accuracy:		91.09 %
Epoch 994 of 2000 took 0.166s
  training loss:		0.054786
  validation loss:		0.522432
  validation accuracy:		91.41 %
Epoch 995 of 2000 took 0.169s
  training loss:		0.050151
  validation loss:		0.532303
  validation accuracy:		90.76 %
Epoch 996 of 2000 took 0.167s
  training loss:		0.058045
  validation loss:		0.526350
  validation accuracy:		91.20 %
Epoch 997 of 2000 took 0.165s
  training loss:		0.056382
  validation loss:		0.517604
  validation accuracy:		91.20 %
Epoch 998 of 2000 took 0.169s
  training loss:		0.049181
  validation loss:		0.521554
  validation accuracy:		91.30 %
Epoch 999 of 2000 took 0.165s
  training loss:		0.047942
  validation loss:		0.539440
  validation accuracy:		91.30 %
Epoch 1000 of 2000 took 0.170s
  training loss:		0.048356
  validation loss:		0.535111
  validation accuracy:		91.41 %
Epoch 1001 of 2000 took 0.165s
  training loss:		0.050150
  validation loss:		0.523801
  validation accuracy:		90.98 %
Epoch 1002 of 2000 took 0.165s
  training loss:		0.046718
  validation loss:		0.530121
  validation accuracy:		91.52 %
Epoch 1003 of 2000 took 0.169s
  training loss:		0.044354
  validation loss:		0.528577
  validation accuracy:		91.41 %
Epoch 1004 of 2000 took 0.165s
  training loss:		0.044373
  validation loss:		0.529890
  validation accuracy:		91.09 %
Epoch 1005 of 2000 took 0.170s
  training loss:		0.050667
  validation loss:		0.549897
  validation accuracy:		91.41 %
Epoch 1006 of 2000 took 0.165s
  training loss:		0.068852
  validation loss:		0.554878
  validation accuracy:		91.20 %
Epoch 1007 of 2000 took 0.165s
  training loss:		0.049406
  validation loss:		0.520166
  validation accuracy:		92.07 %
Epoch 1008 of 2000 took 0.169s
  training loss:		0.053528
  validation loss:		0.550250
  validation accuracy:		91.30 %
Epoch 1009 of 2000 took 0.165s
  training loss:		0.047791
  validation loss:		0.537388
  validation accuracy:		91.20 %
Epoch 1010 of 2000 took 0.170s
  training loss:		0.046641
  validation loss:		0.526997
  validation accuracy:		91.74 %
Epoch 1011 of 2000 took 0.165s
  training loss:		0.046604
  validation loss:		0.540331
  validation accuracy:		91.30 %
Epoch 1012 of 2000 took 0.165s
  training loss:		0.043056
  validation loss:		0.548081
  validation accuracy:		91.63 %
Epoch 1013 of 2000 took 0.169s
  training loss:		0.042752
  validation loss:		0.537017
  validation accuracy:		91.41 %
Epoch 1014 of 2000 took 0.165s
  training loss:		0.045406
  validation loss:		0.536876
  validation accuracy:		91.20 %
Epoch 1015 of 2000 took 0.170s
  training loss:		0.045501
  validation loss:		0.546469
  validation accuracy:		91.85 %
Epoch 1016 of 2000 took 0.165s
  training loss:		0.047174
  validation loss:		0.558762
  validation accuracy:		91.09 %
Epoch 1017 of 2000 took 0.165s
  training loss:		0.049188
  validation loss:		0.551582
  validation accuracy:		90.65 %
Epoch 1018 of 2000 took 0.170s
  training loss:		0.052798
  validation loss:		0.557387
  validation accuracy:		91.52 %
Epoch 1019 of 2000 took 0.164s
  training loss:		0.046679
  validation loss:		0.555546
  validation accuracy:		91.52 %
Epoch 1020 of 2000 took 0.170s
  training loss:		0.047361
  validation loss:		0.540420
  validation accuracy:		91.63 %
Epoch 1021 of 2000 took 0.165s
  training loss:		0.048793
  validation loss:		0.543702
  validation accuracy:		91.85 %
Epoch 1022 of 2000 took 0.164s
  training loss:		0.044218
  validation loss:		0.550976
  validation accuracy:		91.09 %
Epoch 1023 of 2000 took 0.170s
  training loss:		0.050078
  validation loss:		0.565209
  validation accuracy:		90.76 %
Epoch 1024 of 2000 took 0.164s
  training loss:		0.045202
  validation loss:		0.555235
  validation accuracy:		91.85 %
Epoch 1025 of 2000 took 0.170s
  training loss:		0.043810
  validation loss:		0.557504
  validation accuracy:		91.52 %
Epoch 1026 of 2000 took 0.165s
  training loss:		0.061806
  validation loss:		0.540418
  validation accuracy:		92.28 %
Epoch 1027 of 2000 took 0.108s
  training loss:		0.044079
  validation loss:		0.534764
  validation accuracy:		91.41 %
Epoch 1028 of 2000 took 0.098s
  training loss:		0.043880
  validation loss:		0.567111
  validation accuracy:		91.30 %
Epoch 1029 of 2000 took 0.102s
  training loss:		0.043325
  validation loss:		0.570751
  validation accuracy:		90.65 %
Epoch 1030 of 2000 took 0.099s
  training loss:		0.049042
  validation loss:		0.553933
  validation accuracy:		91.74 %
Epoch 1031 of 2000 took 0.098s
  training loss:		0.045132
  validation loss:		0.554739
  validation accuracy:		91.09 %
Epoch 1032 of 2000 took 0.103s
  training loss:		0.041154
  validation loss:		0.552764
  validation accuracy:		91.85 %
Epoch 1033 of 2000 took 0.096s
  training loss:		0.042962
  validation loss:		0.556917
  validation accuracy:		91.41 %
Epoch 1034 of 2000 took 0.097s
  training loss:		0.046175
  validation loss:		0.561453
  validation accuracy:		91.20 %
Epoch 1035 of 2000 took 0.096s
  training loss:		0.042045
  validation loss:		0.549206
  validation accuracy:		91.41 %
Epoch 1036 of 2000 took 0.100s
  training loss:		0.042199
  validation loss:		0.558419
  validation accuracy:		90.98 %
Epoch 1037 of 2000 took 0.098s
  training loss:		0.045048
  validation loss:		0.556050
  validation accuracy:		91.30 %
Epoch 1038 of 2000 took 0.096s
  training loss:		0.045219
  validation loss:		0.558087
  validation accuracy:		91.09 %
Epoch 1039 of 2000 took 0.099s
  training loss:		0.047395
  validation loss:		0.565278
  validation accuracy:		91.85 %
Epoch 1040 of 2000 took 0.096s
  training loss:		0.050800
  validation loss:		0.542567
  validation accuracy:		92.17 %
Epoch 1041 of 2000 took 0.097s
  training loss:		0.040107
  validation loss:		0.561021
  validation accuracy:		91.85 %
Epoch 1042 of 2000 took 0.099s
  training loss:		0.037672
  validation loss:		0.571416
  validation accuracy:		90.87 %
Epoch 1043 of 2000 took 0.096s
  training loss:		0.040933
  validation loss:		0.572985
  validation accuracy:		90.98 %
Epoch 1044 of 2000 took 0.103s
  training loss:		0.047085
  validation loss:		0.608889
  validation accuracy:		90.87 %
Epoch 1045 of 2000 took 0.096s
  training loss:		0.041275
  validation loss:		0.570573
  validation accuracy:		91.41 %
Epoch 1046 of 2000 took 0.098s
  training loss:		0.046087
  validation loss:		0.569091
  validation accuracy:		90.87 %
Epoch 1047 of 2000 took 0.097s
  training loss:		0.045456
  validation loss:		0.600115
  validation accuracy:		90.43 %
Epoch 1048 of 2000 took 0.097s
  training loss:		0.047512
  validation loss:		0.564217
  validation accuracy:		91.20 %
Epoch 1049 of 2000 took 0.099s
  training loss:		0.038958
  validation loss:		0.579811
  validation accuracy:		91.52 %
Epoch 1050 of 2000 took 0.096s
  training loss:		0.041328
  validation loss:		0.577520
  validation accuracy:		91.85 %
Epoch 1051 of 2000 took 0.100s
  training loss:		0.045151
  validation loss:		0.579090
  validation accuracy:		91.30 %
Epoch 1052 of 2000 took 0.096s
  training loss:		0.043645
  validation loss:		0.580058
  validation accuracy:		91.74 %
Epoch 1053 of 2000 took 0.097s
  training loss:		0.040754
  validation loss:		0.563920
  validation accuracy:		91.52 %
Epoch 1054 of 2000 took 0.099s
  training loss:		0.044005
  validation loss:		0.596437
  validation accuracy:		91.52 %
Epoch 1055 of 2000 took 0.096s
  training loss:		0.061411
  validation loss:		0.590817
  validation accuracy:		91.52 %
Epoch 1056 of 2000 took 0.100s
  training loss:		0.039499
  validation loss:		0.581593
  validation accuracy:		91.41 %
Epoch 1057 of 2000 took 0.096s
  training loss:		0.045512
  validation loss:		0.575953
  validation accuracy:		91.52 %
Epoch 1058 of 2000 took 0.099s
  training loss:		0.040739
  validation loss:		0.579087
  validation accuracy:		91.74 %
Epoch 1059 of 2000 took 0.097s
  training loss:		0.039107
  validation loss:		0.575281
  validation accuracy:		91.30 %
Epoch 1060 of 2000 took 0.097s
  training loss:		0.039314
  validation loss:		0.593391
  validation accuracy:		90.87 %
Epoch 1061 of 2000 took 0.099s
  training loss:		0.048321
  validation loss:		0.608053
  validation accuracy:		91.20 %
Epoch 1062 of 2000 took 0.096s
  training loss:		0.054297
  validation loss:		0.580802
  validation accuracy:		91.09 %
Epoch 1063 of 2000 took 0.100s
  training loss:		0.044977
  validation loss:		0.578048
  validation accuracy:		91.20 %
Epoch 1064 of 2000 took 0.096s
  training loss:		0.037259
  validation loss:		0.600958
  validation accuracy:		91.52 %
Epoch 1065 of 2000 took 0.097s
  training loss:		0.045239
  validation loss:		0.579694
  validation accuracy:		90.76 %
Epoch 1066 of 2000 took 0.102s
  training loss:		0.041584
  validation loss:		0.582566
  validation accuracy:		91.41 %
Epoch 1067 of 2000 took 0.096s
  training loss:		0.043058
  validation loss:		0.649933
  validation accuracy:		91.41 %
Epoch 1068 of 2000 took 0.097s
  training loss:		0.046444
  validation loss:		0.598195
  validation accuracy:		91.52 %
Epoch 1069 of 2000 took 0.096s
  training loss:		0.037605
  validation loss:		0.614657
  validation accuracy:		91.20 %
Epoch 1070 of 2000 took 0.101s
  training loss:		0.038939
  validation loss:		0.606666
  validation accuracy:		90.54 %
Epoch 1071 of 2000 took 0.098s
  training loss:		0.048085
  validation loss:		0.613819
  validation accuracy:		90.87 %
Epoch 1072 of 2000 took 0.096s
  training loss:		0.042608
  validation loss:		0.596800
  validation accuracy:		91.63 %
Epoch 1073 of 2000 took 0.101s
  training loss:		0.042737
  validation loss:		0.613729
  validation accuracy:		89.78 %
Epoch 1074 of 2000 took 0.098s
  training loss:		0.041158
  validation loss:		0.594437
  validation accuracy:		91.30 %
Epoch 1075 of 2000 took 0.097s
  training loss:		0.038697
  validation loss:		0.615774
  validation accuracy:		90.76 %
Epoch 1076 of 2000 took 0.097s
  training loss:		0.035825
  validation loss:		0.592778
  validation accuracy:		91.20 %
Epoch 1077 of 2000 took 0.096s
  training loss:		0.037689
  validation loss:		0.605952
  validation accuracy:		90.87 %
Epoch 1078 of 2000 took 0.099s
  training loss:		0.037762
  validation loss:		0.591965
  validation accuracy:		91.41 %
Epoch 1079 of 2000 took 0.096s
  training loss:		0.040765
  validation loss:		0.581592
  validation accuracy:		91.85 %
Epoch 1080 of 2000 took 0.095s
  training loss:		0.039051
  validation loss:		0.596915
  validation accuracy:		91.63 %
Epoch 1081 of 2000 took 0.102s
  training loss:		0.042012
  validation loss:		0.594537
  validation accuracy:		91.52 %
Epoch 1082 of 2000 took 0.095s
  training loss:		0.037086
  validation loss:		0.605569
  validation accuracy:		91.41 %
Epoch 1083 of 2000 took 0.096s
  training loss:		0.043164
  validation loss:		0.677748
  validation accuracy:		90.11 %
Epoch 1084 of 2000 took 0.095s
  training loss:		0.042495
  validation loss:		0.625259
  validation accuracy:		91.41 %
Epoch 1085 of 2000 took 0.097s
  training loss:		0.038116
  validation loss:		0.632884
  validation accuracy:		91.09 %
Epoch 1086 of 2000 took 0.100s
  training loss:		0.037657
  validation loss:		0.609277
  validation accuracy:		91.09 %
Epoch 1087 of 2000 took 0.095s
  training loss:		0.038260
  validation loss:		0.609055
  validation accuracy:		91.63 %
Epoch 1088 of 2000 took 0.096s
  training loss:		0.035730
  validation loss:		0.599356
  validation accuracy:		91.41 %
Epoch 1089 of 2000 took 0.101s
  training loss:		0.040360
  validation loss:		0.609141
  validation accuracy:		91.52 %
Epoch 1090 of 2000 took 0.095s
  training loss:		0.039233
  validation loss:		0.608164
  validation accuracy:		91.30 %
Epoch 1091 of 2000 took 0.096s
  training loss:		0.036355
  validation loss:		0.606642
  validation accuracy:		91.30 %
Epoch 1092 of 2000 took 0.095s
  training loss:		0.035779
  validation loss:		0.612225
  validation accuracy:		90.87 %
Epoch 1093 of 2000 took 0.098s
  training loss:		0.039465
  validation loss:		0.635269
  validation accuracy:		90.33 %
Epoch 1094 of 2000 took 0.098s
  training loss:		0.034665
  validation loss:		0.596016
  validation accuracy:		91.30 %
Epoch 1095 of 2000 took 0.095s
  training loss:		0.045608
  validation loss:		0.622975
  validation accuracy:		90.76 %
Epoch 1096 of 2000 took 0.097s
  training loss:		0.042481
  validation loss:		0.646649
  validation accuracy:		91.09 %
Epoch 1097 of 2000 took 0.100s
  training loss:		0.040109
  validation loss:		0.626704
  validation accuracy:		91.41 %
Epoch 1098 of 2000 took 0.095s
  training loss:		0.042154
  validation loss:		0.609754
  validation accuracy:		91.30 %
Epoch 1099 of 2000 took 0.096s
  training loss:		0.046331
  validation loss:		0.665026
  validation accuracy:		90.43 %
Epoch 1100 of 2000 took 0.095s
  training loss:		0.228492
  validation loss:		0.973660
  validation accuracy:		87.93 %
Epoch 1101 of 2000 took 0.100s
  training loss:		0.083241
  validation loss:		0.599451
  validation accuracy:		91.85 %
Epoch 1102 of 2000 took 0.097s
  training loss:		0.042623
  validation loss:		0.598641
  validation accuracy:		91.41 %
Epoch 1103 of 2000 took 0.095s
  training loss:		0.036030
  validation loss:		0.616516
  validation accuracy:		91.41 %
Epoch 1104 of 2000 took 0.099s
  training loss:		0.034119
  validation loss:		0.610608
  validation accuracy:		91.41 %
Epoch 1105 of 2000 took 0.098s
  training loss:		0.037127
  validation loss:		0.615630
  validation accuracy:		90.76 %
Epoch 1106 of 2000 took 0.096s
  training loss:		0.038278
  validation loss:		0.621732
  validation accuracy:		91.63 %
Epoch 1107 of 2000 took 0.096s
  training loss:		0.036335
  validation loss:		0.598308
  validation accuracy:		91.52 %
Epoch 1108 of 2000 took 0.095s
  training loss:		0.034608
  validation loss:		0.624395
  validation accuracy:		90.76 %
Epoch 1109 of 2000 took 0.100s
  training loss:		0.035446
  validation loss:		0.612404
  validation accuracy:		91.52 %
Epoch 1110 of 2000 took 0.096s
  training loss:		0.035629
  validation loss:		0.620945
  validation accuracy:		91.30 %
Epoch 1111 of 2000 took 0.095s
  training loss:		0.043831
  validation loss:		0.618680
  validation accuracy:		91.20 %
Epoch 1112 of 2000 took 0.101s
  training loss:		0.033415
  validation loss:		0.601757
  validation accuracy:		91.63 %
Epoch 1113 of 2000 took 0.096s
  training loss:		0.033712
  validation loss:		0.635665
  validation accuracy:		91.52 %
Epoch 1114 of 2000 took 0.096s
  training loss:		0.032333
  validation loss:		0.613754
  validation accuracy:		91.52 %
Epoch 1115 of 2000 took 0.095s
  training loss:		0.036434
  validation loss:		0.619635
  validation accuracy:		91.63 %
Epoch 1116 of 2000 took 0.097s
  training loss:		0.034421
  validation loss:		0.628841
  validation accuracy:		91.52 %
Epoch 1117 of 2000 took 0.100s
  training loss:		0.034472
  validation loss:		0.640433
  validation accuracy:		91.41 %
Epoch 1118 of 2000 took 0.096s
  training loss:		0.032515
  validation loss:		0.630355
  validation accuracy:		91.30 %
Epoch 1119 of 2000 took 0.097s
  training loss:		0.038370
  validation loss:		0.627984
  validation accuracy:		91.09 %
Epoch 1120 of 2000 took 0.102s
  training loss:		0.034104
  validation loss:		0.615817
  validation accuracy:		91.52 %
Epoch 1121 of 2000 took 0.096s
  training loss:		0.033955
  validation loss:		0.616976
  validation accuracy:		91.52 %
Epoch 1122 of 2000 took 0.097s
  training loss:		0.035136
  validation loss:		0.653293
  validation accuracy:		90.76 %
Epoch 1123 of 2000 took 0.096s
  training loss:		0.040440
  validation loss:		0.776930
  validation accuracy:		89.46 %
Epoch 1124 of 2000 took 0.098s
  training loss:		0.169482
  validation loss:		0.691104
  validation accuracy:		90.98 %
Epoch 1125 of 2000 took 0.099s
  training loss:		0.114588
  validation loss:		0.638497
  validation accuracy:		90.87 %
Epoch 1126 of 2000 took 0.096s
  training loss:		0.039261
  validation loss:		0.612792
  validation accuracy:		91.41 %
Epoch 1127 of 2000 took 0.098s
  training loss:		0.035063
  validation loss:		0.621544
  validation accuracy:		91.41 %
Epoch 1128 of 2000 took 0.101s
  training loss:		0.032180
  validation loss:		0.639267
  validation accuracy:		90.87 %
Epoch 1129 of 2000 took 0.096s
  training loss:		0.055783
  validation loss:		0.623370
  validation accuracy:		91.30 %
Epoch 1130 of 2000 took 0.097s
  training loss:		0.037251
  validation loss:		0.644597
  validation accuracy:		90.87 %
Epoch 1131 of 2000 took 0.096s
  training loss:		0.032266
  validation loss:		0.637299
  validation accuracy:		91.41 %
Epoch 1132 of 2000 took 0.101s
  training loss:		0.031217
  validation loss:		0.621394
  validation accuracy:		91.20 %
Epoch 1133 of 2000 took 0.098s
  training loss:		0.058096
  validation loss:		0.730835
  validation accuracy:		91.09 %
Epoch 1134 of 2000 took 0.096s
  training loss:		0.046760
  validation loss:		0.641996
  validation accuracy:		91.20 %
Epoch 1135 of 2000 took 0.102s
  training loss:		0.032652
  validation loss:		0.620154
  validation accuracy:		91.63 %
Epoch 1136 of 2000 took 0.097s
  training loss:		0.033810
  validation loss:		0.631976
  validation accuracy:		91.20 %
Epoch 1137 of 2000 took 0.097s
  training loss:		0.035277
  validation loss:		0.630113
  validation accuracy:		91.52 %
Epoch 1138 of 2000 took 0.097s
  training loss:		0.031335
  validation loss:		0.618783
  validation accuracy:		91.20 %
Epoch 1139 of 2000 took 0.097s
  training loss:		0.034143
  validation loss:		0.630644
  validation accuracy:		91.85 %
Epoch 1140 of 2000 took 0.100s
  training loss:		0.033992
  validation loss:		0.621065
  validation accuracy:		91.52 %
Epoch 1141 of 2000 took 0.097s
  training loss:		0.034411
  validation loss:		0.641509
  validation accuracy:		91.63 %
Epoch 1142 of 2000 took 0.097s
  training loss:		0.032545
  validation loss:		0.648494
  validation accuracy:		91.20 %
Epoch 1143 of 2000 took 0.103s
  training loss:		0.036966
  validation loss:		0.619082
  validation accuracy:		91.20 %
Epoch 1144 of 2000 took 0.096s
  training loss:		0.030578
  validation loss:		0.641136
  validation accuracy:		91.30 %
Epoch 1145 of 2000 took 0.097s
  training loss:		0.032359
  validation loss:		0.643928
  validation accuracy:		91.20 %
Epoch 1146 of 2000 took 0.096s
  training loss:		0.035999
  validation loss:		0.624295
  validation accuracy:		91.20 %
Epoch 1147 of 2000 took 0.098s
  training loss:		0.032774
  validation loss:		0.652504
  validation accuracy:		91.20 %
Epoch 1148 of 2000 took 0.100s
  training loss:		0.034440
  validation loss:		0.652432
  validation accuracy:		91.41 %
Epoch 1149 of 2000 took 0.096s
  training loss:		0.033681
  validation loss:		0.655970
  validation accuracy:		91.20 %
Epoch 1150 of 2000 took 0.097s
  training loss:		0.029798
  validation loss:		0.668155
  validation accuracy:		91.20 %
Epoch 1151 of 2000 took 0.101s
  training loss:		0.029939
  validation loss:		0.629737
  validation accuracy:		91.41 %
Epoch 1152 of 2000 took 0.096s
  training loss:		0.031194
  validation loss:		0.663388
  validation accuracy:		90.87 %
Epoch 1153 of 2000 took 0.097s
  training loss:		0.029273
  validation loss:		0.639489
  validation accuracy:		91.41 %
Epoch 1154 of 2000 took 0.096s
  training loss:		0.027213
  validation loss:		0.645849
  validation accuracy:		91.41 %
Epoch 1155 of 2000 took 0.101s
  training loss:		0.027079
  validation loss:		0.650915
  validation accuracy:		91.30 %
Epoch 1156 of 2000 took 0.098s
  training loss:		0.033401
  validation loss:		0.661694
  validation accuracy:		91.09 %
Epoch 1157 of 2000 took 0.096s
  training loss:		0.029182
  validation loss:		0.663745
  validation accuracy:		91.30 %
Epoch 1158 of 2000 took 0.101s
  training loss:		0.029577
  validation loss:		0.662707
  validation accuracy:		91.30 %
Epoch 1159 of 2000 took 0.098s
  training loss:		0.029135
  validation loss:		0.644450
  validation accuracy:		91.41 %
Epoch 1160 of 2000 took 0.096s
  training loss:		0.028568
  validation loss:		0.654691
  validation accuracy:		91.20 %
Epoch 1161 of 2000 took 0.097s
  training loss:		0.028951
  validation loss:		0.680385
  validation accuracy:		90.87 %
Epoch 1162 of 2000 took 0.097s
  training loss:		0.030975
  validation loss:		0.650294
  validation accuracy:		91.52 %
Epoch 1163 of 2000 took 0.100s
  training loss:		0.046805
  validation loss:		0.669428
  validation accuracy:		90.76 %
Epoch 1164 of 2000 took 0.097s
  training loss:		0.027203
  validation loss:		0.665727
  validation accuracy:		89.89 %
Epoch 1165 of 2000 took 0.097s
  training loss:		0.032035
  validation loss:		0.658504
  validation accuracy:		91.30 %
Epoch 1166 of 2000 took 0.103s
  training loss:		0.027350
  validation loss:		0.687171
  validation accuracy:		91.20 %
Epoch 1167 of 2000 took 0.096s
  training loss:		0.029067
  validation loss:		0.686599
  validation accuracy:		91.09 %
Epoch 1168 of 2000 took 0.097s
  training loss:		0.029788
  validation loss:		0.684033
  validation accuracy:		91.41 %
Epoch 1169 of 2000 took 0.096s
  training loss:		0.028836
  validation loss:		0.675977
  validation accuracy:		90.98 %
Epoch 1170 of 2000 took 0.098s
  training loss:		0.027611
  validation loss:		0.648462
  validation accuracy:		91.63 %
Epoch 1171 of 2000 took 0.100s
  training loss:		0.026273
  validation loss:		0.660122
  validation accuracy:		91.30 %
Epoch 1172 of 2000 took 0.096s
  training loss:		0.026144
  validation loss:		0.683125
  validation accuracy:		91.09 %
Epoch 1173 of 2000 took 0.097s
  training loss:		0.025385
  validation loss:		0.654698
  validation accuracy:		91.30 %
Epoch 1174 of 2000 took 0.101s
  training loss:		0.029621
  validation loss:		0.674661
  validation accuracy:		90.43 %
Epoch 1175 of 2000 took 0.096s
  training loss:		0.026977
  validation loss:		0.669149
  validation accuracy:		91.52 %
Epoch 1176 of 2000 took 0.097s
  training loss:		0.027453
  validation loss:		0.680464
  validation accuracy:		91.52 %
Epoch 1177 of 2000 took 0.096s
  training loss:		0.025347
  validation loss:		0.685980
  validation accuracy:		90.98 %
Epoch 1178 of 2000 took 0.100s
  training loss:		0.026734
  validation loss:		0.679038
  validation accuracy:		91.09 %
Epoch 1179 of 2000 took 0.098s
  training loss:		0.027862
  validation loss:		0.698286
  validation accuracy:		90.87 %
Epoch 1180 of 2000 took 0.096s
  training loss:		0.035798
  validation loss:		0.685042
  validation accuracy:		91.30 %
Epoch 1181 of 2000 took 0.101s
  training loss:		0.030307
  validation loss:		0.678830
  validation accuracy:		91.30 %
Epoch 1182 of 2000 took 0.098s
  training loss:		0.027438
  validation loss:		0.697911
  validation accuracy:		90.87 %
Epoch 1183 of 2000 took 0.096s
  training loss:		0.026674
  validation loss:		0.679292
  validation accuracy:		90.87 %
Epoch 1184 of 2000 took 0.097s
  training loss:		0.025382
  validation loss:		0.680563
  validation accuracy:		91.30 %
Epoch 1185 of 2000 took 0.096s
  training loss:		0.024755
  validation loss:		0.678679
  validation accuracy:		91.52 %
Epoch 1186 of 2000 took 0.100s
  training loss:		0.025865
  validation loss:		0.686421
  validation accuracy:		91.30 %
Epoch 1187 of 2000 took 0.097s
  training loss:		0.029226
  validation loss:		0.696899
  validation accuracy:		90.98 %
Epoch 1188 of 2000 took 0.097s
  training loss:		0.030675
  validation loss:		0.711009
  validation accuracy:		90.65 %
Epoch 1189 of 2000 took 0.103s
  training loss:		0.032726
  validation loss:		0.723782
  validation accuracy:		90.65 %
Epoch 1190 of 2000 took 0.096s
  training loss:		0.029231
  validation loss:		0.704479
  validation accuracy:		91.09 %
Epoch 1191 of 2000 took 0.097s
  training loss:		0.026306
  validation loss:		0.695688
  validation accuracy:		91.20 %
Epoch 1192 of 2000 took 0.096s
  training loss:		0.025727
  validation loss:		0.692054
  validation accuracy:		91.09 %
Epoch 1193 of 2000 took 0.098s
  training loss:		0.023903
  validation loss:		0.696653
  validation accuracy:		91.30 %
Epoch 1194 of 2000 took 0.100s
  training loss:		0.025249
  validation loss:		0.682659
  validation accuracy:		91.20 %
Epoch 1195 of 2000 took 0.096s
  training loss:		0.024437
  validation loss:		0.704215
  validation accuracy:		91.20 %
Epoch 1196 of 2000 took 0.097s
  training loss:		0.029127
  validation loss:		0.705534
  validation accuracy:		91.30 %
Epoch 1197 of 2000 took 0.102s
  training loss:		0.025951
  validation loss:		0.698606
  validation accuracy:		91.20 %
Epoch 1198 of 2000 took 0.096s
  training loss:		0.023991
  validation loss:		0.703466
  validation accuracy:		91.41 %
Epoch 1199 of 2000 took 0.097s
  training loss:		0.030486
  validation loss:		0.703707
  validation accuracy:		90.98 %
Epoch 1200 of 2000 took 0.096s
  training loss:		0.027473
  validation loss:		0.699617
  validation accuracy:		91.41 %
Epoch 1201 of 2000 took 0.100s
  training loss:		0.026902
  validation loss:		0.708432
  validation accuracy:		91.30 %
Epoch 1202 of 2000 took 0.098s
  training loss:		0.029095
  validation loss:		0.722611
  validation accuracy:		90.65 %
Epoch 1203 of 2000 took 0.096s
  training loss:		0.025597
  validation loss:		0.730158
  validation accuracy:		90.87 %
Epoch 1204 of 2000 took 0.100s
  training loss:		0.024370
  validation loss:		0.730420
  validation accuracy:		91.30 %
Epoch 1205 of 2000 took 0.098s
  training loss:		0.024624
  validation loss:		0.710579
  validation accuracy:		91.20 %
Epoch 1206 of 2000 took 0.096s
  training loss:		0.024725
  validation loss:		0.700455
  validation accuracy:		91.30 %
Epoch 1207 of 2000 took 0.097s
  training loss:		0.026352
  validation loss:		0.732038
  validation accuracy:		90.43 %
Epoch 1208 of 2000 took 0.097s
  training loss:		0.029360
  validation loss:		0.711570
  validation accuracy:		90.98 %
Epoch 1209 of 2000 took 0.101s
  training loss:		0.051272
  validation loss:		0.732499
  validation accuracy:		91.09 %
Epoch 1210 of 2000 took 0.097s
  training loss:		0.025075
  validation loss:		0.693091
  validation accuracy:		91.30 %
Epoch 1211 of 2000 took 0.096s
  training loss:		0.023294
  validation loss:		0.715788
  validation accuracy:		91.52 %
Epoch 1212 of 2000 took 0.103s
  training loss:		0.022395
  validation loss:		0.726695
  validation accuracy:		90.87 %
Epoch 1213 of 2000 took 0.096s
  training loss:		0.023721
  validation loss:		0.712848
  validation accuracy:		91.20 %
Epoch 1214 of 2000 took 0.097s
  training loss:		0.024617
  validation loss:		0.726504
  validation accuracy:		91.20 %
Epoch 1215 of 2000 took 0.096s
  training loss:		0.026162
  validation loss:		0.760004
  validation accuracy:		90.65 %
Epoch 1216 of 2000 took 0.097s
  training loss:		0.023999
  validation loss:		0.713752
  validation accuracy:		90.98 %
Epoch 1217 of 2000 took 0.100s
  training loss:		0.024572
  validation loss:		0.718438
  validation accuracy:		91.41 %
Epoch 1218 of 2000 took 0.096s
  training loss:		0.022405
  validation loss:		0.737187
  validation accuracy:		91.30 %
Epoch 1219 of 2000 took 0.097s
  training loss:		0.023111
  validation loss:		0.716048
  validation accuracy:		91.20 %
Epoch 1220 of 2000 took 0.102s
  training loss:		0.023146
  validation loss:		0.724796
  validation accuracy:		91.41 %
Epoch 1221 of 2000 took 0.096s
  training loss:		0.022005
  validation loss:		0.708953
  validation accuracy:		91.09 %
Epoch 1222 of 2000 took 0.097s
  training loss:		0.022956
  validation loss:		0.728757
  validation accuracy:		91.41 %
Epoch 1223 of 2000 took 0.096s
  training loss:		0.023205
  validation loss:		0.733417
  validation accuracy:		91.30 %
Epoch 1224 of 2000 took 0.100s
  training loss:		0.022511
  validation loss:		0.735285
  validation accuracy:		90.98 %
Epoch 1225 of 2000 took 0.098s
  training loss:		0.024139
  validation loss:		0.730068
  validation accuracy:		90.98 %
Epoch 1226 of 2000 took 0.096s
  training loss:		0.157898
  validation loss:		1.852090
  validation accuracy:		82.72 %
Epoch 1227 of 2000 took 0.100s
  training loss:		5.436400
  validation loss:		2.822618
  validation accuracy:		75.11 %
Epoch 1228 of 2000 took 0.099s
  training loss:		15.660825
  validation loss:		16.679233
  validation accuracy:		28.48 %
Epoch 1229 of 2000 took 0.096s
  training loss:		35.028319
  validation loss:		5.405111
  validation accuracy:		36.74 %
Epoch 1230 of 2000 took 0.097s
  training loss:		2.861062
  validation loss:		1.786379
  validation accuracy:		46.30 %
Epoch 1231 of 2000 took 0.096s
  training loss:		1.492913
  validation loss:		1.297732
  validation accuracy:		55.11 %
Epoch 1232 of 2000 took 0.101s
  training loss:		1.153422
  validation loss:		1.105247
  validation accuracy:		63.70 %
Epoch 1233 of 2000 took 0.097s
  training loss:		0.988114
  validation loss:		1.017648
  validation accuracy:		67.50 %
Epoch 1234 of 2000 took 0.096s
  training loss:		0.891384
  validation loss:		0.923527
  validation accuracy:		71.96 %
Epoch 1235 of 2000 took 0.102s
  training loss:		0.823933
  validation loss:		0.852527
  validation accuracy:		75.65 %
Epoch 1236 of 2000 took 0.097s
  training loss:		0.774933
  validation loss:		0.816697
  validation accuracy:		76.63 %
Epoch 1237 of 2000 took 0.097s
  training loss:		0.742111
  validation loss:		0.755681
  validation accuracy:		79.24 %
Epoch 1238 of 2000 took 0.096s
  training loss:		0.704842
  validation loss:		0.733831
  validation accuracy:		78.48 %
Epoch 1239 of 2000 took 0.098s
  training loss:		0.675656
  validation loss:		0.700202
  validation accuracy:		80.98 %
Epoch 1240 of 2000 took 0.101s
  training loss:		0.640598
  validation loss:		0.665498
  validation accuracy:		81.30 %
Epoch 1241 of 2000 took 0.096s
  training loss:		0.621754
  validation loss:		0.654360
  validation accuracy:		81.63 %
Epoch 1242 of 2000 took 0.097s
  training loss:		0.603044
  validation loss:		0.643789
  validation accuracy:		80.87 %
Epoch 1243 of 2000 took 0.102s
  training loss:		0.585411
  validation loss:		0.633672
  validation accuracy:		81.30 %
Epoch 1244 of 2000 took 0.096s
  training loss:		0.566343
  validation loss:		0.603911
  validation accuracy:		82.17 %
Epoch 1245 of 2000 took 0.097s
  training loss:		0.554290
  validation loss:		0.606365
  validation accuracy:		82.07 %
Epoch 1246 of 2000 took 0.096s
  training loss:		0.534579
  validation loss:		0.570563
  validation accuracy:		83.59 %
Epoch 1247 of 2000 took 0.099s
  training loss:		0.523738
  validation loss:		0.561511
  validation accuracy:		83.59 %
Epoch 1248 of 2000 took 0.099s
  training loss:		0.510670
  validation loss:		0.543397
  validation accuracy:		84.24 %
Epoch 1249 of 2000 took 0.096s
  training loss:		0.496129
  validation loss:		0.531545
  validation accuracy:		84.57 %
Epoch 1250 of 2000 took 0.099s
  training loss:		0.483393
  validation loss:		0.537834
  validation accuracy:		84.02 %
Epoch 1251 of 2000 took 0.100s
  training loss:		0.468571
  validation loss:		0.529707
  validation accuracy:		84.46 %
Epoch 1252 of 2000 took 0.096s
  training loss:		0.465431
  validation loss:		0.497774
  validation accuracy:		86.20 %
Epoch 1253 of 2000 took 0.097s
  training loss:		0.451998
  validation loss:		0.489708
  validation accuracy:		85.76 %
Epoch 1254 of 2000 took 0.096s
  training loss:		0.441932
  validation loss:		0.488958
  validation accuracy:		85.76 %
Epoch 1255 of 2000 took 0.104s
  training loss:		0.430194
  validation loss:		0.478672
  validation accuracy:		86.20 %
Epoch 1256 of 2000 took 0.098s
  training loss:		0.426540
  validation loss:		0.474567
  validation accuracy:		85.76 %
Epoch 1257 of 2000 took 0.096s
  training loss:		0.415901
  validation loss:		0.463283
  validation accuracy:		86.30 %
Epoch 1258 of 2000 took 0.102s
  training loss:		0.407778
  validation loss:		0.446644
  validation accuracy:		86.85 %
Epoch 1259 of 2000 took 0.096s
  training loss:		0.394182
  validation loss:		0.452377
  validation accuracy:		86.74 %
Epoch 1260 of 2000 took 0.097s
  training loss:		0.395247
  validation loss:		0.441171
  validation accuracy:		87.07 %
Epoch 1261 of 2000 took 0.096s
  training loss:		0.385707
  validation loss:		0.425096
  validation accuracy:		87.72 %
Epoch 1262 of 2000 took 0.097s
  training loss:		0.382874
  validation loss:		0.422680
  validation accuracy:		87.50 %
Epoch 1263 of 2000 took 0.100s
  training loss:		0.367876
  validation loss:		0.414636
  validation accuracy:		87.93 %
Epoch 1264 of 2000 took 0.096s
  training loss:		0.367102
  validation loss:		0.408050
  validation accuracy:		88.26 %
Epoch 1265 of 2000 took 0.097s
  training loss:		0.362540
  validation loss:		0.409535
  validation accuracy:		87.83 %
Epoch 1266 of 2000 took 0.102s
  training loss:		0.351006
  validation loss:		0.408375
  validation accuracy:		88.15 %
Epoch 1267 of 2000 took 0.096s
  training loss:		0.345757
  validation loss:		0.390916
  validation accuracy:		88.26 %
Epoch 1268 of 2000 took 0.097s
  training loss:		0.340241
  validation loss:		0.388945
  validation accuracy:		88.26 %
Epoch 1269 of 2000 took 0.096s
  training loss:		0.334226
  validation loss:		0.382172
  validation accuracy:		88.70 %
Epoch 1270 of 2000 took 0.099s
  training loss:		0.335406
  validation loss:		0.388078
  validation accuracy:		88.15 %
Epoch 1271 of 2000 took 0.099s
  training loss:		0.328281
  validation loss:		0.399640
  validation accuracy:		88.26 %
Epoch 1272 of 2000 took 0.096s
  training loss:		0.328771
  validation loss:		0.369023
  validation accuracy:		89.02 %
Epoch 1273 of 2000 took 0.099s
  training loss:		0.319067
  validation loss:		0.374694
  validation accuracy:		88.91 %
Epoch 1274 of 2000 took 0.100s
  training loss:		0.315511
  validation loss:		0.376483
  validation accuracy:		88.80 %
Epoch 1275 of 2000 took 0.096s
  training loss:		0.312734
  validation loss:		0.363600
  validation accuracy:		88.91 %
Epoch 1276 of 2000 took 0.097s
  training loss:		0.304601
  validation loss:		0.360778
  validation accuracy:		89.35 %
Epoch 1277 of 2000 took 0.096s
  training loss:		0.305266
  validation loss:		0.365012
  validation accuracy:		89.35 %
Epoch 1278 of 2000 took 0.101s
  training loss:		0.301615
  validation loss:		0.365264
  validation accuracy:		89.24 %
Epoch 1279 of 2000 took 0.098s
  training loss:		0.297559
  validation loss:		0.343783
  validation accuracy:		89.67 %
Epoch 1280 of 2000 took 0.096s
  training loss:		0.297736
  validation loss:		0.350963
  validation accuracy:		89.13 %
Epoch 1281 of 2000 took 0.102s
  training loss:		0.293507
  validation loss:		0.339925
  validation accuracy:		89.67 %
Epoch 1282 of 2000 took 0.097s
  training loss:		0.285608
  validation loss:		0.341059
  validation accuracy:		89.78 %
Epoch 1283 of 2000 took 0.097s
  training loss:		0.289857
  validation loss:		0.337130
  validation accuracy:		89.57 %
Epoch 1284 of 2000 took 0.096s
  training loss:		0.285688
  validation loss:		0.335274
  validation accuracy:		89.24 %
Epoch 1285 of 2000 took 0.097s
  training loss:		0.280399
  validation loss:		0.348831
  validation accuracy:		89.57 %
Epoch 1286 of 2000 took 0.100s
  training loss:		0.277060
  validation loss:		0.334709
  validation accuracy:		89.67 %
Epoch 1287 of 2000 took 0.097s
  training loss:		0.271746
  validation loss:		0.324723
  validation accuracy:		89.67 %
Epoch 1288 of 2000 took 0.097s
  training loss:		0.273702
  validation loss:		0.332363
  validation accuracy:		90.00 %
Epoch 1289 of 2000 took 0.102s
  training loss:		0.271690
  validation loss:		0.320768
  validation accuracy:		89.89 %
Epoch 1290 of 2000 took 0.096s
  training loss:		0.266080
  validation loss:		0.333927
  validation accuracy:		89.89 %
Epoch 1291 of 2000 took 0.097s
  training loss:		0.266629
  validation loss:		0.325345
  validation accuracy:		89.78 %
Epoch 1292 of 2000 took 0.096s
  training loss:		0.262932
  validation loss:		0.326660
  validation accuracy:		89.57 %
Epoch 1293 of 2000 took 0.098s
  training loss:		0.256458
  validation loss:		0.323259
  validation accuracy:		89.78 %
Epoch 1294 of 2000 took 0.099s
  training loss:		0.257237
  validation loss:		0.326475
  validation accuracy:		89.89 %
Epoch 1295 of 2000 took 0.096s
  training loss:		0.258097
  validation loss:		0.315288
  validation accuracy:		90.11 %
Epoch 1296 of 2000 took 0.098s
  training loss:		0.261180
  validation loss:		0.319553
  validation accuracy:		89.67 %
Epoch 1297 of 2000 took 0.101s
  training loss:		0.256442
  validation loss:		0.313395
  validation accuracy:		90.00 %
Epoch 1298 of 2000 took 0.096s
  training loss:		0.253381
  validation loss:		0.314103
  validation accuracy:		90.22 %
Epoch 1299 of 2000 took 0.097s
  training loss:		0.250769
  validation loss:		0.321783
  validation accuracy:		89.89 %
Epoch 1300 of 2000 took 0.096s
  training loss:		0.244262
  validation loss:		0.318513
  validation accuracy:		90.00 %
Epoch 1301 of 2000 took 0.101s
  training loss:		0.250411
  validation loss:		0.326592
  validation accuracy:		89.57 %
Epoch 1302 of 2000 took 0.098s
  training loss:		0.246314
  validation loss:		0.311065
  validation accuracy:		90.43 %
Epoch 1303 of 2000 took 0.096s
  training loss:		0.241435
  validation loss:		0.316148
  validation accuracy:		90.43 %
Epoch 1304 of 2000 took 0.102s
  training loss:		0.245529
  validation loss:		0.317936
  validation accuracy:		89.78 %
Epoch 1305 of 2000 took 0.097s
  training loss:		0.240716
  validation loss:		0.303973
  validation accuracy:		90.65 %
Epoch 1306 of 2000 took 0.097s
  training loss:		0.246671
  validation loss:		0.309565
  validation accuracy:		90.65 %
Epoch 1307 of 2000 took 0.097s
  training loss:		0.242455
  validation loss:		0.307590
  validation accuracy:		90.43 %
Epoch 1308 of 2000 took 0.097s
  training loss:		0.238950
  validation loss:		0.306953
  validation accuracy:		90.54 %
Epoch 1309 of 2000 took 0.100s
  training loss:		0.243290
  validation loss:		0.297739
  validation accuracy:		90.54 %
Epoch 1310 of 2000 took 0.097s
  training loss:		0.234932
  validation loss:		0.303641
  validation accuracy:		90.54 %
Epoch 1311 of 2000 took 0.097s
  training loss:		0.235268
  validation loss:		0.298186
  validation accuracy:		90.54 %
Epoch 1312 of 2000 took 0.102s
  training loss:		0.238383
  validation loss:		0.300729
  validation accuracy:		90.54 %
Epoch 1313 of 2000 took 0.096s
  training loss:		0.233202
  validation loss:		0.295319
  validation accuracy:		90.65 %
Epoch 1314 of 2000 took 0.097s
  training loss:		0.231565
  validation loss:		0.312212
  validation accuracy:		90.43 %
Epoch 1315 of 2000 took 0.096s
  training loss:		0.235497
  validation loss:		0.293489
  validation accuracy:		90.43 %
Epoch 1316 of 2000 took 0.098s
  training loss:		0.231786
  validation loss:		0.310126
  validation accuracy:		90.43 %
Epoch 1317 of 2000 took 0.100s
  training loss:		0.230824
  validation loss:		0.305970
  validation accuracy:		90.65 %
Epoch 1318 of 2000 took 0.096s
  training loss:		0.226131
  validation loss:		0.298308
  validation accuracy:		90.65 %
Epoch 1319 of 2000 took 0.097s
  training loss:		0.227848
  validation loss:		0.296283
  validation accuracy:		90.65 %
Epoch 1320 of 2000 took 0.102s
  training loss:		0.229730
  validation loss:		0.304304
  validation accuracy:		90.43 %
Epoch 1321 of 2000 took 0.096s
  training loss:		0.223223
  validation loss:		0.304588
  validation accuracy:		90.33 %
Epoch 1322 of 2000 took 0.097s
  training loss:		0.227254
  validation loss:		0.291009
  validation accuracy:		90.43 %
Epoch 1323 of 2000 took 0.096s
  training loss:		0.226261
  validation loss:		0.297601
  validation accuracy:		90.65 %
Epoch 1324 of 2000 took 0.100s
  training loss:		0.221587
  validation loss:		0.298659
  validation accuracy:		90.54 %
Epoch 1325 of 2000 took 0.098s
  training loss:		0.220406
  validation loss:		0.297764
  validation accuracy:		90.76 %
Epoch 1326 of 2000 took 0.096s
  training loss:		0.217982
  validation loss:		0.304052
  validation accuracy:		90.98 %
Epoch 1327 of 2000 took 0.101s
  training loss:		0.224967
  validation loss:		0.301009
  validation accuracy:		90.33 %
Epoch 1328 of 2000 took 0.098s
  training loss:		0.216117
  validation loss:		0.314364
  validation accuracy:		90.22 %
Epoch 1329 of 2000 took 0.096s
  training loss:		0.217723
  validation loss:		0.299360
  validation accuracy:		90.87 %
Epoch 1330 of 2000 took 0.097s
  training loss:		0.217137
  validation loss:		0.302230
  validation accuracy:		90.76 %
Epoch 1331 of 2000 took 0.097s
  training loss:		0.213705
  validation loss:		0.298148
  validation accuracy:		91.09 %
Epoch 1332 of 2000 took 0.100s
  training loss:		0.212933
  validation loss:		0.302352
  validation accuracy:		90.76 %
Epoch 1333 of 2000 took 0.097s
  training loss:		0.216771
  validation loss:		0.303479
  validation accuracy:		90.98 %
Epoch 1334 of 2000 took 0.097s
  training loss:		0.216244
  validation loss:		0.306642
  validation accuracy:		90.43 %
Epoch 1335 of 2000 took 0.102s
  training loss:		0.211095
  validation loss:		0.291544
  validation accuracy:		90.54 %
Epoch 1336 of 2000 took 0.096s
  training loss:		0.211954
  validation loss:		0.290876
  validation accuracy:		90.54 %
Epoch 1337 of 2000 took 0.097s
  training loss:		0.207855
  validation loss:		0.306380
  validation accuracy:		90.76 %
Epoch 1338 of 2000 took 0.096s
  training loss:		0.214373
  validation loss:		0.290113
  validation accuracy:		90.76 %
Epoch 1339 of 2000 took 0.098s
  training loss:		0.207833
  validation loss:		0.305624
  validation accuracy:		90.33 %
Epoch 1340 of 2000 took 0.100s
  training loss:		0.206890
  validation loss:		0.301733
  validation accuracy:		91.09 %
Epoch 1341 of 2000 took 0.096s
  training loss:		0.205519
  validation loss:		0.292863
  validation accuracy:		90.54 %
Epoch 1342 of 2000 took 0.097s
  training loss:		0.210266
  validation loss:		0.305100
  validation accuracy:		90.54 %
Epoch 1343 of 2000 took 0.101s
  training loss:		0.209425
  validation loss:		0.294233
  validation accuracy:		90.54 %
Epoch 1344 of 2000 took 0.096s
  training loss:		0.200659
  validation loss:		0.311646
  validation accuracy:		90.65 %
Epoch 1345 of 2000 took 0.097s
  training loss:		0.206833
  validation loss:		0.296651
  validation accuracy:		90.98 %
Epoch 1346 of 2000 took 0.096s
  training loss:		0.208224
  validation loss:		0.292504
  validation accuracy:		90.98 %
Epoch 1347 of 2000 took 0.101s
  training loss:		0.202551
  validation loss:		0.301921
  validation accuracy:		90.87 %
Epoch 1348 of 2000 took 0.098s
  training loss:		0.202584
  validation loss:		0.293416
  validation accuracy:		90.76 %
Epoch 1349 of 2000 took 0.096s
  training loss:		0.202157
  validation loss:		0.297654
  validation accuracy:		90.65 %
Epoch 1350 of 2000 took 0.101s
  training loss:		0.204383
  validation loss:		0.297642
  validation accuracy:		90.76 %
Epoch 1351 of 2000 took 0.098s
  training loss:		0.202865
  validation loss:		0.292784
  validation accuracy:		90.76 %
Epoch 1352 of 2000 took 0.097s
  training loss:		0.197518
  validation loss:		0.296878
  validation accuracy:		90.98 %
Epoch 1353 of 2000 took 0.097s
  training loss:		0.201842
  validation loss:		0.281870
  validation accuracy:		91.41 %
Epoch 1354 of 2000 took 0.097s
  training loss:		0.200165
  validation loss:		0.289575
  validation accuracy:		91.09 %
Epoch 1355 of 2000 took 0.100s
  training loss:		0.201203
  validation loss:		0.301942
  validation accuracy:		90.76 %
Epoch 1356 of 2000 took 0.097s
  training loss:		0.201404
  validation loss:		0.289460
  validation accuracy:		91.20 %
Epoch 1357 of 2000 took 0.097s
  training loss:		0.199877
  validation loss:		0.291594
  validation accuracy:		91.20 %
Epoch 1358 of 2000 took 0.103s
  training loss:		0.200470
  validation loss:		0.296171
  validation accuracy:		90.76 %
Epoch 1359 of 2000 took 0.096s
  training loss:		0.193673
  validation loss:		0.293732
  validation accuracy:		91.41 %
Epoch 1360 of 2000 took 0.097s
  training loss:		0.197082
  validation loss:		0.298365
  validation accuracy:		90.87 %
Epoch 1361 of 2000 took 0.096s
  training loss:		0.195805
  validation loss:		0.291204
  validation accuracy:		90.98 %
Epoch 1362 of 2000 took 0.098s
  training loss:		0.199007
  validation loss:		0.295358
  validation accuracy:		91.20 %
Epoch 1363 of 2000 took 0.100s
  training loss:		0.198988
  validation loss:		0.290152
  validation accuracy:		91.09 %
Epoch 1364 of 2000 took 0.096s
  training loss:		0.193538
  validation loss:		0.299250
  validation accuracy:		91.09 %
Epoch 1365 of 2000 took 0.097s
  training loss:		0.192147
  validation loss:		0.304064
  validation accuracy:		90.98 %
Epoch 1366 of 2000 took 0.102s
  training loss:		0.191465
  validation loss:		0.287574
  validation accuracy:		91.09 %
Epoch 1367 of 2000 took 0.096s
  training loss:		0.195850
  validation loss:		0.294445
  validation accuracy:		91.09 %
Epoch 1368 of 2000 took 0.097s
  training loss:		0.198098
  validation loss:		0.294478
  validation accuracy:		91.20 %
Epoch 1369 of 2000 took 0.096s
  training loss:		0.190696
  validation loss:		0.292323
  validation accuracy:		91.41 %
Epoch 1370 of 2000 took 0.100s
  training loss:		0.194153
  validation loss:		0.295708
  validation accuracy:		91.09 %
Epoch 1371 of 2000 took 0.098s
  training loss:		0.196050
  validation loss:		0.291315
  validation accuracy:		91.20 %
Epoch 1372 of 2000 took 0.096s
  training loss:		0.190279
  validation loss:		0.293618
  validation accuracy:		91.41 %
Epoch 1373 of 2000 took 0.100s
  training loss:		0.191973
  validation loss:		0.289625
  validation accuracy:		90.98 %
Epoch 1374 of 2000 took 0.098s
  training loss:		0.186490
  validation loss:		0.291216
  validation accuracy:		90.98 %
Epoch 1375 of 2000 took 0.096s
  training loss:		0.191015
  validation loss:		0.293957
  validation accuracy:		91.20 %
Epoch 1376 of 2000 took 0.097s
  training loss:		0.188150
  validation loss:		0.303009
  validation accuracy:		90.98 %
Epoch 1377 of 2000 took 0.097s
  training loss:		0.190171
  validation loss:		0.292498
  validation accuracy:		90.87 %
Epoch 1378 of 2000 took 0.100s
  training loss:		0.183643
  validation loss:		0.290928
  validation accuracy:		91.09 %
Epoch 1379 of 2000 took 0.097s
  training loss:		0.188356
  validation loss:		0.292910
  validation accuracy:		91.41 %
Epoch 1380 of 2000 took 0.096s
  training loss:		0.189969
  validation loss:		0.295637
  validation accuracy:		91.41 %
Epoch 1381 of 2000 took 0.103s
  training loss:		0.184714
  validation loss:		0.310702
  validation accuracy:		91.09 %
Epoch 1382 of 2000 took 0.096s
  training loss:		0.185603
  validation loss:		0.298952
  validation accuracy:		91.20 %
Epoch 1383 of 2000 took 0.097s
  training loss:		0.184059
  validation loss:		0.300063
  validation accuracy:		91.20 %
Epoch 1384 of 2000 took 0.096s
  training loss:		0.187559
  validation loss:		0.298675
  validation accuracy:		91.09 %
Epoch 1385 of 2000 took 0.098s
  training loss:		0.188328
  validation loss:		0.294948
  validation accuracy:		91.41 %
Epoch 1386 of 2000 took 0.100s
  training loss:		0.181579
  validation loss:		0.296410
  validation accuracy:		90.98 %
Epoch 1387 of 2000 took 0.096s
  training loss:		0.184316
  validation loss:		0.297375
  validation accuracy:		91.30 %
Epoch 1388 of 2000 took 0.097s
  training loss:		0.183329
  validation loss:		0.295744
  validation accuracy:		91.30 %
Epoch 1389 of 2000 took 0.102s
  training loss:		0.184010
  validation loss:		0.290885
  validation accuracy:		91.20 %
Epoch 1390 of 2000 took 0.096s
  training loss:		0.181529
  validation loss:		0.303176
  validation accuracy:		90.98 %
Epoch 1391 of 2000 took 0.097s
  training loss:		0.175222
  validation loss:		0.293406
  validation accuracy:		91.30 %
Epoch 1392 of 2000 took 0.096s
  training loss:		0.183753
  validation loss:		0.295219
  validation accuracy:		91.09 %
Epoch 1393 of 2000 took 0.099s
  training loss:		0.181677
  validation loss:		0.291512
  validation accuracy:		91.20 %
Epoch 1394 of 2000 took 0.098s
  training loss:		0.179568
  validation loss:		0.293784
  validation accuracy:		91.41 %
Epoch 1395 of 2000 took 0.096s
  training loss:		0.179457
  validation loss:		0.299583
  validation accuracy:		91.41 %
Epoch 1396 of 2000 took 0.099s
  training loss:		0.180837
  validation loss:		0.307474
  validation accuracy:		90.76 %
Epoch 1397 of 2000 took 0.100s
  training loss:		0.176563
  validation loss:		0.308713
  validation accuracy:		90.98 %
Epoch 1398 of 2000 took 0.096s
  training loss:		0.177879
  validation loss:		0.296283
  validation accuracy:		91.20 %
Epoch 1399 of 2000 took 0.097s
  training loss:		0.177383
  validation loss:		0.295130
  validation accuracy:		91.20 %
Epoch 1400 of 2000 took 0.096s
  training loss:		0.173467
  validation loss:		0.301833
  validation accuracy:		91.30 %
Epoch 1401 of 2000 took 0.101s
  training loss:		0.174697
  validation loss:		0.294141
  validation accuracy:		91.30 %
Epoch 1402 of 2000 took 0.098s
  training loss:		0.177708
  validation loss:		0.305296
  validation accuracy:		91.52 %
Epoch 1403 of 2000 took 0.096s
  training loss:		0.179012
  validation loss:		0.308816
  validation accuracy:		91.20 %
Epoch 1404 of 2000 took 0.102s
  training loss:		0.176269
  validation loss:		0.293451
  validation accuracy:		91.85 %
Epoch 1405 of 2000 took 0.097s
  training loss:		0.176899
  validation loss:		0.303949
  validation accuracy:		91.52 %
Epoch 1406 of 2000 took 0.097s
  training loss:		0.178306
  validation loss:		0.300766
  validation accuracy:		91.30 %
Epoch 1407 of 2000 took 0.096s
  training loss:		0.170819
  validation loss:		0.295013
  validation accuracy:		91.52 %
Epoch 1408 of 2000 took 0.097s
  training loss:		0.174385
  validation loss:		0.305141
  validation accuracy:		91.20 %
Epoch 1409 of 2000 took 0.100s
  training loss:		0.170880
  validation loss:		0.299815
  validation accuracy:		91.41 %
Epoch 1410 of 2000 took 0.097s
  training loss:		0.173494
  validation loss:		0.295047
  validation accuracy:		91.41 %
Epoch 1411 of 2000 took 0.097s
  training loss:		0.175287
  validation loss:		0.288358
  validation accuracy:		91.74 %
Epoch 1412 of 2000 took 0.102s
  training loss:		0.172918
  validation loss:		0.301075
  validation accuracy:		91.52 %
Epoch 1413 of 2000 took 0.096s
  training loss:		0.173406
  validation loss:		0.304134
  validation accuracy:		91.41 %
Epoch 1414 of 2000 took 0.097s
  training loss:		0.168579
  validation loss:		0.306785
  validation accuracy:		91.20 %
Epoch 1415 of 2000 took 0.096s
  training loss:		0.173182
  validation loss:		0.309727
  validation accuracy:		91.20 %
Epoch 1416 of 2000 took 0.098s
  training loss:		0.172554
  validation loss:		0.308731
  validation accuracy:		90.87 %
Epoch 1417 of 2000 took 0.100s
  training loss:		0.172461
  validation loss:		0.304337
  validation accuracy:		91.20 %
Epoch 1418 of 2000 took 0.096s
  training loss:		0.167086
  validation loss:		0.306859
  validation accuracy:		90.98 %
Epoch 1419 of 2000 took 0.098s
  training loss:		0.165002
  validation loss:		0.305020
  validation accuracy:		91.20 %
Epoch 1420 of 2000 took 0.101s
  training loss:		0.166385
  validation loss:		0.298459
  validation accuracy:		91.63 %
Epoch 1421 of 2000 took 0.096s
  training loss:		0.170503
  validation loss:		0.295905
  validation accuracy:		91.63 %
Epoch 1422 of 2000 took 0.097s
  training loss:		0.165382
  validation loss:		0.297826
  validation accuracy:		91.63 %
Epoch 1423 of 2000 took 0.096s
  training loss:		0.171228
  validation loss:		0.301517
  validation accuracy:		91.52 %
Epoch 1424 of 2000 took 0.100s
  training loss:		0.166710
  validation loss:		0.300618
  validation accuracy:		91.41 %
Epoch 1425 of 2000 took 0.098s
  training loss:		0.169429
  validation loss:		0.303966
  validation accuracy:		91.41 %
Epoch 1426 of 2000 took 0.096s
  training loss:		0.168933
  validation loss:		0.308510
  validation accuracy:		91.20 %
Epoch 1427 of 2000 took 0.100s
  training loss:		0.166098
  validation loss:		0.302449
  validation accuracy:		91.41 %
Epoch 1428 of 2000 took 0.096s
  training loss:		0.164971
  validation loss:		0.304857
  validation accuracy:		91.30 %
Epoch 1429 of 2000 took 0.097s
  training loss:		0.167896
  validation loss:		0.301986
  validation accuracy:		91.41 %
Epoch 1430 of 2000 took 0.099s
  training loss:		0.169655
  validation loss:		0.308716
  validation accuracy:		91.30 %
Epoch 1431 of 2000 took 0.096s
  training loss:		0.164558
  validation loss:		0.308702
  validation accuracy:		91.09 %
Epoch 1432 of 2000 took 0.100s
  training loss:		0.168772
  validation loss:		0.303126
  validation accuracy:		91.30 %
Epoch 1433 of 2000 took 0.096s
  training loss:		0.163760
  validation loss:		0.302422
  validation accuracy:		91.41 %
Epoch 1434 of 2000 took 0.098s
  training loss:		0.167470
  validation loss:		0.299006
  validation accuracy:		91.63 %
Epoch 1435 of 2000 took 0.097s
  training loss:		0.161405
  validation loss:		0.312109
  validation accuracy:		91.20 %
Epoch 1436 of 2000 took 0.097s
  training loss:		0.167941
  validation loss:		0.302481
  validation accuracy:		91.52 %
Epoch 1437 of 2000 took 0.099s
  training loss:		0.163563
  validation loss:		0.307528
  validation accuracy:		91.52 %
Epoch 1438 of 2000 took 0.096s
  training loss:		0.164710
  validation loss:		0.318107
  validation accuracy:		91.20 %
Epoch 1439 of 2000 took 0.100s
  training loss:		0.164880
  validation loss:		0.298843
  validation accuracy:		91.52 %
Epoch 1440 of 2000 took 0.096s
  training loss:		0.161267
  validation loss:		0.293958
  validation accuracy:		91.63 %
Epoch 1441 of 2000 took 0.097s
  training loss:		0.160653
  validation loss:		0.305373
  validation accuracy:		91.41 %
Epoch 1442 of 2000 took 0.099s
  training loss:		0.165642
  validation loss:		0.303943
  validation accuracy:		91.74 %
Epoch 1443 of 2000 took 0.098s
  training loss:		0.160711
  validation loss:		0.311862
  validation accuracy:		91.30 %
Epoch 1444 of 2000 took 0.103s
  training loss:		0.160952
  validation loss:		0.314333
  validation accuracy:		90.87 %
Epoch 1445 of 2000 took 0.099s
  training loss:		0.165458
  validation loss:		0.299453
  validation accuracy:		91.63 %
Epoch 1446 of 2000 took 0.102s
  training loss:		0.161783
  validation loss:		0.306026
  validation accuracy:		91.52 %
Epoch 1447 of 2000 took 0.100s
  training loss:		0.163049
  validation loss:		0.324149
  validation accuracy:		90.76 %
Epoch 1448 of 2000 took 0.100s
  training loss:		0.160309
  validation loss:		0.314474
  validation accuracy:		91.30 %
Epoch 1449 of 2000 took 0.102s
  training loss:		0.160618
  validation loss:		0.298317
  validation accuracy:		91.63 %
Epoch 1450 of 2000 took 0.099s
  training loss:		0.164038
  validation loss:		0.301498
  validation accuracy:		91.74 %
Epoch 1451 of 2000 took 0.103s
  training loss:		0.156776
  validation loss:		0.307235
  validation accuracy:		91.52 %
Epoch 1452 of 2000 took 0.099s
  training loss:		0.157071
  validation loss:		0.304611
  validation accuracy:		91.85 %
Epoch 1453 of 2000 took 0.101s
  training loss:		0.162679
  validation loss:		0.311562
  validation accuracy:		91.30 %
Epoch 1454 of 2000 took 0.104s
  training loss:		0.160181
  validation loss:		0.307472
  validation accuracy:		91.85 %
Epoch 1455 of 2000 took 0.099s
  training loss:		0.161190
  validation loss:		0.310708
  validation accuracy:		91.74 %
Epoch 1456 of 2000 took 0.100s
  training loss:		0.159878
  validation loss:		0.309939
  validation accuracy:		91.30 %
Epoch 1457 of 2000 took 0.099s
  training loss:		0.158897
  validation loss:		0.311834
  validation accuracy:		91.41 %
Epoch 1458 of 2000 took 0.104s
  training loss:		0.161285
  validation loss:		0.304555
  validation accuracy:		91.63 %
Epoch 1459 of 2000 took 0.101s
  training loss:		0.155655
  validation loss:		0.310934
  validation accuracy:		91.30 %
Epoch 1460 of 2000 took 0.099s
  training loss:		0.154080
  validation loss:		0.311987
  validation accuracy:		91.20 %
Epoch 1461 of 2000 took 0.104s
  training loss:		0.155714
  validation loss:		0.303104
  validation accuracy:		91.52 %
Epoch 1462 of 2000 took 0.100s
  training loss:		0.153536
  validation loss:		0.300100
  validation accuracy:		91.74 %
Epoch 1463 of 2000 took 0.100s
  training loss:		0.159526
  validation loss:		0.331380
  validation accuracy:		90.43 %
Epoch 1464 of 2000 took 0.100s
  training loss:		0.159271
  validation loss:		0.306189
  validation accuracy:		91.96 %
Epoch 1465 of 2000 took 0.100s
  training loss:		0.155788
  validation loss:		0.320079
  validation accuracy:		90.87 %
Epoch 1466 of 2000 took 0.103s
  training loss:		0.152606
  validation loss:		0.319788
  validation accuracy:		90.98 %
Epoch 1467 of 2000 took 0.100s
  training loss:		0.154310
  validation loss:		0.308100
  validation accuracy:		91.63 %
Epoch 1468 of 2000 took 0.100s
  training loss:		0.155316
  validation loss:		0.312849
  validation accuracy:		91.20 %
Epoch 1469 of 2000 took 0.105s
  training loss:		0.155622
  validation loss:		0.307102
  validation accuracy:		92.17 %
Epoch 1470 of 2000 took 0.099s
  training loss:		0.157378
  validation loss:		0.304442
  validation accuracy:		91.52 %
Epoch 1471 of 2000 took 0.100s
  training loss:		0.153328
  validation loss:		0.316858
  validation accuracy:		91.41 %
Epoch 1472 of 2000 took 0.099s
  training loss:		0.153751
  validation loss:		0.303511
  validation accuracy:		91.41 %
Epoch 1473 of 2000 took 0.101s
  training loss:		0.151728
  validation loss:		0.308374
  validation accuracy:		91.30 %
Epoch 1474 of 2000 took 0.103s
  training loss:		0.154582
  validation loss:		0.303315
  validation accuracy:		91.52 %
Epoch 1475 of 2000 took 0.099s
  training loss:		0.150957
  validation loss:		0.305376
  validation accuracy:		91.52 %
Epoch 1476 of 2000 took 0.101s
  training loss:		0.154977
  validation loss:		0.308306
  validation accuracy:		91.30 %
Epoch 1477 of 2000 took 0.104s
  training loss:		0.155561
  validation loss:		0.321277
  validation accuracy:		90.98 %
Epoch 1478 of 2000 took 0.099s
  training loss:		0.151080
  validation loss:		0.312106
  validation accuracy:		91.30 %
Epoch 1479 of 2000 took 0.100s
  training loss:		0.151396
  validation loss:		0.299669
  validation accuracy:		91.74 %
Epoch 1480 of 2000 took 0.099s
  training loss:		0.152499
  validation loss:		0.311434
  validation accuracy:		91.09 %
Epoch 1481 of 2000 took 0.104s
  training loss:		0.147815
  validation loss:		0.319244
  validation accuracy:		91.20 %
Epoch 1482 of 2000 took 0.101s
  training loss:		0.150685
  validation loss:		0.315961
  validation accuracy:		90.98 %
Epoch 1483 of 2000 took 0.099s
  training loss:		0.151617
  validation loss:		0.305429
  validation accuracy:		91.41 %
Epoch 1484 of 2000 took 0.104s
  training loss:		0.152148
  validation loss:		0.317772
  validation accuracy:		91.41 %
Epoch 1485 of 2000 took 0.101s
  training loss:		0.147990
  validation loss:		0.310245
  validation accuracy:		91.63 %
Epoch 1486 of 2000 took 0.099s
  training loss:		0.150621
  validation loss:		0.327181
  validation accuracy:		91.30 %
Epoch 1487 of 2000 took 0.100s
  training loss:		0.150685
  validation loss:		0.315388
  validation accuracy:		91.63 %
Epoch 1488 of 2000 took 0.100s
  training loss:		0.146929
  validation loss:		0.310844
  validation accuracy:		91.09 %
Epoch 1489 of 2000 took 0.103s
  training loss:		0.151242
  validation loss:		0.312828
  validation accuracy:		91.63 %
Epoch 1490 of 2000 took 0.100s
  training loss:		0.152698
  validation loss:		0.313346
  validation accuracy:		90.98 %
Epoch 1491 of 2000 took 0.100s
  training loss:		0.148794
  validation loss:		0.319235
  validation accuracy:		91.30 %
Epoch 1492 of 2000 took 0.106s
  training loss:		0.148020
  validation loss:		0.325783
  validation accuracy:		90.76 %
Epoch 1493 of 2000 took 0.099s
  training loss:		0.146856
  validation loss:		0.313151
  validation accuracy:		90.98 %
Epoch 1494 of 2000 took 0.100s
  training loss:		0.146579
  validation loss:		0.313551
  validation accuracy:		91.74 %
Epoch 1495 of 2000 took 0.099s
  training loss:		0.149223
  validation loss:		0.311651
  validation accuracy:		91.09 %
Epoch 1496 of 2000 took 0.101s
  training loss:		0.147590
  validation loss:		0.328518
  validation accuracy:		90.87 %
Epoch 1497 of 2000 took 0.103s
  training loss:		0.151995
  validation loss:		0.309338
  validation accuracy:		91.63 %
Epoch 1498 of 2000 took 0.099s
  training loss:		0.149132
  validation loss:		0.319829
  validation accuracy:		91.41 %
Epoch 1499 of 2000 took 0.100s
  training loss:		0.145145
  validation loss:		0.312376
  validation accuracy:		91.63 %
Epoch 1500 of 2000 took 0.104s
  training loss:		0.148250
  validation loss:		0.314614
  validation accuracy:		90.87 %
Epoch 1501 of 2000 took 0.099s
  training loss:		0.140812
  validation loss:		0.317786
  validation accuracy:		90.98 %
Epoch 1502 of 2000 took 0.100s
  training loss:		0.146052
  validation loss:		0.314579
  validation accuracy:		91.20 %
Epoch 1503 of 2000 took 0.099s
  training loss:		0.142221
  validation loss:		0.312807
  validation accuracy:		91.09 %
Epoch 1504 of 2000 took 0.104s
  training loss:		0.141967
  validation loss:		0.317854
  validation accuracy:		91.09 %
Epoch 1505 of 2000 took 0.101s
  training loss:		0.146710
  validation loss:		0.316227
  validation accuracy:		90.98 %
Epoch 1506 of 2000 took 0.099s
  training loss:		0.142390
  validation loss:		0.310228
  validation accuracy:		91.96 %
Epoch 1507 of 2000 took 0.104s
  training loss:		0.142589
  validation loss:		0.313472
  validation accuracy:		91.63 %
Epoch 1508 of 2000 took 0.101s
  training loss:		0.138059
  validation loss:		0.313272
  validation accuracy:		91.85 %
Epoch 1509 of 2000 took 0.100s
  training loss:		0.144131
  validation loss:		0.320781
  validation accuracy:		90.98 %
Epoch 1510 of 2000 took 0.100s
  training loss:		0.144881
  validation loss:		0.326605
  validation accuracy:		90.65 %
Epoch 1511 of 2000 took 0.100s
  training loss:		0.144230
  validation loss:		0.317021
  validation accuracy:		91.30 %
Epoch 1512 of 2000 took 0.103s
  training loss:		0.139512
  validation loss:		0.324033
  validation accuracy:		91.63 %
Epoch 1513 of 2000 took 0.100s
  training loss:		0.138848
  validation loss:		0.318085
  validation accuracy:		90.98 %
Epoch 1514 of 2000 took 0.100s
  training loss:		0.144477
  validation loss:		0.315262
  validation accuracy:		91.41 %
Epoch 1515 of 2000 took 0.105s
  training loss:		0.143032
  validation loss:		0.330804
  validation accuracy:		90.87 %
Epoch 1516 of 2000 took 0.099s
  training loss:		0.144886
  validation loss:		0.320481
  validation accuracy:		91.52 %
Epoch 1517 of 2000 took 0.100s
  training loss:		0.141757
  validation loss:		0.312614
  validation accuracy:		91.30 %
Epoch 1518 of 2000 took 0.099s
  training loss:		0.137071
  validation loss:		0.310484
  validation accuracy:		91.41 %
Epoch 1519 of 2000 took 0.101s
  training loss:		0.142256
  validation loss:		0.314193
  validation accuracy:		90.98 %
Epoch 1520 of 2000 took 0.105s
  training loss:		0.140393
  validation loss:		0.318720
  validation accuracy:		91.09 %
Epoch 1521 of 2000 took 0.102s
  training loss:		0.140721
  validation loss:		0.315950
  validation accuracy:		90.87 %
Epoch 1522 of 2000 took 0.103s
  training loss:		0.142049
  validation loss:		0.315235
  validation accuracy:		90.65 %
Epoch 1523 of 2000 took 0.105s
  training loss:		0.140276
  validation loss:		0.329598
  validation accuracy:		90.87 %
Epoch 1524 of 2000 took 0.099s
  training loss:		0.139872
  validation loss:		0.315081
  validation accuracy:		91.30 %
Epoch 1525 of 2000 took 0.100s
  training loss:		0.142798
  validation loss:		0.321505
  validation accuracy:		90.76 %
Epoch 1526 of 2000 took 0.099s
  training loss:		0.142622
  validation loss:		0.322022
  validation accuracy:		90.98 %
Epoch 1527 of 2000 took 0.104s
  training loss:		0.141831
  validation loss:		0.315090
  validation accuracy:		90.98 %
Epoch 1528 of 2000 took 0.101s
  training loss:		0.136428
  validation loss:		0.315853
  validation accuracy:		91.63 %
Epoch 1529 of 2000 took 0.099s
  training loss:		0.137076
  validation loss:		0.318441
  validation accuracy:		90.87 %
Epoch 1530 of 2000 took 0.104s
  training loss:		0.135150
  validation loss:		0.313930
  validation accuracy:		91.41 %
Epoch 1531 of 2000 took 0.101s
  training loss:		0.138692
  validation loss:		0.324054
  validation accuracy:		90.65 %
Epoch 1532 of 2000 took 0.100s
  training loss:		0.138148
  validation loss:		0.312164
  validation accuracy:		91.52 %
Epoch 1533 of 2000 took 0.100s
  training loss:		0.137187
  validation loss:		0.313755
  validation accuracy:		91.09 %
Epoch 1534 of 2000 took 0.100s
  training loss:		0.137197
  validation loss:		0.319852
  validation accuracy:		91.09 %
Epoch 1535 of 2000 took 0.103s
  training loss:		0.138206
  validation loss:		0.317194
  validation accuracy:		90.98 %
Epoch 1536 of 2000 took 0.100s
  training loss:		0.136367
  validation loss:		0.318423
  validation accuracy:		91.09 %
Epoch 1537 of 2000 took 0.100s
  training loss:		0.137893
  validation loss:		0.318270
  validation accuracy:		90.87 %
Epoch 1538 of 2000 took 0.106s
  training loss:		0.136581
  validation loss:		0.329065
  validation accuracy:		91.63 %
Epoch 1539 of 2000 took 0.099s
  training loss:		0.133309
  validation loss:		0.320575
  validation accuracy:		90.87 %
Epoch 1540 of 2000 took 0.100s
  training loss:		0.134969
  validation loss:		0.323565
  validation accuracy:		90.87 %
Epoch 1541 of 2000 took 0.099s
  training loss:		0.133995
  validation loss:		0.325137
  validation accuracy:		90.76 %
Epoch 1542 of 2000 took 0.101s
  training loss:		0.135931
  validation loss:		0.311797
  validation accuracy:		91.85 %
Epoch 1543 of 2000 took 0.103s
  training loss:		0.134549
  validation loss:		0.323867
  validation accuracy:		90.87 %
Epoch 1544 of 2000 took 0.099s
  training loss:		0.136846
  validation loss:		0.336144
  validation accuracy:		90.87 %
Epoch 1545 of 2000 took 0.100s
  training loss:		0.131612
  validation loss:		0.310798
  validation accuracy:		92.39 %
Epoch 1546 of 2000 took 0.104s
  training loss:		0.138261
  validation loss:		0.317862
  validation accuracy:		91.52 %
Epoch 1547 of 2000 took 0.099s
  training loss:		0.136679
  validation loss:		0.310548
  validation accuracy:		91.85 %
Epoch 1548 of 2000 took 0.100s
  training loss:		0.136128
  validation loss:		0.323815
  validation accuracy:		91.20 %
Epoch 1549 of 2000 took 0.099s
  training loss:		0.128221
  validation loss:		0.315655
  validation accuracy:		91.41 %
Epoch 1550 of 2000 took 0.104s
  training loss:		0.133548
  validation loss:		0.329865
  validation accuracy:		90.98 %
Epoch 1551 of 2000 took 0.101s
  training loss:		0.136075
  validation loss:		0.315921
  validation accuracy:		91.09 %
Epoch 1552 of 2000 took 0.099s
  training loss:		0.129831
  validation loss:		0.326012
  validation accuracy:		91.20 %
Epoch 1553 of 2000 took 0.105s
  training loss:		0.133333
  validation loss:		0.321380
  validation accuracy:		91.09 %
Epoch 1554 of 2000 took 0.100s
  training loss:		0.132670
  validation loss:		0.333217
  validation accuracy:		91.85 %
Epoch 1555 of 2000 took 0.100s
  training loss:		0.138873
  validation loss:		0.316439
  validation accuracy:		91.52 %
Epoch 1556 of 2000 took 0.100s
  training loss:		0.130691
  validation loss:		0.328121
  validation accuracy:		90.87 %
Epoch 1557 of 2000 took 0.100s
  training loss:		0.130721
  validation loss:		0.331952
  validation accuracy:		90.98 %
Epoch 1558 of 2000 took 0.103s
  training loss:		0.133171
  validation loss:		0.319112
  validation accuracy:		91.20 %
Epoch 1559 of 2000 took 0.100s
  training loss:		0.131549
  validation loss:		0.322660
  validation accuracy:		90.87 %
Epoch 1560 of 2000 took 0.097s
  training loss:		0.128084
  validation loss:		0.322756
  validation accuracy:		90.98 %
Epoch 1561 of 2000 took 0.102s
  training loss:		0.131172
  validation loss:		0.323347
  validation accuracy:		91.63 %
Epoch 1562 of 2000 took 0.097s
  training loss:		0.133038
  validation loss:		0.334851
  validation accuracy:		91.09 %
Epoch 1563 of 2000 took 0.100s
  training loss:		0.128666
  validation loss:		0.322296
  validation accuracy:		91.63 %
Epoch 1564 of 2000 took 0.099s
  training loss:		0.130503
  validation loss:		0.330506
  validation accuracy:		91.20 %
Epoch 1565 of 2000 took 0.101s
  training loss:		0.125224
  validation loss:		0.323301
  validation accuracy:		91.30 %
Epoch 1566 of 2000 took 0.103s
  training loss:		0.131183
  validation loss:		0.326623
  validation accuracy:		91.09 %
Epoch 1567 of 2000 took 0.099s
  training loss:		0.125799
  validation loss:		0.320041
  validation accuracy:		90.76 %
Epoch 1568 of 2000 took 0.100s
  training loss:		0.129209
  validation loss:		0.333825
  validation accuracy:		90.98 %
Epoch 1569 of 2000 took 0.104s
  training loss:		0.128329
  validation loss:		0.329686
  validation accuracy:		90.98 %
Epoch 1570 of 2000 took 0.099s
  training loss:		0.125987
  validation loss:		0.317552
  validation accuracy:		91.52 %
Epoch 1571 of 2000 took 0.100s
  training loss:		0.130883
  validation loss:		0.328392
  validation accuracy:		91.09 %
Epoch 1572 of 2000 took 0.099s
  training loss:		0.128238
  validation loss:		0.322719
  validation accuracy:		92.07 %
Epoch 1573 of 2000 took 0.104s
  training loss:		0.130196
  validation loss:		0.331488
  validation accuracy:		91.41 %
Epoch 1574 of 2000 took 0.101s
  training loss:		0.124937
  validation loss:		0.333111
  validation accuracy:		90.98 %
Epoch 1575 of 2000 took 0.099s
  training loss:		0.127071
  validation loss:		0.339332
  validation accuracy:		90.76 %
Epoch 1576 of 2000 took 0.104s
  training loss:		0.126779
  validation loss:		0.329856
  validation accuracy:		91.09 %
Epoch 1577 of 2000 took 0.101s
  training loss:		0.122633
  validation loss:		0.331194
  validation accuracy:		90.98 %
Epoch 1578 of 2000 took 0.100s
  training loss:		0.125155
  validation loss:		0.333828
  validation accuracy:		90.54 %
Epoch 1579 of 2000 took 0.100s
  training loss:		0.125011
  validation loss:		0.330618
  validation accuracy:		91.20 %
Epoch 1580 of 2000 took 0.100s
  training loss:		0.123603
  validation loss:		0.323693
  validation accuracy:		91.52 %
Epoch 1581 of 2000 took 0.103s
  training loss:		0.130516
  validation loss:		0.333981
  validation accuracy:		90.76 %
Epoch 1582 of 2000 took 0.100s
  training loss:		0.126665
  validation loss:		0.342309
  validation accuracy:		91.30 %
Epoch 1583 of 2000 took 0.100s
  training loss:		0.124241
  validation loss:		0.322090
  validation accuracy:		91.20 %
Epoch 1584 of 2000 took 0.106s
  training loss:		0.121963
  validation loss:		0.327793
  validation accuracy:		90.98 %
Epoch 1585 of 2000 took 0.099s
  training loss:		0.128431
  validation loss:		0.325546
  validation accuracy:		91.20 %
Epoch 1586 of 2000 took 0.100s
  training loss:		0.122287
  validation loss:		0.324790
  validation accuracy:		91.63 %
Epoch 1587 of 2000 took 0.102s
  training loss:		0.124992
  validation loss:		0.320034
  validation accuracy:		91.96 %
Epoch 1588 of 2000 took 0.101s
  training loss:		0.120470
  validation loss:		0.318534
  validation accuracy:		91.74 %
Epoch 1589 of 2000 took 0.103s
  training loss:		0.125029
  validation loss:		0.326517
  validation accuracy:		91.20 %
Epoch 1590 of 2000 took 0.099s
  training loss:		0.122542
  validation loss:		0.329077
  validation accuracy:		91.20 %
Epoch 1591 of 2000 took 0.100s
  training loss:		0.121111
  validation loss:		0.329384
  validation accuracy:		91.20 %
Epoch 1592 of 2000 took 0.104s
  training loss:		0.124502
  validation loss:		0.324002
  validation accuracy:		91.41 %
Epoch 1593 of 2000 took 0.099s
  training loss:		0.122317
  validation loss:		0.325755
  validation accuracy:		91.41 %
Epoch 1594 of 2000 took 0.100s
  training loss:		0.121847
  validation loss:		0.329517
  validation accuracy:		90.98 %
Epoch 1595 of 2000 took 0.099s
  training loss:		0.121631
  validation loss:		0.326153
  validation accuracy:		91.41 %
Epoch 1596 of 2000 took 0.103s
  training loss:		0.121461
  validation loss:		0.347484
  validation accuracy:		90.98 %
Epoch 1597 of 2000 took 0.101s
  training loss:		0.119862
  validation loss:		0.334955
  validation accuracy:		91.30 %
Epoch 1598 of 2000 took 0.099s
  training loss:		0.121308
  validation loss:		0.327252
  validation accuracy:		91.52 %
Epoch 1599 of 2000 took 0.104s
  training loss:		0.121747
  validation loss:		0.339155
  validation accuracy:		90.65 %
Epoch 1600 of 2000 took 0.101s
  training loss:		0.121581
  validation loss:		0.331927
  validation accuracy:		91.20 %
Epoch 1601 of 2000 took 0.100s
  training loss:		0.124457
  validation loss:		0.315337
  validation accuracy:		92.17 %
Epoch 1602 of 2000 took 0.098s
  training loss:		0.122543
  validation loss:		0.323158
  validation accuracy:		91.63 %
Epoch 1603 of 2000 took 0.097s
  training loss:		0.125343
  validation loss:		0.323723
  validation accuracy:		91.09 %
Epoch 1604 of 2000 took 0.100s
  training loss:		0.123181
  validation loss:		0.330625
  validation accuracy:		91.63 %
Epoch 1605 of 2000 took 0.097s
  training loss:		0.119024
  validation loss:		0.336911
  validation accuracy:		90.65 %
Epoch 1606 of 2000 took 0.097s
  training loss:		0.121102
  validation loss:		0.332970
  validation accuracy:		91.52 %
Epoch 1607 of 2000 took 0.102s
  training loss:		0.122123
  validation loss:		0.329521
  validation accuracy:		90.76 %
Epoch 1608 of 2000 took 0.096s
  training loss:		0.120928
  validation loss:		0.341033
  validation accuracy:		91.30 %
Epoch 1609 of 2000 took 0.097s
  training loss:		0.121041
  validation loss:		0.327347
  validation accuracy:		91.41 %
Epoch 1610 of 2000 took 0.096s
  training loss:		0.117512
  validation loss:		0.333069
  validation accuracy:		90.98 %
Epoch 1611 of 2000 took 0.098s
  training loss:		0.118992
  validation loss:		0.323890
  validation accuracy:		91.09 %
Epoch 1612 of 2000 took 0.100s
  training loss:		0.117341
  validation loss:		0.334965
  validation accuracy:		91.20 %
Epoch 1613 of 2000 took 0.096s
  training loss:		0.122543
  validation loss:		0.325283
  validation accuracy:		91.20 %
Epoch 1614 of 2000 took 0.097s
  training loss:		0.120820
  validation loss:		0.328841
  validation accuracy:		91.52 %
Epoch 1615 of 2000 took 0.102s
  training loss:		0.115542
  validation loss:		0.327042
  validation accuracy:		91.85 %
Epoch 1616 of 2000 took 0.096s
  training loss:		0.117586
  validation loss:		0.330980
  validation accuracy:		91.20 %
Epoch 1617 of 2000 took 0.097s
  training loss:		0.118096
  validation loss:		0.343321
  validation accuracy:		90.98 %
Epoch 1618 of 2000 took 0.096s
  training loss:		0.116593
  validation loss:		0.327665
  validation accuracy:		91.41 %
Epoch 1619 of 2000 took 0.100s
  training loss:		0.116253
  validation loss:		0.328756
  validation accuracy:		91.52 %
Epoch 1620 of 2000 took 0.098s
  training loss:		0.115599
  validation loss:		0.334705
  validation accuracy:		91.20 %
Epoch 1621 of 2000 took 0.096s
  training loss:		0.114979
  validation loss:		0.342959
  validation accuracy:		91.85 %
Epoch 1622 of 2000 took 0.100s
  training loss:		0.118019
  validation loss:		0.339434
  validation accuracy:		91.20 %
Epoch 1623 of 2000 took 0.099s
  training loss:		0.113457
  validation loss:		0.331843
  validation accuracy:		91.63 %
Epoch 1624 of 2000 took 0.096s
  training loss:		0.118428
  validation loss:		0.325661
  validation accuracy:		91.74 %
Epoch 1625 of 2000 took 0.097s
  training loss:		0.116710
  validation loss:		0.325422
  validation accuracy:		92.17 %
Epoch 1626 of 2000 took 0.096s
  training loss:		0.117751
  validation loss:		0.341642
  validation accuracy:		90.76 %
Epoch 1627 of 2000 took 0.101s
  training loss:		0.120156
  validation loss:		0.327044
  validation accuracy:		91.63 %
Epoch 1628 of 2000 took 0.097s
  training loss:		0.115905
  validation loss:		0.338152
  validation accuracy:		91.09 %
Epoch 1629 of 2000 took 0.096s
  training loss:		0.111828
  validation loss:		0.347043
  validation accuracy:		91.63 %
Epoch 1630 of 2000 took 0.102s
  training loss:		0.112844
  validation loss:		0.327832
  validation accuracy:		91.52 %
Epoch 1631 of 2000 took 0.096s
  training loss:		0.111351
  validation loss:		0.326295
  validation accuracy:		91.20 %
Epoch 1632 of 2000 took 0.097s
  training loss:		0.114209
  validation loss:		0.331774
  validation accuracy:		92.07 %
Epoch 1633 of 2000 took 0.096s
  training loss:		0.114595
  validation loss:		0.336175
  validation accuracy:		91.63 %
Epoch 1634 of 2000 took 0.097s
  training loss:		0.116019
  validation loss:		0.334648
  validation accuracy:		91.52 %
Epoch 1635 of 2000 took 0.100s
  training loss:		0.112877
  validation loss:		0.337339
  validation accuracy:		91.41 %
Epoch 1636 of 2000 took 0.096s
  training loss:		0.113690
  validation loss:		0.342849
  validation accuracy:		91.52 %
Epoch 1637 of 2000 took 0.097s
  training loss:		0.113895
  validation loss:		0.339359
  validation accuracy:		91.96 %
Epoch 1638 of 2000 took 0.102s
  training loss:		0.113769
  validation loss:		0.326560
  validation accuracy:		91.74 %
Epoch 1639 of 2000 took 0.096s
  training loss:		0.108696
  validation loss:		0.343430
  validation accuracy:		91.63 %
Epoch 1640 of 2000 took 0.097s
  training loss:		0.114071
  validation loss:		0.346159
  validation accuracy:		91.09 %
Epoch 1641 of 2000 took 0.096s
  training loss:		0.116009
  validation loss:		0.341628
  validation accuracy:		91.52 %
Epoch 1642 of 2000 took 0.099s
  training loss:		0.107906
  validation loss:		0.333002
  validation accuracy:		91.63 %
Epoch 1643 of 2000 took 0.099s
  training loss:		0.110558
  validation loss:		0.344652
  validation accuracy:		91.30 %
Epoch 1644 of 2000 took 0.096s
  training loss:		0.109320
  validation loss:		0.340488
  validation accuracy:		91.20 %
Epoch 1645 of 2000 took 0.099s
  training loss:		0.110964
  validation loss:		0.336424
  validation accuracy:		90.76 %
Epoch 1646 of 2000 took 0.100s
  training loss:		0.112498
  validation loss:		0.352691
  validation accuracy:		91.20 %
Epoch 1647 of 2000 took 0.096s
  training loss:		0.107151
  validation loss:		0.337537
  validation accuracy:		91.63 %
Epoch 1648 of 2000 took 0.097s
  training loss:		0.112822
  validation loss:		0.353999
  validation accuracy:		91.20 %
Epoch 1649 of 2000 took 0.096s
  training loss:		0.107212
  validation loss:		0.347193
  validation accuracy:		91.63 %
Epoch 1650 of 2000 took 0.101s
  training loss:		0.113836
  validation loss:		0.353182
  validation accuracy:		91.30 %
Epoch 1651 of 2000 took 0.097s
  training loss:		0.112711
  validation loss:		0.339169
  validation accuracy:		91.96 %
Epoch 1652 of 2000 took 0.096s
  training loss:		0.108610
  validation loss:		0.348693
  validation accuracy:		91.85 %
Epoch 1653 of 2000 took 0.102s
  training loss:		0.110136
  validation loss:		0.349600
  validation accuracy:		91.09 %
Epoch 1654 of 2000 took 0.097s
  training loss:		0.112149
  validation loss:		0.333313
  validation accuracy:		91.30 %
Epoch 1655 of 2000 took 0.097s
  training loss:		0.109401
  validation loss:		0.346794
  validation accuracy:		92.07 %
Epoch 1656 of 2000 took 0.096s
  training loss:		0.108229
  validation loss:		0.348006
  validation accuracy:		91.30 %
Epoch 1657 of 2000 took 0.097s
  training loss:		0.109124
  validation loss:		0.345453
  validation accuracy:		91.30 %
Epoch 1658 of 2000 took 0.100s
  training loss:		0.110161
  validation loss:		0.343058
  validation accuracy:		91.63 %
Epoch 1659 of 2000 took 0.097s
  training loss:		0.111261
  validation loss:		0.349829
  validation accuracy:		91.30 %
Epoch 1660 of 2000 took 0.097s
  training loss:		0.109665
  validation loss:		0.355294
  validation accuracy:		90.98 %
Epoch 1661 of 2000 took 0.102s
  training loss:		0.107692
  validation loss:		0.349801
  validation accuracy:		91.30 %
Epoch 1662 of 2000 took 0.096s
  training loss:		0.106383
  validation loss:		0.347423
  validation accuracy:		91.30 %
Epoch 1663 of 2000 took 0.097s
  training loss:		0.103409
  validation loss:		0.343048
  validation accuracy:		91.30 %
Epoch 1664 of 2000 took 0.096s
  training loss:		0.109803
  validation loss:		0.346179
  validation accuracy:		91.85 %
Epoch 1665 of 2000 took 0.098s
  training loss:		0.107898
  validation loss:		0.352944
  validation accuracy:		91.20 %
Epoch 1666 of 2000 took 0.099s
  training loss:		0.107453
  validation loss:		0.362896
  validation accuracy:		91.09 %
Epoch 1667 of 2000 took 0.096s
  training loss:		0.107238
  validation loss:		0.350368
  validation accuracy:		92.50 %
Epoch 1668 of 2000 took 0.098s
  training loss:		0.105756
  validation loss:		0.341517
  validation accuracy:		91.30 %
Epoch 1669 of 2000 took 0.100s
  training loss:		0.110288
  validation loss:		0.356381
  validation accuracy:		91.74 %
Epoch 1670 of 2000 took 0.096s
  training loss:		0.104208
  validation loss:		0.340683
  validation accuracy:		91.96 %
Epoch 1671 of 2000 took 0.097s
  training loss:		0.108011
  validation loss:		0.355328
  validation accuracy:		91.20 %
Epoch 1672 of 2000 took 0.096s
  training loss:		0.106622
  validation loss:		0.352140
  validation accuracy:		91.41 %
Epoch 1673 of 2000 took 0.101s
  training loss:		0.106719
  validation loss:		0.361235
  validation accuracy:		91.20 %
Epoch 1674 of 2000 took 0.097s
  training loss:		0.108098
  validation loss:		0.349071
  validation accuracy:		92.28 %
Epoch 1675 of 2000 took 0.096s
  training loss:		0.106381
  validation loss:		0.366669
  validation accuracy:		90.98 %
Epoch 1676 of 2000 took 0.102s
  training loss:		0.102510
  validation loss:		0.361392
  validation accuracy:		92.07 %
Epoch 1677 of 2000 took 0.097s
  training loss:		0.106005
  validation loss:		0.365039
  validation accuracy:		91.41 %
Epoch 1678 of 2000 took 0.097s
  training loss:		0.103177
  validation loss:		0.352584
  validation accuracy:		91.52 %
Epoch 1679 of 2000 took 0.096s
  training loss:		0.107948
  validation loss:		0.341543
  validation accuracy:		91.20 %
Epoch 1680 of 2000 took 0.097s
  training loss:		0.102161
  validation loss:		0.349809
  validation accuracy:		91.41 %
Epoch 1681 of 2000 took 0.100s
  training loss:		0.100815
  validation loss:		0.366179
  validation accuracy:		91.20 %
Epoch 1682 of 2000 took 0.097s
  training loss:		0.104027
  validation loss:		0.347197
  validation accuracy:		91.96 %
Epoch 1683 of 2000 took 0.097s
  training loss:		0.105840
  validation loss:		0.350248
  validation accuracy:		91.63 %
Epoch 1684 of 2000 took 0.102s
  training loss:		0.101422
  validation loss:		0.335261
  validation accuracy:		92.50 %
Epoch 1685 of 2000 took 0.096s
  training loss:		0.101927
  validation loss:		0.356844
  validation accuracy:		91.63 %
Epoch 1686 of 2000 took 0.097s
  training loss:		0.101649
  validation loss:		0.370786
  validation accuracy:		92.07 %
Epoch 1687 of 2000 took 0.096s
  training loss:		0.100734
  validation loss:		0.360622
  validation accuracy:		91.30 %
Epoch 1688 of 2000 took 0.098s
  training loss:		0.103382
  validation loss:		0.349967
  validation accuracy:		91.52 %
Epoch 1689 of 2000 took 0.099s
  training loss:		0.102968
  validation loss:		0.344659
  validation accuracy:		91.85 %
Epoch 1690 of 2000 took 0.096s
  training loss:		0.102878
  validation loss:		0.349577
  validation accuracy:		92.39 %
Epoch 1691 of 2000 took 0.098s
  training loss:		0.099971
  validation loss:		0.378007
  validation accuracy:		90.98 %
Epoch 1692 of 2000 took 0.100s
  training loss:		0.104117
  validation loss:		0.366412
  validation accuracy:		91.41 %
Epoch 1693 of 2000 took 0.096s
  training loss:		0.101188
  validation loss:		0.352491
  validation accuracy:		91.52 %
Epoch 1694 of 2000 took 0.097s
  training loss:		0.095921
  validation loss:		0.355096
  validation accuracy:		91.30 %
Epoch 1695 of 2000 took 0.096s
  training loss:		0.104021
  validation loss:		0.356729
  validation accuracy:		91.74 %
Epoch 1696 of 2000 took 0.101s
  training loss:		0.102317
  validation loss:		0.363080
  validation accuracy:		92.28 %
Epoch 1697 of 2000 took 0.098s
  training loss:		0.103134
  validation loss:		0.369565
  validation accuracy:		91.74 %
Epoch 1698 of 2000 took 0.096s
  training loss:		0.104332
  validation loss:		0.366331
  validation accuracy:		91.30 %
Epoch 1699 of 2000 took 0.102s
  training loss:		0.101852
  validation loss:		0.365556
  validation accuracy:		90.98 %
Epoch 1700 of 2000 took 0.097s
  training loss:		0.100839
  validation loss:		0.372795
  validation accuracy:		91.85 %
Epoch 1701 of 2000 took 0.097s
  training loss:		0.102902
  validation loss:		0.346053
  validation accuracy:		92.28 %
Epoch 1702 of 2000 took 0.096s
  training loss:		0.099853
  validation loss:		0.367359
  validation accuracy:		91.20 %
Epoch 1703 of 2000 took 0.097s
  training loss:		0.100715
  validation loss:		0.358190
  validation accuracy:		92.28 %
Epoch 1704 of 2000 took 0.101s
  training loss:		0.099810
  validation loss:		0.369358
  validation accuracy:		91.41 %
Epoch 1705 of 2000 took 0.096s
  training loss:		0.099579
  validation loss:		0.361978
  validation accuracy:		91.74 %
Epoch 1706 of 2000 took 0.097s
  training loss:		0.100555
  validation loss:		0.367310
  validation accuracy:		91.30 %
Epoch 1707 of 2000 took 0.102s
  training loss:		0.102946
  validation loss:		0.379009
  validation accuracy:		91.41 %
Epoch 1708 of 2000 took 0.096s
  training loss:		0.102752
  validation loss:		0.385308
  validation accuracy:		91.63 %
Epoch 1709 of 2000 took 0.097s
  training loss:		0.098815
  validation loss:		0.367141
  validation accuracy:		91.96 %
Epoch 1710 of 2000 took 0.096s
  training loss:		0.098250
  validation loss:		0.366442
  validation accuracy:		91.74 %
Epoch 1711 of 2000 took 0.098s
  training loss:		0.095011
  validation loss:		0.360784
  validation accuracy:		91.74 %
Epoch 1712 of 2000 took 0.099s
  training loss:		0.098385
  validation loss:		0.362296
  validation accuracy:		91.74 %
Epoch 1713 of 2000 took 0.096s
  training loss:		0.095477
  validation loss:		0.378968
  validation accuracy:		91.52 %
Epoch 1714 of 2000 took 0.098s
  training loss:		0.100546
  validation loss:		0.382021
  validation accuracy:		91.63 %
Epoch 1715 of 2000 took 0.100s
  training loss:		0.100800
  validation loss:		0.381304
  validation accuracy:		91.63 %
Epoch 1716 of 2000 took 0.096s
  training loss:		0.095903
  validation loss:		0.367831
  validation accuracy:		91.85 %
Epoch 1717 of 2000 took 0.097s
  training loss:		0.099518
  validation loss:		0.371838
  validation accuracy:		91.41 %
Epoch 1718 of 2000 took 0.096s
  training loss:		0.097825
  validation loss:		0.365436
  validation accuracy:		91.74 %
Epoch 1719 of 2000 took 0.101s
  training loss:		0.099044
  validation loss:		0.377364
  validation accuracy:		91.74 %
Epoch 1720 of 2000 took 0.097s
  training loss:		0.097442
  validation loss:		0.385538
  validation accuracy:		91.74 %
Epoch 1721 of 2000 took 0.096s
  training loss:		0.097762
  validation loss:		0.369600
  validation accuracy:		91.30 %
Epoch 1722 of 2000 took 0.102s
  training loss:		0.092838
  validation loss:		0.362548
  validation accuracy:		91.85 %
Epoch 1723 of 2000 took 0.097s
  training loss:		0.095442
  validation loss:		0.358408
  validation accuracy:		91.52 %
Epoch 1724 of 2000 took 0.097s
  training loss:		0.096361
  validation loss:		0.363445
  validation accuracy:		91.85 %
Epoch 1725 of 2000 took 0.097s
  training loss:		0.094587
  validation loss:		0.353213
  validation accuracy:		91.85 %
Epoch 1726 of 2000 took 0.097s
  training loss:		0.096388
  validation loss:		0.353452
  validation accuracy:		92.50 %
Epoch 1727 of 2000 took 0.100s
  training loss:		0.097166
  validation loss:		0.372251
  validation accuracy:		91.74 %
Epoch 1728 of 2000 took 0.097s
  training loss:		0.097395
  validation loss:		0.367939
  validation accuracy:		91.41 %
Epoch 1729 of 2000 took 0.097s
  training loss:		0.097644
  validation loss:		0.391971
  validation accuracy:		91.63 %
Epoch 1730 of 2000 took 0.102s
  training loss:		0.095990
  validation loss:		0.360290
  validation accuracy:		92.07 %
Epoch 1731 of 2000 took 0.096s
  training loss:		0.099828
  validation loss:		0.371209
  validation accuracy:		91.85 %
Epoch 1732 of 2000 took 0.097s
  training loss:		0.094200
  validation loss:		0.374879
  validation accuracy:		91.52 %
Epoch 1733 of 2000 took 0.096s
  training loss:		0.095858
  validation loss:		0.371185
  validation accuracy:		91.30 %
Epoch 1734 of 2000 took 0.098s
  training loss:		0.095080
  validation loss:		0.369008
  validation accuracy:		92.07 %
Epoch 1735 of 2000 took 0.100s
  training loss:		0.090999
  validation loss:		0.362657
  validation accuracy:		92.61 %
Epoch 1736 of 2000 took 0.096s
  training loss:		0.090669
  validation loss:		0.376792
  validation accuracy:		92.17 %
Epoch 1737 of 2000 took 0.098s
  training loss:		0.095310
  validation loss:		0.379012
  validation accuracy:		91.63 %
Epoch 1738 of 2000 took 0.101s
  training loss:		0.094175
  validation loss:		0.405059
  validation accuracy:		91.30 %
Epoch 1739 of 2000 took 0.096s
  training loss:		0.097158
  validation loss:		0.366890
  validation accuracy:		91.96 %
Epoch 1740 of 2000 took 0.097s
  training loss:		0.090731
  validation loss:		0.374376
  validation accuracy:		91.52 %
Epoch 1741 of 2000 took 0.096s
  training loss:		0.095970
  validation loss:		0.382415
  validation accuracy:		92.07 %
Epoch 1742 of 2000 took 0.101s
  training loss:		0.089832
  validation loss:		0.362086
  validation accuracy:		92.28 %
Epoch 1743 of 2000 took 0.097s
  training loss:		0.092299
  validation loss:		0.364544
  validation accuracy:		92.39 %
Epoch 1744 of 2000 took 0.096s
  training loss:		0.098010
  validation loss:		0.384106
  validation accuracy:		91.63 %
Epoch 1745 of 2000 took 0.102s
  training loss:		0.094783
  validation loss:		0.362219
  validation accuracy:		92.50 %
Epoch 1746 of 2000 took 0.097s
  training loss:		0.095084
  validation loss:		0.378947
  validation accuracy:		91.74 %
Epoch 1747 of 2000 took 0.097s
  training loss:		0.088976
  validation loss:		0.368227
  validation accuracy:		91.85 %
Epoch 1748 of 2000 took 0.097s
  training loss:		0.097152
  validation loss:		0.380819
  validation accuracy:		91.63 %
Epoch 1749 of 2000 took 0.097s
  training loss:		0.095530
  validation loss:		0.371165
  validation accuracy:		92.39 %
Epoch 1750 of 2000 took 0.100s
  training loss:		0.094569
  validation loss:		0.380322
  validation accuracy:		91.96 %
Epoch 1751 of 2000 took 0.097s
  training loss:		0.092905
  validation loss:		0.385849
  validation accuracy:		91.52 %
Epoch 1752 of 2000 took 0.097s
  training loss:		0.091280
  validation loss:		0.374813
  validation accuracy:		91.85 %
Epoch 1753 of 2000 took 0.102s
  training loss:		0.093018
  validation loss:		0.374957
  validation accuracy:		92.39 %
Epoch 1754 of 2000 took 0.096s
  training loss:		0.092385
  validation loss:		0.374207
  validation accuracy:		91.74 %
Epoch 1755 of 2000 took 0.097s
  training loss:		0.092819
  validation loss:		0.390631
  validation accuracy:		91.74 %
Epoch 1756 of 2000 took 0.096s
  training loss:		0.089324
  validation loss:		0.367411
  validation accuracy:		92.72 %
Epoch 1757 of 2000 took 0.098s
  training loss:		0.093860
  validation loss:		0.403521
  validation accuracy:		90.98 %
Epoch 1758 of 2000 took 0.100s
  training loss:		0.094193
  validation loss:		0.369721
  validation accuracy:		91.85 %
Epoch 1759 of 2000 took 0.096s
  training loss:		0.091164
  validation loss:		0.391431
  validation accuracy:		91.96 %
Epoch 1760 of 2000 took 0.097s
  training loss:		0.092363
  validation loss:		0.373295
  validation accuracy:		91.85 %
Epoch 1761 of 2000 took 0.102s
  training loss:		0.091619
  validation loss:		0.385864
  validation accuracy:		91.85 %
Epoch 1762 of 2000 took 0.096s
  training loss:		0.089890
  validation loss:		0.401010
  validation accuracy:		91.52 %
Epoch 1763 of 2000 took 0.097s
  training loss:		0.093367
  validation loss:		0.380349
  validation accuracy:		91.85 %
Epoch 1764 of 2000 took 0.096s
  training loss:		0.088235
  validation loss:		0.388078
  validation accuracy:		92.07 %
Epoch 1765 of 2000 took 0.101s
  training loss:		0.091484
  validation loss:		0.400209
  validation accuracy:		91.41 %
Epoch 1766 of 2000 took 0.098s
  training loss:		0.090247
  validation loss:		0.403199
  validation accuracy:		91.52 %
Epoch 1767 of 2000 took 0.096s
  training loss:		0.088911
  validation loss:		0.383454
  validation accuracy:		92.07 %
Epoch 1768 of 2000 took 0.100s
  training loss:		0.090183
  validation loss:		0.378934
  validation accuracy:		91.85 %
Epoch 1769 of 2000 took 0.098s
  training loss:		0.088662
  validation loss:		0.389613
  validation accuracy:		91.41 %
Epoch 1770 of 2000 took 0.097s
  training loss:		0.089630
  validation loss:		0.386968
  validation accuracy:		91.63 %
Epoch 1771 of 2000 took 0.097s
  training loss:		0.088823
  validation loss:		0.389797
  validation accuracy:		91.52 %
Epoch 1772 of 2000 took 0.096s
  training loss:		0.089395
  validation loss:		0.402291
  validation accuracy:		91.52 %
Epoch 1773 of 2000 took 0.100s
  training loss:		0.091317
  validation loss:		0.374234
  validation accuracy:		91.96 %
Epoch 1774 of 2000 took 0.097s
  training loss:		0.089925
  validation loss:		0.379368
  validation accuracy:		91.63 %
Epoch 1775 of 2000 took 0.096s
  training loss:		0.086888
  validation loss:		0.380954
  validation accuracy:		91.63 %
Epoch 1776 of 2000 took 0.103s
  training loss:		0.089333
  validation loss:		0.365896
  validation accuracy:		92.72 %
Epoch 1777 of 2000 took 0.096s
  training loss:		0.090982
  validation loss:		0.382809
  validation accuracy:		91.85 %
Epoch 1778 of 2000 took 0.097s
  training loss:		0.090437
  validation loss:		0.373219
  validation accuracy:		92.39 %
Epoch 1779 of 2000 took 0.096s
  training loss:		0.086341
  validation loss:		0.414526
  validation accuracy:		91.41 %
Epoch 1780 of 2000 took 0.098s
  training loss:		0.089082
  validation loss:		0.409221
  validation accuracy:		91.41 %
Epoch 1781 of 2000 took 0.100s
  training loss:		0.089436
  validation loss:		0.377892
  validation accuracy:		92.28 %
Epoch 1782 of 2000 took 0.096s
  training loss:		0.087510
  validation loss:		0.393301
  validation accuracy:		91.63 %
Epoch 1783 of 2000 took 0.097s
  training loss:		0.088653
  validation loss:		0.391426
  validation accuracy:		92.39 %
Epoch 1784 of 2000 took 0.102s
  training loss:		0.090377
  validation loss:		0.391783
  validation accuracy:		91.85 %
Epoch 1785 of 2000 took 0.096s
  training loss:		0.086547
  validation loss:		0.393842
  validation accuracy:		91.85 %
Epoch 1786 of 2000 took 0.097s
  training loss:		0.083545
  validation loss:		0.389773
  validation accuracy:		91.74 %
Epoch 1787 of 2000 took 0.096s
  training loss:		0.089341
  validation loss:		0.405916
  validation accuracy:		92.07 %
Epoch 1788 of 2000 took 0.099s
  training loss:		0.085814
  validation loss:		0.392945
  validation accuracy:		91.85 %
Epoch 1789 of 2000 took 0.098s
  training loss:		0.087706
  validation loss:		0.373891
  validation accuracy:		92.39 %
Epoch 1790 of 2000 took 0.096s
  training loss:		0.088413
  validation loss:		0.388855
  validation accuracy:		91.41 %
Epoch 1791 of 2000 took 0.099s
  training loss:		0.088835
  validation loss:		0.405828
  validation accuracy:		91.52 %
Epoch 1792 of 2000 took 0.099s
  training loss:		0.086828
  validation loss:		0.378078
  validation accuracy:		91.74 %
Epoch 1793 of 2000 took 0.097s
  training loss:		0.085157
  validation loss:		0.392667
  validation accuracy:		92.07 %
Epoch 1794 of 2000 took 0.097s
  training loss:		0.084649
  validation loss:		0.395127
  validation accuracy:		91.96 %
Epoch 1795 of 2000 took 0.096s
  training loss:		0.084097
  validation loss:		0.394395
  validation accuracy:		91.85 %
Epoch 1796 of 2000 took 0.101s
  training loss:		0.086111
  validation loss:		0.409186
  validation accuracy:		91.74 %
Epoch 1797 of 2000 took 0.097s
  training loss:		0.087616
  validation loss:		0.419901
  validation accuracy:		91.52 %
Epoch 1798 of 2000 took 0.096s
  training loss:		0.087834
  validation loss:		0.394290
  validation accuracy:		92.17 %
Epoch 1799 of 2000 took 0.102s
  training loss:		0.083764
  validation loss:		0.396892
  validation accuracy:		91.74 %
Epoch 1800 of 2000 took 0.096s
  training loss:		0.085234
  validation loss:		0.398302
  validation accuracy:		91.41 %
Epoch 1801 of 2000 took 0.097s
  training loss:		0.084262
  validation loss:		0.400989
  validation accuracy:		91.85 %
Epoch 1802 of 2000 took 0.096s
  training loss:		0.084996
  validation loss:		0.407342
  validation accuracy:		91.52 %
Epoch 1803 of 2000 took 0.098s
  training loss:		0.085163
  validation loss:		0.396788
  validation accuracy:		91.85 %
Epoch 1804 of 2000 took 0.101s
  training loss:		0.083932
  validation loss:		0.393887
  validation accuracy:		91.63 %
Epoch 1805 of 2000 took 0.096s
  training loss:		0.083786
  validation loss:		0.396890
  validation accuracy:		91.63 %
Epoch 1806 of 2000 took 0.097s
  training loss:		0.083424
  validation loss:		0.405867
  validation accuracy:		91.52 %
Epoch 1807 of 2000 took 0.102s
  training loss:		0.085691
  validation loss:		0.403969
  validation accuracy:		92.07 %
Epoch 1808 of 2000 took 0.096s
  training loss:		0.082643
  validation loss:		0.396649
  validation accuracy:		91.85 %
Epoch 1809 of 2000 took 0.097s
  training loss:		0.088134
  validation loss:		0.414580
  validation accuracy:		91.52 %
Epoch 1810 of 2000 took 0.096s
  training loss:		0.083668
  validation loss:		0.413378
  validation accuracy:		91.30 %
Epoch 1811 of 2000 took 0.099s
  training loss:		0.084111
  validation loss:		0.408783
  validation accuracy:		91.52 %
Epoch 1812 of 2000 took 0.099s
  training loss:		0.085727
  validation loss:		0.401281
  validation accuracy:		91.74 %
Epoch 1813 of 2000 took 0.096s
  training loss:		0.084771
  validation loss:		0.391766
  validation accuracy:		91.96 %
Epoch 1814 of 2000 took 0.099s
  training loss:		0.084624
  validation loss:		0.408539
  validation accuracy:		91.85 %
Epoch 1815 of 2000 took 0.097s
  training loss:		0.082773
  validation loss:		0.427400
  validation accuracy:		90.98 %
Epoch 1816 of 2000 took 0.097s
  training loss:		0.084006
  validation loss:		0.429764
  validation accuracy:		91.74 %
Epoch 1817 of 2000 took 0.099s
  training loss:		0.085032
  validation loss:		0.405078
  validation accuracy:		91.85 %
Epoch 1818 of 2000 took 0.096s
  training loss:		0.084741
  validation loss:		0.397222
  validation accuracy:		91.74 %
Epoch 1819 of 2000 took 0.100s
  training loss:		0.085285
  validation loss:		0.415350
  validation accuracy:		91.74 %
Epoch 1820 of 2000 took 0.096s
  training loss:		0.083179
  validation loss:		0.404522
  validation accuracy:		91.85 %
Epoch 1821 of 2000 took 0.097s
  training loss:		0.081896
  validation loss:		0.396957
  validation accuracy:		91.85 %
Epoch 1822 of 2000 took 0.099s
  training loss:		0.081804
  validation loss:		0.408220
  validation accuracy:		91.96 %
Epoch 1823 of 2000 took 0.096s
  training loss:		0.083059
  validation loss:		0.411217
  validation accuracy:		91.30 %
Epoch 1824 of 2000 took 0.100s
  training loss:		0.082568
  validation loss:		0.416093
  validation accuracy:		91.09 %
Epoch 1825 of 2000 took 0.096s
  training loss:		0.079780
  validation loss:		0.411997
  validation accuracy:		91.52 %
Epoch 1826 of 2000 took 0.099s
  training loss:		0.080355
  validation loss:		0.408141
  validation accuracy:		91.96 %
Epoch 1827 of 2000 took 0.097s
  training loss:		0.081722
  validation loss:		0.386860
  validation accuracy:		92.50 %
Epoch 1828 of 2000 took 0.097s
  training loss:		0.080975
  validation loss:		0.433534
  validation accuracy:		91.30 %
Epoch 1829 of 2000 took 0.099s
  training loss:		0.081948
  validation loss:		0.397575
  validation accuracy:		91.85 %
Epoch 1830 of 2000 took 0.096s
  training loss:		0.079427
  validation loss:		0.389869
  validation accuracy:		92.28 %
Epoch 1831 of 2000 took 0.100s
  training loss:		0.082555
  validation loss:		0.417039
  validation accuracy:		91.30 %
Epoch 1832 of 2000 took 0.096s
  training loss:		0.079776
  validation loss:		0.404200
  validation accuracy:		91.74 %
Epoch 1833 of 2000 took 0.097s
  training loss:		0.081450
  validation loss:		0.409923
  validation accuracy:		91.74 %
Epoch 1834 of 2000 took 0.098s
  training loss:		0.080462
  validation loss:		0.420037
  validation accuracy:		91.09 %
Epoch 1835 of 2000 took 0.096s
  training loss:		0.078034
  validation loss:		0.408923
  validation accuracy:		91.52 %
Epoch 1836 of 2000 took 0.099s
  training loss:		0.083925
  validation loss:		0.409251
  validation accuracy:		91.74 %
Epoch 1837 of 2000 took 0.096s
  training loss:		0.079406
  validation loss:		0.430376
  validation accuracy:		91.09 %
Epoch 1838 of 2000 took 0.099s
  training loss:		0.081892
  validation loss:		0.434197
  validation accuracy:		91.52 %
Epoch 1839 of 2000 took 0.096s
  training loss:		0.081789
  validation loss:		0.416367
  validation accuracy:		91.63 %
Epoch 1840 of 2000 took 0.097s
  training loss:		0.081752
  validation loss:		0.419902
  validation accuracy:		91.30 %
Epoch 1841 of 2000 took 0.102s
  training loss:		0.076639
  validation loss:		0.399730
  validation accuracy:		91.74 %
Epoch 1842 of 2000 took 0.096s
  training loss:		0.081650
  validation loss:		0.446781
  validation accuracy:		91.52 %
Epoch 1843 of 2000 took 0.097s
  training loss:		0.083040
  validation loss:		0.422153
  validation accuracy:		91.63 %
Epoch 1844 of 2000 took 0.096s
  training loss:		0.080142
  validation loss:		0.406386
  validation accuracy:		91.63 %
Epoch 1845 of 2000 took 0.099s
  training loss:		0.080235
  validation loss:		0.418339
  validation accuracy:		91.30 %
Epoch 1846 of 2000 took 0.099s
  training loss:		0.079728
  validation loss:		0.426369
  validation accuracy:		91.09 %
Epoch 1847 of 2000 took 0.099s
  training loss:		0.078598
  validation loss:		0.410775
  validation accuracy:		91.52 %
Epoch 1848 of 2000 took 0.102s
  training loss:		0.078119
  validation loss:		0.417244
  validation accuracy:		92.07 %
Epoch 1849 of 2000 took 0.103s
  training loss:		0.077131
  validation loss:		0.414633
  validation accuracy:		91.74 %
Epoch 1850 of 2000 took 0.099s
  training loss:		0.078766
  validation loss:		0.422980
  validation accuracy:		91.74 %
Epoch 1851 of 2000 took 0.100s
  training loss:		0.077229
  validation loss:		0.437696
  validation accuracy:		91.74 %
Epoch 1852 of 2000 took 0.099s
  training loss:		0.082920
  validation loss:		0.424169
  validation accuracy:		91.85 %
Epoch 1853 of 2000 took 0.104s
  training loss:		0.077428
  validation loss:		0.410058
  validation accuracy:		91.52 %
Epoch 1854 of 2000 took 0.101s
  training loss:		0.076837
  validation loss:		0.421178
  validation accuracy:		91.74 %
Epoch 1855 of 2000 took 0.099s
  training loss:		0.080393
  validation loss:		0.414826
  validation accuracy:		91.96 %
Epoch 1856 of 2000 took 0.105s
  training loss:		0.081261
  validation loss:		0.424623
  validation accuracy:		91.85 %
Epoch 1857 of 2000 took 0.100s
  training loss:		0.075918
  validation loss:		0.407475
  validation accuracy:		91.96 %
Epoch 1858 of 2000 took 0.100s
  training loss:		0.077848
  validation loss:		0.410985
  validation accuracy:		91.96 %
Epoch 1859 of 2000 took 0.099s
  training loss:		0.078143
  validation loss:		0.426458
  validation accuracy:		91.30 %
Epoch 1860 of 2000 took 0.100s
  training loss:		0.076650
  validation loss:		0.433271
  validation accuracy:		91.96 %
Epoch 1861 of 2000 took 0.103s
  training loss:		0.078931
  validation loss:		0.408721
  validation accuracy:		91.74 %
Epoch 1862 of 2000 took 0.100s
  training loss:		0.078219
  validation loss:		0.410575
  validation accuracy:		91.85 %
Epoch 1863 of 2000 took 0.100s
  training loss:		0.074174
  validation loss:		0.407816
  validation accuracy:		92.39 %
Epoch 1864 of 2000 took 0.105s
  training loss:		0.074279
  validation loss:		0.436671
  validation accuracy:		91.52 %
Epoch 1865 of 2000 took 0.099s
  training loss:		0.078596
  validation loss:		0.426000
  validation accuracy:		91.30 %
Epoch 1866 of 2000 took 0.100s
  training loss:		0.079527
  validation loss:		0.447290
  validation accuracy:		91.09 %
Epoch 1867 of 2000 took 0.099s
  training loss:		0.076340
  validation loss:		0.436761
  validation accuracy:		91.41 %
Epoch 1868 of 2000 took 0.101s
  training loss:		0.076280
  validation loss:		0.424507
  validation accuracy:		91.74 %
Epoch 1869 of 2000 took 0.102s
  training loss:		0.074895
  validation loss:		0.433407
  validation accuracy:		91.30 %
Epoch 1870 of 2000 took 0.099s
  training loss:		0.076851
  validation loss:		0.422158
  validation accuracy:		91.63 %
Epoch 1871 of 2000 took 0.101s
  training loss:		0.074616
  validation loss:		0.418414
  validation accuracy:		91.63 %
Epoch 1872 of 2000 took 0.104s
  training loss:		0.078761
  validation loss:		0.417538
  validation accuracy:		91.63 %
Epoch 1873 of 2000 took 0.099s
  training loss:		0.078322
  validation loss:		0.427219
  validation accuracy:		92.07 %
Epoch 1874 of 2000 took 0.100s
  training loss:		0.078080
  validation loss:		0.425182
  validation accuracy:		91.63 %
Epoch 1875 of 2000 took 0.099s
  training loss:		0.077752
  validation loss:		0.432621
  validation accuracy:		91.41 %
Epoch 1876 of 2000 took 0.104s
  training loss:		0.072888
  validation loss:		0.429586
  validation accuracy:		91.74 %
Epoch 1877 of 2000 took 0.101s
  training loss:		0.076986
  validation loss:		0.448107
  validation accuracy:		91.41 %
Epoch 1878 of 2000 took 0.099s
  training loss:		0.074416
  validation loss:		0.444717
  validation accuracy:		91.30 %
Epoch 1879 of 2000 took 0.105s
  training loss:		0.075431
  validation loss:		0.430766
  validation accuracy:		91.63 %
Epoch 1880 of 2000 took 0.100s
  training loss:		0.073902
  validation loss:		0.446367
  validation accuracy:		91.41 %
Epoch 1881 of 2000 took 0.100s
  training loss:		0.075174
  validation loss:		0.422045
  validation accuracy:		91.20 %
Epoch 1882 of 2000 took 0.099s
  training loss:		0.076158
  validation loss:		0.458328
  validation accuracy:		91.30 %
Epoch 1883 of 2000 took 0.100s
  training loss:		0.080523
  validation loss:		0.433807
  validation accuracy:		91.41 %
Epoch 1884 of 2000 took 0.104s
  training loss:		0.078510
  validation loss:		0.433351
  validation accuracy:		91.52 %
Epoch 1885 of 2000 took 0.100s
  training loss:		0.073863
  validation loss:		0.438110
  validation accuracy:		91.63 %
Epoch 1886 of 2000 took 0.099s
  training loss:		0.074626
  validation loss:		0.437244
  validation accuracy:		91.52 %
Epoch 1887 of 2000 took 0.103s
  training loss:		0.075493
  validation loss:		0.427160
  validation accuracy:		91.52 %
Epoch 1888 of 2000 took 0.096s
  training loss:		0.072793
  validation loss:		0.444234
  validation accuracy:		91.20 %
Epoch 1889 of 2000 took 0.097s
  training loss:		0.075472
  validation loss:		0.439188
  validation accuracy:		91.52 %
Epoch 1890 of 2000 took 0.096s
  training loss:		0.073273
  validation loss:		0.438342
  validation accuracy:		91.52 %
Epoch 1891 of 2000 took 0.098s
  training loss:		0.075269
  validation loss:		0.437522
  validation accuracy:		91.52 %
Epoch 1892 of 2000 took 0.100s
  training loss:		0.072787
  validation loss:		0.456020
  validation accuracy:		91.09 %
Epoch 1893 of 2000 took 0.096s
  training loss:		0.075351
  validation loss:		0.431889
  validation accuracy:		91.30 %
Epoch 1894 of 2000 took 0.098s
  training loss:		0.073178
  validation loss:		0.451042
  validation accuracy:		91.20 %
Epoch 1895 of 2000 took 0.101s
  training loss:		0.071571
  validation loss:		0.426575
  validation accuracy:		91.52 %
Epoch 1896 of 2000 took 0.096s
  training loss:		0.073448
  validation loss:		0.434602
  validation accuracy:		91.74 %
Epoch 1897 of 2000 took 0.097s
  training loss:		0.072138
  validation loss:		0.455203
  validation accuracy:		91.63 %
Epoch 1898 of 2000 took 0.096s
  training loss:		0.071158
  validation loss:		0.433935
  validation accuracy:		91.20 %
Epoch 1899 of 2000 took 0.101s
  training loss:		0.075426
  validation loss:		0.459511
  validation accuracy:		91.52 %
Epoch 1900 of 2000 took 0.098s
  training loss:		0.073561
  validation loss:		0.445128
  validation accuracy:		91.20 %
Epoch 1901 of 2000 took 0.096s
  training loss:		0.073649
  validation loss:		0.430370
  validation accuracy:		92.17 %
Epoch 1902 of 2000 took 0.101s
  training loss:		0.072225
  validation loss:		0.452537
  validation accuracy:		91.63 %
Epoch 1903 of 2000 took 0.097s
  training loss:		0.072077
  validation loss:		0.441490
  validation accuracy:		91.30 %
Epoch 1904 of 2000 took 0.097s
  training loss:		0.073554
  validation loss:		0.445302
  validation accuracy:		91.41 %
Epoch 1905 of 2000 took 0.097s
  training loss:		0.072981
  validation loss:		0.439961
  validation accuracy:		91.41 %
Epoch 1906 of 2000 took 0.097s
  training loss:		0.073755
  validation loss:		0.445711
  validation accuracy:		91.52 %
Epoch 1907 of 2000 took 0.100s
  training loss:		0.072515
  validation loss:		0.452878
  validation accuracy:		91.85 %
Epoch 1908 of 2000 took 0.097s
  training loss:		0.073335
  validation loss:		0.443917
  validation accuracy:		91.74 %
Epoch 1909 of 2000 took 0.097s
  training loss:		0.075412
  validation loss:		0.451545
  validation accuracy:		91.63 %
Epoch 1910 of 2000 took 0.102s
  training loss:		0.069964
  validation loss:		0.458629
  validation accuracy:		91.41 %
Epoch 1911 of 2000 took 0.096s
  training loss:		0.069676
  validation loss:		0.459036
  validation accuracy:		91.30 %
Epoch 1912 of 2000 took 0.097s
  training loss:		0.072360
  validation loss:		0.458801
  validation accuracy:		91.30 %
Epoch 1913 of 2000 took 0.096s
  training loss:		0.071716
  validation loss:		0.453597
  validation accuracy:		91.41 %
Epoch 1914 of 2000 took 0.098s
  training loss:		0.074479
  validation loss:		0.460652
  validation accuracy:		91.20 %
Epoch 1915 of 2000 took 0.100s
  training loss:		0.068104
  validation loss:		0.485381
  validation accuracy:		90.65 %
Epoch 1916 of 2000 took 0.096s
  training loss:		0.072344
  validation loss:		0.478762
  validation accuracy:		91.09 %
Epoch 1917 of 2000 took 0.097s
  training loss:		0.071093
  validation loss:		0.468028
  validation accuracy:		91.30 %
Epoch 1918 of 2000 took 0.102s
  training loss:		0.071518
  validation loss:		0.425222
  validation accuracy:		92.39 %
Epoch 1919 of 2000 took 0.096s
  training loss:		0.069089
  validation loss:		0.453952
  validation accuracy:		91.63 %
Epoch 1920 of 2000 took 0.097s
  training loss:		0.073587
  validation loss:		0.448138
  validation accuracy:		91.41 %
Epoch 1921 of 2000 took 0.096s
  training loss:		0.070314
  validation loss:		0.458148
  validation accuracy:		91.41 %
Epoch 1922 of 2000 took 0.100s
  training loss:		0.069512
  validation loss:		0.440032
  validation accuracy:		92.28 %
Epoch 1923 of 2000 took 0.098s
  training loss:		0.071411
  validation loss:		0.461938
  validation accuracy:		91.41 %
Epoch 1924 of 2000 took 0.096s
  training loss:		0.074957
  validation loss:		0.484647
  validation accuracy:		91.09 %
Epoch 1925 of 2000 took 0.101s
  training loss:		0.070623
  validation loss:		0.457932
  validation accuracy:		91.30 %
Epoch 1926 of 2000 took 0.098s
  training loss:		0.070216
  validation loss:		0.473777
  validation accuracy:		91.09 %
Epoch 1927 of 2000 took 0.097s
  training loss:		0.070371
  validation loss:		0.458190
  validation accuracy:		91.52 %
Epoch 1928 of 2000 took 0.097s
  training loss:		0.069941
  validation loss:		0.477861
  validation accuracy:		91.09 %
Epoch 1929 of 2000 took 0.097s
  training loss:		0.070176
  validation loss:		0.458277
  validation accuracy:		91.63 %
Epoch 1930 of 2000 took 0.100s
  training loss:		0.071213
  validation loss:		0.456302
  validation accuracy:		91.41 %
Epoch 1931 of 2000 took 0.097s
  training loss:		0.068537
  validation loss:		0.454916
  validation accuracy:		91.30 %
Epoch 1932 of 2000 took 0.096s
  training loss:		0.074552
  validation loss:		0.457689
  validation accuracy:		91.30 %
Epoch 1933 of 2000 took 0.103s
  training loss:		0.070731
  validation loss:		0.470981
  validation accuracy:		90.87 %
Epoch 1934 of 2000 took 0.096s
  training loss:		0.072638
  validation loss:		0.452076
  validation accuracy:		91.52 %
Epoch 1935 of 2000 took 0.097s
  training loss:		0.069692
  validation loss:		0.461272
  validation accuracy:		91.20 %
Epoch 1936 of 2000 took 0.096s
  training loss:		0.068359
  validation loss:		0.488269
  validation accuracy:		91.52 %
Epoch 1937 of 2000 took 0.098s
  training loss:		0.068382
  validation loss:		0.452351
  validation accuracy:		91.52 %
Epoch 1938 of 2000 took 0.100s
  training loss:		0.068807
  validation loss:		0.451106
  validation accuracy:		91.41 %
Epoch 1939 of 2000 took 0.096s
  training loss:		0.068793
  validation loss:		0.459950
  validation accuracy:		91.41 %
Epoch 1940 of 2000 took 0.097s
  training loss:		0.067938
  validation loss:		0.460190
  validation accuracy:		91.41 %
Epoch 1941 of 2000 took 0.102s
  training loss:		0.072416
  validation loss:		0.475025
  validation accuracy:		91.20 %
Epoch 1942 of 2000 took 0.096s
  training loss:		0.067010
  validation loss:		0.467626
  validation accuracy:		91.41 %
Epoch 1943 of 2000 took 0.097s
  training loss:		0.067596
  validation loss:		0.478493
  validation accuracy:		90.98 %
Epoch 1944 of 2000 took 0.096s
  training loss:		0.070051
  validation loss:		0.479435
  validation accuracy:		91.09 %
Epoch 1945 of 2000 took 0.099s
  training loss:		0.066710
  validation loss:		0.453586
  validation accuracy:		91.96 %
Epoch 1946 of 2000 took 0.099s
  training loss:		0.069827
  validation loss:		0.468853
  validation accuracy:		91.41 %
Epoch 1947 of 2000 took 0.096s
  training loss:		0.067206
  validation loss:		0.467699
  validation accuracy:		91.30 %
Epoch 1948 of 2000 took 0.099s
  training loss:		0.069043
  validation loss:		0.466025
  validation accuracy:		91.30 %
Epoch 1949 of 2000 took 0.100s
  training loss:		0.066088
  validation loss:		0.486438
  validation accuracy:		90.87 %
Epoch 1950 of 2000 took 0.096s
  training loss:		0.068313
  validation loss:		0.464453
  validation accuracy:		91.63 %
Epoch 1951 of 2000 took 0.097s
  training loss:		0.067876
  validation loss:		0.460588
  validation accuracy:		91.30 %
Epoch 1952 of 2000 took 0.096s
  training loss:		0.065321
  validation loss:		0.458399
  validation accuracy:		91.52 %
Epoch 1953 of 2000 took 0.101s
  training loss:		0.068017
  validation loss:		0.493862
  validation accuracy:		90.98 %
Epoch 1954 of 2000 took 0.097s
  training loss:		0.067315
  validation loss:		0.500826
  validation accuracy:		91.30 %
Epoch 1955 of 2000 took 0.096s
  training loss:		0.069552
  validation loss:		0.473739
  validation accuracy:		91.41 %
Epoch 1956 of 2000 took 0.102s
  training loss:		0.066821
  validation loss:		0.483667
  validation accuracy:		91.52 %
Epoch 1957 of 2000 took 0.096s
  training loss:		0.063171
  validation loss:		0.470557
  validation accuracy:		91.63 %
Epoch 1958 of 2000 took 0.097s
  training loss:		0.068514
  validation loss:		0.477416
  validation accuracy:		91.20 %
Epoch 1959 of 2000 took 0.096s
  training loss:		0.068148
  validation loss:		0.484092
  validation accuracy:		91.52 %
Epoch 1960 of 2000 took 0.097s
  training loss:		0.068431
  validation loss:		0.480953
  validation accuracy:		91.20 %
Epoch 1961 of 2000 took 0.100s
  training loss:		0.068940
  validation loss:		0.486919
  validation accuracy:		91.30 %
Epoch 1962 of 2000 took 0.096s
  training loss:		0.065249
  validation loss:		0.486336
  validation accuracy:		91.30 %
Epoch 1963 of 2000 took 0.097s
  training loss:		0.066037
  validation loss:		0.467054
  validation accuracy:		91.52 %
Epoch 1964 of 2000 took 0.102s
  training loss:		0.066408
  validation loss:		0.489383
  validation accuracy:		91.52 %
Epoch 1965 of 2000 took 0.096s
  training loss:		0.069032
  validation loss:		0.498624
  validation accuracy:		91.52 %
Epoch 1966 of 2000 took 0.097s
  training loss:		0.066258
  validation loss:		0.468461
  validation accuracy:		91.30 %
Epoch 1967 of 2000 took 0.096s
  training loss:		0.066846
  validation loss:		0.489421
  validation accuracy:		91.09 %
Epoch 1968 of 2000 took 0.099s
  training loss:		0.067654
  validation loss:		0.476095
  validation accuracy:		91.20 %
Epoch 1969 of 2000 took 0.099s
  training loss:		0.067881
  validation loss:		0.488077
  validation accuracy:		91.09 %
Epoch 1970 of 2000 took 0.096s
  training loss:		0.067829
  validation loss:		0.493158
  validation accuracy:		91.30 %
Epoch 1971 of 2000 took 0.099s
  training loss:		0.066481
  validation loss:		0.508764
  validation accuracy:		90.98 %
Epoch 1972 of 2000 took 0.100s
  training loss:		0.067101
  validation loss:		0.476183
  validation accuracy:		91.52 %
Epoch 1973 of 2000 took 0.096s
  training loss:		0.069111
  validation loss:		0.493182
  validation accuracy:		91.41 %
Epoch 1974 of 2000 took 0.097s
  training loss:		0.066523
  validation loss:		0.472204
  validation accuracy:		91.74 %
Epoch 1975 of 2000 took 0.096s
  training loss:		0.067971
  validation loss:		0.500232
  validation accuracy:		91.41 %
Epoch 1976 of 2000 took 0.101s
  training loss:		0.067108
  validation loss:		0.485949
  validation accuracy:		91.09 %
Epoch 1977 of 2000 took 0.097s
  training loss:		0.063524
  validation loss:		0.488873
  validation accuracy:		91.41 %
Epoch 1978 of 2000 took 0.096s
  training loss:		0.067962
  validation loss:		0.471842
  validation accuracy:		91.63 %
Epoch 1979 of 2000 took 0.102s
  training loss:		0.063674
  validation loss:		0.479964
  validation accuracy:		91.52 %
Epoch 1980 of 2000 took 0.097s
  training loss:		0.066462
  validation loss:		0.481978
  validation accuracy:		91.41 %
Epoch 1981 of 2000 took 0.097s
  training loss:		0.067264
  validation loss:		0.490375
  validation accuracy:		91.41 %
Epoch 1982 of 2000 took 0.096s
  training loss:		0.063866
  validation loss:		0.487636
  validation accuracy:		91.30 %
Epoch 1983 of 2000 took 0.097s
  training loss:		0.063537
  validation loss:		0.477594
  validation accuracy:		91.52 %
Epoch 1984 of 2000 took 0.100s
  training loss:		0.062832
  validation loss:		0.505122
  validation accuracy:		91.30 %
Epoch 1985 of 2000 took 0.097s
  training loss:		0.067824
  validation loss:		0.492055
  validation accuracy:		91.30 %
Epoch 1986 of 2000 took 0.097s
  training loss:		0.065989
  validation loss:		0.458931
  validation accuracy:		91.96 %
Epoch 1987 of 2000 took 0.102s
  training loss:		0.065088
  validation loss:		0.476622
  validation accuracy:		91.85 %
Epoch 1988 of 2000 took 0.096s
  training loss:		0.066700
  validation loss:		0.488458
  validation accuracy:		91.20 %
Epoch 1989 of 2000 took 0.097s
  training loss:		0.062758
  validation loss:		0.500410
  validation accuracy:		91.52 %
Epoch 1990 of 2000 took 0.096s
  training loss:		0.064049
  validation loss:		0.502804
  validation accuracy:		91.20 %
Epoch 1991 of 2000 took 0.098s
  training loss:		0.063289
  validation loss:		0.489326
  validation accuracy:		91.52 %
Epoch 1992 of 2000 took 0.100s
  training loss:		0.060713
  validation loss:		0.494009
  validation accuracy:		91.20 %
Epoch 1993 of 2000 took 0.096s
  training loss:		0.063396
  validation loss:		0.496963
  validation accuracy:		91.85 %
Epoch 1994 of 2000 took 0.098s
  training loss:		0.063504
  validation loss:		0.472103
  validation accuracy:		92.50 %
Epoch 1995 of 2000 took 0.101s
  training loss:		0.068271
  validation loss:		0.477185
  validation accuracy:		92.07 %
Epoch 1996 of 2000 took 0.096s
  training loss:		0.063551
  validation loss:		0.488844
  validation accuracy:		91.52 %
Epoch 1997 of 2000 took 0.097s
  training loss:		0.061328
  validation loss:		0.538631
  validation accuracy:		91.20 %
Epoch 1998 of 2000 took 0.096s
  training loss:		0.068029
  validation loss:		0.511392
  validation accuracy:		90.87 %
Epoch 1999 of 2000 took 0.101s
  training loss:		0.064307
  validation loss:		0.483447
  validation accuracy:		91.52 %
Epoch 2000 of 2000 took 0.098s
  training loss:		0.064573
  validation loss:		0.509729
  validation accuracy:		90.87 %
Final results:
  test loss:			1.161546
  test accuracy:		82.98 %
